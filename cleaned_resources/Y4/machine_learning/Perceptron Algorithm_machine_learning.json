{
  "title": "Perceptron Algorithm",
  "language": "javascript",
  "topics": [
    "machine_learning",
    "fundamentals",
    "networking",
    "algorithms",
    "database"
  ],
  "purpose": "\u25cf neural network.",
  "code": "Simplest output function\n\u25cf\nUsed to classify patterns said to be linearly\n\u25cf\nseparable\nLinearly Separable\nLinearly Separable\nThe bias is proportional to the offset of the plane\nfrom the origin\nThe weights determine the slope of the line\nThe weight vector\nis perpendicular to\nthe plane\nPerceptron Learning Algorithm\nWe want to train the perceptron to classify\n\u25cf\ninputs correctly\nAccomplished by adjusting the connecting\n\u25cf\nweights and the bias\nCan only properly handle linearly separable\n\u25cf\nsets\nPerceptron Learning Algorithm\nWe have a \u201ctraining set\u201d which is a set of input\n\u25cf\nvectors used to train the perceptron.\nq\nDuring training both w and (bias) are modified\n\u25cf\ni\nq\nfor convenience, let w = and x = 1\n0 0\nh ,\nLet, the learning rate, be a small positive\n\u25cf\nnumber (small steps lessen the possibility of\ndestroying correct classifications)\nInitialise w to some values\n\u25cf\ni\nPerceptron Learning Algorithm\n1 if x n set A\n{\ue083 \ue09e \ue09f\u2208 }\nDesired output d n\n\ue09e \ue09f =\n1 if x n set B\n\u2212 \ue09e \ue09f\u2208\n1. Select random sample from training set as input\n2. If classification is correct, do nothing\n3. If classification is incorrect, modify the weight\nvector w using\nw w \u03b7d n x n\n= \ue083 \ue09e \ue09f \ue09e \ue09f\ni i i\nRepeat this procedure until the entire training set\nis classified correctly\nLearning Example\nInitial Values:\nh =\n0.2\n0\n\ue09e \ue09f\nw\n= 1\n0.5\n0 w w x w x\n= \ue083 \ue083\n0 1 1 2 2\n0 x 0.5x\n= \ue083 \ue083\n1 2\nx 2x\n\u21d2 = \u2212\n2 1\nLearning Example\nh =\n0.2\n0\n\ue09e \ue09f\nw\n= 1\n0.5\nx = 1, x = 1\n1 2\nwTx > 0\nCorrect classification,\nno action\nLearning Example\nh =\n0.2\n0\n\ue09e \ue09f\nw\n= 1\n0.5\nx = 2, x = -2\n1 2\nw w 0.2 1\n= \u2212 \u2217\n0 0\nw w 0.2 2\n= \u2212 \u2217\n1 1\nw w 0.2 2\n= \u2212 \u2217\ue09e\u2212 \ue09f\n2 2\nLearning Example\nh =\n0.2\n0.2\n\ue09e\u2212 \ue09f\nw\n= 0.6\n0.9\nx = 2, x = -2\n1 2\nw w 0.2 1\n= \u2212 \u2217\n0 0\nw w 0.2 2\n= \u2212 \u2217\n1 1\nw w 0.2 2\n= \u2212 \u2217\ue09e\u2212 \ue09f\n2 2\nLearning Example\nh =\n0.2\n0.2\n\ue09e\u2212 \ue09f\nw\n= 0.6\n0.9\nx = -1, x = -1.5\n1 2\nwTx < 0\nCorrect classification,\nno action\nLearning Example\nh =\n0.2\n0.2\n\ue09e\u2212 \ue09f\nw\n= 0.6\n0.9\nx = -2, x = -1\n1 2\nwTx < 0\nCorrect classification,\nno action\nLearning Example\nh =\n0.2\n0.2\n\ue09e\u2212 \ue09f\nw\n= 0.6\n0.9\nx = -2, x = 1\n1 2\nw w 0.2 1\n= \ue083 \u2217\n0 0\nw w 0.2 2\n= \ue083 \u2217\ue09e\u2212 \ue09f\n1 1\nw w 0.2 1\n= \ue083 \u2217\n2 2\nLearning Example\nh =\n0.2\n0\n\ue09e \ue09f\nw\n= 0.2\n1.1\nx = -2, x = 1\n1 2\nw w 0.2 1\n= \ue083 \u2217\n0 0\nw w 0.2 2\n= \ue083 \u2217\ue09e\u2212 \ue09f\n1 1\nw w 0.2 1\n= \ue083 \u2217\n2 2\nLearning Example\nh =\n0.2\n0\n\ue09e \ue09f\nw\n= 0.2\n1.1\nx = 1.5, x = -0.5\n1 2\nw w 0.2 1\n= \ue083 \u2217\n0 0\nw w 0.2 1.5\n= \ue083 \u2217\n1 1\nw w 0.2 0.5\n= \ue083 \u2217\ue09e\u2212 \ue09f\n2 2\nLearning Example\nh =\n0.2\n0.2\n\ue09e \ue09f\nw\n= 0.5\n1\nx = 1.5, x = -0.5\n1 2\nw w 0.2 1\n= \ue083 \u2217\n0 0\nw w 0.2 1.5\n= \ue083 \u2217\n1 1\nw w 0.2 0.5\n= \ue083 \u2217\ue09e\u2212 \ue09f\n2 2\nThe End\n",
  "context": "\u25cf\nneural network.\nSimple Perceptron",
  "source_file": "resources\\Year 4\\Perceptron Algorithm.pdf",
  "line_numbers": [
    7,
    237
  ]
}