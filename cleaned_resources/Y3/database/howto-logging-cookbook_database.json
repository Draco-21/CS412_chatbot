{
  "title": "howto-logging-cookbook",
  "language": "cpp",
  "topics": [
    "machine_learning",
    "web_dev",
    "fundamentals",
    "algorithms",
    "data_structures",
    "networking",
    "database"
  ],
  "purpose": "20 Amoreelaboratemultiprocessingexample 37 21 InsertingaBOMintomessagessenttoaSysLogHandler 41 22 Implementingstructuredlogging 41",
  "code": "23 CustomizinghandlerswithdictConfig() 43\n24 Usingparticularformattingstylesthroughoutyourapplication 45\n24.1 UsingLogRecordfactories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n24.2 Usingcustommessageobjects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n25 ConfiguringfilterswithdictConfig() 46\n26 Customizedexceptionformatting 48\n27 Speakingloggingmessages 48\n28 Bufferingloggingmessagesandoutputtingthemconditionally 49\n29 Sendingloggingmessagestoemail,withbuffering 51\n30 FormattingtimesusingUTC(GMT)viaconfiguration 53\n31 Usingacontextmanagerforselectivelogging 54\n32 ACLIapplicationstartertemplate 55\n33 AQtGUIforlogging 58\n34 LoggingtosyslogwithRFC5424support 62\n35 Howtotreataloggerlikeanoutputstream 64\n36 Patternstoavoid 66\n36.1 Openingthesamelogfilemultipletimes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n36.2 Usingloggersasattributesinaclassorpassingthemasparameters . . . . . . . . . . . . . . . . . 67\n36.3 AddinghandlersotherthanNullHandlertoaloggerinalibrary . . . . . . . . . . . . . . . . . . 67\n36.4 Creatingalotofloggers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n37 Otherresources 67\nIndex 68\nAuthor\nVinaySajip<vinay_sajipatred-dovedotcom>\nThis page contains a number of recipes related to logging, which have been found useful in the past. For links to\ntutorialandreferenceinformation,pleaseseeOtherresources.\n2\n1 Using logging in multiple modules\nMultiplecallstologging.getLogger('someLogger')returnareferencetothesameloggerobject. Thisistrue\nnotonlywithinthesamemodule,butalsoacrossmodulesaslongasitisinthesamePythoninterpreterprocess. Itis\ntrueforreferencestothesameobject;additionally,applicationcodecandefineandconfigureaparentloggerinone\nmoduleandcreate(butnotconfigure)achildloggerinaseparatemodule,andallloggercallstothechildwillpass\nuptotheparent. Hereisamainmodule:\nimport logging\nimport auxiliary_module\n# create logger with 'spam_application'\nlogger = logging.getLogger('spam_application')\nlogger.setLevel(logging.DEBUG)\n# create file handler which logs even debug messages\nfh = logging.FileHandler('spam.log')\nfh.setLevel(logging.DEBUG)\n# create console handler with a higher log level\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\n# create formatter and add it to the handlers\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s\n,\u2192')\nfh.setFormatter(formatter)\nch.setFormatter(formatter)\n# add the handlers to the logger\nlogger.addHandler(fh)\nlogger.addHandler(ch)\nlogger.info('creating an instance of auxiliary_module.Auxiliary')\na = auxiliary_module.Auxiliary()\nlogger.info('created an instance of auxiliary_module.Auxiliary')\nlogger.info('calling auxiliary_module.Auxiliary.do_something')\na.do_something()\nlogger.info('finished auxiliary_module.Auxiliary.do_something')\nlogger.info('calling auxiliary_module.some_function()')\nauxiliary_module.some_function()\nlogger.info('done with auxiliary_module.some_function()')\nHereistheauxiliarymodule:\nimport logging\n# create logger\nmodule_logger = logging.getLogger('spam_application.auxiliary')\nclass Auxiliary:\ndef __init__(self):\nself.logger = logging.getLogger('spam_application.auxiliary.Auxiliary')\nself.logger.info('creating an instance of Auxiliary')\ndef do_something(self):\nself.logger.info('doing something')\na = 1 + 1\nself.logger.info('done doing something')\ndef some_function():\nmodule_logger.info('received a call to \"some_function\"')\n3\nTheoutputlookslikethis:\n2005-03-23 23:47:11,663 - spam_application - INFO -\ncreating an instance of auxiliary_module.Auxiliary\n2005-03-23 23:47:11,665 - spam_application.auxiliary.Auxiliary - INFO -\ncreating an instance of Auxiliary\n2005-03-23 23:47:11,665 - spam_application - INFO -\ncreated an instance of auxiliary_module.Auxiliary\n2005-03-23 23:47:11,668 - spam_application - INFO -\ncalling auxiliary_module.Auxiliary.do_something\n2005-03-23 23:47:11,668 - spam_application.auxiliary.Auxiliary - INFO -\ndoing something\n2005-03-23 23:47:11,669 - spam_application.auxiliary.Auxiliary - INFO -\ndone doing something\n2005-03-23 23:47:11,670 - spam_application - INFO -\nfinished auxiliary_module.Auxiliary.do_something\n2005-03-23 23:47:11,671 - spam_application - INFO -\ncalling auxiliary_module.some_function()\n2005-03-23 23:47:11,672 - spam_application.auxiliary - INFO -\nreceived a call to 'some_function'\n2005-03-23 23:47:11,673 - spam_application - INFO -\ndone with auxiliary_module.some_function()\n2 Logging from multiple threads\nLoggingfrommultiplethreadsrequiresnospecialeffort. Thefollowingexampleshowsloggingfromthemain(initial)\nthreadandanotherthread:\nimport logging\nimport threading\nimport time\ndef worker(arg):\nwhile not arg['stop']:\nlogging.debug('Hi from myfunc')\ntime.sleep(0.5)\ndef main():\nlogging.basicConfig(level=logging.DEBUG, format='%(relativeCreated)6d\n,\u2192%(threadName)s %(message)s')\ninfo = {'stop': False}\nthread = threading.Thread(target=worker, args=(info,))\nthread.start()\nwhile True:\ntry:\nlogging.debug('Hello from main')\ntime.sleep(0.75)\nexcept KeyboardInterrupt:\ninfo['stop'] = True\nbreak\nthread.join()\nif __name__ == '__main__':\nmain()\nWhenrun,thescriptshouldprintsomethinglikethefollowing:\n4\n0 Thread-1 Hi from myfunc\n3 MainThread Hello from main\n505 Thread-1 Hi from myfunc\n755 MainThread Hello from main\n1007 Thread-1 Hi from myfunc\n1507 MainThread Hello from main\n1508 Thread-1 Hi from myfunc\n2010 Thread-1 Hi from myfunc\n2258 MainThread Hello from main\n2512 Thread-1 Hi from myfunc\n3009 MainThread Hello from main\n3013 Thread-1 Hi from myfunc\n3515 Thread-1 Hi from myfunc\n3761 MainThread Hello from main\n4017 Thread-1 Hi from myfunc\n4513 MainThread Hello from main\n4518 Thread-1 Hi from myfunc\nThisshowstheloggingoutputinterspersedasonemightexpect. Thisapproachworksformorethreadsthanshown\nhere,ofcourse.\n3 Multiple handlers and formatters\nLoggersareplainPythonobjects. TheaddHandler()methodhasnominimumormaximumquotaforthenumber\nofhandlersyoumayadd. Sometimesitwillbebeneficialforanapplicationtologallmessagesofallseveritiestoa\ntextfilewhilesimultaneouslyloggingerrorsorabovetotheconsole. Tosetthisup,simplyconfiguretheappropriate\nhandlers. The logging calls in the application code will remain unchanged. Here is a slight modification to the\nprevioussimplemodule-basedconfigurationexample:\nimport logging\nlogger = logging.getLogger('simple_example')\nlogger.setLevel(logging.DEBUG)\n# create file handler which logs even debug messages\nfh = logging.FileHandler('spam.log')\nfh.setLevel(logging.DEBUG)\n# create console handler with a higher log level\nch = logging.StreamHandler()\nch.setLevel(logging.ERROR)\n# create formatter and add it to the handlers\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s\n,\u2192')\nch.setFormatter(formatter)\nfh.setFormatter(formatter)\n# add the handlers to logger\nlogger.addHandler(ch)\nlogger.addHandler(fh)\n# 'application' code\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message')\nNotice that the \u2018application\u2019 code does not care about multiple handlers. All that changed was the addition and\nconfigurationofanewhandlernamedfh.\n5\nTheabilitytocreatenewhandlerswithhigher-orlower-severityfilterscanbeveryhelpfulwhenwritingandtest-\ninganapplication. Insteadofusingmanyprintstatementsfordebugging,uselogger.debug: Unliketheprint\nstatements,whichyouwillhavetodeleteorcommentoutlater,thelogger.debugstatementscanremainintactinthe\nsourcecodeandremaindormantuntilyouneedthemagain. Atthattime,theonlychangethatneedstohappenisto\nmodifytheseverityleveloftheloggerand/orhandlertodebug.\n4 Logging to multiple destinations\nLet\u2019ssayyouwanttologtoconsoleandfilewithdifferentmessageformatsandindifferingcircumstances. Sayyou\nwanttologmessageswithlevelsofDEBUGandhighertofile,andthosemessagesatlevelINFOandhighertothe\nconsole. Let\u2019salsoassumethatthefileshouldcontaintimestamps,buttheconsolemessagesshouldnot. Here\u2019show\nyoucanachievethis:\nimport logging\n# set up logging to file - see previous section for more details\nlogging.basicConfig(level=logging.DEBUG,\nformat='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\ndatefmt='%m-%d %H:%M',\nfilename='/tmp/myapp.log',\nfilemode='w')\n# define a Handler which writes INFO messages or higher to the sys.stderr\nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\n# set a format which is simpler for console use\nformatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n# tell the handler to use this format\nconsole.setFormatter(formatter)\n# add the handler to the root logger\nlogging.getLogger('').addHandler(console)\n# Now, we can log to the root logger, or any other logger. First the root...\nlogging.info('Jackdaws love my big sphinx of quartz.')\n# Now, define a couple of other loggers which might represent areas in your\n# application:\nlogger1 = logging.getLogger('myapp.area1')\nlogger2 = logging.getLogger('myapp.area2')\nlogger1.debug('Quick zephyrs blow, vexing daft Jim.')\nlogger1.info('How quickly daft jumping zebras vex.')\nlogger2.warning('Jail zesty vixen who grabbed pay from quack.')\nlogger2.error('The five boxing wizards jump quickly.')\nWhenyourunthis,ontheconsoleyouwillsee\nroot : INFO Jackdaws love my big sphinx of quartz.\nmyapp.area1 : INFO How quickly daft jumping zebras vex.\nmyapp.area2 : WARNING Jail zesty vixen who grabbed pay from quack.\nmyapp.area2 : ERROR The five boxing wizards jump quickly.\nandinthefileyouwillseesomethinglike\n10-22 22:19 root INFO Jackdaws love my big sphinx of quartz.\n10-22 22:19 myapp.area1 DEBUG Quick zephyrs blow, vexing daft Jim.\n10-22 22:19 myapp.area1 INFO How quickly daft jumping zebras vex.\n(continuesonnextpage)\n6\n(continuedfrompreviouspage)\n10-22 22:19 myapp.area2 WARNING Jail zesty vixen who grabbed pay from quack.\n10-22 22:19 myapp.area2 ERROR The five boxing wizards jump quickly.\nAsyoucansee,theDEBUGmessageonlyshowsupinthefile. Theothermessagesaresenttobothdestinations.\nThisexampleusesconsoleandfilehandlers,butyoucanuseanynumberandcombinationofhandlersyouchoose.\nNotethattheabovechoiceoflogfilename/tmp/myapp.logimpliesuseofastandardlocationfortemporaryfiles\nonPOSIXsystems. OnWindows,youmayneedtochooseadifferentdirectorynameforthelog-justensurethat\nthedirectoryexistsandthatyouhavethepermissionstocreateandupdatefilesinit.\n5 Custom handling of levels\nSometimes,youmightwanttodosomethingslightlydifferentfromthestandardhandlingoflevelsinhandlers,where\nalllevelsaboveathresholdgetprocessedbyahandler. Todothis,youneedtousefilters. Let\u2019slookatascenario\nwhereyouwanttoarrangethingsasfollows:\n\u2022 SendmessagesofseverityINFOandWARNINGtosys.stdout\n\u2022 SendmessagesofseverityERRORandabovetosys.stderr\n\u2022 SendmessagesofseverityDEBUGandabovetofileapp.log\nSupposeyouconfigureloggingwiththefollowingJSON:\n{\n\"version\": 1,\n\"disable_existing_loggers\": false,\n\"formatters\": {\n\"simple\": {\n\"format\": \"%(levelname)-8s - %(message)s\"\n}\n},\n\"handlers\": {\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\"\n},\n\"stderr\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"ERROR\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stderr\"\n},\n\"file\": {\n\"class\": \"logging.FileHandler\",\n\"formatter\": \"simple\",\n\"filename\": \"app.log\",\n\"mode\": \"w\"\n}\n},\n\"root\": {\n\"level\": \"DEBUG\",\n\"handlers\": [\n\"stderr\",\n\"stdout\",\n\"file\"\n(continuesonnextpage)\n7\n(continuedfrompreviouspage)\n]\n}\n}\nThisconfigurationdoesalmostwhatwewant,exceptthatsys.stdoutwouldshowmessagesofseverityERRORand\nonlyeventsofthisseverityandhigherwillbetrackedaswellasINFOandWARNINGmessages. Topreventthis,we\ncansetupafilterwhichexcludesthosemessagesandaddittotherelevanthandler. Thiscanbeconfiguredbyadding\nafilterssectionparalleltoformattersandhandlers:\n{\n\"filters\": {\n\"warnings_and_below\": {\n\"()\" : \"__main__.filter_maker\",\n\"level\": \"WARNING\"\n}\n}\n}\nandchangingthesectiononthestdouthandlertoaddit:\n{\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\",\n\"filters\": [\"warnings_and_below\"]\n}\n}\nAfilterisjustafunction,sowecandefinethefilter_maker(afactoryfunction)asfollows:\ndef filter_maker(level):\nlevel = getattr(logging, level)\ndef filter(record):\nreturn record.levelno <= level\nreturn filter\nThis converts the string argument passed in to a numeric level, and returns a function which only returns True if\nthe level of the passed in record is at or below the specified level. Note that in this example I have defined the\nfilter_makerinatestscriptmain.pythatIrunfromthecommandline,soitsmodulewillbe__main__-hence\nthe__main__.filter_makerinthefilterconfiguration. Youwillneedtochangethatifyoudefineitinadifferent\nmodule.\nWiththefilteradded,wecanrunmain.py,whichinfullis:\nimport json\nimport logging\nimport logging.config\nCONFIG = '''\n{\n\"version\": 1,\n\"disable_existing_loggers\": false,\n\"formatters\": {\n(continuesonnextpage)\n8\n(continuedfrompreviouspage)\n\"simple\": {\n\"format\": \"%(levelname)-8s - %(message)s\"\n}\n},\n\"filters\": {\n\"warnings_and_below\": {\n\"()\" : \"__main__.filter_maker\",\n\"level\": \"WARNING\"\n}\n},\n\"handlers\": {\n\"stdout\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"INFO\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stdout\",\n\"filters\": [\"warnings_and_below\"]\n},\n\"stderr\": {\n\"class\": \"logging.StreamHandler\",\n\"level\": \"ERROR\",\n\"formatter\": \"simple\",\n\"stream\": \"ext://sys.stderr\"\n},\n\"file\": {\n\"class\": \"logging.FileHandler\",\n\"formatter\": \"simple\",\n\"filename\": \"app.log\",\n\"mode\": \"w\"\n}\n},\n\"root\": {\n\"level\": \"DEBUG\",\n\"handlers\": [\n\"stderr\",\n\"stdout\",\n\"file\"\n]\n}\n}\n'''\ndef filter_maker(level):\nlevel = getattr(logging, level)\ndef filter(record):\nreturn record.levelno <= level\nreturn filter\nlogging.config.dictConfig(json.loads(CONFIG))\nlogging.debug('A DEBUG message')\nlogging.info('An INFO message')\nlogging.warning('A WARNING message')\nlogging.error('An ERROR message')\nlogging.critical('A CRITICAL message')\n9\nAndafterrunningitlikethis:\npython main.py 2>stderr.log >stdout.log\nWecanseetheresultsareasexpected:\n$ more *.log\n::::::::::::::\napp.log\n::::::::::::::\nDEBUG - A DEBUG message\nINFO - An INFO message\nWARNING - A WARNING message\nERROR - An ERROR message\nCRITICAL - A CRITICAL message\n::::::::::::::\nstderr.log\n::::::::::::::\nERROR - An ERROR message\nCRITICAL - A CRITICAL message\n::::::::::::::\nstdout.log\n::::::::::::::\nINFO - An INFO message\nWARNING - A WARNING message\n6 Configuration server example\nHereisanexampleofamoduleusingtheloggingconfigurationserver:\nimport logging\nimport logging.config\nimport time\nimport os\n# read initial config file\nlogging.config.fileConfig('logging.conf')\n# create and start listener on port 9999\nt = logging.config.listen(9999)\nt.start()\nlogger = logging.getLogger('simpleExample')\ntry:\n# loop through logging calls to see the difference\n# new configurations make, until Ctrl+C is pressed\nwhile True:\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warn message')\nlogger.error('error message')\nlogger.critical('critical message')\ntime.sleep(5)\nexcept KeyboardInterrupt:\n# cleanup\nlogging.config.stopListening()\n(continuesonnextpage)\n10\n(continuedfrompreviouspage)\nt.join()\nAndhereisascriptthattakesafilenameandsendsthatfiletotheserver,properlyprecededwiththebinary-encoded\nlength,asthenewloggingconfiguration:\n#!/usr/bin/env python\nimport socket, sys, struct\nwith open(sys.argv[1], 'rb') as f:\ndata_to_send = f.read()\nHOST = 'localhost'\nPORT = 9999\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nprint('connecting...')\ns.connect((HOST, PORT))\nprint('sending config...')\ns.send(struct.pack('>L', len(data_to_send)))\ns.send(data_to_send)\ns.close()\nprint('complete')\n7 Dealing with handlers that block\nSometimesyouhavetogetyourlogginghandlerstodotheirworkwithoutblockingthethreadyou\u2019reloggingfrom.\nThisiscommoninwebapplications,thoughofcourseitalsooccursinotherscenarios.\nA common culprit which demonstrates sluggish behaviour is the SMTPHandler: sending emails can take a long\ntime, for a number of reasons outside the developer\u2019s control (for example, a poorly performing mail or network\ninfrastructure). But almost any network-based handler can block: Even a SocketHandler operation may do a\nDNS query under the hood which is too slow (and this query can be deep in the socket library code, below the\nPythonlayer,andoutsideyourcontrol).\nOnesolutionistouseatwo-partapproach. Forthefirstpart,attachonlyaQueueHandlertothoseloggerswhichare\naccessedfromperformance-criticalthreads. Theysimplywritetotheirqueue,whichcanbesizedtoalargeenough\ncapacityorinitializedwithnoupperboundtotheirsize. Thewritetothequeuewilltypicallybeacceptedquickly,\nthoughyouwillprobablyneedtocatchthequeue.Fullexceptionasaprecautioninyourcode. Ifyouarealibrary\ndeveloperwhohasperformance-criticalthreadsintheircode,besuretodocumentthis(togetherwithasuggestion\ntoattachonlyQueueHandlerstoyourloggers)forthebenefitofotherdeveloperswhowilluseyourcode.\nThesecondpartofthesolutionisQueueListener,whichhasbeendesignedasthecounterparttoQueueHandler.\nAQueueListenerisverysimple: it\u2019spassedaqueueandsomehandlers,anditfiresupaninternalthreadwhich\nlistenstoitsqueueforLogRecordssentfromQueueHandlers(oranyothersourceofLogRecords,forthatmatter).\nTheLogRecordsareremovedfromthequeueandpassedtothehandlersforprocessing.\nTheadvantageofhavingaseparateQueueListenerclassisthatyoucanusethesameinstancetoservicemultiple\nQueueHandlers. Thisismoreresource-friendlythan,say,havingthreadedversionsoftheexistinghandlerclasses,\nwhichwouldeatuponethreadperhandlerfornoparticularbenefit.\nAnexampleofusingthesetwoclassesfollows(importsomitted):\nque = queue.Queue(-1) # no limit on size\nqueue_handler = QueueHandler(que)\nhandler = logging.StreamHandler()\nlistener = QueueListener(que, handler)\nroot = logging.getLogger()\nroot.addHandler(queue_handler)\nformatter = logging.Formatter('%(threadName)s: %(message)s')\n(continuesonnextpage)\n11\n(continuedfrompreviouspage)\nhandler.setFormatter(formatter)\nlistener.start()\n# The log output will display the thread which generated\n# the event (the main thread) rather than the internal\n# thread which monitors the internal queue. This is what\n# you want to happen.\nroot.warning('Look out!')\nlistener.stop()\nwhich,whenrun,willproduce:\nMainThread: Look out!\n(cid:174) Note\nAlthoughtheearlierdiscussionwasn\u2019tspecificallytalkingaboutasynccode,butratheraboutslowlogginghandlers,\nit should be noted that when logging from async code, network and even file handlers could lead to problems\n(blockingtheeventloop)becausesomeloggingisdonefromasynciointernals. Itmightbebest,ifanyasync\ncodeisusedinanapplication,tousetheaboveapproachforlogging,sothatanyblockingcoderunsonlyinthe\nQueueListenerthread.\nChangedinversion3.5: PriortoPython3.5,theQueueListeneralwayspassedeverymessagereceivedfromthe\nqueuetoeveryhandleritwasinitializedwith. (Thiswasbecauseitwasassumedthatlevelfilteringwasalldoneon\ntheotherside, wherethequeueisfilled.) From3.5onwards, thisbehaviourcanbechangedbypassingakeyword\nargumentrespect_handler_level=Truetothelistener\u2019sconstructor. Whenthisisdone,thelistenercompares\nthelevelofeachmessagewiththehandler\u2019slevel,andonlypassesamessagetoahandlerifit\u2019sappropriatetodoso.\n8 Sending and receiving logging events across a network\nLet\u2019ssayyouwanttosendloggingeventsacrossanetwork,andhandlethematthereceivingend. Asimplewayof\ndoingthisisattachingaSocketHandlerinstancetotherootloggeratthesendingend:\nimport logging, logging.handlers\nrootLogger = logging.getLogger('')\nrootLogger.setLevel(logging.DEBUG)\nsocketHandler = logging.handlers.SocketHandler('localhost',\nlogging.handlers.DEFAULT_TCP_LOGGING_PORT)\n# don't bother with a formatter, since a socket handler sends the event as\n# an unformatted pickle\nrootLogger.addHandler(socketHandler)\n# Now, we can log to the root logger, or any other logger. First the root...\nlogging.info('Jackdaws love my big sphinx of quartz.')\n# Now, define a couple of other loggers which might represent areas in your\n# application:\nlogger1 = logging.getLogger('myapp.area1')\nlogger2 = logging.getLogger('myapp.area2')\nlogger1.debug('Quick zephyrs blow, vexing daft Jim.')\nlogger1.info('How quickly daft jumping zebras vex.')\nlogger2.warning('Jail zesty vixen who grabbed pay from quack.')\nlogger2.error('The five boxing wizards jump quickly.')\n12\nAtthereceivingend,youcansetupareceiverusingthesocketservermodule. Hereisabasicworkingexample:\nimport pickle\nimport logging\nimport logging.handlers\nimport socketserver\nimport struct\nclass LogRecordStreamHandler(socketserver.StreamRequestHandler):\n\"\"\"Handler for a streaming logging request.\nThis basically logs the record using whatever logging policy is\nconfigured locally.\n\"\"\"\ndef handle(self):\n\"\"\"\nHandle multiple requests - each expected to be a 4-byte length,\nfollowed by the LogRecord in pickle format. Logs the record\naccording to whatever policy is configured locally.\n\"\"\"\nwhile True:\nchunk = self.connection.recv(4)\nif len(chunk) < 4:\nbreak\nslen = struct.unpack('>L', chunk)[0]\nchunk = self.connection.recv(slen)\nwhile len(chunk) < slen:\nchunk = chunk + self.connection.recv(slen - len(chunk))\nobj = self.unPickle(chunk)\nrecord = logging.makeLogRecord(obj)\nself.handleLogRecord(record)\ndef unPickle(self, data):\nreturn pickle.loads(data)\ndef handleLogRecord(self, record):\n# if a name is specified, we use the named logger rather than the one\n# implied by the record.\nif self.server.logname is not None:\nname = self.server.logname\nelse:\nname = record.name\nlogger = logging.getLogger(name)\n# N.B. EVERY record gets logged. This is because Logger.handle\n# is normally called AFTER logger-level filtering. If you want\n# to do filtering, do it at the client end to save wasting\n# cycles and network bandwidth!\nlogger.handle(record)\nclass LogRecordSocketReceiver(socketserver.ThreadingTCPServer):\n\"\"\"\nSimple TCP socket-based logging receiver suitable for testing.\n\"\"\"\nallow_reuse_address = True\n(continuesonnextpage)\n13\n(continuedfrompreviouspage)\ndef __init__(self, host='localhost',\nport=logging.handlers.DEFAULT_TCP_LOGGING_PORT,\nhandler=LogRecordStreamHandler):\nsocketserver.ThreadingTCPServer.__init__(self, (host, port), handler)\nself.abort = 0\nself.timeout = 1\nself.logname = None\ndef serve_until_stopped(self):\nimport select\nabort = 0\nwhile not abort:\nrd, wr, ex = select.select([self.socket.fileno()],\n[], [],\nself.timeout)\nif rd:\nself.handle_request()\nabort = self.abort\ndef main():\nlogging.basicConfig(\nformat='%(relativeCreated)5d %(name)-15s %(levelname)-8s %(message)s')\ntcpserver = LogRecordSocketReceiver()\nprint('About to start TCP server...')\ntcpserver.serve_until_stopped()\nif __name__ == '__main__':\nmain()\nFirstruntheserver,andthentheclient. Ontheclientside,nothingisprintedontheconsole;ontheserverside,you\nshouldseesomethinglike:\nAbout to start TCP server...\n59 root INFO Jackdaws love my big sphinx of quartz.\n59 myapp.area1 DEBUG Quick zephyrs blow, vexing daft Jim.\n69 myapp.area1 INFO How quickly daft jumping zebras vex.\n69 myapp.area2 WARNING Jail zesty vixen who grabbed pay from quack.\n69 myapp.area2 ERROR The five boxing wizards jump quickly.\nNotethattherearesomesecurityissueswithpickleinsomescenarios. Iftheseaffectyou,youcanuseanalternative\nserializationschemebyoverridingthemakePickle()methodandimplementingyouralternativethere,aswellas\nadaptingtheabovescripttouseyouralternativeserialization.\n8.1 Running a logging socket listener in production\nTorunalogginglistenerinproduction,youmayneedtouseaprocess-managementtoolsuchasSupervisor. Hereis\naGistwhichprovidesthebare-bonesfilestoruntheabovefunctionalityusingSupervisor. Itconsistsofthefollowing\nfiles:\n14\nFile Purpose\nprepare.sh ABashscripttopreparetheenvironmentfortesting\nsupervisor. TheSupervisorconfigurationfile,whichhasentriesforthelistenerandamulti-processweb\nconf application\nensure_app.sh ABashscripttoensurethatSupervisorisrunningwiththeaboveconfiguration\nlog_listener. Thesocketlistenerprogramwhichreceiveslogeventsandrecordsthemtoafile\npy\nmain.py Asimplewebapplicationwhichperformsloggingviaasocketconnectedtothelistener\nwebapp.json AJSONconfigurationfileforthewebapplication\nclient.py APythonscripttoexercisethewebapplication\nThewebapplicationusesGunicorn,whichisapopularwebapplicationserverthatstartsmultipleworkerprocesses\ntohandlerequests. Thisexamplesetupshowshowtheworkerscanwritetothesamelogfilewithoutconflictingwith\noneanother\u2014theyallgothroughthesocketlistener.\nTotestthesefiles,dothefollowinginaPOSIXenvironment:\n1. DownloadtheGistasaZIParchiveusingtheDownloadZIPbutton.\n2. Unziptheabovefilesfromthearchiveintoascratchdirectory.\n3. Inthescratchdirectory,runbash prepare.shtogetthingsready. Thiscreatesarunsubdirectorytocontain\nSupervisor-relatedandlogfiles,andavenvsubdirectorytocontainavirtualenvironmentintowhichbottle,\ngunicornandsupervisorareinstalled.\n4. Runbash ensure_app.shtoensurethatSupervisorisrunningwiththeaboveconfiguration.\n5. Runvenv/bin/python client.pytoexercisethewebapplication,whichwillleadtorecordsbeingwritten\ntothelog.\n6. Inspect the log files in the run subdirectory. You should see the most recent log lines in files matching the\npattern app.log*. They won\u2019t be in any particular order, since they have been handled concurrently by\ndifferentworkerprocessesinanon-deterministicway.\n7. You can shut down the listener and the web application by running venv/bin/supervisorctl -c\nsupervisor.conf shutdown.\nYoumayneedtotweaktheconfigurationfilesintheunlikelyeventthattheconfiguredportsclashwithsomething\nelseinyourtestenvironment.\nThe default configuration uses a TCP socket on port 9020. You can use a Unix Domain socket instead of a TCP\nsocketbydoingthefollowing:\n1. In listener.json, add a socket key with the path to the domain socket you want to use. If this key is\npresent, the listener listens on the corresponding domain socket and not on a TCP socket (the port key is\nignored).\n2. Inwebapp.json,changethesockethandlerconfigurationdictionarysothatthehostvalueisthepathtothe\ndomainsocket,andsettheportvaluetonull.\n9 Adding contextual information to your logging output\nSometimes you want logging output to contain contextual information in addition to the parameters passed to the\nloggingcall. Forexample, inanetworkedapplication, itmaybedesirableto logclient-specificinformationinthe\nlog(e.g. remoteclient\u2019susername,orIPaddress). Althoughyoucouldusetheextraparametertoachievethis,it\u2019s\nnotalwaysconvenienttopasstheinformationinthisway. WhileitmightbetemptingtocreateLoggerinstances\non a per-connection basis, this is not a good idea because these instances are not garbage collected. While this is\nnotaprobleminpractice,whenthenumberofLoggerinstancesisdependentonthelevelofgranularityyouwant\ntouseinlogginganapplication,itcouldbehardtomanageifthenumberofLoggerinstancesbecomeseffectively\nunbounded.\n15\n9.1 Using LoggerAdapters to impart contextual information\nAneasywayinwhichyoucanpasscontextualinformationtobeoutputalongwithloggingeventinformationistouse\ntheLoggerAdapterclass. ThisclassisdesignedtolooklikeaLogger,sothatyoucancalldebug(),info(),\nwarning(),error(),exception(),critical()andlog(). Thesemethodshavethesamesignaturesastheir\ncounterpartsinLogger,soyoucanusethetwotypesofinstancesinterchangeably.\nWhenyoucreateaninstanceofLoggerAdapter,youpassitaLoggerinstanceandadict-likeobjectwhichcontains\nyour contextual information. When you call one of the logging methods on an instance of LoggerAdapter, it\ndelegatesthecalltotheunderlyinginstanceofLoggerpassedtoitsconstructor,andarrangestopassthecontextual\ninformationinthedelegatedcall. Here\u2019sasnippetfromthecodeofLoggerAdapter:\ndef debug(self, msg, /, *args, **kwargs):\n\"\"\"\nDelegate a debug call to the underlying logger, after adding\ncontextual information from this adapter instance.\n\"\"\"\nmsg, kwargs = self.process(msg, kwargs)\nself.logger.debug(msg, *args, **kwargs)\nTheprocess() methodof LoggerAdapter iswherethecontextualinformationisaddedto theloggingoutput.\nIt\u2019spassedthemessageandkeywordargumentsoftheloggingcall,anditpassesback(potentially)modifiedversions\nofthesetouseinthecalltotheunderlyinglogger. Thedefaultimplementationofthismethodleavesthemessage\nalone,butinsertsan\u2018extra\u2019keyinthekeywordargumentwhosevalueisthedict-likeobjectpassedtotheconstructor.\nOfcourse,ifyouhadpassedan\u2018extra\u2019keywordargumentinthecalltotheadapter,itwillbesilentlyoverwritten.\nThe advantage of using \u2018extra\u2019 is that the values in the dict-like object are merged into the LogRecord instance\u2019s\n__dict__,allowingyoutousecustomizedstringswithyourFormatterinstanceswhichknowaboutthekeysofthe\ndict-likeobject. Ifyouneedadifferentmethod,e.g. ifyouwanttoprependorappendthecontextualinformationto\nthemessagestring,youjustneedtosubclassLoggerAdapterandoverrideprocess()todowhatyouneed. Here\nisasimpleexample:\nclass CustomAdapter(logging.LoggerAdapter):\n\"\"\"\nThis example adapter expects the passed in dict-like object to have a\n'connid' key, whose value in brackets is prepended to the log message.\n\"\"\"\ndef process(self, msg, kwargs):\nreturn '[%s] %s' % (self.extra['connid'], msg), kwargs\nwhichyoucanuselikethis:\nlogger = logging.getLogger(__name__)\nadapter = CustomAdapter(logger, {'connid': some_conn_id})\nThenanyeventsthatyoulogtotheadapterwillhavethevalueofsome_conn_idprependedtothelogmessages.\nUsingobjectsotherthandictstopasscontextualinformation\nYoudon\u2019tneedtopassanactualdicttoaLoggerAdapter-youcouldpassaninstanceofaclasswhichimplements\n__getitem__and__iter__sothatitlookslikeadicttologging. Thiswouldbeusefulifyouwanttogenerate\nvaluesdynamically(whereasthevaluesinadictwouldbeconstant).\n9.2 Using Filters to impart contextual information\nYoucanalsoaddcontextualinformationtologoutputusingauser-definedFilter. Filterinstancesareallowed\ntomodifytheLogRecordspassedtothem,includingaddingadditionalattributeswhichcanthenbeoutputusinga\nsuitableformatstring,orifneededacustomFormatter.\nForexampleinawebapplication,therequestbeingprocessed(oratleast,theinterestingpartsofit)canbestored\ninathreadlocal(threading.local)variable,andthenaccessedfromaFiltertoadd,say,informationfromthe\n16\nrequest-say,theremoteIPaddressandremoteuser\u2019susername-totheLogRecord,usingtheattributenames\u2018ip\u2019\nand\u2018user\u2019asintheLoggerAdapterexampleabove. Inthatcase,thesameformatstringcanbeusedtogetsimilar\noutputtothatshownabove. Here\u2019sanexamplescript:\nimport logging\nfrom random import choice\nclass ContextFilter(logging.Filter):\n\"\"\"\nThis is a filter which injects contextual information into the log.\nRather than use actual contextual information, we just use random\ndata in this demo.\n\"\"\"\nUSERS = ['jim', 'fred', 'sheila']\nIPS = ['123.231.231.123', '127.0.0.1', '192.168.0.1']\ndef filter(self, record):\nrecord.ip = choice(ContextFilter.IPS)\nrecord.user = choice(ContextFilter.USERS)\nreturn True\nif __name__ == '__main__':\nlevels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.\n,\u2192CRITICAL)\nlogging.basicConfig(level=logging.DEBUG,\nformat='%(asctime)-15s %(name)-5s %(levelname)-8s IP:\n,\u2192%(ip)-15s User: %(user)-8s %(message)s')\na1 = logging.getLogger('a.b.c')\na2 = logging.getLogger('d.e.f')\nf = ContextFilter()\na1.addFilter(f)\na2.addFilter(f)\na1.debug('A debug message')\na1.info('An info message with %s', 'some parameters')\nfor x in range(10):\nlvl = choice(levels)\nlvlname = logging.getLevelName(lvl)\na2.log(lvl, 'A message at %s level with %d %s', lvlname, 2, 'parameters')\nwhich,whenrun,producessomethinglike:\n2010-09-06 22:38:15,292 a.b.c DEBUG IP: 123.231.231.123 User: fred A debug\u2423\n,\u2192message\n2010-09-06 22:38:15,300 a.b.c INFO IP: 192.168.0.1 User: sheila An info\u2423\n,\u2192message with some parameters\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1 User: sheila A\u2423\n,\u2192message at CRITICAL level with 2 parameters\n2010-09-06 22:38:15,300 d.e.f ERROR IP: 127.0.0.1 User: jim A\u2423\n,\u2192message at ERROR level with 2 parameters\n2010-09-06 22:38:15,300 d.e.f DEBUG IP: 127.0.0.1 User: sheila A\u2423\n,\u2192message at DEBUG level with 2 parameters\n2010-09-06 22:38:15,300 d.e.f ERROR IP: 123.231.231.123 User: fred A\u2423\n,\u2192message at ERROR level with 2 parameters\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 192.168.0.1 User: jim A\u2423\n(continuesonnextpage)\n17\n(continuedfrompreviouspage)\n,\u2192message at CRITICAL level with 2 parameters\n2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1 User: sheila A\u2423\n,\u2192message at CRITICAL level with 2 parameters\n2010-09-06 22:38:15,300 d.e.f DEBUG IP: 192.168.0.1 User: jim A\u2423\n,\u2192message at DEBUG level with 2 parameters\n2010-09-06 22:38:15,301 d.e.f ERROR IP: 127.0.0.1 User: sheila A\u2423\n,\u2192message at ERROR level with 2 parameters\n2010-09-06 22:38:15,301 d.e.f DEBUG IP: 123.231.231.123 User: fred A\u2423\n,\u2192message at DEBUG level with 2 parameters\n2010-09-06 22:38:15,301 d.e.f INFO IP: 123.231.231.123 User: fred A\u2423\n,\u2192message at INFO level with 2 parameters\n10 Use of contextvars\nSincePython3.7,thecontextvarsmodulehasprovidedcontext-localstoragewhichworksforboththreading\nandasyncioprocessingneeds. Thistypeofstoragemaythusbegenerallypreferabletothread-locals. Thefollowing\nexampleshowshow, inamulti-threadedenvironment, logscanpopulatedwithcontextualinformationsuchas, for\nexample,requestattributeshandledbywebapplications.\nFor the purposes of illustration, say that you have different web applications, each independent of the other but\nrunninginthesamePythonprocessandusingalibrarycommontothem. Howcaneachoftheseapplicationshave\ntheirownlog, whereallloggingmessagesfromthelibrary(andotherrequestprocessingcode)aredirectedtothe\nappropriateapplication\u2019slogfile,whileincludinginthelogadditionalcontextualinformationsuchasclientIP,HTTP\nrequestmethodandclientusername?\nLet\u2019sassumethatthelibrarycanbesimulatedbythefollowingcode:\n# webapplib.py\nimport logging\nimport time\nlogger = logging.getLogger(__name__)\ndef useful():\n# Just a representative event logged from the library\nlogger.debug('Hello from webapplib!')\n# Just sleep for a bit so other threads get to run\ntime.sleep(0.01)\nWecansimulatethemultiplewebapplicationsbymeansoftwosimpleclasses,RequestandWebApp. Thesesimulate\nhowrealthreadedwebapplicationswork-eachrequestishandledbyathread:\n# main.py\nimport argparse\nfrom contextvars import ContextVar\nimport logging\nimport os\nfrom random import choice\nimport threading\nimport webapplib\nlogger = logging.getLogger(__name__)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nclass Request:\n(continuesonnextpage)\n18\n(continuedfrompreviouspage)\n\"\"\"\nA simple dummy request class which just holds dummy HTTP request method,\nclient IP address and client username\n\"\"\"\ndef __init__(self, method, ip, user):\nself.method = method\nself.ip = ip\nself.user = user\n# A dummy set of requests which will be used in the simulation - we'll just pick\n# from this list randomly. Note that all GET requests are from 192.168.2.XXX\n# addresses, whereas POST requests are from 192.16.3.XXX addresses. Three users\n# are represented in the sample requests.\nREQUESTS = [\nRequest('GET', '192.168.2.20', 'jim'),\nRequest('POST', '192.168.3.20', 'fred'),\nRequest('GET', '192.168.2.21', 'sheila'),\nRequest('POST', '192.168.3.21', 'jim'),\nRequest('GET', '192.168.2.22', 'fred'),\nRequest('POST', '192.168.3.22', 'sheila'),\n]\n# Note that the format string includes references to request context information\n# such as HTTP method, client IP and username\nformatter = logging.Formatter('%(threadName)-11s %(appName)s %(name)-9s %(user)-6s\n,\u2192%(ip)s %(method)-4s %(message)s')\n# Create our context variables. These will be filled at the start of request\n# processing, and used in the logging that happens during that processing\nctx_request = ContextVar('request')\nctx_appname = ContextVar('appname')\nclass InjectingFilter(logging.Filter):\n\"\"\"\nA filter which injects context-specific information into logs and ensures\nthat only information for a specific webapp is included in its log\n\"\"\"\ndef __init__(self, app):\nself.app = app\ndef filter(self, record):\nrequest = ctx_request.get()\nrecord.method = request.method\nrecord.ip = request.ip\nrecord.user = request.user\nrecord.appName = appName = ctx_appname.get()\nreturn appName == self.app.name\nclass WebApp:\n\"\"\"\nA dummy web application class which has its own handler and filter for a\nwebapp-specific log.\n\"\"\"\n(continuesonnextpage)\n19\n(continuedfrompreviouspage)\ndef __init__(self, name):\nself.name = name\nhandler = logging.FileHandler(name + '.log', 'w')\nf = InjectingFilter(self)\nhandler.setFormatter(formatter)\nhandler.addFilter(f)\nroot.addHandler(handler)\nself.num_requests = 0\ndef process_request(self, request):\n\"\"\"\nThis is the dummy method for processing a request. It's called on a\ndifferent thread for every request. We store the context information into\nthe context vars before doing anything else.\n\"\"\"\nctx_request.set(request)\nctx_appname.set(self.name)\nself.num_requests += 1\nlogger.debug('Request processing started')\nwebapplib.useful()\nlogger.debug('Request processing finished')\ndef main():\nfn = os.path.splitext(os.path.basename(__file__))[0]\nadhf = argparse.ArgumentDefaultsHelpFormatter\nap = argparse.ArgumentParser(formatter_class=adhf, prog=fn,\ndescription='Simulate a couple of web '\n'applications handling some '\n'requests, showing how request '\n'context can be used to '\n'populate logs')\naa = ap.add_argument\naa('--count', '-c', type=int, default=100, help='How many requests to simulate\n,\u2192')\noptions = ap.parse_args()\n# Create the dummy webapps and put them in a list which we can use to select\n# from randomly\napp1 = WebApp('app1')\napp2 = WebApp('app2')\napps = [app1, app2]\nthreads = []\n# Add a common handler which will capture all events\nhandler = logging.FileHandler('app.log', 'w')\nhandler.setFormatter(formatter)\nroot.addHandler(handler)\n# Generate calls to process requests\nfor i in range(options.count):\ntry:\n# Pick an app at random and a request for it to process\napp = choice(apps)\nrequest = choice(REQUESTS)\n# Process the request in its own thread\nt = threading.Thread(target=app.process_request, args=(request,))\nthreads.append(t)\n(continuesonnextpage)\n20\n(continuedfrompreviouspage)\nt.start()\nexcept KeyboardInterrupt:\nbreak\n# Wait for the threads to terminate\nfor t in threads:\nt.join()\nfor app in apps:\nprint('%s processed %s requests' % (app.name, app.num_requests))\nif __name__ == '__main__':\nmain()\nIfyouruntheabove,youshouldfindthatroughlyhalftherequestsgointoapp1.logandtherestintoapp2.log,\nandthealltherequestsareloggedtoapp.log. Eachwebapp-specificlogwillcontainonlylogentriesforonlythat\nwebapp, andtherequestinformationwillbedisplayedconsistentlyinthelog(i.e. theinformationineachdummy\nrequestwillalwaysappeartogetherinalogline). Thisisillustratedbythefollowingshelloutput:\n~/logging-contextual-webapp$ python main.py\napp1 processed 51 requests\napp2 processed 49 requests\n~/logging-contextual-webapp$ wc -l *.log\n153 app1.log\n147 app2.log\n300 app.log\n600 total\n~/logging-contextual-webapp$ head -3 app1.log\nThread-3 (process_request) app1 __main__ jim 192.168.3.21 POST Request\u2423\n,\u2192processing started\nThread-3 (process_request) app1 webapplib jim 192.168.3.21 POST Hello from\u2423\n,\u2192webapplib!\nThread-5 (process_request) app1 __main__ jim 192.168.3.21 POST Request\u2423\n,\u2192processing started\n~/logging-contextual-webapp$ head -3 app2.log\nThread-1 (process_request) app2 __main__ sheila 192.168.2.21 GET Request\u2423\n,\u2192processing started\nThread-1 (process_request) app2 webapplib sheila 192.168.2.21 GET Hello from\u2423\n,\u2192webapplib!\nThread-2 (process_request) app2 __main__ jim 192.168.2.20 GET Request\u2423\n,\u2192processing started\n~/logging-contextual-webapp$ head app.log\nThread-1 (process_request) app2 __main__ sheila 192.168.2.21 GET Request\u2423\n,\u2192processing started\nThread-1 (process_request) app2 webapplib sheila 192.168.2.21 GET Hello from\u2423\n,\u2192webapplib!\nThread-2 (process_request) app2 __main__ jim 192.168.2.20 GET Request\u2423\n,\u2192processing started\nThread-3 (process_request) app1 __main__ jim 192.168.3.21 POST Request\u2423\n,\u2192processing started\nThread-2 (process_request) app2 webapplib jim 192.168.2.20 GET Hello from\u2423\n,\u2192webapplib!\nThread-3 (process_request) app1 webapplib jim 192.168.3.21 POST Hello from\u2423\n,\u2192webapplib!\nThread-4 (process_request) app2 __main__ fred 192.168.2.22 GET Request\u2423\n,\u2192processing started\n(continuesonnextpage)\n21\n(continuedfrompreviouspage)\nThread-5 (process_request) app1 __main__ jim 192.168.3.21 POST Request\u2423\n,\u2192processing started\nThread-4 (process_request) app2 webapplib fred 192.168.2.22 GET Hello from\u2423\n,\u2192webapplib!\nThread-6 (process_request) app1 __main__ jim 192.168.3.21 POST Request\u2423\n,\u2192processing started\n~/logging-contextual-webapp$ grep app1 app1.log | wc -l\n153\n~/logging-contextual-webapp$ grep app2 app2.log | wc -l\n147\n~/logging-contextual-webapp$ grep app1 app.log | wc -l\n153\n~/logging-contextual-webapp$ grep app2 app.log | wc -l\n147\n11 Imparting contextual information in handlers\nEach Handler has its own chain of filters. If you want to add contextual information to a LogRecord without\nleakingittootherhandlers,youcanuseafilterthatreturnsanewLogRecordinsteadofmodifyingitin-place,as\nshowninthefollowingscript:\nimport copy\nimport logging\ndef filter(record: logging.LogRecord):\nrecord = copy.copy(record)\nrecord.user = 'jim'\nreturn record\nif __name__ == '__main__':\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\nhandler = logging.StreamHandler()\nformatter = logging.Formatter('%(message)s from %(user)-8s')\nhandler.setFormatter(formatter)\nhandler.addFilter(filter)\nlogger.addHandler(handler)\nlogger.info('A log message')\n12 Logging to a single file from multiple processes\nAlthoughloggingisthread-safe, andloggingtoasinglefilefrommultiplethreadsinasingleprocessis supported,\nloggingtoasinglefilefrommultipleprocessesisnotsupported,becausethereisnostandardwaytoserializeaccessto\nasinglefileacrossmultipleprocessesinPython. Ifyouneedtologtoasinglefilefrommultipleprocesses,oneway\nofdoingthisistohavealltheprocesseslogtoaSocketHandler,andhaveaseparateprocesswhichimplements\nasocketserverwhichreadsfromthesocketandlogstofile. (Ifyouprefer, youcandedicateonethreadinoneof\ntheexistingprocessestoperformthisfunction.) Thissectiondocumentsthisapproachinmoredetailandincludesa\nworkingsocketreceiverwhichcanbeusedasastartingpointforyoutoadaptinyourownapplications.\nYou could also write your own handler which uses the Lock class from the multiprocessing module to se-\nrialize access to the file from your processes. The stdlib FileHandler and subclasses do not make use of\nmultiprocessing.\nAlternatively,youcanuseaQueueandaQueueHandlertosendallloggingeventstooneoftheprocessesinyour\nmulti-processapplication. Thefollowingexamplescriptdemonstrateshowyoucandothis;intheexampleaseparate\n22\nlistenerprocesslistensforeventssentbyotherprocessesandlogsthemaccordingtoitsownloggingconfiguration.\nAlthough the example only demonstrates one way of doing it (for example, you may want to use a listener thread\nratherthanaseparatelistenerprocess\u2013theimplementationwouldbeanalogous)itdoesallowforcompletelydifferent\nloggingconfigurationsforthelistenerandtheotherprocessesinyourapplication, andcanbeusedasthebasisfor\ncodemeetingyourownspecificrequirements:\n# You'll need these imports in your own code\nimport logging\nimport logging.handlers\nimport multiprocessing\n# Next two import lines for this demo only\nfrom random import choice, random\nimport time\n#\n# Because you'll want to define the logging configurations for listener and\u2423\n,\u2192workers, the\n# listener and worker process functions take a configurer parameter which is a\u2423\n,\u2192callable\n# for configuring logging for that process. These functions are also passed the\u2423\n,\u2192queue,\n# which they use for communication.\n#\n# In practice, you can configure the listener however you want, but note that in\u2423\n,\u2192this\n# simple example, the listener does not apply level or filter logic to received\u2423\n,\u2192records.\n# In practice, you would probably want to do this logic in the worker processes,\u2423\n,\u2192to avoid\n# sending events which would be filtered out between processes.\n#\n# The size of the rotated files is made small so you can see the results easily.\ndef listener_configurer():\nroot = logging.getLogger()\nh = logging.handlers.RotatingFileHandler('mptest.log', 'a', 300, 10)\nf = logging.Formatter('%(asctime)s %(processName)-10s %(name)s %(levelname)-8s\n,\u2192%(message)s')\nh.setFormatter(f)\nroot.addHandler(h)\n# This is the listener process top-level loop: wait for logging events\n# (LogRecords)on the queue and handle them, quit when you get a None for a\n# LogRecord.\ndef listener_process(queue, configurer):\nconfigurer()\nwhile True:\ntry:\nrecord = queue.get()\nif record is None: # We send this as a sentinel to tell the listener\u2423\n,\u2192to quit.\nbreak\nlogger = logging.getLogger(record.name)\nlogger.handle(record) # No level or filter logic applied - just do it!\nexcept Exception:\nimport sys, traceback\nprint('Whoops! Problem:', file=sys.stderr)\ntraceback.print_exc(file=sys.stderr)\n(continuesonnextpage)\n23\n(continuedfrompreviouspage)\n# Arrays used for random selections in this demo\nLEVELS = [logging.DEBUG, logging.INFO, logging.WARNING,\nlogging.ERROR, logging.CRITICAL]\nLOGGERS = ['a.b.c', 'd.e.f']\nMESSAGES = [\n'Random message #1',\n'Random message #2',\n'Random message #3',\n]\n# The worker configuration is done at the start of the worker process run.\n# Note that on Windows you can't rely on fork semantics, so each process\n# will run the logging configuration code when it starts.\ndef worker_configurer(queue):\nh = logging.handlers.QueueHandler(queue) # Just the one handler needed\nroot = logging.getLogger()\nroot.addHandler(h)\n# send all messages, for demo; no other level or filter logic applied.\nroot.setLevel(logging.DEBUG)\n# This is the worker process top-level loop, which just logs ten events with\n# random intervening delays before terminating.\n# The print messages are just so you know it's doing something!\ndef worker_process(queue, configurer):\nconfigurer(queue)\nname = multiprocessing.current_process().name\nprint('Worker started: %s' % name)\nfor i in range(10):\ntime.sleep(random())\nlogger = logging.getLogger(choice(LOGGERS))\nlevel = choice(LEVELS)\nmessage = choice(MESSAGES)\nlogger.log(level, message)\nprint('Worker finished: %s' % name)\n# Here's where the demo gets orchestrated. Create the queue, create and start\n# the listener, create ten workers and start them, wait for them to finish,\n# then send a None to the queue to tell the listener to finish.\ndef main():\nqueue = multiprocessing.Queue(-1)\nlistener = multiprocessing.Process(target=listener_process,\nargs=(queue, listener_configurer))\nlistener.start()\nworkers = []\nfor i in range(10):\nworker = multiprocessing.Process(target=worker_process,\nargs=(queue, worker_configurer))\nworkers.append(worker)\nworker.start()\nfor w in workers:\nw.join()\nqueue.put_nowait(None)\n(continuesonnextpage)\n24\n(continuedfrompreviouspage)\nlistener.join()\nif __name__ == '__main__':\nmain()\nAvariantoftheabovescriptkeepsthelogginginthemainprocess,inaseparatethread:\nimport logging\nimport logging.config\nimport logging.handlers\nfrom multiprocessing import Process, Queue\nimport random\nimport threading\nimport time\ndef logger_thread(q):\nwhile True:\nrecord = q.get()\nif record is None:\nbreak\nlogger = logging.getLogger(record.name)\nlogger.handle(record)\ndef worker_process(q):\nqh = logging.handlers.QueueHandler(q)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nroot.addHandler(qh)\nlevels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL]\nloggers = ['foo', 'foo.bar', 'foo.bar.baz',\n'spam', 'spam.ham', 'spam.ham.eggs']\nfor i in range(100):\nlvl = random.choice(levels)\nlogger = logging.getLogger(random.choice(loggers))\nlogger.log(lvl, 'Message no. %d', i)\nif __name__ == '__main__':\nq = Queue()\nd = {\n'version': 1,\n'formatters': {\n'detailed': {\n'class': 'logging.Formatter',\n'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-\n,\u219210s %(message)s'\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'level': 'INFO',\n},\n'file': {\n'class': 'logging.FileHandler',\n(continuesonnextpage)\n25\n(continuedfrompreviouspage)\n'filename': 'mplog.log',\n'mode': 'w',\n'formatter': 'detailed',\n},\n'foofile': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-foo.log',\n'mode': 'w',\n'formatter': 'detailed',\n},\n'errors': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-errors.log',\n'mode': 'w',\n'level': 'ERROR',\n'formatter': 'detailed',\n},\n},\n'loggers': {\n'foo': {\n'handlers': ['foofile']\n}\n},\n'root': {\n'level': 'DEBUG',\n'handlers': ['console', 'file', 'errors']\n},\n}\nworkers = []\nfor i in range(5):\nwp = Process(target=worker_process, name='worker %d' % (i + 1), args=(q,))\nworkers.append(wp)\nwp.start()\nlogging.config.dictConfig(d)\nlp = threading.Thread(target=logger_thread, args=(q,))\nlp.start()\n# At this point, the main process could do some useful work of its own\n# Once it's done that, it can wait for the workers to terminate...\nfor wp in workers:\nwp.join()\n# And now tell the logging thread to finish up, too\nq.put(None)\nlp.join()\nThis variant shows how you can e.g. apply configuration for particular loggers - e.g. the foo logger has a special\nhandler which stores all events in the foo subsystem in a file mplog-foo.log. This will be used by the logging\nmachineryinthemainprocess(eventhoughtheloggingeventsaregeneratedintheworkerprocesses)todirectthe\nmessagestotheappropriatedestinations.\n12.1 Using concurrent.futures.ProcessPoolExecutor\nIfyouwanttouseconcurrent.futures.ProcessPoolExecutortostartyourworkerprocesses,youneedto\ncreatethequeueslightlydifferently. Insteadof\nqueue = multiprocessing.Queue(-1)\nyoushoulduse\n26\nqueue = multiprocessing.Manager().Queue(-1) # also works with the examples above\nandyoucanthenreplacetheworkercreationfromthis:\nworkers = []\nfor i in range(10):\nworker = multiprocessing.Process(target=worker_process,\nargs=(queue, worker_configurer))\nworkers.append(worker)\nworker.start()\nfor w in workers:\nw.join()\ntothis(rememberingtofirstimportconcurrent.futures):\nwith concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\nfor i in range(10):\nexecutor.submit(worker_process, queue, worker_configurer)\n12.2 Deploying Web applications using Gunicorn and uWSGI\nWhen deploying Web applications using Gunicorn or uWSGI (or similar), multiple worker processes are created\ntohandleclientrequests. Insuchenvironments,avoidcreatingfile-basedhandlersdirectlyinyourwebapplication.\nInstead,useaSocketHandlertologfromthewebapplicationtoalistenerinaseparateprocess. Thiscanbeset\nupusingaprocessmanagementtoolsuchasSupervisor-seeRunningaloggingsocketlistenerinproductionformore\ndetails.\n13 Using file rotation\nSometimes you want to let a log file grow to a certain size, then open a new file and log to that. You may want\nto keep a certain number of these files, and when that many files have been created, rotate the files so that the\nnumberoffilesandthesizeofthefilesbothremainbounded. Forthisusagepattern,theloggingpackageprovidesa\nRotatingFileHandler:\nimport glob\nimport logging\nimport logging.handlers\nLOG_FILENAME = 'logging_rotatingfile_example.out'\n# Set up a specific logger with our desired output level\nmy_logger = logging.getLogger('MyLogger')\nmy_logger.setLevel(logging.DEBUG)\n# Add the log message handler to the logger\nhandler = logging.handlers.RotatingFileHandler(\nLOG_FILENAME, maxBytes=20, backupCount=5)\nmy_logger.addHandler(handler)\n# Log some messages\nfor i in range(20):\nmy_logger.debug('i = %d' % i)\n# See what files are created\nlogfiles = glob.glob('%s*' % LOG_FILENAME)\n(continuesonnextpage)\n27\n(continuedfrompreviouspage)\nfor filename in logfiles:\nprint(filename)\nTheresultshouldbe6separatefiles,eachwithpartoftheloghistoryfortheapplication:\nlogging_rotatingfile_example.out\nlogging_rotatingfile_example.out.1\nlogging_rotatingfile_example.out.2\nlogging_rotatingfile_example.out.3\nlogging_rotatingfile_example.out.4\nlogging_rotatingfile_example.out.5\nThemostcurrentfileisalwayslogging_rotatingfile_example.out,andeachtimeitreachesthesizelimitit\nisrenamedwiththesuffix.1. Eachoftheexistingbackupfilesisrenamedtoincrementthesuffix(.1becomes.2,\netc.) andthe.6fileiserased.\nObviouslythisexamplesetstheloglengthmuchtoosmallasanextremeexample. YouwouldwanttosetmaxBytes\ntoanappropriatevalue.\n14 Use of alternative formatting styles\nWhenloggingwasaddedtothePythonstandardlibrary,theonlywayofformattingmessageswithvariablecontent\nwas to use the %-formatting method. Since then, Python has gained two new formatting approaches: string.\nTemplate(addedinPython2.4)andstr.format()(addedinPython2.6).\nLogging(asof3.2)providesimprovedsupportforthesetwoadditionalformattingstyles. TheFormatterclassbeen\nenhancedtotakeanadditional,optionalkeywordparameternamedstyle. Thisdefaultsto'%',butotherpossible\nvaluesare'{'and'$',whichcorrespondtotheothertwoformattingstyles. Backwardscompatibilityismaintained\nbydefault(asyouwouldexpect),butbyexplicitlyspecifyingastyleparameter,yougettheabilitytospecifyformat\nstrings which work with str.format() or string.Template. Here\u2019s an example console session to show the\npossibilities:\n>>> import logging\n>>> root = logging.getLogger()\n>>> root.setLevel(logging.DEBUG)\n>>> handler = logging.StreamHandler()\n>>> bf = logging.Formatter('{asctime} {name} {levelname:8s} {message}',\n... style='{')\n>>> handler.setFormatter(bf)\n>>> root.addHandler(handler)\n>>> logger = logging.getLogger('foo.bar')\n>>> logger.debug('This is a DEBUG message')\n2010-10-28 15:11:55,341 foo.bar DEBUG This is a DEBUG message\n>>> logger.critical('This is a CRITICAL message')\n2010-10-28 15:12:11,526 foo.bar CRITICAL This is a CRITICAL message\n>>> df = logging.Formatter('$asctime $name ${levelname} $message',\n... style='$')\n>>> handler.setFormatter(df)\n>>> logger.debug('This is a DEBUG message')\n2010-10-28 15:13:06,924 foo.bar DEBUG This is a DEBUG message\n>>> logger.critical('This is a CRITICAL message')\n2010-10-28 15:13:11,494 foo.bar CRITICAL This is a CRITICAL message\n>>>\nNotethattheformattingofloggingmessagesforfinaloutputtologsiscompletelyindependentofhowanindividual\nloggingmessageisconstructed. Thatcanstilluse%-formatting,asshownhere:\n28\n>>> logger.error('This is an%s %s %s', 'other,', 'ERROR,', 'message')\n2010-10-28 15:19:29,833 foo.bar ERROR This is another, ERROR, message\n>>>\nLogging calls (logger.debug(), logger.info() etc.) only take positional parameters for the actual logging\nmessage itself, with keyword parameters used only for determining options for how to handle the actual logging\ncall(e.g. theexc_infokeywordparametertoindicatethattracebackinformationshouldbelogged,ortheextra\nkeywordparametertoindicateadditionalcontextualinformationtobeaddedtothelog). Soyoucannotdirectlymake\nloggingcallsusingstr.format()orstring.Templatesyntax,becauseinternallytheloggingpackageuses%-\nformattingtomergetheformatstringandthevariablearguments. Therewouldbenochangingthiswhilepreserving\nbackwardcompatibility,sinceallloggingcallswhichareoutthereinexistingcodewillbeusing%-formatstrings.\nThere is, however, a way that you can use {}- and $- formatting to construct your individual log messages. Recall\nthatforamessageyoucanuseanarbitraryobjectasamessageformatstring,andthattheloggingpackagewillcall\nstr()onthatobjecttogettheactualformatstring. Considerthefollowingtwoclasses:\nclass BraceMessage:\ndef __init__(self, fmt, /, *args, **kwargs):\nself.fmt = fmt\nself.args = args\nself.kwargs = kwargs\ndef __str__(self):\nreturn self.fmt.format(*self.args, **self.kwargs)\nclass DollarMessage:\ndef __init__(self, fmt, /, **kwargs):\nself.fmt = fmt\nself.kwargs = kwargs\ndef __str__(self):\nfrom string import Template\nreturn Template(self.fmt).substitute(**self.kwargs)\nEither of these can be used in place of a format string, to allow {}- or $-formatting to be used to build the actual\n\u201cmessage\u201dpartwhichappearsintheformattedlogoutputinplaceof\u201c%(message)s\u201dor\u201c{message}\u201dor\u201c$message\u201d.\nIt\u2019salittleunwieldytousetheclassnameswheneveryouwanttologsomething,butit\u2019squitepalatableifyouusean\naliassuchas__(doubleunderscore\u2014nottobeconfusedwith_,thesingleunderscoreusedasasynonym/aliasfor\ngettext.gettext()oritsbrethren).\nTheaboveclassesarenotincludedinPython,thoughthey\u2019reeasyenoughtocopyandpasteintoyourowncode. They\ncanbeusedasfollows(assumingthatthey\u2019redeclaredinamodulecalledwherever):\n>>> from wherever import BraceMessage as __\n>>> print(__('Message with {0} {name}', 2, name='placeholders'))\nMessage with 2 placeholders\n>>> class Point: pass\n...\n>>> p = Point()\n>>> p.x = 0.5\n>>> p.y = 0.5\n>>> print(__('Message with coordinates: ({point.x:.2f}, {point.y:.2f})',\n... point=p))\nMessage with coordinates: (0.50, 0.50)\n>>> from wherever import DollarMessage as __\n>>> print(__('Message with $num $what', num=2, what='placeholders'))\nMessage with 2 placeholders\n>>>\n29\nWhile the above examples use print() to show how the formatting works, you would of course use logger.\ndebug()orsimilartoactuallylogusingthisapproach.\nOnethingtonoteisthatyoupaynosignificantperformancepenaltywiththisapproach: theactualformattinghappens\nnotwhenyoumaketheloggingcall,butwhen(andif)theloggedmessageisactuallyabouttobeoutputtoalogbya\nhandler. Sotheonlyslightlyunusualthingwhichmighttripyouupisthattheparenthesesgoaroundtheformatstring\nandthearguments,notjusttheformatstring. That\u2019sbecausethe__notationisjustsyntaxsugarforaconstructorcall\ntooneoftheXXXMessageclasses.\nIfyouprefer,youcanuseaLoggerAdaptertoachieveasimilareffecttotheabove,asinthefollowingexample:\nimport logging\nclass Message:\ndef __init__(self, fmt, args):\nself.fmt = fmt\nself.args = args\ndef __str__(self):\nreturn self.fmt.format(*self.args)\nclass StyleAdapter(logging.LoggerAdapter):\ndef log(self, level, msg, /, *args, stacklevel=1, **kwargs):\nif self.isEnabledFor(level):\nmsg, kwargs = self.process(msg, kwargs)\nself.logger.log(level, Message(msg, args), **kwargs,\nstacklevel=stacklevel+1)\nlogger = StyleAdapter(logging.getLogger(__name__))\ndef main():\nlogger.debug('Hello, {}', 'world!')\nif __name__ == '__main__':\nlogging.basicConfig(level=logging.DEBUG)\nmain()\nTheabovescriptshouldlogthemessageHello, world!whenrunwithPython3.8orlater.\n15 Customizing LogRecord\nEveryloggingeventisrepresentedbyaLogRecordinstance. Whenaneventisloggedandnotfilteredoutbyalogger\u2019s\nlevel,aLogRecordiscreated,populatedwithinformationabouttheeventandthenpassedtothehandlersforthat\nlogger (and its ancestors, up to and including the logger where further propagation up the hierarchy is disabled).\nBeforePython3.2,therewereonlytwoplaceswherethiscreationwasdone:\n\u2022 Logger.makeRecord(),whichiscalledinthenormalprocessoflogginganevent. ThisinvokedLogRecord\ndirectlytocreateaninstance.\n\u2022 makeLogRecord(), which is called with a dictionary containing attributes to be added to the LogRecord.\nThisistypicallyinvokedwhenasuitabledictionaryhasbeenreceivedoverthenetwork(e.g. inpickleform\nviaaSocketHandler,orinJSONformviaanHTTPHandler).\nThis has usually meant that if you need to do anything special with a LogRecord, you\u2019ve had to do one of the\nfollowing.\n\u2022 Create your own Logger subclass, which overrides Logger.makeRecord(), and set it using\nsetLoggerClass()beforeanyloggersthatyoucareaboutareinstantiated.\n\u2022 Add a Filter to a logger or handler, which does the necessary special manipulation you need when its\nfilter()methodiscalled.\n30\nThe first approach would be a little unwieldy in the scenario where (say) several different libraries wanted to do\ndifferentthings. EachwouldattempttosetitsownLoggersubclass,andtheonewhichdidthislastwouldwin.\nThesecondapproachworksreasonablywellformanycases,butdoesnotallowyoutoe.g. useaspecializedsubclass\nofLogRecord. Librarydeveloperscansetasuitablefilterontheirloggers,buttheywouldhavetoremembertodo\nthiseverytimetheyintroducedanewlogger(whichtheywoulddosimplybyaddingnewpackagesormodulesand\ndoing\nlogger = logging.getLogger(__name__)\nat module level). It\u2019s probably one too many things to think about. Developers could also add the filter to a\nNullHandlerattachedtotheirtop-levellogger,butthiswouldnotbeinvokedifanapplicationdeveloperattached\nahandlertoalower-levellibrarylogger\u2014sooutputfromthathandlerwouldnotreflecttheintentionsofthelibrary\ndeveloper.\nInPython3.2andlater,LogRecordcreationisdonethroughafactory,whichyoucanspecify. Thefactoryisjust\na callable you can set with setLogRecordFactory(), and interrogate with getLogRecordFactory(). The\nfactoryisinvokedwiththesamesignatureastheLogRecordconstructor,asLogRecordisthedefaultsettingfor\nthefactory.\nThisapproachallowsacustomfactorytocontrolallaspectsofLogRecordcreation. Forexample,youcouldreturn\nasubclass,orjustaddsomeadditionalattributestotherecordoncecreated,usingapatternsimilartothis:\nold_factory = logging.getLogRecordFactory()\ndef record_factory(*args, **kwargs):\nrecord = old_factory(*args, **kwargs)\nrecord.custom_attribute = 0xdecafbad\nreturn record\nlogging.setLogRecordFactory(record_factory)\nThis pattern allows different libraries to chain factories together, and as long as they don\u2019t overwrite each other\u2019s\nattributesorunintentionallyoverwritetheattributesprovidedasstandard,thereshouldbenosurprises. However,it\nshouldbeborneinmindthateachlinkinthechainaddsrun-timeoverheadtoallloggingoperations,andthetechnique\nshouldonlybeusedwhentheuseofaFilterdoesnotprovidethedesiredresult.\n16 Subclassing QueueHandler and QueueListener- a ZeroMQ ex-\nample\n16.1 Subclass QueueHandler\nYoucanuseaQueueHandlersubclasstosendmessagestootherkindsofqueues,forexampleaZeroMQ\u2018publish\u2019\nsocket. Intheexamplebelow,thesocketiscreatedseparatelyandpassedtothehandler(asits\u2018queue\u2019):\nimport zmq # using pyzmq, the Python binding for ZeroMQ\nimport json # for serializing records portably\nctx = zmq.Context()\nsock = zmq.Socket(ctx, zmq.PUB) # or zmq.PUSH, or other suitable value\nsock.bind('tcp://*:5556') # or wherever\nclass ZeroMQSocketHandler(QueueHandler):\ndef enqueue(self, record):\nself.queue.send_json(record.__dict__)\nhandler = ZeroMQSocketHandler(sock)\n31\nOfcoursethereareotherwaysoforganizingthis,forexamplepassinginthedataneededbythehandlertocreatethe\nsocket:\nclass ZeroMQSocketHandler(QueueHandler):\ndef __init__(self, uri, socktype=zmq.PUB, ctx=None):\nself.ctx = ctx or zmq.Context()\nsocket = zmq.Socket(self.ctx, socktype)\nsocket.bind(uri)\nsuper().__init__(socket)\ndef enqueue(self, record):\nself.queue.send_json(record.__dict__)\ndef close(self):\nself.queue.close()\n16.2 Subclass QueueListener\nYoucanalsosubclassQueueListenertogetmessagesfromotherkindsofqueues,forexampleaZeroMQ\u2018sub-\nscribe\u2019socket. Here\u2019sanexample:\nclass ZeroMQSocketListener(QueueListener):\ndef __init__(self, uri, /, *handlers, **kwargs):\nself.ctx = kwargs.get('ctx') or zmq.Context()\nsocket = zmq.Socket(self.ctx, zmq.SUB)\nsocket.setsockopt_string(zmq.SUBSCRIBE, '') # subscribe to everything\nsocket.connect(uri)\nsuper().__init__(socket, *handlers, **kwargs)\ndef dequeue(self):\nmsg = self.queue.recv_json()\nreturn logging.makeLogRecord(msg)\n17 Subclassing QueueHandler and QueueListener- a pynng exam-\nple\nIn a similar way to the above section, we can implement a listener and handler using pynng, which is a Python\nbindingtoNNG,billedasaspiritualsuccessortoZeroMQ.Thefollowingsnippetsillustrate\u2013youcantestthemin\nanenvironmentwhichhaspynnginstalled. Justforvariety,wepresentthelistenerfirst.\n17.1 Subclass QueueListener\n# listener.py\nimport json\nimport logging\nimport logging.handlers\nimport pynng\nDEFAULT_ADDR = \"tcp://localhost:13232\"\ninterrupted = False\nclass NNGSocketListener(logging.handlers.QueueListener):\n(continuesonnextpage)\n32\n(continuedfrompreviouspage)\ndef __init__(self, uri, /, *handlers, **kwargs):\n# Have a timeout for interruptability, and open a\n# subscriber socket\nsocket = pynng.Sub0(listen=uri, recv_timeout=500)\n# The b'' subscription matches all topics\ntopics = kwargs.pop('topics', None) or b''\nsocket.subscribe(topics)\n# We treat the socket as a queue\nsuper().__init__(socket, *handlers, **kwargs)\ndef dequeue(self, block):\ndata = None\n# Keep looping while not interrupted and no data received over the\n# socket\nwhile not interrupted:\ntry:\ndata = self.queue.recv(block=block)\nbreak\nexcept pynng.Timeout:\npass\nexcept pynng.Closed: # sometimes happens when you hit Ctrl-C\nbreak\nif data is None:\nreturn None\n# Get the logging event sent from a publisher\nevent = json.loads(data.decode('utf-8'))\nreturn logging.makeLogRecord(event)\ndef enqueue_sentinel(self):\n# Not used in this implementation, as the socket isn't really a\n# queue\npass\nlogging.getLogger('pynng').propagate = False\nlistener = NNGSocketListener(DEFAULT_ADDR, logging.StreamHandler(), topics=b'')\nlistener.start()\nprint('Press Ctrl-C to stop.')\ntry:\nwhile True:\npass\nexcept KeyboardInterrupt:\ninterrupted = True\nfinally:\nlistener.stop()\n17.2 Subclass QueueHandler\n# sender.py\nimport json\nimport logging\nimport logging.handlers\nimport time\nimport random\nimport pynng\n(continuesonnextpage)\n33\n(continuedfrompreviouspage)\nDEFAULT_ADDR = \"tcp://localhost:13232\"\nclass NNGSocketHandler(logging.handlers.QueueHandler):\ndef __init__(self, uri):\nsocket = pynng.Pub0(dial=uri, send_timeout=500)\nsuper().__init__(socket)\ndef enqueue(self, record):\n# Send the record as UTF-8 encoded JSON\nd = dict(record.__dict__)\ndata = json.dumps(d)\nself.queue.send(data.encode('utf-8'))\ndef close(self):\nself.queue.close()\nlogging.getLogger('pynng').propagate = False\nhandler = NNGSocketHandler(DEFAULT_ADDR)\n# Make sure the process ID is in the output\nlogging.basicConfig(level=logging.DEBUG,\nhandlers=[logging.StreamHandler(), handler],\nformat='%(levelname)-8s %(name)10s %(process)6s %(message)s')\nlevels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL)\nlogger_names = ('myapp', 'myapp.lib1', 'myapp.lib2')\nmsgno = 1\nwhile True:\n# Just randomly select some loggers and levels and log away\nlevel = random.choice(levels)\nlogger = logging.getLogger(random.choice(logger_names))\nlogger.log(level, 'Message no. %5d' % msgno)\nmsgno += 1\ndelay = random.random() * 2 + 0.5\ntime.sleep(delay)\nYoucanruntheabovetwosnippetsinseparatecommandshells. Ifwerunthelistenerinoneshellandrunthesender\nintwoseparateshells,weshouldseesomethinglikethefollowing. Inthefirstsendershell:\n$ python sender.py\nDEBUG myapp 613 Message no. 1\nWARNING myapp.lib2 613 Message no. 2\nCRITICAL myapp.lib2 613 Message no. 3\nWARNING myapp.lib2 613 Message no. 4\nCRITICAL myapp.lib1 613 Message no. 5\nDEBUG myapp 613 Message no. 6\nCRITICAL myapp.lib1 613 Message no. 7\nINFO myapp.lib1 613 Message no. 8\n(and so on)\nInthesecondsendershell:\n$ python sender.py\nINFO myapp.lib2 657 Message no. 1\nCRITICAL myapp.lib2 657 Message no. 2\nCRITICAL myapp 657 Message no. 3\n(continuesonnextpage)\n34\n(continuedfrompreviouspage)\nCRITICAL myapp.lib1 657 Message no. 4\nINFO myapp.lib1 657 Message no. 5\nWARNING myapp.lib2 657 Message no. 6\nCRITICAL myapp 657 Message no. 7\nDEBUG myapp.lib1 657 Message no. 8\n(and so on)\nInthelistenershell:\n$ python listener.py\nPress Ctrl-C to stop.\nDEBUG myapp 613 Message no. 1\nWARNING myapp.lib2 613 Message no. 2\nINFO myapp.lib2 657 Message no. 1\nCRITICAL myapp.lib2 613 Message no. 3\nCRITICAL myapp.lib2 657 Message no. 2\nCRITICAL myapp 657 Message no. 3\nWARNING myapp.lib2 613 Message no. 4\nCRITICAL myapp.lib1 613 Message no. 5\nCRITICAL myapp.lib1 657 Message no. 4\nINFO myapp.lib1 657 Message no. 5\nDEBUG myapp 613 Message no. 6\nWARNING myapp.lib2 657 Message no. 6\nCRITICAL myapp 657 Message no. 7\nCRITICAL myapp.lib1 613 Message no. 7\nINFO myapp.lib1 613 Message no. 8\nDEBUG myapp.lib1 657 Message no. 8\n(and so on)\nAsyoucansee,theloggingfromthetwosenderprocessesisinterleavedinthelistener\u2019soutput.\n18 An example dictionary-based configuration\nBelowisanexampleofaloggingconfigurationdictionary-it\u2019stakenfromthedocumentationontheDjangoproject.\nThisdictionaryispassedtodictConfig()toputtheconfigurationintoeffect:\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'verbose': {\n'format': '{levelname} {asctime} {module} {process:d} {thread:d}\n,\u2192{message}',\n'style': '{',\n},\n'simple': {\n'format': '{levelname} {message}',\n'style': '{',\n},\n},\n'filters': {\n'special': {\n'()': 'project.logging.SpecialFilter',\n'foo': 'bar',\n},\n},\n(continuesonnextpage)\n35\n(continuedfrompreviouspage)\n'handlers': {\n'console': {\n'level': 'INFO',\n'class': 'logging.StreamHandler',\n'formatter': 'simple',\n},\n'mail_admins': {\n'level': 'ERROR',\n'class': 'django.utils.log.AdminEmailHandler',\n'filters': ['special']\n}\n},\n'loggers': {\n'django': {\n'handlers': ['console'],\n'propagate': True,\n},\n'django.request': {\n'handlers': ['mail_admins'],\n'level': 'ERROR',\n'propagate': False,\n},\n'myproject.custom': {\n'handlers': ['console', 'mail_admins'],\n'level': 'INFO',\n'filters': ['special']\n}\n}\n}\nFormoreinformationaboutthisconfiguration,youcanseetherelevantsectionoftheDjangodocumentation.\n19 Using a rotator and namer to customize log rotation processing\nAnexampleofhowyoucandefineanamerandrotatorisgiveninthefollowingrunnablescript,whichshowsgzip\ncompressionofthelogfile:\nimport gzip\nimport logging\nimport logging.handlers\nimport os\nimport shutil\ndef namer(name):\nreturn name + \".gz\"\ndef rotator(source, dest):\nwith open(source, 'rb') as f_in:\nwith gzip.open(dest, 'wb') as f_out:\nshutil.copyfileobj(f_in, f_out)\nos.remove(source)\nrh = logging.handlers.RotatingFileHandler('rotated.log', maxBytes=128,\u2423\n,\u2192backupCount=5)\nrh.rotator = rotator\n(continuesonnextpage)\n36\n(continuedfrompreviouspage)\nrh.namer = namer\nroot = logging.getLogger()\nroot.setLevel(logging.INFO)\nroot.addHandler(rh)\nf = logging.Formatter('%(asctime)s %(message)s')\nrh.setFormatter(f)\nfor i in range(1000):\nroot.info(f'Message no. {i + 1}')\nAfterrunningthis,youwillseesixnewfiles,fiveofwhicharecompressed:\n$ ls rotated.log*\nrotated.log rotated.log.2.gz rotated.log.4.gz\nrotated.log.1.gz rotated.log.3.gz rotated.log.5.gz\n$ zcat rotated.log.1.gz\n2023-01-20 02:28:17,767 Message no. 996\n2023-01-20 02:28:17,767 Message no. 997\n2023-01-20 02:28:17,767 Message no. 998\n20 A more elaborate multiprocessing example\nThefollowingworkingexampleshowshowloggingcanbeusedwithmultiprocessingusingconfigurationfiles. The\nconfigurationsarefairlysimple,butservetoillustratehowmorecomplexonescouldbeimplementedinarealmul-\ntiprocessingscenario.\nIntheexample,themainprocessspawnsalistenerprocessandsomeworkerprocesses. Eachofthemainprocess,\nthelistenerandtheworkershavethreeseparateconfigurations(theworkersallsharethesameconfiguration). We\ncan see logging in the main process, how the workers log to a QueueHandler and how the listener implements a\nQueueListenerandamorecomplexloggingconfiguration,andarrangestodispatcheventsreceivedviathequeueto\nthehandlersspecifiedintheconfiguration. Notethattheseconfigurationsarepurelyillustrative,butyoushouldbe\nabletoadaptthisexampletoyourownscenario.\nHere\u2019sthescript-thedocstringsandthecommentshopefullyexplainhowitworks:\nimport logging\nimport logging.config\nimport logging.handlers\nfrom multiprocessing import Process, Queue, Event, current_process\nimport os\nimport random\nimport time\nclass MyHandler:\n\"\"\"\nA simple handler for logging events. It runs in the listener process and\ndispatches events to loggers based on the name in the received record,\nwhich then get dispatched, by the logging system, to the handlers\nconfigured for those loggers.\n\"\"\"\ndef handle(self, record):\nif record.name == \"root\":\nlogger = logging.getLogger()\nelse:\nlogger = logging.getLogger(record.name)\n(continuesonnextpage)\n37\n(continuedfrompreviouspage)\nif logger.isEnabledFor(record.levelno):\n# The process name is transformed just to show that it's the listener\n# doing the logging to files and console\nrecord.processName = '%s (for %s)' % (current_process().name, record.\n,\u2192processName)\nlogger.handle(record)\ndef listener_process(q, stop_event, config):\n\"\"\"\nThis could be done in the main process, but is just done in a separate\nprocess for illustrative purposes.\nThis initialises logging according to the specified configuration,\nstarts the listener and waits for the main process to signal completion\nvia the event. The listener is then stopped, and the process exits.\n\"\"\"\nlogging.config.dictConfig(config)\nlistener = logging.handlers.QueueListener(q, MyHandler())\nlistener.start()\nif os.name == 'posix':\n# On POSIX, the setup logger will have been configured in the\n# parent process, but should have been disabled following the\n# dictConfig call.\n# On Windows, since fork isn't used, the setup logger won't\n# exist in the child, so it would be created and the message\n# would appear - hence the \"if posix\" clause.\nlogger = logging.getLogger('setup')\nlogger.critical('Should not appear, because of disabled logger ...')\nstop_event.wait()\nlistener.stop()\ndef worker_process(config):\n\"\"\"\nA number of these are spawned for the purpose of illustration. In\npractice, they could be a heterogeneous bunch of processes rather than\nones which are identical to each other.\nThis initialises logging according to the specified configuration,\nand logs a hundred messages with random levels to randomly selected\nloggers.\nA small sleep is added to allow other processes a chance to run. This\nis not strictly needed, but it mixes the output from the different\nprocesses a bit more than if it's left out.\n\"\"\"\nlogging.config.dictConfig(config)\nlevels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL]\nloggers = ['foo', 'foo.bar', 'foo.bar.baz',\n'spam', 'spam.ham', 'spam.ham.eggs']\nif os.name == 'posix':\n# On POSIX, the setup logger will have been configured in the\n# parent process, but should have been disabled following the\n# dictConfig call.\n# On Windows, since fork isn't used, the setup logger won't\n(continuesonnextpage)\n38\n(continuedfrompreviouspage)\n# exist in the child, so it would be created and the message\n# would appear - hence the \"if posix\" clause.\nlogger = logging.getLogger('setup')\nlogger.critical('Should not appear, because of disabled logger ...')\nfor i in range(100):\nlvl = random.choice(levels)\nlogger = logging.getLogger(random.choice(loggers))\nlogger.log(lvl, 'Message no. %d', i)\ntime.sleep(0.01)\ndef main():\nq = Queue()\n# The main process gets a simple configuration which prints to the console.\nconfig_initial = {\n'version': 1,\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'level': 'INFO'\n}\n},\n'root': {\n'handlers': ['console'],\n'level': 'DEBUG'\n}\n}\n# The worker process configuration is just a QueueHandler attached to the\n# root logger, which allows all messages to be sent to the queue.\n# We disable existing loggers to disable the \"setup\" logger used in the\n# parent process. This is needed on POSIX because the logger will\n# be there in the child following a fork().\nconfig_worker = {\n'version': 1,\n'disable_existing_loggers': True,\n'handlers': {\n'queue': {\n'class': 'logging.handlers.QueueHandler',\n'queue': q\n}\n},\n'root': {\n'handlers': ['queue'],\n'level': 'DEBUG'\n}\n}\n# The listener process configuration shows that the full flexibility of\n# logging configuration is available to dispatch events to handlers however\n# you want.\n# We disable existing loggers to disable the \"setup\" logger used in the\n# parent process. This is needed on POSIX because the logger will\n# be there in the child following a fork().\nconfig_listener = {\n'version': 1,\n'disable_existing_loggers': True,\n'formatters': {\n'detailed': {\n(continuesonnextpage)\n39\n(continuedfrompreviouspage)\n'class': 'logging.Formatter',\n'format': '%(asctime)s %(name)-15s %(levelname)-8s %(processName)-\n,\u219210s %(message)s'\n},\n'simple': {\n'class': 'logging.Formatter',\n'format': '%(name)-15s %(levelname)-8s %(processName)-10s\n,\u2192%(message)s'\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'formatter': 'simple',\n'level': 'INFO'\n},\n'file': {\n'class': 'logging.FileHandler',\n'filename': 'mplog.log',\n'mode': 'w',\n'formatter': 'detailed'\n},\n'foofile': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-foo.log',\n'mode': 'w',\n'formatter': 'detailed'\n},\n'errors': {\n'class': 'logging.FileHandler',\n'filename': 'mplog-errors.log',\n'mode': 'w',\n'formatter': 'detailed',\n'level': 'ERROR'\n}\n},\n'loggers': {\n'foo': {\n'handlers': ['foofile']\n}\n},\n'root': {\n'handlers': ['console', 'file', 'errors'],\n'level': 'DEBUG'\n}\n}\n# Log some initial events, just to show that logging in the parent works\n# normally.\nlogging.config.dictConfig(config_initial)\nlogger = logging.getLogger('setup')\nlogger.info('About to create workers ...')\nworkers = []\nfor i in range(5):\nwp = Process(target=worker_process, name='worker %d' % (i + 1),\nargs=(config_worker,))\nworkers.append(wp)\n(continuesonnextpage)\n40\n(continuedfrompreviouspage)\nwp.start()\nlogger.info('Started worker: %s', wp.name)\nlogger.info('About to create listener ...')\nstop_event = Event()\nlp = Process(target=listener_process, name='listener',\nargs=(q, stop_event, config_listener))\nlp.start()\nlogger.info('Started listener')\n# We now hang around for the workers to finish their work.\nfor wp in workers:\nwp.join()\n# Workers all done, listening can now stop.\n# Logging in the parent still works normally.\nlogger.info('Telling listener to stop ...')\nstop_event.set()\nlp.join()\nlogger.info('All done.')\nif __name__ == '__main__':\nmain()\n21 Inserting a BOM into messages sent to a SysLogHandler\nRFC5424requiresthataUnicodemessagebesenttoasyslogdaemonasasetofbyteswhichhavethefollowing\nstructure: anoptionalpure-ASCIIcomponent,followedbyaUTF-8ByteOrderMark(BOM),followedbyUnicode\nencodedusingUTF-8. (Seetherelevantsectionofthespecification.)\nIn Python 3.1, code was added to SysLogHandler to insert a BOM into the message, but unfortunately, it was\nimplementedincorrectly,withtheBOMappearingatthebeginningofthemessageandhencenotallowinganypure-\nASCIIcomponenttoappearbeforeit.\nAsthisbehaviourisbroken,theincorrectBOMinsertioncodeisbeingremovedfromPython3.2.4andlater. How-\never,itisnotbeingreplaced,andifyouwanttoproduceRFC5424-compliantmessageswhichincludeaBOM,an\noptionalpure-ASCIIsequencebeforeitandarbitraryUnicodeafterit, encodedusingUTF-8, thenyouneedtodo\nthefollowing:\n1. AttachaFormatterinstancetoyourSysLogHandlerinstance,withaformatstringsuchas:\n'ASCII section\\ufeffUnicode section'\nTheUnicodecodepointU+FEFF,whenencodedusingUTF-8,willbeencodedasaUTF-8BOM\u2013thebyte-\nstringb'\\xef\\xbb\\xbf'.\n2. Replace the ASCII section with whatever placeholders you like, but make sure that the data that appears in\nthereaftersubstitutionisalwaysASCII(thatway,itwillremainunchangedafterUTF-8encoding).\n3. ReplacetheUnicodesectionwithwhateverplaceholdersyoulike;ifthedatawhichappearsthereaftersubsti-\ntutioncontainscharactersoutsidetheASCIIrange,that\u2019sfine\u2013itwillbeencodedusingUTF-8.\nTheformattedmessagewillbeencodedusingUTF-8encodingbySysLogHandler. Ifyoufollowtheaboverules,\nyou should be able to produce RFC 5424-compliant messages. If you don\u2019t, logging may not complain, but your\nmessageswillnotbeRFC5424-compliant,andyoursyslogdaemonmaycomplain.\n22 Implementing structured logging\nAlthoughmostloggingmessagesareintendedforreadingbyhumans,andthusnotreadilymachine-parseable,there\nmightbecircumstanceswhereyouwanttooutputmessagesinastructuredformatwhichiscapableofbeingparsed\nby a program (without needing complex regular expressions to parse the log message). This is straightforward to\n41\nachieveusingtheloggingpackage. Thereareanumberofwaysinwhichthiscouldbeachieved,butthefollowingis\nasimpleapproachwhichusesJSONtoserialisetheeventinamachine-parseablemanner:\nimport json\nimport logging\nclass StructuredMessage:\ndef __init__(self, message, /, **kwargs):\nself.message = message\nself.kwargs = kwargs\ndef __str__(self):\nreturn '%s >>> %s' % (self.message, json.dumps(self.kwargs))\n_ = StructuredMessage # optional, to improve readability\nlogging.basicConfig(level=logging.INFO, format='%(message)s')\nlogging.info(_('message 1', foo='bar', bar='baz', num=123, fnum=123.456))\nIftheabovescriptisrun,itprints:\nmessage 1 >>> {\"fnum\": 123.456, \"num\": 123, \"bar\": \"baz\", \"foo\": \"bar\"}\nNotethattheorderofitemsmightbedifferentaccordingtotheversionofPythonused.\nIfyouneedmorespecialisedprocessing,youcanuseacustomJSONencoder,asinthefollowingcompleteexample:\nimport json\nimport logging\nclass Encoder(json.JSONEncoder):\ndef default(self, o):\nif isinstance(o, set):\nreturn tuple(o)\nelif isinstance(o, str):\nreturn o.encode('unicode_escape').decode('ascii')\nreturn super().default(o)\nclass StructuredMessage:\ndef __init__(self, message, /, **kwargs):\nself.message = message\nself.kwargs = kwargs\ndef __str__(self):\ns = Encoder().encode(self.kwargs)\nreturn '%s >>> %s' % (self.message, s)\n_ = StructuredMessage # optional, to improve readability\ndef main():\nlogging.basicConfig(level=logging.INFO, format='%(message)s')\nlogging.info(_('message 1', set_value={1, 2, 3}, snowman='\\u2603'))\nif __name__ == '__main__':\nmain()\nWhentheabovescriptisrun,itprints:\n42\nmessage 1 >>> {\"snowman\": \"\\u2603\", \"set_value\": [1, 2, 3]}\nNotethattheorderofitemsmightbedifferentaccordingtotheversionofPythonused.\n23 Customizing handlers with dictConfig()\nTherearetimeswhenyouwanttocustomizelogginghandlersinparticularways,andifyouusedictConfig()you\nmay be able to do this without subclassing. As an example, consider that you may want to set the ownership of a\nlogfile. OnPOSIX,thisiseasilydoneusingshutil.chown(),butthefilehandlersinthestdlibdon\u2019tofferbuilt-in\nsupport. Youcancustomizehandlercreationusingaplainfunctionsuchas:\ndef owned_file_handler(filename, mode='a', encoding=None, owner=None):\nif owner:\nif not os.path.exists(filename):\nopen(filename, 'a').close()\nshutil.chown(filename, *owner)\nreturn logging.FileHandler(filename, mode, encoding)\nYou can then specify, in a logging configuration passed to dictConfig(), that a logging handler be created by\ncallingthisfunction:\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'default': {\n'format': '%(asctime)s %(levelname)s %(name)s %(message)s'\n},\n},\n'handlers': {\n'file':{\n# The values below are popped from this dictionary and\n# used to create the handler, set the handler's level and\n# its formatter.\n'()': owned_file_handler,\n'level':'DEBUG',\n'formatter': 'default',\n# The values below are passed to the handler creator callable\n# as keyword arguments.\n'owner': ['pulse', 'pulse'],\n'filename': 'chowntest.log',\n'mode': 'w',\n'encoding': 'utf-8',\n},\n},\n'root': {\n'handlers': ['file'],\n'level': 'DEBUG',\n},\n}\nIn this example I am setting the ownership using the pulse user and group, just for the purposes of illustration.\nPuttingittogetherintoaworkingscript,chowntest.py:\nimport logging, logging.config, os, shutil\ndef owned_file_handler(filename, mode='a', encoding=None, owner=None):\n(continuesonnextpage)\n43\n(continuedfrompreviouspage)\nif owner:\nif not os.path.exists(filename):\nopen(filename, 'a').close()\nshutil.chown(filename, *owner)\nreturn logging.FileHandler(filename, mode, encoding)\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'default': {\n'format': '%(asctime)s %(levelname)s %(name)s %(message)s'\n},\n},\n'handlers': {\n'file':{\n# The values below are popped from this dictionary and\n# used to create the handler, set the handler's level and\n# its formatter.\n'()': owned_file_handler,\n'level':'DEBUG',\n'formatter': 'default',\n# The values below are passed to the handler creator callable\n# as keyword arguments.\n'owner': ['pulse', 'pulse'],\n'filename': 'chowntest.log',\n'mode': 'w',\n'encoding': 'utf-8',\n},\n},\n'root': {\n'handlers': ['file'],\n'level': 'DEBUG',\n},\n}\nlogging.config.dictConfig(LOGGING)\nlogger = logging.getLogger('mylogger')\nlogger.debug('A debug message')\nTorunthis,youwillprobablyneedtorunasroot:\n$ sudo python3.3 chowntest.py\n$ cat chowntest.log\n2013-11-05 09:34:51,128 DEBUG mylogger A debug message\n$ ls -l chowntest.log\n-rw-r--r-- 1 pulse pulse 55 2013-11-05 09:34 chowntest.log\nNotethatthisexampleusesPython3.3becausethat\u2019swhereshutil.chown()makesanappearance. Thisapproach\nshouldworkwithanyPythonversionthatsupportsdictConfig()-namely,Python2.7,3.2orlater. Withpre-3.3\nversions,youwouldneedtoimplementtheactualownershipchangeusinge.g. os.chown().\nInpractice,thehandler-creatingfunctionmaybeinautilitymodulesomewhereinyourproject. Insteadoftheline\nintheconfiguration:\n'()': owned_file_handler,\nyoucouldusee.g.:\n44\n'()': 'ext://project.util.owned_file_handler',\nwhere project.util can be replaced with the actual name of the package where the function resides. In the\naboveworkingscript,using'ext://__main__.owned_file_handler'shouldwork. Here,theactualcallable\nisresolvedbydictConfig()fromtheext:// specification.\nThis example hopefully also points the way to how you could implement other types of file change - e.g. setting\nspecificPOSIXpermissionbits-inthesameway,usingos.chmod().\nOfcourse,theapproachcouldalsobeextendedtotypesofhandlerotherthanaFileHandler-forexample,one\noftherotatingfilehandlers,oradifferenttypeofhandleraltogether.\n24 Using particular formatting styles throughout your application\nInPython3.2,theFormattergainedastylekeywordparameterwhich,whiledefaultingto%forbackwardcom-\npatibility, allowed the specification of { or $ to support the formatting approaches supported by str.format()\nandstring.Template. Notethatthisgovernstheformattingofloggingmessagesforfinaloutputtologs,andis\ncompletelyorthogonaltohowanindividualloggingmessageisconstructed.\nLoggingcalls(debug(), info() etc.) onlytakepositionalparametersfortheactualloggingmessageitself, with\nkeywordparametersusedonlyfordeterminingoptionsforhowtohandletheloggingcall(e.g. theexc_infokeyword\nparameter to indicate that traceback information should be logged, or the extra keyword parameter to indicate\nadditional contextual information to be added to the log). So you cannot directly make logging calls using str.\nformat()orstring.Templatesyntax, becauseinternallytheloggingpackageuses%-formattingtomergethe\nformatstringandthevariablearguments. Therewouldbenochangingthiswhilepreservingbackwardcompatibility,\nsinceallloggingcallswhichareoutthereinexistingcodewillbeusing%-formatstrings.\nTherehavebeensuggestionstoassociateformatstyleswithspecificloggers,butthatapproachalsorunsintobackward\ncompatibilityproblemsbecauseanyexistingcodecouldbeusingagivenloggernameandusing%-formatting.\nForloggingtoworkinteroperablybetweenanythird-partylibrariesandyourcode,decisionsaboutformattingneed\ntobemadeattheleveloftheindividualloggingcall. Thisopensupacoupleofwaysinwhichalternativeformatting\nstylescanbeaccommodated.\n24.1 Using LogRecord factories\nInPython3.2,alongwiththeFormatterchangesmentionedabove,theloggingpackagegainedtheabilitytoallow\nuserstosettheirownLogRecordsubclasses,usingthesetLogRecordFactory()function. Youcanusethistoset\nyourownsubclassofLogRecord,whichdoestheRightThingbyoverridingthegetMessage()method. Thebase\nclass implementation of this method is where the msg % args formatting happens, and where you can substitute\nyouralternateformatting;however,youshouldbecarefultosupportallformattingstylesandallow%-formattingas\nthedefault, toensureinteroperabilitywithothercode. Careshouldalsobetakentocallstr(self.msg), justas\nthebaseimplementationdoes.\nRefertothereferencedocumentationonsetLogRecordFactory()andLogRecordformoreinformation.\n24.2 Using custom message objects\nThereisanother,perhapssimplerwaythatyoucanuse{}-and$-formattingtoconstructyourindividuallogmessages.\nYou may recall (from arbitrary-object-messages) that when logging you can use an arbitrary object as a message\nformatstring,andthattheloggingpackagewillcallstr()onthatobjecttogettheactualformatstring. Consider\nthefollowingtwoclasses:\nclass BraceMessage:\ndef __init__(self, fmt, /, *args, **kwargs):\nself.fmt = fmt\nself.args = args\nself.kwargs = kwargs\n(continuesonnextpage)\n45\n(continuedfrompreviouspage)\ndef __str__(self):\nreturn self.fmt.format(*self.args, **self.kwargs)\nclass DollarMessage:\ndef __init__(self, fmt, /, **kwargs):\nself.fmt = fmt\nself.kwargs = kwargs\ndef __str__(self):\nfrom string import Template\nreturn Template(self.fmt).substitute(**self.kwargs)\nEither of these can be used in place of a format string, to allow {}- or $-formatting to be used to build the actual\n\u201cmessage\u201dpartwhichappearsintheformattedlogoutputinplaceof\u201c%(message)s\u201dor\u201c{message}\u201dor\u201c$message\u201d.\nIf you find it a little unwieldy to use the class names whenever you want to log something, you can make it more\npalatableifyouuseanaliassuchasMor_forthemessage(orperhaps__,ifyouareusing_forlocalization).\nExamplesofthisapproacharegivenbelow. Firstly,formattingwithstr.format():\n>>> __ = BraceMessage\n>>> print(__('Message with {0} {1}', 2, 'placeholders'))\nMessage with 2 placeholders\n>>> class Point: pass\n...\n>>> p = Point()\n>>> p.x = 0.5\n>>> p.y = 0.5\n>>> print(__('Message with coordinates: ({point.x:.2f}, {point.y:.2f})', point=p))\nMessage with coordinates: (0.50, 0.50)\nSecondly,formattingwithstring.Template:\n>>> __ = DollarMessage\n>>> print(__('Message with $num $what', num=2, what='placeholders'))\nMessage with 2 placeholders\n>>>\nOnethingtonoteisthatyoupaynosignificantperformancepenaltywiththisapproach: theactualformattinghappens\nnotwhenyoumaketheloggingcall,butwhen(andif)theloggedmessageisactuallyabouttobeoutputtoalogbya\nhandler. Sotheonlyslightlyunusualthingwhichmighttripyouupisthattheparenthesesgoaroundtheformatstring\nandthearguments,notjusttheformatstring. That\u2019sbecausethe__notationisjustsyntaxsugarforaconstructorcall\ntooneoftheXXXMessageclassesshownabove.\n25 Configuring filters with dictConfig()\nYoucanconfigurefiltersusingdictConfig(), thoughitmightnotbeobviousatfirstglancehowtodoit(hence\nthisrecipe). SinceFilteristheonlyfilterclassincludedinthestandardlibrary,anditisunlikelytocatertomany\nrequirements (it\u2019s only there as a base class), you will typically need to define your own Filter subclass with an\noverriddenfilter()method. Todothis,specifythe()keyintheconfigurationdictionaryforthefilter,specifying\nacallablewhichwillbeusedtocreatethefilter(aclassisthemostobvious,butyoucanprovideanycallablewhich\nreturnsaFilterinstance). Hereisacompleteexample:\nimport logging\nimport logging.config\nimport sys\n(continuesonnextpage)\n46\n(continuedfrompreviouspage)\nclass MyFilter(logging.Filter):\ndef __init__(self, param=None):\nself.param = param\ndef filter(self, record):\nif self.param is None:\nallow = True\nelse:\nallow = self.param not in record.msg\nif allow:\nrecord.msg = 'changed: ' + record.msg\nreturn allow\nLOGGING = {\n'version': 1,\n'filters': {\n'myfilter': {\n'()': MyFilter,\n'param': 'noshow',\n}\n},\n'handlers': {\n'console': {\n'class': 'logging.StreamHandler',\n'filters': ['myfilter']\n}\n},\n'root': {\n'level': 'DEBUG',\n'handlers': ['console']\n},\n}\nif __name__ == '__main__':\nlogging.config.dictConfig(LOGGING)\nlogging.debug('hello')\nlogging.debug('hello - noshow')\nThisexampleshowshowyoucanpassconfigurationdatatothecallablewhichconstructstheinstance,intheformof\nkeywordparameters. Whenrun,theabovescriptwillprint:\nchanged: hello\nwhichshowsthatthefilterisworkingasconfigured.\nAcoupleofextrapointstonote:\n\u2022 Ifyoucan\u2019trefertothecallabledirectlyintheconfiguration(e.g. ifitlivesinadifferentmodule,andyoucan\u2019t\nimport it directly where the configuration dictionary is), you can use the form ext://... as described in\nlogging-config-dict-externalobj. Forexample,youcouldhaveusedthetext'ext://__main__.MyFilter'\ninsteadofMyFilterintheaboveexample.\n\u2022 Aswellasforfilters,thistechniquecanalsobeusedtoconfigurecustomhandlersandformatters. Seelogging-\nconfig-dict-userdefformoreinformationonhowloggingsupportsusinguser-definedobjectsinitsconfigura-\ntion,andseetheothercookbookrecipeCustomizinghandlerswithdictConfig()above.\n47\n26 Customized exception formatting\nThere might be times when you want to do customized exception formatting - for argument\u2019s sake, let\u2019s say you\nwantexactlyonelineperloggedevent,evenwhenexceptioninformationispresent. Youcandothiswithacustom\nformatterclass,asshowninthefollowingexample:\nimport logging\nclass OneLineExceptionFormatter(logging.Formatter):\ndef formatException(self, exc_info):\n\"\"\"\nFormat an exception so that it prints on a single line.\n\"\"\"\nresult = super().formatException(exc_info)\nreturn repr(result) # or format into one line however you want to\ndef format(self, record):\ns = super().format(record)\nif record.exc_text:\ns = s.replace('\\n', '') + '|'\nreturn s\ndef configure_logging():\nfh = logging.FileHandler('output.txt', 'w')\nf = OneLineExceptionFormatter('%(asctime)s|%(levelname)s|%(message)s|',\n'%d/%m/%Y %H:%M:%S')\nfh.setFormatter(f)\nroot = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nroot.addHandler(fh)\ndef main():\nconfigure_logging()\nlogging.info('Sample message')\ntry:\nx = 1 / 0\nexcept ZeroDivisionError as e:\nlogging.exception('ZeroDivisionError: %s', e)\nif __name__ == '__main__':\nmain()\nWhenrun,thisproducesafilewithexactlytwolines:\n28/01/2015 07:21:23|INFO|Sample message|\n28/01/2015 07:21:23|ERROR|ZeroDivisionError: integer division or modulo by zero|\n,\u2192'Traceback (most recent call last):\\n File \"logtest7.py\", line 30, in main\\n \u2423\n,\u2192x = 1 / 0\\nZeroDivisionError: integer division or modulo by zero'|\nWhile the above treatment is simplistic, it points the way to how exception information can be formatted to your\nliking. Thetracebackmodulemaybehelpfulformorespecializedneeds.\n27 Speaking logging messages\nTheremightbesituationswhenitisdesirabletohaveloggingmessagesrenderedinanaudibleratherthanavisible\nformat. Thisiseasytodoifyouhavetext-to-speech(TTS)functionalityavailableinyoursystem,evenifitdoesn\u2019t\nhaveaPythonbinding. MostTTSsystemshaveacommandlineprogramyoucanrun,andthiscanbeinvokedfrom\na handler using subprocess. It\u2019s assumed here that TTS command line programs won\u2019t expect to interact with\n48\nusersortakealongtimetocomplete,andthatthefrequencyofloggedmessageswillbenotsohighastoswampthe\nuserwithmessages,andthatit\u2019sacceptabletohavethemessagesspokenoneatatimeratherthanconcurrently,The\nexampleimplementationbelowwaitsforonemessagetobespokenbeforethenextisprocessed,andthismightcause\notherhandlerstobekeptwaiting. Hereisashortexampleshowingtheapproach,whichassumesthattheespeak\nTTSpackageisavailable:\nimport logging\nimport subprocess\nimport sys\nclass TTSHandler(logging.Handler):\ndef emit(self, record):\nmsg = self.format(record)\n# Speak slowly in a female English voice\ncmd = ['espeak', '-s150', '-ven+f3', msg]\np = subprocess.Popen(cmd, stdout=subprocess.PIPE,\nstderr=subprocess.STDOUT)\n# wait for the program to finish\np.communicate()\ndef configure_logging():\nh = TTSHandler()\nroot = logging.getLogger()\nroot.addHandler(h)\n# the default formatter just returns the message\nroot.setLevel(logging.DEBUG)\ndef main():\nlogging.info('Hello')\nlogging.debug('Goodbye')\nif __name__ == '__main__':\nconfigure_logging()\nsys.exit(main())\nWhenrun,thisscriptshouldsay\u201cHello\u201dandthen\u201cGoodbye\u201dinafemalevoice.\nTheaboveapproachcan,ofcourse,beadaptedtootherTTSsystemsandevenothersystemsaltogetherwhichcan\nprocessmessagesviaexternalprogramsrunfromacommandline.\n28 Buffering logging messages and outputting them conditionally\nThere might be situations where you want to log messages in a temporary area and only output them if a certain\nconditionoccurs. Forexample,youmaywanttostartloggingdebugeventsinafunction,andifthefunctioncompletes\nwithout errors, you don\u2019t want to clutter the log with the collected debug information, but if there is an error, you\nwantallthedebuginformationtobeoutputaswellastheerror.\nHereisanexamplewhichshowshowyoucoulddothisusingadecoratorforyourfunctionswhereyouwantlogging\ntobehavethisway. Itmakesuseofthelogging.handlers.MemoryHandler,whichallowsbufferingoflogged\neventsuntilsomeconditionoccurs,atwhichpointthebufferedeventsareflushed-passedtoanotherhandler(the\ntargethandler)forprocessing. Bydefault,theMemoryHandlerflushedwhenitsbuffergetsfilleduporanevent\nwhoselevelisgreaterthanorequaltoaspecifiedthresholdisseen. Youcanusethisrecipewithamorespecialised\nsubclassofMemoryHandlerifyouwantcustomflushingbehavior.\nThe example script has a simple function, foo, which just cycles through all the logging levels, writing to sys.\nstderr to say what level it\u2019s about to log at, and then actually logging a message at that level. You can pass a\nparametertofoowhich,iftrue,willlogatERRORandCRITICALlevels-otherwise,itonlylogsatDEBUG,INFO\nandWARNINGlevels.\nThescriptjustarrangestodecoratefoowithadecoratorwhichwilldotheconditionalloggingthat\u2019srequired. The\n49\ndecoratortakesaloggerasaparameterandattachesamemoryhandlerforthedurationofthecalltothedecorated\nfunction. The decorator can be additionally parameterised using a target handler, a level at which flushing should\noccur,andacapacityforthebuffer(numberofrecordsbuffered). ThesedefaulttoaStreamHandlerwhichwrites\ntosys.stderr,logging.ERRORand100respectively.\nHere\u2019sthescript:\nimport logging\nfrom logging.handlers import MemoryHandler\nimport sys\nlogger = logging.getLogger(__name__)\nlogger.addHandler(logging.NullHandler())\ndef log_if_errors(logger, target_handler=None, flush_level=None, capacity=None):\nif target_handler is None:\ntarget_handler = logging.StreamHandler()\nif flush_level is None:\nflush_level = logging.ERROR\nif capacity is None:\ncapacity = 100\nhandler = MemoryHandler(capacity, flushLevel=flush_level, target=target_\n,\u2192handler)\ndef decorator(fn):\ndef wrapper(*args, **kwargs):\nlogger.addHandler(handler)\ntry:\nreturn fn(*args, **kwargs)\nexcept Exception:\nlogger.exception('call failed')\nraise\nfinally:\nsuper(MemoryHandler, handler).flush()\nlogger.removeHandler(handler)\nreturn wrapper\nreturn decorator\ndef write_line(s):\nsys.stderr.write('%s\\n' % s)\ndef foo(fail=False):\nwrite_line('about to log at DEBUG ...')\nlogger.debug('Actually logged at DEBUG')\nwrite_line('about to log at INFO ...')\nlogger.info('Actually logged at INFO')\nwrite_line('about to log at WARNING ...')\nlogger.warning('Actually logged at WARNING')\nif fail:\nwrite_line('about to log at ERROR ...')\nlogger.error('Actually logged at ERROR')\nwrite_line('about to log at CRITICAL ...')\nlogger.critical('Actually logged at CRITICAL')\nreturn fail\ndecorated_foo = log_if_errors(logger)(foo)\n(continuesonnextpage)\n50\n(continuedfrompreviouspage)\nif __name__ == '__main__':\nlogger.setLevel(logging.DEBUG)\nwrite_line('Calling undecorated foo with False')\nassert not foo(False)\nwrite_line('Calling undecorated foo with True')\nassert foo(True)\nwrite_line('Calling decorated foo with False')\nassert not decorated_foo(False)\nwrite_line('Calling decorated foo with True')\nassert decorated_foo(True)\nWhenthisscriptisrun,thefollowingoutputshouldbeobserved:\nCalling undecorated foo with False\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nCalling undecorated foo with True\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nabout to log at ERROR ...\nabout to log at CRITICAL ...\nCalling decorated foo with False\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nCalling decorated foo with True\nabout to log at DEBUG ...\nabout to log at INFO ...\nabout to log at WARNING ...\nabout to log at ERROR ...\nActually logged at DEBUG\nActually logged at INFO\nActually logged at WARNING\nActually logged at ERROR\nabout to log at CRITICAL ...\nActually logged at CRITICAL\nAsyoucansee,actualloggingoutputonlyoccurswhenaneventisloggedwhoseseverityisERRORorgreater,but\ninthatcase,anypreviouseventsatlowerseveritiesarealsologged.\nYoucanofcourseusetheconventionalmeansofdecoration:\n@log_if_errors(logger)\ndef foo(fail=False):\n...\n29 Sending logging messages to email, with buffering\nTo illustrate how you can send log messages via email, so that a set number of messages are sent per email, you\ncan subclass BufferingHandler. In the following example, which you can adapt to suit your specific needs, a\nsimpletestharnessisprovidedwhichallowsyoutorunthescriptwithcommandlineargumentsspecifyingwhatyou\ntypicallyneedtosendthingsviaSMTP.(Runthedownloadedscriptwiththe-hargumenttoseetherequiredand\noptionalarguments.)\n51\nimport logging\nimport logging.handlers\nimport smtplib\nclass BufferingSMTPHandler(logging.handlers.BufferingHandler):\ndef __init__(self, mailhost, port, username, password, fromaddr, toaddrs,\nsubject, capacity):\nlogging.handlers.BufferingHandler.__init__(self, capacity)\nself.mailhost = mailhost\nself.mailport = port\nself.username = username\nself.password = password\nself.fromaddr = fromaddr\nif isinstance(toaddrs, str):\ntoaddrs = [toaddrs]\nself.toaddrs = toaddrs\nself.subject = subject\nself.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)-5s\n,\u2192%(message)s\"))\ndef flush(self):\nif len(self.buffer) > 0:\ntry:\nsmtp = smtplib.SMTP(self.mailhost, self.mailport)\nsmtp.starttls()\nsmtp.login(self.username, self.password)\nmsg = \"From: %s\\r\\nTo: %s\\r\\nSubject: %s\\r\\n\\r\\n\" % (self.fromaddr,\n,\u2192 ','.join(self.toaddrs), self.subject)\nfor record in self.buffer:\ns = self.format(record)\nmsg = msg + s + \"\\r\\n\"\nsmtp.sendmail(self.fromaddr, self.toaddrs, msg)\nsmtp.quit()\nexcept Exception:\nif logging.raiseExceptions:\nraise\nself.buffer = []\nif __name__ == '__main__':\nimport argparse\nap = argparse.ArgumentParser()\naa = ap.add_argument\naa('host', metavar='HOST', help='SMTP server')\naa('--port', '-p', type=int, default=587, help='SMTP port')\naa('user', metavar='USER', help='SMTP username')\naa('password', metavar='PASSWORD', help='SMTP password')\naa('to', metavar='TO', help='Addressee for emails')\naa('sender', metavar='SENDER', help='Sender email address')\naa('--subject', '-s',\ndefault='Test Logging email from Python logging module (buffering)',\nhelp='Subject of email')\noptions = ap.parse_args()\nlogger = logging.getLogger()\nlogger.setLevel(logging.DEBUG)\nh = BufferingSMTPHandler(options.host, options.port, options.user,\noptions.password, options.sender,\n(continuesonnextpage)\n52\n(continuedfrompreviouspage)\noptions.to, options.subject, 10)\nlogger.addHandler(h)\nfor i in range(102):\nlogger.info(\"Info index = %d\", i)\nh.flush()\nh.close()\nIf you run this script and your SMTP server is correctly set up, you should find that it sends eleven emails to the\naddresseeyouspecify. Thefirsttenemailswilleachhavetenlogmessages,andtheeleventhwillhavetwomessages.\nThatmakesup102messagesasspecifiedinthescript.\n30 Formatting times using UTC (GMT) via configuration\nSometimesyouwanttoformattimesusingUTC,whichcanbedoneusingaclasssuchasUTCFormatter,shown\nbelow:\nimport logging\nimport time\nclass UTCFormatter(logging.Formatter):\nconverter = time.gmtime\nandyoucanthenusetheUTCFormatterinyourcodeinsteadofFormatter. Ifyouwanttodothatviaconfigura-\ntion,youcanusethedictConfig()APIwithanapproachillustratedbythefollowingcompleteexample:\nimport logging\nimport logging.config\nimport time\nclass UTCFormatter(logging.Formatter):\nconverter = time.gmtime\nLOGGING = {\n'version': 1,\n'disable_existing_loggers': False,\n'formatters': {\n'utc': {\n'()': UTCFormatter,\n'format': '%(asctime)s %(message)s',\n},\n'local': {\n'format': '%(asctime)s %(message)s',\n}\n},\n'handlers': {\n'console1': {\n'class': 'logging.StreamHandler',\n'formatter': 'utc',\n},\n'console2': {\n'class': 'logging.StreamHandler',\n'formatter': 'local',\n},\n},\n'root': {\n'handlers': ['console1', 'console2'],\n(continuesonnextpage)\n53\n(continuedfrompreviouspage)\n}\n}\nif __name__ == '__main__':\nlogging.config.dictConfig(LOGGING)\nlogging.warning('The local time is %s', time.asctime())\nWhenthisscriptisrun,itshouldprintsomethinglike:\n2015-10-17 12:53:29,501 The local time is Sat Oct 17 13:53:29 2015\n2015-10-17 13:53:29,501 The local time is Sat Oct 17 13:53:29 2015\nshowinghowthetimeisformattedbothaslocaltimeandUTC,oneforeachhandler.\n31 Using a context manager for selective logging\nTherearetimeswhenitwouldbeusefultotemporarilychangetheloggingconfigurationandrevertitbackafterdoing\nsomething. Forthis,acontextmanageristhemostobviouswayofsavingandrestoringtheloggingcontext. Here\nisasimpleexampleofsuchacontextmanager, whichallowsyoutooptionallychangethelogginglevelandadda\nlogginghandlerpurelyinthescopeofthecontextmanager:\nimport logging\nimport sys\nclass LoggingContext:\ndef __init__(self, logger, level=None, handler=None, close=True):\nself.logger = logger\nself.level = level\nself.handler = handler\nself.close = close\ndef __enter__(self):\nif self.level is not None:\nself.old_level = self.logger.level\nself.logger.setLevel(self.level)\nif self.handler:\nself.logger.addHandler(self.handler)\ndef __exit__(self, et, ev, tb):\nif self.level is not None:\nself.logger.setLevel(self.old_level)\nif self.handler:\nself.logger.removeHandler(self.handler)\nif self.handler and self.close:\nself.handler.close()\n# implicit return of None => don't swallow exceptions\nIfyouspecifyalevelvalue,thelogger\u2019slevelissettothatvalueinthescopeofthewithblockcoveredbythecontext\nmanager. Ifyouspecifyahandler,itisaddedtotheloggeronentrytotheblockandremovedonexitfromtheblock.\nYou can also ask the manager to close the handler for you on block exit - you could do this if you don\u2019t need the\nhandleranymore.\nToillustratehowitworks,wecanaddthefollowingblockofcodetotheabove:\nif __name__ == '__main__':\nlogger = logging.getLogger('foo')\n(continuesonnextpage)\n54\n(continuedfrompreviouspage)\nlogger.addHandler(logging.StreamHandler())\nlogger.setLevel(logging.INFO)\nlogger.info('1. This should appear just once on stderr.')\nlogger.debug('2. This should not appear.')\nwith LoggingContext(logger, level=logging.DEBUG):\nlogger.debug('3. This should appear once on stderr.')\nlogger.debug('4. This should not appear.')\nh = logging.StreamHandler(sys.stdout)\nwith LoggingContext(logger, level=logging.DEBUG, handler=h, close=True):\nlogger.debug('5. This should appear twice - once on stderr and once on\u2423\n,\u2192stdout.')\nlogger.info('6. This should appear just once on stderr.')\nlogger.debug('7. This should not appear.')\nWeinitiallysetthelogger\u2019sleveltoINFO,somessage#1appearsandmessage#2doesn\u2019t. Wethenchangethelevel\ntoDEBUGtemporarilyinthefollowingwithblock, andsomessage#3appears. Aftertheblockexits, thelogger\u2019s\nlevelisrestoredtoINFOandsomessage#4doesn\u2019tappear. Inthenextwithblock,wesettheleveltoDEBUGagain\nbutalsoaddahandlerwritingtosys.stdout. Thus,message#5appearstwiceontheconsole(onceviastderr\nandonceviastdout). Afterthewithstatement\u2019scompletion,thestatusisasitwasbeforesomessage#6appears\n(likemessage#1)whereasmessage#7doesn\u2019t(justlikemessage#2).\nIfweruntheresultingscript,theresultisasfollows:\n$ python logctx.py\n1. This should appear just once on stderr.\n3. This should appear once on stderr.\n5. This should appear twice - once on stderr and once on stdout.\n5. This should appear twice - once on stderr and once on stdout.\n6. This should appear just once on stderr.\nIf we run it again, but pipe stderr to /dev/null, we see the following, which is the only message written to\nstdout:\n$ python logctx.py 2>/dev/null\n5. This should appear twice - once on stderr and once on stdout.\nOnceagain,butpipingstdoutto/dev/null,weget:\n$ python logctx.py >/dev/null\n1. This should appear just once on stderr.\n3. This should appear once on stderr.\n5. This should appear twice - once on stderr and once on stdout.\n6. This should appear just once on stderr.\nInthiscase,themessage#5printedtostdoutdoesn\u2019tappear,asexpected.\nOfcourse,theapproachdescribedherecanbegeneralised,forexampletoattachloggingfilterstemporarily. Note\nthattheabovecodeworksinPython2aswellasPython3.\n32 A CLI application starter template\nHere\u2019sanexamplewhichshowshowyoucan:\n\u2022 Usealogginglevelbasedoncommand-linearguments\n\u2022 Dispatchtomultiplesubcommandsinseparatefiles,allloggingatthesamelevelinaconsistentway\n\u2022 Makeuseofsimple,minimalconfiguration\n55\nSuppose we have a command-line application whose job is to stop, start or restart some services. This could be\norganisedforthepurposesofillustrationasafileapp.pythatisthemainscriptfortheapplication,withindividual\ncommands implemented in start.py, stop.py and restart.py. Suppose further that we want to control the\nverbosityoftheapplicationviaacommand-lineargument,defaultingtologging.INFO.Here\u2019sonewaythatapp.\npycouldbewritten:\nimport argparse\nimport importlib\nimport logging\nimport os\nimport sys\ndef main(args=None):\nscriptname = os.path.basename(__file__)\nparser = argparse.ArgumentParser(scriptname)\nlevels = ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL')\nparser.add_argument('--log-level', default='INFO', choices=levels)\nsubparsers = parser.add_subparsers(dest='command',\nhelp='Available commands:')\nstart_cmd = subparsers.add_parser('start', help='Start a service')\nstart_cmd.add_argument('name', metavar='NAME',\nhelp='Name of service to start')\nstop_cmd = subparsers.add_parser('stop',\nhelp='Stop one or more services')\nstop_cmd.add_argument('names', metavar='NAME', nargs='+',\nhelp='Name of service to stop')\nrestart_cmd = subparsers.add_parser('restart',\nhelp='Restart one or more services')\nrestart_cmd.add_argument('names', metavar='NAME', nargs='+',\nhelp='Name of service to restart')\noptions = parser.parse_args()\n# the code to dispatch commands could all be in this file. For the purposes\n# of illustration only, we implement each command in a separate module.\ntry:\nmod = importlib.import_module(options.command)\ncmd = getattr(mod, 'command')\nexcept (ImportError, AttributeError):\nprint('Unable to find the code for command \\'%s\\'' % options.command)\nreturn 1\n# Could get fancy here and load configuration from file or dictionary\nlogging.basicConfig(level=options.log_level,\nformat='%(levelname)s %(name)s %(message)s')\ncmd(options)\nif __name__ == '__main__':\nsys.exit(main())\nAndthestart,stopandrestartcommandscanbeimplementedinseparatemodules,likesoforstarting:\n# start.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nlogger.debug('About to start %s', options.name)\n# actually do the command processing here ...\nlogger.info('Started the \\'%s\\' service.', options.name)\n56\nandthusforstopping:\n# stop.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nn = len(options.names)\nif n == 1:\nplural = ''\nservices = '\\'%s\\'' % options.names[0]\nelse:\nplural = 's'\nservices = ', '.join('\\'%s\\'' % name for name in options.names)\ni = services.rfind(', ')\nservices = services[:i] + ' and ' + services[i + 2:]\nlogger.debug('About to stop %s', services)\n# actually do the command processing here ...\nlogger.info('Stopped the %s service%s.', services, plural)\nandsimilarlyforrestarting:\n# restart.py\nimport logging\nlogger = logging.getLogger(__name__)\ndef command(options):\nn = len(options.names)\nif n == 1:\nplural = ''\nservices = '\\'%s\\'' % options.names[0]\nelse:\nplural = 's'\nservices = ', '.join('\\'%s\\'' % name for name in options.names)\ni = services.rfind(', ')\nservices = services[:i] + ' and ' + services[i + 2:]\nlogger.debug('About to restart %s', services)\n# actually do the command processing here ...\nlogger.info('Restarted the %s service%s.', services, plural)\nIfwerunthisapplicationwiththedefaultloglevel,wegetoutputlikethis:\n$ python app.py start foo\nINFO start Started the 'foo' service.\n$ python app.py stop foo bar\nINFO stop Stopped the 'foo' and 'bar' services.\n$ python app.py restart foo bar baz\nINFO restart Restarted the 'foo', 'bar' and 'baz' services.\nThefirstwordisthelogginglevel,andthesecondwordisthemoduleorpackagenameoftheplacewheretheevent\nwaslogged.\nIfwechangethelogginglevel,thenwecanchangetheinformationsenttothelog. Forexample,ifwewantmore\ninformation:\n57\n$ python app.py --log-level DEBUG start foo\nDEBUG start About to start foo\nINFO start Started the 'foo' service.\n$ python app.py --log-level DEBUG stop foo bar\nDEBUG stop About to stop 'foo' and 'bar'\nINFO stop Stopped the 'foo' and 'bar' services.\n$ python app.py --log-level DEBUG restart foo bar baz\nDEBUG restart About to restart 'foo', 'bar' and 'baz'\nINFO restart Restarted the 'foo', 'bar' and 'baz' services.\nAndifwewantless:\n$ python app.py --log-level WARNING start foo\n$ python app.py --log-level WARNING stop foo bar\n$ python app.py --log-level WARNING restart foo bar baz\nInthiscase,thecommandsdon\u2019tprintanythingtotheconsole,sincenothingatWARNINGleveloraboveisloggedby\nthem.\n33 A Qt GUI for logging\nAquestionthatcomesupfromtimetotimeisabouthowtologtoaGUIapplication. TheQtframeworkisapopular\ncross-platformUIframeworkwithPythonbindingsusingPySide2orPyQt5libraries.\nThe following example shows how to log to a Qt GUI. This introduces a simple QtHandler class which takes a\ncallable,whichshouldbeaslotinthemainthreadthatdoesGUIupdates. Aworkerthreadisalsocreatedtoshow\nhowyoucanlogtotheGUIfromboththeUIitself(viaabuttonformanuallogging)aswellasaworkerthreaddoing\nworkinthebackground(here,justloggingmessagesatrandomlevelswithrandomshortdelaysinbetween).\nTheworkerthreadisimplementedusingQt\u2019sQThreadclassratherthanthethreadingmodule,astherearecir-\ncumstanceswhereonehastouseQThread,whichoffersbetterintegrationwithotherQtcomponents.\nThe code should work with recent releases of any of PySide6, PyQt6, PySide2 or PyQt5. You should be able\ntoadapttheapproachtoearlierversionsofQt. Pleaserefertothecommentsinthecodesnippetformoredetailed\ninformation.\nimport datetime\nimport logging\nimport random\nimport sys\nimport time\n# Deal with minor differences between different Qt packages\ntry:\nfrom PySide6 import QtCore, QtGui, QtWidgets\nSignal = QtCore.Signal\nSlot = QtCore.Slot\nexcept ImportError:\ntry:\nfrom PyQt6 import QtCore, QtGui, QtWidgets\nSignal = QtCore.pyqtSignal\nSlot = QtCore.pyqtSlot\nexcept ImportError:\ntry:\nfrom PySide2 import QtCore, QtGui, QtWidgets\nSignal = QtCore.Signal\n(continuesonnextpage)\n58\n(continuedfrompreviouspage)\nSlot = QtCore.Slot\nexcept ImportError:\nfrom PyQt5 import QtCore, QtGui, QtWidgets\nSignal = QtCore.pyqtSignal\nSlot = QtCore.pyqtSlot\nlogger = logging.getLogger(__name__)\n#\n# Signals need to be contained in a QObject or subclass in order to be correctly\n# initialized.\n#\nclass Signaller(QtCore.QObject):\nsignal = Signal(str, logging.LogRecord)\n#\n# Output to a Qt GUI is only supposed to happen on the main thread. So, this\n# handler is designed to take a slot function which is set up to run in the main\n# thread. In this example, the function takes a string argument which is a\n# formatted log message, and the log record which generated it. The formatted\n# string is just a convenience - you could format a string for output any way\n# you like in the slot function itself.\n#\n# You specify the slot function to do whatever GUI updates you want. The handler\n# doesn't know or care about specific UI elements.\n#\nclass QtHandler(logging.Handler):\ndef __init__(self, slotfunc, *args, **kwargs):\nsuper().__init__(*args, **kwargs)\nself.signaller = Signaller()\nself.signaller.signal.connect(slotfunc)\ndef emit(self, record):\ns = self.format(record)\nself.signaller.signal.emit(s, record)\n#\n# This example uses QThreads, which means that the threads at the Python level\n# are named something like \"Dummy-1\". The function below gets the Qt name of the\n# current thread.\n#\ndef ctname():\nreturn QtCore.QThread.currentThread().objectName()\n#\n# Used to generate random levels for logging.\n#\nLEVELS = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,\nlogging.CRITICAL)\n#\n# This worker class represents work that is done in a thread separate to the\n# main thread. The way the thread is kicked off to do work is via a button press\n# that connects to a slot in the worker.\n(continuesonnextpage)\n59\n(continuedfrompreviouspage)\n#\n# Because the default threadName value in the LogRecord isn't much use, we add\n# a qThreadName which contains the QThread name as computed above, and pass that\n# value in an \"extra\" dictionary which is used to update the LogRecord with the\n# QThread name.\n#\n# This example worker just outputs messages sequentially, interspersed with\n# random delays of the order of a few seconds.\n#\nclass Worker(QtCore.QObject):\n@Slot()\ndef start(self):\nextra = {'qThreadName': ctname() }\nlogger.debug('Started work', extra=extra)\ni = 1\n# Let the thread run until interrupted. This allows reasonably clean\n# thread termination.\nwhile not QtCore.QThread.currentThread().isInterruptionRequested():\ndelay = 0.5 + random.random() * 2\ntime.sleep(delay)\ntry:\nif random.random() < 0.1:\nraise ValueError('Exception raised: %d' % i)\nelse:\nlevel = random.choice(LEVELS)\nlogger.log(level, 'Message after delay of %3.1f: %d', delay, i,\n,\u2192 extra=extra)\nexcept ValueError as e:\nlogger.exception('Failed: %s', e, extra=extra)\ni += 1\n#\n# Implement a simple UI for this cookbook example. This contains:\n#\n# * A read-only text edit window which holds formatted log messages\n# * A button to start work and log stuff in a separate thread\n# * A button to log something from the main thread\n# * A button to clear the log window\n#\nclass Window(QtWidgets.QWidget):\nCOLORS = {\nlogging.DEBUG: 'black',\nlogging.INFO: 'blue',\nlogging.WARNING: 'orange',\nlogging.ERROR: 'red',\nlogging.CRITICAL: 'purple',\n}\ndef __init__(self, app):\nsuper().__init__()\nself.app = app\nself.textedit = te = QtWidgets.QPlainTextEdit(self)\n# Set whatever the default monospace font is for the platform\nf = QtGui.QFont('nosuchfont')\nif hasattr(f, 'Monospace'):\n(continuesonnextpage)\n60\n(continuedfrompreviouspage)\nf.setStyleHint(f.Monospace)\nelse:\nf.setStyleHint(f.StyleHint.Monospace) # for Qt6\nte.setFont(f)\nte.setReadOnly(True)\nPB = QtWidgets.QPushButton\nself.work_button = PB('Start background work', self)\nself.log_button = PB('Log a message at a random level', self)\nself.clear_button = PB('Clear log window', self)\nself.handler = h = QtHandler(self.update_status)\n# Remember to use qThreadName rather than threadName in the format string.\nfs = '%(asctime)s %(qThreadName)-12s %(levelname)-8s %(message)s'\nformatter = logging.Formatter(fs)\nh.setFormatter(formatter)\nlogger.addHandler(h)\n# Set up to terminate the QThread when we exit\napp.aboutToQuit.connect(self.force_quit)\n# Lay out all the widgets\nlayout = QtWidgets.QVBoxLayout(self)\nlayout.addWidget(te)\nlayout.addWidget(self.work_button)\nlayout.addWidget(self.log_button)\nlayout.addWidget(self.clear_button)\nself.setFixedSize(900, 400)\n# Connect the non-worker slots and signals\nself.log_button.clicked.connect(self.manual_update)\nself.clear_button.clicked.connect(self.clear_display)\n# Start a new worker thread and connect the slots for the worker\nself.start_thread()\nself.work_button.clicked.connect(self.worker.start)\n# Once started, the button should be disabled\nself.work_button.clicked.connect(lambda : self.work_button.\n,\u2192setEnabled(False))\ndef start_thread(self):\nself.worker = Worker()\nself.worker_thread = QtCore.QThread()\nself.worker.setObjectName('Worker')\nself.worker_thread.setObjectName('WorkerThread') # for qThreadName\nself.worker.moveToThread(self.worker_thread)\n# This will start an event loop in the worker thread\nself.worker_thread.start()\ndef kill_thread(self):\n# Just tell the worker to stop, then tell it to quit and wait for that\n# to happen\nself.worker_thread.requestInterruption()\nif self.worker_thread.isRunning():\nself.worker_thread.quit()\nself.worker_thread.wait()\nelse:\nprint('worker has already exited.')\n(continuesonnextpage)\n61\n(continuedfrompreviouspage)\ndef force_quit(self):\n# For use when the window is closed\nif self.worker_thread.isRunning():\nself.kill_thread()\n# The functions below update the UI and run in the main thread because\n# that's where the slots are set up\n@Slot(str, logging.LogRecord)\ndef update_status(self, status, record):\ncolor = self.COLORS.get(record.levelno, 'black')\ns = '<pre><font color=\"%s\">%s</font></pre>' % (color, status)\nself.textedit.appendHtml(s)\n@Slot()\ndef manual_update(self):\n# This function uses the formatted message passed in, but also uses\n# information from the record to format the message in an appropriate\n# color according to its severity (level).\nlevel = random.choice(LEVELS)\nextra = {'qThreadName': ctname() }\nlogger.log(level, 'Manually logged!', extra=extra)\n@Slot()\ndef clear_display(self):\nself.textedit.clear()\ndef main():\nQtCore.QThread.currentThread().setObjectName('MainThread')\nlogging.getLogger().setLevel(logging.DEBUG)\napp = QtWidgets.QApplication(sys.argv)\nexample = Window(app)\nexample.show()\nif hasattr(app, 'exec'):\nrc = app.exec()\nelse:\nrc = app.exec_()\nsys.exit(rc)\nif __name__=='__main__':\nmain()\n34 Logging to syslog with RFC5424 support\nAlthough RFC 5424 dates from 2009, most syslog servers are configured by default to use the older RFC 3164,\nwhichhailsfrom2001. WhenloggingwasaddedtoPythonin2003, itsupportedtheearlier(andonlyexisting)\nprotocolatthetime. SinceRFC5424cameout,astherehasnotbeenwidespreaddeploymentofitinsyslogservers,\ntheSysLogHandlerfunctionalityhasnotbeenupdated.\nRFC5424containssomeusefulfeaturessuchassupportforstructureddata,andifyouneedtobeabletologtoa\nsyslogserverwithsupportforit,youcandosowithasubclassedhandlerwhichlookssomethinglikethis:\nimport datetime\nimport logging.handlers\nimport re\n(continuesonnextpage)\n62\n(continuedfrompreviouspage)\nimport socket\nimport time\nclass SysLogHandler5424(logging.handlers.SysLogHandler):\ntz_offset = re.compile(r'([+-]\\d{2})(\\d{2})$')\nescaped = re.compile(r'([\\]\"\\\\])')\ndef __init__(self, *args, **kwargs):\nself.msgid = kwargs.pop('msgid', None)\nself.appname = kwargs.pop('appname', None)\nsuper().__init__(*args, **kwargs)\ndef format(self, record):\nversion = 1\nasctime = datetime.datetime.fromtimestamp(record.created).isoformat()\nm = self.tz_offset.match(time.strftime('%z'))\nhas_offset = False\nif m and time.timezone:\nhrs, mins = m.groups()\nif int(hrs) or int(mins):\nhas_offset = True\nif not has_offset:\nasctime += 'Z'\nelse:\nasctime += f'{hrs}:{mins}'\ntry:\nhostname = socket.gethostname()\nexcept Exception:\nhostname = '-'\nappname = self.appname or '-'\nprocid = record.process\nmsgid = '-'\nmsg = super().format(record)\nsdata = '-'\nif hasattr(record, 'structured_data'):\nsd = record.structured_data\n# This should be a dict where the keys are SD-ID and the value is a\n# dict mapping PARAM-NAME to PARAM-VALUE (refer to the RFC for what\u2423\n,\u2192these\n# mean)\n# There's no error checking here - it's purely for illustration, and\u2423\n,\u2192you\n# can adapt this code for use in production environments\nparts = []\ndef replacer(m):\ng = m.groups()\nreturn '\\\\' + g[0]\nfor sdid, dv in sd.items():\npart = f'[{sdid}'\nfor k, v in dv.items():\ns = str(v)\ns = self.escaped.sub(replacer, s)\npart += f' {k}=\"{s}\"'\n(continuesonnextpage)\n63\n(continuedfrompreviouspage)\npart += ']'\nparts.append(part)\nsdata = ''.join(parts)\nreturn f'{version} {asctime} {hostname} {appname} {procid} {msgid} {sdata}\n,\u2192{msg}'\nYou\u2019llneedtobefamiliarwithRFC5424tofullyunderstandtheabovecode,anditmaybethatyouhaveslightly\ndifferentneeds(e.g. forhowyoupassstructuraldatatothelog). Nevertheless,theaboveshouldbeadaptabletoyour\nspeciricneeds. Withtheabovehandler,you\u2019dpassstructureddatausingsomethinglikethis:\nsd = {\n'foo@12345': {'bar': 'baz', 'baz': 'bozz', 'fizz': r'buzz'},\n'foo@54321': {'rab': 'baz', 'zab': 'bozz', 'zzif': r'buzz'}\n}\nextra = {'structured_data': sd}\ni = 1\nlogger.debug('Message %d', i, extra=extra)\n35 How to treat a logger like an output stream\nSometimes, youneedtointerfacetoathird-partyAPIwhichexpectsafile-likeobjecttowriteto, butyouwantto\ndirecttheAPI\u2019soutputtoalogger. Youcandothisusingaclasswhichwrapsaloggerwithafile-likeAPI.Here\u2019sa\nshortscriptillustratingsuchaclass:\nimport logging\nclass LoggerWriter:\ndef __init__(self, logger, level):\nself.logger = logger\nself.level = level\ndef write(self, message):\nif message != '\\n': # avoid printing bare newlines, if you like\nself.logger.log(self.level, message)\ndef flush(self):\n# doesn't actually do anything, but might be expected of a file-like\n# object - so optional depending on your situation\npass\ndef close(self):\n# doesn't actually do anything, but might be expected of a file-like\n# object - so optional depending on your situation. You might want\n# to set a flag so that later calls to write raise an exception\npass\ndef main():\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger('demo')\ninfo_fp = LoggerWriter(logger, logging.INFO)\ndebug_fp = LoggerWriter(logger, logging.DEBUG)\nprint('An INFO message', file=info_fp)\nprint('A DEBUG message', file=debug_fp)\nif __name__ == \"__main__\":\nmain()\n64\nWhenthisscriptisrun,itprints\nINFO:demo:An INFO message\nDEBUG:demo:A DEBUG message\nYoucouldalsouseLoggerWritertoredirectsys.stdoutandsys.stderrbydoingsomethinglikethis:\nimport sys\nsys.stdout = LoggerWriter(logger, logging.INFO)\nsys.stderr = LoggerWriter(logger, logging.WARNING)\nYoushoulddothisafter configuringloggingforyourneeds. Intheaboveexample,thebasicConfig()calldoes\nthis(usingthesys.stderrvaluebeforeitisoverwrittenbyaLoggerWriterinstance). Then,you\u2019dgetthiskind\nofresult:\n>>> print('Foo')\nINFO:demo:Foo\n>>> print('Bar', file=sys.stderr)\nWARNING:demo:Bar\n>>>\nOf course, the examples above show output according to the format used by basicConfig(), butyou can use a\ndifferentformatterwhenyouconfigurelogging.\nNotethatwiththeabovescheme,youaresomewhatatthemercyofbufferingandthesequenceofwritecallswhich\nyouareintercepting. Forexample,withthedefinitionofLoggerWriterabove,ifyouhavethesnippet\nsys.stderr = LoggerWriter(logger, logging.WARNING)\n1 / 0\nthenrunningthescriptresultsin\nWARNING:demo:Traceback (most recent call last):\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/test.py\", line 53, in\n,\u2192<module>\nWARNING:demo:\nWARNING:demo:main()\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/test.py\", line 49, in main\nWARNING:demo:\nWARNING:demo:1 / 0\nWARNING:demo:ZeroDivisionError\nWARNING:demo::\nWARNING:demo:division by zero\nAs you can see, this output isn\u2019t ideal. That\u2019s because the underlying code which writes to sys.stderr makes\nmultiple writes, each of which results in a separate logged line (for example, the last three lines above). To get\naroundthisproblem,youneedtobufferthingsandonlyoutputloglineswhennewlinesareseen. Let\u2019suseaslightly\nbetterimplementationofLoggerWriter:\nclass BufferingLoggerWriter(LoggerWriter):\ndef __init__(self, logger, level):\nsuper().__init__(logger, level)\nself.buffer = ''\ndef write(self, message):\n(continuesonnextpage)\n65\n(continuedfrompreviouspage)\nif '\\n' not in message:\nself.buffer += message\nelse:\nparts = message.split('\\n')\nif self.buffer:\ns = self.buffer + parts.pop(0)\nself.logger.log(self.level, s)\nself.buffer = parts.pop()\nfor part in parts:\nself.logger.log(self.level, part)\nThis just buffers up stuff until a newline is seen, and then logs complete lines. With this approach, you get better\noutput:\nWARNING:demo:Traceback (most recent call last):\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/main.py\", line 55, in\n,\u2192<module>\nWARNING:demo: main()\nWARNING:demo: File \"/home/runner/cookbook-loggerwriter/main.py\", line 52, in main\nWARNING:demo: 1/0\nWARNING:demo:ZeroDivisionError: division by zero\n36 Patterns to avoid\nAlthoughtheprecedingsectionshavedescribedwaysofdoingthingsyoumightneedtodoordealwith,itisworth\nmentioning some usage patterns which are unhelpful, and which should therefore be avoided in most cases. The\nfollowingsectionsareinnoparticularorder.\n36.1 Opening the same log file multiple times\nOnWindows,youwillgenerallynotbeabletoopenthesamefilemultipletimesasthiswillleadtoa\u201cfileisinuse\nbyanotherprocess\u201derror. However,onPOSIXplatformsyou\u2019llnotgetanyerrorsifyouopenthesamefilemultiple\ntimes. Thiscouldbedoneaccidentally,forexampleby:\n\u2022 Adding a file handler more than once which references the same file (e.g. by a copy/paste/forget-to-change\nerror).\n\u2022 Openingtwofilesthatlookdifferent,astheyhavedifferentnames,butarethesamebecauseoneisasymbolic\nlinktotheother.\n\u2022 Forking a process, following which both parent and child have a reference to the same file. This might be\nthroughuseofthemultiprocessingmodule,forexample.\nOpeningafilemultipletimesmightappeartoworkmostofthetime,butcanleadtoanumberofproblemsinpractice:\n\u2022 Loggingoutputcanbegarbledbecausemultiplethreadsorprocessestrytowritetothesamefile. Although\nloggingguardsagainstconcurrentuseofthesamehandlerinstancebymultiplethreads,thereisnosuchpro-\ntectionifconcurrentwritesareattemptedbytwodifferentthreadsusingtwodifferenthandlerinstanceswhich\nhappentopointtothesamefile.\n\u2022 Anattempttodeleteafile(e.g. duringfilerotation)silentlyfails,becausethereisanotherreferencepointingto\nit. Thiscanleadtoconfusionandwasteddebuggingtime-logentriesendupinunexpectedplaces,orarelost\naltogether. Orafilethatwassupposedtobemovedremainsinplace,andgrowsinsizeunexpectedlydespite\nsize-basedrotationbeingsupposedlyinplace.\nUsethetechniquesoutlinedinLoggingtoasinglefilefrommultipleprocessestocircumventsuchissues.\n66\n36.2 Using loggers as attributes in a class or passing them as parameters\nWhile there might be unusual cases where you\u2019ll need to do this, in general there is no point because loggers are\nsingletons. Codecanalwaysaccessagivenloggerinstancebynameusinglogging.getLogger(name),sopassing\ninstancesaroundandholdingthemasinstanceattributesispointless. NotethatinotherlanguagessuchasJavaand\nC#,loggersareoftenstaticclassattributes. However,thispatterndoesn\u2019tmakesenseinPython,wherethemodule\n(andnottheclass)istheunitofsoftwaredecomposition.\n36.3 Adding handlers other than NullHandler to a logger in a library\nConfiguringloggingbyaddinghandlers,formattersandfiltersistheresponsibilityoftheapplicationdeveloper,not\nthelibrarydeveloper. Ifyouaremaintainingalibrary,ensurethatyoudon\u2019taddhandlerstoanyofyourloggersother\nthanaNullHandlerinstance.\n36.4 Creating a lot of loggers\nLoggers are singletons that are never freed during a script execution, and so creating lots of loggers will use up\nmemorywhichcan\u2019tthenbefreed. Ratherthancreatealoggerpere.g. fileprocessedornetworkconnectionmade,\nusetheexistingmechanismsforpassingcontextualinformationintoyourlogsandrestricttheloggerscreatedtothose\ndescribingareaswithinyourapplication(generallymodules,butoccasionallyslightlymorefine-grainedthanthat).\n37 Other resources\n(cid:181) Seealso\nModulelogging\nAPIreferencefortheloggingmodule.\nModulelogging.config\nConfigurationAPIfortheloggingmodule.\nModulelogging.handlers\nUsefulhandlersincludedwiththeloggingmodule.\nBasicTutorial\nAdvancedTutorial\n67\nIndex\nR\nRFC\nRFC 3164,62\nRFC 5424,41,62\nRFC 5424 Section 6,41\n68\n",
  "context": "20 Amoreelaboratemultiprocessingexample 37\n21 InsertingaBOMintomessagessenttoaSysLogHandler 41\n22 Implementingstructuredlogging 41",
  "source_file": "resources\\Year 3\\Python\\howto-logging-cookbook.pdf",
  "line_numbers": [
    40,
    3258
  ]
}