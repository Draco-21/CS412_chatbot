{
  "title": "Data Structures and Algorithms in Java, 6th Edition",
  "language": "cpp",
  "topics": [
    "machine_learning",
    "web_dev",
    "fundamentals",
    "algorithms",
    "data_structures",
    "networking",
    "database"
  ],
  "purpose": "Drive, Danvers, MA 01923, website www.copyright.com.",
  "code": "http://www.wiley.com/go/permissions.\nEvaluation copies are provided to qualified academics and professionals for review pur-\nposesonly,foruseintheircoursesduringthenextacademicyear.Thesecopiesarelicensed\nandmaynotbesoldortransferredtoathirdparty. Uponcompletionofthereviewperiod,\npleasereturntheevaluationcopytoWiley. Returninstructionsandafreeofchargereturn\nmailinglabelareavailableatwww.wiley.com/go/returnlabel. Ifyouhavechosentoadopt\nthistextbookforuse inyourcourse,pleaseacceptthisbookasyourcomplimentarydesk\ncopy.OutsideoftheUnitedStates,pleasecontactyourlocalsalesrepresentative.\nISBN: 978-1-118-77133-4(paperback)\nPrintedintheUnitedStatesofAmerica\n10987654321\nwww.it-ebooks.info\nTo Karen, Paul,Anna, and Jack\n\u2013 MichaelT.Goodrich\nTo Isabel\n\u2013 RobertoTamassia\nTo Susan, Calista,and Maya\n\u2013 MichaelH.Goldwasser\nwww.it-ebooks.info\nwww.it-ebooks.info\nPreface to the Sixth Edition\nDataStructures andAlgorithmsinJavaprovides anintroduction todatastructures\nand algorithms, including their design, analysis, and implementation. The major\nchanges inthissixtheditionincludethefollowing:\nWe redesigned the entire code base to increase clarity of presentation and\n\u2022\nconsistency instyle andconvention, including reliance ontype inference, as\nintroduced inJava7,toreduceclutterwheninstantiating generictypes.\nWeadded38newfigures,andredesigned 144existingfigures.\n\u2022\nWerevisedandexpandedexercises,bringingthegrandtotalto794exercises!\n\u2022\nWe continue our approach of dividing them into reinforcement, creativity,\nand project exercises. However, we have chosen not to reset the number-\ning scheme with each new category, thereby avoiding possible ambiguity\nbetweenexercisessuchasR-7.5,C-7.5,P-7.5.\nTheintroductory chapters containadditional examplesofclassesandinheri-\n\u2022\ntance,increaseddiscussionofJava\u2019sgenericsframework,andexpandedcov-\nerageofcloning andequivalence testinginthecontextofdatastructures.\nA new chapter, dedicated to the topic of recursion, provides comprehensive\n\u2022\ncoverage of material that was previously divided within Chapters 3, 4, and\n9 of the fifth edition, while newly introducing the use of recursion when\nprocessing filesystems.\nWe provide a new empirical study of the efficiency of Java\u2019s StringBuilder\n\u2022\nclass relative to the repeated concatenation of strings, and then discuss the\ntheoretical underpinnings ofitsamortizedperformance.\nWe provide increased discussion of iterators, contrasting between so-called\n\u2022\nlazy iterators andsnapshot iterators, withexamples ofboth styles ofimple-\nmentation forseveraldatastructures.\nWe have increased the use of abstract base classes to reduce redundancy\n\u2022\nwhen providing multiple implementations of a common interface, and the\nuseofnestedclassestoprovidegreaterencapsulation forourdatastructures.\nWe have included complete Java implementations for many data structures\n\u2022\nandalgorithmsthatwereonlydescribed withpseudocode inearliereditions.\nThese new implementations include both array-based and linked-list-based\nqueueimplementations, aheap-based adaptable priorityqueue, abottom-up\nheapconstruction,hashtableswitheitherseparatechainingorlinearprobing,\nsplay trees, dynamic programming fortheleast-common subsequence prob-\nlem, a union-find data structure with path compression, breadth-first search\nof a graph, the Floyd-Warshall algorithm for computing a graph\u2019s transitive\nclosure, topological sortingofaDAG,andboththePrim-Jarn\u00b4\u0131kandKruskal\nalgorithms forcomputingaminimumspanning tree.\nv\nwww.it-ebooks.info\nvi Preface\nPrerequisites\nWe assume that the reader is at least vaguely familiar with a high-level program-\nminglanguage,suchasC,C++,Python,orJava,andthatheorsheunderstands the\nmainconstructs fromsuchahigh-level language, including:\nVariablesandexpressions\n\u2022\nMethods(alsoknownasfunctions orprocedures)\n\u2022\nDecisionstructures (suchasif-statements andswitch-statements)\n\u2022\nIteration structures (for-loops andwhile-loops)\n\u2022\nFor readers who are familiar with these concepts, but not with how they are ex-\npressed in Java, weprovide a primer on the Java language in Chapter 1. Still, this\nbookisprimarilyadatastructuresbook,notaJavabook;hence,itdoesnotprovide\nacomprehensive treatmentofJava. Nevertheless, wedonotassumethatthereader\nis necessarily familiar with object-oriented design or with linked structures, such\naslinked lists,forthesetopicsarecoveredinthecorechaptersofthisbook.\nIntermsofmathematicalbackground,weassumethereaderissomewhatfamil-\niar with topics from high-school mathematics. Even so, in Chapter 4, we discuss\nthesevenmost-importantfunctionsforalgorithmanalysis. Infact,sectionsthatuse\nsomething otherthanoneofthesesevenfunctions areconsidered optional, andare\n\u22c6\nindicated withastar( ).\nOnline Resources\nThis book is accompanied by an extensive set of online resources, which can be\nfoundatthefollowingwebsite:\nwww.wiley.com/college/goodrich\nIncluded onthiswebsiteisacollection ofeducational aidsthataugmentthetopics\nof this book, for both students and instructors. For all readers, and especially for\nstudents, weinclude thefollowingresources:\nAllJavasourcecodepresented inthisbook\n\u2022\nAnappendix ofusefulmathematical facts\n\u2022\nPDFhandouts ofPowerPointslides(four-per-page)\n\u2022\nAstudyguidewithhintstoexercises, indexedbyproblem number\n\u2022\nForinstructors usingthisbook,weincludethefollowingadditional teachingaids:\nSolutions tohundreds ofthebook\u2019sexercises\n\u2022\nColorversionsofallfiguresandillustrations fromthebook\n\u2022\nSlidesinPowerPointandPDF(one-per-page) format\n\u2022\nThe slides are fully editable, so as to allow an instructor using this book full free-\ndomincustomizing hisorherpresentations.\nwww.it-ebooks.info\nPreface vii\nUse as a Textbook\nThe design and analysis of efficient data structures has long been recognized as a\ncoresubjectincomputing. Wefeelthatthecentralroleofdatastructuredesignand\nanalysis in the curriculum is fully justified, given the importance of efficient data\nstructures and algorithms in most software systems, including the Web, operating\nsystems,databases, compilers, andscientificsimulation systems.\nThis book is designed for use in a beginning-level data structures course, or\nin an intermediate-level introduction to algorithms course. The chapters for this\nbookareorganized toprovideapedagogical paththatstartswiththebasicsofJava\nprogramming and object-oriented design. We then discuss concrete structures in-\ncludingarraysandlinkedlists,andfoundational techniques likealgorithmanalysis\nand recursion. Inthe mainportion ofthe book wepresent fundamental data struc-\ntures and algorithms, concluding with a discussion of memory management. A\ndetailed tableofcontents followsthispreface, beginning onpagex.\nTo assist instructors in designing a course in the context of the IEEE/ACM\n2013 Computing Curriculum, the following table describes curricular knowledge\nunitsthatarecoveredwithinthisbook.\nKnowledgeUnit RelevantMaterial\nAL/BasicAnalysis Chapter4andSections5.2&12.1.4\nSections 5.3.3, 12.1.1, 13.2.1, 13.4.2, 13.5,\nAL/AlgorithmicStrategies\n14.6.2&14.7\nAL/Fundamental Data Structures Sections 3.1.2, 5.1.3, 9.3, 9.4.1, 10.2, 11.1,\nandAlgorithms 13.2,andChapters12&14\nSections7.2.1,10.4,11.2\u201311.6,12.2.1,13.3,\nAL/AdvancedDataStructures\n14.5.1&15.3\nAR/MemorySystemOrganization\nChapter15\nandArchitecture\nDS/Sets,Relations,andFunctions Sections9.2.2&10.5\nDS/ProofTechniques Sections4.4,5.2,7.2.3,9.3.4&12.3.1\nDS/BasicsofCounting Sections2.2.3,6.2.2,8.2.2&12.1.4.\nDS/GraphsandTrees Chapters8and14\nDS/DiscreteProbability Sections3.1.3,10.2,10.4.2&12.2.1\nPL/Object-OrientedProgramming Chapter2andSections7.3,9.5.1&11.2.1\nSDF/AlgorithmsandDesign Sections2.1,4.3&12.1.1\nSDF/FundamentalProgramming\nChapters1&5\nConcepts\nSDF/FundamentalDataStructures Chapters3&6,andSections1.3,9.1&10.1\nSDF/DevelopmentalMethods Sections1.9&2.4\nSE/SoftwareDesign Section2.1\nMappingtheIEEE/ACM2013ComputingCurriculumknowledgeunitstocoverage\nwithinthisbook.\nwww.it-ebooks.info\nviii Preface\nAbout the Authors\nMichaelGoodrichreceivedhisPh.D.inComputerSciencefromPurdueUniversity\nin 1987. He is currently a Chancellor\u2019s Professor in the Department of Computer\nScienceatUniversityofCalifornia, Irvine. Previously, hewasaprofessor atJohns\nHopkins University. He is a Fulbright Scholar and a Fellow of the American As-\nsociation for the Advancement of Science (AAAS), Association for Computing\nMachinery (ACM), and Institute of Electrical and Electronics Engineers (IEEE).\nHe is a recipient of the IEEE Computer Society Technical Achievement Award,\nthe ACM Recognition of Service Award, and the Pond Award for Excellence in\nUndergraduate Teaching.\nRoberto Tamassia received his Ph.D. in Electrical and Computer Engineering\nfrom the University of Illinois at Urbana\u2013Champaign in 1988. He is the Plastech\nProfessor ofComputer Science andtheChairoftheDepartment ofComputer Sci-\nenceatBrownUniversity. HeisalsotheDirectorofBrown\u2019sCenterforGeometric\nComputing. Hisresearchinterestsincludeinformationsecurity,cryptography,anal-\nysis,design, andimplementation ofalgorithms, graphdrawing,andcomputational\ngeometry. He is a Fellow of the American Association for the Advancement of\nScience (AAAS), Association for Computing Machinery (ACM) and Institute for\nElectricalandElectronicEngineers(IEEE).HeisarecipientoftheIEEEComputer\nSocietyTechnicalAchievementAward.\nMichael Goldwasser received his Ph.D. in Computer Science from Stanford\nUniversityin1997. HeiscurrentlyProfessorandDirectoroftheComputerScience\nprogram in the Department of Mathematics and Computer Science at Saint Louis\nUniversity. He was previously a faculty member in the Department of Computer\nScience at Loyola University Chicago. His research interests focus on the design\nandimplementationofalgorithms,havingpublishedworkinvolvingapproximation\nalgorithms, online computation, computational biology, and computational geom-\netry. Heisalsoactiveinthecomputerscienceeducation community.\nAdditional Books by These Authors\nDiBattista,Eades,Tamassia,andTollis,GraphDrawing,PrenticeHall\n\u2022\nGoodrich,Tamassia,andGoldwasser,DataStructuresandAlgorithmsinPython,\n\u2022\nWiley\nGoodrich,Tamassia,andMount,DataStructuresandAlgorithmsinC++,Wiley\n\u2022\nGoodrich and Tamassia, Algorithm Design: Foundations, Analysis, andInternet\n\u2022\nExamples,Wiley\nGoodrichandTamassia,Introduction toComputerSecurity, Addison-Wesley\n\u2022\nGoldwasser and Letscher, Object-Oriented Programming in Python, Prentice\n\u2022\nHall\nwww.it-ebooks.info\nPreface ix\nAcknowledgments\nTherearesomanyindividuals whohavemadecontributions tothedevelopmentof\nthis book over the past decade, it is difficult to name them all. We wish to reit-\nerate our thanks to the many research collaborators and teaching assistants whose\nfeedback shaped the previous versions of this material. The benefits of those con-\ntributions carryforwardtothisbook.\nFor the sixth edition, we are indebted to the outside reviewers and readers for\ntheircopiouscomments,emails,andconstructivecriticisms. Wethereforethankthe\nfollowingpeoplefortheircommentsandsuggestions: SameerO.Abufardeh(North\nDakota State University), Mary Boelk (Marquette University), Frederick Crabbe\n(UnitedStatesNavalAcademy),ScotDrysdale(DartmouthCollege),DavidEisner,\nHenry A. Etlinger (Rochester Institute of Technology), Chun-Hsi Huang (Univer-\nsity ofConnecticut), John Lasseter (Hobart and William Smith Colleges), Yupeng\nLin, Suely Oliveira (University of Iowa), Vincent van Oostrom (Utrecht Univer-\nsity), Justus Piater(University ofInnsbruck), VictorI.Shtern(Boston University),\nTimSoethout, andanumberofadditional anonymous reviewers.\nTherehavebeenanumberoffriendsandcolleagueswhosecommentshaveled\ntoimprovementsinthetext. Weareparticularly thankful toErinChambers,Karen\nGoodrich, David Letscher, David Mount, and Ioannis Tollis for their insightful\ncomments. Inaddition, contributions byDavidMounttothecoverageofrecursion\nandtoseveralfiguresaregratefully acknowledged.\nWe appreciate the wonderful team at Wiley, including our editor, Beth Lang\nGolub, for her enthusiastic support of this project from beginning to end, and the\nProductSolutionsGroupeditors,MaryO\u2019SullivanandEllenKeohane,forcarrying\ntheprojecttoitscompletion. Thequalityofthisbookisgreatlyenhancedasaresult\noftheattention todetail demonstrated byourcopyeditor, JulieKennedy. Thefinal\nmonthsoftheproduction process weregracefully managedbyJoycePoh.\nFinally, we would like to warmly thank Karen Goodrich, Isabel Cruz, Susan\nGoldwasser,GiuseppeDiBattista,FrancoPreparata,IoannisTollis,andourparents\nfor providing advice, encouragement, and support at various stages of the prepa-\nration of this book, and Calista and Maya Goldwasser for offering their advice\nregarding the artistic merits of many illustrations. More importantly, we thank all\nofthesepeopleforremindingusthattherearethingsinlifebeyondwritingbooks.\nMichaelT.Goodrich\nRobertoTamassia\nMichaelH.Goldwasser\nwww.it-ebooks.info\nContents\n1 Java Primer 1\n1.1 Getting Started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.1.1 Base Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.2 Classes and Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.1 Creating and Using Objects . . . . . . . . . . . . . . . . . . . . 6\n1.2.2 Defining a Class . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.3 Strings, Wrappers, Arrays, and Enum Types . . . . . . . . . . . . . 17\n1.4 Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n1.4.1 Literals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n1.4.2 Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n1.4.3 Type Conversions . . . . . . . . . . . . . . . . . . . . . . . . . 28\n1.5 Control Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n1.5.1 The If and Switch Statements . . . . . . . . . . . . . . . . . . 30\n1.5.2 Loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n1.5.3 Explicit Control-Flow Statements . . . . . . . . . . . . . . . . . 37\n1.6 Simple Input and Output . . . . . . . . . . . . . . . . . . . . . . . . 38\n1.7 An Example Program . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n1.8 Packages and Imports . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n1.9 Software Development . . . . . . . . . . . . . . . . . . . . . . . . . 46\n1.9.1 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n1.9.2 Pseudocode . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n1.9.3 Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n1.9.4 Documentation and Style . . . . . . . . . . . . . . . . . . . . . 50\n1.9.5 Testing and Debugging . . . . . . . . . . . . . . . . . . . . . . 53\n1.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n2 Object-Oriented Design 59\n2.1 Goals, Principles, and Patterns . . . . . . . . . . . . . . . . . . . . 60\n2.1.1 Object-Oriented Design Goals . . . . . . . . . . . . . . . . . . 60\n2.1.2 Object-Oriented Design Principles . . . . . . . . . . . . . . . . 61\n2.1.3 Design Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n2.2 Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n2.2.1 Extending the CreditCard Class . . . . . . . . . . . . . . . . . . 65\n2.2.2 Polymorphism and Dynamic Dispatch . . . . . . . . . . . . . . 68\n2.2.3 Inheritance Hierarchies . . . . . . . . . . . . . . . . . . . . . . 69\n2.3 Interfaces and Abstract Classes . . . . . . . . . . . . . . . . . . . . 76\n2.3.1 Interfaces in Java . . . . . . . . . . . . . . . . . . . . . . . . . 76\n2.3.2 Multiple Inheritance for Interfaces . . . . . . . . . . . . . . . . 79\n2.3.3 Abstract Classes . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n2.4 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n2.4.1 Catching Exceptions. . . . . . . . . . . . . . . . . . . . . . . . 82\n2.4.2 Throwing Exceptions . . . . . . . . . . . . . . . . . . . . . . . 85\n2.4.3 Java\u2019s Exception Hierarchy . . . . . . . . . . . . . . . . . . . . 86\n2.5 Casting and Generics . . . . . . . . . . . . . . . . . . . . . . . . . . 88\nx\nwww.it-ebooks.info\nContents xi\n2.5.1 Casting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n2.5.2 Generics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\n2.6 Nested Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n2.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n3 Fundamental Data Structures 103\n3.1 Using Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n3.1.1 Storing Game Entries in an Array . . . . . . . . . . . . . . . . . 104\n3.1.2 Sorting an Array . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n3.1.3 java.util Methods for Arrays and Random Numbers . . . . . . . 112\n3.1.4 Simple Cryptography with Character Arrays . . . . . . . . . . . 115\n3.1.5 Two-DimensionalArrays and Positional Games . . . . . . . . . 118\n3.2 Singly Linked Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n3.2.1 Implementing a Singly Linked List Class . . . . . . . . . . . . . 126\n3.3 Circularly Linked Lists . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n3.3.1 Round-Robin Scheduling . . . . . . . . . . . . . . . . . . . . . 128\n3.3.2 Designing and Implementing a Circularly Linked List . . . . . . 129\n3.4 Doubly Linked Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n3.4.1 Implementing a Doubly Linked List Class . . . . . . . . . . . . 135\n3.5 Equivalence Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n3.5.1 Equivalence Testing with Arrays . . . . . . . . . . . . . . . . . 139\n3.5.2 Equivalence Testing with Linked Lists . . . . . . . . . . . . . . 140\n3.6 Cloning Data Structures . . . . . . . . . . . . . . . . . . . . . . . . 141\n3.6.1 Cloning Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . 142\n3.6.2 Cloning Linked Lists . . . . . . . . . . . . . . . . . . . . . . . . 144\n3.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\n4 Algorithm Analysis 149\n4.1 Experimental Studies . . . . . . . . . . . . . . . . . . . . . . . . . . 151\n4.1.1 Moving Beyond Experimental Analysis . . . . . . . . . . . . . . 154\n4.2 The Seven Functions Used in This Book . . . . . . . . . . . . . . . 156\n4.2.1 Comparing Growth Rates . . . . . . . . . . . . . . . . . . . . . 163\n4.3 Asymptotic Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n4.3.1 The \u201cBig-Oh\u201d Notation . . . . . . . . . . . . . . . . . . . . . . 164\n4.3.2 Comparative Analysis . . . . . . . . . . . . . . . . . . . . . . . 168\n4.3.3 Examples of Algorithm Analysis . . . . . . . . . . . . . . . . . 170\n4.4 Simple Justification Techniques . . . . . . . . . . . . . . . . . . . . 178\n4.4.1 By Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\n4.4.2 The \u201cContra\u201d Attack . . . . . . . . . . . . . . . . . . . . . . . 178\n4.4.3 Induction and Loop Invariants . . . . . . . . . . . . . . . . . . 179\n4.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\n5 Recursion 189\n5.1 Illustrative Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 191\n5.1.1 The Factorial Function . . . . . . . . . . . . . . . . . . . . . . 191\n5.1.2 Drawing an English Ruler . . . . . . . . . . . . . . . . . . . . . 193\n5.1.3 Binary Search . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\nwww.it-ebooks.info\nxii Contents\n5.1.4 File Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\n5.2 Analyzing Recursive Algorithms . . . . . . . . . . . . . . . . . . . . 202\n5.3 Further Examples of Recursion. . . . . . . . . . . . . . . . . . . . . 206\n5.3.1 Linear Recursion . . . . . . . . . . . . . . . . . . . . . . . . . . 206\n5.3.2 Binary Recursion . . . . . . . . . . . . . . . . . . . . . . . . . 211\n5.3.3 Multiple Recursion . . . . . . . . . . . . . . . . . . . . . . . . 212\n5.4 Designing Recursive Algorithms . . . . . . . . . . . . . . . . . . . . 214\n5.5 Recursion Run Amok . . . . . . . . . . . . . . . . . . . . . . . . . . 215\n5.5.1 Maximum Recursive Depth in Java . . . . . . . . . . . . . . . . 218\n5.6 Eliminating Tail Recursion . . . . . . . . . . . . . . . . . . . . . . . 219\n5.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\n6 Stacks, Queues, and Deques 225\n6.1 Stacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\n6.1.1 The Stack Abstract Data Type . . . . . . . . . . . . . . . . . . 227\n6.1.2 A Simple Array-Based Stack Implementation . . . . . . . . . . 230\n6.1.3 Implementing a Stack with a Singly Linked List . . . . . . . . . 233\n6.1.4 Reversing an Array Using a Stack . . . . . . . . . . . . . . . . 234\n6.1.5 Matching Parentheses and HTML Tags . . . . . . . . . . . . . 235\n6.2 Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n6.2.1 The Queue Abstract Data Type . . . . . . . . . . . . . . . . . 239\n6.2.2 Array-Based Queue Implementation . . . . . . . . . . . . . . . 241\n6.2.3 Implementing a Queue with a Singly Linked List . . . . . . . . . 245\n6.2.4 A Circular Queue . . . . . . . . . . . . . . . . . . . . . . . . . 246\n6.3 Double-Ended Queues. . . . . . . . . . . . . . . . . . . . . . . . . . 248\n6.3.1 The Deque Abstract Data Type . . . . . . . . . . . . . . . . . 248\n6.3.2 Implementing a Deque . . . . . . . . . . . . . . . . . . . . . . 250\n6.3.3 Deques in the Java Collections Framework . . . . . . . . . . . . 251\n6.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\n7 List and Iterator ADTs 257\n7.1 The List ADT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\n7.2 Array Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\n7.2.1 Dynamic Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . 263\n7.2.2 Implementing a Dynamic Array . . . . . . . . . . . . . . . . . . 264\n7.2.3 Amortized Analysis of Dynamic Arrays . . . . . . . . . . . . . . 265\n7.2.4 Java\u2019s StringBuilder class . . . . . . . . . . . . . . . . . . . . . 269\n7.3 Positional Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\n7.3.1 Positions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n7.3.2 The Positional List Abstract Data Type . . . . . . . . . . . . . 272\n7.3.3 Doubly Linked List Implementation . . . . . . . . . . . . . . . . 276\n7.4 Iterators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\n7.4.1 The Iterable Interface and Java\u2019s For-Each Loop . . . . . . . . 283\n7.4.2 Implementing Iterators . . . . . . . . . . . . . . . . . . . . . . 284\n7.5 The Java Collections Framework . . . . . . . . . . . . . . . . . . . 288\n7.5.1 List Iterators in Java . . . . . . . . . . . . . . . . . . . . . . . 289\n7.5.2 Comparison to Our Positional List ADT . . . . . . . . . . . . . 290\nwww.it-ebooks.info\nContents xiii\n7.5.3 List-Based Algorithms in the Java Collections Framework . . . . 291\n7.6 Sorting a Positional List . . . . . . . . . . . . . . . . . . . . . . . . 293\n7.7 Case Study: Maintaining Access Frequencies . . . . . . . . . . . . 294\n7.7.1 Using a Sorted List . . . . . . . . . . . . . . . . . . . . . . . . 294\n7.7.2 Using a List with the Move-to-Front Heuristic . . . . . . . . . . 297\n7.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\n8 Trees 307\n8.1 General Trees. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308\n8.1.1 Tree Definitions and Properties . . . . . . . . . . . . . . . . . . 309\n8.1.2 The Tree Abstract Data Type . . . . . . . . . . . . . . . . . . 312\n8.1.3 Computing Depth and Height. . . . . . . . . . . . . . . . . . . 314\n8.2 Binary Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317\n8.2.1 The Binary Tree Abstract Data Type . . . . . . . . . . . . . . . 319\n8.2.2 Properties of Binary Trees . . . . . . . . . . . . . . . . . . . . 321\n8.3 Implementing Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . 323\n8.3.1 Linked Structure for Binary Trees . . . . . . . . . . . . . . . . . 323\n8.3.2 Array-Based Representation of a Binary Tree . . . . . . . . . . 331\n8.3.3 Linked Structure for General Trees . . . . . . . . . . . . . . . . 333\n8.4 Tree Traversal Algorithms . . . . . . . . . . . . . . . . . . . . . . . 334\n8.4.1 Preorder and Postorder Traversals of General Trees . . . . . . . 334\n8.4.2 Breadth-First Tree Traversal . . . . . . . . . . . . . . . . . . . 336\n8.4.3 Inorder Traversal of a Binary Tree . . . . . . . . . . . . . . . . 337\n8.4.4 Implementing Tree Traversals in Java . . . . . . . . . . . . . . 339\n8.4.5 Applications of Tree Traversals . . . . . . . . . . . . . . . . . . 343\n8.4.6 Euler Tours . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\n8.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\n9 Priority Queues 359\n9.1 The Priority Queue Abstract Data Type . . . . . . . . . . . . . . . 360\n9.1.1 Priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\n9.1.2 The Priority Queue ADT . . . . . . . . . . . . . . . . . . . . . 361\n9.2 Implementing a Priority Queue . . . . . . . . . . . . . . . . . . . . 362\n9.2.1 The Entry Composite . . . . . . . . . . . . . . . . . . . . . . . 362\n9.2.2 Comparing Keys with Total Orders . . . . . . . . . . . . . . . . 363\n9.2.3 The AbstractPriorityQueue Base Class . . . . . . . . . . . . . . 364\n9.2.4 Implementing a Priority Queue with an Unsorted List . . . . . . 366\n9.2.5 Implementing a Priority Queue with a Sorted List . . . . . . . . 368\n9.3 Heaps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\n9.3.1 The Heap Data Structure . . . . . . . . . . . . . . . . . . . . . 370\n9.3.2 Implementing a Priority Queue with a Heap . . . . . . . . . . . 372\n9.3.3 Analysis of a Heap-Based Priority Queue . . . . . . . . . . . . . 379\n\u22c6\n9.3.4 Bottom-Up Heap Construction . . . . . . . . . . . . . . . . 380\n9.3.5 Using the java.util.PriorityQueue Class . . . . . . . . . . . . . . 384\n9.4 Sorting with a Priority Queue . . . . . . . . . . . . . . . . . . . . . 385\n9.4.1 Selection-Sort and Insertion-Sort . . . . . . . . . . . . . . . . . 386\n9.4.2 Heap-Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 388\nwww.it-ebooks.info\nxiv Contents\n9.5 Adaptable Priority Queues . . . . . . . . . . . . . . . . . . . . . . . 390\n9.5.1 Location-Aware Entries . . . . . . . . . . . . . . . . . . . . . . 391\n9.5.2 Implementing an Adaptable Priority Queue . . . . . . . . . . . 392\n9.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395\n10 Maps, Hash Tables, and Skip Lists 401\n10.1 Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 402\n10.1.1 The Map ADT . . . . . . . . . . . . . . . . . . . . . . . . . . 403\n10.1.2 Application: Counting Word Frequencies . . . . . . . . . . . . . 405\n10.1.3 An AbstractMap Base Class . . . . . . . . . . . . . . . . . . . 406\n10.1.4 A Simple Unsorted Map Implementation . . . . . . . . . . . . . 408\n10.2 Hash Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410\n10.2.1 Hash Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 411\n10.2.2 Collision-HandlingSchemes . . . . . . . . . . . . . . . . . . . . 417\n10.2.3 Load Factors, Rehashing, and Efficiency . . . . . . . . . . . . . 420\n10.2.4 Java Hash Table Implementation . . . . . . . . . . . . . . . . . 422\n10.3 Sorted Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 428\n10.3.1 Sorted Search Tables . . . . . . . . . . . . . . . . . . . . . . . 429\n10.3.2 Two Applications of Sorted Maps . . . . . . . . . . . . . . . . 433\n10.4 Skip Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436\n10.4.1 Search and Update Operations in a Skip List . . . . . . . . . . 438\n\u22c6\n10.4.2 Probabilistic Analysis of Skip Lists . . . . . . . . . . . . . . . 442\n10.5 Sets, Multisets, and Multimaps . . . . . . . . . . . . . . . . . . . . 445\n10.5.1 The Set ADT . . . . . . . . . . . . . . . . . . . . . . . . . . . 445\n10.5.2 The Multiset ADT . . . . . . . . . . . . . . . . . . . . . . . . 447\n10.5.3 The Multimap ADT . . . . . . . . . . . . . . . . . . . . . . . . 448\n10.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451\n11 Search Trees 459\n11.1 Binary Search Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . 460\n11.1.1 Searching Within a Binary Search Tree . . . . . . . . . . . . . . 461\n11.1.2 Insertions and Deletions . . . . . . . . . . . . . . . . . . . . . . 463\n11.1.3 Java Implementation . . . . . . . . . . . . . . . . . . . . . . . 466\n11.1.4 Performance of a Binary Search Tree . . . . . . . . . . . . . . . 470\n11.2 Balanced Search Trees . . . . . . . . . . . . . . . . . . . . . . . . . 472\n11.2.1 Java Framework for Balancing Search Trees . . . . . . . . . . . 475\n11.3 AVL Trees. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 479\n11.3.1 Update Operations . . . . . . . . . . . . . . . . . . . . . . . . 481\n11.3.2 Java Implementation . . . . . . . . . . . . . . . . . . . . . . . 486\n11.4 Splay Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 488\n11.4.1 Splaying . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 488\n11.4.2 When to Splay. . . . . . . . . . . . . . . . . . . . . . . . . . . 492\n11.4.3 Java Implementation . . . . . . . . . . . . . . . . . . . . . . . 494\n\u22c6\n11.4.4 Amortized Analysis of Splaying . . . . . . . . . . . . . . . . 495\n11.5 (2,4) Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 500\n11.5.1 Multiway Search Trees . . . . . . . . . . . . . . . . . . . . . . 500\n11.5.2 (2,4)-Tree Operations . . . . . . . . . . . . . . . . . . . . . . . 503\nwww.it-ebooks.info\nContents xv\n11.6 Red-Black Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 510\n11.6.1 Red-Black Tree Operations . . . . . . . . . . . . . . . . . . . . 512\n11.6.2 Java Implementation . . . . . . . . . . . . . . . . . . . . . . . 522\n11.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 525\n12 Sorting and Selection 531\n12.1 Merge-Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 532\n12.1.1 Divide-and-Conquer . . . . . . . . . . . . . . . . . . . . . . . . 532\n12.1.2 Array-Based Implementation of Merge-Sort . . . . . . . . . . . 537\n12.1.3 The Running Time of Merge-Sort . . . . . . . . . . . . . . . . 538\n\u22c6\n12.1.4 Merge-Sort and Recurrence Equations . . . . . . . . . . . . . 540\n12.1.5 Alternative Implementations of Merge-Sort . . . . . . . . . . . 541\n12.2 Quick-Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 544\n12.2.1 Randomized Quick-Sort . . . . . . . . . . . . . . . . . . . . . . 551\n12.2.2 Additional Optimizations for Quick-Sort . . . . . . . . . . . . . 553\n12.3 Studying Sorting through an Algorithmic Lens . . . . . . . . . . . 556\n12.3.1 Lower Bound for Sorting . . . . . . . . . . . . . . . . . . . . . 556\n12.3.2 Linear-Time Sorting: Bucket-Sort and Radix-Sort . . . . . . . . 558\n12.4 Comparing Sorting Algorithms . . . . . . . . . . . . . . . . . . . . . 561\n12.5 Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563\n12.5.1 Prune-and-Search . . . . . . . . . . . . . . . . . . . . . . . . . 563\n12.5.2 Randomized Quick-Select . . . . . . . . . . . . . . . . . . . . . 564\n12.5.3 Analyzing Randomized Quick-Select . . . . . . . . . . . . . . . 565\n12.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 566\n13 Text Processing 573\n13.1 Abundance of Digitized Text . . . . . . . . . . . . . . . . . . . . . . 574\n13.1.1 Notations for Character Strings . . . . . . . . . . . . . . . . . . 575\n13.2 Pattern-Matching Algorithms . . . . . . . . . . . . . . . . . . . . . 576\n13.2.1 Brute Force . . . . . . . . . . . . . . . . . . . . . . . . . . . . 576\n13.2.2 The Boyer-Moore Algorithm . . . . . . . . . . . . . . . . . . . 578\n13.2.3 The Knuth-Morris-Pratt Algorithm . . . . . . . . . . . . . . . . 582\n13.3 Tries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 586\n13.3.1 Standard Tries . . . . . . . . . . . . . . . . . . . . . . . . . . . 586\n13.3.2 Compressed Tries . . . . . . . . . . . . . . . . . . . . . . . . . 590\n13.3.3 Suffix Tries . . . . . . . . . . . . . . . . . . . . . . . . . . . . 592\n13.3.4 Search Engine Indexing . . . . . . . . . . . . . . . . . . . . . . 594\n13.4 Text Compression and the Greedy Method . . . . . . . . . . . . . 595\n13.4.1 The Huffman Coding Algorithm . . . . . . . . . . . . . . . . . 596\n13.4.2 The Greedy Method . . . . . . . . . . . . . . . . . . . . . . . . 597\n13.5 Dynamic Programming . . . . . . . . . . . . . . . . . . . . . . . . . 598\n13.5.1 Matrix Chain-Product . . . . . . . . . . . . . . . . . . . . . . . 598\n13.5.2 DNA and Text Sequence Alignment . . . . . . . . . . . . . . . 601\n13.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605\nwww.it-ebooks.info\nxvi Contents\n14 Graph Algorithms 611\n14.1 Graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 612\n14.1.1 The Graph ADT . . . . . . . . . . . . . . . . . . . . . . . . . . 618\n14.2 Data Structures for Graphs . . . . . . . . . . . . . . . . . . . . . . . 619\n14.2.1 Edge List Structure . . . . . . . . . . . . . . . . . . . . . . . . 620\n14.2.2 Adjacency List Structure . . . . . . . . . . . . . . . . . . . . . 622\n14.2.3 Adjacency Map Structure . . . . . . . . . . . . . . . . . . . . . 624\n14.2.4 Adjacency Matrix Structure . . . . . . . . . . . . . . . . . . . . 625\n14.2.5 Java Implementation . . . . . . . . . . . . . . . . . . . . . . . 626\n14.3 Graph Traversals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 630\n14.3.1 Depth-First Search . . . . . . . . . . . . . . . . . . . . . . . . 631\n14.3.2 DFS Implementation and Extensions . . . . . . . . . . . . . . . 636\n14.3.3 Breadth-First Search . . . . . . . . . . . . . . . . . . . . . . . 640\n14.4 Transitive Closure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 643\n14.5 Directed Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . 647\n14.5.1 Topological Ordering . . . . . . . . . . . . . . . . . . . . . . . 647\n14.6 Shortest Paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 651\n14.6.1 Weighted Graphs . . . . . . . . . . . . . . . . . . . . . . . . . 651\n14.6.2 Dijkstra\u2019s Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 653\n14.7 Minimum Spanning Trees. . . . . . . . . . . . . . . . . . . . . . . . 662\n14.7.1 Prim-Jarn\u00b4\u0131k Algorithm . . . . . . . . . . . . . . . . . . . . . . 664\n14.7.2 Kruskal\u2019s Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 667\n14.7.3 Disjoint Partitions and Union-Find Structures . . . . . . . . . . 672\n14.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 677\n15 Memory Management and B-Trees 687\n15.1 Memory Management . . . . . . . . . . . . . . . . . . . . . . . . . . 688\n15.1.1 Stacks in the Java Virtual Machine . . . . . . . . . . . . . . . . 688\n15.1.2 Allocating Space in the Memory Heap . . . . . . . . . . . . . . 691\n15.1.3 Garbage Collection . . . . . . . . . . . . . . . . . . . . . . . . 693\n15.2 Memory Hierarchies and Caching . . . . . . . . . . . . . . . . . . . 695\n15.2.1 Memory Systems . . . . . . . . . . . . . . . . . . . . . . . . . 695\n15.2.2 Caching Strategies . . . . . . . . . . . . . . . . . . . . . . . . 696\n15.3 External Searching and B-Trees . . . . . . . . . . . . . . . . . . . . 701\n15.3.1 (a,b) Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . 702\n15.3.2 B-Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 704\n15.4 External-Memory Sorting . . . . . . . . . . . . . . . . . . . . . . . . 705\n15.4.1 Multiway Merging . . . . . . . . . . . . . . . . . . . . . . . . . 706\n15.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 707\nBibliography 710\nIndex 714\nUseful Mathematical Facts available at www.wiley.com/college/goodrich\nwww.it-ebooks.info\nChapter\n1\nJava Primer\nContents\n1.1 Getting Started . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.1.1 Base Types . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.2 Classes and Objects . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.1 Creating and Using Objects . . . . . . . . . . . . . . . . . 6\n1.2.2 Defining a Class . . . . . . . . . . . . . . . . . . . . . . . 9\n1.3 Strings, Wrappers, Arrays, and Enum Types . . . . . . . . 17\n1.4 Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n1.4.1 Literals . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n1.4.2 Operators . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n1.4.3 Type Conversions . . . . . . . . . . . . . . . . . . . . . . 28\n1.5 Control Flow . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n1.5.1 The If and Switch Statements . . . . . . . . . . . . . . . 30\n1.5.2 Loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n1.5.3 Explicit Control-Flow Statements . . . . . . . . . . . . . . 37\n1.6 Simple Input and Output . . . . . . . . . . . . . . . . . . . 38\n1.7 An Example Program . . . . . . . . . . . . . . . . . . . . . 41\n1.8 Packages and Imports . . . . . . . . . . . . . . . . . . . . . 44\n1.9 Software Development . . . . . . . . . . . . . . . . . . . . 46\n1.9.1 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n1.9.2 Pseudocode . . . . . . . . . . . . . . . . . . . . . . . . . 48\n1.9.3 Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n1.9.4 Documentation and Style . . . . . . . . . . . . . . . . . . 50\n1.9.5 Testing and Debugging . . . . . . . . . . . . . . . . . . . 53\n1.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nwww.it-ebooks.info\n2 Chapter1. JavaPrimer\n1.1 Getting Started\nBuilding datastructures and algorithms requires that wecommunicate detailed in-\nstructions to a computer. An excellent way to perform such communication is\nusing ahigh-level computer language, such asJava. Inthischapter, weprovide an\noverviewoftheJavaprogramminglanguage,andwecontinuethisdiscussioninthe\nnextchapter,focusingonobject-orienteddesignprinciples. Weassumethatreaders\naresomewhatfamiliarwithanexistinghigh-levellanguage,althoughnotnecessar-\nily Java. This book does not provide a complete description of the Java language\n(therearenumerouslanguage references forthatpurpose), butitdoesintroduce all\naspectsofthelanguagethatareusedincodefragments laterinthisbook.\nWebegin our Java primerwithaprogram thatprints \u201cHelloUniverse!\u201d onthe\nscreen, whichisshowninadissected forminFigure1.1.\nFigure1.1: A\u201cHelloUniverse!\u201d program.\nInJava, executable statements areplaced infunctions, knownasmethods, that\nbelong to class definitions. The Universe class, in our first example, is extremely\nsimple;itsonlymethodisastaticonenamedmain,whichisthefirstmethodtobe\nexecuted when running aJava program. Anyset of statements between the braces\n\u201c \u201dand\u201c \u201ddefineaprogramblock. NoticethattheentireUniverseclassdefinition\n{ }\nisdelimited bysuchbraces,asisthebodyofthemainmethod.\nThe name of a class, method, or variable in Java is called an identifier, which\ncanbeanystring ofcharacters aslongasitbegins withaletter andconsists oflet-\nters,numbers,andunderscorecharacters(where\u201cletter\u201dand\u201cnumber\u201dcanbefrom\nany written language defined inthe Unicode character set). Welist the exceptions\ntothisgeneralruleforJavaidentifiersinTable1.1.\nwww.it-ebooks.info\n1.1. GettingStarted 3\nReserved Words\nabstract default goto package synchronized\nassert do if private this\nboolean double implements protected throw\nbreak else import public throws\nbyte enum instanceof return transient\ncase extends int short true\ncatch false interface static try\nchar final long strictfp void\nclass finally native super volatile\nconst float new switch while\ncontinue for null\nTable1.1: A listing of the reserved words in Java. These names cannot be used as\nclass,method,orvariablenames.\nComments\nIn addition to executable statements and declarations, Java allows a programmer\nto embed comments, which are annotations provided for human readers that are\nnot processed by the Java compiler. Java allows two kinds of comments: inline\ncomments and block comments. Java uses a \u201c//\u201d to begin an inline comment,\nignoring everything subsequently onthatline. Forexample:\n// This is an inline comment.\nWe will intentionally color all comments in blue in this book, so that they are not\nconfused withexecutable code.\nWhileinlinecommentsarelimitedtooneline,Javaallowsmultilinecomments\nin the form of block comments. Java uses a \u201c/*\u201d to begin a block comment and a\n\u201c*/\u201dtocloseit. Forexample:\n/*\n* This is a block comment.\n*/\nBlockcommentsthatbeginwith\u201c/**\u201d(notethesecondasterisk)haveaspecial\npurpose,allowingaprogram,calledJavadoc,toreadthesecommentsandautomat-\nically generate software documentation. We discuss the syntax and interpretation\nofJavadoc commentsinSection1.9.4.\nwww.it-ebooks.info\n4 Chapter1. JavaPrimer\n1.1.1 Base Types\nFor the most commonly used data types, Java provides the following base types\n(alsocalledprimitivetypes):\nboolean aboolean value: trueorfalse\nchar 16-bitUnicodecharacter\nbyte 8-bitsignedtwo\u2019scomplementinteger\nshort 16-bitsignedtwo\u2019scomplementinteger\nint 32-bitsignedtwo\u2019scomplementinteger\nlong 64-bitsignedtwo\u2019scomplementinteger\nfloat 32-bitfloating-point number(IEEE754-1985)\ndouble 64-bitfloating-point number(IEEE754-1985)\nA variable having one of these types simply stores a value of that type. Integer\nconstants, like 14 or 195, are of type int, unless followed immediately by an \u2018L\u2019\nor \u2018l\u2019, in which case they are of type long. Floating-point constants, like 3.1416\nor 6.022e23, are of type double, unless followed immediately by an \u2018F\u2019 or \u2018f\u2019, in\nwhichcasetheyareoftypefloat. CodeFragment1.1demonstratesthedeclaration,\nandinitialization insomecases, ofvariousbase-type variables.\n1 boolean flag = true;\n2 boolean verbose, debug; // two variables declared, but not yet initialized\n3 char grade = 'A';\n4 byte b = 12;\n5 short s = 24;\n6 int i, j, k = 257; // three variables declared; only k initialized\n7 long l = 890L; // note the use of \u201dL\u201d here\n8 float pi = 3.1416F; // note the use of \u201dF\u201d here\n9 double e = 2.71828,a = 6.022e23; // both variables are initialized\nCodeFragment1.1: Declarations andinitializations ofseveralbase-type variables.\nNotethatitispossibletodeclare(andinitialize) multiplevariables ofthesame\ntypeinasinglestatement, asdoneonlines2,6,and9ofthisexample. Inthiscode\nfragment,variablesverbose,debug,i,andjremainuninitialized. Variablesdeclared\nlocallywithinablockofcodemustbeinitialized beforetheyarefirstused.\nAnicefeatureofJavaisthatwhenbase-type variablesaredeclared asinstance\nvariables of a class (see next section), Java ensures initial default values if not ex-\nplicitlyinitialized. Inparticular, allnumerictypesareinitialized tozero,aboolean\nisinitialized tofalse,andacharacter isinitialized tothenullcharacter bydefault.\nwww.it-ebooks.info\n1.2. ClassesandObjects 5\n1.2 Classes and Objects\nIn more complex Java programs, the primary \u201cactors\u201d are objects. Every object is\nan instance of a class, which serves as the type of the object and as a blueprint,\ndefining thedata which theobject stores andthe methods foraccessing and modi-\nfyingthatdata. ThecriticalmembersofaclassinJavaarethefollowing:\nInstancevariables,whicharealsocalledfields,representthedataassociated\n\u2022\nwith an object of a class. Instance variables must have a type, which can\neither be a base type (such as int, float, or double) or any class type (also\nknownasareferencetypeforreasonswesoonexplain).\nMethods in Java are blocks of code that can be called to perform actions\n\u2022\n(similartofunctionsandproceduresinotherhigh-levellanguages). Methods\ncan accept parameters as arguments, and their behavior may depend on the\nobjectuponwhichtheyareinvokedandthevaluesofanyparametersthatare\npassed. Amethodthatreturnsinformationtothecallerwithoutchangingany\ninstancevariables isknownasanaccessormethod,whileanupdatemethod\nisonethatmaychangeoneormoreinstance variableswhencalled.\nFor the purpose of illustration, Code Fragment 1.2 provides a complete def-\ninition of a very simple class named Counter, to which we will refer during the\nremainderofthissection.\n1 public class Counter\n{\n2 private int count; // a simple integer instance variable\n3 public Counter() // default constructor (count is 0)\n{ }\n4 public Counter(int initial) count = initial; // an alternate constructor\n{ }\n5 public int getCount() return count; // an accessor method\n{ }\n6 public void increment() count++; // an update method\n{ }\n7 public void increment(int delta) count += delta; // an update method\n{ }\n8 public void reset() count = 0; // an update method\n{ }\n9\n}\nCode Fragment1.2: A Counter class for a simple counter, which can be queried,\nincremented, andreset.\nThis class includes one instance variable, named count, which is declared at\nline 2. Asnoted on the previous page, the count will have a default value of zero,\nunlessweotherwiseinitialize it.\nThe class includes two special methods known as constructors (lines 3 and\n4), one accessor method (line 5), and three update methods (lines 6\u20138). Unlike\nthe original Universe class from page 2, our Counter class does not have a main\nmethod,andsoitcannotberunasacompleteprogram. Instead, thepurposeofthe\nCounterclassistocreateinstances thatmightbeusedaspartofalarger program.\nwww.it-ebooks.info\n6 Chapter1. JavaPrimer\n1.2.1 Creating and Using Objects\nBeforeweexploretheintricaciesofthesyntaxforourCounterclassdefinition,we\nprefer to describe how Counter instances can be created and used. To this end,\nCodeFragment1.3presents anewclassnamedCounterDemo.\n1 public class CounterDemo\n{\n2 public static void main(String[ ] args)\n{\n3 Counter c; // declares a variable; no counter yet constructed\n4 c = new Counter(); // constructs a counter; assigns its reference to c\n5 c.increment(); // increases its value by one\n6 c.increment(3); // increases its value by three more\n7 int temp = c.getCount(); // will be 4\n8 c.reset(); // value becomes 0\n9 Counter d = new Counter(5);// declares and constructs a counter having value 5\n10 d.increment(); // value becomes 6\n11 Counter e = d; // assigns e to reference the same object as d\n12 temp = e.getCount(); // will be 6 (as e and d reference the same counter)\n13 e.increment(2); // value of e (also known as d) becomes 8\n14\n}\n15\n}\nCodeFragment1.3: Ademonstration oftheuseofCounterinstances.\nThere is an important distinction in Java between the treatment of base-type\nvariablesandclass-type variables. Atline3ofourdemonstration, anewvariablec\nisdeclared withthesyntax:\nCounter c;\nThisestablishestheidentifier,c,asavariableoftypeCounter,butitdoesnotcreate\naCounterinstance. ClassesareknownasreferencetypesinJava,andavariableof\nthattype(such ascinourexample) isknownasareference variable. Areference\nvariableiscapable ofstoring thelocation (i.e.,memoryaddress) ofanobjectfrom\nthe declared class. So we might assign it to reference an existing instance or a\nnewly constructed instance. A reference variable can also store a special value,\nnull,thatrepresents thelackofanobject.\nInJava,anewobjectiscreatedbyusingthenewoperatorfollowedbyacallto\naconstructor forthedesiredclass;aconstructor isamethodthatalwayssharesthe\nsamenameasitsclass. Thenew operator returns areference tothenewlycreated\ninstance; thereturnedreference istypicallyassigned toavariableforfurtheruse.\nInCodeFragment1.3,anewCounterisconstructedatline4,withitsreference\nassigned tothevariablec. Thatreliesonaformoftheconstructor, Counter(),that\ntakes no arguments between the parentheses. (Such a zero-parameter constructor\nisknownasadefaultconstructor.) Atline9weconstruct another counter using a\none-parameterformthatallowsustospecifyanonzeroinitialvalueforthecounter.\nwww.it-ebooks.info\n1.2. ClassesandObjects 7\nThreeeventsoccuraspartofthecreationofanewinstanceofaclass:\nAnewobject isdynamically allocated inmemory, andallinstance variables\n\u2022\nare initialized to standard default values. The default values are null for\nreferencevariablesand0forallbasetypesexceptbooleanvariables(which\narefalsebydefault).\nThe constructor for the new object is called with the parameters specified.\n\u2022\nThe constructor may assign more meaningful values to any of the instance\nvariables, andperformanyadditionalcomputations thatmustbedonedueto\nthecreation ofthisobject.\nAftertheconstructor returns, thenew operator returns areference (thatis, a\n\u2022\nmemoryaddress)tothenewlycreatedobject. Iftheexpressionisintheform\nofanassignmentstatement, thenthisaddressisstoredintheobjectvariable,\nsotheobjectvariablereferstothisnewlycreatedobject.\nThe Dot Operator\nOneoftheprimaryusesofanobjectreferencevariableistoaccessthemembersof\nthe class for this object, an instance of its class. That is, an object reference vari-\nable is useful for accessing the methods and instance variables associated with an\nobject. Thisaccessisperformedwiththedot(\u201c.\u201d) operator. Wecallamethodasso-\nciatedwithanobjectbyusingthereferencevariablename,followingthatbythedot\noperatorandthenthemethodnameanditsparameters. Forexample,inCodeFrag-\nment 1.3, we call c.increment() at line 5, c.increment(3) at line 6, c.getCount()\nat line 7, and c.reset() at line 8. If the dot operator is used on a reference that is\ncurrently null,theJavaruntimeenvironment willthrowaNullPointerException.\nIf there are several methods with this same name defined for a class, then the\nJava runtime system uses the one that matches the actual number of parameters\nsent as arguments, as well as their respective types. For example, our Counter\nclass supports two methods named increment: a zero-parameter form and a one-\nparameterform. Javadetermineswhichversiontocallwhenevaluatingcommands\nsuchasc.increment()versusc.increment(3). Amethod\u2019snamecombinedwiththe\nnumber and types of its parameters is called a method\u2019s signature, for it takes all\nofthese parts to determine theactual method toperform foracertain method call.\nNote,however,thatthesignatureofamethodinJavadoesnotincludethetypethat\nthemethodreturns,soJavadoesnotallowtwomethodswiththesamesignatureto\nreturndifferenttypes.\nAreference variablevcanbeviewedasa\u201cpointer\u201d tosomeobjecto. Itisasif\nthe variable is a holder for a remote control that can be used to control the newly\ncreatedobject(thedevice). Thatis,thevariablehasawayofpointing attheobject\nandaskingittodothings orgiveusaccess toitsdata. Weillustrate thisconcept in\nFigure 1.2. Using the remote control analogy, a null reference is a remote control\nholderthatisempty.\nwww.it-ebooks.info\n8 Chapter1. JavaPrimer\nFigure1.2: Illustrating the relationship between objects and object reference vari-\nables. Whenweassignanobjectreference(thatis,memoryaddress)toareference\nvariable, itisasifwearestoringthatobject\u2019s remotecontrolatthatvariable.\nTherecan,infact,bemanyreferencestothesameobject,andeachreferenceto\naspecificobjectcanbeusedtocallmethodsonthatobject. Suchasituation would\ncorrespond to our having many remote controls that all work on the same device.\nAny of the remotes can be used to make a change to the device (like changing a\nchannel on a television). Note that if one remote control is used to change the\ndevice, thenthe (single) object pointed tobyallthe remotes changes. Likewise, if\noneobjectreference variable isusedtochangethestateoftheobject, thenitsstate\nchangesforallthereferencestoit. Thisbehaviorcomesfromthefactthatthereare\nmanyreferences, buttheyallpointtothesameobject.\nReturningtoourCounterDemoexample,theinstance constructed atline9as\nCounter d = new Counter(5);\nisadistinctinstancefromtheoneidentifiedasc. However,thecommandatline11,\nCounter e = d;\ndoes notresult inthe construction ofanewCounter instance. Thisdeclares anew\nreference variable named e, and assigns that variable a reference to the existing\ncounter instance currently identified asd. Atthat point, both variables d and eare\naliases for the same object, and so the call to d.getCount() behaves just as would\ne.getCount(). Similarly, thecall toupdate method e.increment(2)isaffecting the\nsameobjectidentified byd.\nIt is worth noting, however, that the aliasing of two reference variables to the\nsame object is not permanent. At any point in time, we may reassign a reference\nvariabletoanewinstance, toadifferentexistinginstance, ortonull.\nwww.it-ebooks.info\n1.2. ClassesandObjects 9\n1.2.2 Defining a Class\nThus far, we have provided definitions for two simple classes: the Universe class\nonpage2andtheCounterclassonpage5. Atitscore,aclassdefinitionisablock\nofcode,delimitedbybraces\u201c \u201dand\u201c \u201d,withinwhichisincluded declarations of\n{ }\ninstance variables and methods that are the members of the class. In this section,\nwewillundertake adeeperexamination ofclassdefinitions inJava.\nModifiers\nImmediately before the definition of a class, instance variable, or method in Java,\nkeywordsknownasmodifierscanbeplacedtoconveyadditionalstipulationsabout\nthatdefinition.\nAccess Control Modifiers\nThefirstsetofmodifierswediscussareknownasaccesscontrolmodifiers,asthey\ncontrol the level of access (also known as visibility) that the defining class grants\ntoother classes inthe context ofalarger Java program. Theability tolimit access\namong classes supports a key principle of object-orientation known as encapsula-\ntion (see Section 2.1). In general, the different access control modifiers and their\nmeaningareasfollows:\nThe public class modifier designates that all classes may access the defined\n\u2022\naspect. Forexample,line1ofofCodeFragment1.2designates\npublic class Counter\n{\nand therefore all other classes (such as CounterDemo) are allowed to con-\nstructnewinstances oftheCounterclass,aswellastodeclare variables and\nparameters of type Counter. In Java, each public class must be defined in a\nseparate filenamedclassname.java, where\u201cclassname\u201d isthenameofthe\nclass(forexample,fileCounter.javafortheCounterclassdefinition).\nThe designation of public access for a particular method of a class allows\nany other class to make a call to that method. For example, line 5 of Code\nFragment1.2designates\npublic int getCount() return count;\n{ }\nwhichiswhytheCounterDemoclassmaycallc.getCount().\nIf an instance variable is declared as public, dot notation can be used to di-\nrectlyaccessthevariablebycodeinanyotherclassthatpossessesareference\ntoaninstanceofthisclass. Forexample,werethecountvariableofCounter\nto be declared as public (which it is not), then the CounterDemo would be\nallowedtoreadormodifythatvariableusingasyntaxsuchasc.count.\nwww.it-ebooks.info\n10 Chapter1. JavaPrimer\nTheprotected class modifier designates that access tothe defined aspect is\n\u2022\nonlygrantedtothefollowinggroupsofotherclasses:\nClasses that are designated as subclasses of the given class through\n\u25e6\ninheritance. (Wewilldiscuss inheritance asthefocusofSection2.2.)\nClasses that belong to the same package as the given class. (We will\n\u25e6\ndiscuss packages withinSection1.8.)\nThe private class modifier designates that access to a defined member of a\n\u2022\nclass be granted only to code within that class. Neither subclasses nor any\notherclasseshaveaccesstosuchmembers.\nForexample, wedefined the count instance variable of theCounter class to\nhave private access level. We were allowed to read or edit its value from\nwithin methods of that class (such as getCount, increment, and reset), but\nother classes such as CounterDemo cannot directly access that field. Of\ncourse, we did provide other public methods to grant outside classes with\nbehaviors thatdepended onthecurrentcountvalue.\nFinally, we note that if no explicit access control modifier is given, the de-\n\u2022\nfinedaspecthaswhatisknownaspackage-private access level. Thisallows\nother classes in the same package (see Section 1.8) to have access, but not\nanyclassesorsubclasses fromotherpackages.\nThe static Modifier\nThe static modifier in Java can be declared for any variable or method of a class\n(orforanestedclass,aswewillintroduce inSection2.6).\nWhen a variable of a class is declared as static, its value is associated with\nthe class as a whole, rather than with each individual instance of that class. Static\nvariablesareusedtostore\u201cglobal\u201dinformationaboutaclass. (Forexample,astatic\nvariable could be used to maintain the total number of instances of that class that\nhavebeencreated.) Staticvariables existevenifnoinstance oftheirclassexists.\nWhen a method of a class is declared as static, it too is associated with the\nclass itself, and not with a particular instance of the class. That means that the\nmethodisnotinvoked onaparticular instance oftheclassusing thetraditional dot\nnotation. Instead, itistypicallyinvoked usingthenameoftheclassasaqualifier.\nAs an example, in the java.lang package, which is part of the standard Java\ndistribution, thereisaMathclassthatprovidesmanystaticmethods,includingone\nnamedsqrtthatcomputessquare rootsofnumbers. Tocomputeasquareroot, you\ndo not need to create an instance of the Math class; that method is called using a\nsyntax such as Math.sqrt(2), with the class name Mathas the qualifier before the\ndotoperator.\nStatic methods can be useful for providing utility behaviors related to a class\nthatneednotrelyonthestateofanyparticular instance ofthatclass.\nwww.it-ebooks.info\n1.2. ClassesandObjects 11\nThe abstract Modifier\nAmethodofaclassmaybedeclaredasabstract,inwhichcaseitssignatureispro-\nvidedbutwithoutanimplementation ofthemethodbody. Abstractmethodsarean\nadvancedfeatureofobject-orientedprogrammingtobecombinedwithinheritance,\nandthefocusofSection2.3.3. Inshort,anysubclassofaclasswithabstractmeth-\nodsisexpected toprovideaconcrete implementation foreachabstractmethod.\nA class with one or more abstract methods must also be formally declared as\nabstract, because it is essentially incomplete. (It is also permissible to declare\na class as abstract even if it does not contain any abstract methods.) As a result,\nJava will not allow any instances of an abstract class to be constructed, although\nreference variablesmaybedeclared withanabstracttype.\nThe final Modifier\nA variable that is declared with the final modifier can be initialized as part of that\ndeclaration, but can never again be assigned a new value. If it is a base type, then\nitisaconstant. Ifareference variable isfinal,thenitwillalwaysrefertothesame\nobject(evenifthatobjectchangesitsinternalstate). Ifamembervariableofaclass\nisdeclaredasfinal,itwilltypicallybedeclaredasstaticaswell,becauseitwould\nbeunnecessarily wastefultohaveeveryinstancestoretheidenticalvaluewhenthat\nvaluecanbesharedbytheentireclass.\nDesignating a method or an entire class as final has a completely different\nconsequence, onlyrelevant inthecontextofinheritance. Afinalmethodcannotbe\noverridden byasubclass, andafinalclasscannotevenbesubclassed.\nDeclaring Instance Variables\nWhendefiningaclass,wecandeclareanynumberofinstancevariables. Animpor-\ntantprincipleofobject-orientation isthateachinstanceofaclassmaintainsitsown\nindividual set of instance variables (that is, in fact, why they are called instance\nvariables). So in the case of the Counter class, each instance will store its own\n(independent) valueofcount.\nThegeneral syntaxfordeclaring oneormoreinstance variables ofaclassisas\nfollows(withoptional portionsbracketed):\n[modifiers] typeidentifier [=initialValue ],identifier [=initialValue ];\n1 1 2 2\nInthecaseoftheCounterclass,wedeclared\nprivate int count;\nwhere private is the modifier, int is the type, and count is the identifier. Because\nwedidnotdeclareaninitialvalue,itautomatically receivesthedefaultofzeroasa\nbase-type integer.\nwww.it-ebooks.info\n12 Chapter1. JavaPrimer\nDeclaring Methods\nA method definition has two parts: the signature, which defines the name and\nparameters for a method, and the body, which defines what the method does. The\nmethodsignaturespecifieshowthemethodiscalled,andthemethodbodyspecifies\nwhat the object will do when it is called. The syntax for defining a method is as\nfollows:\n[modifiers] returnType methodName(type param , ..., type param )\n1 1 n n\n{\n// method body . . .\n}\nEach of the pieces of this declaration has an important purpose. We have al-\nready discussed the significance of modifiers such as public, private, and static.\nThereturnType designation defines the type ofvalue returned by the method. The\nmethodNamecanbeanyvalidJavaidentifier. Thelistofparametersandtheirtypes\ndeclares the local variables that correspond to the values that are to be passed as\narguments to this method. Each type declaration type can be any Java type name\ni\nand each param can be any distinct Java identifier. This list of parameters and\ni\ntheir types can be empty, which signifies that there are no values to be passed to\nthis method whenit isinvoked. These parameter variables, aswell asthe instance\nvariables of the class, can be used inside the body of the method. Likewise, other\nmethodsofthisclasscanbecalledfrominsidethebodyofamethod.\nWhen a (nonstatic) method of a class is called, it is invoked on a specific in-\nstanceofthatclassandcanchangethestateofthatobject. Forexample,thefollow-\ningmethodoftheCounterclassincreasesthecounter\u2019svaluebythegivenamount.\npublic void increment(int delta)\n{\ncount += delta;\n}\nNotice that the body ofthis method uses count,which isan instance variable, and\ndelta,whichisaparameter.\nReturn Types\nA method definition must specify the type of value the method will return. If the\nmethoddoesnotreturnavalue(aswiththeincrementmethodoftheCounterclass),\nthen the keyword void must be used. To return a value in Java, the body of the\nmethodmustusethereturnkeyword,followedbyavalueoftheappropriatereturn\ntype. Here is an example of a method (from the Counter class) with a nonvoid\nreturntype:\npublic int getCount()\n{\nreturn count;\n}\nwww.it-ebooks.info\n1.2. ClassesandObjects 13\nJava methods can return only one value. Toreturn multiple values in Java, we\nshould instead combine all the values we want to return in a compound object,\nwhoseinstancevariablesincludeallthevalueswewanttoreturn,andthenreturna\nreference tothatcompound object. Inaddition, wecanchange theinternal stateof\nanobjectthatispassedtoamethodasanotherwayof\u201creturning\u201d multipleresults.\nParameters\nAmethod\u2019sparametersaredefinedinacomma-separatedlistenclosedinparenthe-\nsesafterthenameofthemethod. Aparameterconsists oftwoparts,theparameter\ntype and the parameter name. If a method has no parameters, then only an empty\npairofparentheses isused.\nAllparametersinJavaarepassedbyvalue,thatis,anytimewepassaparameter\ntoa method, acopy of that parameter ismade for use within the method body. So\nifwepass an int variable to amethod, then that variable\u2019s integer value is copied.\nThemethodcanchangethecopybutnottheoriginal. Ifwepassanobjectreference\nasaparametertoamethod,thenthereferenceiscopiedaswell. Rememberthatwe\ncanhavemanydifferent variablesthatallrefertothesameobject. Reassigning the\ninternal reference variable inside a method will not change the reference that was\npassedin.\nForthesakeofdemonstration, wewillassumethat thefollowing twomethods\nwereaddedtoanarbitrary class(suchasCounterDemo).\npublic static void badReset(Counter c)\n{\nc = new Counter(); // reassigns local name c to a new counter\n}\npublic static void goodReset(Counter c)\n{\nc.reset(); // resets the counter sent by the caller\n}\nNowwe willassume that variable strikes refers to an existing Counter instance in\nsomecontext,andthatitcurrently hasavalueof3.\nIfweweretocallbadReset(strikes),thishasnoeffectontheCounterknownas\nstrikes. ThebodyofthebadResetmethodreassignsthe(local)parametervariablec\ntoreferenceanewlycreatedCounterinstance; butthisdoesnotchangethestateof\ntheexistingcounterthatwassentbythecaller(i.e.,strikes).\nIn contrast, if we were to call goodReset(strikes), this does indeed reset the\ncaller\u2019s counter backtoavalue ofzero. Thatisbecause thevariables candstrikes\nare both reference variables that refer to the same Counter instance. So when\nc.reset()iscalled, thatiseffectively thesameasifstrikes.reset()werecalled.\nwww.it-ebooks.info\n14 Chapter1. JavaPrimer\nDefining Constructors\nAconstructor isaspecial kind ofmethod that isused toinitialize anewly created\ninstance of the class so that it will be in a consistent and stable initial state. This\nis typically achieved by initializing each instance variable of the object (unless\nthe default value will suffice), although a constructor can perform more complex\ncomputation. Thegeneralsyntaxfordeclaring aconstructor inJavaisasfollows:\nmodifiers name(type parameter , ..., type parameter )\n0 0 n\u22121 n\u22121\n{\n// constructor body . . .\n}\nConstructorsaredefinedinaverysimilarwayasothermethodsofaclass,butthere\nareafewimportantdistinctions:\n1. Constructors cannot bestatic,abstract,orfinal,sotheonlymodifiers that\nare allowed are those that affect visibility (i.e., public, protected, private,\northedefaultpackage-level visibility).\n2. The name of the constructor must be identical to the name of the class it\nconstructs. Forexample,whendefiningtheCounterclass,aconstructormust\nbenamedCounteraswell.\n3. We don\u2019t specify a return type for a constructor (not even void). Nor does\nthe body of a constructor explicitly return anything. When a user of a class\ncreatesaninstance usingasyntaxsuchas\nCounter d = new Counter(5);\nthenewoperatorisresponsible forreturning areference tothenewinstance\ntothecaller; theresponsibility oftheconstructor methodisonlytoinitialize\nthestateofthenewinstance.\nA class can have many constructors, but each must have adifferent signature,\nthat is, each must be distinguished by the type and number of the parameters it\ntakes. If no constructors are explicitly defined, Java provides an implicit default\nconstructor fortheclass, having zero arguments andleaving allinstance variables\ninitializedtotheirdefaultvalues. However,ifaclassdefinesoneormorenondefault\nconstructors, nodefault constructor willbeprovided.\nAsanexample,ourCounterclassdefinesthefollowingpairofconstructors:\npublic Counter()\n{ }\npublic Counter(int initial) count = initial;\n{ }\nThefirstofthesehasatrivialbody, ,asthegoalforthisdefaultconstructoristo\n{ }\ncreateacounter withvaluezero,andthatisalreadythedefault valueoftheinteger\ninstance variable, count. However, it is still important that we declared such an\nexplicit constructor, because otherwise none would have been provided, given the\nexistence of the nondefault constructor. In that scenario, a user would have been\nunabletousethesyntax, new Counter().\nwww.it-ebooks.info\n1.2. ClassesandObjects 15\nThe Keyword this\nWithinthebodyofa(nonstatic) methodinJava,thekeywordthisisautomatically\ndefined as a reference to the instance upon which the method was invoked. That\nis, if a caller uses a syntax such as thing.foo(a, b, c), then within the body of\nmethod foo for that call, the keyword this refers to the object known as thing in\nthecaller\u2019s context. There arethree commonreasons whythis reference isneeded\nfromwithinamethodbody:\n1. To store the reference in a variable, or send it as a parameter to another\nmethodthatexpectsaninstance ofthattypeasanargument.\n2. To differentiate between an instance variable and a local variable with the\nsame name. If a local variable is declared in a method having the same\nname as an instance variable for the class, that name will refer to the local\nvariable within that method body. (We say that the local variable masks the\ninstance variable.) In this case, the instance variable can still be accessed\nby explicitly using the dot notation with this as the qualifier. For example,\nsomeprogrammers prefertousethefollowing styleforaconstructor, witha\nparameterhaving thesamenameastheunderlying variable.\npublic Counter(int count)\n{\nthis.count = count; // set the instance variable equal to parameter\n}\n3. Toallowoneconstructorbodytoinvokeanotherconstructorbody. Whenone\nmethod of a class invokes another method of that same class on the current\ninstance, that is typically done by using the (unqualified) name of the other\nmethod. Butthesyntaxforcallingaconstructorisspecial. Javaallowsuseof\nthekeywordthistobeusedasamethodwithinthebodyofoneconstructor,\nsoastoinvoke anotherconstructor withadifferent signature.\nThis is often useful because all of the initialization steps of one constructor\ncan be reused with appropriate parameterization. As a trivial demonstra-\ntion of the syntax, we could reimplement the zero-argument version of our\nCounterconstructor tohaveitinvoketheone-argument versionsending0as\nanexplicitparameter. Thiswouldbewrittenasfollows:\npublic Counter()\n{\nthis(0); // invoke one-parameter constructor with value zero\n}\nWewillprovideamoremeaningfuldemonstrationofthistechniqueinalater\nexampleofaCreditCardclassinSection1.7.\nwww.it-ebooks.info\n16 Chapter1. JavaPrimer\nThe main Method\nSomeJavaclasses,suchasourCounterclass,aremeanttobeusedbyotherclasses,\nbutarenotintendedtoserveasaself-standingprogram. Theprimarycontrolforan\napplicationinJavamustbegininsomeclasswiththeexecutionofaspecialmethod\nnamedmain. Thismethodmustbedeclared asfollows:\npublic static void main(String[ ] args)\n{\n// main method body...\n}\nThe args parameter is an array of String objects, that is, a collection of indexed\nstrings, withthefirststringbeingargs[0],thesecond beingargs[1],andsoon. (We\nsaymoreaboutstringsandarraysinSection1.3.) Thoserepresentwhatareknown\nascommand-lineargumentsthataregivenbyauserwhentheprogramisexecuted.\nJava programs canbecalled from thecommand lineusing thejavacommand\n(inaWindows,Linux,orUnixshell),followedbythenameoftheJavaclasswhose\nmain method we want to run, plus any optional arguments. For example, to exe-\ncute the main method of a class named Aquarium, we could issue the following\ncommand:\njava Aquarium\nInthiscase,theJavaruntimesystemlooksforacompiledversionoftheAquarium\nclass,andtheninvokes thespecial mainmethodinthatclass.\nIf we had defined the Aquarium program to take an optional argument that\nspecifiesthenumberoffishintheaquarium, thenwemightinvoke theprogram by\ntypingthefollowinginashellwindow:\njava Aquarium 45\nto specify that we want an aquarium with 45 fish in it. In this case, args[0] would\nrefertothestring\"45\". Itwouldbeuptothebodyofthemainmethodtointerpret\nthatstringasthedesirednumberoffish.\nProgrammers who use an integrated development environment (IDE), such as\nEclipse, can optionally specify command-line arguments when executing the pro-\ngramthroughtheIDE.\nUnit Testing\nWhen defining a class, such as Counter, that is meant to be used by other classes\nrather than as a self-standing program, there is no need to define a main method.\nHowever, a nice feature of Java\u2019s design is that we could provide such a method\nas a way to test the functionality of that class in isolation, knowing that it would\nnot berun unless wespecifically invoke the javacommand onthat isolated class.\nHowever,formorerobust testing,frameworkssuchasJUnitarepreferred.\nwww.it-ebooks.info\n1.3. Strings,Wrappers,Arrays,andEnumTypes 17\n1.3 Strings, Wrappers, Arrays, and Enum Types\nThe String Class\nJava\u2019scharbasetypestoresavaluethatrepresentsasingletextcharacter. InJava,\nthesetofallpossiblecharacters,knownasanalphabet,istheUnicodeinternational\ncharacter set,a16-bitcharacter encoding thatcovers mostusedwritten languages.\n(Some programming languages use the smaller ASCII character set, which is a\nproper subset of the Unicode alphabet based on a 7-bit encoding.) The form for\nexpressing acharacter literalinJavaisusingsinglequotes,suchas'G'.\nBecause it is common to work with sequences of text characters in programs\n(e.g., for user interactions or data processing), Java provides support in the form\nofaStringclass. Astring instance represents asequence of zero ormore charac-\nters. Theclassprovides extensive support forvarious text-processing tasks, andin\nChapter 13 wewillexamine several ofthe underlying algorithms for text process-\ning. For now, we will only highlight the most central aspects of the String class.\nJava uses double quotes to designate string literals. Therefore, we might declare\nandinitialize aStringinstance asfollows:\nString title = \"Data Structures & Algorithms in Java\"\nCharacter Indexing\nEach character c within a string s can be referenced by using an index, which is\nequal to the number of characters that come before c in s. By this convention, the\nfirstcharacterisatindex0,andthelastisatindexn 1,wherenisthelengthofthe\n\u2212\nstring. Forexample, thestringtitle,definedabove, haslength36. Thecharacter at\nindex 2 is 't' (the third character), and the character at index 4 is ' ' (the space\ncharacter). Java\u2019sStringclasssupportsamethodlength(),whichreturnsthelength\nofastringinstance,andamethodcharAt(k),whichreturnsthecharacteratindexk.\nConcatenation\nTheprimary operation for combining strings is called concatenation, which takes\na string P and a string Q combines them into a new string, denoted P+Q, which\nconsists of all the characters of P followed by all the characters of Q. In Java, the\n\u201c+\u201doperation performsconcatenation whenactingontwostrings, asfollows:\nString term = \"over\" + \"load\";\nThis statement defines a variable named term that references a string with value\n\"overload\". (Wewilldiscussassignmentstatementsandexpressionssuchasthat\naboveinmoredetaillaterinthischapter.)\nwww.it-ebooks.info\n18 Chapter1. JavaPrimer\nThe StringBuilder Class\nAn important trait of Java\u2019s String class is that its instances are immutable; once\naninstance iscreated andinitialized, thevalue ofthatinstance cannot bechanged.\nThis is an intentional design, as it allows for great efficiencies and optimizations\nwithintheJavaVirtualMachine.\nHowever, because String is a class in Java, it is a reference type. Therefore,\nvariables of type String can be reassigned to another string instance (even if the\ncurrentstringinstance cannotbechanged), asinthefollowing:\nString greeting = \"Hello\";\ngreeting = \"Ciao\"; // we changed our mind\nItisalsoquitecommoninJavatousestringconcatenationtobuildanewstringthat\nissubsequently usedtoreplaceoneoftheoperands ofconcatenation, asin:\ngreeting = greeting + '!'; // now it is \u201dCiao!\u201d\nHowever, it is important to remember that this operation does create a new string\ninstance, copying all the characters of the existing string in the process. For long\nstring(suchasDNAsequences), thiscanbeverytimeconsuming. (Infact,wewill\nexperimentwiththeefficiencyofstringconcatenation tobeginChapter4.)\nIn order to support more efficient editing of character strings, Java provides\na StringBuilder class, which is effectively a mutable version of a string. This\nclasscombinessomeoftheaccessor methodsoftheStringclass,whilesupporting\nadditional methodsincluding thefollowing(andmore):\nsetCharAt(k,c): Changethecharacter atindexktocharacter c.\ninsert(k,s): Insertacopyofstringsstartingatindexkofthesequence,\nshifting existingcharacters further backtomakeroom.\nappend(s): Appendstringstotheendofthesequence.\nreverse(): Reversethecurrentsequence.\ntoString(): Return a traditional String instance based on the current\ncharacter sequence.\nAnerror condition occurs, for both Stringand StringBuilderclasses, if an index k\nisoutoftheboundsoftheindicesofthecharacter sequence.\nTheStringBuilderclass can beveryuseful, anditserves asaninteresting case\nstudy for data structures and algorithms. Wewill further explore the empirical ef-\nficiencyoftheStringBuilderclassinSection4.1andthetheoretical underpinnings\nofitsimplementation inSection7.2.4.\nwww.it-ebooks.info\n1.3. Strings,Wrappers,Arrays,andEnumTypes 19\nWrapper Types\nThere are many data structures and algorithms in Java\u2019s libraries that are specif-\nically designed so that they only work with object types (not primitives). To get\naround this obstacle, Java defines awrapper class for each base type. Aninstance\nof each wrapper type stores a single value of the corresponding base type. In Ta-\nble1.2, weshow thebasetypes and theircorresponding wrapperclass, along with\nexamplesofhowobjectsarecreatedandaccessed.\nBaseType ClassName CreationExample AccessExample\nboolean Boolean obj = new Boolean(true); obj.booleanValue()\nchar Character obj = new Character(\u2019Z\u2019); obj.charValue()\nbyte Byte obj = new Byte((byte) 34); obj.byteValue()\nshort Short obj = new Short((short) 100); obj.shortValue()\nint Integer obj = new Integer(1045); obj.intValue()\nlong Long obj = new Long(10849L); obj.longValue()\nfloat Float obj = new Float(3.934F); obj.floatValue()\ndouble Double obj = new Double(3.934); obj.doubleValue()\nTable1.2: Java\u2019s wrapper classes. Each class is given with its corresponding base\ntype and example expressions for creating and accessing such objects. For each\nrow,weassumethevariableobjisdeclaredwiththecorresponding classname.\nAutomatic Boxing and Unboxing\nJava provides additional support for implicitly converting between base types and\ntheirwrappertypesthroughaprocess knownasautomaticboxingandunboxing.\nIn any context for which an Integer is expected (for example, as a parameter),\nan int value k can be expressed, in which case Java automatically boxes the int,\nwith an implicit call to new Integer(k). In reverse, in any context for which an\nint is expected, an Integer value v can be given in which case Java automatically\nunboxesitwithanimplicitcalltov.intValue(). Similarconversionsaremadewith\ntheother base-type wrappers. Finally, allof thewrapper types provide support for\nconvertingbackandforthbetweenstringliterals. CodeFragment1.4demonstrates\nmanysuchfeatures.\n1 int j = 8;\n2 Integer a = new Integer(12);\n3 int k = a; // implicit call to a.intValue()\n4 int m = j + a; // a is automatically unboxed before the addition\n5 a = 3 \u2217 m; // result is automatically boxed before assignment\n6 Integer b = new Integer(\"-135\"); // constructor accepts a String\n7 int n = Integer.parseInt(\"2013\"); // using static method of Integer class\nCodeFragment1.4: Ademonstration oftheuseoftheIntegerwrapperclass.\nwww.it-ebooks.info\n20 Chapter1. JavaPrimer\nArrays\nA common programming task is to keep track of an ordered sequence of related\nvaluesorobjects. Forexample,wemaywantavideogametokeeptrackofthetop\ntenscores forthat game. Ratherthan using tendifferent variables forthis task, we\nwould prefer touse asingle name for the group and use index numbers to refer to\nthehighscoresinthatgroup. Similarly,wemaywantamedicalinformationsystem\ntokeeptrackofthepatientscurrently assignedtobedsinacertainhospital. Again,\nwe would rather not have to introduce 200 variables in our program just because\nthehospitalhas200beds.\nIn such cases, we can save programming effort by using an array, which is a\nsequenced collection ofvariables allofthesametype. Eachvariable, orcell, inan\narrayhasanindex,whichuniquely referstothevalue storedinthatcell. Thecells\nofanarray aarenumbered 0,1,2,andsoon. Weillustrate anarray ofhighscores\nforavideogameinFigure1.3.\nHigh\nscores\nindices\nFigure1.3: Anillustration ofanarrayoften(int)highscoresforavideogame.\nArray Elements and Capacities\nEachvaluestoredinanarrayiscalledanelementofthatarray. Sincethelengthof\nanarraydeterminesthemaximumnumberofthingsthatcanbestoredinthearray,\nwewillsometimesrefertothelengthofanarrayasitscapacity. InJava,thelength\nof an array named a can be accessed using the syntax a.length. Thus, the cells of\nan array a are numbered 0, 1, 2, and so on, up through a.length 1, and the cell\n\u2212\nwithindexkcanbeaccessed withsyntaxa[k].\nOut of Bounds Errors\nItisadangerousmistaketoattempttoindexintoanarrayausinganumberoutside\nthe range from 0 to a.length 1. Such a reference is said to be out of bounds.\n\u2212\nOut of bounds references have been exploited numerous times by hackers using a\nmethod called the buffer overflow attack to compromise the security of computer\nsystemswritteninlanguages otherthanJava. Asasafetyfeature, arrayindices are\nalways checked in Java to see if they are ever out of bounds. If an array index is\noutofbounds, theruntimeJava environment signals anerror condition. Thename\nofthis condition is theArrayIndexOutOfBoundsException. Thischeck helps Java\navoidanumberofsecurity problems,suchasbufferoverflowattacks.\nwww.it-ebooks.info\n1.3. Strings,Wrappers,Arrays,andEnumTypes 21\nDeclaring and Constructing Arrays\nArrays in Java are somewhat unusual, in that they are not technically a base type\nnoraretheyinstancesofaparticularclass. Withthatsaid,aninstanceofanarrayis\ntreatedasanobjectbyJava,andvariablesofanarraytypearereferencevariables.\nTo declare a variable (or parameter) to have an array type, we use an empty\npair of square brackets just after the type of element that the array will store. For\nexample,wemightdeclare:\nint[ ] primes;\nBecause arrays areareference type, thisdeclares thevariable primes tobearefer-\nence to an array of integer values, but it does not immediately construct any such\narray. Therearetwowaysforcreatinganarray.\nThe first way to create an array is to use an assignment to a literal form when\ninitially declaring thearray, usingasyntaxas:\nelementType[]arrayName= initialValue ,initialValue ,...,initialValue ;\n0 1 N\u22121\n{ }\nThe elementType can be any Java base type or class name, and arrayName can be\nany valid Java identifier. The initial values must be of the same type as the array.\nFor example, we could initialize the array of primes to contain the first ten prime\nnumbersas:\nint[ ] primes = 2, 3, 5, 7, 11, 13, 17, 19, 23, 29 ;\n{ }\nWhenusing aninitializer, anarray iscreated having precisely thecapacity needed\ntostoretheindicated values.\nThesecondwaytocreateanarrayistousethenewoperator. However,because\nan array is not an instance of a class, we do not use a typical constructor syntax.\nInsteadweusethesyntax:\nnewelementType[length]\nwhere length is a positive integer denoting the length of the new array. The new\noperatorreturnsareferencetothenewarray,andtypicallythiswouldbeassignedto\nan array variable. Forexample, the following statement declares an array variable\nnamedmeasurements,andimmediately assignsitanewarrayof1000cells.\ndouble[ ] measurements = new double[1000];\nWhen arrays are created using the new operator, all of their elements are au-\ntomatically assigned the default value for the element type. Thatis, ifthe element\ntype is numeric, all cells of the array are initialized to zero, if the element type is\nboolean,allcellsarefalse,andiftheelementtypeisareferencetype(suchaswith\nanarrayofStringinstances), allcellsareinitialized tonull.\nwww.it-ebooks.info\n22 Chapter1. JavaPrimer\nEnum Types\nInoldentimes,programmers wouldoftendefineaseriesofconstant integervalues\nto be used for representing a finite set of choices. For example, in representing a\nday of the week, they might declare variable today as an int and then set it with\nvalue0forMonday, 1forTuesday,andsoon.\nAslightly better programming style istodefinestaticconstants (withthefinal\nkeyword), tomaketheassociations, suchas:\nstatic final int MON = 0;\nstatic final int TUE = 1;\nstatic final int WED = 2;\n...\nbecause then it becomes possible to make assignments such as today = TUE,\nrather than the more obscure today = 1. Unfortunately, the variable today is still\ndeclaredasanintusingsuchaprogrammingstyle,anditmaynotbeclearthatyou\nintend for it to represent a day of the week when storing it as an instance variable\norsending itasaparameter.\nJava supports a more elegant approach to representing choices from a finite\nset by defining what is known as an enumerated type, or enum for short. These\nare types that are only allowed to take on values that come from a specified set of\nnames. Theyaredeclared asfollows:\nmodifier enum name valueName , valueName , ..., valueName ;\n0 1 n\u22121\n{ }\nwhere the modifier can be blank, public, protected, or private. The name of\nthis enum, name, can be any legal Java identifier. Each of the value identifiers,\nvalueName, is the name of a possible value that variables of this enum type can\ni\ntake on. Each of these name values can also be any legal Java identifier, but the\nJavaconvention isthattheseshould usually becapitalized words. Forexample, an\nenumerated typedefinitionfordaysoftheweakmightappearas:\npublic enum Day MON, TUE, WED, THU, FRI, SAT, SUN ;\n{ }\nOnce defined, Day becomes an official type and we may declare variables or pa-\nrameterswithtypeDay. Avariable ofthattypecanbedeclared as:\nDay today;\nandanassignmentofavaluetothatvariablecanappearas:\ntoday = Day.TUE;\nwww.it-ebooks.info\n1.4. Expressions 23\n1.4 Expressions\nVariablesandconstantsareusedinexpressionstodefinenewvaluesandtomodify\nvariables. Inthissection, wediscuss howexpressions workinJava inmoredetail.\nExpressionsinvolvetheuseofliterals,variables, andoperators. Sincewehaveal-\nreadydiscussed variables, letusbrieflyfocusonliteralsandthendiscussoperators\ninsomedetail.\n1.4.1 Literals\nAliteralisany\u201cconstant\u201d valuethatcanbeusedinanassignment orotherexpres-\nsion. Javaallowsthefollowingkindsofliterals:\nThe null object reference (this is the only object literal, and it is allowed to\n\u2022\nbeanyreference type).\nBoolean: trueandfalse.\n\u2022\nInteger: The default for an integer like 176, or -52 is that it is of type int,\n\u2022\nwhich isa 32-bit integer. A long integer literal must end with an \u201cL\u201d or \u201cl\u201d,\nforexample,176Lor-52l,anddefinesa64-bitinteger.\nFloating Point: The default for floating-point numbers, such as 3.1415 and\n\u2022\n135.23, is that they are double. To specify that a literal is a float, it must\nendwithan\u201cF\u201dor\u201cf\u201d. Floating-pointliteralsinexponentialnotationarealso\nallowed,suchas3.14E2or.19e10;thebaseisassumedtobe10.\nCharacter: In Java, character constants are assumed to be taken from the\n\u2022\nUnicode alphabet. Typically, a character is defined as an individual symbol\nenclosedinsinglequotes. Forexample,\u2019a\u2019and\u2019?\u2019 arecharacterconstants.\nInaddition, Javadefinesthefollowingspecial characterconstants:\n'\\n' (newline) '\\t' (tab)\n'\\b' (backspace) '\\r' (return)\n'\\f' (formfeed) '\\\\' (backslash)\n'\\'' (singlequote) '\\\"' (doublequote).\nStringLiteral: Astringliteralisasequence ofcharacters enclosed indouble\n\u2022\nquotes, forexample,thefollowingisastringliteral:\n\"dogs cannot climb trees\"\nwww.it-ebooks.info\n24 Chapter1. JavaPrimer\n1.4.2 Operators\nJava expressions involve composing literals and variables with operators. We will\nsurveytheoperators inJavainthissection.\nArithmetic Operators\nThefollowingarebinaryarithmeticoperators inJava:\n+ addition\nsubtraction\n\u2212\n\u2217 multiplication\n/ division\n% themodulooperator\nThislastoperator, modulo, isalsoknownasthe\u201cremainder\u201d operator, because\nitistheremainderleftafteranintegerdivision. Weoftenuse\u201cmod\u201dtodenote the\nmodulooperator, andwedefineitformallyas\nnmod m=r,\nsuchthat\nn=mq+r,\nforanintegerqand0 r<m.\n\u2264\nJavaalsoprovidesaunaryminus( ),whichcanbeplacedinfrontofanarith-\n\u2212\nmetic expression to invert its sign. Parentheses can be used in any expression to\ndefinetheorder ofevaluation. Javaalso usesafairly intuitive operator precedence\nrule to determine the order of evaluation when parentheses are not used. Unlike\nC++,Javadoesnotallowoperatoroverloading forclasstypes.\nString Concatenation\nWithstrings, the(+)operatorperformsconcatenation, sothatthecode\nString rug = \"carpet\";\nString dog = \"spot\";\nString mess = rug + dog;\nString answer = mess + \" will cost me \" + 5 + \" hours!\";\nwouldhavetheeffectofmakinganswerrefertothestring\n\"carpetspot will cost me 5 hours!\"\nThisexamplealsoshowshowJavaconvertsnonstringvalues(suchas5)intostrings,\nwhentheyareinvolved inastringconcatenation operation.\nwww.it-ebooks.info\n1.4. Expressions 25\nIncrement and Decrement Operators\nLikeCandC++,Javaprovidesincrement anddecrementoperators. Specifically,it\nprovides the plus-one increment (++) and decrement ( ) operators. If such an\n\u2212\u2212\noperator is used in front of a variable reference, then 1 is added to (or subtracted\nfrom) the variable and its value is read into the expression. If it is used after a\nvariable reference, then the value is first read and then the variable is incremented\nordecremented by1. So,forexample,thecodefragment\nint i = 8;\nint j = i++; // j becomes 8 and then i becomes 9\nint k = ++i; // i becomes 10 and then k becomes 10\nint m = i ; // m becomes 10 and then i becomes 9\n\u2212\u2212\nint n = 9 + i; // i becomes 8 and then n becomes 17\n\u2212\u2212\nassigns8toj,10tok,10tom,17ton,andreturnsitovalue8,asnoted.\nLogical Operators\nJavasupports thestandard comparisons operators betweennumbers:\n< lessthan\n<= lessthanorequalto\n== equalto\n!= notequalto\n>= greaterthanorequalto\n> greaterthan\nThetypeoftheresultofanyofthesecomparison isaboolean. Comparisons may\nalso be performed on char values, with inequalities determined according to the\nunderlying charactercodes.\nFor reference types, it is important to know that the operators == and != are\ndefined so that expression a == b is true if a and b both refer to the identical\nobject (or are both null). Most object types support an equals method, such that\na.equals(b)istrueifaandbrefertowhataredeemedas\u201cequivalent\u201dinstancesfor\nthatclass(evenifnotthesameinstance); seeSection3.5forfurtherdiscussion.\nOperatorsdefinedforbooleanvaluesarethefollowing:\n! not(prefix)\n&& conditional and\nconditional or\n||\nThebooleanoperators&&and willnotevaluatethesecondoperand(totheright)\n||\nintheirexpression ifitisnotneededtodeterminethevalueoftheexpression. This\n\u201cshortcircuiting\u201dfeatureisusefulforconstructing booleanexpressions wherewe\nfirsttestthatacertainconditionholds(suchasanarrayindexbeingvalid)andthen\ntestaconditionthatcouldhaveotherwisegeneratedanerrorconditionhadtheprior\ntestnotsucceeded.\nwww.it-ebooks.info\n26 Chapter1. JavaPrimer\nBitwise Operators\nJavaalsoprovides thefollowingbitwiseoperators forintegersandbooleans:\nbitwisecomplement (prefixunaryoperator)\n\u223c\n& bitwiseand\nbitwiseor\n|\n\u02c6 bitwiseexclusive-or\n<< shiftbitsleft,fillinginwithzeros\n>> shiftbitsright,fillinginwithsignbit\n>>> shiftbitsright,fillinginwithzeros\nThe Assignment Operator\nThestandard assignment operator inJava is \u201c=\u201d. Itisused to assign avalue toan\ninstance variableorlocalvariable. Itssyntaxisasfollows:\nvariable = expression\nwherevariablereferstoavariablethatisallowedtobereferencedbythestatement\nblockcontainingthisexpression. Thevalueofanassignmentoperationisthevalue\nof theexpression that wasassigned. Thus, ifjand k areboth declared as type int,\nitiscorrecttohaveanassignment statementlikethefollowing:\nj = k = 25; // works because \u2019=\u2019 operators are evaluated right-to-left\nCompound Assignment Operators\nBesidesthestandardassignmentoperator(=),Javaalsoprovidesanumberofother\nassignment operators that combine a binary operation with an assignment. These\notherkindsofoperators areofthefollowingform:\nvariable op=expression\nwhereopisanybinaryoperator. Theaboveexpression isgenerally equivalent to\nvariable =variable opexpression\nsothatx \u2217= 2isequivalenttox = x \u2217 2. However,ifvariablecontainsanexpres-\nsion(forexample,anarrayindex),theexpressionisevaluatedonlyonce. Thus,the\ncodefragment\na[5] = 10;\nj = 5;\na[j++] += 2; // not the same as a[j++] = a[j++] + 2\nleavesa[5]withvalue12andjwithvalue6.\nwww.it-ebooks.info\n1.4. Expressions 27\nOperator Precedence\nOperators inJavaaregivenpreferences, orprecedence, thatdeterminetheorderin\nwhich operations are performed when the absence of parentheses brings up eval-\nuation ambiguities. For example, we need a way of deciding if the expression,\n\u201c5+2*3,\u201d has value 21 or 11 (Java says it is 11). We show the precedence of the\noperators inJava(which,incidentally, isthesameasinCandC++)inTable1.3.\nOperatorPrecedence\nType Symbols\n1 arrayindex [ ]\nmethodcall ()\ndotoperator .\n2 postfixops exp++ exp\n\u2212\u2212\nprefixops ++exp exp +exp exp \u02dcexp !exp\n\u2212\u2212 \u2212\ncast (type)exp\n3 mult./div. \u2217 / %\n4 add./subt. +\n\u2212\n5 shift << >> >>>\n6 comparison < <= > >= instanceof\n7 equality == !=\n8 bitwise-and &\n9 bitwise-xor \u02c6\n10 bitwise-or\n|\n11 and &&\n12 or\n||\n13 conditional booleanExpression? valueIfTrue: valueIfFalse\n14 assignment = += = \u2217= /= %= <<= >>= >>>= &= \u02c6= =\n\u2212 |\nTable1.3: TheJava precedence rules. Operators inJavaareevaluated according to\ntheorderingaboveifparentheses arenotusedtodeterminetheorderofevaluation.\nOperators on the same line are evaluated in left-to-right order (except for assign-\nment and prefix operations, which are evaluated in right-to-left order), subject to\nthe conditional evaluation rule for boolean && and operations. The operations\n||\nare listed from highest to lowest precedence (we use exp to denote an atomic or\nparenthesized expression). Without parenthesization, higher precedence operators\nareperformedbeforelowerprecedence operators.\nWehavenowdiscussedalmostalloftheoperatorslistedinTable1.3. Anotable\nexception is the conditional operator, which involves evaluating a boolean expres-\nsion and then taking on the appropriate value depending on whether this boolean\nexpression is true or false. (We discuss the use of the instanceof operator in the\nnextchapter.)\nwww.it-ebooks.info\n28 Chapter1. JavaPrimer\n1.4.3 Type Conversions\nCastingisanoperationthatallowsustochangethetypeofavalue. Inessence, we\ncan take a value of one type and cast it into an equivalent value of another type.\nTherearetwoformsofcastinginJava: explicitcastingandimplicitcasting.\nExplicit Casting\nJavasupports anexplicitcastingsyntaxwiththefollowingform:\n(type)exp\nwhere type is the type that we would like the expression exp to have. This syntax\nmay only be used to cast from one primitive type to another primitive type, or\nfromonereference typetoanotherreference type. Wewilldiscussitsusebetween\nprimitiveshere,andbetweenreference typesinSection2.5.1.\nCasting from an int to a double is known as a widening cast, as the double\ntype is more broad than the int type, and a conversion can be performed without\nlosinginformation. Butacastfromadoubletoanintisanarrowingcast;wemay\nloseprecision,asanyfractionalportionofthevaluewillbetruncated. Forexample,\nconsider thefollowing:\ndouble d1 = 3.2;\ndouble d2 = 3.9999;\nint i1 = (int) d1; // i1 gets value 3\nint i2 = (int) d2; // i2 gets value 3\ndouble d3 = (double) i2; // d3 gets value 3.0\nAlthoughexplicitcastingcannotdirectlyconvertaprimitivetypetoareference\ntype, or vice versa, there are other means for performing such type conversions.\nWe already discussed, as part of Section 1.3, conversions between Java\u2019s primi-\ntive types and corresponding wrapper classes (such as int and Integer). For con-\nvenience, those wrapper classes also provide static methods that convert between\ntheircorresponding primitivetypeandStringvalues.\nForexample,theInteger.toStringmethodacceptsanintparameterandreturns\naStringrepresentation ofthatinteger, whiletheInteger.parseIntmethodaccepts a\nString as a parameter and returns the corresponding int value that the string rep-\nresents. (If that string does not represent an integer, a NumberFormatException\nresults.) Wedemonstrate theiruseasfollows:\nString s1 = \"2014\";\nint i1 = Integer.parseInt(s1); // i1 gets value 2014\nint i2 = 35;\n\u2212\nString s2 = Integer.toString(i2); // s2 gets value \u201d-35\u201d\nSimilarmethodsaresupported byotherwrappertypes,suchasDouble.\nwww.it-ebooks.info\n1.4. Expressions 29\nImplicit Casting\nThere are cases where Java will perform an implicit cast based upon the context\nofanexpression. Forexample,youcanperformawideningcastbetweenprimitive\ntypes(suchasfromaninttoadouble),withoutexplicituseofthecastingoperator.\nHowever, if attempting to do an implicit narrowing cast, a compiler error results.\nFor example, the following demonstrates both a legal and an illegal implicit cast\nviaassignment statements:\nint i1 = 42;\ndouble d1 = i1; // d1 gets value 42.0\ni1 = d1; // compile error: possible loss of precision\nImplicitcastingalsooccurswhenperformingarithmeticoperationsinvolving a\nmixtureofnumerictypes. Mostnotably, whenperforminganoperation withanin-\ntegertypeasoneoperandandafloating-pointtypeastheotheroperand,theinteger\nvalue is implicitly converted to a floating-point type before the operation is per-\nformed. Forexample, the expression 3 + 5.7 is implicitly converted to 3.0 + 5.7\nbeforecomputing theresulting doublevalueof8.7.\nIt is common to combine an explicit cast and an implicit cast to perform a\nfloating-point division on two integer operands. The expression (double) 7 / 4\nproducestheresult1.75,becauseoperatorprecedencedictatesthatthecasthappens\nfirst, as ( (double) 7) / 4, and thus 7.0 / 4, which implicitly becomes 7.0 / 4.0.\nNotehoweverthattheexpression, (double) (7 / 4)produces theresult1.0.\nIncidentally,thereisonesituationinJavawhenonlyimplicitcastingisallowed,\nandthatisinstringconcatenation. Anytimeastringisconcatenatedwithanyobject\norbasetype,thatobjectorbasetypeisautomaticallyconvertedtoastring. Explicit\ncasting of an object or base type to a string is not allowed, however. Thus, the\nfollowingassignments areincorrect:\nString s = 22; // this is wrong!\nString t = (String) 4.5; // this is wrong!\nString u = \"Value = \" + (String) 13; // this is wrong!\nToperform a conversion to a string, wemust use the appropriate toStringmethod\nor perform an implicit cast via the concatenation operation. Thus, the following\nstatements arecorrect:\nString s = Integer.toString(22); // this is good\nString t = \"\" + 4.5; // correct, but poor style\nString u = \"Value = \" + 13; // this is good\nwww.it-ebooks.info\n30 Chapter1. JavaPrimer\n1.5 Control Flow\nControlflowinJavaissimilartothatofotherhigh-level languages. Wereviewthe\nbasicstructure andsyntax ofcontrol flowinJavainthissection, including method\nreturns, if statements, switch statements, loops, and restricted forms of \u201cjumps\u201d\n(thebreakandcontinuestatements).\n1.5.1 The If and Switch Statements\nInJava,conditionals worksimilarlytothewaytheyworkinotherlanguages. They\nprovideawaytomakeadecisionandthenexecuteoneormoredifferentstatement\nblocksbasedontheoutcomeofthatdecision.\nThe If Statement\nThesyntaxofasimpleif statement isasfollows:\nif (booleanExpression)\ntrueBody\nelse\nfalseBody\nwherebooleanExpression isaboolean expression andtrueBody andfalseBody are\neacheither asingle statement orablock ofstatements enclosed inbraces (\u201c \u201d and\n{\n\u201c \u201d). Notethat, unlike somesimilar languages, thevalue tested by anif statement\n}\nin Java must be a boolean expression. In particular, it is definitely not an integer\nexpression. Nevertheless, asinothersimilarlanguages, theelsepart(anditsasso-\nciated statement) in aJava if statement is optional. There is also a way togroup a\nnumberofbooleantests, asfollows:\nif (firstBooleanExpression)\nfirstBody\nelse if (secondBooleanExpression)\nsecondBody\nelse\nthirdBody\nIfthefirstbooleanexpressionisfalse,thesecondbooleanexpressionwillbetested,\nand so on. An if statement can have an arbitrary number of else if parts. Braces\ncanbeusedforanyorallstatementbodies todefinetheirextent.\nwww.it-ebooks.info\n1.5. ControlFlow 31\nAsasimpleexample,arobotcontroller mighthavethefollowinglogic:\nif (door.isClosed())\ndoor.open();\nadvance();\nNotice that the final command, advance(), is not part of the conditional body; it\nwillbeexecutedunconditionally (although afteropeningacloseddoor).\nWemaynestonecontrol structure withinanother, relying onexplicit bracesto\nmarktheextentofthevariousbodiesifneeded. Revisitingourrobotexample,here\nisamorecomplexcontrol thataccounts forunlocking acloseddoor.\nif (door.isClosed())\n{\nif (door.isLocked())\ndoor.unlock();\ndoor.open();\n}\nadvance();\nThelogicexpressedbythisexamplecanbediagrammedasatraditional flowchart,\nasportrayed inFigure1.4.\nfalse true\ndoor.isClosed()\nfalse true\ndoor.isLocked()\ndoor.unlock()\ndoor.open()\nadvance()\nFigure1.4: Aflowchartdescribing thelogicofnestedconditional statements.\nwww.it-ebooks.info\n32 Chapter1. JavaPrimer\nThefollowingisanexampleofthenestingofifandelseclauses.\nif (snowLevel < 2)\n{\ngoToClass();\ncomeHome();\nelse if (snowLevel < 5)\n} {\ngoSledding();\nhaveSnowballFight();\nelse\n}\nstayAtHome(); // single-statement body needs no braces\n{ }\nSwitch Statements\nJavaprovides formultiple-value control flowusingtheswitchstatement, whichis\nespecially useful with enum types. The following is an indicative example (based\nonavariabledoftheDayenumtypeofSection1.3).\nswitch (d)\n{\ncase MON:\nSystem.out.println(\"This is tough.\");\nbreak;\ncase TUE:\nSystem.out.println(\"This is getting better.\");\nbreak;\ncase WED:\nSystem.out.println(\"Half way there.\");\nbreak;\ncase THU:\nSystem.out.println(\"I can see the light.\");\nbreak;\ncase FRI:\nSystem.out.println(\"Now we are talking.\");\nbreak;\ndefault:\nSystem.out.println(\"Day off!\");\n}\nThe switch statement evaluates an integer, string, or enum expression and\ncauses control flow to jump to the code location labeled with the value of this\nexpression. Ifthereisnomatchinglabel,thencontrolflowjumpstothelocationla-\nbeled\u201cdefault.\u201d Thisistheonlyexplicitjumpperformedbytheswitchstatement,\nhowever,soflowofcontrol\u201cfallsthrough\u201d tothenextcaseifthecodeforacaseis\nnotendedwithabreakstatement (whichcausescontrolflowtojumptotheend).\nwww.it-ebooks.info\n1.5. ControlFlow 33\n1.5.2 Loops\nAnotherimportantcontrolflowmechanism inaprogramminglanguage islooping.\nJavaprovides forthreetypesofloops.\nWhile Loops\nThe simplest kind of loop in Java is a while loop. Such a loop tests that a certain\nconditionissatisfiedandwillperformthebodyoftheloopeachtimethiscondition\nis evaluated to be true. The syntax for such a conditional test before a loop body\nisexecutedisasfollows:\nwhile (booleanExpression)\nloopBody\nAs with an if statement, booleanExpression, can be an arbitrary boolean expres-\nsion, and the body of the loop can be an arbitrary block of code (including nested\ncontrolstructures). Theexecutionofawhileloopbeginswithatestoftheboolean\ncondition. If that condition evaluates to true, the body of the loop is performed.\nAfter each execution of the body, the loop condition is retested and if it evaluates\nto true, another iteration of the body is performed. If the condition evaluates to\nfalsewhentested(assumingiteverdoes),theloopisexitedandtheflowofcontrol\ncontinues justbeyondthebodyoftheloop.\nAs an example, here is a loop that advances an index through an array named\ndatauntilfindinganentrywithvaluetargetorreaching theendofthearray.\nint j = 0;\nwhile ((j < data.length) && (data[j] != target))\nj++;\nWhenthisloopterminates,variablej\u2019svaluewillbetheindexoftheleftmostoccur-\nrenceoftarget,iffound,orotherwisethelengthofthearray(whichisrecognizable\nas an invalid index to indicate failure of the search). The correctness of the loop\nrelies on the short-circuiting behavior of the logical && operator, as described on\npage 25. We intentionally test j < data.length to ensure that j is a valid index,\nprior to accessing element data[j]. Had we written that compound condition with\ntheoppositeorder,theevaluationofdata[j]wouldeventuallythrowanArrayIndex-\nOutOfBoundsExceptionifthetargetisnotfound. (SeeSection 2.4fordiscussion\nofexceptions.)\nWe note that a while loop will execute its body zero times in the case that the\ninitialconditionfails. Forexample,ouraboveloopwillnotincrementthevalueofj\nifdata[0]matchesthetarget(orifthearrayhaslength0).\nwww.it-ebooks.info\n34 Chapter1. JavaPrimer\nDo-While Loops\nJava has another form of the while loop that allows the boolean condition to be\ncheckedattheendofeachpassoftheloopratherthanbeforeeachpass. Thisform\nisknownasado-whileloop,andhassyntax shownbelow:\ndo\nloopBody\nwhile(booleanExpression)\nA consequence of the do-while loop is that its body always executes at least\nonce. (Incontrast,awhileloopwillexecutezerotimesiftheinitialconditionfails.)\nThis form is most useful for a situation in which the condition is ill-defined until\nafter atleast one pass. Consider, for example, that wewant to prompt the user for\ninput and then do something useful with that input. (We discuss Java input and\noutputinmoredetailinSection1.6.) Apossible condition, inthiscase, forexiting\nthe loop is when the user enters an empty string. However, even in this case, we\nmay want to handle that input and inform the user that he or she has quit. The\nfollowingexampleillustrates thiscase:\nString input;\ndo\n{\ninput = getInputString();\nhandleInput(input);\nwhile (input.length() > 0);\n}\nFor Loops\nAnotherkindofloopistheforloop. Javasupportstwodifferent stylesofforloop.\nThefirst,whichwewillrefertoasthe\u201ctraditional\u201dstyle,ispatternedafterasimilar\nsyntaxasforloopsintheCandC++languages. Thesecondstyle,whichisknown\nasthe\u201cfor-each\u201dloop,wasintroducedintoJavain2004aspartoftheSE5release.\nThis style provides a more succinct syntax for iterating through elements of an\narrayoranappropriate container type.\nThe traditional for-loop syntax consists of four sections\u2014an initialization, a\nboolean condition, an increment statement, and the body\u2014although any of those\ncanbeempty. Thestructure isasfollows:\nfor (initialization; booleanCondition; increment)\nloopBody\nFor example, the most common use of a for loop provides repetition based on an\nintegerindex,suchasthefollowing:\nfor (int j=0; j < n; j++)\n// do something\nwww.it-ebooks.info\n1.5. ControlFlow 35\nThebehavior ofaforloopisverysimilartothefollowingwhileloopequivalent:\n{\ninitialization;\nwhile (booleanCondition)\n{\nloopBody;\nincrement;\n}\n}\nTheinitializationsectionwillbeexecutedonce,beforeanyotherportionoftheloop\nbegins. Traditionally, it is used to either initialize existing variables, or to declare\nand initialize new variables. Note that any variables declared in the initialization\nsectiononlyexistinscopefortheduration oftheforloop.\nThe booleanCondition will be evaluated immediately before each potential it-\neration of the loop. It should be expressed similar to a while-loop condition, in\nthat ifit is true, the loop body isexecuted, and if false, the loop isexited and the\nprogram continues tothenextstatementbeyondthefor-loopbody.\nTheincrementsectionisexecutedimmediatelyaftereachiterationoftheformal\nloop body, and is traditionally used to update the value of the primary loop vari-\nable. However, the incrementing statement can be any legal statement, allowing\nsignificant flexibilityincoding.\nAsa concrete example, here is amethod that computes the sum of an array of\ndoublevaluesusingaforloop:\npublic static double sum(double[ ] data)\n{\ndouble total = 0;\nfor (int j=0; j < data.length; j++) // note the use of length\ntotal += data[j];\nreturn total;\n}\nAs one further example, the following method computes the maximum value\nwithina(nonempty) array.\npublic static double max(double[ ] data)\n{\ndouble currentMax = data[0]; // assume first is biggest (for now)\nfor (int j=1; j < data.length; j++) // consider all other entries\nif (data[j] > currentMax) // if data[j] is biggest thus far...\ncurrentMax = data[j]; // record it as the current max\nreturn currentMax;\n}\nNoticethataconditionalstatementisnestedwithinthebodyoftheloop,andthatno\nexplicit \u201c \u201d and \u201c \u201d braces are needed for the loop body, as the entire conditional\n{ }\nconstruct servesasasinglestatement.\nwww.it-ebooks.info\n36 Chapter1. JavaPrimer\nFor-Each Loop\nSince looping through elements of a collection is such a common construct, Java\nprovides ashorthand notation forsuchloops, called thefor-each loop. Thesyntax\nforsuchaloopisasfollows:\nfor(elementType name: container)\nloopBody\nwhere container is an array of the given elementType (or a collection that imple-\nmentstheIterableinterface, aswewilllaterdiscussinSection7.4.1).\nRevisiting a previous example, the traditional loop for computing the sum of\nelementsinanarrayofdoublevaluescanbewrittenas:\npublic static double sum(double[ ] data)\n{\ndouble total = 0;\nfor (double val : data) // Java\u2019s for-each loop style\ntotal += val;\nreturn total;\n}\nWhen using a for-each loop, there is no explicit use of array indices. The loop\nvariable represents one particular element of the array. However, within the body\noftheloop,thereisnodesignation astowhichelementitis.\nItisalsoworthemphasizingthatmakinganassignmenttotheloopvariablehas\nno effect on the underlying array. Therefore, the following method is an invalid\nattempttoscaleallvaluesofanumericarray.\npublic static void scaleBad(double[ ] data, double factor)\n{\nfor (double val : data)\nval \u2217= factor; // changes local variable only\n}\nIn order to overwrite the values in the cells of an array, we must make use of\nindices. Therefore, this task is best solved with a traditional for loop, such as the\nfollowing:\npublic static void scaleGood(double[ ] data, double factor)\n{\nfor (int j=0; j < data.length; j++)\ndata[j] \u2217= factor; // overwrites cell of the array\n}\nwww.it-ebooks.info\n1.5. ControlFlow 37\n1.5.3 Explicit Control-Flow Statements\nJava also provides statements that cause explicit change in theflowofcontrol of a\nprogram.\nReturning from a Method\nIfaJavamethodisdeclaredwithareturntypeofvoid,thenflowofcontrolreturns\nwhen itreaches the last line ofcode inthe method orwhenit encounters areturn\nstatement (withnoargument). Ifamethodisdeclared withareturntype, however,\nthemethodmustexitbyreturning anappropriate valueasanargument toareturn\nstatement. Itfollowsthatthereturnstatement mustbethelaststatement executed\ninamethod,astherestofthecodewillneverbereached.\nNotethatthereisasignificantdifferencebetweenastatementbeingthelastline\nof code that is executed in a method and the last line of code in the method itself.\nThefollowing(correct) exampleillustrates returning fromamethod:\npublic double abs(double value)\n{\nif (value < 0) // value is negative,\nreturn value; // so return its negation\n\u2212\nreturn value; // return the original nonnegative value\n}\nIn the example above, the line return value; is clearly not the last line of\n\u2212\ncodethatiswritteninthemethod,butitmaybethelastlinethatisexecuted(ifthe\noriginalvalueisnegative). Suchastatementexplicitlyinterruptstheflowofcontrol\ninthemethod. Therearetwoothersuchexplicitcontrol-flowstatements,whichare\nusedinconjunction withloopsandswitchstatements.\nThe break Statement\nWe first introduced use of the break command, in Section 1.5.1, to exit from the\nbody of a switch statement. More generally, it can be used to \u201cbreak\u201d out of the\ninnermost switch, for,while, ordo-whilestatement body. Whenitisexecuted, a\nbreakstatementcausestheflowofcontroltojumptothenextlineaftertheloopor\nswitchtothebodycontaining thebreak.\nThe continue Statement\nA continue statement can be used within a loop. It causes the execution to skip\nover the remaining steps of the current iteration of the loop body, but then, unlike\nthebreakstatement,theflowofcontrolreturnstothetopoftheloop,assumingits\ncondition remainssatisfied.\nwww.it-ebooks.info\n38 Chapter1. JavaPrimer\n1.6 Simple Input and Output\nJava provides a rich set of classes and methods for performing input and output\nwithin a program. There are classes in Java for doing graphical user interface de-\nsign,completewithpop-upwindowsandpull-downmenus,aswellasmethodsfor\nthe display and input of text and numbers. Java also provides methods for deal-\ning with graphical objects, images, sounds, Web pages, and mouse events (such\nas clicks, mouse overs, and dragging). Moreover, many of these input and output\nmethodscanbeusedineitherstand-alone programsorinapplets.\nUnfortunately, going into the details on how all of the methods work for con-\nstructing sophisticated graphical user interfaces is beyond the scope of this book.\nStill,forthesakeofcompleteness, wedescribehowsimpleinputandoutputcanbe\ndoneinJavainthissection.\nSimple input and output in Java occurs within the Java console window. De-\npending on the Java environment we are using, this window is either a special\npop-up window that can be used for displaying and inputting text, or a window\nused to issue commands to the operating system (such windows are referred to as\nshellwindows,commandwindows,orterminalwindows).\nSimple Output Methods\nJava provides a built-in static object, called System.out, that performs output to\nthe \u201cstandard output\u201d device. Most operating system shells allow users toredirect\nstandard output to files or even as input to other programs, but the default out-\nput is to the Java console window. The System.out object is an instance of the\njava.io.PrintStreamclass. Thisclassdefinesmethodsforabufferedoutputstream,\nmeaning that characters are put in a temporary location, called a buffer, which is\nthenemptiedwhentheconsole windowisreadytoprintcharacters.\nSpecifically, the java.io.PrintStreamclass provides the following methods for\nperformingsimpleoutput(weusebaseTypeheretorefertoanyofthepossiblebase\ntypes):\nprint(Strings): Printthestrings.\nprint(Object o): PrinttheobjectousingitstoStringmethod.\nprint(baseType b): Printthebasetypevalueb.\nprintln(Strings): Printthestrings,followedbythenewlinecharacter.\nprintln(Object o): Similartoprint(o),followedbythenewlinecharacter.\nprintln(baseType b): Similartoprint(b),followedbythenewlinecharacter.\nwww.it-ebooks.info\n1.6. SimpleInputandOutput 39\nAn Output Example\nConsider, forexample,thefollowingcodefragment:\nSystem.out.print(\"Java values: \");\nSystem.out.print(3.1416);\nSystem.out.print(',');\nSystem.out.print(15);\nSystem.out.println(\" (double,char,int).\");\nWhenexecuted,thisfragmentwilloutputthefollowingintheJavaconsolewindow:\nJava values: 3.1416,15 (double,char,int).\nSimple Input Using the java.util.Scanner Class\nJust as there is aspecial object for performing output tothe Java console window,\nthere isalso aspecial object, called System.in,for performing input from the Java\nconsole window. Technically, the input is actually coming from the \u201cstandard in-\nput\u201d device, which by default is the computer keyboard echoing its characters in\nthe Java console. The System.in object is an object associated with the standard\ninput device. Asimplewayofreading input withthisobject istouse ittocreate a\nScannerobject,usingtheexpression\nnew Scanner(System.in)\nThe Scanner class has a number of convenient methods that read from the given\ninputstream,oneofwhichisdemonstrated inthefollowingprogram:\nimport java.util.Scanner; // loads Scanner definition for our use\npublic class InputExample\n{\npublic static void main(String[ ] args)\n{\nScanner input = new Scanner(System.in);\nSystem.out.print(\"Enter your age in years: \");\ndouble age = input.nextDouble();\nSystem.out.print(\"Enter your maximum heart rate: \");\ndouble rate = input.nextDouble();\ndouble fb = (rate age) \u2217 0.65;\n\u2212\nSystem.out.println(\"Your ideal fat-burning heart rate is \" + fb);\n}\n}\nWhenexecuted,thisprogramcouldproducethefollowingontheJavaconsole:\nEnter your age in years: 21\nEnter your maximum heart rate: 220\nYour ideal fat-burning heart rate is 129.35\nwww.it-ebooks.info\n40 Chapter1. JavaPrimer\njava.util.Scanner Methods\nThe Scanner class reads the input stream and divides it into tokens, which are\nstrings of characters separated by delimiters. A delimiter is a special separating\nstring, and the default delimiter is whitespace. That is, tokens are separated by\nstringsofspaces,tabs,andnewlines,bydefault. Tokenscaneitherbereadimmedi-\nately asstrings oraScannerobject canconvert atoken toabase type, ifthetoken\nhas the right form. Specifically, the Scanner class includes the following methods\nfordealingwithtokens:\nhasNext(): Returntrueifthereisanothertokenintheinputstream.\nnext(): Returnthenexttokenstringintheinputstream;generate\nanerroriftherearenomoretokensleft.\nhasNextType(): Return trueif there is another token in the input stream\nand itcan beinterpreted asthecorresponding base type,\nType, where Type can be Boolean, Byte, Double, Float,\nInt,Long,orShort.\nnextType(): Return the next token in the input stream, returned as\nthebasetype corresponding toType;generate anerrorif\nthere are no more tokens left or if the next token cannot\nbeinterpreted asabasetypecorresponding toType.\nAdditionally, Scanner objects can process input line by line, ignoring delim-\niters, and even look for patterns within lines while doing so. The methods for\nprocessing inputinthiswayincludethefollowing:\nhasNextLine(): Returnstrueiftheinputstreamhasanother lineoftext.\nnextLine(): Advances the input past the current line ending and re-\nturnstheinputthatwasskipped.\nfindInLine(Strings): Attempts to find a string matching the (regular expres-\nsion) pattern sinthecurrent line. Ifthepattern isfound,\nit is returned and the scanner advances to the first char-\nacter after this match. If the pattern is not found, the\nscanner returnsnullanddoesn\u2019t advance.\nThesemethodscanbeusedwiththoseabove,asinthefollowing:\nScanner input = new Scanner(System.in);\nSystem.out.print(\"Please enter an integer: \");\nwhile (!input.hasNextInt())\n{\ninput.nextLine();\nSystem.out.print(\"Invalid integer; please enter an integer: \");\n}\nint i = input.nextInt();\nwww.it-ebooks.info\n1.7. AnExampleProgram 41\n1.7 An Example Program\nInthis section, wepresent another example ofaJavaclass, which illustrates many\nof the constructs defined thus far in this chapter. This CreditCard class defines\ncreditcardobjects thatmodelasimplifiedversion oftraditional credit cards. They\nstore information about thecustomer, issuing bank, account identifier, creditlimit,\nand current balance. They do not charge interest or late payments, but they do\nrestrict charges that would cause a card\u2019s balance to go over its credit limit. We\nalsoprovideastaticmainmethodaspartofthisclasstodemonstrate itsuse.\nThe primary definition of the CreditCard class is given in Code Fragment 1.5.\nWedeferuntilCodeFragment1.6thepresentationofthemainmethod,andinCode\nFragment 1.7 we show the output produced by the main method. Highlights of\nthisclass,andunderlying techniques thataredemonstrated, include:\nThe class defines five instance variables (lines 3\u20137), four of which are de-\n\u2022\nclared asprivateand onethat isprotected. (Wewilltake advantage ofthe\nprotected balance member when introducing inheritance in the next chap-\nter.)\nThe class defines two different constructor forms. The first version (begin-\n\u2022\nning at line 9) requires five parameters, including an explicit initial balance\nfor the account. The second constructor (beginning at line 16) accepts only\nfour parameters; it relies on use of the special this keyword to invoke the\nfive-parameter version, with an explicit initial balance of zero (a reasonable\ndefault formostnewaccounts).\nTheclass defines fivebasic accessor methods (lines 20\u201324), and twoupdate\n\u2022\nmethods (charge and makePayment). The charge method relies on condi-\ntionallogictoensurethatachargeisrejected ifitwouldhaveresulted inthe\nbalance exceeding thecreditlimitonthecard.\nWeprovideastaticutilitymethod,namedprintSummary,inlines37\u201343.\n\u2022\nThe main method includes an array, named wallet, storing CreditCard in-\n\u2022\nstances. The main method also demonstrates a while loop, a traditional\nforloop,andafor-each loopoverthecontents ofthewallet.\nThe main method demonstrates the syntax for calling traditional (nonstatic)\n\u2022\nmethods\u2014charge,getBalance,andmakePayment\u2014aswellasthesyntaxfor\ninvoking thestaticprintSummarymethod.\nwww.it-ebooks.info\n42 Chapter1. JavaPrimer\n1 public class CreditCard\n{\n2 // Instance variables:\n3 private String customer; // name of the customer (e.g., \u201dJohn Bowman\u201d)\n4 private String bank; // name of the bank (e.g., \u201dCalifornia Savings\u201d)\n5 private String account; // account identifier (e.g., \u201d5391 0375 9387 5309\u201d)\n6 private int limit; // credit limit (measured in dollars)\n7 protected double balance; // current balance (measured in dollars)\n8 // Constructors:\n9 public CreditCard(String cust, String bk, String acnt, int lim, double initialBal)\n{\n10 customer = cust;\n11 bank = bk;\n12 account = acnt;\n13 limit = lim;\n14 balance = initialBal;\n15\n}\n16 public CreditCard(String cust, String bk, String acnt, int lim)\n{\n17 this(cust, bk, acnt, lim, 0.0); // use a balance of zero as default\n18\n}\n19 // Accessor methods:\n20 public String getCustomer() return customer;\n{ }\n21 public String getBank() return bank;\n{ }\n22 public String getAccount() return account;\n{ }\n23 public int getLimit() return limit;\n{ }\n24 public double getBalance() return balance;\n{ }\n25 // Update methods:\n26 public boolean charge(double price) // make a charge\n{\n27 if (price + balance > limit) // if charge would surpass limit\n28 return false; // refuse the charge\n29 // at this point, the charge is successful\n30 balance += price; // update the balance\n31 return true; // announce the good news\n32\n}\n33 public void makePayment(double amount) // make a payment\n{\n34 balance = amount;\n\u2212\n35\n36 } // Utility method to print a card's information\n37 public static void printSummary(CreditCard card)\n{\n38 System.out.println(\"Customer = \" + card.customer);\n39 System.out.println(\"Bank = \" + card.bank);\n40 System.out.println(\"Account = \" + card.account);\n41 System.out.println(\"Balance = \" + card.balance); // implicit cast\n42 System.out.println(\"Limit = \" + card.limit); // implicit cast\n43\n}\n44 // main method shown on next page...\n45\n}\nCodeFragment1.5: TheCreditCardclass.\nwww.it-ebooks.info\n1.7. AnExampleProgram 43\n1 public static void main(String[ ] args)\n{\n2 CreditCard[ ] wallet = new CreditCard[3];\n3 wallet[0] = new CreditCard(\"John Bowman\", \"California Savings\",\n4 \"5391 0375 9387 5309\", 5000);\n5 wallet[1] = new CreditCard(\"John Bowman\", \"California Federal\",\n6 \"3485 0399 3395 1954\", 3500);\n7 wallet[2] = new CreditCard(\"John Bowman\", \"California Finance\",\n8 \"5391 0375 9387 5309\", 2500,300);\n9\n10 for (int val = 1; val <= 16; val++)\n11 wallet[0].charge(3\u2217val); {\n12 wallet[1].charge(2\u2217val);\n13 wallet[2].charge(val);\n14\n}\n15\n16 for (CreditCard card : wallet)\n{\n17 CreditCard.printSummary(card); // calling static method\n18 while (card.getBalance() > 200.0)\n{\n19 card.makePayment(200);\n20 System.out.println(\"New balance = \" + card.getBalance());\n21\n}\n22\n}\n23\n}\nCodeFragment1.6: ThemainmethodoftheCreditCardclass.\nCustomer = John Bowman\nBank = California Savings\nAccount = 5391 0375 9387 5309\nBalance = 408.0\nLimit = 5000\nNew balance = 208.0\nNew balance = 8.0\nCustomer = John Bowman\nBank = California Federal\nAccount = 3485 0399 3395 1954\nBalance = 272.0\nLimit = 3500\nNew balance = 72.0\nCustomer = John Bowman\nBank = California Finance\nAccount = 5391 0375 9387 5309\nBalance = 436.0\nLimit = 2500\nNew balance = 236.0\nNew balance = 36.0\nCodeFragment1.7: OutputfromtheTestclass.\nwww.it-ebooks.info\n44 Chapter1. JavaPrimer\n1.8 Packages and Imports\nTheJavalanguagetakesageneralandusefulapproachtotheorganizationofclasses\ninto programs. Every stand-alone public class defined in Java must be given in a\nseparate file. The file name is the name of the class with a .java extension. So\na class declared as public class Window is defined in a file Window.java. That\nfilemaycontaindefinitions forotherstand-alone classes, butnoneofthemmaybe\ndeclared withpublicvisibility.\nTo aid in the organization of large code repository, Java allows a group of re-\nlatedtypedefinitions(suchasclassesandenums)tobegroupedintowhatisknown\nasapackage. Fortypes tobelong toapackage named packageName, their source\ncode must all be located in a directory named packageName and each file must\nbeginwiththeline:\npackage packageName;\nByconvention, mostpackagenamesarelowercased. Forexample,wemightdefine\nan architecture package that defines classes such as Window, Door, and Room.\nPublic definitions within a file that does not have an explicit package declaration\nareplacedintowhatisknownasthedefaultpackage.\nTorefer to a type within a named package, wemay use a fully qualified name\nbased on dot notation, with that type treated as an attribute of the package. For\nexample,wemightdeclareavariablewitharchitecture.Windowasitstype.\nPackages can be further organized hierarchically into subpackages. Code for\nclasses in a subpackage must be located within a subdirectory of the package\u2019s\ndirectory, and qualified names for subpackages relyon further useof dotnotation.\nFor example, there is a java.util.zip subpackage (with support for working with\nZIP compression) within the java.util package, and the Deflater class within that\nsubpackage isfullyqualifiedasjava.util.zip.Deflater.\nTherearemanyadvantages toorganizing classesintopackages, mostnotably:\nPackages help us avoid the pitfalls of name conflicts. If all type defini-\n\u2022\ntions were in a single package, there could be only one public class named\nWindow. Butwithpackages,wecanhaveanarchitecture.Windowclassthat\nisindependent fromagui.Windowclassforgraphical userinterfaces.\nIt is much easier to distribute a comprehensive set of classes for other pro-\n\u2022\ngrammerstousewhenthoseclassesarepackaged.\nWhentypedefinitions havearelatedpurpose, itisofteneasierforotherpro-\n\u2022\ngrammers tofindthem in alarge library and tobetter understand their coor-\ndinated usewhentheyaregroupedasapackage.\nClasseswithinthesamepackagehaveaccesstoanyofeachothers\u2019members\n\u2022\nhaving public,protected,ordefaultvisibility (i.e.,anything butprivate).\nwww.it-ebooks.info\n1.8. PackagesandImports 45\nImport Statements\nAs noted on the previous page, we may refer to a type within a package using its\nfully qualified name. For example, the Scanner class, introduced in Section 1.6,\nis defined in the java.util package, and so we may refer to it as java.util.Scanner.\nWe could declare and construct a new instance of that class in a project using the\nfollowingstatement:\njava.util.Scanner input = new java.util.Scanner(System.in);\nHowever,alltheextratypingneeded torefertoaclassoutsideofthecurrentpack-\nage can get tiring. In Java, we can use the import keyword to include external\nclasses or entire packages in the current file. Toimport an individual class from a\nspecificpackage, wetypethefollowingatthebeginning ofthefile:\nimport packageName.className;\nFor example, in Section 1.6 we imported the Scanner class from the java.util\npackage withthecommand:\nimport java.util.Scanner;\nandthenwewereallowedtousethelessburdensome syntax:\nScanner input = new Scanner(System.in);\nNote that it is illegal to import a class with the above syntax if a similarly\nnamed class is defined elsewhere in the current file, or has already been imported\nfrom another package. For example, we could not simultaneously import both\narchitecture.Windowandgui.Windowtousewiththeunqualified nameWindow.\nImporting a Whole Package\nIf we know we will be using many definitions from the same package, we can\nimport all of them using an asterisk character (\u2217) to denote a wildcard, as in the\nfollowingsyntax:\nimport packageName.\u2217;\nIf a locally defined name conflicts with one in a package being imported in this\nway,thelocallydefinedoneretainstheunqualifiedname. Ifthereisanameconflict\nbetween definitions in two different packages being imported this way, neither of\ntheconflictingnamescanbeusedwithoutqualification. Forexample,ifweimport\nthefollowinghypothetical packages:\nimport architecture.\u2217; // which we assume includes a Window class\nimport gui.\u2217; // which we assume includes a Window class\nwemuststillusethequalified namesarchitecture.Windowandgui.Windowinthe\nrestofourprogram.\nwww.it-ebooks.info\n46 Chapter1. JavaPrimer\n1.9 Software Development\nTraditional softwaredevelopment involves severalphases. Threemajorstepsare:\n1. Design\n2. Coding\n3. TestingandDebugging\nInthissection,webrieflydiscusstheroleofthesephases,andweintroduceseveral\ngood practices for programming in Java, including coding style, naming conven-\ntions,formaldocumentation, andtesting.\n1.9.1 Design\nFor object-oriented programming, the design step is perhaps the most important\nphase intheprocess ofdeveloping software. Itisinthedesign step thatwedecide\nhowtodividetheworkingsofourprogramintoclasses,whenwedecidehowthese\nclasseswillinteract,whatdataeachwillstore,andwhatactionseachwillperform.\nIndeed, one of the main challenges that beginning programmers face is deciding\nwhat classes to define to do the work of their program. While general prescrip-\ntions are hard to come by, there are some rules of thumb that we can apply when\ndetermining howtodefineourclasses:\nResponsibilities: Dividetheworkintodifferent actors, eachwithadifferent\n\u2022\nresponsibility. Try to describe responsibilities using action verbs. These\nactorswillformtheclassesfortheprogram.\nIndependence: Define the work for each class to be as independent from\n\u2022\nother classes as possible. Subdivide responsibilities between classes so that\neach classhasautonomy oversomeaspect oftheprogram. Givedata(asin-\nstancevariables)totheclassthathasjurisdictionovertheactionsthatrequire\naccesstothisdata.\nBehaviors: Define the behaviors for each class carefully and precisely, so\n\u2022\nthat the consequences of each action performed by a class will be well un-\nderstood by other classes that interact with it. These behaviors will define\nthemethodsthatthisclassperforms,andthesetofbehaviorsforaclassform\ntheprotocolbywhichotherpiecesofcodewillinteractwithobjectsfromthe\nclass.\nDefining the classes, together with their instance variables and methods, are key\nto the design of an object-oriented program. A good programmer will naturally\ndevelop greater skill in performing these tasks over time, as experience teaches\nhim or her to notice patterns in the requirements of a program that match patterns\nthatheorshehasseenbefore.\nwww.it-ebooks.info\n1.9. SoftwareDevelopment 47\nA common tool for developing an initial high-level design for a project is the\nuse of CRC cards. Class-Responsibility-Collaborator (CRC) cards are simple in-\ndexcardsthatsubdividetheworkrequiredofaprogram. Themainideabehindthis\ntool is to have each card represent a component, which will ultimately become a\nclassintheprogram. Wewritethenameofeachcomponent onthetopofanindex\ncard. On the left-hand side of the card, we begin writing the responsibilities for\nthis component. On the right-hand side, we list the collaborators for this compo-\nnent,thatis,theothercomponentsthatthiscomponentwillhavetointeractwithto\nperform itsduties.\nThe design process iterates through an action/actor cycle, where we firstiden-\ntify an action (that is, a responsibility), and we then determine an actor (that is, a\ncomponent)thatisbestsuitedtoperformthataction. Thedesigniscompletewhen\nwehaveassigned allactions toactors. Inusing indexcardsforthisprocess (rather\nthanlargerpiecesofpaper),wearerelyingonthefactthateachcomponent should\nhaveasmallsetofresponsibilitiesandcollaborators. Enforcingthisrulehelpskeep\ntheindividual classesmanageable.\nAs the design takes form, a standard approach to explain and document the\ndesign is the use of UML (Unified Modeling Language) diagrams to express the\norganizationofaprogram. UMLdiagramsareastandardvisualnotationtoexpress\nobject-oriented software designs. Several computer-aided tools are available to\nbuildUMLdiagrams. OnetypeofUMLfigureisknownasaclassdiagram.\nAn example of a class diagram is given in Figure 1.5, corresponding to our\nCreditCard class from Section 1.7. The diagram has three portions, with the first\ndesignating the name of the class, the second designating the recommended in-\nstance variables, and the third designating therecommended methods ofthe class.\nThe type declarations of variables, parameters, and return values are specified in\nthe appropriate place following a colon, and the visibility of each member is des-\nignated on its left, with the \u201c+\u201d symbol for public visibility, the \u201c#\u201d symbol for\nprotectedvisibility, andthe\u201c \u201dsymbolforprivatevisibility.\n\u2212\nclass: CreditCard\nfields: customer : String limit : int\n\u2212 \u2212\nbank : String # balance : double\n\u2212\naccount : String\n\u2212\nmethods: + getCustomer() : String + getAccount() : String\n+ getBank() : String + getLimit() : int\n+ charge(price : double) : boolean + getBalance() : double\n+ makePayment(amount : double)\nFigure1.5: AUMLClassdiagram fortheCreditCardclassfromSection1.7.\nwww.it-ebooks.info\n48 Chapter1. JavaPrimer\n1.9.2 Pseudocode\nAs an intermediate step before the implementation of a design, programmers are\noften asked to describe algorithms in a way that is intended for human eyes only.\nSuch descriptions are called pseudocode. Pseudocode is not a computer program,\nbut is more structured than usual prose. It is a mixture of natural language and\nhigh-level programming constructs that describe the main ideas behind a generic\nimplementation of a data structure or algorithm. Because pseudocode is designed\nforahuman reader, notacomputer, wecancommunicate high-level ideas without\nbeing burdened bylow-level implementation details. Atthe sametime, weshould\nnotglossoverimportantsteps. Likemanyformsofhumancommunication,finding\ntherightbalance isanimportantskillthatisrefinedthroughpractice.\nThere really is no precise definition of the pseudocode language. At the same\ntime, to help achieve clarity, pseudocode mixes natural language with standard\nprogramming language constructs. Theprogramming language constructs that we\nchoosearethoseconsistent withmodernhigh-level languages suchasC,C++,and\nJava. Theseconstructs includethefollowing:\nExpressions: Weusestandardmathematicalsymbolstoexpressnumericand\n\u2022\nboolean expressions. Tobe consistent with Java, weuse the equal sign \u201c=\u201d\nas theassignment operator inassignment statements, and the \u201c==\u201drelation\ntotestequivalence inbooleanexpressions.\nMethod declarations: Algorithm name(param1,param2,...)declares new\n\u2022\nmethod\u201cname\u201danditsparameters.\nDecision structures: if condition then true-actions [else false-actions]. We\n\u2022\nuseindentationtoindicatewhatactionsshouldbeincludedinthetrue-actions\nandfalse-actions.\nWhile-loops: while condition do actions. We use indentation to indicate\n\u2022\nwhatactionsshouldbeincluded intheloopactions.\nRepeat-loops: repeatactionsuntilcondition. Weuseindentationtoindicate\n\u2022\nwhatactionsshouldbeincluded intheloopactions.\nFor-loops: forvariable-increment-definition doactions. Weuseindentation\n\u2022\ntoindicatewhatactionsshouldbeincluded amongtheloopactions.\nArray indexing: A[i] represents the ith cell in the array A. The cells of an\n\u2022\nn-celled arrayAareindexedfromA[0]toA[n 1](consistent withJava).\n\u2212\nMethodcalls: object.method(args);objectisoptionalifitisunderstood.\n\u2022\nMethodreturns: returnvalue. Thisoperation returns thevalue specified to\n\u2022\nthemethodthatcalledthisone.\nComments: Commentgoeshere. . Weenclosecommentsinbraces.\n\u2022 { }\nwww.it-ebooks.info\n1.9. SoftwareDevelopment 49\n1.9.3 Coding\nOne of the key steps in implementing an object-oriented program is coding the\ndescriptionsofclassesandtheirrespectivedataandmethods. Inordertoaccelerate\nthedevelopmentofthisskill,wewilldiscussvariousdesignpatternsfordesigning\nobject-oriented programs(seeSection2.1.3)atvarious pointsthroughout thistext.\nThese patterns provide templates for defining classes and theinteractions between\ntheseclasses.\nOnce we have settled on a design for the classes or our program and their re-\nsponsibilities, andperhaps drafted pseudocode fortheirbehaviors, wearereadyto\nbegintheactualcodingonacomputer. WetypetheJavasourcecodefortheclasses\nofourprogrambyusingeitheranindependenttexteditor(suchasemacs,WordPad,\nor vi), or the editor embedded in an integrated development environment (IDE),\nsuchasEclipse.\nOnce we have completed coding for a class (or package), we compile this file\ninto working code by invoking a compiler. If we are not using an IDE, then we\ncompile our program by calling a program, such as javac, on our file. If we are\nusing an IDE, then we compile our program by clicking the appropriate compila-\ntion button. If we are fortunate, and our program has no syntax errors, then this\ncompilation processwillcreatefileswitha\u201c.class\u201dextension.\nIfourprogramcontainssyntaxerrors,thenthesewillbeidentified,andwewill\nhave to go back into our editor to fix the offending lines of code. Once we have\neliminatedallsyntaxerrors,andcreatedtheappropriatecompiledcode,wecanrun\nour program by either invoking a command, such as \u201cjava\u201d (outside an IDE), or\nbyclicking ontheappropriate \u201crun\u201dbutton(withinanIDE).WhenaJavaprogram\nis run in this way, the runtime environment locates the directories containing the\nnamed class and any other classes that are referenced from this class according to\naspecialoperatingsystemenvironmentvariablenamed\u201cCLASSPATH.\u201dThisvari-\nabledefinesanorderofdirectories inwhichtosearch,givenasalistofdirectories,\nwhichareseparated bycolons inUnix/Linuxorsemicolons inDOS/Windows. An\nexample CLASSPATH assignment in the DOS/Windows operating system could\nbethefollowing:\nSET CLASSPATH=.;C:\\java;C:\\Program Files\\Java\\\nWhereasanexampleCLASSPATHassignmentintheUnix/Linuxoperatingsystem\ncouldbethefollowing:\nsetenv CLASSPATH \".:/usr/local/java/lib:/usr/netscape/classes\"\nIn both cases, the dot (\u201c.\u201d) refers to the current directory in which the runtime\nenvironment isinvoked.\nwww.it-ebooks.info\n50 Chapter1. JavaPrimer\n1.9.4 Documentation and Style\nJavadoc\nInordertoencouragegooduseofblockcommentsandtheautomaticproductionof\ndocumentation, the Java programming environment comes with a documentation\nproduction programcalledjavadoc. ThisprogramtakesacollectionofJavasource\nfilesthathavebeencommentedusingcertainkeywords,calledtags,anditproduces\na series of HTML documents that describe the classes, methods, variables, and\nconstantscontainedinthesefiles. Asanexample,Figure1.6showsaportionofthe\ndocumentation generated forourCreditCardclass.\nEachjavadoccommentisablockcommentthatstartswith\u201c/**\u201dandendswith\n\u201c*/\u201d,andeachlinebetweenthesetwocanbeginwithasingleasterisk, \u201c*\u201d,which\nis ignored. The block comment is assumed to start with a descriptive sentence,\nwhich isfollowed by special lines that begin with javadoc tags. Ablock comment\nthat comes just before a class definition, instance variable declaration, or method\ndefinition is processed by javadoc into a comment about that class, variable, or\nmethod. Theprimaryjavadoc tagsthatweusearethefollowing:\n@authortext: Identifieseachauthor(oneperline)foraclass.\n\u2022\n@throws exceptionName description: Identifies an error condition that is\n\u2022\nsignaled bythismethod(seeSection2.4).\n@paramparameterNamedescription: Identifiesaparameteracceptedbythis\n\u2022\nmethod.\n@returndescription: Describes thereturn typeanditsrange ofvalues fora\n\u2022\nmethod.\nThere are other tags as well; the interested reader is referred to online documen-\ntation for javadoc for further information. For space reasons, we cannot always\nincludejavadoc-style commentsinalltheexampleprogramsincludedinthisbook,\nbutweinclude such asample inCodeFragment 1.8, andwithintheonline codeat\nthewebsitethataccompanies thisbook.\nFigure1.6: DocumentationrenderedbyjavadocfortheCreditCard.chargemethod.\nwww.it-ebooks.info\n1.9. SoftwareDevelopment 51\n1 /\u2217\u2217\n2 \u2217 A simple model for a consumer credit card.\n3 \u2217\n4 \u2217 @author Michael T. Goodrich\n5 \u2217 @author Roberto Tamassia\n6 \u2217 @author Michael H. Goldwasser\n7 \u2217/\n8 public class CreditCard\n9 /\u2217\u2217 {\n10 \u2217 Constructs a new credit card instance.\n11 \u2217 @param cust the name of the customer (e.g., \u201dJohn Bowman\u201d)\n12 \u2217 @param bk the name of the bank (e.g., \u201dCalifornia Savings\u201d)\n13 \u2217 @param acnt the account identifier (e.g., \u201d5391 0375 9387 5309\u201d)\n14 \u2217 @param lim the credit limit (measured in dollars)\n15 \u2217 @param initialBal the initial balance (measured in dollars)\n16 \u2217/\n17 public CreditCard(String cust, String bk, String acnt, int lim, double initialBal)\n{\n18 customer = cust;\n19 bank = bk;\n20 account = acnt;\n21 limit = lim;\n22 balance = initialBal;\n23\n}\n24\n25 /\u2217\u2217\n26 \u2217 Charges the given price to the card, assuming sufficient credit limit.\n27 \u2217 @param price the amount to be charged\n28 \u2217 @return true if charge was accepted; false if charge was denied\n29 \u2217/\n30 public boolean charge(double price) // make a charge\n{\n31 if (price + balance > limit) // if charge would surpass limit\n32 return false; // refuse the charge\n33 // at this point, the charge is successful\n34 balance += price; // update the balance\n35 return true; // announce the good news\n36\n}\n37\n38 /\u2217\u2217\n39 \u2217 Processes customer payment that reduces balance.\n40 \u2217 @param amount the amount of payment made\n41 \u2217/\n42 public void makePayment(double amount) // make a payment\n{\n43 balance = amount;\n\u2212\n44\n}\n45 // remainder of class omitted...\nCode Fragment 1.8: A portion of the CreditCard class definition, originally from\nCodeFragment1.5,withjavadoc-style commentsincluded.\nwww.it-ebooks.info\n52 Chapter1. JavaPrimer\nReadability and Programming Conventions\nProgramsshouldbemadeeasytoreadandunderstand. Goodprogrammers should\ntherefore be mindful of their coding style, and develop a style that communicates\ntheimportantaspectsofaprogram\u2019sdesignforbothhumansandcomputers. Much\nhas been written about good coding style, with some of the main principles being\nthefollowing:\nUsemeaningful names foridentifiers. Tryto choose namesthat can be read\n\u2022\naloud, and choose names that reflect the action, responsibility, or data each\nidentifierisnaming. ThetraditioninmostJavacirclesistocapitalizethefirst\nletter of each word in an identifier, except for the first word for a variable\nor method name. By this convention, \u201cDate,\u201d \u201cVector,\u201d \u201cDeviceManager\u201d\nwould identify classes, and \u201cisFull(),\u201d \u201cinsertItem(),\u201d \u201cstudentName,\u201d and\n\u201cstudentHeight\u201dwouldrespectively identifymethodsandvariables.\nUse named constants or enum types instead of literals. Readability, robust-\n\u2022\nness, and modifiability are enhanced if we include a series of definitions of\nnamed constant values in a class definition. These can then be used within\nthis class and others to refer tospecial values forthis class. Thetradition in\nJavaistofullycapitalize suchconstants, asshownbelow:\npublic class Student\n{\npublic static final int MIN CREDITS = 12; // min credits per term\npublic static final int MAX CREDITS = 24; // max credits per term\npublic enum Year FRESHMAN, SOPHOMORE, JUNIOR, SENIOR ;\n{ }\n// Instance variables, constructors, and method definitions go here...\n}\nIndentstatementblocks. Typicallyprogrammersindenteachstatementblock\n\u2022\nby4spaces;inthisbookwetypicallyuse2spaces,however,toavoidhaving\nourcodeoverrunthebook\u2019smargins.\nOrganizeeachclassinthefollowingorder:\n\u2022\n1. Constants\n2. Instance variables\n3. Constructors\n4. Methods\nWe note that some Java programmers prefer to put instance variable defini-\ntions last. We put them earlier so that we can read each class sequentially\nandunderstand thedataeachmethodisworkingwith.\nUse comments that add meaning to a program and explain ambiguous or\n\u2022\nconfusing constructs. In-line commentsaregood forquickexplanations and\ndo not need to be sentences. Block comments are good for explaining the\npurpose ofamethodandcomplexcodesections.\nwww.it-ebooks.info\n1.9. SoftwareDevelopment 53\n1.9.5 Testing and Debugging\nTesting is the process of experimentally checking the correctness of a program,\nwhiledebugging isthe process oftracking the execution ofaprogram and discov-\nering the errors in it. Testing and debugging are often the most time-consuming\nactivityinthedevelopment ofaprogram.\nTesting\nAcarefultestingplanisanessentialpartofwritingaprogram. Whileverifyingthe\ncorrectness of a program over all possible inputs is usually infeasible, we should\naim at executing the program on a representative subset of inputs. At the very\nminimum, we should make sure that every method of a program is tested at least\nonce (method coverage). Even better, each code statement in the program should\nbeexecutedatleastonce(statementcoverage).\nProgramsoftentendtofailonspecialcasesoftheinput. Suchcasesneedtobe\ncarefully identified andtested. Forexample, whentesting amethodthatsorts(that\nis,putsinorder)anarrayofintegers, weshouldconsider thefollowinginputs:\nThearrayhaszerolength(noelements).\n\u2022\nThearrayhasoneelement.\n\u2022\nAlltheelementsofthearrayarethesame.\n\u2022\nThearrayisalreadysorted.\n\u2022\nThearrayisreversesorted.\n\u2022\nIn addition to special inputs to the program, we should also consider special\nconditionsforthestructuresusedbytheprogram. Forexample,ifweuseanarrayto\nstoredata,weshouldmakesurethatboundarycases,suchasinsertingorremoving\natthebeginning orendofthesubarray holdingdata,areproperly handled.\nWhileitisessentialtousehandcraftedtestsuites,itisalsoadvantageoustorun\ntheprogramonalargecollectionofrandomlygeneratedinputs. TheRandomclass\nin the java.util package provides several means for generating pseudorandom\nnumbers.\nThere is a hierarchy among the classes and methods of a program induced by\nthe caller-callee relationship. Namely, a method A is above a method B in the\nhierarchy ifA calls B. There are twomain testing strategies, top-down testing and\nbottom-uptesting, whichdifferintheorderinwhichmethodsaretested.\nTop-down testing proceeds from the top to the bottom of the program hierar-\nchy. It is typically used in conjunction with stubbing, a boot-strapping technique\nthat replaces a lower-level method with a stub, a replacement for the method that\nsimulates the functionality of the original. Forexample, ifmethod A calls method\nB to get the first line of a file, when testing A we can replace B with a stub that\nreturnsafixedstring.\nwww.it-ebooks.info\n54 Chapter1. JavaPrimer\nBottom-uptestingproceedsfromlower-levelmethodstohigher-levelmethods.\nForexample,bottom-level methods,whichdonotinvokeothermethods,aretested\nfirst,followedbymethodsthatcallonlybottom-levelmethods,andsoon. Similarly\na class that does not depend upon any other classes can be tested before another\nclass that depends on the former. This form of testing is usually described as unit\ntesting, as the functionality of a specific component is tested in isolation of the\nlarger software project. If used properly, this strategy better isolates the cause of\nerrors to the component being tested, as lower-level components upon which it\nreliesshouldhavealreadybeenthoroughly tested.\nJavaprovides several formsofsupport forautomated testing. Wehavealready\ndiscussed how a class\u2019s static main method can be repurposed to perform tests of\nthe functionality of that class (as was done in Code 1.6 for the CreditCard class).\nSuch a test can be executed by invoking the Java virtual machine directly on this\nsecondary class, rather than on the primary class for the entire application. When\nJavaisstartedontheprimaryclass,anycodewithinsuchsecondary mainmethods\nwillbeignored.\nMore robust support for automation of unit testing is provided by the JUnit\nframework, which is not part of the standard Java toolkit but freely available at\nwww.junit.org.Thisframeworkallowsthegroupingofindividualtestcasesinto\nlarger test suites, and provides support for executing those suites, and reporting or\nanalyzing the results of those tests. As software is maintained, regression testing\nshouldbeperformed,wherebyautomationisusedtore-executeallpreviousteststo\nensure thatchanges tothesoftwaredonotintroduce newbugs inpreviously tested\ncomponents.\nDebugging\nThe simplest debugging technique consists of using print statements to track the\nvalues of variables during the execution of the program. A problem with this ap-\nproach is that eventually the print statements need to be removed or commented\nout,sotheyarenotexecutedwhenthesoftwareisfinallyreleased.\nAbetterapproach istoruntheprogram within adebugger, whichisaspecial-\nized environment for controlling and monitoring the execution of a program. The\nbasic functionality provided by a debugger is the insertion of breakpoints within\nthe code. When the program is executed within the debugger, it stops at each\nbreakpoint. While the program is stopped, the current value of variables can be\ninspected. In addition to fixed breakpoints, advanced debuggers allow specifica-\ntion of conditional breakpoints, which are triggered only if a given expression is\nsatisfied.\nThe standard Java toolkit includes a basic debugger named jdb, which has\na command-line interface. Most IDEs for Java programming provide advanced\ndebugging environments withgraphical userinterfaces.\nwww.it-ebooks.info\n1.10. Exercises 55\n1.10 Exercises\nReinforcement\nR-1.1 Write a short Java method, inputAllBaseTypes, that inputs a differentvalue of\neachbasetypefromthestandardinputdeviceandprintsitbacktothestandard\noutputdevice.\nR-1.2 Supposethatwe create an arrayA of GameEntry objects, which hasan integer\nscores field, and we clone A and store the result in an array B. If we then im-\nmediatelysetA[4].scoreequalto550,whatisthescorevalueoftheGameEntry\nobjectreferencedbyB[4]?\nR-1.3 WriteashortJavamethod,isMultiple,thattakestwolongvalues,nandm,and\nreturnstrueifandonlyifnisamultipleofm,thatis,n=miforsomeintegeri.\nR-1.4 WriteashortJavamethod,isEven,thattakesanintiandreturnstrueifandonly\nif i is even. Your method cannot use the multiplication, modulus, or division\noperators,however.\nR-1.5 Write a short Java method that takes an integer n and returns the sum of all\npositiveintegerslessthanorequalton.\nR-1.6 Write ashortJava methodthattakesanintegern andreturnsthesumofallthe\noddpositiveintegerslessthanorequalton.\nR-1.7 Write a short Java method that takes an integer n and returns the sum of the\nsquaresofallpositiveintegerslessthanorequalton.\nR-1.8 WriteashortJavamethodthatcountsthenumberofvowelsinagivencharacter\nstring.\nR-1.9 Write a short Java method that uses a StringBuilder instance to remove all the\npunctuation from a string s storing a sentence, for example, transforming the\nstring\"Let\u2019s try, Mike!\"to\"Lets try Mike\".\nR-1.10 WriteaJavaclass,Flower,thathasthreeinstancevariablesoftypeString,int,\nand float, which respectively represent the name of the flower, its number of\npetals, and price. Your class must include a constructormethod that initializes\neachvariabletoanappropriatevalue,andyourclassshouldincludemethodsfor\nsettingthevalueofeachtype,andgettingthevalueofeachtype.\nR-1.11 ModifytheCreditCard class fromCode Fragment1.5to includea methodthat\nupdatesthecreditlimit.\nR-1.12 Modifythe CreditCardclass fromCodeFragment1.5so thatitignoresanyre-\nquesttoprocessanegativepaymentamount.\nR-1.13 Modify the declaration of the first for loop in the main method in Code Frag-\nment 1.6 so that its charges will cause exactly one of the three credit cards to\nattempttogooveritscreditlimit. Whichcreditcardisit?\nwww.it-ebooks.info\n56 Chapter1. JavaPrimer\nCreativity\nC-1.14 Writeapseudocodedescriptionofamethodthatreversesanarrayofnintegers,\nso that the numbersare listed in the opposite order than they were before, and\ncomparethismethodtoanequivalentJavamethodfordoingthesamething.\nC-1.15 Writeapseudocodedescriptionofamethodforfindingthesmallestandlargest\nnumbersinanarrayofintegersandcomparethattoaJavamethodthatwoulddo\nthesamething.\nC-1.16 Writeashortprogramthattakesasinputthreeintegers,a,b,andc,fromtheJava\nconsoleanddeterminesiftheycanbeusedinacorrectarithmeticformula(inthe\ngivenorder),like\u201ca+b=c,\u201d\u201ca=b c,\u201dor\u201ca b=c.\u201d\n\u2212 \u2217\nC-1.17 WriteashortJavamethodthattakesanarrayofintvaluesanddeterminesifthere\nisapairofdistinctelementsofthearraywhoseproductiseven.\nC-1.18 Thep-normofavectorv=(v ,v ,...,v )inn-dimensionalspaceisdefinedas\n1 2 n\np\nv = vp +vp + +vp .\nk k 1 2 \u00b7\u00b7\u00b7 n\nq\nFor the special case of p=2, this results in the traditional Euclidean norm,\nwhich represents the length of the vector. For example, the Euclidean norm\nof a two-dimensional vector with coordinates (4,3) has a Euclidean norm of\n\u221a42+32=\u221a16+9=\u221a25=5. Give an implementationof a method named\nnormsuchthatnorm(v, p)returnsthep-normvalueofvandnorm(v)returnsthe\nEuclideannormofv,wherevisrepresentedasanarrayofcoordinates.\nC-1.19 WriteaJavaprogramthatcantakeapositiveintegergreaterthan2asinputand\nwriteoutthenumberoftimesonemustrepeatedlydividethisnumberby2before\ngettingavaluelessthan2.\nC-1.20 WriteaJavamethodthattakesanarrayoffloatvaluesanddeterminesifallthe\nnumbersaredifferentfromeachother(thatis,theyaredistinct).\nC-1.21 Write a Java methodthattakesan arraycontainingthe setof allintegersin the\nrange1to52andshufflesitintorandomorder. Yourmethodshouldoutputeach\npossibleorderwithequalprobability.\nC-1.22 WriteashortJavaprogramthatoutputsallpossiblestringsformedbyusingthe\ncharacters'c','a','t','d','o',and'g'exactlyonce.\nC-1.23 WriteashortJavaprogramthattakestwoarraysaandboflengthnstoringint\nvalues, and returnsthe dot productof a and b. That is, it returnsan array c of\nlengthnsuchthatc[i]=a[i] b[i],fori=0,...,n 1.\n\u00b7 \u2212\nC-1.24 ModifytheCreditCardclassfromCodeFragment1.5sothatprintSummarybe-\ncomesanonstaticmethod,andmodifythemainmethodfromCodeFragment1.6\naccordingly.\nC-1.25 Modify the CreditCard class to add a toString() method that returns a String\nrepresentation of the card (rather than printing it to the console, as done by\nprintSummary). ModifythemainmethodfromCodeFragment1.6accordingly\ntousethestandardprintlncommand.\nwww.it-ebooks.info\nChapterNotes 57\nProjects\nP-1.26 Write a short Java program that takes all the lines input to standard input and\nwritesthemtostandardoutputinreverseorder.Thatis,eachlineisoutputinthe\ncorrectorder,buttheorderingofthelinesisreversed.\nP-1.27 WriteaJavaprogramthatcansimulateasimplecalculator,usingtheJavaconsole\nastheexclusiveinputandoutputdevice. Thatis,eachinputtothecalculator,be\nit a number, like 12.34 or 1034, or an operator, like + or =, can be done on a\nseparateline. Aftereachsuchinput,youshouldoutputtotheJavaconsolewhat\nwouldbedisplayedonyourcalculator.\nP-1.28 A common punishment for school children is to write out a sentence multiple\ntimes. Write a Java stand-alone program that will write out the following sen-\ntence one hundredtimes: \u201cI will neverspam my friendsagain.\u201d Your program\nshouldnumbereachofthesentencesanditshouldmakeeightdifferentrandom-\nlookingtypos.\nP-1.29 The birthday paradox says that the probability that two people in a room will\nhavethesamebirthdayismorethanhalf,providedn,thenumberofpeopleinthe\nroom, is more than 23. This propertyis notreally a paradox, butmany people\nfind it surprising. Design a Java programthat can test this paradox by a series\nofexperimentsonrandomlygeneratedbirthdays,whichtestthisparadoxforn=\n5,10,15,20,...,100.\nP-1.30 (ForthosewhoknowJavagraphicaluserinterfacemethods:) DefineaGraphi-\ncalTestclassthatteststhefunctionalityoftheCreditCardclassfromCodeFrag-\nment1.5usingtextfieldsandbuttons.\nChapter Notes\nFormoredetailedinformationabouttheJavaprogramminglanguage,wereferthereader\ntotheJavawebsite(http://www.java.com),aswellassomeofthefinebooksaboutJava,\nincluding the books by Arnold, Gosling and Holmes [8], Flanagan [33], and Horstmann\nandCornell[47,48].\nwww.it-ebooks.info\nwww.it-ebooks.info\nChapter\n2\nObject-Oriented Design\nContents\n2.1 Goals, Principles, and Patterns . . . . . . . . . . . . . . . . 60\n2.1.1 Object-Oriented Design Goals . . . . . . . . . . . . . . . 60\n2.1.2 Object-Oriented Design Principles . . . . . . . . . . . . . 61\n2.1.3 Design Patterns . . . . . . . . . . . . . . . . . . . . . . . 63\n2.2 Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n2.2.1 Extending the CreditCard Class . . . . . . . . . . . . . . . 65\n2.2.2 Polymorphism and Dynamic Dispatch . . . . . . . . . . . 68\n2.2.3 Inheritance Hierarchies . . . . . . . . . . . . . . . . . . . 69\n2.3 Interfaces and Abstract Classes . . . . . . . . . . . . . . . 76\n2.3.1 Interfaces in Java . . . . . . . . . . . . . . . . . . . . . . 76\n2.3.2 Multiple Inheritance for Interfaces . . . . . . . . . . . . . 79\n2.3.3 Abstract Classes . . . . . . . . . . . . . . . . . . . . . . . 80\n2.4 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n2.4.1 Catching Exceptions. . . . . . . . . . . . . . . . . . . . . 82\n2.4.2 Throwing Exceptions . . . . . . . . . . . . . . . . . . . . 85\n2.4.3 Java\u2019s Exception Hierarchy . . . . . . . . . . . . . . . . . 86\n2.5 Casting and Generics . . . . . . . . . . . . . . . . . . . . . 88\n2.5.1 Casting . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n2.5.2 Generics . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\n2.6 Nested Classes . . . . . . . . . . . . . . . . . . . . . . . . . 96\n2.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\nwww.it-ebooks.info\n60 Chapter2. Object-OrientedDesign\n2.1 Goals, Principles, and Patterns\nAsthe name implies, the main \u201cactors\u201d in the object-oriented paradigm are called\nobjects. Each object is an instance of a class. Each class presents to the outside\nworld a concise and consistent view of the objects that are instances of this class,\nwithoutgoingintotoomuchunnecessary detailorgivingothersaccesstotheinner\nworkings of the objects. The class definition typically specifies the data fields,\nalso known as instance variables, that an object contains, as well as the methods\n(operations)thatanobjectcanexecute. Thisviewofcomputingfulfillseveralgoals\nandincorporates designprinciples, whichwewilldiscussinthischapter.\n2.1.1 Object-Oriented Design Goals\nSoftware implementations should achieve robustness, adaptability, and reusabil-\nity. (SeeFigure2.1.)\nFigure2.1: Goalsofobject-oriented design.\nRobustness\nEverygoodprogrammerwantstodevelopsoftwarethatiscorrect,whichmeansthat\na program produces the right output for all the anticipated inputs in the program\u2019s\napplication. Inaddition,wewantsoftwaretoberobust,thatis,capableofhandling\nunexpected inputs that are not explicitly defined for its application. For example,\nif a program is expecting a positive integer (perhaps representing the price of an\nitem) and instead is given a negative integer, then the program should be able to\nrecover gracefully from this error. More importantly, in life-critical applications,\nwhere asoftware error can lead toinjury or loss oflife, software that is not robust\ncould bedeadly. Thispointwasdriven homeinthelate1980s inaccidents involv-\ningTherac-25, aradiation-therapy machine, whichseverely overdosed sixpatients\nbetween 1985 and 1987, some of whom died from complications resulting from\ntheirradiation overdose. Allsixaccidents weretracedtosoftwareerrors.\nwww.it-ebooks.info\n2.1. Goals,Principles,andPatterns 61\nAdaptability\nModern software applications, such as Web browsers and Internet search engines,\ntypically involve large programs that are used for many years. Software, there-\nfore, needs tobeabletoevolve overtimeinresponse tochanging conditions inits\nenvironment. Thus, another important goal of quality software is that it achieves\nadaptability (alsocalledevolvability). Relatedtothisconcept isportability, which\nis the ability of software to run with minimal change on different hardware and\noperating system platforms. Anadvantage ofwritingsoftwareinJavaistheporta-\nbilityprovidedbythelanguage itself.\nReusability\nGoing hand in hand with adaptability is the desire that software be reusable, that\nis, the same code should be usable as a component of different systems in various\napplications. Developing quality software can be an expensive enterprise, and its\ncostcanbeoffsetsomewhatifthesoftwareisdesignedinawaythatmakesiteasily\nreusable infuture applications. Such reuse should bedone withcare, however, for\noneofthemajorsourcesofsoftwareerrorsintheTherac-25camefrominappropri-\nate reuse of Therac-20 software (which was not object-oriented and not designed\nforthehardwareplatformusedwiththeTherac-25).\n2.1.2 Object-Oriented Design Principles\nChief among theprinciples of theobject-oriented approach, which are intended to\nfacilitate thegoalsoutlined above,arethefollowing(seeFigure2.2):\nAbstraction\n\u2022\nEncapsulation\n\u2022\nModularity\n\u2022\nAbstraction Encapsulation Modularity\nFigure2.2: Principlesofobject-oriented design.\nwww.it-ebooks.info\n62 Chapter2. Object-OrientedDesign\nAbstraction\nThenotionofabstractionistodistillacomplicatedsystemdowntoitsmostfunda-\nmentalparts. Typically, describingthepartsofasysteminvolves namingthemand\nexplaining their functionality. Applying the abstraction paradigm to the design of\ndatastructuresgivesrisetoabstractdatatypes(ADTs). AnADTisamathematical\nmodel of a data structure that specifies the type ofdata stored, the operations sup-\nported on them, and the types of parameters of the operations. An ADT specifies\nwhateachoperationdoes,butnothowitdoesit. InJava,anADTcanbeexpressed\nbyaninterface, which issimply alist ofmethod declarations, whereeachmethod\nhasanemptybody. (WewillsaymoreaboutJavainterfaces inSection2.3.1.)\nAn ADT is realized by a concrete data structure, which is modeled in Java by\na class. A class defines the data being stored and the operations supported by the\nobjects that are instances of the class. Also, unlike interfaces, classes specify how\nthe operations are performed in the body of each method. A Java class is said\nto implement an interface if its methods include all the methods declared in the\ninterface,thusprovidingabodyforthem. However,aclasscanhavemoremethods\nthanthoseoftheinterface.\nEncapsulation\nAnother important principle of object-oriented design is encapsulation; different\ncomponents of a software system should not reveal the internal details of their\nrespective implementations. Oneofthemainadvantages ofencapsulation isthatit\ngives one programmer freedom to implement the details of a component, without\nconcern that other programmers will be writing code that intricately depends on\nthose internal decisions. The only constraint on the programmer of a component\nis to maintain the public interface for the component, as other programmers will\nbe writing code that depends on that interface. Encapsulation yields robustness\nand adaptability, for it allows the implementation details of parts of a program to\nchangewithoutadverselyaffectingotherparts,therebymakingiteasiertofixbugs\noraddnewfunctionality withrelatively localchanges toacomponent.\nModularity\nModern software systems typically consist of several different components that\nmust interact correctly in order for the entire system to work properly. Keeping\nthese interactions straight requires that these different components be well orga-\nnized. Modularity refers to an organizing principle in which different compo-\nnentsofasoftwaresystemaredividedintoseparatefunctionalunits. Robustnessis\ngreatlyincreased becauseitiseasiertotestanddebug separate components before\ntheyareintegrated intoalargersoftwaresystem.\nwww.it-ebooks.info\n2.1. Goals,Principles,andPatterns 63\n2.1.3 Design Patterns\nObject-oriented design facilitates reusable, robust, and adaptable software. De-\nsigning good code takes more than simply understanding object-oriented method-\nologies,however. Itrequirestheeffectiveuseofobject-oriented designtechniques.\nComputing researchers andpractitioners havedeveloped avariety oforganiza-\ntional concepts and methodologies for designing quality object-oriented software\nthat is concise, correct, and reusable. Ofspecial relevance to this book is the con-\ncept ofadesign pattern, whichdescribes asolution toa\u201ctypical\u201d software design\nproblem. Apatternprovidesageneraltemplateforasolutionthatcanbeappliedin\nmanydifferentsituations. Itdescribesthemainelementsofasolutioninanabstract\nway that can be specialized for a specific problem at hand. It consists of a name,\nwhichidentifiesthepattern;acontext,whichdescribesthescenariosforwhichthis\npattern canbeapplied; atemplate, whichdescribes howthepatternisapplied; and\naresult, whichdescribes andanalyzes whatthepattern produces.\nWepresent several design patterns inthis book, andweshow how they canbe\nconsistently applied to implementations of data structures and algorithms. These\ndesign patterns fall into two groups\u2014patterns for solving algorithm design prob-\nlems and patterns for solving software engineering problems. Some of the algo-\nrithmdesignpatternswediscussinclude thefollowing:\nRecursion (Chapter5)\n\u2022\nAmortization (Sections7.2.3,11.4.4,and14.7.3)\n\u2022\nDivide-and-conquer (Section12.1.1)\n\u2022\nPrune-and-search, alsoknownasdecrease-and-conquer (Section12.5.1)\n\u2022\nBruteforce(Section13.2.1)\n\u2022\nThegreedymethod(Sections13.4.2,14.6.2,and14.7)\n\u2022\nDynamicprogramming (Section13.5)\n\u2022\nLikewise,someofthesoftwareengineeringdesignpatternswediscussinclude:\nTemplatemethod(Sections 2.3.3,10.5.1,and11.2.1)\n\u2022\nComposition (Sections2.5.2,2.6,and9.2.1)\n\u2022\nAdapter(Section6.1.3)\n\u2022\nPosition(Sections7.3,8.1.2,and14.7.3)\n\u2022\nIterator (Section7.4)\n\u2022\nFactoryMethod(Sections8.3.1and11.2.1)\n\u2022\nComparator(Sections9.2.2,10.3,andChapter12)\n\u2022\nLocator(Section9.5.1)\n\u2022\nRather than explain each of these concepts here, however, we will introduce\nthem throughout the text as noted above. For each pattern, be it for algorithm\nengineering orsoftware engineering, weexplainitsgeneral useandweillustrate it\nwithatleastoneconcrete example.\nwww.it-ebooks.info\n64 Chapter2. Object-OrientedDesign\n2.2 Inheritance\nA natural way to organize various structural components of a software package\nis in a hierarchical fashion, with similar abstract definitions grouped together in\na level-by-level manner that goes from specific to more general as one traverses\nup the hierarchy. An example of such a hierarchy is shown in Figure 2.3. Using\nmathematical notations, the set of houses is a subset of the set of buildings, but a\nsupersetofthesetofranches. Thecorrespondence betweenlevelsisoftenreferred\ntoasan\u201cisa\u201drelationship, asahouseisabuilding, andaranchisahouse.\nBuilding\nCommercial\nApartment House\nBuilding\nLow-rise High-rise Two-story\nRanch Skyscraper\nApartment Apartment House\nFigure2.3: Anexampleofan\u201cisa\u201dhierarchyinvolving architectural buildings.\nAhierarchical design isuseful in software development, ascommon function-\nality can be grouped at the most general level, thereby promoting reuse of code,\nwhile differentiated behaviors can be viewed as extensions of the general case. In\nobject-oriented programming, themechanism foramodularandhierarchical orga-\nnizationisatechniqueknownasinheritance. Thisallowsanewclasstobedefined\nbased upon an existing class as the starting point. In object-oriented terminology,\nthe existing class is typically described as the base class, parent class, or super-\nclass, while the newly defined class is known as the subclass or child class. We\nsaythatthesubclass extendsthesuperclass.\nWhen inheritance is used, the subclass automatically inherits, as its starting\npoint, all methods from the superclass (other than constructors). The subclass can\ndifferentiate itself from its superclass intwoways. Itmayaugmentthesuperclass\nby adding new fields and new methods. It may also specialize existing behaviors\nbyproviding anewimplementation thatoverridesanexistingmethod.\nwww.it-ebooks.info\n2.2. Inheritance 65\n2.2.1 Extending the CreditCard Class\nAs an introduction to the use of inheritance, we revisit the CreditCard class of\nSection 1.7, designing a new subclass that, for lack of a better name, we name\nPredatoryCreditCard. The new class will differ from the original in two ways:\n(1) if an attempted charge is rejected because it would have exceeded the credit\nlimit, a $5 fee will be charged, and (2) there will be a mechanism for assessing\na monthly interest charge on the outstanding balance, using an annual percentage\nrate(APR)specifiedasaconstructor parameter.\nFigure2.4providesaUMLdiagramthatservesasanoverviewofourdesignfor\nthe new PredatoryCreditCard class as a subclass of the existing CreditCard class.\nThe hollow arrow in that diagram indicates the use of inheritance, with the arrow\noriented fromthesubclass tothesuperclass.\nThePredatoryCreditCardclassaugmentstheoriginalCreditCardclass,adding\nanewinstancevariablenamedaprtostoretheannualpercentagerate,andaddinga\nnew method namedprocessMonth that willassess interest charges. Thenewclass\nalsospecializes itssuperclass byoverriding theoriginal chargemethodinorderto\nprovideanewimplementation thatassessa$5feeforanattempted overcharge.\nclass: CreditCard\nfields: customer : String limit : int\n\u2212 \u2212\nbank : String # balance : double\n\u2212\naccount : String\n\u2212\nmethods: + getCustomer() : String + getAccount() : String\n+ getBank() : String + getLimit() : int\n+ charge(price : double) : boolean + getBalance() : double\n+ makePayment(amount : double)\nclass: PredatoryCreditCard\nfields: apr : double\n\u2212\nmethods: + charge(price : double) : boolean + processMonth()\nFigure 2.4: A UML diagram showing PredatoryCreditCard as a subclass of\nCreditCard. (SeeFigure1.5fortheoriginalCreditCarddesign.)\nwww.it-ebooks.info\n66 Chapter2. Object-OrientedDesign\nTo demonstrate the mechanisms for inheritance in Java, Code Fragment 2.1\npresents a complete implementation of the new PredatoryCreditCard class. We\nwishtodrawattention toseveralaspectsoftheJavaimplementation.\nWebeginwiththefirstlineoftheclassdefinition, whichindicates thatthenew\nclassinherits fromtheexisting CreditCardclassbyusingJava\u2019sextendskeyword\nfollowed by the name ofits superclass. In Java, each class can extend exactly one\nother class. Because ofthis property, Java issaid toallow only single inheritance\namongclasses. Weshouldalsonotethatevenifaclassdefinitionmakesnoexplicit\nuseoftheextendsclause, itautomatically inherits fromaclass, java.lang.Object,\nwhichservesastheuniversalsuperclass inJava.\nWe next consider the declaration of the new apr instance variable, at line 3 of\nthe code. Each instance of the PredatoryCreditCard class will store each of the\nvariablesinheritedfromtheCreditCarddefinition(customer,bank,account,limit,\nand balance) in addition to the new apr variable. Yet we are only responsible for\ndeclaring thenewinstancevariable withinthesubclassdefinition.\n1 public class PredatoryCreditCard extends CreditCard\n{\n2 // Additional instance variable\n3 private double apr; // annual percentage rate\n4\n5 // Constructor for this class\n6 public PredatoryCreditCard(String cust, String bk, String acnt, int lim,\n7 double initialBal, double rate)\n{\n8 super(cust, bk, acnt, lim, initialBal); // initialize superclass attributes\n9 apr = rate;\n10\n}\n11\n12 // A new method for assessing monthly interest charges\n13 public void processMonth()\n{\n14 if (balance > 0) // only charge interest on a positive balance\n{\n15 double monthlyFactor = Math.pow(1 + apr, 1.0/12);// compute monthly rate\n16 balance \u2217= monthlyFactor; // assess interest\n17\n}\n18\n}\n19\n20 // Overriding the charge method defined in the superclass\n21 public boolean charge(double price)\n{\n22 boolean isSuccess = super.charge(price); // call inherited method\n23 if (!isSuccess)\n24 balance += 5; // assess a $5 penalty\n25 return isSuccess;\n26\n}\n27\n}\nCodeFragment2.1: Asubclass ofCreditCardthatassesses interestandfees.\nwww.it-ebooks.info\n2.2. Inheritance 67\nConstructors are never inherited in Java. Lines 6\u201310 of Code Fragment 2.1\ndefine a constructor for the new class. When a PredatoryCreditCard instance is\ncreated, allofitsfieldsmust beproperly initialized, including anyinherited fields.\nForthisreason,thefirstoperationperformedwithinthebodyofaconstructormust\nbe to invoke a constructor of the superclass, which is responsible for properly ini-\ntializing thefieldsdefinedinthesuperclass.\nInJava, aconstructor ofthesuperclass isinvoked byusing thekeyword super\nwithappropriateparameterization,asdemonstratedatline8ofourimplementation:\nsuper(cust, mk, acnt, lim, initialBal);\nThis use of the super keyword is very similar to use of the keyword this when\ninvoking a different constructor within the same class (as described on page 15 of\nSection1.2.2). Ifaconstructorforasubclassdoesnotmakeanexplicitcalltosuper\nor this as its first command, then an implicit call to super(), the zero-parameter\nversion of the superclass constructor, will be made. Returning our attention to the\nconstructor for PredatoryCreditCard, after calling the superclass constructor with\nappropriate parameters, line 9 initializes the newly declared apr field. (That field\nwasunknowntothesuperclass.)\nThe processMonth method is a new behavior, so there is no inherited version\nuponwhichtorely. Inourmodel,thismethodshouldbeinvokedbythebank,once\neachmonth,toaddnewinterestchargestothecustomer\u2019sbalance. Fromatechnical\naspect, we note that this method accesses the value of the inherited balance field\n(at line 14), and potentially modifies that balance at line 16. This is permitted\nprecisely because thebalanceattributed wasdeclared withprotected visibility in\ntheoriginalCreditCardclass. (SeeCodeFragment1.5.)\nThe most challenging aspect in implementing the processMonth method is\nmaking sure we have working knowledge of how an annual percentage rate trans-\nlates toamonthly rate. Wedo notsimplydivide theannual rate bytwelvetoget a\nmonthly rate (that would betoo predatory, asitwould result inahigher APRthan\nadvertised). The correct computation is to take the twelfth-root of 1 + apr, and\nusethatasamultiplicative factor. Forexample,iftheAPRis0.0825(representing\n8.25%),wecompute \u221a12 1.0825 1.006628,andthereforecharge0.6628%interest\n\u2248\npermonth. Inthisway,each$100ofdebtwillamass$8.25ofcompoundedinterest\ninayear. NoticethatweusetheMath.powmethodfromJava\u2019slibraries.\nFinally,weconsiderthenewimplementationofthechargemethodprovidedfor\nthePredatoryCreditCardclass(lines21\u201327). Thisdefinitionoverridestheinherited\nmethod. Yet,ourimplementationofthenewmethodreliesonacalltotheinherited\nmethod, with syntax super.charge(price) at line 22. The return value of that call\ndesignates whether the charge was successful. We examine that return value to\ndecidewhethertoassessafee,andineithercasereturnthatbooleantothecaller,so\nthatthenewversionofchargemaintainsasimilaroutwardinterfaceastheoriginal.\nwww.it-ebooks.info\n68 Chapter2. Object-OrientedDesign\n2.2.2 Polymorphism and Dynamic Dispatch\nThe word polymorphism literally means \u201cmany forms.\u201d In the context of object-\norienteddesign,itreferstotheabilityofareferencevariabletotakedifferentforms.\nConsider, forexample,thedeclaration ofavariablehaving CreditCardasitstype:\nCreditCard card;\nBecausethisisareferencevariable,thestatementdeclaresthenewvariable,which\ndoes not yet refer to any card instance. While we have already seen that we can\nassignittoanewlyconstructedinstanceoftheCreditCardclass,Javaalsoallowsus\ntoassign thatvariable torefertoaninstance ofthePredatoryCreditCard subclass.\nThatis,wecandothefollowing:\nCreditCard card = new PredatoryCreditCard(...); // parameters omitted\nThis is a demonstration of what is known as the Liskov Substitution Principle,\nwhich states that a variable (or parameter) with a declared type can be assigned\nan instance from any direct or indirect subclass of that type. Informally, this is\na manifestation of the \u201cis a\u201d relationship modeled by inheritance, as a predatory\ncreditcardisacreditcard(butacreditcardisnotnecessarily predatory).\nWesaythatthevariable, card,ispolymorphic; itmaytakeoneofmanyforms,\ndepending on the specific class of the object to which it refers. Because card\nhas been declared with type CreditCard, that variable may only be used to call\nmethods that are declared as part of the CreditCard definition. So we can call\ncard.makePayment(50) and card.charge(100), but a compilation error would be\nreported for the callcard.processMonth()because aCreditCard isnot guaranteed\nto have such a behavior. (That call could be made if the variable were originally\ndeclared tohavePredatoryCreditCardasitstype.)\nAn interesting (and important) issue is how Java handles a call such as\ncard.charge(100)whenthevariablecardhasadeclaredtypeofCreditCard. Recall\nthat the object referenced by card might be an instance of the CreditCard class or\naninstanceofthePredatoryCreditCardclass,andthattherearedistinctimplemen-\ntationsofthechargemethod: CreditCard.chargeandPredatoryCreditCard.charge.\nJavausesaprocessknownasdynamicdispatch,decidingatruntimetocallthever-\nsion of the method that is most specific to the actual type of the referenced object\n(not thedeclared type). So, iftheobject isaPredatoryCreditCard instance, itwill\nexecutethePredatoryCreditCard.chargemethod,evenifthereferencevariablehas\nadeclared typeofCreditCard.\nJavaalsoprovidesaninstanceofoperatorthattests,atruntime,whetheranin-\nstancesatisfiesasaparticulartype. Forexample,theevaluationofthebooleancon-\ndition, (card instanceof PredatoryCreditCard), produces true if the object cur-\nrentlyreferencedbythevariablecardbelongstothePredatoryCreditCardclass,or\nanyfurthersubclassofthatclass. (SeeSection2.5.1forfurtherdiscusion.)\nwww.it-ebooks.info\n2.2. Inheritance 69\n2.2.3 Inheritance Hierarchies\nAlthoughasubclassmaynotinheritfrommultiplesuperclassesinJava,asuperclass\nmayhavemanysubclasses. Infact, itisquitecommoninJavatodevelopcomplex\ninheritance hierarchies tomaximizethereusability ofcode.\nAsasecondexampleoftheuseofinheritance,wedevelopahierarchyofclasses\nfor iterating numeric progressions. A numeric progression is a sequence of num-\nbers, where each number depends on one or more of the previous numbers. For\nexample, anarithmeticprogression determines thenextnumberbyadding afixed\nconstant to the previous value, and a geometric progression determines the next\nnumber by multiplying the previous value by a fixed constant. In general, a pro-\ngression requires a first value, and a way of identifying a new value based on one\normoreprevious values.\nOurhierarchy stemsfromageneral baseclassthatwenameProgression. This\nclass produces the progression of whole numbers: 0, 1, 2, .... More importantly,\nthisclasshasbeendesignedsothatitcaneasilybespecializedbyotherprogression\ntypes,producing ahierarchygiveninFigure2.5.\nProgression\nArithmeticProgression GeometricProgression FibonacciProgression\nFigure2.5: Anoverviewofourhierarchy ofprogression classes.\nOur implementation of the basic Progression class is provided in Code Frag-\nment2.2. Thisclass hasasingle field, namedcurrent. Itdefinestwoconstructors,\none accepting an arbitrary starting value for the progression and the other using 0\nasthedefault value. Theremainderoftheclassincludes threemethods:\nnextValue(): A public method that returns the next value of the pro-\ngression, implicitlyadvancing thevalueeachtime.\nadvance(): Aprotected methodthatisresponsible foradvancing the\nvalueofcurrentintheprogression.\nprintProgression(n): A public utility that advances the progression n times\nwhiledisplaying eachvalue.\nOurdecisiontofactorouttheprotectedadvance()method,whichiscalleddur-\ning the execution of nextValue(), is to minimize the burden on subclasses, which\naresolelyresponsibleforoverridingtheadvancemethodtoupdatethecurrentfield.\nwww.it-ebooks.info\n70 Chapter2. Object-OrientedDesign\n1 /\u2217\u2217 Generates a simple progression. By default: 0, 1, 2, ... \u2217/\n2 public class Progression\n{\n3\n4 // instance variable\n5 protected long current;\n6\n7 /\u2217\u2217 Constructs a progression starting at zero. \u2217/\n8 public Progression() this(0);\n{ }\n9\n10 /\u2217\u2217 Constructs a progression with given start value. \u2217/\n11 public Progression(long start) current = start;\n{ }\n12\n13 /\u2217\u2217 Returns the next value of the progression. \u2217/\n14 public long nextValue()\n{\n15 long answer = current;\n16 advance(); // this protected call is responsible for advancing the current value\n17 return answer;\n18\n}\n19\n20 /\u2217\u2217 Advances the current value to the next value of the progression. \u2217/\n21 protected void advance()\n{\n22 current++;\n23\n}\n24\n25 /\u2217\u2217 Prints the next n values of the progression, separated by spaces. \u2217/\n26 public void printProgression(int n)\n{\n27 System.out.print(nextValue()); // print first value without leading space\n28 for (int j=1; j < n; j++)\n29 System.out.print(\" \" + nextValue()); // print leading space before others\n30 System.out.println(); // end the line\n31\n}\n32\n}\nCodeFragment2.2: Generalnumericprogression class.\nThe body of the nextValue method temporarily records the current value of\ntheprogression, whichwillsoonbereturned, andthencalls theprotected advance\nmethodinordertoupdatethevalueinpreparation forasubsequent call.\nThe implementation of the advance method in our Progression class simply\nincrementsthecurrentvalue. Thismethodistheonethatwillbeoverriddenbyour\nspecialized subclasses inordertoaltertheprogression ofnumbers.\nIntheremainderofthissection,wepresentthreesubclasses oftheProgression\nclass\u2014ArithmeticProgression,GeometricProgression,andFibonacciProgression\u2013\nwhichrespectively produce arithmetic, geometric, andFibonacciprogressions.\nwww.it-ebooks.info\n2.2. Inheritance 71\nAn Arithmetic Progression Class\nOurfirstexample ofaspecialized progression is anarithmetic progression. While\nthe default progression increases its value by one in each step, an arithmetic pro-\ngression adds a fixed constant to one term of the progression to produce the next.\nForexample, using an increment of 4for an arithmetic progression that starts at 0\nresultsinthesequence 0,4,8,12,....\nCode Fragment 2.3 presents our implementation of an ArithmeticProgression\nclass, which relies on Progression as its base class. We include three construc-\ntor forms, with the most general (at lines 12\u201315) accepting an increment value\nand a start value, such that ArithmeticProgression(4, 2) produces the sequence\n2,6,10,14,.... The body of that constructor invokes the superclass constructor,\nwith syntax super(start), to initialize current to the given start value, and then it\ninitializes theincrementfieldintroduced bythissubclass.\nFor convenience, we offer two additional constructors, so that the default pro-\ngressionproduces0,1,2,3,...,andaone-parameterconstructorproducesanarith-\nmeticprogression withagivenincrementvalue(butadefault startingvalueof0).\nFinally (and most importantly), we override the protected advance method so\nthatthegivenincrementisaddedtoeachsuccessive valueoftheprogression.\n1 public class ArithmeticProgression extends Progression\n{\n2\n3 protected long increment;\n4\n5 /\u2217\u2217 Constructs progression 0, 1, 2, ... \u2217/\n6 public ArithmeticProgression() this(1, 0); // start at 0 with increment of 1\n{ }\n7\n8 /\u2217\u2217 Constructs progression 0, stepsize, 2\u2217stepsize, ... \u2217/\n9 public ArithmeticProgression(long stepsize) this(stepsize, 0); // start at 0\n{ }\n10\n11 /\u2217\u2217 Constructs arithmetic progression with arbitrary start and increment. \u2217/\n12 public ArithmeticProgression(long stepsize, long start)\n{\n13 super(start);\n14 increment = stepsize;\n15\n}\n16\n17 /\u2217\u2217 Adds the arithmetic increment to the current value. \u2217/\n18 protected void advance()\n{\n19 current += increment;\n20\n}\n21\n}\nCodeFragment2.3: Classforarithmeticprogressions, whichinheritsfromthegen-\neralprogression classshowninCodeFragment2.2.\nwww.it-ebooks.info\n72 Chapter2. Object-OrientedDesign\nA Geometric Progression Class\nOur second example of a specialized progression is a geometric progression, in\nwhich each value is produced by multiplying the preceding value by a fixed con-\nstant, known as the base of the geometric progression. The starting point of a ge-\nometric progression is traditionally 1, rather than 0, because multiplying 0 by any\nfactor results in0. Asanexample, ageometric progression withbase2,starting at\nvalue1,produces thesequence 1,2,4,8,16,....\nCode Fragment 2.4 presents our implementation of a GeometricProgression\nclass. It is quite similar to the ArithmeticProgression class in terms of the pro-\ngramming techniques used. In particular, it introduces one new field (the base of\nthegeometric progression), provides threeformsofaconstructor forconvenience,\nand overrides the protected advance method so that the current value of the pro-\ngression ismultiplied bythebaseateachstep.\nInthecaseofageometricprogression,wehavechosentohavethedefault(zero-\nparameter) constructor use astarting value of 1and a base of2 sothat it produces\ntheprogression 1,2,4,8,.... Theone-parameter versionoftheconstructor accepts\nan arbitrary base and uses 1 as the starting value, thus GeometricProgression(3)\nproducesthesequence1,3,9,27,.... Finally,weofferatwo-parameterversionac-\nceptingbothabaseandstartvalue,suchthatGeometricProgression(3,2)produces\nthesequence 2,6,18,54,....\n1 public class GeometricProgression extends Progression\n{\n2\n3 protected long base;\n4\n5 /\u2217\u2217 Constructs progression 1, 2, 4, 8, 16, ... \u2217/\n6 public GeometricProgression() this(2, 1); // start at 1 with base of 2\n{ }\n7\n8 /\u2217\u2217 Constructs progression 1, b, b\u02c62, b\u02c63, b\u02c64, ... for base b. \u2217/\n9 public GeometricProgression(long b) this(b, 1); // start at 1\n{ }\n10\n11 /\u2217\u2217 Constructs geometric progression with arbitrary base and start. \u2217/\n12 public GeometricProgression(long b, long start)\n{\n13 super(start);\n14 base = b;\n15\n}\n16\n17 /\u2217\u2217 Multiplies the current value by the geometric base. \u2217/\n18 protected void advance()\n19 current \u2217= base; { // multiply current by the geometric base\n20\n}\n21\n}\nCodeFragment2.4: Classforgeometricprogressions.\nwww.it-ebooks.info\n2.2. Inheritance 73\nA Fibonacci Progression Class\nAs our final example, we demonstrate how to use our progression framework to\nproduceaFibonacciprogression. EachvalueofaFibonacciseriesisthesumofthe\ntwomostrecent values. Tobegintheseries, thefirsttwovaluesareconventionally\n0and1,leadingtotheFibonacciseries0,1,1,2,3,5,8,... . Moregenerally, sucha\nseriescanbegenerated fromanytwostartingvalues. Forexample, ifwestartwith\nvalues4and6,theseriesproceeds as4,6,10,16,26,42,... .\nCode Fragment 2.5 presents an implementation of the FibonacciProgression\nclass. Thisclass ismarkedly different from those forthearithmetic andgeometric\nprogressions because we cannot determine the next value of a Fibonacci series\nsolely from the current one. We must maintain knowledge of the two most recent\nvalues. Our FibonacciProgression class introduces a new member, named prev,\nto store the value that proceeded the current one (which is stored in the inherited\ncurrentfield).\nHowever, the question arises as to how to initialize the previous value in the\nconstructor, when provided with the desired first and second values as parame-\nters. The first should be stored as current so that it is reported by the first call to\nnextValue(). Withinthatmethodcall,anassignmentwillsetthenewcurrentvalue\n(which will be the second value reported) equal to the first value plus the \u201cprevi-\nous.\u201d Byinitializingthepreviousvalueto(second first),theinitialadvancement\n\u2212\nwillsetthenewcurrentvaluetofirst + (second first) = second,asdesired.\n\u2212\n1 public class FibonacciProgression extends Progression\n{\n2\n3 protected long prev;\n4\n5 /\u2217\u2217 Constructs traditional Fibonacci, starting 0, 1, 1, 2, 3, ... \u2217/\n6 public FibonacciProgression() this(0, 1);\n{ }\n7\n8 /\u2217\u2217 Constructs generalized Fibonacci, with give first and second values. \u2217/\n9 public FibonacciProgression(long first, long second)\n{\n10 super(first);\n11 prev = second first; // fictitious value preceding the first\n\u2212\n12\n}\n13\n14 /\u2217\u2217 Replaces (prev,current) with (current, current+prev). \u2217/\n15 protected void advance()\n{\n16 long temp = prev;\n17 prev = current;\n18 current += temp;\n19\n}\n20\n}\nCodeFragment2.5: ClassfortheFibonacciprogression.\nwww.it-ebooks.info\n74 Chapter2. Object-OrientedDesign\nclass: Progression\nfields: # current : long\nmethods: + nextValue() : long\n+ printProgression(n : int)\n# advance()\nArithmeticProgression GeometricProgression FibonacciProgression\n# increment : long # base : long # prev : long\n# advance() # advance() # advance()\nFigure2.6: Detailedinheritance diagram forclassProgressionanditssubclasses.\nAs a summary, Figure 2.6 presents a more detailed version of our inheritance\ndesign than was originally given in Figure 2.5. Notice that each of these classes\nintroduces an additional field that allows it to properly implement the advance()\nmethodinanappropriate mannerforitsprogression.\nTesting Our Progression Hierarchy\nTocompleteourexample,wedefineaclassTestProgression,showninCodeFrag-\nment 2.6, which performs a simple test of each of the three classes. In this class,\nvariable prog is polymorphic during the execution of the main method, since it\nreferences objects of class ArithmeticProgression, GeometricProgression, and Fi-\nbonacciProgression in turn. When the main method of the TestProgression class\nis invoked by the Java runtime system, the output shown in Code Fragment 2.7 is\nproduced.\nThe example presented in this section is admittedly simple, but it provides an\nillustrationofaninheritancehierarchyinJava. Asaninterestingaside,weconsider\nhow quickly the numbers grow in the three progressions, and how long it would\nbe before the long integers used for computations overflow. With the default in-\ncrementofone, anarithmetic progression wouldnotoverflowfor263 steps(thatis\napproximately 10 billion billions). In contrast, a geometric progression with base\nb=3 will overflow a long integer after 40 iterations, as 340 >263. Likewise, the\n94th Fibonacci number is greater than 263; hence, the Fibonacci progression will\noverflowalongintegerafter94iterations.\nwww.it-ebooks.info\n2.2. Inheritance 75\n1 /\u2217\u2217 Test program for the progression hierarchy. \u2217/\n2 public class TestProgression\n{\n3 public static void main(String[ ] args)\n{\n4 Progression prog;\n5 // test ArithmeticProgression\n6 System.out.print(\"Arithmetic progression with default increment: \");\n7 prog = new ArithmeticProgression();\n8 prog.printProgression(10);\n9 System.out.print(\"Arithmetic progression with increment 5: \");\n10 prog = new ArithmeticProgression(5);\n11 prog.printProgression(10);\n12 System.out.print(\"Arithmetic progression with start 2: \");\n13 prog = new ArithmeticProgression(5, 2);\n14 prog.printProgression(10);\n15 // test GeometricProgression\n16 System.out.print(\"Geometric progression with default base: \");\n17 prog = new GeometricProgression();\n18 prog.printProgression(10);\n19 System.out.print(\"Geometric progression with base 3: \");\n20 prog = new GeometricProgression(3);\n21 prog.printProgression(10);\n22 // test FibonacciProgression\n23 System.out.print(\"Fibonacci progression with default start values: \");\n24 prog = new FibonacciProgression();\n25 prog.printProgression(10);\n26 System.out.print(\"Fibonacci progression with start values 4 and 6: \");\n27 prog = new FibonacciProgression(4, 6);\n28 prog.printProgression(8);\n29\n}\n30\n}\nCodeFragment2.6: Programfortestingtheprogression classes.\nArithmetic progression with default increment: 0 1 2 3 4 5 6 7 8 9\nArithmetic progression with increment 5: 0 5 10 15 20 25 30 35 40 45\nArithmetic progression with start 2: 2 7 12 17 22 27 32 37 42 47\nGeometric progression with default base: 1 2 4 8 16 32 64 128 256 512\nGeometric progression with base 3: 1 3 9 27 81 243 729 2187 6561 19683\nFibonacci progression with default start values: 0 1 1 2 3 5 8 13 21 34\nFibonacci progression with start values 4 and 6: 4 6 10 16 26 42 68 110\nCodeFragment2.7: OutputoftheTestProgressionprogramofCodeFragment2.6.\nwww.it-ebooks.info\n76 Chapter2. Object-OrientedDesign\n2.3 Interfaces and Abstract Classes\nIn order for two objects to interact, they must \u201cknow\u201d about the various messages\nthat each will accept, that is, the methods each object supports. To enforce this\n\u201cknowledge,\u201d the object-oriented design paradigm asks that classes specify the\napplication programming interface (API), or simply interface, that their objects\npresent to other objects. In the ADT-based approach (see Section 2.1.2) to data\nstructures followed in this book, an interface defining an ADT is specified as a\ntype definition and a collection of methods for this type, with the arguments for\neach method being of specified types. This specification is, in turn, enforced by\nthe compiler or runtime system, which requires that the types of parameters that\nare actually passed to methods rigidly conform with the type specified in the in-\nterface. This requirement is known as strong typing. Having to define interfaces\nand then having those definitions enforced by strong typing admittedly places a\nburden ontheprogrammer, but thisburden isoffset bytherewards itprovides, for\nit enforces the encapsulation principle and often catches programming errors that\nwouldotherwisegounnoticed.\n2.3.1 Interfaces in Java\nThe main structural element in Java that enforces an API is an interface. An in-\nterface is a collection of method declarations with no data and no bodies. That is,\nthe methods of an interface are always empty; they are simply method signatures.\nInterfaces donothaveconstructors andtheycannotbedirectlyinstantiated.\nWhen a class implements an interface, it must implement all of the methods\ndeclared in the interface. In this way, interfaces enforce requirements that an im-\nplementing classhasmethodswithcertainspecifiedsignatures.\nSuppose, forexample, thatwewanttocreateaninventory ofantiquesweown,\ncategorized as objects of various types and withvarious properties. Wemight, for\ninstance, wishtoidentify someofourobjects assellable, inwhichcasetheycould\nimplementtheSellableinterface showninCodeFragment2.8.\nWecanthendefineaconcreteclass,Photograph,showninCodeFragment2.9,\nthat implements the Sellable interface, indicating that we would be willing to sell\nany of our Photograph objects. This class defines an object that implements each\nofthemethods oftheSellableinterface, asrequired. Inaddition, itaddsamethod,\nisColor,whichisspecialized forPhotographobjects.\nAnotherkindofobjectinourcollectionmightbesomethingwecouldtransport.\nForsuchobjects, wedefinetheinterface showninCodeFragment2.10.\nwww.it-ebooks.info\n2.3. InterfacesandAbstractClasses 77\n1 /\u2217\u2217 Interface for objects that can be sold. \u2217/\n2 public interface Sellable\n{\n3\n4 /\u2217\u2217 Returns a description of the object. \u2217/\n5 public String description();\n6\n7 /\u2217\u2217 Returns the list price in cents. \u2217/\n8 public int listPrice();\n9\n10 /\u2217\u2217 Returns the lowest price in cents we will accept. \u2217/\n11 public int lowestPrice();\n12\n}\nCodeFragment2.8: InterfaceSellable.\n1 /\u2217\u2217 Class for photographs that can be sold. \u2217/\n2 public class Photograph implements Sellable\n{\n3 private String descript; // description of this photo\n4 private int price; // the price we are setting\n5 private boolean color; // true if photo is in color\n6\n7 public Photograph(String desc, int p, boolean c) // constructor\n{\n8 descript = desc;\n9 price = p;\n10 color = c;\n11\n}\n12\n13 public String description() return descript;\n{ }\n14 public int listPrice() return price;\n{ }\n15 public int lowestPrice() return price/2;\n{ }\n16 public boolean isColor() return color;\n{ }\n17\n}\nCodeFragment2.9: ClassPhotographimplementing theSellableinterface.\n1 /\u2217\u2217 Interface for objects that can be transported. \u2217/\n2 public interface Transportable\n3 /\u2217\u2217 Returns the weight in gram { s. \u2217/\n4 public int weight();\n5 /\u2217\u2217 Returns whether the object is hazardous. \u2217/\n6 public boolean isHazardous();\n7\n}\nCodeFragment2.10: Interface Transportable.\nwww.it-ebooks.info\n78 Chapter2. Object-OrientedDesign\nWe could then define the class BoxedItem, shown in Code Fragment 2.11, for\nmiscellaneous antiquesthatwecansell,pack,andship. Thus,theclassBoxedItem\nimplements the methods of the Sellableinterface and the Transportable interface,\nwhilealsoaddingspecializedmethodstosetaninsuredvalueforaboxedshipment\nandtosetthedimensions ofaboxforshipment.\n1 /\u2217\u2217 Class for objects that can be sold, packed, and shipped. \u2217/\n2 public class BoxedItem implements Sellable, Transportable\n{\n3 private String descript; // description of this item\n4 private int price; // list price in cents\n5 private int weight; // weight in grams\n6 private boolean haz; // true if object is hazardous\n7 private int height=0; // box height in centimeters\n8 private int width=0; // box width in centimeters\n9 private int depth=0; // box depth in centimeters\n10 /\u2217\u2217 Constructor \u2217/\n11 public BoxedItem(String desc, int p, int w, boolean h)\n{\n12 descript = desc;\n13 price = p;\n14 weight = w;\n15 haz = h;\n16\n}\n17 public String description() return descript;\n{ }\n18 public int listPrice() return price;\n{ }\n19 public int lowestPrice() return price/2;\n{ }\n20 public int weight() return weight;\n{ }\n21 public boolean isHazardous() return haz;\n22 public int insuredValue() ret { urn price\u22172; }\n{ }\n23 public void setBox(int h, int w, int d)\n{\n24 height = h;\n25 width = w;\n26 depth = d;\n27\n}\n28\n}\nCodeFragment2.11: ClassBoxedItem.\nThe class BoxedItem shows another feature of classes and interfaces in Java,\nas well\u2014that a class can implement multiple interfaces (even though it may only\nextend one other class). This allows us a great deal of flexibility when defining\nclassesthatshouldconform tomultipleAPIs.\nwww.it-ebooks.info\n2.3. InterfacesandAbstractClasses 79\n2.3.2 Multiple Inheritance for Interfaces\nTheabilityofextendingfrommorethanonetypeisknownasmultipleinheritance.\nInJava,multipleinheritanceisallowedforinterfacesbutnotforclasses. Thereason\nfor this rule is that interfaces do not define fields or method bodies, yet classes\ntypically do. Thus, if Java were to allow multiple inheritance for classes, there\ncouldbeaconfusionifaclasstriedtoextendfromtwoclassesthatcontainedfields\nwith the same name or methods with the same signatures. Since there is no such\nconfusionforinterfaces,andtherearetimeswhenmultipleinheritanceofinterfaces\nisuseful, Javaallowsinterfaces tousemultipleinheritance.\nOne use for multiple inheritance of interfaces is to approximate a multiple in-\nheritancetechniquecalledthemixin. UnlikeJava,someobject-oriented languages,\nsuchasSmalltalkandC++,allowmultiple inheritance ofconcrete classes, notjust\ninterfaces. Insuchlanguages, itiscommontodefineclasses, called mixinclasses,\nthat are never intended to be created as stand-alone objects, but are instead meant\nto provide additional functionality to existing classes. Such inheritance is not al-\nlowed in Java, however, so programmers must approximate it with interfaces. In\nparticular, wecan use multiple inheritance ofinterfaces as amechanism for \u201cmix-\ning\u201d the methods from two ormore unrelated interfaces to define an interface that\ncombines their functionality, possibly adding moremethods ofits own. Returning\nto our example of the antique objects, we could define an interface for insurable\nitemsasfollows:\npublic interface Insurable extends Sellable, Transportable\n{\n/\u2217\u2217 Returns insured value in cents \u2217/\npublic int insuredValue();\n}\nThisinterfacecombinesthemethodsoftheTransportableinterface withthemeth-\nods of the Sellable interface, and adds an extra method, insuredValue. Such an\ninterface couldallowustodefinetheBoxedItemalternately asfollows:\npublic class BoxedItem2 implements Insurable\n{\n// ... same code as class BoxedItem\n}\nIn this case, note that the method insuredValue is not optional, whereas it was\noptional inthedeclaration ofBoxedItemgivenpreviously.\nJava interfaces thatapproximate the mixininclude java.lang.Cloneable, which\nadds a copy feature to a class; java.lang.Comparable, which adds a comparability\nfeaturetoaclass(imposinganaturalorderonitsinstances);andjava.util.Observer,\nwhich adds an update feature to a class that wishes to be notified when certain\n\u201cobservable\u201d objectschangestate.\nwww.it-ebooks.info\n80 Chapter2. Object-OrientedDesign\n2.3.3 Abstract Classes\nInJava,anabstractclassservesarolesomewhatbetweenthatofatraditionalclass\nand that of an interface. Like an interface, an abstract class may define signatures\nfor one or more methods without providing an implementation of those method\nbodies; such methods are known as abstract methods. However, unlike an inter-\nface, an abstract class may define one or more fields and any number of methods\nwithimplementation (so-called concretemethods). Anabstractclassmayalsoex-\ntendanother classandbeextendedbyfurthersubclasses.\nAsisthecasewithinterfaces, anabstract classmaynotbeinstantiated, thatis,\nno object can be created directly from an abstract class. In a sense, it remains an\nincomplete class. A subclass of an abstract class must provide an implementation\nfor the abstract methods of its superclass, or else remain abstract. To distinguish\nfromabstract classes, wewillrefertononabstract classesasconcreteclasses.\nIn comparing the use of interfaces and abstract classes, it is clear that abstract\nclasses are morepowerful, as they canprovide some concrete functionality. How-\never, the use of abstract classes in Java is limited to single inheritance, so a class\nmayhaveatmostonesuperclass, whetherconcrete orabstract (seeSection2.3.2).\nWewilltakegreatadvantage ofabstractclasses inourstudyofdatastructures,\nastheysupportgreater reusability ofcode(oneofourobject-oriented designgoals\nfrom Section 2.1.1). The commonality between a family of classes can be placed\nwithin an abstract class, which serves as a superclass to multiple concrete classes.\nInthisway,theconcretesubclassesneedonlyimplementtheadditionalfunctional-\nitythatdifferentiates themselvesfromeachother.\nAs a tangible example, we reconsider the progression hierarchy introduced in\nSection 2.2.3. Although wedidnot formally declare the Progression base class as\nabstract in that presentation, it would have been a reasonable design to have done\nso. WedidnotintendforuserstodirectlycreateinstancesoftheProgressionclass;\nin fact, the sequence that itproduces is simply aspecial case ofan arithmetic pro-\ngression with increment one. The primary purpose of the Progression class is to\nprovide common functionality to all three subclasses: the declaration and initial-\nizationofthecurrentfield,andtheconcreteimplementations ofthenextValueand\nprintProgressionmethods.\nThemostimportant aspect inspecializing that class wasinoverriding the pro-\ntectedadvancemethod. Althoughwegaveasimpleimplementationofthatmethod\nwithintheProgression class toincrement thecurrent value, none ofourthreesub-\nclasses rely on that behavior. On the next page, we demonstrate the mechan-\nics of abstract classes in Java by redesigning the progression base class into an\nAbstractProgression base class. In that design, we leave the advance method as\ntrulyabstract, leavingtheburdenofanimplementation tothevarioussubclasses.\nwww.it-ebooks.info\n2.3. InterfacesandAbstractClasses 81\nMechanics of Abstract Classes in Java\nIn Code Fragment 2.12, we give a Java implementation of a new abstract base\nclass for our progression hierarchy. We name the new class AbstractProgression\nrather than Progression, only to differentiate it in our discussion. The definitions\nare almost identical; there are only two key differences that we highlight. The\nfirst is the use of the abstract modifier on line 1, when declaring the class. (See\nSection1.2.2foradiscussion ofclassmodifiers.)\nAswithouroriginalclass,thenewclassdeclaresthecurrentfieldandprovides\nconstructors that initialize it. Although our abstract class cannot be instantiated,\nthe constructors can be invoked within the subclass constructors using the super\nkeyword. (Wedojustthat,withinallthreeofourprogression subclasses.)\nThe new class has the same concrete implementations of methods nextValue\nandprintProgressionasdidouroriginal. However,weexplicitlydefinetheadvance\nmethodwiththeabstractmodifieratline19,andwithoutanymethodbody.\nEven though we have not implemented the advance method as part of the\nAbstractProgression class, it is legal to call it from within the body of nextValue.\nThis is an example of an object-oriented design pattern known as the template\nmethod pattern, in which an abstract base class provides a concrete behavior that\nrelies upon calls to other abstract behaviors. Once a subclass provides definitions\nforthemissingabstract behaviors, theinheritedconcrete behavior iswelldefined.\n1 public abstract class AbstractProgression\n{\n2 protected long current;\n3 public AbstractProgression() this(0);\n{ }\n4 public AbstractProgression(long start) current = start;\n{ }\n5\n6 public long nextValue() // this is a concrete method\n{\n7 long answer = current;\n8 advance(); // this protected call is responsible for advancing the current value\n9 return answer;\n10\n}\n11\n12 public void printProgression(int n) // this is a concrete method\n{\n13 System.out.print(nextValue()); // print first value without leading space\n14 for (int j=1; j < n; j++)\n15 System.out.print(\" \" + nextValue()); // print leading space before others\n16 System.out.println(); // end the line\n17\n}\n18\n19 protected abstract void advance(); // notice the lack of a method body\n20\n}\nCodeFragment2.12: An abstract version of the progression base class, originally\ngiveninCodeFragment2.2. (Weomitdocumentation forbrevity.)\nwww.it-ebooks.info\n82 Chapter2. Object-OrientedDesign\n2.4 Exceptions\nExceptions are unexpected events that occur during the execution of a program.\nAnexception mightresultduetoanunavailable resource, unexpected inputfroma\nuser, or simply a logical error on the part of the programmer. In Java, exceptions\nareobjects thatcan bethrownbycodethat encounters anunexpected situation, or\nbytheJavaVirtualMachine,forexample,ifrunningoutofmemory. Anexception\nmay also be caught by a surrounding block of code that \u201chandles\u201d the problem\nin an appropriate fashion. If uncaught, an exception causes the virtual machine to\nstopexecutingtheprogramandtoreportanappropriate messagetotheconsole. In\nthis section, wediscuss common exception types inJava, aswellas thesyntax for\nthrowingandcatchexceptions withinuser-defined blocksofcode.\n2.4.1 Catching Exceptions\nIfanexception occurs andisnothandled, thentheJavaruntimesystemwilltermi-\nnatetheprogram afterprinting anappropriate message together withatraceofthe\nruntime stack. The stack trace shows the series of nested method calls that were\nactiveatthetimetheexceptionoccurred, asinthefollowingexample:\nException in thread \"main\" java.lang.NullPointerException\nat java.util.ArrayList.toArray(ArrayList.java:358)\nat net.datastructures.HashChainMap.bucketGet(HashChainMap.java:35)\nat net.datastructures.AbstractHashMap.get(AbstractHashMap.java:62)\nat dsaj.design.Demonstration.main(Demonstration.java:12)\nHowever,beforeaprogramisterminated,eachmethodonthestacktracehasan\nopportunity tocatchtheexception. Startingwiththemostdeeplynestedmethodin\nwhich the exception occurs, each method mayeither catch the exception, orallow\nittopassthroughtothemethodthatcalledit. Forexample,intheabovestacktrace,\ntheArrayList.javamethodhadthefirstopportunity tocatchtheexception. Sinceit\ndid not do so, the exception was passed upward to the HashChainMap.bucketGet\nmethod, which in turn ignored the exception, causing it to pass further upward to\nthe AbstractHashMap.get method. The final opportunity to catch the exception\nwas in the Demonstration.main method, but since it did not do so, the program\nterminated withtheabovediagnostic message.\nThe general methodology for handling exceptions is a try-catch construct in\nwhich a guarded fragment of code that might throw an exception is executed. If\nitthrowsanexception, then thatexception iscaughtby having the flowofcontrol\njump to a predefined catch block that contains the code to analyze the exception\nandapplyanappropriateresolution. Ifnoexceptionoccursintheguardedcode,all\ncatchblocksareignored.\nwww.it-ebooks.info\n2.4. Exceptions 83\nAtypicalsyntaxforatry-catch statementinJavaisasfollows:\ntry\n{\nguardedBody\ncatch(exceptionType variable )\n1 1\n} {\nremedyBody\n1\ncatch(exceptionType variable )\n2 2\n} {\nremedyBody\n2\n...\n}\n...\nEach exceptionType is the type of some exception, and each variable is a valid\ni i\nJavavariablename.\nTheJavaruntimeenvironment beginsperformingatry-catch statementsuchas\nthis by executing the block of statements, guardedBody. If no exceptions are gen-\nerated during this execution, the flow of control continues with the first statement\nbeyondthelastlineoftheentiretry-catch statement.\nIf, onthe other hand, the block, guardedBody, generates anexception atsome\npoint,theexecutionofthatblockimmediateterminatesandexecutionjumpstothe\ncatch block whose exceptionType most closely matches the exception thrown (if\nany). The variable for this catch statement references the exception object itself,\nwhichcanbeusedintheblockofthematchingcatchstatement. Onceexecutionof\nthatcatchblockcompletes, controlflowcontinues withthefirststatement beyond\ntheentiretry-catchconstruct.\nIf an exception occurs during the execution of the block, guardedBody, that\ndoes not match any of the exception types declared in the catch statements, that\nexception isrethrowninthesurrounding context.\nThere are several possible reactions when an exception is caught. One possi-\nbility is to print out an error message and terminate the program. There are also\nsome interesting cases in which the best way to handle an exception is to quietly\ncatch and ignore it (this can be done by having an empty body as a catch block).\nAnother legitimate way of handling exceptions is to create and throw another ex-\nception, possibly onethatspecifiestheexceptional condition moreprecisely.\nWenote briefly that try-catch statements in Java support afew advanced tech-\nniques that we will not use in this book. There can be an optional finally clause\nwithabodythatwillbeexecutedwhetherornotanexceptionhappensintheorigi-\nnalguardedbody;thiscanbeuseful, forexample,tocloseafilebeforeproceeding\nonward. Java SE 7 introduced a new syntax known as a \u201ctry with resource\u201d that\nprovides even more advanced cleanup techniques for resources such as open files\nthat must be properly cleaned up. Also as of Java SE 7, each catch statement can\ndesignate multiple exception types that it handles; previously, a separate clause\nwouldbeneededforeachone,evenifthesameremedywereappliedineachcase.\nwww.it-ebooks.info\n84 Chapter2. Object-OrientedDesign\n1 public static void main(String[ ] args)\n{\n2 int n = DEFAULT;\n3 try\n{\n4 n = Integer.parseInt(args[0]);\n5 if (n <= 0)\n{\n6 System.out.println(\"n must be positive. Using default.\");\n7 n = DEFAULT;\n8\n}\n9 catch (ArrayIndexOutOfBoundsException e)\n} {\n10 System.out.println(\"No argument specified for n. Using default.\");\n11 catch (NumberFormatException e)\n} {\n12 System.out.println(\"Invalid integer argument. Using default.\");\n13\n}\n14\n}\nCodeFragment2.13: Ademonstration ofcatching anexception.\nAsatangibleexampleofatry-catchstatement,weconsiderthesimpleapplica-\ntion presented inCode Fragment2.13. Thismainmethod attempts tointerpret the\nfirstcommand-lineargumentasapositiveinteger. (Command-lineargumentswere\nintroduced onpage16.)\nThe statement at risk of throwing an exception, at line 4, is the command\nn = Integer.parseInt(args[0]). That command may fail for one of two reasons.\nFirst, the attempt to access args[0] will fail if the user did not specify any argu-\nments, and thus, the array args is empty. An ArrayIndexOutOfBoundsException\nwill be thrown in that case (and caught by us at line 9). The second potential ex-\nception is when calling the Integer.parseInt method. That command succeeds so\nlong asthe parameter isastring that isalegitimate integer representation, such as\n\"2013\". Of course, since a command-line argument can be any string, the user\nmightprovideaninvalid integerrepresentation, inwhichcasetheparseIntmethod\nthrowsaNumberFormatException (caught byusatline11).\nA final condition we wish to enforce is that the integer specified by the user\nis positive. To test this property, we rely on a traditional conditional statement\n(lines 5\u20138). However,notice thatwehaveplaced thatconditional statement within\ntheprimarybodyofthetry-catchstatement. Thatconditionalstatementwillonlybe\nevaluated ifthecommandatline 4succeeded without exception; hadanexception\noccurredatline4,theprimarytryblockisterminated,andcontrolproceedsdirectly\ntotheexception handling fortheappropriate catchstatement.\nAs an aside, if we had been willing to use the same error message for the two\nexceptional cases, wecanuseasinglecatchclausewiththefollowingsyntax:\ncatch (ArrayIndexOutOfBoundsException NumberFormatException e)\n} | {\nSystem.out.println(\"Using default value for n.\");\n}\nwww.it-ebooks.info\n2.4. Exceptions 85\n2.4.2 Throwing Exceptions\nExceptions originate whenapiece of Java code findssomesort ofproblem during\nexecutionandthrowsanexceptionobject. Thisisdonebyusingthethrowkeyword\nfollowed by an instance of the exception type to be thrown. It is often convenient\ntoinstantiate anexception objectatthetimetheexception hastobethrown. Thus,\nathrowstatementistypically writtenasfollows:\nthrownew exceptionType(parameters);\nwhere exceptionType is the type of the exception and the parameters are sent to\nthat type\u2019s constructor; most exception types offer a version of a constructor that\nacceptsanerrormessagestringasaparameter.\nAs an example, the following method takes an integer parameter, which it ex-\npects to be positive. If a negative integer is sent, an IllegalArgumentException is\nthrown.\npublic void ensurePositive(int n)\n{\nif (n < 0)\nthrow new IllegalArgumentException(\"That's not positive!\");\n// ...\n}\nTheexecutionofathrowstatementimmediatelyterminatesthebodyofamethod.\nThe Throws Clause\nWhen a method is declared, it is possible to explicitly declare, as part of its sig-\nnature, the possibility that aparticular exception type maybethrown during acall\nto that method. It does not matter whether the exception is directly from a throw\nstatementinthatmethodbody,orpropagatedupwardfromasecondarymethodcall\nmadefromwithinthebody.\nThesyntaxfordeclaringpossibleexceptionsinamethodsignaturereliesonthe\nkeywordthrows(nottobeconfusedwithanactualthrowstatement). Forexample,\ntheparseIntmethodoftheIntegerclasshasthefollowingformalsignature:\npublic static int parseInt(String s) throws NumberFormatException;\nThedesignation \u201cthrows NumberFormatException\u201dwarns users about the possi-\nbility of an exceptional case, so that they might be better prepared to handle an\nexception that mayarise. Ifone ofmanyexception types maypossibly bethrown,\nall such types can be listed, separated with commas. Alternatively, it may be pos-\nsible tolist anappropriate superclass that encompasses allspecific exceptions that\nmaybethrown.\nwww.it-ebooks.info\n86 Chapter2. Object-OrientedDesign\nThe use of a throws clause in a method signature does not take away the re-\nsponsibility ofproperlydocumenting allpossibleexceptionsthroughtheuseofthe\n@throws tag within a javadoc comment (see Section 1.9.4). The type and reasons\nforanypotential exceptions should alwaysbeproperly declared inthedocumenta-\ntionforamethod.\nIn contrast, the use of the throws clause in a method signature is optional\nfor many types of exceptions. For example, the documentation for the nextInt()\nmethod of the Scanner class makes clear that three different exception types may\narise:\nAnIllegalStateException,ifthescannerhasbeenclosed\n\u2022\nA NoSuchElementException, if the scanner is active, but there is currently\n\u2022\nnotokenavailable forinput\nAn InputMismatchException, if the next available token does not represent\n\u2022\naninteger\nHowever, no potential exceptions are formally declared within the method signa-\nture;theyareonlynotedinthedocumentation.\nTo better understand the functional purpose of the throws declaration in a\nmethodsignature, itishelpful toknowmoreaboutthewayJavaorganizes itshier-\narchyofexceptiontypes.\n2.4.3 Java\u2019s Exception Hierarchy\nJavadefinesarich inheritance hierarchy ofallobjects thataredeemedThrowable.\nWeshowasmallportionofthishierarchyinFigure2.7. Thehierarchyisintention-\nallydivided intotwosubclasses: ErrorandException. Errorsaretypically thrown\nonlybytheJavaVirtualMachineanddesignate themostserioussituations thatare\nunlikely to be recoverable, such as when the virtual machine is asked to execute\na corrupt class file, or when the system runs out of memory. In contrast, excep-\ntionsdesignate situations inwhicharunning program mightreasonably beableto\nrecover, forexample,whenunabletoopenadatafile.\nChecked and Unchecked Exceptions\nJava provides further refinement by declaring the RuntimeException class as an\nimportant subclass of Exception. All subtypes of RuntimeException in Java are\nofficially treated as unchecked exceptions, and any exception type that is not part\noftheRuntimeExceptionisacheckedexception.\nThe intent of the design is that runtime exceptions occur entirely due to mis-\ntakesinprogramminglogic,suchasusingabadindexwithanarray,orsendingan\ninappropriate value as a parameter to a method. While such programming errors\nwww.it-ebooks.info\n2.4. Exceptions 87\nThrowable\nError Exception\nVirtualMachineError IOError ... RuntimeException IOException ...\nOutofMemoryError\nIllegalArgumentException FileNotFoundException EOFException\nIndexOutOfBoundsException\nNumberFormatException NullPointerException\nArrayIndexOutOfBoundsException NoSuchElementException ClassCastException\nFigure2.7: Asmallportion ofJava\u2019shierarchy ofThrowabletypes.\nwill certainly occur as part of the software development process, they should pre-\nsumably be resolved before software reaches production quality. Therefore, it is\nnotintheinterestofefficiencytoexplicitlycheckforeachsuchmistakeatruntime,\nandthusthesearedesignated as\u201cunchecked\u201d exceptions.\nIn contrast, other exceptions occur because of conditions that cannot easily be\ndetecteduntilaprogramisexecuting,suchasanunavailablefileorafailednetwork\nconnection. Those are typically designated as \u201cchecked\u201d exceptions in Java (and\nthus,notasubtype ofRuntimeException).\nThedesignationbetweencheckedanduncheckedexceptionsplaysasignificant\nroleinthesyntax ofthelanguage. Inparticular, allcheckedexceptions thatmight\npropagate upwardfromamethodmustbeexplicitly declared initssignature.\nA consequence is that if one method calls asecond method declaring checked\nexceptions, then the call to that second method must either be guarded within a\ntry-catch statement, or else the calling method must itself declare the checked ex-\nceptions initssignature, since thereisriskthatsuchanexception mightpropagate\nupwardfromthecallingmethod.\nDefining New Exception Types\nInthisbook,wewillrelyentirelyonexistingRuntimeExceptiontypestodesignate\nvarious requirements on the use of our data structures. However, some libraries\ndefine newclasses of exceptions todescribe more specific conditions. Specialized\nexceptions should inherit either from the Exception class (if checked), from the\nRuntimeException class (if unchecked), or from an existing Exception subtype\nthatismorerelevant.\nwww.it-ebooks.info\n88 Chapter2. Object-OrientedDesign\n2.5 Casting and Generics\nInthissection,wediscusscastingamongreferencevariables,aswellasatechnique,\ncalledgenerics,thatallowsustodefinemethodsandclassesthatworkwithavariety\nofdatatypeswithouttheneedforexplicitcasting.\n2.5.1 Casting\nWebeginourdiscussion withmethodsfortypeconversions forobjects.\nWidening Conversions\nA widening conversion occurs when a type T is converted into a \u201cwider\u201d typeU.\nThefollowingarecommoncasesofwideningconversions:\nT andU areclasstypesandU isasuperclass ofT.\n\u2022\nT andU areinterface typesandU isasuperinterface ofT.\n\u2022\nT isaclassthatimplementsinterfaceU.\n\u2022\nWidening conversions areautomatically performed tostoretheresultofanex-\npressionintoavariable,withouttheneedforanexplicitcast. Thus,wecandirectly\nassign the result of an expression of type T into a variable v of typeU when the\nconversion fromT toU isawideningconversion. Whendiscussing polymorphism\nonpage68,wegavethefollowingexampleofanimplicitwideningcast,assigning\nan instance of the narrower PredatoryCreditCard class to a variable of the wider\nCreditCardtype:\nCreditCard card = new PredatoryCreditCard(...); // parameters omitted\nThe correctness of a widening conversion can be checked by the compiler and its\nvalidity does not require testing by the Java runtime environment during program\nexecution.\nNarrowing Conversions\nA narrowing conversion occurs when a type T is converted into a \u201cnarrower\u201d\ntypeS. Thefollowingarecommoncasesofnarrowingconversions:\nT andSareclasstypesandSisasubclass ofT.\n\u2022\nT andSareinterface typesandSisasubinterface ofT.\n\u2022\nT isaninterface implementedbyclassS.\n\u2022\nIngeneral, anarrowing conversion ofreference types requires anexplicit cast.\nAlso, thecorrectness ofanarrowing conversion maynot beverifiable bythecom-\npiler. Thus, its validity should be tested by the Java runtime environment during\nprogram execution.\nwww.it-ebooks.info\n2.5. CastingandGenerics 89\nThe example code fragment below shows how to use a cast to perform a nar-\nrowingconversion fromtypePredatoryCreditCardtotypeCreditCard.\nCreditCard card = new PredatoryCreditCard(...); // widening\nPredatoryCreditCard pc = (PredatoryCreditCard) card; // narrowing\nAlthoughvariablecardhappenstoreferenceaninstanceofaPredatoryCreditCard,\nthe variable has declared type, CreditCard. Therefore, the assignment pc = card\nis a narrowing conversion and requires an explicit cast that will be evaluated at\nruntime(asnotallcardsarepredatory).\nCasting Exceptions\nIn Java, we can cast an object reference o of type T into a type S, provided the\nobject o is referring to is actually of type S. If, on the other hand, object o is not\nalso of type S, then attempting to cast o to type S will throw an exception called\nClassCastException. We illustrate this rule in the following code fragment, using\nJava\u2019sNumberabstract class,whichisasuperclass ofbothIntegerandDouble.\nNumber n;\nInteger i;\nn = new Integer(3);\ni = (Integer) n; // This is legal\nn = new Double(3.1415);\ni = (Integer) n; // This is illegal\nToavoid problems such asthis andtoavoid peppering ourcode withtry-catch\nblocks every time we perform a cast, Java provides a way to make sure an object\ncastwillbecorrect. Namely,itprovides anoperator, instanceof,thatallowsusto\ntest whether anobject variable is referring to anobject that belongs to aparticular\ntype. The syntax for this operator is objectReference instanceof referenceType,\nwhere objectReference is an expression that evaluates to an object reference and\nreferenceType isthenameofsomeexisting class, interface, orenum (Section1.3).\nIfobjectReference isindeedaninstancesatisfyingreferenceType, thentheoperator\nreturnstrue;otherwise, itreturnsfalse. Thus,wecanavoidaClassCastException\nfrombeingthrowninthecodefragmentabovebymodifying itasfollows:\nNumber n;\nInteger i;\nn = new Integer(3);\nif (n instanceof Integer)\ni = (Integer) n; // This is legal\nn = new Double(3.1415);\nif (n instanceof Integer)\ni = (Integer) n; // This will not be attempted\nwww.it-ebooks.info\n90 Chapter2. Object-OrientedDesign\nCasting with Interfaces\nInterfaces allow us to enforce that objects implement certain methods, but using\ninterface variables with concrete objects sometimes requires casting. Suppose we\ndeclare a Person interface as shown in Code Fragment 2.14. Note that method\nequals of the Person interface takes one parameter of type Person. Thus, we can\npassanobjectofanyclassimplementing thePersoninterface tothismethod.\n1 public interface Person\n{\n2 public boolean equals(Person other); // is this the same person?\n3 public String getName(); // get this person\u2019s name\n4 public int getAge(); // get this person\u2019s age\n5\n}\nCodeFragment2.14: Interface Person.\nIn Code Fragment 2.15, we show a class, Student, that implements Person.\nBecause theparameter toequalsis aPerson, the implementation mustnot assume\nthat itisnecessarily oftype Student. Instead, itfirstuses the instanceof operator\nat line 15, returning false if the argument is not a student (since it surely is not\nthe student in question). Only after verifying that the parameter is a student, is it\nexplicitly casttoaStudent,atwhichpointitsidfieldcanbeaccessed.\n1 public class Student implements Person\n{\n2 String id;\n3 String name;\n4 int age;\n5 public Student(String i, String n, int a) // simple constructor\n{\n6 id = i;\n7 name = n;\n8 age = a;\n9\n}\n10 protected int studyHours() return age/2; // just a guess\n{ }\n11 public String getID() return id; // ID of the student\n{ }\n12 public String getName() return name; // from Person interface\n{ }\n13 public int getAge() return age; // from Person interface\n{ }\n14 public boolean equals(Person other) // from Person interface\n{\n15 if (!(other instanceof Student)) return false; // cannot possibly be equal\n16 Student s = (Student) other; // explicit cast now safe\n17 return id.equals(s.id); // compare IDs\n18\n}\n19 public String toString() // for printing\n{\n20 return \"Student(ID:\" + id + \", Name:\" + name + \", Age:\" + age + \")\";\n21\n}\n22\n}\nCodeFragment2.15: ClassStudentimplementing interface Person.\nwww.it-ebooks.info\n2.5. CastingandGenerics 91\n2.5.2 Generics\nJavaincludessupportforwritinggenericclassesandmethodsthatcanoperateona\nvariety ofdata types whileoften avoiding the needfor explicit casts. Thegenerics\nframework allows ustodefine aclass interms ofaset offormal type parameters,\nwhich can then be used as the declared type for variables, parameters, and return\nvalueswithintheclassdefinition. Thoseformaltypeparameters arelaterspecified\nwhenusingthegenericclassasatypeelsewhereinaprogram.\nTobetter motivatetheuseofgenerics, weconsider asimplecasestudy. Often,\nwe wish to treat a pair of related values as a single object, for example, so that\nthe pair can bereturned from amethod. Asolution is todefine anew class whose\ninstances store both values. This is our first example of an object-oriented design\npatternknownasthecompositiondesignpattern. Ifweknow,forexample,thatwe\nwant a pair to store a string and a floating-point number, perhaps to store a stock\nticker label and a price, we could easily design a custom class for that purpose.\nHowever,foranotherpurpose,wemightwanttostoreapairthatconsistsofaBook\nobject and an integer that represents aquantity. The goal of generic programming\nistobeabletowriteasingleclassthatcanrepresent allsuchpairs.\nThe generics framework was not a part of the original Java language; it was\nadded as part of Java SE 5. Prior to that, generic programming was implemented\nby relying heavily on Java\u2019s Object class, which is the universal supertype of all\nobjects(including thewrappertypescorresponding toprimitives). Inthat\u201cclassic\u201d\nstyle,ageneric pairmightbeimplemented asshowninCodeFragment2.16.\n1 public class ObjectPair\n{\n2 Object first;\n3 Object second;\n4 public ObjectPair(Object a, Object b) // constructor\n{\n5 first = a;\n6 second = b;\n7\n}\n8 public Object getFirst() return first;\n{ }\n9 public Object getSecond() return second;\n{ }\n10\n}\nCodeFragment2.16: Representing agenericpairofobjectsusingaclassicstyle.\nAn ObjectPair instance stores the two objects that are sent to the constructor,\nandprovidesindividual accessors foreachcomponent ofthepair. Withthisdefini-\ntion,apaircanbedeclaredandinstantiated withthefollowingcommand:\nObjectPair bid = new ObjectPair(\"ORCL\", 32.07);\nThisinstantiationislegalbecausetheparameterstotheconstructorundergowiden-\ningconversions. Thefirstparameter, \"ORCL\",isaString,andthusalsoanObject.\nwww.it-ebooks.info\n92 Chapter2. Object-OrientedDesign\nThe second parameter is a double, but it is automatically boxed into a Double,\nwhich then qualifies as an Object. (For the record, this is not quite the \u201cclassic\u201d\nstyle,asautomaticboxingwasnotintroduced untilJavaSE5.)\nThe drawback of the classic approach involves use of the accessors, both of\nwhichformally returnanObjectreference. Evenifweknowthatthefirstobjectis\nastringinourapplication, wecannot legallymakethefollowingassignment:\nString stock = bid.getFirst(); // illegal; compile error\nThisrepresents anarrowing conversion from the declared return type of Object to\nthevariableoftypeString. Instead, anexplicitcastisrequired, asfollows:\nString stock = (String) bid.getFirst();// narrowing cast: Object to String\nWiththeclassicstyleforgenerics, codebecamerampantwithsuchexplicit casts.\nUsing Java\u2019s Generics Framework\nWith Java\u2019s generics framework, we can implement a pair class using formal type\nparameters to represent the two relevant types in our composition. An implemen-\ntationusingthisframeworkisgiveninCodeFragment2.17.\n1 public class Pair<A,B>\n{\n2 A first;\n3 B second;\n4 public Pair(A a, B b) // constructor\n{\n5 first = a;\n6 second = b;\n7\n}\n8 public A getFirst() return first;\n{ }\n9 public B getSecond() return second;\n{ }\n10\n}\nCodeFragment2.17: Representing apairofobjectswithgenerictypeparameters.\nAnglebracketsareusedatline1toenclosethesequenceofformaltypeparameters.\nAlthough anyvalididentifier canbeusedforaformaltypeparameter, single-letter\nuppercasenamesareconventionally used(inthisexample,AandB). Wemaythen\nusethesetype parameters withinthebody oftheclass definition. Forexample, we\ndeclare instance variable, first, to have type A; we similarly use A as the declared\ntypeforthefirstconstructor parameterandforthereturntypeofmethod,getFirst.\nWhensubsequentlydeclaringavariablewithsuchaparameterizetype,wemust\nexplicitly specify actual type parameters that will take the place of the generic\nformal type parameters. Forexample, to declare avariable that isa pair holding a\nstock-ticker stringandaprice,wewritethefollowing:\nPair<String,Double> bid;\nwww.it-ebooks.info\n2.5. CastingandGenerics 93\nEffectively, we have stated that we wish to have String serve in place of type A,\nandDoubleserveinplaceoftypeBforthepairknownasbid. Theactualtypesfor\ngenericprogrammingmustbeobjecttypes,whichiswhyweusethewrapperclass\nDouble instead of the primitive type double. (Fortunately, the automatic boxing\nandunboxing willworkinourfavor.)\nWecansubsequently instantiate thegeneric classusingthefollowingsyntax:\nbid = new Pair<>(\"ORCL\", 32.07); // rely on type inference\nAfter the new operator, we provide the name of the generic class, then an empty\nset of angle brackets (known as the \u201cdiamond\u201d), and finally the parameters to the\nconstructor. An instance of the generic class is created, with the actual types for\nthe formal type parameters determined based upon the original declaration of the\nvariabletowhichitisassigned(bidinthisexample). Thisprocessisknownastype\ninference,andwasintroduced tothegenerics frameworkinJavaSE7.\nIt is also possible to use a style that existed prior to Java SE 7, in which the\ngeneric type parameters are explicitly specified between angle brackets during in-\nstantiation. Usingthatstyle,ourpreviousexamplewouldbeimplemented as:\nbid = new Pair<String,Double>(\"ORCL\", 32.07); // give explicit types\nHowever, it is important that one of the two above styles be used. If angle\nbrackets areentirely omitted,asinthefollowingexample,\nbid = new Pair(\"ORCL\", 32.07); // classic style\nthisreverts totheclassic style, withObjectautomatically usedforallgeneric type\nparameters, and resulting inacompiler warning whenassigning to avariable with\nmorespecifictypes.\nAlthough the syntax for the declaration and instantiation of objects using the\ngenerics framework is slightly more cluttered than the classic style, the advantage\nis that there is no longer any need for explicit narrowing casts from Object to a\nmore specific type. Continuing with our example, since bid was declared with\nactualtypeparameters<String,Double>,thereturntypeofthegetFirst()method\nis String, and the return type of the getSecond() method is Double. Unlike the\nclassic style, we can make the following assignments without any explicit casting\n(although thereisstillanautomaticunboxing oftheDouble):\nString stock = bid.getFirst();\ndouble price = bid.getSecond();\nwww.it-ebooks.info\n94 Chapter2. Object-OrientedDesign\nGenerics and Arrays\nThereisanimportantcaveatrelatedtogenerictypesandtheuseofarrays. Although\nJava allows the declaration of an array storing a parameterized type, it does not\ntechnicallyallowtheinstantiationofnewarraysinvolvingthosetypes. Fortunately,\nit allows an array defined with a parameterized type to be initialized with a newly\ncreated, nonparametric array, which can then be cast to the parameterized type.\nEvenso,thislattermechanismcausestheJavacompilertoissueawarning,because\nitisnot100%type-safe.\nWewillseethisissueariseintwoways:\nCode outside a generic class may wish to declare an array storing instances\n\u2022\nofthegenericclasswithactualtypeparameters.\nA generic class may wish to declare an array storing objects that belong to\n\u2022\noneoftheformalparametertypes.\nAsanexampleofthefirstusecase,wecontinuewithourstockmarketexample\nandpresumethatwewouldliketokeepanarrayofPair<String,Double>objects.\nSuchanarraycanbedeclaredwithaparameterizedtype,butitmustbeinstantiated\nwith an unparameterized type and then cast back to the parameterized type. We\ndemonstrate thisusageinthefollowing:\nPair<String,Double>[ ] holdings;\nholdings = new Pair<String,Double>[25]; // illegal; compile error\nholdings = new Pair[25]; // correct, but warning about unchecked cast\nholdings[0] = new Pair<>(\"ORCL\", 32.07); // valid element assignment\nAsanexampleofthesecond usecase,assumethatwewanttocreateageneric\nPortfolio class that can store a fixed number of generic entries in an array. If the\nclass uses <T> as a parameterized type, it can declare an array of type T[ ], but\nit cannot directly instantiate such an array. Instead, a common approach is to in-\nstantiateanarrayoftypeObject[ ],andthenmakeanarrowingcasttotypeT[ ],as\nshowninthefollowing:\npublic class Portfolio<T>\n{\nT[ ] data;\npublic Portfolio(int capacity)\n{\ndata = new T[capacity]; // illegal; compiler error\ndata = (T[ ]) new Object[capacity]; // legal, but compiler warning\n}\npublic T get(int index) return data[index];\n{ }\npublic void set(int index, T element) data[index] = element;\n{ }\n}\nwww.it-ebooks.info\n2.5. CastingandGenerics 95\nGeneric Methods\nThegenericsframeworkallowsustodefinegenericversionsofindividualmethods\n(as opposed to generic versions of entire classes). To do so, we include a generic\nformaltypedeclaration amongthemethodmodifiers.\nFor example, we show below a nonparametric GenericDemo class with a pa-\nrameterized static method that can reverse an array containing elements of any\nobjecttype.\npublic class GenericDemo\n{\npublic static <T> void reverse(T[ ] data)\n{\nint low = 0, high = data.length 1;\n\u2212\nwhile (low < high) // swap data[low] and data[high]\n{\nT temp = data[low];\ndata[low++] = data[high]; // post-increment of low\ndata[high ] = temp; // post-decrement of high\n\u2212\u2212\n}\n}\n}\nNotetheuseofthe<T>modifiertodeclarethemethodtobegeneric, andtheuse\nofthetypeTwithinthemethodbody, whendeclaring thelocalvariable, temp.\nThemethodcanbecalledusingthesyntax,GenericDemo.reverse(books),with\ntype inference determining the generic type, assuming books is an array of some\nobject type. (This generic method cannot be applied to primitive arrays, because\nautoboxing doesnotapplytoentirearrays.)\nAsanaside,wenotethatwecouldhaveimplementedareversemethodequally\nwellusingaclassicstyle,actinguponanObject[ ]array.\nBounded Generic Types\nBy default, when using a type name such as T in a generic class or method, a\nuser can specify any object type as the actual type of the generic. A formal pa-\nrameter type can be restricted by using the extends keyword followed by a class\nor interface. In that case, only a type that satisfies the stated condition is allowed\nto substitute for the parameter. The advantage of such a bounded type is that it\nbecomespossible tocallanymethodsthatareguaranteed bythestatedbound.\nAs an example, we might declare a generic ShoppingCart that could only be\ninstantiatedwithatypethatsatisfiedtheSellableinterface(fromCodeFragment2.8\nonpage77). Suchaclasswouldbedeclaredbeginning withtheline:\npublic class ShoppingCart<T extends Sellable>\n{\nWithin that class definition, we would then be allowed to call methods such as\ndescription()andlowestPrice()onanyinstances oftypeT.\nwww.it-ebooks.info\n96 Chapter2. Object-OrientedDesign\n2.6 Nested Classes\nJava allows a class definition to be nested inside the definition of another class.\nThe main use for nesting classes is when defining a class that is strongly affili-\natedwithanotherclass. Thiscanhelpincreaseencapsulation andreduceundesired\nname conflicts. Nested classes are a valuable technique when implementing data\nstructures, as an instance of a nested use can be used to represent a small portion\nof a larger data structure, or an auxiliary class that helps navigate a primary data\nstructure. Wewillusenestedclassesinmanyimplementations withinthisbook.\nTodemonstratethemechanicsofanestedclass,weconsideranewTransaction\nclasstosupportloggingoftransactionsassociatedwithacreditcard. Thatnewclass\ndefinitioncanbenestedwithintheCreditCardclassusingastyleasfollows:\npublic class CreditCard\n{\nprivate static class Transaction /\u2217 details omitted \u2217/\n{ }\n// instance variable for a CreditCard\nTransaction[ ] history; // keep log of all transactions for this card\n}\nThecontainingclassisknownastheouterclass. Thenestedclassisformallya\nmemberoftheouterclass,anditsfullyqualifiednameisOuterName.NestedName.\nForexample, withtheabovedefinition thenestedclassisCreditCard.Transaction,\nalthoughwemayrefertoitsimplyasTransactionfromwithintheCreditCardclass.\nMuch like packages (see Section 1.8), the use of nested classes can help re-\nduce name collisions, as it is perfectly acceptable to have another class named\nTransactionnestedwithinsomeotherclass(orasaself-standing class).\nA nested class has an independent set of modifiers from the outer class. Visi-\nbility modifiers (e.g., public, private) effect whether the nested class definition is\naccessible beyond the outer class definition. For example, a private nested class\ncanbeusedbytheouterclass,butbynootherclasses.\nAnestedclasscanalsobedesignated aseitherstaticor(bydefault) nonstatic,\nwithsignificantconsequences. Astaticnestedclassismostlikeatraditionalclass;\nitsinstances havenoassociation withanyspecificinstanceoftheouterclass.\nA nonstatic nested class is more commonly known as an inner class in Java.\nAninstanceofaninnerclasscanonlybecreatedfromwithinanonstaticmethodof\nthe outer class, and that inner instance becomes associated with the outer instance\nthat creates it. Each instance of an inner class implicitly stores a reference to its\nassociated outerinstance, accessible fromwithintheinnerclassmethodsusingthe\nsyntax OuterName.this (as opposed to this, which refers to the inner instance).\nThe inner instance also has private access to all members of its associated outer\ninstance, andcanrelyontheformaltypeparameters oftheouterclass,ifgeneric.\nwww.it-ebooks.info\n2.7. Exercises 97\n2.7 Exercises\nReinforcement\nR-2.1 Givethreeexamplesoflife-criticalsoftwareapplications.\nR-2.2 Give an example of a software application in which adaptability can mean the\ndifferencebetweenaprolongedlifetimeofsalesandbankruptcy.\nR-2.3 Describe a componentfroma text-editorGUI and the methodsthatit encapsu-\nlates.\nR-2.4 Assume that we change the CreditCard class (see Code Fragment 1.5) so that\ninstancevariablebalancehasprivatevisibility.Whyisthefollowingimplemen-\ntationofthePredatoryCreditCard.chargemethodflawed?\npublic boolean charge(double price)\n{\nboolean isSuccess = super.charge(price);\nif (!isSuccess)\ncharge(5); // the penalty\nreturn isSuccess;\n}\nR-2.5 Assume that we change the CreditCard class (see Code Fragment 1.5) so that\ninstancevariablebalancehasprivatevisibility.Whyisthefollowingimplemen-\ntationofthePredatoryCreditCard.chargemethodflawed?\npublic boolean charge(double price)\n{\nboolean isSuccess = super.charge(price);\nif (!isSuccess)\nsuper.charge(5); // the penalty\nreturn isSuccess;\n}\nR-2.6 Give a shortfragmentof Java code that uses the progressionclasses fromSec-\ntion 2.2.3 to find the eighth value of a Fibonacciprogression that starts with 2\nand2asitsfirsttwovalues.\nR-2.7 Ifwechooseanincrementof128,howmanycallstothenextValuemethodfrom\ntheArithmeticProgressionclassofSection2.2.3canwemakebeforewecausea\nlong-integeroverflow?\nR-2.8 Cantwointerfacesmutuallyextendeachother? Whyorwhynot?\nR-2.9 Whataresomepotentialefficiencydisadvantagesofhavingverydeepinheritance\ntrees,thatis,alargesetofclasses,A,B,C,andsoon,suchthatBextendsA,C\nextendsB,DextendsC,etc.?\nR-2.10 Whataresomepotentialefficiencydisadvantagesofhavingveryshallowinheri-\ntancetrees,thatis,alargesetofclasses,A,B,C,andsoon,suchthatallofthese\nclassesextendasingleclass,Z?\nwww.it-ebooks.info\n98 Chapter2. Object-OrientedDesign\nR-2.11 Considerthefollowingcodefragment,takenfromsomepackage:\npublic class Maryland extends State\nMaryland() /\u2217 null constructor \u2217/ {\n{ }\npublic void printMe() System.out.println(\"Read it.\");\n{ }\npublic static void main(String[ ] args)\n{\nRegion east = new State();\nState md = new Maryland();\nObject obj = new Place();\nPlace usa = new Region();\nmd.printMe();\neast.printMe();\n((Place) obj).printMe();\nobj = md;\n((Maryland) obj).printMe();\nobj = usa;\n((Place) obj).printMe();\nusa = md;\n((Place) usa).printMe();\n}\n}\nclass State extends Region\nState() /\u2217 null construct { or \u2217/\n{ }\npublic void printMe() System.out.println(\"Ship it.\");\n{ }\n}\nclass Region extends Place\nRegion() /\u2217 null construc { tor \u2217/\n{ }\npublic void printMe() System.out.println(\"Box it.\");\n{ }\n}\nclass Place extends Object\nPlace() /\u2217 null construct { or \u2217/\n{ }\npublic void printMe() System.out.println(\"Buy it.\");\n{ }\n}\nWhatistheoutputfromcallingthemain()methodoftheMarylandclass?\nR-2.12 Drawaclassinheritancediagramforthefollowingsetofclasses:\nClassGoatextendsObjectandaddsaninstancevariabletailandmethods\n\u2022\nmilk()andjump().\nClassPigextendsObjectandaddsaninstancevariablenoseandmethods\n\u2022\neat(food)andwallow().\nClass HorseextendsObjectandaddsinstancevariablesheightandcolor,\n\u2022\nandmethodsrun()andjump().\nClassRacerextendsHorseandaddsamethodrace().\n\u2022\nClassEquestrianextendsHorseandaddsinstancevariableweightandis-\n\u2022\nTrained,andmethodstrot()andisTrained().\nwww.it-ebooks.info\n2.7. Exercises 99\nR-2.13 ConsidertheinheritanceofclassesfromExerciseR-2.12,andletd beanobject\nvariableoftypeHorse. Ifd referstoanactualobjectoftypeEquestrian,canit\nbecasttotheclassRacer? Whyorwhynot?\nR-2.14 Give an exampleof a Java code fragmentthat performsan array referencethat\nis possibly out of bounds, and if it is out of bounds, the program catches that\nexceptionandprintsthefollowingerrormessage:\n\u201cDon\u2019t try buffer overflow attacks in Java!\u201d\nR-2.15 IftheparametertothemakePaymentmethodoftheCreditCardclass(seeCode\nFragment 1.5) were a negative number, that would have the effect of raising\nthe balance on the account. Revise the implementation so that it throws an\nIllegalArgumentExceptionifanegativeamountissentasaparameter.\nCreativity\nC-2.16 Suppose you are on the design team for a new e-book reader. What are the\nprimary classes and methods that the Java software for your reader will need?\nYoushouldincludeaninheritancediagramforthis code, butyoudon\u2019tneedto\nwriteanyactualcode.Yoursoftwarearchitectureshouldatleastincludewaysfor\ncustomersto buynew books, view their list of purchasedbooks, andread their\npurchasedbooks.\nC-2.17 MostmodernJavacompilershaveoptimizersthatcandetectsimplecaseswhen\nitislogicallyimpossibleforcertainstatementsinaprogramtoeverbeexecuted.\nInsuchcases,thecompilerwarnstheprogrammerabouttheuselesscode. Write\na short Java method that contains code for which it is provably impossible for\nthatcodetoeverbeexecuted,yettheJavacompilerdoesnotdetectthisfact.\nC-2.18 ThePredatoryCreditCardclassprovidesaprocessMonth()methodthatmodels\nthecompletionofamonthlycycle. Modifytheclasssothatonceacustomerhas\nmadeten callstocharge duringa month,eachadditionalcallto thatmethodin\nthecurrentmonthresultsinanadditional$1surcharge.\nC-2.19 ModifythePredatoryCreditCardclasssothatacustomerisassignedaminimum\nmonthlypayment,asapercentageofthebalance,andsothatalatefeeisassessed\nifthecustomerdoesnotsubsequentlypaythatminimumamountbeforethenext\nmonthlycycle.\nC-2.20 Assume that we change the CreditCard class (see Code Fragment 1.5) so that\ninstancevariablebalancehasprivatevisibility,butanewprotectedmethodis\nadded, with signature setBalance(newBalance). Show how to properly imple-\nmentthemethodPredatoryCreditCard.processMonth()inthissetting.\nC-2.21 Write aprogramthatconsistsofthreeclasses, A,B, andC, suchthatB extends\nAandthatCextendsB. Eachclassshoulddefineaninstancevariablenamed\u201cx\u201d\n(thatis, eachhasits ownvariablenamedx). Describea wayfora methodinC\nto access and set A\u2019s version of x to a given value, without changing B orC\u2019s\nversion.\nwww.it-ebooks.info\n100 Chapter2. Object-OrientedDesign\nC-2.22 Explainwhy the Java dynamicdispatch algorithm, whichlooksfor the method\ntoinvokeforacallobj.foo(),willnevergetintoaninfiniteloop.\nC-2.23 ModifytheadvancemethodoftheFibonacciProgressionclasssoastoavoiduse\nofanytemporaryvariable.\nC-2.24 WriteaJavaclassthatextendstheProgressionclasssothateachvalueinthepro-\ngressionistheabsolutevalueofthedifferencebetweentheprevioustwovalues.\nYoushouldincludeadefaultconstructorthatstartswith2and200asthefirsttwo\nvaluesand a parametricconstructorthatstarts with a specified pair of numbers\nasthefirsttwovalues.\nC-2.25 RedesigntheProgressionclasstobeabstractandgeneric,producingasequence\nofvaluesofgenerictypeT, andsupportinga singleconstructorthatacceptsan\ninitial value. Make all correspondingmodificationsto the rest of the classes in\nourhierarchysothattheyremainasnongenericclasses,whileinheritingfromthe\nnewgenericProgressionclass.\nC-2.26 Use a solution to Exercise C-2.25 to create a new progression class for which\neach value is the square root of the previous value, represented as a Double.\nYoushouldincludeadefaultconstructorthathas65,536asthefirstvalueanda\nparametricconstructorthatstartswithaspecifiednumberasthefirstvalue.\nC-2.27 UseasolutiontoExerciseC-2.25toreimplementtheFibonacciProgressionsub-\nclasstorelyontheBigIntegerclass,inordertoavoidoverflowsalltogether.\nC-2.28 WriteasetofJavaclassesthatcansimulateanInternetapplicationinwhichone\nparty, Alice, is periodically creating a set of packets that she wants to send to\nBob. An Internet process is continually checking if Alice has any packets to\nsend,andifso,itdeliversthemtoBob\u2019scomputer;Bobisperiodicallychecking\nifhiscomputerhasapacketfromAlice,andifso,hereadsanddeletesit.\nC-2.29 WriteaJavaprogramthatinputsapolynomialinstandardalgebraicnotationand\noutputsthefirstderivativeofthatpolynomial.\nProjects\nP-2.30 WriteaJavaprogramthatinputsadocumentandthenoutputsabar-chartplotof\nthefrequenciesofeachalphabetcharacterthatappearswithinthatdocument.\nP-2.31 WriteaJavaprogramtosimulateanecosystemcontainingtwotypesofcreatures,\nbearsandfish. Theecosystemconsistsofariver,whichismodeledasarelatively\nlarge array. Each cell of the arrayshould contain an Animal object, which can\nbe a Bear object, a Fish object, or null. In each time step, based on a random\nprocess, eachanimaleitherattemptsto moveintoanadjacentarraycellorstay\nwhere it is. If two animals of the same type are about to collide in the same\ncell, then they stay where they are, but they create a new instance of that type\nof animal, which is placed in a randomempty (i.e., previouslynull) cell in the\narray. Ifabearandafishcollide,however,thenthefishdies(i.e.,itdisappears).\nUse actual object creation, via the new operator, to model the creation of new\nobjects,andprovideavisualizationofthearrayaftereachtimestep.\nwww.it-ebooks.info\nChapterNotes 101\nP-2.32 Writeasimulatorasinthepreviousproject,butaddabooleangenderfieldand\na floating-point strength field to each Animal object. Now, if two animals of\nthesametypetrytocollide,thentheyonlycreateanewinstanceofthattypeof\nanimal if they are of different genders. Otherwise, if two animals of the same\ntypeandgendertrytocollide,thenonlytheoneoflargerstrengthsurvives.\nP-2.33 WriteaJavaprogramthatsimulatesasystemthatsupportsthefunctionsofane-\nbookreader. Youshouldincludemethodsforusersofyoursystemto\u201cbuy\u201dnew\nbooks,viewtheirlistofpurchasedbooks,andreadtheirpurchasedbooks. Your\nsystemshoulduseactualbooks,whichhaveexpiredcopyrightsandareavailable\nontheInternet,topopulateyoursetofavailablebooksforusersofyoursystem\nto\u201cpurchase\u201dandread.\nP-2.34 DefineaPolygoninterfacethathasmethodsarea()andperimeter(). Thenim-\nplementclassesforTriangle,Quadrilateral, Pentagon,Hexagon,andOctagon,\nwhich implement this interface, with the obvious meanings for the area() and\nperimeter() methods. Also implement classes, IsoscelesTriangle, Equilateral-\nTriangle, Rectangle, and Square, which have the appropriate inheritance rela-\ntionships. Finally, write a simple user interface, which allows users to create\npolygonsof the various types, input their geometric dimensions, and then out-\nput their area and perimeter. For extra effort, allow users to inputpolygonsby\nspecifyingtheirvertexcoordinatesand be able to test if two such polygonsare\nsimilar.\nP-2.35 Write a Java programthat inputs a list of words, separated by whitespace, and\noutputshowmanytimeseachwordappearsinthelist. Youneednotworryabout\nefficiencyatthispoint,however,asthistopicissomethingthatwillbeaddressed\nlaterinthisbook.\nP-2.36 Write a Java program that can \u201cmake change.\u201d Your program should take two\nnumbers as input, one that is a monetary amount charged and the other that is\namonetaryamountgiven. Itshouldthenreturnthenumberofeachkindofbill\nandcointogivebackaschangeforthedifferencebetweentheamountgivenand\ntheamountcharged. Thevaluesassignedtothebillsandcoinscanbebasedon\nthe monetary system of any currentor formergovernment. Try to design your\nprogramsothatitreturnsthefewestnumberofbillsandcoinsaspossible.\nChapter Notes\nForabroadoverviewofdevelopmentsincomputerscienceandengineering,wereferthe\nreaderto The ComputerScience andEngineeringHandbook[89]. Formore information\nabouttheTherac-25incident,pleaseseethepaperbyLevesonandTurner[65].\nThereaderinterestedinstudyingobject-orientedprogrammingfurtherisreferredtothe\nbooksbyBooch[16],Budd[19],andLiskovandGuttag[67]. LiskovandGuttagalsopro-\nvideanicediscussionofabstractdatatypes,asdoesthebookchapterbyDemurjian[28]in\ntheTheComputerScienceandEngineeringHandbook[89]. Designpatternsaredescribed\ninthebookbyGammaetal.[37].\nwww.it-ebooks.info\nwww.it-ebooks.info\nChapter\n3\nFundamental Data Structures\nContents\n3.1 Using Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n3.1.1 Storing Game Entries in an Array . . . . . . . . . . . . . . 104\n3.1.2 Sorting an Array . . . . . . . . . . . . . . . . . . . . . . . 110\n3.1.3 java.util Methods for Arrays and Random Numbers . . . . 112\n3.1.4 Simple Cryptography with Character Arrays . . . . . . . . 115\n3.1.5 Two-DimensionalArrays and Positional Games . . . . . . 118\n3.2 Singly Linked Lists . . . . . . . . . . . . . . . . . . . . . . . 122\n3.2.1 Implementing a Singly Linked List Class . . . . . . . . . . 126\n3.3 Circularly Linked Lists . . . . . . . . . . . . . . . . . . . . . 128\n3.3.1 Round-Robin Scheduling . . . . . . . . . . . . . . . . . . 128\n3.3.2 Designing and Implementing a Circularly Linked List . . . 129\n3.4 Doubly Linked Lists . . . . . . . . . . . . . . . . . . . . . . 132\n3.4.1 Implementing a Doubly Linked List Class . . . . . . . . . 135\n3.5 Equivalence Testing . . . . . . . . . . . . . . . . . . . . . . 138\n3.5.1 Equivalence Testing with Arrays . . . . . . . . . . . . . . 139\n3.5.2 Equivalence Testing with Linked Lists . . . . . . . . . . . 140\n3.6 Cloning Data Structures . . . . . . . . . . . . . . . . . . . 141\n3.6.1 Cloning Arrays . . . . . . . . . . . . . . . . . . . . . . . . 142\n3.6.2 Cloning Linked Lists . . . . . . . . . . . . . . . . . . . . . 144\n3.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\nwww.it-ebooks.info\n104 Chapter3. FundamentalDataStructures\n3.1 Using Arrays\nInthissection,weexploreafewapplicationsofarrays\u2014theconcretedatastructures\nintroduced inSection1.3thataccesstheirentriesusingintegerindices.\n3.1.1 Storing Game Entries in an Array\nThefirstapplicationwestudyisstoringasequenceofhighscoreentriesforavideo\ngamein an array. Thisis representative ofmany applications in which asequence\nofobjects must bestored. Wecould justas easily have chosen to store records for\npatients in a hospital or the names of players on a football team. Nevertheless, let\nusfocusonstoring highscoreentries, whichisasimpleapplication thatisalready\nrichenoughtopresentsomeimportantdata-structuring concepts.\nTo begin, we consider what information to include in an object representing a\nhigh score entry. Obviously, one component to include is an integer representing\nthe score itself, which we identify as score. Another useful thing to include is the\nname of the person earning this score, which we identify as name. We could go\non from here, adding fields representing the date the score was earned or game\nstatistics thatledtothatscore. However,weomitsuchdetailstokeepourexample\nsimple. A Java class, GameEntry, representing a game entry, is given in Code\nFragment3.1.\n1 public class GameEntry\n{\n2 private String name; // name of the person earning this score\n3 private int score; // the score value\n4 /\u2217\u2217 Constructs a game entry with given parameters.. \u2217/\n5 public GameEntry(String n, int s)\n{\n6 name = n;\n7 score = s;\n8\n9 } /\u2217\u2217 Returns the name field. \u2217/\n10 public String getName() return name;\n11 /\u2217\u2217 Returns the score field { . \u2217/ }\n12 public int getScore() return score;\n13 /\u2217\u2217 Returns a string re { presentation of } this entry. \u2217/\n14 public String toString()\n{\n15 return \"(\" + name + \", \" + score + \")\";\n16\n}\n17\n}\nCodeFragment3.1: JavacodeforasimpleGameEntryclass. Notethatweinclude\nmethods for returning the name and score for a game entry object, as well as a\nmethodforreturning astringrepresentation ofthisentry.\nwww.it-ebooks.info\n3.1. UsingArrays 105\nA Class for High Scores\nTo maintain a sequence of high scores, we develop a class named Scoreboard. A\nscoreboardislimitedtoacertainnumberofhighscoresthatcanbesaved;oncethat\nlimitisreached, anewscoreonlyqualifiesforthescoreboard ifitisstrictly higher\nthan the lowest \u201chigh score\u201d on the board. The length of the desired scoreboard\nmay depend on the game, perhaps 10, 50, or 500. Since that limit may vary, we\nallowittobespecifiedasaparametertoourScoreboardconstructor.\nInternally, we will use an array named board to manage the GameEntry in-\nstances that represent the high scores. The array is allocated with the specified\nmaximum capacity, but all entries are initially null. As entries are added, we will\nmaintain them from highest to lowest score, starting at index 0 of the array. We\nillustrate a typical state of the data structure in Figure 3.1, and give Java code to\nconstruct suchadatastructureinCodeFragment3.2.\nFigure 3.1: An illustration of an array of length ten storing references to six\nGameEntryobjectsinthecellswithindices0to5;therestarenullreferences.\n1 /\u2217\u2217 Class for storing high scores in an array in nondecreasing order. \u2217/\n2 public class Scoreboard\n{\n3 private int numEntries = 0; // number of actual entries\n4 private GameEntry[ ] board; // array of game entries (names & scores)\n5 /\u2217\u2217 Constructs an empty scoreboard with the given capacity for storing entries. \u2217/\n6 public Scoreboard(int capacity)\n{\n7 board = new GameEntry[capacity];\n8\n}\n... // more methods will go here\n36\n}\nCodeFragment3.2: The beginning of a Scoreboard class for maintaining a set of\nscoresasGameEntryobjects. (CompletedinCodeFragments3.3and3.4.)\nwww.it-ebooks.info\n106 Chapter3. FundamentalDataStructures\nAdding an Entry\nOneofthemostcommonupdateswemightwanttomaketoaScoreboardistoadd\na new entry. Keep in mind that not every entry will necessarily qualify as a high\nscore. Iftheboardisnotyetfull,anynewentrywillberetained. Oncetheboardis\nfull, anew entry isonly retained if itis strictly better than one of theother scores,\ninparticular,thelastentryofthescoreboard,whichisthelowestofthehighscores.\nCode Fragment 3.3 provides an implementation of an update method for the\nScoreboardclassthatconsiders theadditionofanewgameentry.\n9 /\u2217\u2217 Attempt to add a new score to the collection (if it is high enough) \u2217/\n10 public void add(GameEntry e)\n{\n11 int newScore = e.getScore();\n12 // is the new entry e really a high score?\n13 if (numEntries < board.length newScore > board[numEntries 1].getScore())\n|| \u2212 {\n14 if (numEntries < board.length) // no score drops from the board\n15 numEntries++; // so overall number increases\n16 // shift any lower scores rightward to make room for the new entry\n17 int j = numEntries 1;\n\u2212\n18 while (j > 0 && board[j 1].getScore() < newScore)\n\u2212 {\n19 board[j] = board[j 1]; // shift entry from j-1 to j\n\u2212\n20 j ; // and decrement j\n\u2212\u2212\n21\n}\n22 board[j] = e; // when done, add new entry\n23\n}\n24\n}\nCodeFragment3.3: Javacodeforinserting aGameEntryobjectintoaScoreboard.\nWhenanewscoreisconsidered, thefirstgoalistodeterminewhetheritquali-\nfiesasahighscore. Thiswillbethecase(seeline13)ifthescoreboardisbelowits\ncapacity, orifthenewscoreisstrictlyhigherthanthelowestscoreontheboard.\nOnce it has been determined that a new entry should be kept, there are two\nremaining tasks: (1) properly update the number of entries, and (2) place the new\nentryintheappropriate location, shiftingentries withinferiorscoresasneeded.\nThefirstofthesetasksiseasily handled atlines14and15,asthetotalnumber\nofentries can only beincreased iftheboard isnot yetatfullcapacity. (When full,\nthe addition of a new entry will be counteracted by the removal of the entry with\nlowestscore.)\nThe placement of the new entry is implemented by lines 17\u201322. Index j is\ninitiallysettonumEntries 1,whichistheindexatwhichthelastGameEntrywill\n\u2212\nreside after completing the operation. Either j is the correct index for the newest\nentry,oroneormoreimmediatelybeforeitwillhavelesserscores. Thewhileloop\nchecks the compound condition, shifting entries rightward and decrementing j, as\nlongasthereisanotherentryatindex j 1withascorelessthanthenewscore.\n\u2212\nwww.it-ebooks.info\n3.1. UsingArrays 107\nFigure3.2: PreparingtoaddJill\u2019sGameEntryobjecttotheboardarray. Inorderto\nmake room for the new reference, we have to shift any references to game entries\nwithsmallerscoresthanthenewonetotherightbyonecell.\nFigure 3.2 shows an example of the process, just after the shifting of existing\nentries, but before adding the new entry. When the loop completes, j will be the\ncorrectindexforthenewentry. Figure3.3showstheresultofacompleteoperation,\naftertheassignment ofboard[j] = e,accomplished byline22ofthecode.\nIn Exercise C-3.19, we explore how game entry addition might be simplified\nforthecasewhenwedon\u2019tneedtopreserverelativeorders.\nFigure3.3: Adding a reference to Jill\u2019s GameEntry object to the board array. The\nreference can now be inserted at index 2, since we have shifted all references to\nGameEntryobjectswithscoreslessthanthenewonetotheright.\nwww.it-ebooks.info\n108 Chapter3. FundamentalDataStructures\nRemoving an Entry\nSupposesomehotshotplays ourvideo gameandgetshisorhernameonourhigh\nscore list, but we later learn that cheating occurred. In this case, we might want\nto have a method that lets us remove a game entry from the list of high scores.\nTherefore,letusconsiderhowwemightremoveareferencetoaGameEntryobject\nfromaScoreboard.\nWechoose toaddamethod totheScoreboard class, withsignature remove(i),\nwhere i designates the current index of the entry that should be removed and re-\nturned. Whenascoreisremoved,anylowerscoreswillbeshiftedupward,tofillin\nfortheremovedentry. Ifindexiisoutside therange ofcurrent entries, themethod\nwillthrowanIndexOutOfBoundsException.\nOur implementation for remove will involve a loop for shifting entries, much\nlikeouralgorithmforaddition,butinreverse. Toremovethereferencetotheobject\nat index i, we start at index i and move all the references at indices higher than i\nonecelltotheleft. (SeeFigure3.4.)\nFigure3.4: An illustration of the removal of Paul\u2019s score from index 3 of an array\nstoringreferences toGameEntryobjects.\nOur implementation of the remove method for the Scoreboard class is given\nin Code Fragment 3.4. The details for doing the remove operation contain a few\nsubtle points. The first is that, in order to remove and return the game entry (let\u2019s\ncall it e) at index i in our array, we must first save e in a temporary variable. We\nwillusethisvariabletoreturnewhenwearedoneremovingit.\nwww.it-ebooks.info\n3.1. UsingArrays 109\n25 /\u2217\u2217 Remove and return the high score at index i. \u2217/\n26 public GameEntry remove(int i) throws IndexOutOfBoundsException\n{\n27 if (i < 0 i >= numEntries)\n||\n28 throw new IndexOutOfBoundsException(\"Invalid index: \" + i);\n29 GameEntry temp = board[i]; // save the object to be removed\n30 for (int j = i; j < numEntries 1; j++) // count up from i (not down)\n\u2212\n31 board[j] = board[j+1]; // move one cell to the left\n32 board[numEntries 1 ] = null; // null out the old last score\n\u2212\n33 numEntries ;\n\u2212\u2212\n34 return temp; // return the removed object\n35\n}\nCodeFragment3.4: Javacodeforperforming theScoreboard.remove operation.\nThe second subtle point is that, in moving references higher than i one cell to\nthe left, we don\u2019t go all the way to the end of the array. First, we base our loop\non the number of current entries, not the capacity of the array, because there is\nno reason for \u201cshifting\u201d a series of null references that may be at the end of the\narray. Wealsocarefullydefinetheloopcondition,j < numEntries 1,sothatthe\n\u2212\nlast iteration of the loop assigns board[numEntries 2] = board[numEntries 1].\n\u2212 \u2212\nThere is no entry to shift into cell board[numEntries 1], so we return that cell to\n\u2212\nnulljustaftertheloop. Weconclude byreturning areference totheremovedentry\n(whichnolongerhasanyreference pointing toitwithintheboardarray).\nConclusions\nIn the version of the Scoreboard class that is available online, we include an im-\nplementation ofthe toString()method, which allows ustodisplay the contents of\nthecurrent scoreboard, separated bycommas. Wealsoinclude amainmethodthat\nperformsabasictestoftheclass.\nThe methods for adding and removing objects in an array of high scores are\nsimple. Nevertheless, they form the basis of techniques that are used repeatedly\nto build more sophisticated data structures. These other structures may be more\ngeneral than the array structure above, of course, and often they will have a lot\nmoreoperations thattheycanperform thanjust addandremove. Butstudying the\nconcrete array data structure, as we are doing now, is a great starting point to un-\nderstandingtheseotherstructures,sinceeverydatastructurehastobeimplemented\nusingconcretemeans.\nIn fact, later in this book, we will study a Java collections class, ArrayList,\nwhichismoregeneralthanthearraystructure wearestudying here. TheArrayList\nhas methods to operate onanunderlying array; yet italso eliminates the error that\noccurs when adding an object to a full array by automatically copying the objects\nintoalarger arraywhennecessary. Wewilldiscuss theArrayListclass infarmore\ndetailinSection7.2.\nwww.it-ebooks.info\n110 Chapter3. FundamentalDataStructures\n3.1.2 Sorting an Array\nIn the previous subsection, we considered an application for which we added an\nobjecttoanarrayatagivenpositionwhileshiftingotherelementssoastokeepthe\npreviousorderintact. Inthissection,weuseasimilartechniquetosolvethesorting\nproblem,thatis,startingwithanunorderedarrayofelementsandrearrangingthem\nintonondecreasing order.\nThe Insertion-Sort Algorithm\nWe study several sorting algorithms in this book, most of which are described in\nChapter 12. As a warm-up, in this section wedescribe a simple sorting algorithm\nknown as insertion-sort. The algorithm proceeds by considering one element at\na time, placing the element in the correct order relative to those before it. We\nstart with the first element in the array, which is trivially sorted by itself. When\nconsidering the next element in the array, if it is smaller than the first, we swap\nthem. Nextweconsider thethirdelementinthearray,swapping itleftwarduntilit\nisinitsproper order relative tothe firsttwoelements. Wecontinue inthismanner\nwiththefourthelement,thefifth,andsoon,untilthewholearrayissorted. Wecan\nexpresstheinsertion-sortalgorithminpseudocode,asshowninCodeFragment3.5.\nAlgorithmInsertionSort(A):\nInput: AnarrayAofncomparable elements\nOutput: ThearrayAwithelementsrearranged innondecreasing order\nforkfrom1ton 1do\n\u2212\nInsertA[k]atitsproperlocationwithinA[0],A[1],...,A[k].\nCodeFragment3.5: High-leveldescription oftheinsertion-sort algorithm.\nThis is a simple, high-level description of insertion-sort. If we look back to\nCode Fragment 3.3 in Section 3.1.1, we see that the task of inserting a new entry\ninto the list of high scores is almost identical to the task of inserting a newly con-\nsidered element in insertion-sort (except that gamescores were ordered from high\ntolow). WeprovideaJavaimplementation ofinsertion-sort inCodeFragment3.6,\nusing anouterloop toconsider eachelement inturn, andaninner loopthatmoves\na newly considered element to its proper location relative to the (sorted) subarray\nof elements that are to its left. We illustrate an example run of the insertion-sort\nalgorithm inFigure3.5.\nWe note that if an array is already sorted, the inner loop of insertion-sort does\nonly one comparison, determines that there is no swap needed, and returns back\nto the outer loop. Ofcourse, we might have to do a lot more work than this if the\ninput array is extremely out of order. In fact, we will have to do the most work if\ntheinputarrayisindecreasing order.\nwww.it-ebooks.info\n3.1. UsingArrays 111\n1 /\u2217\u2217 Insertion-sort of an array of characters into nondecreasing order \u2217/\n2 public static void insertionSort(char[ ] data)\n{\n3 int n = data.length;\n4 for (int k = 1; k < n; k++) // begin with second character\n{\n5 char cur = data[k]; // time to insert cur=data[k]\n6 int j = k; // find correct index j for cur\n7 while (j > 0 && data[j 1] > cur) // thus, data[j-1] must go after cur\n\u2212 {\n8 data[j] = data[j 1]; // slide data[j-1] rightward\n\u2212\n9 j ; // and consider previous j for cur\n\u2212\u2212\n10\n}\n11 data[j] = cur; // this is the proper place for cur\n12\n}\n13\n}\nCodeFragment3.6: Javacodeforperforming insertion-sort onacharacter array.\ncur nomove\nC B C D A E H G F\n0 1 2 3 4 5 6 7\nnomove\nD B C D A E H G F\n0 1 2 3 4 5 6 7\nA insert\nmove move move\nA B C D E H G F B C D E H G F B C D E H G F\n0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7\nnomove\nE A B C D E H G F\n0 1 2 3 4 5 6 7\nnomove\nH A B C D E H G F\n0 1 2 3 4 5 6 7 G\nmove nomove insert\nG A B C D E H F A B C D E H F\n0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 F\nmove move nomove insert\nF A B C D E G H A B C D E G H A B C D E G H\n0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7\nDone!\nA B C D E F G H\n0 1 2 3 4 5 6 7\nFigure 3.5: Execution of the insertion-sort algorithm on an array of eight charac-\nters. Each row corresponds to an iteration of the outer loop, and each copy of the\nsequenceinarowcorrespondstoaniterationoftheinnerloop. Thecurrentelement\nthatisbeinginserted ishighlighted inthearray, andshownasthecurvalue.\nwww.it-ebooks.info\n112 Chapter3. FundamentalDataStructures\n3.1.3 java.util Methods for Arrays and Random Numbers\nBecause arrays are so important, Java provides a class, java.util.Arrays, with a\nnumberofbuilt-instaticmethodsforperformingcommontasksonarrays. Laterin\nthis book, we will describe the algorithms that several of these methods are based\nupon. For now, we provide an overview of the most commonly used methods of\nthatclass,asfollows(morediscussion isinSection3.5.1):\nequals(A,B): ReturnstrueifandonlyifthearrayAandthearrayBare\nequal. Two arrays are considered equal if they have the\nsame number of elements and every corresponding pair\nofelements inthetwoarraysareequal. Thatis,AandB\nhavethesamevaluesinthesameorder.\nfill(A,x): Storesvalue xineverycellofarray A,provided thetype\nof array A is defined so that it is allowed to store the\nvaluex.\ncopyOf(A,n): Returnsanarrayofsizensuchthatthefirstkelementsof\nthisarrayarecopiedfromA,wherek=min n,A.length .\n{ }\nIf n > A.length, then the last n A.length elements in\n\u2212\nthis array will be padded with default values, e.g., 0 for\nanarrayofintandnullforanarrayofobjects.\ncopyOfRange(A,s,t): Returns an array of size t s such that the elements of\n\u2212\nthisarrayarecopiedinorderfromA[s]toA[t 1],where\n\u2212\ns<t,padded aswithcopyOf()ift >A.length.\ntoString(A): ReturnsaStringrepresentation ofthearrayA,beginning\nwith [, ending with ], and with elements of A displayed\nseparated by string \", \". The string representation of\nan element A[i] is obtained using String.valueOf(A[i]),\nwhichreturns thestring\"null\"foranullreference and\notherwise callsA[i].toString().\nsort(A): Sorts the array A based on a natural ordering of its el-\nements, which must be comparable. Sorting algorithms\narethefocusofChapter12.\nbinarySearch(A,x): Searches the sorted array A for value x, returning the\nindex where it is found, or else the index of where it\ncouldbeinsertedwhilemaintainingthesortedorder. The\nbinary-search algorithm isdescribed inSection5.1.3.\nAs static methods, these are invoked directly on the java.util.Arrays class, not\non a particular instance of the class. For example, if data were an array, we\ncould sort it with syntax, java.util.Arrays.sort(data), or with the shorter syntax\nArrays.sort(data)ifwefirstimporttheArraysclass(seeSection1.8).\nwww.it-ebooks.info\n3.1. UsingArrays 113\nPseudoRandom Number Generation\nAnotherfeaturebuiltintoJava,whichisoftenusefulwhentestingprogramsdealing\nwitharrays, istheabilitytogeneratepseudorandom numbers,thatis,numbersthat\nappear to be random (but are not necessarily truly random). In particular, Java\nhasabuilt-inclass,java.util.Random,whoseinstancesarepseudorandomnumber\ngenerators,thatis,objectsthatcomputeasequenceofnumbersthatarestatistically\nrandom. These sequences are not actually random, however, in that it is possible\nto predict the next number in the sequence given the past list of numbers. Indeed,\na popular pseudorandom number generator is to generate the next number, next,\nfromthecurrentnumber, cur,according totheformula(inJavasyntax):\nnext = (a \u2217 cur + b) % n;\nwhere a, b, and n are appropriately chosen integers, and % is the modulus opera-\ntor. Something along these lines is, in fact, the method used by java.util.Random\nobjects, with n=248. It turns out that such a sequence can be proven to be statis-\ntically uniform, whichisusually goodenough formostapplications requiring ran-\ndomnumbers,suchasgames. Forapplications, suchascomputersecuritysettings,\nwhereunpredictable randomsequencesareneeded,thiskindofformulashouldnot\nbeused. Instead, ideally asample from asource thatisactually random should be\nused,suchasradiostaticcomingfromouterspace.\nSince the next number in a pseudorandom generator is determined by the pre-\nvious number(s), suchagenerator alwaysneeds aplacetostart, whichiscalled its\nseed. Thesequenceofnumbersgeneratedforagivenseedwillalwaysbethesame.\nTheseedforaninstance ofthejava.util.Randomclasscanbesetinitsconstructor\norwithitssetSeed()method.\nOne common trick to get a different sequence each time a program is run is\nto use a seed that will be different for each run. For example, we could use some\ntimedinputfromauserorwecouldsettheseedtothecurrenttimeinmilliseconds\nsinceJanuary1,1970(provided bymethodSystem.currentTimeMillis).\nMethodsofthejava.util.Randomclassincludethefollowing:\nnextBoolean(): Returnsthenextpseudorandom booleanvalue.\nnextDouble(): Returns the next pseudorandom double value, between\n0.0and1.0.\nnextInt(): Returnsthenextpseudorandom intvalue.\nnextInt(n): Returns the next pseudorandom int value in the range\nfrom0uptobutnotincluding n.\nsetSeed(s): Sets theseed of thispseudorandom number generator to\nthelong s.\nwww.it-ebooks.info\n114 Chapter3. FundamentalDataStructures\nAn Illustrative Example\nWeprovideashort(butcomplete)illustrative program inCodeFragment3.7.\n1 import java.util.Arrays;\n2 import java.util.Random;\n3 /\u2217\u2217 Program showing some array uses. \u2217/\n4 public class ArrayTest\n{\n5 public static void main(String[ ] args)\n{\n6 int data[ ] = new int[10];\n7 Random rand = new Random(); // a pseudo-random number generator\n8 rand.setSeed(System.currentTimeMillis()); // use current time as a seed\n9 // fill the data array with pseudo-random numbers from 0 to 99, inclusive\n10 for (int i = 0; i < data.length; i++)\n11 data[i] = rand.nextInt(100); // the next pseudo-random number\n12 int[ ] orig = Arrays.copyOf(data, data.length); // make a copy of the data array\n13 System.out.println(\"arrays equal before sort: \"+Arrays.equals(data, orig));\n14 Arrays.sort(data); // sorting the data array (orig is unchanged)\n15 System.out.println(\"arrays equal after sort: \" + Arrays.equals(data, orig));\n16 System.out.println(\"orig = \" + Arrays.toString(orig));\n17 System.out.println(\"data = \" + Arrays.toString(data));\n18\n}\n19\n}\nCodeFragment3.7: Asimpletestofsomebuilt-in methodsinjava.util.Arrays.\nWeshowasampleoutput ofthisprogram below:\narrays equal before sort: true\narrays equal after sort: false\norig = [41, 38, 48, 12, 28, 46, 33, 19, 10, 58]\ndata = [10, 12, 19, 28, 33, 38, 41, 46, 48, 58]\nInanotherrun,wegotthefollowingoutput:\narrays equal before sort: true\narrays equal after sort: false\norig = [87, 49, 70, 2, 59, 37, 63, 37, 95, 1]\ndata = [1, 2, 37, 37, 49, 59, 63, 70, 87, 95]\nBy using a pseudorandom number generator to determine program values, we\ngetadifferentinputtoourprogrameachtimewerunit. Thisfeatureis,infact,what\nmakespseudorandom numbergeneratorsusefulfortestingcode,particularly when\ndealing witharrays. Evenso,weshould notuserandom testrunsasareplacement\nforreasoningaboutourcode,aswemightmissimportantspecialcasesintestruns.\nNote,forexample,thatthereisaslightchancethattheoriganddataarrayswillbe\nequal evenafterdataissorted, namely, iforig isalready ordered. Theodds ofthis\noccurring are less than 1in 3million, so it\u2019s unlikely tohappen during even afew\nthousand testruns;however,weneedtoreasonthatthisispossible.\nwww.it-ebooks.info\n3.1. UsingArrays 115\n3.1.4 Simple Cryptography with Character Arrays\nAn important application of character arrays and strings is cryptography, which\nis the science of secret messages. This field involves the process of encryption,\nin which a message, called the plaintext, is converted into a scrambled message,\ncalled the ciphertext. Likewise, cryptography studies corresponding ways of per-\nformingdecryption, turningaciphertext backintoitsoriginalplaintext.\nArguably theearliest encryption schemeistheCaesar cipher, whichisnamed\nafter Julius Caesar, who used this scheme to protect important military messages.\n(All of Caesar\u2019s messages were written in Latin, of course, which already makes\nthem unreadable for most of us!) The Caesar cipher is a simple way to obscure a\nmessagewritteninalanguagethatformswordswithanalphabet.\nTheCaesarcipherinvolvesreplacingeachletterinamessagewiththeletterthat\nisacertainnumberoflettersafteritinthealphabet. So,inanEnglishmessage,we\nmightreplaceeachAwithD,eachBwithE,eachCwithF,andsoon,ifshiftingby\nthreecharacters. Wecontinue thisapproach allthewayuptoW,whichisreplaced\nwith Z. Then, we let the substitution pattern wrap around, so that we replace X\nwithA,YwithB,andZwithC.\nConverting Between Strings and Character Arrays\nGiven that strings are immutable, we cannot directly edit an instance to encrypt\nit. Instead, our goal will be to generate a new string. A convenient technique for\nperformingstringtransformationsistocreateanequivalentarrayofcharacters,edit\nthearray,andthenreassemble a(new)stringbasedonthearray.\nJavahassupportforconversionsfromstringstocharacterarraysandviceversa.\nGiven a string S, we can create a new character array matching S by using the\nmethod,S.toCharArray(). Forexample,ifs=\"bird\",themethodreturnsthechar-\nacter array A= 'b', 'i', 'r', 'd' . Conversely, there is a form of the String\n{ }\nconstructor that accepts a character array as a parameter. For example, with char-\nacterarrayA= 'b','i','r','d' ,thesyntaxnew String(A)produces \"bird\".\n{ }\nUsing Character Arrays as Replacement Codes\nIfweweretonumberourletterslikearrayindices,sothatAis0,Bis1,Cis2,then\nwecan represent thereplacement ruleasacharacter array, encoder,such that Ais\nmappedtoencoder[0],Bismappedtoencoder[1],andsoon. Then,inordertofind\na replacement for a character in our Caesar cipher, we need to map the characters\nfromAtoZtotherespectivenumbersfrom0to25. Fortunately,wecanrelyonthe\nfactthatcharactersarerepresentedinUnicodebyintegercodepoints,andthecode\npointsfortheuppercaselettersoftheLatinalphabetareconsecutive(forsimplicity,\nwerestrictourencryption touppercase letters).\nwww.it-ebooks.info\n116 Chapter3. FundamentalDataStructures\nJava allows us to \u201csubtract\u201d two characters from each other, with an integer\nresult equal to their separation distance in the encoding. Given a variable c that is\nknown to be an uppercase letter, the Java computation, j = c 'A' produces the\n\u2212\ndesiredindex j. Asasanitycheck,ifcharactercis'A',then j=0. Whencis'B',\nthedifferenceis1. Ingeneral,theinteger jthatresultsfromsuchacalculation can\nbeusedasanindexintoourprecomputedencoderarray,asillustratedinFigure3.6.\nencoderarray\nD E F G H I J K L M N O P Q R S T U V W X Y Z A B C\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n'T' \u2212 'A'\nUsing'T'asanindex\n= 84 \u2212 65 Hereisthe\nInUnicode replacementfor'T'\n= 19\nFigure 3.6: Illustrating the use of uppercase characters as indices, in this case to\nperform thereplacement ruleforCaesarcipherencryption.\nThe process of decrypting the message can be implemented by simply using\na different character array to represent the replacement rule\u2014one that effectively\nshiftscharacters intheopposite direction.\nInCodeFragment3.8, wepresent aJava class thatperforms theCaesar cipher\nwith an arbitrary rotational shift. The constructor for the class builds the encoder\nand decoder translation arrays for the given rotation. We rely heavily on modular\narithmetic, asaCaesarcipherwitharotation ofrencodes theletterhaving indexk\nwith the letter having index (k+r) mod 26, where mod is the modulo operator,\nwhich returns the remainder after performing an integer division. This operator is\ndenoted with % in Java, and it is exactly the operator we need to easily perform\nthe wraparound at the end of the alphabet, for 26 mod 26 is 0, 27 mod 26 is 1,\nand28 mod 26is2. Thedecoder array fortheCaesarcipherisjusttheopposite\u2014\nwe replace each letter with the one r places before it, with wraparound; to avoid\nsubtleties involving negative numbers and the modulus operator, we will replace\ntheletterhaving codekwiththeletterhaving code(k r+26) mod 26.\n\u2212\nWith the encoder and decoder arrays in hand, the encryption and decryption\nalgorithms areessentially thesame, andsoweperform both bymeansofaprivate\nutility method named transform. This method converts a string to a character ar-\nray, performs thetranslation diagrammed inFigure3.6foranyuppercase alphabet\nsymbols, andfinallyreturnsanewstring,constructed fromtheupdated array.\nThemainmethodoftheclass,asasimpletest,produces thefollowingoutput:\nEncryption code = DEFGHIJKLMNOPQRSTUVWXYZABC\nDecryption code = XYZABCDEFGHIJKLMNOPQRSTUVW\nSecret: WKH HDJOH LV LQ SODB; PHHW DW MRH\u2019V.\nMessage: THE EAGLE IS IN PLAY; MEET AT JOE\u2019S.\nwww.it-ebooks.info\n3.1. UsingArrays 117\n1 /\u2217\u2217 Class for doing encryption and decryption using the Caesar Cipher. \u2217/\n2 public class CaesarCipher\n{\n3 protected char[ ] encoder = new char[26]; // Encryption array\n4 protected char[ ] decoder = new char[26]; // Decryption array\n5 /\u2217\u2217 Constructor that initializes the encryption and decryption arrays \u2217/\n6 public CaesarCipher(int rotation)\n{\n7 for (int k=0; k < 26; k++)\n{\n8 encoder[k] = (char) ('A' + (k + rotation) % 26);\n9 decoder[k] = (char) ('A' + (k rotation + 26) % 26);\n\u2212\n10\n}\n11\n12 } /\u2217\u2217 Returns String representing encrypted message. \u2217/\n13 public String encrypt(String message)\n{\n14 return transform(message, encoder); // use encoder array\n15\n16 } /\u2217\u2217 Returns decrypted message given encrypted secret. \u2217/\n17 public String decrypt(String secret)\n{\n18 return transform(secret, decoder); // use decoder array\n19\n20 } /\u2217\u2217 Returns transformation of original String using given code. \u2217/\n21 private String transform(String original, char[ ] code)\n{\n22 char[ ] msg = original.toCharArray();\n23 for (int k=0; k < msg.length; k++)\n24 if (Character.isUpperCase(msg[k])) // we have a letter to change\n{\n25 int j = msg[k] 'A'; // will be value from 0 to 25\n\u2212\n26 msg[k] = code[j]; // replace the character\n27\n}\n28 return new String(msg);\n29\n30 } /\u2217\u2217 Simple main method for testing the Caesar cipher \u2217/\n31 public static void main(String[ ] args)\n{\n32 CaesarCipher cipher = new CaesarCipher(3);\n33 System.out.println(\"Encryption code = \" + new String(cipher.encoder));\n34 System.out.println(\"Decryption code = \" + new String(cipher.decoder));\n35 String message = \"THE EAGLE IS IN PLAY; MEET AT JOE'S.\";\n36 String coded = cipher.encrypt(message);\n37 System.out.println(\"Secret: \" + coded);\n38 String answer = cipher.decrypt(coded);\n39 System.out.println(\"Message: \" + answer); // should be plaintext again\n40\n}\n41\n}\nCodeFragment3.8: AcompleteJavaclassforperforming theCaesarcipher.\nwww.it-ebooks.info\n118 Chapter3. FundamentalDataStructures\n3.1.5 Two-Dimensional Arrays and Positional Games\nMany computer games, be they strategy games, simulation games, or first-person\nconflictgames,involveobjectsthatresideinatwo-dimensionalspace. Softwarefor\nsuch positional games needs a way of representing objects in a two-dimensional\nspace. Anaturalwaytodothisiswithatwo-dimensionalarray,whereweusetwo\nindices, say iand j, to refer to the cells in the array. The first index usually refers\ntoarownumber andthesecond toacolumn number. Givensuchanarray, wecan\nmaintain two-dimensional game boards and perform other kinds of computations\ninvolving datastoredinrowsandcolumns.\nArrays in Java are one-dimensional; we use a single index to access each cell\nof an array. Nevertheless, there is a way we can define two-dimensional arrays in\nJava\u2014wecancreateatwo-dimensional arrayasanarrayofarrays. Thatis,wecan\ndefine a two-dimensional array to be an array with each of its cells being another\narray. Suchatwo-dimensional arrayissometimesalsocalledamatrix. InJava,we\nmaydeclareatwo-dimensional arrayasfollows:\nint[ ][ ] data = new int[8][10];\nThis statement creates a two-dimensional \u201carray of arrays,\u201d data, which is8 10,\n\u00d7\nhaving 8rowsand10columns. Thatis,dataisanarray oflength 8suchthateach\nelementofdataisanarrayoflength10ofintegers. (SeeFigure3.7.) Thefollowing\nwouldthenbevalidusesofarraydataandintvariables i,j,andk:\ndata[i][i+1] = data[i][i] + 3;\nj = data.length; // j is 8\nk = data[4].length; // k is 10\nTwo-dimensional arrays have manyapplications tonumerical analysis. Rather\nthangoingintothedetailsofsuchapplications, however,weexploreanapplication\noftwo-dimensional arraysforimplementing asimplepositional game.\n0 1 2 3 4 5 6 7 8 9\n0 22 18 709 5 33 10 4 56 82 440\n1 45 32 830 120 750 660 13 77 20 105\n2 4 880 45 66 61 28 650 7 510 67\n3 940 12 36 3 20 100 306 590 0 500\n4 50 65 42 49 88 25 70 126 83 288\n5 398 233 5 83 59 232 49 8 365 90\n6 33 58 632 87 94 5 59 204 120 829\n7 62 394 3 4 102 140 183 390 16 26\nFigure3.7: Illustration of atwo-dimensional integer array, data,which has8 rows\nand10columns. Thevalueofdata[3][5]is100andthevalueofdata[6][2]is632.\nwww.it-ebooks.info\n3.1. UsingArrays 119\nTic-Tac-Toe\nAs most school children know, Tic-Tac-Toe is a game played in a three-by-three\nboard. Two players\u2014X and O\u2014alternate in placing their respective marks in the\ncellsofthisboard, starting withplayerX.Ifeitherplayer succeeds ingettingthree\nofhisorhermarksinarow,column,ordiagonal, thenthatplayerwins.\nThis is admittedly not a sophisticated positional game, and it\u2019s not even that\nmuchfuntoplay,sinceagoodplayerOcanalwaysforceatie. Tic-Tac-Toe\u2019ssaving\ngrace isthatitisanice, simple exampleshowing howtwo-dimensional arrays can\nbe used for positional games. Software for more sophisticated positional games,\nsuchascheckers,chess,orthepopularsimulationgames,areallbasedonthesame\napproach weillustrate hereforusingatwo-dimensional arrayforTic-Tac-Toe.\nThe basic idea is to use a two-dimensional array, board, to maintain the game\nboard. Cellsinthisarraystorevalues thatindicate ifthatcellisemptyorstoresan\nXorO.Thatis,boardisathree-by-three matrix,whosemiddlerowconsistsofthe\ncells board[1][0], board[1][1], and board[1][2]. Inour case, wechoose tomake the\ncellsintheboardarraybeintegers,witha0indicatinganemptycell,a1indicating\nan X, and a 1 indicating an O. This encoding allows us to have a simple way of\n\u2212\ntesting if a given board configuration is a win for X or O, namely, if the values\nof a row, column, or diagonal add up to 3 or 3, respectively. We illustrate this\n\u2212\napproach inFigure3.8.\nFigure3.8: Anillustration ofaTic-Tac-Toeboardandthetwo-dimensional integer\narray,board,representing it.\nWe give a complete Java class for maintaining a Tic-Tac-Toe board for two\nplayers in Code Fragments 3.9 and 3.10. We show a sample output in Figure 3.9.\nNote that this code is just for maintaining the Tic-Tac-Toe board and register-\ning moves; it doesn\u2019t perform any strategy or allow someone to play Tic-Tac-Toe\nagainst the computer. The details of such a program are beyond the scope of this\nchapter,butitmightnonetheless makeagoodcourseproject(seeExerciseP-8.67).\nwww.it-ebooks.info\n120 Chapter3. FundamentalDataStructures\n1 /\u2217\u2217 Simulation of a Tic-Tac-Toe game (does not do strategy). \u2217/\n2 public class TicTacToe\n{\n3 public static final int X = 1, O = 1; // players\n\u2212\n4 public static final int EMPTY = 0; // empty cell\n5 private int board[ ][ ] = new int[3][3]; // game board\n6 private int player; // current player\n7 /\u2217\u2217 Constructor \u2217/\n8 public TicTacToe() clearBoard();\n9 /\u2217\u2217 Clears the board {\u2217/ }\n10 public void clearBoard()\n{\n11 for (int i = 0; i < 3; i++)\n12 for (int j = 0; j < 3; j++)\n13 board[i][j] = EMPTY; // every cell should be empty\n14 player = X; // the first player is 'X'\n15\n16 } /\u2217\u2217 Puts an X or O mark at position i,j. \u2217/\n17 public void putMark(int i, int j) throws IllegalArgumentException\n{\n18 if ((i < 0) (i > 2) (j < 0) (j > 2))\n|| || ||\n19 throw new IllegalArgumentException(\"Invalid board position\");\n20 if (board[i][j] != EMPTY)\n21 throw new IllegalArgumentException(\"Board position occupied\");\n22 board[i][j] = player; // place the mark for the current player\n23 player = player; // switch players (uses fact that O = - X)\n\u2212\n24\n25 } /\u2217\u2217 Checks whether the board configuration is a win for the given player. \u2217/\n26 public boolean isWin(int mark)\n27 return ((board[0][0] + board[0] { [1] + board[0][2] == mark\u22173) // row 0\n28 (board[1][0] + board[1][1] + board[1][2] == mark\u22173) // row 1\n29 || (board[2][0] + board[2][1] + board[2][2] == mark\u22173) // row 2\n30 || (board[0][0] + board[1][0] + board[2][0] == mark\u22173) // column 0\n31 || (board[0][1] + board[1][1] + board[2][1] == mark\u22173) // column 1\n32 || (board[0][2] + board[1][2] + board[2][2] == mark\u22173) // column 2\n33 || (board[0][0] + board[1][1] + board[2][2] == mark\u22173) // diagonal\n34 || (board[2][0] + board[1][1] + board[0][2] == mark\u22173)); // rev diag\n||\n35\n36 } /\u2217\u2217 Returns the winning player's code, or 0 to indicate a tie (or unfinished game).\u2217/\n37 public int winner()\n{\n38 if (isWin(X))\n39 return(X);\n40 else if (isWin(O))\n41 return(O);\n42 else\n43 return(0);\n44\n}\nCodeFragment3.9: Asimple,completeJavaclassforplayingTic-Tac-Toebetween\ntwoplayers. (ContinuesinCodeFragment3.10.)\nwww.it-ebooks.info\n3.1. UsingArrays 121\n45 /\u2217\u2217 Returns a simple character string showing the current board. \u2217/\n46 public String toString()\n{\n47 StringBuilder sb = new StringBuilder();\n48 for (int i=0; i<3; i++)\n{\n49 for (int j=0; j<3; j++)\n{\n50 switch (board[i][j])\n{\n51 case X: sb.append(\"X\"); break;\n52 case O: sb.append(\"O\"); break;\n53 case EMPTY: sb.append(\" \"); break;\n54\n}\n55 if (j < 2) sb.append(\"|\"); // column boundary\n56\n}\n57 if (i < 2) sb.append(\"\\n-----\\n\"); // row boundary\n58\n}\n59 return sb.toString();\n60\n61 } /\u2217\u2217 Test run of a simple game \u2217/\n62 public static void main(String[ ] args)\n{\n63 TicTacToe game = new TicTacToe();\n64 /\u2217 X moves: \u2217/ /\u2217 O moves: \u2217/\n65 game.putMark(1,1); game.putMark(0,2);\n66 game.putMark(2,2); game.putMark(0,0);\n67 game.putMark(0,1); game.putMark(2,1);\n68 game.putMark(1,2); game.putMark(1,0);\n69 game.putMark(2,0);\n70 System.out.println(game);\n71 int winningPlayer = game.winner();\n72 String[ ] outcome = \"O wins\", \"Tie\", \"X wins\" ; // rely on ordering\n{ }\n73 System.out.println(outcome[1 + winningPlayer]);\n74\n}\n75\n}\nCode Fragment 3.10: A simple, complete Java class for playing Tic-Tac-Toe be-\ntweentwoplayers. (Continued fromCodeFragment3.9.)\nO|X|O\n-----\nO|X|X\n-----\nX|O|X\nTie\nFigure3.9: SampleoutputofaTic-Tac-Toegame.\nwww.it-ebooks.info\n122 Chapter3. FundamentalDataStructures\n3.2 Singly Linked Lists\nIn the previous section, we presented the array data structure and discussed some\nof its applications. Arrays are great for storing things in a certain order, but they\nhave drawbacks. The capacity of the array must be fixed when it is created, and\ninsertions and deletions at interior positions of an array can be time consuming if\nmanyelementsmustbeshifted.\nInthissection, weintroduce adatastructureknownasalinkedlist,whichpro-\nvides an alternative to anarray-based structure. A linked list, in itssimplest form,\nisacollection ofnodesthatcollectively formalinear sequence. Inasinglylinked\nlist,eachnodestoresareferencetoanobjectthatisanelementofthesequence, as\nwellasareference tothenextnodeofthelist(seeFigure3.10).\nMSP\nelement next\nFigure 3.10: Example of a node instance that forms part of a singly linked list.\nThenode\u2019selementfieldreferstoanobjectthatisanelementofthesequence (the\nairport code MSP, in this example), while the next field refers to the subsequent\nnodeofthelinkedlist(ornullifthereisnofurthernode).\nA linked list\u2019s representation relies on the collaboration of many objects (see\nFigure 3.11). Minimally, the linked list instance must keep a reference to the first\nnode of the list, known as the head. Without an explicit reference to the head,\nthere would be no way to locate that node (or indirectly, any others). The last\nnodeofthelistisknownasthetail. Thetailofalistcanbefoundbytraversingthe\nlinkedlist\u2014startingattheheadandmovingfromonenodetoanotherbyfollowing\neach node\u2019s next reference. Wecan identify the tail as the node having null as its\nnext reference. This process is also known as link hopping or pointer hopping.\nHowever, storing an explicit reference to the tail node is a common efficiency to\navoid such a traversal. In similar regard, it is common for a linked list instance to\nkeepacountofthetotalnumberofnodesthatcomprise thelist(alsoknownasthe\nsizeofthelist),toavoidtraversing thelisttocountthenodes.\nLAX MSP ATL BOS\nhead tail\nFigure3.11: Example of a singly linked list whose elements are strings indicating\nairport codes. The list instance maintains a member named head that refers to the\nfirstnode of thelist, and another member namedtailthat refers to thelast node of\nthelist. Thenullvalueisdenotedas\u00d8.\nwww.it-ebooks.info\n3.2. SinglyLinkedLists 123\nInserting an Element at the Head of a Singly Linked List\nAnimportantpropertyofalinkedlististhatitdoesnothaveapredetermined fixed\nsize; it uses space proportional to its current number of elements. When using a\nsingly linked list, we can easily insert an element at the head of the list, as shown\nin Figure 3.12, and described with pseudocode in Code Fragment 3.11. The main\nidea is that we create a new node, set its element to the new element, set its next\nlinktorefertothecurrenthead,andsetthelist\u2019sheadtopointtothenewnode.\nhead\nMSP ATL BOS\n(a)\nnewest head\nLAX MSP ATL BOS\n(b)\nnewest head\nLAX MSP ATL BOS\n(c)\nFigure3.12:Insertionofanelementattheheadofasinglylinkedlist: (a)beforethe\ninsertion; (b) after a new node is created and linked to the existing head; (c) after\nreassignment oftheheadreference tothenewestnode.\nAlgorithmaddFirst(e):\nnewest = Node(e) createnewnodeinstance storingreference toelemente\n{ }\nnewest.next = head setnewnode\u2019s nexttoreference theoldheadnode\n{ }\nhead = newest setvariableheadtoreference thenewnode\n{ }\nsize = size+1 incrementthenodecount\n{ }\nCodeFragment3.11:Insertinganewelementatthebeginningofasinglylinkedlist.\nNotethatwesetthenextpointerofthenewnodebeforewereassignvariablehead\ntoit. Ifthe listwere initially empty (i.e., headis null),then anatural consequence\nisthatthenewnodehasitsnextreference settonull.\nwww.it-ebooks.info\n124 Chapter3. FundamentalDataStructures\nInserting an Element at the Tail of a Singly Linked List\nWe can also easily insert an element at the tail of the list, provided we keep a\nreference to the tail node, as shown in Figure 3.13. In this case, we create a new\nnode, assign its next reference to null, set the next reference of the tail to point to\nthis new node, and then update the tail reference itself to this new node. We give\npseudocode fortheprocess inCodeFragment3.12.\ntail\nMSP ATL BOS\n(a)\ntail newest\nMSP ATL BOS MIA\n(b)\ntail newest\nMSP ATL BOS MIA\n(c)\nFigure 3.13: Insertion at the tail of a singly linked list: (a) before the insertion;\n(b) after creation of a new node; (c) after reassignment of the tail reference. Note\nthatwemustsetthenextlinkofthetailnodein(b)beforeweassignthetailvariable\ntopointtothenewnodein(c).\nAlgorithmaddLast(e):\nnewest = Node(e) createnewnodeinstance storingreference toelemente\n{ }\nnewest.next = null setnewnode\u2019snexttoreferencethenullobject\n{ }\ntail.next = newest makeoldtailnodepointtonewnode\n{ }\ntail = newest setvariabletailtoreference thenewnode\n{ }\nsize = size+1 incrementthenodecount\n{ }\nCodeFragment3.12: Inserting a new node at the end of a singly linked list. Note\nthatwesetthenextpointer fortheoldtailnodebeforewemakevariabletailpoint\ntothe new node. Thiscode would need tobe adjusted for inserting onto an empty\nlist,sincetherewouldnotbeanexistingtailnode.\nwww.it-ebooks.info\n3.2. SinglyLinkedLists 125\nRemoving an Element from a Singly Linked List\nRemovinganelementfromtheheadofasinglylinkedlistisessentiallythereverse\noperation of inserting a new element at the head. This operation is illustrated in\nFigure3.14anddescribed indetailinCodeFragment3.13.\nhead\nLAX MSP ATL BOS\n(a)\nhead\nLAX MSP ATL BOS\n(b)\nhead\nMSP ATL BOS\n(c)\nFigure3.14: Removal of an element at the head of a singly linked list: (a) before\ntheremoval;(b)after\u201clinking out\u201dtheoldhead;(c)finalconfiguration.\nAlgorithmremoveFirst():\nifhead==nullthen\nthelistisempty.\nhead = head.next makeheadpointtonextnode(ornull)\n{ }\nsize = size 1 decrementthenodecount\n\u2212 { }\nCodeFragment3.13: Removingthenodeatthebeginning ofasinglylinkedlist.\nUnfortunately,wecannoteasilydeletethelastnodeofasinglylinkedlist. Even\nifwemaintain atailreference directly tothe last node ofthe list, wemustbe able\nto access the node before the last node in order to remove the last node. But we\ncannotreachthenodebeforethetailbyfollowingnextlinksfromthetail. Theonly\nway to access this node is to start from the head of the list and search all the way\nthrough thelist. Butsuch asequence oflink-hopping operations could take along\ntime. Ifwewanttosupportsuchanoperation efficiently,wewillneedtomakeour\nlistdoublylinked(aswedoinSection3.4).\nwww.it-ebooks.info\n126 Chapter3. FundamentalDataStructures\n3.2.1 Implementing a Singly Linked List Class\nInthis section, wepresent acomplete implementation ofaSinglyLinkedList class,\nsupporting thefollowingmethods:\nsize(): Returnsthenumberofelementsinthelist.\nisEmpty(): Returnstrueifthelistisempty,andfalseotherwise.\nfirst(): Returns(butdoesnotremove)thefirstelementinthelist.\nlast(): Returns(butdoesnotremove)thelastelementinthelist.\naddFirst(e): Addsanewelementtothefrontofthelist.\naddLast(e): Addsanewelementtotheendofthelist.\nremoveFirst(): Removesandreturnsthefirstelementofthelist.\nIffirst(),last(),orremoveFirst()arecalled onalistthatisempty,wewillsimply\nreturnanullreference andleavethelistunchanged.\nBecauseitdoesnotmattertouswhattypeofelementsarestoredinthelist,we\nuseJava\u2019sgenericsframework(seeSection2.5.2)todefineourclasswithaformal\ntypeparameterEthatrepresents theuser\u2019sdesired elementtype.\nOur implementation also takes advantage of Java\u2019s support for nested classes\n(see Section 2.6), as we define a private Node class within the scope of the pub-\nlicSinglyLinkedListclass. CodeFragment3.14presents theNodeclassdefinition,\nand Code Fragment 3.15 the rest of the SinglyLinkedList class. Having Node as a\nnestedclassprovidesstrongencapsulation,shieldingusersofourclassfromtheun-\nderlyingdetailsaboutnodesandlinks. ThisdesignalsoallowsJavatodifferentiate\nthisnodetypefromformsofnodeswemaydefineforuseinotherstructures.\n1 public class SinglyLinkedList<E>\n{\n2 //----------------nested Node class ----------------\n3 private static class Node<E>\n{\n4 private E element; // reference to the element stored at this node\n5 private Node<E> next; // reference to the subsequent node in the list\n6 public Node(E e, Node<E> n)\n{\n7 element = e;\n8 next = n;\n9\n}\n10 public E getElement() return element;\n{ }\n11 public Node<E> getNext() return next;\n{ }\n12 public void setNext(Node<E> n) next = n;\n{ }\n13 //-----------end of nested Node class -----------\n}\n... rest of SinglyLinkedList class will follow ...\nCodeFragment3.14: A nested Node class within the SinglyLinkedList class. (The\nremainderoftheSinglyLinkedListclasswillbegiveninCodeFragment3.15.)\nwww.it-ebooks.info\n3.2. SinglyLinkedLists 127\n1 public class SinglyLinkedList<E>\n{\n... (nested Node class goes here)\n14 // instance variables of the SinglyLinkedList\n15 private Node<E> head = null; // head node of the list (or null if empty)\n16 private Node<E> tail = null; // last node of the list (or null if empty)\n17 private int size = 0; // number of nodes in the list\n18 public SinglyLinkedList() // constructs an initially empty list\n{ }\n19 // access methods\n20 public int size() return size;\n{ }\n21 public boolean isEmpty() return size == 0;\n{ }\n22 public E first() // returns (but does not remove) the first element\n{\n23 if (isEmpty()) return null;\n24 return head.getElement();\n25\n}\n26 public E last() // returns (but does not remove) the last element\n{\n27 if (isEmpty()) return null;\n28 return tail.getElement();\n29\n}\n30 // update methods\n31 public void addFirst(E e) // adds element e to the front of the list\n{\n32 head = new Node<>(e, head); // create and link a new node\n33 if (size == 0)\n34 tail = head; // special case: new node becomes tail also\n35 size++;\n36\n}\n37 public void addLast(E e) // adds element e to the end of the list\n{\n38 Node<E> newest = new Node<>(e, null); // node will eventually be the tail\n39 if (isEmpty())\n40 head = newest; // special case: previously empty list\n41 else\n42 tail.setNext(newest); // new node after existing tail\n43 tail = newest; // new node becomes the tail\n44 size++;\n45\n}\n46 public E removeFirst() // removes and returns the first element\n{\n47 if (isEmpty()) return null; // nothing to remove\n48 E answer = head.getElement();\n49 head = head.getNext(); // will become null if list had only one node\n50 size ;\n\u2212\u2212\n51 if (size == 0)\n52 tail = null; // special case as list is now empty\n53 return answer;\n54\n}\n55\n}\nCode Fragment3.15: The SinglyLinkedList class definition (when combined with\nthenestedNodeclassofCodeFragment3.14).\nwww.it-ebooks.info\n128 Chapter3. FundamentalDataStructures\n3.3 Circularly Linked Lists\nLinked lists are traditionally viewed as storing a sequence of items in a linear or-\nder, from first to last. However, there are many applications in which data can\nbe more naturally viewed as having a cyclic order, with well-defined neighboring\nrelationships, butnofixedbeginning orend.\nFor example, many multiplayer games are turn-based, with player A taking a\nturn,thenplayerB,thenplayerC,andsoon,buteventuallybacktoplayerAagain,\nandplayerBagain,withthepatternrepeating. Asanother example,citybusesand\nsubways often run on a continuous loop, making stops in a scheduled order, but\nwith no designated first or last stop per se. We next consider another important\nexampleofacyclicorderinthecontextofcomputeroperating systems.\n3.3.1 Round-Robin Scheduling\nOne of the most important roles of an operating system is in managing the many\nprocessesthatarecurrentlyactiveonacomputer,includingtheschedulingofthose\nprocesses on one or more central processing units (CPUs). In order to support\ntheresponsiveness ofanarbitrary numberofconcurrent processes, mostoperating\nsystems allow processes to effectively share use of the CPUs, using some form of\nan algorithm known as round-robin scheduling. A process is given a short turn\nto execute, known as a time slice, but it is interrupted when the slice ends, even if\nits job is not yet complete. Each active process is given its own time slice, taking\nturns in a cyclic order. New processes can be added to the system, and processes\nthatcompletetheirworkcanberemoved.\nAround-robinschedulercouldbeimplementedwithatraditionallinkedlist,by\nrepeatedly performing thefollowingstepsonlinkedlistL(seeFigure3.15):\n1. process p=L.removeFirst()\n2. Giveatimeslicetoprocess p\n3. L.addLast(p)\nUnfortunately, there are drawbacks to the use of a traditional linked list for this\npurpose. It is unnecessarily inefficient to repeatedly throw away a node from one\nendofthelist, onlytocreateanewnodeforthesameelementwhenreinserting it,\nnottomention thevarious updates that areperformed todecrement andincrement\nthelist\u2019ssizeandtounlinkandrelinknodes.\nIn the remainder of this section, we demonstrate how a slight modification to\nour singly linked list implementation can be used to provide a more efficient data\nstructure forrepresenting acyclicorder.\nwww.it-ebooks.info\n3.3. CircularlyLinkedLists 129\n2. Give current process\na time slice on CPU\nCPU\n1. Remove the next 3. Add process to end\nwaiting process waiting processes of waiting pool\nFigure3.15: Thethreeiterativestepsforround-robin scheduling.\n3.3.2 Designing and Implementing a Circularly Linked List\nIn this section, we design a structure known as a circularly linked list, which is\nessentially asingularly linkedlistinwhichthenextreferenceofthetailnodeisset\ntoreferbacktotheheadofthelist(ratherthannull),asshowninFigure3.16.\nhead tail\nLAX MSP ATL BOS\nFigure3.16: Exampleofasinglylinkedlistwithcircularstructure.\nWe use this model to design and implement a new CircularlyLinkedList class,\nwhich supports all of the public behaviors of our SinglyLinkedList class and one\nadditional updatemethod:\nrotate(): Movesthefirstelementtotheendofthelist.\nWiththisnewoperation,round-robinschedulingcanbeefficientlyimplementedby\nrepeatedly performing thefollowingstepsonacircularly linkedlistC:\n1. GiveatimeslicetoprocessC.first()\n2. C.rotate()\nAdditional Optimization\nInimplementing anewclass,wemakeoneadditional optimization\u2014we nolonger\nexplicitly maintain the head reference. So long as we maintain a reference to the\ntail, we can locate the head as tail.getNext(). Maintaining only the tail reference\nnotonlysavesabitonmemoryusage,itmakesthecodesimplerandmoreefficient,\nas it removes the need to perform additional operations to keep a head reference\ncurrent. Infact,ournewimplementationisarguably superiortoouroriginalsingly\nlinkedlistimplementation, evenifwearenotinterested inthenewrotatemethod.\nwww.it-ebooks.info\n130 Chapter3. FundamentalDataStructures\nOperations on a Circularly Linked List\nImplementing the new rotate method is quite trivial. We do not move any nodes\norelements, wesimply advance thetailreference topoint tothenode that follows\nit(the implicit head ofthe list). Figure 3.17 illustrates this operation using amore\nsymmetricvisualization ofacircularly linkedlist.\n(head) tail\n(head)\ntail\nLAX LAX\nBOS MSP BOS MSP\nATL ATL\n(a) (b)\nFigure3.17: The rotation operation on a circularly linked list: (a) before the rota-\ntion, representing sequence LAX,MSP,ATL,BOS ; (b) after the rotation, rep-\n{ }\nresenting sequence MSP,ATL,BOS,LAX . Wedisplaytheimplicitheadrefer-\n{ }\nence,whichisidentifiedonlyastail.getNext()withintheimplementation.\nWe can add a new element at the front of the list by creating a new node and\nlinking it just after the tail of the list, as shown in Figure 3.18. To implement the\naddLastmethod,wecanrelyontheuseofacalltoaddFirstandthenimmediately\nadvancethetailreference sothatthenewestnodebecomesthelast.\nRemoving the first node from a circularly linked list can be accomplished by\nsimply updating the next field of the tail node to bypass the implicit head. A Java\nimplementation of all methods of the CircularlyLinkedList class is given in Code\nFragment3.16.\ntail newest\nLAX STL\nBOS\nMSP\nATL\nFigure3.18: Effect of a call to addFirst(STL) on the circularly linked list of Fig-\nure 3.17(b). The variable newest has local scope during the execution of the\nmethod. Notice that when the operation is complete, STL is the first element of\nthelist,asitisstoredwithintheimplicithead,tail.getNext().\nwww.it-ebooks.info\n3.3. CircularlyLinkedLists 131\n1 public class CircularlyLinkedList<E>\n{\n... (nested node class identical to that of the SinglyLinkedListclass)\n14 // instance variables of the CircularlyLinkedList\n15 private Node<E> tail = null; // we store tail (but not head)\n16 private int size = 0; // number of nodes in the list\n17 public CircularlyLinkedList() // constructs an initially empty list\n{ }\n18 // access methods\n19 public int size() return size;\n{ }\n20 public boolean isEmpty() return size == 0;\n{ }\n21 public E first() // returns (but does not remove) the first element\n{\n22 if (isEmpty()) return null;\n23 return tail.getNext().getElement(); // the head is *after* the tail\n24\n}\n25 public E last() // returns (but does not remove) the last element\n{\n26 if (isEmpty()) return null;\n27 return tail.getElement();\n28\n}\n29 // update methods\n30 public void rotate() // rotate the first element to the back of the list\n{\n31 if (tail != null) // if empty, do nothing\n32 tail = tail.getNext(); // the old head becomes the new tail\n33\n}\n34 public void addFirst(E e) // adds element e to the front of the list\n{\n35 if (size == 0)\n{\n36 tail = new Node<>(e, null);\n37 tail.setNext(tail); // link to itself circularly\n38 else\n} {\n39 Node<E> newest = new Node<>(e, tail.getNext());\n40 tail.setNext(newest);\n41\n}\n42 size++;\n43\n}\n44 public void addLast(E e) // adds element e to the end of the list\n{\n45 addFirst(e); // insert new element at front of list\n46 tail = tail.getNext(); // now new element becomes the tail\n47\n}\n48 public E removeFirst() // removes and returns the first element\n{\n49 if (isEmpty()) return null; // nothing to remove\n50 Node<E> head = tail.getNext();\n51 if (head == tail) tail = null; // must be the only node left\n52 else tail.setNext(head.getNext()); // removes \u201dhead\u201d from the list\n53 size ;\n\u2212\u2212\n54 return head.getElement();\n55\n}\n56\n}\nCodeFragment3.16: Implementation oftheCircularlyLinkedListclass.\nwww.it-ebooks.info\n132 Chapter3. FundamentalDataStructures\n3.4 Doubly Linked Lists\nInasingly linked list, eachnode maintains areference tothenode thatisimmedi-\nately after it. We have demonstrated the usefulness of such a representation when\nmanaging a sequence of elements. However, there are limitations that stem from\ntheasymmetryofasingly linked list. InSection3.2,wedemonstrated thatwecan\nefficientlyinsertanodeateitherendofasinglylinkedlist,andcandeleteanodeat\ntheheadofalist,butweareunabletoefficientlydeleteanodeatthetailofthelist.\nMoregenerally, wecannot efficiently delete anarbitrary nodefrom aninterior po-\nsitionofthelistifonlygivenareferencetothatnode,becausewecannotdetermine\nthenode that immediately precedes thenode tobedeleted (yet, that node needs to\nhaveitsnextreference updated).\nToprovide greater symmetry, wedefinealinked listinwhicheach nodekeeps\nanexplicitreference tothenodebeforeitandareference tothenodeafterit. Such\na structure is known as a doubly linked list. These lists allow a greater variety of\nO(1)-time update operations, including insertions and deletions at arbitrary posi-\ntions within the list. We continue to use the term \u201cnext\u201d for the reference to the\nnodethatfollowsanother,andweintroducetheterm\u201cprev\u201dforthereferencetothe\nnodethatprecedesit.\nHeader and Trailer Sentinels\nInordertoavoidsomespecialcaseswhenoperatingneartheboundariesofadoubly\nlinkedlist,ithelpstoaddspecialnodesatbothendsofthelist: aheadernodeatthe\nbeginningofthelist,andatrailernodeattheendofthelist. These\u201cdummy\u201dnodes\nare known as sentinels (or guards), and they do not store elements of the primary\nsequence. Adoubly linkedlistwithsuchsentinels isshowninFigure3.19.\nheader trailer\nnext next next next\nJFK PVD SFO\nprev prev prev prev\nFigure 3.19: A doubly linked list representing the sequence JFK, PVD, SFO ,\n{ }\nusingsentinels headerandtrailertodemarcatetheendsofthelist.\nWhen using sentinel nodes, an empty list is initialized so that the next field\nof the header points to the trailer, and the prev field of the trailer points to the\nheader; the remaining fields of the sentinels are irrelevant (presumably null, in\nJava). Foranonemptylist,theheader\u2019snextwillrefertoanodecontainingthefirst\nrealelementofasequence, justasthetrailer\u2019s prev references thenodecontaining\nthelastelementofasequence.\nwww.it-ebooks.info\n3.4. DoublyLinkedLists 133\nAdvantage of Using Sentinels\nAlthough we could implement a doubly linked list without sentinel nodes (as we\ndidwithoursinglylinkedlistinSection3.2),theslightextramemorydevotedtothe\nsentinelsgreatlysimplifiesthelogicofouroperations. Mostnotably,theheaderand\ntrailer nodes never change\u2014only the nodes between them change. Furthermore,\nwecan treat allinsertions in aunified manner, because anew node will always be\nplacedbetweenapairofexistingnodes. Insimilarfashion, everyelementthatisto\nbedeletedisguaranteed tobestoredinanodethathasneighbors oneachside.\nForcontrast,welookatourSinglyLinkedListimplementationfromSection3.2.\nItsaddLastmethodrequired aconditional (lines 39\u201342ofCodeFragment3.15)to\nmanagethespecialcaseofinsertingintoanemptylist. Inthegeneralcase,thenew\nnode was linked after the existing tail. But when adding to an empty list, there is\nnoexisting tail; instead itisnecessary to reassign headto reference the new node.\nTheuseofasentinelnodeinthatimplementationwouldeliminatethespecialcase,\nastherewouldalwaysbeanexistingnode(possiblytheheader)beforeanewnode.\nInserting and Deleting with a Doubly Linked List\nEvery insertion into our doubly linked list representation will take place between\napair ofexisting nodes, as diagrammed in Figure 3.20. Forexample, when anew\nelement is inserted at the front of the sequence, we will simply add the new node\nbetweentheheaderandthenodethatiscurrentlyaftertheheader. (SeeFigure3.21.)\nheader trailer\nBWI JFK SFO\n(a)\nheader trailer\nBWI JFK PVD SFO\n(b)\nheader trailer\nBWI JFK PVD SFO\n(c)\nFigure3.20: Addinganelement toadoubly linked listwithheader andtrailer sen-\ntinels: (a)beforetheoperation;(b)aftercreatingthenewnode;(c)afterlinkingthe\nneighbors tothenewnode.\nwww.it-ebooks.info\n134 Chapter3. FundamentalDataStructures\nheader trailer\nBWI JFK SFO\n(a)\nheader trailer\nPVD BWI JFK SFO\n(b)\nheader trailer\nPVD BWI JFK SFO\n(c)\nFigure 3.21: Adding an element to the front of a sequence represented by a dou-\nbly linked list with header and trailer sentinels: (a) before the operation; (b) after\ncreating thenewnode;(c)afterlinkingtheneighbors tothenewnode.\nThedeletionofanode,portrayedinFigure3.22,proceedsintheoppositefash-\nionofaninsertion. Thetwoneighbors ofthenodetobedeletedarelinkeddirectly\nto each other, thereby bypassing the original node. As a result, that node will no\nlongerbeconsideredpartofthelistanditcanbereclaimedbythesystem. Because\nofouruseofsentinels,thesameimplementationcanbeusedwhendeletingthefirst\northelastelement ofasequence, because evensuchanelement willbestored ata\nnodethatliesbetweentwoothers.\nheader trailer\nBWI JFK PVD SFO\n(a)\nheader trailer\nBWI JFK PVD SFO\n(b)\nheader trailer\nBWI JFK SFO\n(c)\nFigure 3.22: Removing the element PVD from a doubly linked list: (a) before\nthe removal; (b) after linking out the old node; (c) after the removal (and garbage\ncollection).\nwww.it-ebooks.info\n3.4. DoublyLinkedLists 135\n3.4.1 Implementing a Doubly Linked List Class\nInthissection,wepresentacompleteimplementationofaDoublyLinkedListclass,\nsupporting thefollowingpublicmethods:\nsize(): Returnsthenumberofelementsinthelist.\nisEmpty(): Returnstrueifthelistisempty,andfalseotherwise.\nfirst(): Returns(butdoesnotremove)thefirstelementinthelist.\nlast(): Returns(butdoesnotremove)thelastelementinthelist.\naddFirst(e): Addsanewelementtothefrontofthelist.\naddLast(e): Addsanewelementtotheendofthelist.\nremoveFirst(): Removesandreturnsthefirstelementofthelist.\nremoveLast(): Removesandreturnsthelastelementofthelist.\nIffirst(),last(),removeFirst(),orremoveLast()arecalled onalistthatisempty,\nwewillreturnanullreference andleavethelistunchanged.\nAlthough we have seen that it is possible to add or remove an element at an\ninternal position of a doubly linked list, doing so requires knowledge of one or\nmore nodes, to identify the position at which the operation should occur. In this\nchapter, weprefer tomaintain encapsulation, withaprivate, nested Nodeclass. In\nChapter 7, we will revisit the use of doubly linked lists, offering a more advanced\ninterfacethatsupportsinternalinsertionsanddeletionswhilemaintainingencapsu-\nlation.\nCode Fragments 3.17 and 3.18 present the DoublyLinkedList class implemen-\ntation. As wedid with our SinglyLinkedList class, we use the generics framework\nto accept any type of element. The nested Node class for the doubly linked list is\nsimilar to that of the singly linked list, except with support for an additional prev\nreference tothepreceding node.\nOur use of sentinel nodes, header and trailer, impacts the implementation in\nseveral ways. We create and link the sentinels when constructing an empty list\n(lines 25\u201329). We also keep in mind that the first element of a nonempty list is\nstored inthenode just after the header (not inthe header itself), and similarly that\nthelastelementisstoredinthenodejustbeforethetrailer.\nThe sentinels greatly ease our implementation of the various update methods.\nWe will provide a private method, addBetween, to handle the general case of an\ninsertion,andthenwewillrelyonthatutilityasastraightforwardmethodtoimple-\nmentbothaddFirstandaddLast. Insimilarfashion,wewilldefineaprivateremove\nmethodthatcanbeusedtoeasilyimplementbothremoveFirstandremoveLast.\nwww.it-ebooks.info\n136 Chapter3. FundamentalDataStructures\n1 /\u2217\u2217 A basic doubly linked list implementation. \u2217/\n2 public class DoublyLinkedList<E>\n{\n3 //----------------nested Node class ----------------\n4 private static class Node<E>\n{\n5 private E element; // reference to the element stored at this node\n6 private Node<E> prev; // reference to the previous node in the list\n7 private Node<E> next; // reference to the subsequent node in the list\n8 public Node(E e, Node<E> p, Node<E> n)\n{\n9 element = e;\n10 prev = p;\n11 next = n;\n12\n}\n13 public E getElement() return element;\n{ }\n14 public Node<E> getPrev() return prev;\n{ }\n15 public Node<E> getNext() return next;\n{ }\n16 public void setPrev(Node<E> p) prev = p;\n{ }\n17 public void setNext(Node<E> n) next = n;\n{ }\n18 //-----------end of nested Node class -----------\n}\n19\n20 // instance variables of the DoublyLinkedList\n21 private Node<E> header; // header sentinel\n22 private Node<E> trailer; // trailer sentinel\n23 private int size = 0; // number of elements in the list\n24 /\u2217\u2217 Constructs a new empty list. \u2217/\n25 public DoublyLinkedList()\n{\n26 header = new Node<>(null, null, null); // create header\n27 trailer = new Node<>(null, header, null); // trailer is preceded by header\n28 header.setNext(trailer); // header is followed by trailer\n29\n30 } /\u2217\u2217 Returns the number of elements in the linked list. \u2217/\n31 public int size() return size;\n32 /\u2217\u2217 Tests whethe { r the linked list } is empty. \u2217/\n33 public boolean isEmpty() return size == 0;\n34 /\u2217\u2217 Returns (but does not r { emove) the first elem } ent of the list. \u2217/\n35 public E first()\n{\n36 if (isEmpty()) return null;\n37 return header.getNext().getElement(); // first element is beyond header\n38\n39 } /\u2217\u2217 Returns (but does not remove) the last element of the list. \u2217/\n40 public E last()\n{\n41 if (isEmpty()) return null;\n42 return trailer.getPrev().getElement(); // last element is before trailer\n43\n}\nCodeFragment3.17: Implementation oftheDoublyLinkedListclass. (Continuesin\nCodeFragment3.18.)\nwww.it-ebooks.info\n3.4. DoublyLinkedLists 137\n44 // public update methods\n45 /\u2217\u2217 Adds element e to the front of the list. \u2217/\n46 public void addFirst(E e)\n{\n47 addBetween(e, header, header.getNext()); // place just after the header\n48\n49 } /\u2217\u2217 Adds element e to the end of the list. \u2217/\n50 public void addLast(E e)\n{\n51 addBetween(e, trailer.getPrev(), trailer); // place just before the trailer\n52\n53 } /\u2217\u2217 Removes and returns the first element of the list. \u2217/\n54 public E removeFirst()\n{\n55 if (isEmpty()) return null; // nothing to remove\n56 return remove(header.getNext()); // first element is beyond header\n57\n58 } /\u2217\u2217 Removes and returns the last element of the list. \u2217/\n59 public E removeLast()\n{\n60 if (isEmpty()) return null; // nothing to remove\n61 return remove(trailer.getPrev()); // last element is before trailer\n62\n}\n63\n64 // private update methods\n65 /\u2217\u2217 Adds element e to the linked list in between the given nodes. \u2217/\n66 private void addBetween(E e, Node<E> predecessor, Node<E> successor)\n{\n67 // create and link a new node\n68 Node<E> newest = new Node<>(e, predecessor, successor);\n69 predecessor.setNext(newest);\n70 successor.setPrev(newest);\n71 size++;\n72\n73 } /\u2217\u2217 Removes the given node from the list and returns its element. \u2217/\n74 private E remove(Node<E> node)\n{\n75 Node<E> predecessor = node.getPrev();\n76 Node<E> successor = node.getNext();\n77 predecessor.setNext(successor);\n78 successor.setPrev(predecessor);\n79 size ;\n\u2212\u2212\n80 return node.getElement();\n81\n}\n82 //-----------end of DoublyLinkedList class -----------\n}\nCodeFragment3.18: Implementation ofthepublic and private update methods for\ntheDoublyLinkedListclass. (Continued fromCodeFragment3.17.)\nwww.it-ebooks.info\n138 Chapter3. FundamentalDataStructures\n3.5 Equivalence Testing\nWhen working with reference types, there are many different notions of what it\nmeansforoneexpression tobeequaltoanother. Atthelowestlevel,ifaandbare\nreferencevariables,thenexpressiona == btestswhetheraandbrefertothesame\nobject(orifbotharesettothenullvalue).\nHowever, for many types there is a higher-level notion of two variables being\nconsidered \u201cequivalent\u201d even if they do not actually refer to the same instance of\nthe class. For example, we typically want to consider two String instances to be\nequivalent toeachotheriftheyrepresent theidentical sequence ofcharacters.\nTo support a broader notion of equivalence, all object types support a method\nnamed equals. Users of reference types should rely on the syntax a.equals(b),\nunless they have a specific need to test the more narrow notion of identity. The\nequalsmethodisformallydefinedintheObjectclass,whichservesasasuperclass\nfor all reference types, but that implementation reverts to returning the value of\nexpression a == b. Defining a more meaningful notion of equivalence requires\nknowledgeaboutaclassanditsrepresentation.\nThe author of each class has a responsibility to provide an implementation of\ntheequalsmethod,whichoverridestheoneinheritedfromObject,ifthereisamore\nrelevantdefinitionfortheequivalence oftwoinstances. Forexample,Java\u2019sString\nclassredefinesequalstotestcharacter-for-character equivalence.\nGreatcaremustbetakenwhenoverriding thenotion ofequality, astheconsis-\ntency of Java\u2019s libraries depends upon the equals method defining what is known\nasanequivalencerelation inmathematics, satisfying thefollowingproperties:\nTreatmentofnull: For any nonnull reference variable x, the call x.equals(null)\nshould returnfalse(thatis,nothingequalsnullexceptnull).\nReflexivity: Foranynonnullreferencevariablex,thecallx.equals(x)should\nreturntrue(thatis,anobjectshouldequalitself).\nSymmetry: Foranynonnullreferencevariablesxandy,thecallsx.equals(y)\nandy.equals(x)shouldreturnthesamevalue.\nTransitivity: For any nonnull reference variables x, y, and z, if both calls\nx.equals(y) and y.equals(z) return true, then call x.equals(z)\nmustreturntrueaswell.\nWhile these properties may seem intuitive, it can be challenging to properly\nimplementequalsforsomedatastructures,especiallyinanobject-orientedcontext,\nwithinheritanceandgenerics. Formostofthedatastructuresinthisbook,weomit\nthe implementation of a valid equals method (leaving it as an exercise). However,\ninthissection,weconsiderthetreatmentofequivalencetestingforbotharraysand\nlinkedlists,includingaconcreteexampleofaproperimplementationoftheequals\nmethodforourSinglyLinkedListclass.\nwww.it-ebooks.info\n3.5. EquivalenceTesting 139\n3.5.1 Equivalence Testing with Arrays\nAs we mentioned in Section 1.3, arrays are a reference type in Java, but not tech-\nnically a class. However, the java.util.Arrays class, introduced in Section 3.1.3,\nprovidesadditional staticmethodsthatareusefulwhenprocessing arrays. Thefol-\nlowing provides a summary of the treatment of equivalence for arrays, assuming\nthatvariables aandbrefertoarrayobjects:\na == b: Testsifaandbrefertothesameunderlying arrayinstance.\na.equals(b): Interestingly, this is identical to a == b. Arrays are not a\ntrueclasstypeanddonotoverridetheObject.equalsmethod.\nArrays.equals(a,b): Thisprovidesamoreintuitivenotionofequivalence, return-\ning true if the arrays have the same length and all pairs\nof corresponding elements are \u201cequal\u201d to each other. More\nspecifically, ifthearrayelementsareprimitives, thenituses\nthe standard == to compare values. If elements of the ar-\nrays are a reference type, then it makes pairwise compar-\nisonsa[k].equals(b[k])inevaluating theequivalence.\nFormostapplications, theArrays.equalsbehavior captures the appropriate no-\ntion of equivalence. However, there is an additional complication when using\nmultidimensional arrays. The fact that two-dimensional arrays in Java are really\none-dimensional arrays nested inside a common one-dimensional array raises an\ninteresting issue withrespect tohow wethink about compoundobjects, whichare\nobjects\u2014like a two-dimensional array\u2014that are made up of other objects. In par-\nticular, itbringsupthequestion ofwhereacompound objectbeginsandends.\nThus, if we have a two-dimensional array, a, and another two-dimensional ar-\nray, b, that has the same entries as a, we probably want to think that a is equal\nto b. But the one-dimensional arrays that make up the rows of a and b (such as\na[0] and b[0]) are stored in different memory locations, even though they have the\nsameinternal content. Therefore, acalltothemethod java.util.Arrays.equals(a,b)\nwill return false in this case, because it tests a[k].equals(b[k]), which invokes the\nObjectclass\u2019s definitionofequals.\nTo support the more natural notion of multidimensional arrays being equal if\ntheyhaveequalcontents, theclassprovides anadditional method:\nArrays.deepEquals(a,b): IdenticaltoArrays.equals(a,b)exceptwhentheelements\nof a and b are themselves arrays, in which case it calls\nArrays.deepEquals(a[k],b[k]) for corresponding entries,\nratherthana[k].equals(b[k]).\nwww.it-ebooks.info\n140 Chapter3. FundamentalDataStructures\n3.5.2 Equivalence Testing with Linked Lists\nIn this section, wedevelop an implementation ofthe equals method in the context\noftheSinglyLinkedListclassofSection3.2.1. Usingadefinitionverysimilartothe\ntreatment ofarrays bythejava.util.Arrays.equalsmethod, weconsider twoliststo\nbeequivalentiftheyhavethesamelengthandcontentsthatareelement-by-element\nequivalent. We can evaluate such equivalence by simultaneously traversing two\nlists,verifying thatx.equals(y)foreachpairofcorresponding elementsxandy.\nThe implementation of the SinglyLinkedList.equals method is given in Code\nFragment3.19. Although wearefocused oncomparingtwosinglylinked lists,the\nequalsmethodmusttakeanarbitraryObjectasaparameter. Wetakeaconservative\napproach, demanding that two objects be instances of the same class to have any\npossibility ofequivalence. (Forexample, wedonotconsider asingly linked listto\nbe equivalent to a doubly linked list with the same sequence of elements.) After\nensuring, at line 2, that parameter o is nonnull, line 3 uses the getClass() method\nsupported byallobjectstotestwhetherthetwoinstances belongtothesameclass.\nWhen reaching line 4, we have ensured that the parameter was an instance of\nthe SinglyLinkedList class (or an appropriate subclass), and so we can safely cast\nittoaSinglyLinkedList,sothatwemayaccessitsinstancevariablessizeandhead.\nThere is subtlety involving the treatment of Java\u2019s generics framework. Although\nour SinglyLinkedList class has a declared formal type parameter <E>, we cannot\ndetect atruntime whether the other list has amatching type. (Forthose interested,\nlookonlineforadiscussionoferasureinJava.) Sowereverttousingamoreclassic\napproach with nonparameterized type SinglyLinkedList at line 4, and nonparame-\nterizedNodedeclarations atlines6and7. Ifthetwolistshaveincompatible types,\nthiswillbedetectedwhencallingtheequalsmethodoncorresponding elements.\n1 public boolean equals(Object o)\n{\n2 if (o == null) return false;\n3 if (getClass() != o.getClass()) return false;\n4 SinglyLinkedListother = (SinglyLinkedList) o; // use nonparameterized type\n5 if (size != other.size) return false;\n6 Node walkA = head; // traverse the primary list\n7 Node walkB = other.head; // traverse the secondary list\n8 while (walkA != null)\n{\n9 if (!walkA.getElement().equals(walkB.getElement())) return false; //mismatch\n10 walkA = walkA.getNext();\n11 walkB = walkB.getNext();\n12\n}\n13 return true; // if we reach this, everything matched successfully\n14\n}\nCodeFragment3.19: Implementation oftheSinglyLinkedList.equalsmethod.\nwww.it-ebooks.info\n3.6. CloningDataStructures 141\n3.6 Cloning Data Structures\nThe beauty of object-oriented programming is that abstraction allows for a data\nstructure to be treated as a single object, even though the encapsulated implemen-\ntationofthestructuremightrelyonamorecomplexcombination ofmanyobjects.\nInthissection, weconsider whatitmeanstomakeacopyofsuchastructure.\nIn a programming environment, a common expectation is that a copy of an\nobjecthasitsownstateandthat,oncemade,thecopyisindependentoftheoriginal\n(for example, so that changes to one do not directly affect the other). However,\nwhenobjectshavefieldsthatarereferencevariablespointingtoauxiliaryobjects,it\nisnotalwaysobvious whetheracopyshould haveacorresponding fieldthatrefers\ntothesameauxiliary object,ortoanewcopyofthatauxiliary object.\nFor example, if a hypothetical AddressBook class has instances that represent\nanelectronicaddressbook\u2014withcontactinformation(suchasphonenumbersand\nemailaddresses)foraperson\u2019sfriendsandacquaintances\u2014how mightweenvision\nacopyofanaddressbook? Shouldanentryaddedtoonebookappearintheother?\nIf we change a person\u2019s phone number in one book, would we expect that change\ntobesynchronized intheother?\nThere is no one-size-fits-all answer to questions like this. Instead, each class\nin Java is responsible for defining whether its instances can be copied, and if\nso, precisely how the copy is constructed. The universal Object superclass de-\nfines a method named clone, which can be used to produce what is known as a\nshallow copy of an object. This uses the standard assignment semantics to as-\nsign the value of each field of the new object equal to the corresponding field of\nthe existing object that is being copied. The reason this is known as a shallow\ncopy is because if the field is a reference type, then an initialization of the form\nduplicate.field = original.field causes the field of the new object to refer to the\nsameunderlying instance asthefieldoftheoriginalobject.\nA shallow copy is not always appropriate for all classes, and therefore, Java\nintentionally disables use oftheclone()method bydeclaring itasprotected,and\nby having it throw a CloneNotSupportedException when called. The author of\na class must explicitly declare support for cloning by formally declaring that the\nclass implements the Cloneable interface, and by declaring apublic version of the\nclone() method. That public method can simply call the protected one to do the\nfield-by-field assignment that results in a shallow copy, if appropriate. However,\nfor many classes, the class may choose to implement a deeper version of cloning,\ninwhichsomeofthereferenced objectsarethemselvescloned.\nFor most of the data structures in this book, we omit the implementation of a\nvalidclonemethod(leavingitasanexercise). However,inthissection,weconsider\napproachesforcloningbotharraysandlinkedlists,includingaconcreteimplemen-\ntationoftheclonemethodfortheSinglyLinkedListclass.\nwww.it-ebooks.info\n142 Chapter3. FundamentalDataStructures\n3.6.1 Cloning Arrays\nAlthough arrays support some special syntaxes such as a[k]and a.length, it is im-\nportant to remember that they are objects, and that array variables are reference\nvariables. This has important consequences. As a first example, consider the fol-\nlowingcode:\nint[ ] data = 2, 3, 5, 7, 11, 13, 17, 19 ;\n{ }\nint[ ] backup;\nbackup = data; // warning; not a copy\nTheassignmentofvariablebackuptodatadoesnotcreateanynewarray;itsimply\ncreatesanewaliasforthesamearray,asportrayed inFigure3.23.\ndata\n2 3 5 7 11 13 17 19\nbackup 0 1 2 3 4 5 6 7\nFigure3.23: Theresultofthecommandbackup = dataforintarrays.\nInstead, ifwewanttomakeacopyofthearray,data,andassignareference to\nthenewarraytovariable, backup,weshouldwrite:\nbackup = data.clone();\nTheclonemethod,whenexecutedonanarray,initializeseachcellofthenewarray\ntothevaluethatisstoredinthecorrespondingcelloftheoriginalarray. Thisresults\ninanindependent array,asshowninFigure3.24.\ndata 2 3 5 7 11 13 17 19\n0 1 2 3 4 5 6 7\nbackup 2 3 5 7 11 13 17 19\n0 1 2 3 4 5 6 7\nFigure3.24: Theresultofthecommandbackup = data.clone()forintarrays.\nIfwesubsequently makeanassignmentsuchasdata[4] = 23inthisconfiguration,\nthebackuparrayisunaffected.\nThere are more considerations when copying an array that stores reference\ntypes rather than primitive types. The clone() method produces a shallow copy\nofthearray,producinganewarraywhosecellsrefertothesameobjectsreferenced\nbythefirstarray.\nwww.it-ebooks.info\n3.6. CloningDataStructures 143\nForexample, if the variable contacts refers toan array of hypothetical Person\ninstances, the result of the command guests = contacts.clone() produces a shal-\nlowcopy,asportrayed inFigure3.25.\n0 1 2 3 4 5 6 7\ncontacts\nguests\n0 1 2 3 4 5 6 7\nFigure 3.25: A shallow copy of an array of objects, resulting from the command\nguests = contacts.clone().\nA deep copy of the contact list can be created by iteratively cloning the indi-\nvidualelements, asfollows,butonlyifthePersonclassisdeclared asCloneable.\nPerson[ ] guests = new Person[contacts.length];\nfor (int k=0; k < contacts.length; k++)\nguests[k] = (Person) contacts[k].clone(); // returns Object type\nBecauseatwo-dimensionalarrayisreallyaone-dimensionalarraystoringother\none-dimensional arrays, the same distinction between a shallow and deep copy\nexists. Unfortunately, thejava.util.Arraysclass does not provide any\u201cdeepClone\u201d\nmethod. However, we can implement our own method by cloning the individual\nrowsofanarray, asshowninCodeFragment3.20, foratwo-dimensional array of\nintegers.\n1 public static int[ ][ ] deepClone(int[ ][ ] original)\n{\n2 int[ ][ ] backup = new int[original.length][ ]; // create top-level array of arrays\n3 for (int k=0; k < original.length; k++)\n4 backup[k] = original[k].clone(); // copy row k\n5 return backup;\n6\n}\nCodeFragment3.20:Amethodforcreatingadeepcopyofatwo-dimensionalarray\nofintegers.\nwww.it-ebooks.info\n144 Chapter3. FundamentalDataStructures\n3.6.2 Cloning Linked Lists\nIn this section, we add support for cloning instances of the SinglyLinkedList class\nfrom Section 3.2.1. The first step to making a class cloneable in Java is declaring\nthatitimplementstheCloneableinterface. Therefore,weadjustthefirstlineofthe\nclassdefinition toappearasfollows:\npublic class SinglyLinkedList<E> implements Cloneable\n{\nTheremaining task isimplementing apublic version oftheclone()method of\nthe class, which we present in Code Fragment 3.21. By convention, that method\nshouldbeginbycreatinganewinstanceusingacalltosuper.clone(),whichinour\ncase invokes themethod from theObject class (line 3). Because the inherited ver-\nsionreturnsanObject,weperformanarrowingcasttotypeSinglyLinkedList<E>.\nAtthispointintheexecution, theotherlisthasbeencreated asashallow copy\nof the original. Since our list class has two fields, size and head, the following\nassignments havebeenmade:\nother.size = this.size;\nother.head = this.head;\nWhiletheassignmentofthesizevariableiscorrect,wecannotallowthenewlistto\nshare the same head value (unless it is null). For a nonempty list to have an inde-\npendentstate,itmusthaveanentirelynewchainofnodes,eachstoringareference\ntothecorresponding elementfromtheoriginallist. Wethereforecreateanewhead\nnode at line 5 of the code, and then perform a walk through the remainder of the\noriginal list(lines8\u201313)whilecreatingandlinking newnodesforthenewlist.\n1 public SinglyLinkedList<E> clone() throws CloneNotSupportedException\n{\n2 // always use inherited Object.clone() to create the initial copy\n3 SinglyLinkedList<E> other = (SinglyLinkedList<E>) super.clone(); // safe cast\n4 if (size > 0) // we need independent chain of nodes\n{\n5 other.head = new Node<>(head.getElement(), null);\n6 Node<E> walk = head.getNext(); // walk through remainder of original list\n7 Node<E> otherTail = other.head; // remember most recently created node\n8 while (walk != null) // make a new node storing same element\n{\n9 Node<E> newest = new Node<>(walk.getElement(), null);\n10 otherTail.setNext(newest); // link previous node to this one\n11 otherTail = newest;\n12 walk = walk.getNext();\n13\n}\n14\n}\n15 return other;\n16\n}\nCodeFragment3.21: Implementation oftheSinglyLinkedList.clonemethod.\nwww.it-ebooks.info\n3.7. Exercises 145\n3.7 Exercises\nReinforcement\nR-3.1 Givethenextfivepseudorandomnumbersgeneratedbytheprocessdescribedon\npage113,witha=12,b=5,andn=100,and92astheseedforcur.\nR-3.2 WriteaJavamethodthatrepeatedlyselectsandremovesarandomentryfroman\narrayuntilthearrayholdsnomoreentries.\nR-3.3 Explainthe changesthatwould haveto be madeto the programof Code Frag-\nment3.8sothatitcouldperformtheCaesarcipherformessagesthatarewritten\nin an alphabet-based language other than English, such as Greek, Russian, or\nHebrew.\nR-3.4 TheTicTacToeclassofCodeFragments3.9and3.10hasaflaw,inthatitallows\naplayertoplaceamarkevenafterthegamehasalreadybeenwonbysomeone.\nModifytheclasssothattheputMarkmethodthrowsanIllegalStateExceptionin\nthatcase.\nR-3.5 TheremoveFirstmethodoftheSinglyLinkedListclassincludesaspecialcaseto\nresetthetailfieldtonullwhendeletingthelastnodeofalist(seelines51and52\nofCodeFragment3.15).Whataretheconsequencesifweweretoremovethose\ntwo linesfromthecode? Explainwhytheclass wouldorwouldnotworkwith\nsuchamodification.\nR-3.6 Give an algorithm for finding the second-to-last node in a singly linked list in\nwhichthelastnodeisindicatedbyanullnextreference.\nR-3.7 Consider the implementation of CircularlyLinkedList.addFirst, in Code Frag-\nment 3.16. The else bodyat lines 39 and 40 of that method relies on a locally\ndeclared variable, newest. Redesign that clause to avoid use of any local vari-\nable.\nR-3.8 Describeamethodforfindingthemiddlenodeofadoublylinkedlistwithheader\nandtrailersentinelsby\u201clinkhopping,\u201dandwithoutrelyingonexplicitknowledge\nof the size of the list. In the case of an evennumberof nodes, reportthe node\nslightlyleftofcenterasthe\u201cmiddle.\u201dWhatistherunningtimeofthismethod?\nR-3.9 Giveanimplementationofthesize()methodfortheSingularlyLinkedListclass,\nassumingthatwedidnotmaintainsizeasaninstancevariable.\nR-3.10 Giveanimplementationofthesize()methodfortheCircularlyLinkedListclass,\nassumingthatwedidnotmaintainsizeasaninstancevariable.\nR-3.11 Give an implementation of the size() method for the DoublyLinkedList class,\nassumingthatwedidnotmaintainsizeasaninstancevariable.\nR-3.12 Implementarotate()methodintheSinglyLinkedListclass,whichhassemantics\nequaltoaddLast(removeFirst()),yetwithoutcreatinganynewnode.\nwww.it-ebooks.info\n146 Chapter3. FundamentalDataStructures\nR-3.13 What is the differencebetween a shallow equality test and a deep equality test\nbetweentwoJavaarrays,AandB,iftheyareone-dimensionalarraysoftypeint?\nWhatifthearraysaretwo-dimensionalarraysoftypeint?\nR-3.14 Give three different examples of a single Java statement that assigns variable,\nbackup,toanewarraywithcopiesofallintentriesofanexistingarray,original.\nR-3.15 Implementtheequals()methodfortheCircularlyLinkedListclass,assumingthat\ntwolistsareequaliftheyhavethesamesequenceofelements,withcorrespond-\ningelementscurrentlyatthefrontofthelist.\nR-3.16 Implementtheequals()methodfortheDoublyLinkedListclass.\nCreativity\nC-3.17 LetAbeanarrayofsizen 2containingintegersfrom1ton 1inclusive,one\n\u2265 \u2212\nof which is repeated. Describe an algorithmfor finding the integer in A that is\nrepeated.\nC-3.18 LetBbeanarrayofsizen 6containingintegersfrom1ton 5inclusive,five\n\u2265 \u2212\nof which are repeated. Describe an algorithm for finding the five integersin B\nthatarerepeated.\nC-3.19 GiveJavacodeforperformingadd(e)andremove(i)methodsfortheScoreboard\nclass,asinCodeFragments3.3and3.4,exceptthistime,don\u2019tmaintainthegame\nentriesinorder.Assumethatwestillneedtokeepnentriesstoredinindices0to\nn 1.Youshouldbeabletoimplementthemethodswithoutusinganyloops,so\n\u2212\nthatthenumberofstepstheyperformdoesnotdependonn.\nC-3.20 Give examples of values for a and b in the pseudorandom generator given on\npage 113 of this chapter such that the result is not very random looking, for\nn=1000.\nC-3.21 Supposeyouaregivenanarray,A, containing100integersthatweregenerated\nusingthe methodr.nextInt(10), wherer is anobjectoftypejava.util.Random.\nLetxdenotetheproductoftheintegersinA. Thereisasinglenumberthatxwill\nequalwithprobabilityatleast0.99. Whatisthatnumberandwhatisaformula\ndescribingtheprobabilitythatxisequaltothatnumber?\nC-3.22 Writeamethod,shuffle(A),thatrearrangestheelementsofarrayAsothatevery\npossible ordering is equally likely. You may rely on the nextInt(n) method of\nthejava.util.Randomclass,whichreturnsarandomnumberbetween0andn 1\n\u2212\ninclusive.\nC-3.23 Supposeyouaredesigningamultiplayergamethathasn 1000players,num-\n\u2265\nbered1 ton, interactinginanenchantedforest. Thewinnerofthisgameis the\nfirst player who can meet all the other players at least once (ties are allowed).\nAssumingthatthereisamethodmeet(i, j),whichiscalledeachtimeaplayeri\nmeetsaplayer j(withi= j),describeawaytokeeptrackofthepairsofmeeting\n6\nplayersandwhoisthewinner.\nwww.it-ebooks.info\n3.7. Exercises 147\nC-3.24 Write a Java method that takes two three-dimensional integer arrays and adds\nthemcomponentwise.\nC-3.25 Describeanalgorithmforconcatenatingtwo singlylinkedlistsLandM, intoa\nsinglelistL\u2032 thatcontainsallthenodesofLfollowedbyallthenodesofM.\nC-3.26 GiveanalgorithmforconcatenatingtwodoublylinkedlistsLandM,withheader\nandtrailersentinelnodes,intoasinglelistL\u2032.\nC-3.27 Describeindetailhowtoswaptwonodesxandy(andnotjusttheircontents)in\nasinglylinkedlistLgivenreferencesonlytoxandy. Repeatthisexerciseforthe\ncasewhenLisadoublylinkedlist. Whichalgorithmtakesmoretime?\nC-3.28 Describe in detail an algorithmfor reversinga singly linkedlist L using onlya\nconstantamountofadditionalspace.\nC-3.29 Supposeyouaregiventwocircularlylinkedlists,LandM.Describeanalgorithm\nfor telling if L and M store the same sequence of elements (but perhaps with\ndifferentstartingpoints).\nC-3.30 Given a circularly linked list L containing an even number of nodes, describe\nhowtosplitLintotwocircularlylinkedlistsofhalfthesize.\nC-3.31 Ourimplementationofadoublylinkedlistreliesontwosentinelnodes,header\nand trailer, but a single sentinel node that guards both ends of the list should\nsuffice. ReimplementtheDoublyLinkedListclassusingonlyonesentinelnode.\nC-3.32 Implementacircularversionofa doublylinkedlist, withoutanysentinels, that\nsupportsallthepublicbehaviorsoftheoriginalaswellastwonewupdatemeth-\nods,rotate()androtateBackward().\nC-3.33 Solvethepreviousproblemusinginheritance,suchthataDoublyLinkedListclass\ninheritsfromtheexistingCircularlyLinkedList, andtheDoublyLinkedList.Node\nnestedclassinheritsfromCircularlyLinkedList.Node.\nC-3.34 Implementtheclone()methodfortheCircularlyLinkedListclass.\nC-3.35 Implementtheclone()methodfortheDoublyLinkedListclass.\nProjects\nP-3.36 WriteaJavaprogramforamatrixclassthatcanaddandmultiplyarbitrarytwo-\ndimensionalarraysofintegers.\nP-3.37 Writeaclassthatmaintainsthetoptenscoresforagameapplication,implement-\ningtheadd andremove methodsofSection3.1.1,butusingasinglylinkedlist\ninsteadofanarray.\nP-3.38 Performthepreviousproject,butuseadoublylinkedlist. Moreover,yourimple-\nmentationofremove(i)shouldmakethefewestnumberofpointerhopstogetto\nthegameentryatindexi.\nP-3.39 Write a program that can perform the Caesar cipher for English messages that\nincludebothupper-andlowercasecharacters.\nwww.it-ebooks.info\n148 Chapter3. FundamentalDataStructures\nP-3.40 Implementaclass,SubstitutionCipher,withaconstructorthattakesastringwith\nthe 26 uppercaselettersin an arbitraryorderand uses that as the encoderfor a\ncipher(thatis, A is mappedto the first characterof the parameter,B is mapped\ntothesecond,andsoon.)Youshouldderivethedecodingmapfromtheforward\nversion.\nP-3.41 Redesign the CaesarCipher class as a subclass of the SubstitutionCipher from\nthepreviousproblem.\nP-3.42 DesignaRandomCipherclassasasubclassoftheSubstitutionCipherfromEx-\nercise P-3.40,so thateachinstanceoftheclass reliesona randompermutation\noflettersforitsmapping.\nP-3.43 In the children\u2019sgame, Duck, Duck, Goose, a group of children sit in a circle.\nOneofthemiselected\u201cit\u201dandthatpersonwalksaroundtheoutsideofthecircle.\nThe person who is \u201cit\u201d pats each child on the head, saying \u201cDuck\u201d each time,\nuntilrandomlyreachingachildthatthe\u201cit\u201dpersonidentifiesas\u201cGoose.\u201dAtthis\npointthereisamadscramble,asthe\u201cGoose\u201dandthe\u201cit\u201dpersonracearoundthe\ncircle. Whoever returns to the Goose\u2019s former place first gets to remain in the\ncircle. The loser of this race is the \u201cit\u201d personfor the nextroundof play. The\ngame continues like this until the children get bored or an adult tells them it\u2019s\nsnacktime. WritesoftwarethatsimulatesagameofDuck,Duck,Goose.\nChapter Notes\nThefundamentaldatastructuresofarraysandlinkedlistsdiscussedinthischapterbelong\nto the folklore of computer science. They were first chronicled in the computer science\nliteraturebyKnuthinhisseminalbookonFundamentalAlgorithms[60].\nwww.it-ebooks.info\nChapter\n4\nAlgorithm Analysis\nContents\n4.1 Experimental Studies . . . . . . . . . . . . . . . . . . . . . 151\n4.1.1 Moving Beyond Experimental Analysis . . . . . . . . . . . 154\n4.2 The Seven Functions Used in This Book . . . . . . . . . . 156\n4.2.1 Comparing Growth Rates . . . . . . . . . . . . . . . . . . 163\n4.3 Asymptotic Analysis . . . . . . . . . . . . . . . . . . . . . . 164\n4.3.1 The \u201cBig-Oh\u201d Notation . . . . . . . . . . . . . . . . . . . 164\n4.3.2 Comparative Analysis . . . . . . . . . . . . . . . . . . . . 168\n4.3.3 Examples of Algorithm Analysis . . . . . . . . . . . . . . 170\n4.4 Simple Justification Techniques . . . . . . . . . . . . . . . 178\n4.4.1 By Example . . . . . . . . . . . . . . . . . . . . . . . . . 178\n4.4.2 The \u201cContra\u201d Attack . . . . . . . . . . . . . . . . . . . . 178\n4.4.3 Induction and Loop Invariants . . . . . . . . . . . . . . . 179\n4.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\nwww.it-ebooks.info\n150 Chapter4. AlgorithmAnalysis\nIn a classic story, the famous mathematician Archimedes was asked to deter-\nmine if a golden crown commissioned by the king was indeed pure gold, and not\npartsilver, asaninformant hadclaimed. Archimedes discovered awaytoperform\nthisanalysis whilestepping intoabath. Henotedthatwaterspilledoutofthebath\ninproportion to theamount ofhim that wentin. Realizing theimplications of this\nfact, he immediately got out of the bath and ran naked through the city shouting,\n\u201cEureka, eureka!\u201d for he had discovered an analysis tool (displacement), which,\nwhen combined witha simple scale, could determine if the king\u2019s new crown was\ngoodornot. Thatis,Archimedescoulddipthecrownandanequal-weight amount\nof gold into a bowl of water to see if they both displaced the same amount. This\ndiscovery was unfortunate for the goldsmith, however, for when Archimedes did\nhis analysis, the crown displaced more water than an equal-weight lump of pure\ngold,indicating thatthecrownwasnot,infact,puregold.\nInthisbook,weareinterestedinthedesignof\u201cgood\u201ddatastructuresandalgo-\nrithms. Simplyput, adatastructureisasystematic wayoforganizing andaccess-\ningdata,andanalgorithmisastep-by-step procedureforperformingsometaskin\nafiniteamountoftime. Theseconcepts arecentral tocomputing, but tobeableto\nclassifysomedatastructuresandalgorithmsas\u201cgood,\u201dwemusthavepreciseways\nofanalyzing them.\nThe primary analysis tool we will use in this book involves characterizing the\nrunning times of algorithms and data structure operations, with space usage also\nbeing ofinterest. Running timeisanatural measureof\u201cgoodness,\u201d since timeisa\nprecious resource\u2014computer solutions should run as fast as possible. In general,\ntherunningtimeofanalgorithmordatastructureoperationincreaseswiththeinput\nsize, although itmayalso varyfordifferent inputs ofthesamesize. Also, the run-\nning time is affected by the hardware environment (e.g., the processor, clock rate,\nmemory,disk)andsoftwareenvironment(e.g.,theoperatingsystem,programming\nlanguage) in which the algorithm is implemented and executed. All other factors\nbeingequal,therunning timeofthesamealgorithm onthesameinputdatawillbe\nsmaller if the computer has, say, a much faster processor or if the implementation\nis done in a program compiled into native machine code instead of an interpreted\nimplementationrunonavirtualmachine. Webeginthischapterbydiscussingtools\nforperforming experimental studies, yet also limitations totheuse ofexperiments\nasaprimarymeansforevaluating algorithm efficiency.\nFocusingonrunningtimeasaprimarymeasureofgoodnessrequiresthatwebe\nable to use a few mathematical tools. In spite of the possible variations that come\nfrom different environmental factors, we would like to focus on the relationship\nbetweentherunningtimeofanalgorithmandthesizeofitsinput. Weareinterested\nin characterizing an algorithm\u2019s running time as a function of the input size. But\nwhat is the proper way of measuring it? In this chapter, we \u201croll up our sleeves\u201d\nanddevelopamathematical wayofanalyzing algorithms.\nwww.it-ebooks.info\n4.1. ExperimentalStudies 151\n4.1 Experimental Studies\nOnewaytostudy theefficiency ofanalgorithm istoimplement itandexperiment\nbyrunningtheprogramonvarioustestinputswhilerecordingthetimespentduring\neach execution. A simple mechanism for collecting such running times in Java is\nbased on use of the currentTimeMillis method of the System class. That method\nreportsthenumberofmillisecondsthathavepassedsinceabenchmarktimeknown\nas the epoch (January 1, 1970 UTC).Itis not that weare directly interested in the\ntime since the epoch; the key is that if we record the time immediately before\nexecuting the algorithm and then immediately after, we can measure the elapsed\ntime of an algorithm\u2019s execution by computing the difference of those times. A\ntypicalwaytoautomatethisprocessisshowninCodeFragment4.1.\n1 long startTime = System.currentTimeMillis(); // record the starting time\n2 /\u2217 (run the algorithm) \u2217/\n3 long endTime = System.currentTimeMillis(); // record the ending time\n4 long elapsed = endTime startTime; // compute the elapsed time\n\u2212\nCodeFragment4.1: Typicalapproach fortiminganalgorithm inJava.\nMeasuring elapsed time in this fashion provides a reasonable reflection of an\nalgorithm\u2019s efficiency; for extremely quick operations, Java provides a method,\nnanoTime,thatmeasuresinnanoseconds ratherthanmilliseconds.\nBecause we are interested in the general dependence of running time on the\nsize and structure of the input, we should perform independent experiments on\nmany different test inputs of various sizes. We can then visualize the results by\nplotting the performance of each run of the algorithm as apoint withx-coordinate\nequal to the input size, n, and y-coordinate equal to the running time, t. Such a\nvisualization provides some intuition regarding the relationship between problem\nsize and execution time for the algorithm. This may be followed by a statistical\nanalysisthatseekstofitthebestfunctionoftheinputsizetotheexperimentaldata.\nTobemeaningful,thisanalysisrequiresthatwechoosegoodsampleinputsandtest\nenough of them to be able to make sound statistical claims about the algorithm\u2019s\nrunning time.\nHowever,themeasuredtimesreportedbybothmethodscurrentTimeMillisand\nnanoTime will vary greatly from machine to machine, and may likely vary from\ntrial totrial, evenon thesame machine. This isbecause manyprocesses share use\nof a computer\u2019s central processing unit(or CPU)and memory system; therefore,\ntheelapsed timewilldepend onwhatother processes arerunning onthecomputer\nwhen atest is performed. While the precise running time may not be dependable,\nexperiments are quite useful when comparing the efficiency of two or more algo-\nrithms,solongastheygatheredundersimilarcircumstances.\nwww.it-ebooks.info\n152 Chapter4. AlgorithmAnalysis\nAs a tangible example of experimental analysis, we consider two algorithms\nfor constructing long strings in Java. Our goal will be to have a method, with a\ncalling signature such as repeat('*', 40), that produces a string composed of 40\nasterisks: \"****************************************\".\nThe first algorithm we consider performs repeated string concatenation, based\non the + operator. It is implemented as method repeat1 in Code Fragment 4.2.\nThesecond algorithm relies on Java\u2019s StringBuilderclass (see Section 1.3), andis\nimplementedasmethodrepeat2inCodeFragment4.2.\n1 /\u2217\u2217 Uses repeated concatenation to compose a String with n copies of character c. \u2217/\n2 public static String repeat1(char c, int n)\n{\n3 String answer = \"\";\n4 for (int j=0; j < n; j++)\n5 answer += c;\n6 return answer;\n7\n}\n8\n9 /\u2217\u2217 Uses StringBuilder to compose a String with n copies of character c. \u2217/\n10 public static String repeat2(char c, int n)\n{\n11 StringBuilder sb = new StringBuilder();\n12 for (int j=0; j < n; j++)\n13 sb.append(c);\n14 return sb.toString();\n15\n}\nCodeFragment4.2: Twoalgorithms forcomposing astringofrepeated characters.\nAs an experiment, we used System.currentTimeMillis(), in the style of Code\nFragment4.1,tomeasuretheefficiencyofbothrepeat1andrepeat2forverylarge\nstrings. Weexecuted trials to compose strings of increasing lengths toexplore the\nrelationship between the running time and the string length. The results of our\nexperiments areshowninTable4.1andchartedonalog-logscaleinFigure4.1.\nn repeat1(inms) repeat2(inms)\n50,000 2,884 1\n100,000 7,437 1\n200,000 39,158 2\n400,000 170,173 3\n800,000 690,836 7\n1,600,000 2,874,968 13\n3,200,000 12,809,631 28\n6,400,000 59,594,275 58\n12,800,000 265,696,421 135\nTable4.1: Resultsoftimingexperiment onthemethodsfromCodeFragment4.2.\nwww.it-ebooks.info\n4.1. ExperimentalStudies 153\n108\n107\n106\n105 repeat1\n104\nrepeat2\n103\n102\n101\n100\n104 105 106 107\nn\n)sm(emiTgninnuR\n109\nFigure4.1: Chart oftheresults ofthe timing experiment from Code Fragment 4.2,\ndisplayed onalog-log scale. Thedivergent slopes demonstrate anorderofmagni-\ntudedifference inthegrowthoftherunningtimes.\nThemoststrikingoutcomeoftheseexperimentsishowmuchfastertherepeat2\nalgorithm isrelative torepeat1. Whilerepeat1isalready taking morethan 3days\nto compose a string of 12.8 million characters, repeat2 is able to do the same in a\nfraction ofasecond. Wealsoseesomeinteresting trendsinhowtherunning times\nofthealgorithms eachdepend uponthesizeofn. Asthevalueofnisdoubled, the\nrunning time of repeat1 typically increases more than fourfold, while the running\ntimeofrepeat2approximately doubles.\nChallenges of Experimental Analysis\nWhile experimental studies of running times are valuable, especially when fine-\ntuning production-quality code, there are three major limitations to their use for\nalgorithm analysis:\nExperimental running times of two algorithms are difficult to directly com-\n\u2022\npareunlesstheexperimentsareperformedinthesamehardwareandsoftware\nenvironments.\nExperiments can be done only on a limited set of test inputs; hence, they\n\u2022\nleave out the running times of inputs not included in the experiment (and\ntheseinputsmaybeimportant).\nAn algorithm must be fully implemented in order to execute it to study its\n\u2022\nrunning timeexperimentally.\nThislastrequirementisthemostseriousdrawbacktotheuseofexperimentalstud-\nies. At early stages of design, when considering a choice of data structures or\nalgorithms,itwouldbefoolishtospendasignificantamountoftimeimplementing\nanapproachthatcouldeasilybedeemedinferiorbyahigher-level analysis.\nwww.it-ebooks.info\n154 Chapter4. AlgorithmAnalysis\n4.1.1 Moving Beyond Experimental Analysis\nOurgoalistodevelopanapproach toanalyzing theefficiencyofalgorithms that:\n1. Allows us to evaluate the relative efficiency of any two algorithms in a way\nthatisindependent ofthehardwareandsoftwareenvironment.\n2. Is performed by studying a high-level description of the algorithm without\nneedforimplementation.\n3. Takesintoaccount allpossible inputs.\nCounting Primitive Operations\nTo analyze the running time of an algorithm without performing experiments, we\nperform an analysis directly on a high-level description of the algorithm (either in\nthe form of an actual code fragment, or language-independent pseudocode). We\ndefineasetofprimitiveoperations suchasthefollowing:\nAssigning avaluetoavariable\n\u2022\nFollowinganobjectreference\n\u2022\nPerforminganarithmeticoperation (forexample,addingtwonumbers)\n\u2022\nComparingtwonumbers\n\u2022\nAccessing asingleelementofanarraybyindex\n\u2022\nCallingamethod\n\u2022\nReturning fromamethod\n\u2022\nFormally, aprimitiveoperation corresponds toalow-levelinstruction withanexe-\ncutiontimethatisconstant. Ideally,thismightbethetypeofbasicoperationthatis\nexecutedbythehardware,althoughmanyofourprimitiveoperationsmaybetrans-\nlated to asmall number of instructions. Instead oftrying todetermine the specific\nexecution time ofeach primitive operation, wewillsimply count how manyprim-\nitive operations are executed, and use this number t as a measure of the running\ntimeofthealgorithm.\nThisoperation countwillcorrelate toanactualrunning timeinaspecificcom-\nputer,foreachprimitiveoperationcorrespondstoaconstantnumberofinstructions,\nandthereareonlyafixednumberofprimitiveoperations. Theimplicitassumption\nin this approach is that the running times of different primitive operations will be\nfairly similar. Thus, the number, t, of primitive operations an algorithm performs\nwillbeproportional totheactualrunning timeofthatalgorithm.\nMeasuring Operations as a Function of Input Size\nTo capture the order of growth of an algorithm\u2019s running time, we will associate,\nwith each algorithm, a function f(n) that characterizes the number of primitive\noperations that areperformed asafunction oftheinputsizen. Section4.2willin-\ntroducethesevenmostcommonfunctionsthatarise,andSection4.3willintroduce\namathematical frameworkforcomparingfunctions toeachother.\nwww.it-ebooks.info\n4.1. ExperimentalStudies 155\nFocusing on the Worst-Case Input\nAnalgorithmmayrunfasteronsomeinputsthanitdoesonothersofthesamesize.\nThus, wemay wish to express the running time of an algorithm as the function of\nthe input size obtained by taking the average over all possible inputs of the same\nsize. Unfortunately, such an average-case analysis is typically quite challenging.\nItrequiresustodefineaprobability distribution onthesetofinputs,whichisoften\nadifficulttask. Figure4.2schematically showshow,depending ontheinputdistri-\nbution, the running time of an algorithm can be anywhere between the worst-case\ntime and the best-case time. For example, what if inputs are really only of types\n\u201cA\u201dor\u201cD\u201d?\nAn average-case analysis usually requires that we calculate expected running\ntimes based on a given input distribution, which usually involves sophisticated\nprobability theory. Therefore, for the remainder of this book, unless we specify\notherwise,wewillcharacterize runningtimesintermsoftheworstcase,asafunc-\ntionoftheinputsize,n,ofthealgorithm.\nWorst-case analysis is much easier than average-case analysis, as it requires\nonly the ability to identify the worst-case input, which is often simple. Also, this\napproachtypicallyleadstobetteralgorithms. Makingthestandardofsuccessforan\nalgorithm toperformwellintheworstcasenecessarily requiresthatitwilldowell\non every input. That is, designing for the worst case leads to stronger algorithmic\n\u201cmuscles,\u201dmuchlikeatrackstarwhoalwayspractices byrunning upanincline.\nemiTgninnuR\n5ms worst-casetime\n4ms\naverage-casetime?\n3ms\n(cid:27)\nbest-casetime\n2ms\n1ms\nA B C D E F G\nInputInstance\nFigure4.2: Thedifference between best-case andworst-case time. Eachbarrepre-\nsentstherunning timeofsomealgorithm onadifferent possible input.\nwww.it-ebooks.info\n156 Chapter4. AlgorithmAnalysis\n4.2 The Seven Functions Used in This Book\nIn this section, we will briefly discuss the seven most important functions used\nin the analysis of algorithms. We will use only these seven simple functions for\nalmost all the analysis we do in this book. In fact, a section that uses a function\nother than one of these seven will be marked with a star (\u22c6) to indicate that it is\noptional. Inaddition to these seven fundamental functions, an appendix (available\non the companion website) contains a list of other useful mathematical facts that\napplyintheanalysis ofdatastructures andalgorithms.\nThe Constant Function\nThesimplestfunction wecanthinkofistheconstantfunction,thatis,\nf(n)=c,\nfor some fixed constant c, such as c = 5, c = 27, or c = 210. That is, for any\nargument n, theconstant function f(n)assigns the value c. Inother words, itdoes\nnotmatterwhatthevalueofnis; f(n)willalwaysbeequaltotheconstantvaluec.\nBecausewearemostinterestedinintegerfunctions,themostfundamentalcon-\nstant function is g(n)=1, and this is the typical constant function we use in this\nbook. Notethatanyotherconstant function, f(n)=c,canbewrittenasaconstant\nctimesg(n). Thatis, f(n)=cg(n)inthiscase.\nAssimpleasitis,theconstantfunctionisusefulinalgorithmanalysisbecauseit\ncharacterizesthenumberofstepsneededtodoabasicoperationonacomputer,like\naddingtwonumbers, assigning avaluetoavariable, orcomparingtwonumbers.\nThe Logarithm Function\nOne of the interesting and sometimes even surprising aspects of the analysis of\ndatastructuresandalgorithmsistheubiquitouspresenceofthelogarithmfunction,\nf(n)=log n,forsomeconstant b>1. Thisfunction isdefinedastheinverse ofa\nb\npower,asfollows:\nx=log n ifandonlyif bx =n.\nb\nThevaluebisknownasthebaseofthelogarithm. Notethatbytheabovedefinition,\nforanybaseb>0,wehavethatlog 1=0.\nb\nThemost common base for the logarithm function incomputer science is 2as\ncomputers store integers in binary. In fact, this base is so common that we will\ntypically omititfromthenotation whenitis2. Thatis,forus,\nlogn=log n.\n2\nWe note that most handheld calculators have a button marked LOG, but this is\ntypically forcalculating thelogarithm base-10, notbase-two.\nwww.it-ebooks.info\n4.2. TheSevenFunctionsUsedinThisBook 157\nComputing thelogarithm function exactlyforanyintegerninvolves theuseof\ncalculus, but we can use an approximation that is good enough for our purposes\nwithout calculus. We recall that the ceiling of a real number, x, is the smallest\nintegergreaterthanorequaltox,denotedwith x . Theceilingofxcanbeviewed\n\u2308 \u2309\nas an integer approximation of x since we have x x < x+1. For a positive\n\u2264 \u2308 \u2309\ninteger, n,werepeatedly dividenbybandstopwhenwegetanumberlessthanor\nequalto1. Thenumberofdivisions performedisequalto log n . Wegivebelow\n\u2308 b \u2309\nthreeexamplesofthecomputation of log n byrepeated divisions:\n\u2308 b \u2309\nlog 27 =3,because((27/3)/3)/3=1;\n\u2022 \u2308 3 \u2309\nlog 64 =3,because((64/4)/4)/4=1;\n\u2022 \u2308 4 \u2309\nlog 12 =4,because(((12/2)/2)/2)/2 =0.75 1.\n\u2022 \u2308 2 \u2309 \u2264\nThe following proposition describes several important identities that involve\nlogarithmsforanybasegreaterthan1.\nProposition 4.1 (Logarithm Rules): Givenrealnumbersa>0,b>1,c>0,\nandd>1,wehave:\n1. log (ac)=log a+log c\nb b b\n2. log (a/c)=log a log c\nb b b\n\u2212\n3. log (ac)=clog a\nb b\n4. log a=log a/log b\nb d d\n5. blog d a=alog d b\nBy convention, the unparenthesized notation lognc denotes the value log(nc).\nWeuseanotational shorthand, logcn,todenote thequantity, (logn)c,inwhichthe\nresultofthelogarithm israisedtoapower.\nTheaboveidentitiescanbederivedfromconverserulesforexponentiation that\nwewillpresentonpage161. Weillustrate theseidentities withafewexamples.\nExample 4.2: Wedemonstratebelowsomeinterestingapplicationsoftheloga-\nrithmrulesfromProposition4.1(usingtheusualconventionthatthebaseofa\nlogarithmis2ifitisomitted).\nlog(2n)=log2+logn=1+logn,byrule1\n\u2022\nlog(n/2)=logn log2=logn 1,byrule2\n\u2022 \u2212 \u2212\nlogn3=3logn,byrule3\n\u2022\nlog2n=nlog2=n 1=n,byrule3\n\u2022 \u00b7\nlog n=(logn)/log4=(logn)/2,byrule4\n4\n\u2022\n2logn=nlog2=n1=n,byrule5.\n\u2022\nAsapracticalmatter,wenotethatrule4givesusawaytocomputethebase-two\nlogarithmonacalculatorthathasabase-10logarithmbutton,LOG,for\nlog n=LOGn/LOG2.\n2\nwww.it-ebooks.info\n158 Chapter4. AlgorithmAnalysis\nThe Linear Function\nAnothersimpleyetimportantfunction isthelinearfunction,\nf(n)=n.\nThatis,givenaninputvaluen,thelinearfunction f assigns thevaluenitself.\nThisfunctionarisesinalgorithmanalysisanytimewehavetodoasinglebasic\noperation for each of n elements. For example, comparing a number x to each\nelement of an array of size n will require n comparisons. The linear function also\nrepresents the best running time we can hope to achieve for any algorithm that\nprocesseseachofnobjectsthatarenotalreadyinthecomputer\u2019smemory,because\nreadinginthenobjectsalreadyrequires noperations.\nN N\nThe -Log- Function\nThenextfunction wediscuss inthissection isthen-log-nfunction,\nf(n)=nlogn,\nthat is, the function that assigns to an input n the value of n times the logarithm\nbase-twoofn. Thisfunctiongrowsalittlemorerapidlythanthelinearfunctionand\nalotlessrapidly thanthequadratic function; therefore, wewouldgreatlypreferan\nalgorithmwitharunningtimethatisproportionaltonlogn,thanonewithquadratic\nrunning time. Wewillseeseveralimportant algorithms thatexhibitarunning time\nproportional to the n-log-n function. For example, the fastest possible algorithms\nforsortingnarbitrary valuesrequiretimeproportional tonlogn.\nThe Quadratic Function\nAnotherfunctionthatappearsofteninalgorithmanalysisisthequadraticfunction,\nf(n)=n2.\nThat is, given an input value n, the function f assigns the product of n with itself\n(inotherwords,\u201cnsquared\u201d).\nThe main reason why the quadratic function appears in the analysis of algo-\nrithms is that there are many algorithms that have nested loops, where the inner\nloop performs a linear number of operations and the outer loop is performed a\nlinear number of times. Thus, in such cases, the algorithm performs n n = n2\n\u00b7\noperations.\nwww.it-ebooks.info\n4.2. TheSevenFunctionsUsedinThisBook 159\nNested Loops and the Quadratic Function\nThequadratic function canalso arise inthe context ofnested loops where the first\niterationofaloopusesoneoperation,thesecondusestwooperations,thethirduses\nthreeoperations, andsoon. Thatis,thenumberofoperations is\n1+2+3+ +(n 2)+(n 1)+n.\n\u00b7\u00b7\u00b7 \u2212 \u2212\nInotherwords, thisisthetotalnumberofoperations thatwillbeperformed bythe\nnestedloopifthenumberofoperationsperformedinsidetheloopincreasesbyone\nwitheachiterationoftheouterloop. Thisquantity alsohasaninteresting history.\nIn1787,aGermanschoolteacher decidedtokeephis9-and10-year-old pupils\noccupied by adding up the integers from 1 to 100. But almost immediately one\nof the children claimed to have the answer! The teacher was suspicious, for the\nstudenthadonlytheansweronhisslate. Buttheanswer,5050,wascorrectandthe\nstudent, CarlGauss, grew upto be one ofthe greatest mathematicians of his time.\nWepresumethatyoungGaussusedthefollowingidentity.\nProposition 4.3: Foranyintegern 1,wehave:\n\u2265\nn(n+1)\n1+2+3+ +(n 2)+(n 1)+n= .\n\u00b7\u00b7\u00b7 \u2212 \u2212 2\nWegivetwo\u201cvisual\u201djustifications ofProposition 4.3inFigure4.3.\nn\n3\n2\n1\n0 1 2 3 n\n...\nn+1\nn\n3\n2\n1\n0 1 2 n/2\n...\n(a) (b)\nFigure4.3: Visual justifications ofProposition 4.3. Both illustrations visualize the\nidentity in terms of the total area covered by n unit-width rectangles with heights\n1,2,...,n. In(a),therectanglesareshowntocoverabigtriangleofarean2/2(base\nn and height n) plus n small triangles of area 1/2 each (base 1 and height 1). In\n(b), which applies only when n is even, the rectangles are shown to cover a big\nrectangle ofbasen/2andheightn+1.\nwww.it-ebooks.info\n160 Chapter4. AlgorithmAnalysis\nThelessontobelearnedfromProposition4.3isthatifweperformanalgorithm\nwith nested loops such that the operations in the inner loop increase by one each\ntime, then the total number of operations is quadratic in the number of times, n,\nwe perform the outer loop. To be fair, the number of operations is n2/2 + n/2,\nandsothis isjustoverhalf thenumber ofoperations than analgorithm that uses n\noperations each time the inner loop is performed. But the order of growth is still\nquadratic inn.\nThe Cubic Function and Other Polynomials\nContinuing our discussion of functions that are powers of the input, we consider\nthecubicfunction,\nf(n)=n3,\nwhichassignstoaninputvaluentheproduct ofnwithitselfthreetimes.\nThecubic function appears lessfrequently inthecontext ofalgorithm analysis\nthantheconstant, linear, andquadratic functions previously mentioned, butitdoes\nappearfromtimetotime.\nPolynomials\nThe linear, quadratic and cubic functions can each be viewed as being part of a\nlargerclassoffunctions, thepolynomials. Apolynomialfunctionhastheform,\nf(n)=a +a n+a n2+a n3+ +a nd,\n0 1 2 3 d\n\u00b7\u00b7\u00b7\nwhere a ,a ,...,a are constants, called the coefficients of the polynomial, and\n0 1 d\na =0. Integer d, which indicates the highest power in the polynomial, is called\nd\n6\nthedegreeofthepolynomial.\nForexample,thefollowingfunctions areallpolynomials:\nf(n)=2+5n+n2\n\u2022\nf(n)=1+n3\n\u2022\nf(n)=1\n\u2022\nf(n)=n\n\u2022\nf(n)=n2\n\u2022\nTherefore,wecouldarguethatthisbookpresentsjustfourimportantfunctionsused\ninalgorithmanalysis,butwewillsticktosayingthatthereareseven,sincethecon-\nstant, linear, and quadratic functions are too important to be lumped in with other\npolynomials. Running times that are polynomials with small degree are generally\nbetterthanpolynomial runningtimeswithlargerdegree.\nwww.it-ebooks.info\n4.2. TheSevenFunctionsUsedinThisBook 161\nSummations\nAnotation thatappearsagainandagainintheanalysis ofdatastructures andalgo-\nrithmsisthesummation,whichisdefinedasfollows:\nb\n\u2211 f(i)= f(a)+ f(a+1)+ f(a+2)+ + f(b),\n\u00b7\u00b7\u00b7\ni=a\nwhereaandbareintegersanda b. Summationsariseindatastructure andalgo-\n\u2264\nrithmanalysisbecausetherunningtimesofloopsnaturallygiverisetosummations.\nUsingasummation, wecanrewritetheformulaofProposition 4.3as\nn n(n+1)\n\u2211i=\n.\n2\ni=1\nLikewise,wecanwriteapolynomial f(n)ofdegreedwithcoefficientsa ,...,a as\n0 d\nd\nf(n)= \u2211ani.\ni\ni=0\nThus, the summation notation gives us a shorthand way of expressing sums of in-\ncreasing termsthathavearegularstructure.\nThe Exponential Function\nAnotherfunctionusedintheanalysisofalgorithmsistheexponentialfunction,\nf(n)=bn,\nwherebisapositiveconstant, calledthebase,andtheargumentnistheexponent.\nThat is, function f(n) assigns to the input argument n the value obtained by mul-\ntiplying the base b by itself n times. As was the case with the logarithm function,\nthemostcommonbasefortheexponential function inalgorithm analysis isb=2.\nFor example, an integer word containing n bits can represent all the nonnegative\nintegers less than 2n. If we have a loop that starts by performing one operation\nandthendoubles thenumberofoperations performed witheach iteration, thenthe\nnumberofoperations performed inthenth iteration is2n.\nWe sometimes have other exponents besides n, however; hence, it is useful\nfor us to know a few handy rules for working with exponents. In particular, the\nfollowingexponentrulesarequitehelpful.\nProposition 4.4 (Exponent Rules): Givenpositiveintegersa,b,andc,wehave\n1. (ba)c=bac\n2. babc=ba+c\n3. ba/bc =ba\u2212c\nwww.it-ebooks.info\n162 Chapter4. AlgorithmAnalysis\nForexample,wehavethefollowing:\n256=162=(24)2=24\u00b72=28=256(Exponent Rule1)\n\u2022\n243=35=32+3=3233=9 27=243(ExponentRule2)\n\u2022 \u00b7\n16=1024/64=210/26 =210\u22126=24=16(Exponent Rule3)\n\u2022\nWe can extend the exponential function to exponents that are fractions or real\nnumbers and to negative exponents, as follows. Given a positive integer k, wede-\nfine b1/k to be kth root of b, that is, the number r such that rk =b. For example,\n251/2 =5, since 52 =25. Likewise, 271/3 =3 and 161/4 =2. This approach al-\nlows us to define any power whose exponent can be expressed as a fraction, for\nba/c =(ba)1/c, by Exponent Rule 1. For example, 93/2 =(93)1/2 =7291/2 =27.\nThus,ba/c isreallyjustthecth rootoftheintegralexponent ba.\nWecanfurtherextendtheexponentialfunctiontodefinebx foranyrealnumber\nx,bycomputingaseriesofnumbersoftheformba/c forfractions a/cthatgetpro-\ngressivelycloserandclosertox. Anyrealnumberxcanbeapproximatedarbitrarily\nclosely by a fraction a/c; hence, we can use the fraction a/c as the exponent of b\nto get arbitrarily close to bx. Forexample, the number 2\u03c0 is well defined. Finally,\ngivenanegativeexponentd,wedefinebd =1/b\u2212d,whichcorrespondstoapplying\nExponentRule3witha=0andc= d. Forexample,2\u22123=1/23=1/8.\n\u2212\nGeometric Sums\nSupposewehavealoopforwhicheachiterationtakesamultiplicativefactorlonger\nthantheprevious one. Thisloopcanbeanalyzed usingthefollowingproposition.\nProposition 4.5: Foranyintegern 0andanyrealnumberasuchthata>0and\n\u2265\na=1,considerthesummation\n6\nn\n\u2211ai=1+a+a2+ +an\n\u00b7\u00b7\u00b7\ni=0\n(rememberingthata0=1ifa>0).Thissummationisequalto\nan+1 1\n\u2212 .\na 1\n\u2212\nSummationsasshowninProposition4.5arecalledgeometricsummations,be-\ncauseeachtermisgeometricallylargerthanthepreviousoneifa>1. Forexample,\neveryoneworkingincomputingshouldknowthat\n1+2+4+8+ +2n\u22121=2n 1,\n\u00b7\u00b7\u00b7 \u2212\nfor this is the largest unsigned integer that can be represented in binary notation\nusingnbits.\nwww.it-ebooks.info\n4.2. TheSevenFunctionsUsedinThisBook 163\n4.2.1 Comparing Growth Rates\nTosumup,Table4.2shows,inorder, eachofthesevencommonfunctions usedin\nalgorithm analysis.\nconstant logarithm linear n-log-n quadratic cubic exponential\n1 logn n nlogn n2 n3 an\nTable4.2: Sevenfunctions commonlyusedintheanalysisofalgorithms. Werecall\nthatlogn=log n. Also,wedenotewithaaconstant greaterthan1.\n2\nIdeally, we would like data structure operations to run in times proportional\nto the constant or logarithm function, and we would like our algorithms to run in\nlinear or n-log-n time. Algorithms with quadratic or cubic running times are less\npractical, and algorithms with exponential running times are infeasible for all but\nthesmallestsizedinputs. Plotsofthesevenfunctions areshowninFigure4.4.\n)n(f\n1044 Exponential\n1040\nCubic\n1036\nQuadratic\n1032\n1028 N-Log-N\n1024 Linear\n1020\nLogarithmic\n1016\n1012 Constant\n108\n104\n100\n100 101 102 103 104 105 106 107 108 109 1010 1011 1012 1013 1014 1015\nn\nFigure 4.4: Growth rates for the seven fundamental functions used in algorithm\nanalysis. Weusebasea=2fortheexponential function. Thefunctionsareplotted\non a log-log chart to compare the growth rates primarily as slopes. Even so, the\nexponential functiongrowstoofasttodisplay allitsvaluesonthechart.\nThe Ceiling and Floor Functions\nWhen discussing logarithms, we noted that the value is generally not an integer,\nyet the running time of an algorithm is usually expressed by means of an integer\nquantity, such as the number of operations performed. Thus, theanalysis of anal-\ngorithmmaysometimesinvolvetheuseofthefloorfunctionandceilingfunction,\nwhicharedefinedrespectively asfollows:\nx =thelargestintegerlessthanorequaltox. (e.g., 3.7 =3.)\n\u2022 \u230a \u230b \u230a \u230b\nx =thesmallestintegergreaterthanorequaltox. (e.g., 5.2 =6.)\n\u2022 \u2308 \u2309 \u2308 \u2309\nwww.it-ebooks.info\n164 Chapter4. AlgorithmAnalysis\n4.3 Asymptotic Analysis\nInalgorithmanalysis,wefocusonthegrowthrateoftherunningtimeasafunction\noftheinputsizen,takinga\u201cbig-picture\u201dapproach. Forexample,itisoftenenough\njusttoknowthattherunningtimeofanalgorithm growsproportionally ton.\nWe analyze algorithms using a mathematical notation for functions that disre-\ngards constant factors. Namely, we characterize the running times of algorithms\nby using functions that map the size of the input, n, to values that correspond to\nthe main factor that determines the growth rate in terms of n. This approach re-\nflects that each basic step in a pseudocode description or a high-level language\nimplementation may correspond to a small number of primitive operations. Thus,\nwecan perform ananalysis ofanalgorithm byestimating thenumber ofprimitive\noperations executed up to a constant factor, rather than getting bogged down in\nlanguage-specific or hardware-specific analysis of the exact number of operations\nthatexecuteonthecomputer.\n4.3.1 The \u201cBig-Oh\u201d Notation\nLet f(n)andg(n)befunctions mappingpositive integerstopositive realnumbers.\nWesaythat f(n)isO(g(n))ifthereisarealconstantc>0andanintegerconstant\nn 1suchthat\n0\n\u2265\nf(n) c g(n), for n n .\n0\n\u2264 \u00b7 \u2265\nThisdefinitionisoftenreferredtoasthe\u201cbig-Oh\u201dnotation,foritissometimespro-\nnounced as\u201cf(n)isbig-Ohofg(n).\u201d Figure4.5illustrates thegeneraldefinition.\nInput Size\nemiT\ngninnuR\ncg(n)\nf(n)\nn\n0\nFigure4.5: Illustrating the \u201cbig-Oh\u201d notation. Thefunction f(n) isO(g(n)), since\nf(n) c g(n)whenn n .\n0\n\u2264 \u00b7 \u2265\nwww.it-ebooks.info\n4.3. AsymptoticAnalysis 165\nExample 4.6: Thefunction8n+5isO(n).\nJustification: Bythebig-Ohdefinition,weneedtofindarealconstantc>0and\nanintegerconstantn 1suchthat8n+5 cnforeveryintegern n . Itiseasy\n0 0\n\u2265 \u2264 \u2265\nto see that a possible choice is c=9 and n =5. Indeed, this is one of infinitely\n0\nmanychoicesavailablebecausethereisatrade-offbetweencandn . Forexample,\n0\nwecouldrelyonconstants c=13andn =1.\n0\nThebig-Ohnotation allowsustosaythatafunction f(n)is\u201clessthanorequal\nto\u201d another function g(n) up to a constant factor and in the asymptotic sense as n\ngrowstowardinfinity. Thisabilitycomesfromthefactthatthedefinitionuses\u201c \u201d\n\u2264\ntocompare f(n)toag(n)timesaconstant,c,fortheasymptoticcaseswhenn n .\n0\n\u2265\nHowever, it is considered poor taste to say \u201cf(n) O(g(n)),\u201d since the big-Oh\n\u2264\nalready denotes the \u201cless-than-or-equal-to\u201d concept. Likewise, although common,\nitisnotfully correct tosay \u201cf(n)=O(g(n)),\u201d withthe usual understanding ofthe\n\u201c=\u201d relation, because there is no way to make sense of the symmetric statement,\n\u201cO(g(n))= f(n).\u201d Itisbesttosay,\u201cf(n)isO(g(n)).\u201d\nAlternatively, wecansay\u201cf(n)isorderofg(n).\u201d Forthemoremathematically\ninclined,itisalsocorrecttosay,\u201cf(n) O(g(n)),\u201dforthebig-Ohnotation, techni-\n\u2208\ncallyspeaking, denotes awholecollection offunctions. Inthisbook, wewillstick\ntopresentingbig-Ohstatementsas\u201cf(n)isO(g(n)).\u201d Evenwiththisinterpretation,\nthereisconsiderablefreedominhowwecanusearithmeticoperationswiththebig-\nOhnotation, andwiththisfreedomcomesacertain amountofresponsibility.\nSome Properties of the Big-Oh Notation\nThebig-Ohnotationallowsustoignoreconstantfactorsandlower-ordertermsand\nfocusonthemaincomponents ofafunction thataffectitsgrowth.\nExample 4.7: 5n4+3n3+2n2+4n+1isO(n4).\nJustification: Notethat5n4+3n3+2n2+4n+1 (5+3+2+4+1)n4=cn4,\n\u2264\nforc=15,whenn n =1.\n0\n\u2265\nInfact,wecancharacterize thegrowthrateofanypolynomial function.\nProposition 4.8: If f(n)isapolynomialofdegreed,thatis,\nf(n)=a +a n+ +a nd,\n0 1 d\n\u00b7\u00b7\u00b7\nanda >0,then f(n)isO(nd).\nd\nJustification: Notethat,forn 1,wehave1 n n2 nd;hence,\n\u2265 \u2264 \u2264 \u2264\u00b7\u00b7\u00b7\u2264\na +a n+a n2+ +a nd (a + a + a + + a )nd.\n0 1 2 d 0 1 2 d\n\u00b7\u00b7\u00b7 \u2264 | | | | | | \u00b7\u00b7\u00b7 | |\nWeshowthat f(n)isO(nd)bydefiningc= a + a + + a andn =1.\n0 1 d 0\n| | | | \u00b7\u00b7\u00b7 | |\nwww.it-ebooks.info\n166 Chapter4. AlgorithmAnalysis\nThus, the highest-degree term in a polynomial is the term that determines the\nasymptoticgrowthrateofthatpolynomial. Weconsidersomeadditionalproperties\nofthebig-Ohnotationintheexercises. Letusconsidersomefurtherexampleshere,\nfocusing on combinations of the seven fundamental functions used in algorithm\ndesign. Werelyonthemathematical factthatlogn nforn 1.\n\u2264 \u2265\nExample 4.9: 5n2+3nlogn+2n+5isO(n2).\nJustification: 5n2+3nlogn+2n+5 (5+3+2+5)n2=cn2,forc=15,when\n\u2264\nn n =1.\n0\n\u2265\nExample 4.10: 20n3+10nlogn+5isO(n3).\nJustification: 20n3+10nlogn+5 35n3,forn 1.\n\u2264 \u2265\nExample 4.11: 3logn+2isO(logn).\nJustification: 3logn+2 5logn, for n 2. Note that logn is zero for n=1.\n\u2264 \u2265\nThatiswhyweusen n =2inthiscase.\n0\n\u2265\nExample 4.12: 2n+2isO(2n).\nJustification: 2n+2=2n 22=4 2n;hence,wecantakec=4andn =1inthis\n0\n\u00b7 \u00b7\ncase.\nExample 4.13: 2n+100lognisO(n).\nJustification: 2n+100logn 102n,forn n =1;hence,wecantakec=102\n0\n\u2264 \u2265\ninthiscase.\nCharacterizing Functions in Simplest Terms\nIngeneral, weshould use thebig-Ohnotation tocharacterize afunction asclosely\nas possible. While it is true that the function f(n)=4n3+3n2 is O(n5) or even\nO(n4), itis more accurate to say that f(n) is O(n3). Consider, by wayof analogy,\nascenariowhereahungrytravelerdrivingalongalongcountryroadhappensupon\na local farmer walking home from a market. If the traveler asks the farmer how\nmuchlonger hemustdrivebeforehecanfindsomefood, itmaybetruthful forthe\nfarmer to say, \u201ccertainly no longer than 12 hours,\u201d but it is much more accurate\n(andhelpful)forhimtosay,\u201cyoucanfindamarketjustafewminutesdriveupthis\nroad.\u201d Thus, even with the big-Oh notation, we should strive as much as possible\ntotellthewholetruth.\nItisalsoconsideredpoortastetoincludeconstantfactorsandlower-orderterms\nin the big-Oh notation. For example, it is not fashionable to say that the function\n2n2 is O(4n2+6nlogn), although this is completely correct. We should strive\ninsteadtodescribethefunction inthebig-Ohinsimplestterms.\nwww.it-ebooks.info\n4.3. AsymptoticAnalysis 167\nTheseven functions listed in Section 4.2 are the most common functions used\ninconjunctionwiththebig-Ohnotationtocharacterizetherunningtimesandspace\nusageofalgorithms. Indeed, wetypically usethenamesofthesefunctions torefer\ntotherunningtimesofthealgorithmstheycharacterize. So,forexample,wewould\nsaythatanalgorithm that runsinworst-case time4n2+nlognisaquadratic-time\nalgorithm, since it runs in O(n2) time. Likewise, an algorithm running in time at\nmost5n+20logn+4wouldbecalledalinear-timealgorithm.\nBig-Omega\nJustasthebig-Ohnotation providesanasymptotic wayofsayingthatafunctionis\n\u201clessthanorequalto\u201danotherfunction, thefollowingnotationsprovideanasymp-\ntoticwayofsaying thatafunction growsataratethatis\u201cgreater thanorequal to\u201d\nthatofanother.\nLet f(n)andg(n)befunctions mappingpositive integers topositiverealnum-\nbers. Wesaythat f(n)is\u2126(g(n)),pronounced\u201cf(n)isbig-Omegaofg(n),\u201difg(n)\nisO(f(n)),thatis,thereisarealconstantc>0andanintegerconstantn 1such\n0\n\u2265\nthat\nf(n) cg(n), for n n .\n0\n\u2265 \u2265\nThis definition allows us to say asymptotically that one function is greater than or\nequaltoanother, uptoaconstantfactor.\nExample 4.14: 3nlogn 2nis\u2126(nlogn).\n\u2212\nJustification: 3nlogn 2n=nlogn+2n(logn 1) nlogn for n 2; hence,\n\u2212 \u2212 \u2265 \u2265\nwecantakec=1andn =2inthiscase.\n0\nBig-Theta\nIn addition, there is a notation that allows us to say that two functions grow at the\nsame rate, up to constant factors. We say that f(n) is \u0398(g(n)), pronounced \u201cf(n)\nisbig-Theta ofg(n),\u201dif f(n)isO(g(n))and f(n)is\u2126(g(n)), thatis,therearereal\nconstants c\u2032>0andc\u2032\u2032>0,andanintegerconstant n 1suchthat\n0\n\u2265\nc\u2032g(n) f(n) c\u2032\u2032g(n), for n n .\n0\n\u2264 \u2264 \u2265\nExample 4.15: 3nlogn+4n+5lognis\u0398(nlogn).\nJustification: 3nlogn 3nlogn+4n+5logn (3+4+5)nlognforn 2.\n\u2264 \u2264 \u2265\nwww.it-ebooks.info\n168 Chapter4. AlgorithmAnalysis\n4.3.2 Comparative Analysis\nThebig-Ohnotationiswidelyusedtocharacterizerunningtimesandspacebounds\nin terms of some parameter n, which is defined as a chosen measure of the \u201csize\u201d\nof the problem. Suppose two algorithms solving the same problem are available:\nanalgorithmA,whichhasarunningtimeofO(n),andanalgorithmB,whichhasa\nrunningtimeofO(n2). Whichalgorithmisbetter? WeknowthatnisO(n2),which\nimplies that algorithm A is asymptotically better than algorithm B, although for a\nsmallvalueofn,BmayhavealowerrunningtimethanA.\nWe can use the big-Oh notation to order classes of functions by asymptotic\ngrowth rate. Our seven functions are ordered by increasing growth rate in the fol-\nlowingsequence,suchthat f(n)isO(g(n))iffunction f(n)precedesfunctiong(n):\n1, logn, n, nlogn, n2, n3, 2n.\nWe illustrate the growth rates of the seven functions in Table 4.3. (See also\nFigure4.4fromSection4.2.1.)\nn logn n nlogn n2 n3 2n\n8 3 8 24 64 512 256\n16 4 16 64 256 4,096 65,536\n32 5 32 160 1,024 32,768 4,294,967,296\n64 6 64 384 4,096 262,144 1.84\u00d71019\n128 7 128 896 16,384 2,097,152 3.40\u00d71038\n256 8 256 2,048 65,536 16,777,216 1.15\u00d71077\n512 9 512 4,608 262,144 134,217,728 1.34\u00d710154\nTable4.3: Selectedvaluesoffundamental functions inalgorithm analysis.\nWe further illustrate the importance of the asymptotic viewpoint in Table 4.4.\nThis table explores the maximum size allowed for an input instance that is pro-\ncessed byanalgorithm in1second, 1minute, and1hour. Itshowstheimportance\nof good algorithm design, because an asymptotically slow algorithm is beaten in\nthe long run by an asymptotically faster algorithm, even if the constant factor for\ntheasymptotically fasteralgorithm isworse.\nRunning MaximumProblemSize(n)\nTime(\u00b5s) 1second 1minute 1hour\n400n 2,500 150,000 9,000,000\n2n2 707 5,477 42,426\n2n 19 25 31\nTable 4.4: Maximum size of a problem that can be solved in 1 second, 1 minute,\nand1hour, forvariousrunning timesmeasuredinmicroseconds.\nwww.it-ebooks.info\n4.3. AsymptoticAnalysis 169\nTheimportance ofgoodalgorithm designgoesbeyondjustwhatcanbesolved\neffectively on a given computer, however. As shown in Table 4.5, even if we\nachieve a dramatic speedup in hardware, we still cannot overcome the handicap\nofanasymptotically slowalgorithm. Thistableshowsthenewmaximumproblem\nsize achievable for any fixed amount of time, assuming algorithms with the given\nrunning timesarenowrunonacomputer256timesfasterthantheprevious one.\nRunningTime NewMaximumProblemSize\n400n 256m\n2n2 16m\n2n m+8\nTable4.5: Increase inthemaximum sizeofaproblem thatcanbesolved inafixed\namountoftime,byusingacomputerthatis256timesfasterthanthepreviousone.\nEachentryisafunction ofm,thepreviousmaximumproblemsize.\nSome Words of Caution\nA few words of caution about asymptotic notation are in order at this point. First,\nnote that the use of the big-Oh and related notations can be somewhat misleading\nshould theconstant factors they\u201chide\u201d bevery large. Forexample, whileitistrue\nthat the function 10100n is O(n), if this is the running time of an algorithm being\ncompared toonewhose running timeis10nlogn, weshould prefer theO(nlogn)-\ntimealgorithm,eventhoughthelinear-timealgorithmisasymptoticallyfaster. This\npreference is because the constant factor, 10100, which is called \u201cone googol,\u201d is\nbelievedbymanyastronomerstobeanupperboundonthenumberofatomsinthe\nobservable universe. Soweareunlikelytoeverhaveareal-worldproblem thathas\nthisnumberasitsinputsize.\nThe observation above raises the issue of what constitutes a \u201cfast\u201d algorithm.\nGenerally speaking, any algorithm running in O(nlogn) time (with a reasonable\nconstant factor) should be considered efficient. Even an O(n2)-time function may\nbe fast enough in some contexts, that is, whenn issmall. But analgorithm whose\nrunning time is an exponential function, e.g., O(2n), should almost never be con-\nsideredefficient.\nExponential Running Times\nToseehowfastthefunction2n grows,considerthefamousstoryabouttheinventor\nof the game of chess. He asked only that his king pay him 1 grain of rice for the\nfirst square on the board, 2 grains for the second, 4 grains for the third, 8 for the\nfourth, andsoon. Thenumberofgrainsinthe64thsquarewouldbe\n263=9,223,372,036,854,775,808,\nwhichisaboutninebillionbillions!\nwww.it-ebooks.info\n170 Chapter4. AlgorithmAnalysis\nIf we must draw a line between efficient and inefficient algorithms, therefore,\nit is natural to make this distinction be that between those algorithms running in\npolynomial time and those running inexponential time. Thatis, make the distinc-\ntionbetweenalgorithmswitharunningtimethatisO(nc),forsomeconstantc>1,\nandthosewitharunningtimethatisO(bn),forsomeconstantb>1. Likesomany\nnotions wehavediscussed inthissection, thistooshould betakenwitha\u201cgrainof\nsalt,\u201d for an algorithm running in O(n100) time should probably not be considered\n\u201cefficient.\u201d Evenso,thedistinctionbetweenpolynomial-timeandexponential-time\nalgorithms isconsidered arobustmeasureoftractability.\n4.3.3 Examples of Algorithm Analysis\nNow that we have the big-Oh notation for doing algorithm analysis, let us give\nsomeexamplesbycharacterizingtherunningtimeofsomesimplealgorithmsusing\nthis notation. Moreover, in keeping with our earlier promise, we will illustrate\nbelow how each of the seven functions given earlier in this chapter can be used to\ncharacterize therunningtimeofanexamplealgorithm.\nConstant-Time Operations\nAll of the primitive operations, originally described on page 154, are assumed to\nrun in constant time; formally, we say they run in O(1) time. We wish to empha-\nsize several important constant-time operations that involve arrays. Assume that\nvariable A is an array of n elements. The expression A.length in Java is evaluated\ninconstanttime,becausearraysarerepresented internally withanexplicitvariable\nthat records the length of the array. Another central behavior of arrays is that for\nany valid index j, the individual element, A[j], can be accessed in constant time.\nThisisbecause anarrayusesaconsecutive block ofmemory. The jth elementcan\nbefound,notbyiteratingthroughthearrayoneelementatatime,butbyvalidating\nthe index, and using it as an offset from the beginning of the array in determin-\ning the appropriate memory address. Therefore, wesay that the expression A[j]is\nevaluated inO(1)timeforanarray.\nFinding the Maximum of an Array\nAs a classic example of an algorithm with a running time that grows proportional\nto n, we consider the goal of finding the largest element of an array. A typical\nstrategy is to loop through elements of the array while maintaining as a variable\nthe largest element seen thus far. Code Fragment 4.3 presents a method named\narrayMaximplementing thisstrategy.\nwww.it-ebooks.info\n4.3. AsymptoticAnalysis 171\n1 /\u2217\u2217 Returns the maximum value of a nonempty array of numbers. \u2217/\n2 public static double arrayMax(double[ ] data)\n{\n3 int n = data.length;\n4 double currentMax = data[0]; // assume first entry is biggest (for now)\n5 for (int j=1; j < n; j++) // consider all other entries\n6 if (data[j] > currentMax) // if data[j] is biggest thus far...\n7 currentMax = data[j]; // record it as the current max\n8 return currentMax;\n9\n}\nCodeFragment4.3: Amethodthatreturnsthemaximumvalueofanarray.\nUsing the big-Oh notation, wecan write the following mathematically precise\nstatementontherunningtimeofalgorithm arrayMaxforanycomputer.\nProposition 4.16: Thealgorithm, arrayMax,forcomputingthemaximumele-\nmentofanarrayofnnumbers,runsinO(n)time.\nJustification: Theinitializationatlines3and4andthereturnstatementatline8\nrequire only a constant number of primitive operations. Each iteration of the loop\nalsorequiresonlyaconstantnumberofprimitiveoperations, andtheloopexecutes\nn 1 times. Therefore, we account for the number of primitive operations being\n\u2212\nc\u2032 (n 1)+c\u2032\u2032 forappropriateconstantsc\u2032andc\u2032\u2032thatreflect,respectively,thework\n\u00b7 \u2212\nperformedinsideandoutsidetheloopbody. Becauseeachprimitiveoperationruns\ninconstant time,wehavethattherunning timeofalgorithm arrayMaxonaninput\nofsizenisatmostc\u2032 (n 1)+c\u2032\u2032=c\u2032 n+(c\u2032\u2032 c\u2032) c\u2032 nifweassume,without\n\u00b7 \u2212 \u00b7 \u2212 \u2264 \u00b7\nloss of generality, that c\u2032\u2032 c\u2032. We conclude that the running time of algorithm\n\u2264\narrayMaxisO(n).\nFurther Analysis of the Maximum-Finding Algorithm\nA more interesting question about arrayMax is how many times we might update\nthecurrent\u201cbiggest\u201dvalue. Intheworstcase,ifthedataisgiventousinincreasing\norder, the biggest value is reassigned n 1 times. But what if the input is given\n\u2212\nto us in random order, with all orders equally likely; what would be the expected\nnumberoftimesweupdatethebiggestvalueinthiscase? Toanswerthisquestion,\nnotethatweupdatethecurrentbiggestinaniterationofthelooponlyifthecurrent\nelement is bigger than all the elements that precede it. If the sequence is given to\nus in random order, the probability that the jth element is the largest of the first j\nelements is 1/j (assuming uniqueness). Hence, the expected number of times we\nupdate the biggest (including initialization) is H =\u2211n 1/j, which is known as\nn j=1\nthe nth Harmonic number. It can be shown that H is O(logn). Therefore, the\nn\nexpectednumberoftimesthebiggestvalueisupdatedbyarrayMaxonarandomly\norderedsequence isO(logn).\nwww.it-ebooks.info\n172 Chapter4. AlgorithmAnalysis\nComposing Long Strings\nAsournextexample, werevisittheexperimental studyfromSection4.1,inwhich\nweexaminedtwodifferentimplementationsforcomposingalongstring(seeCode\nFragment4.2). Ourfirstalgorithmwasbasedonrepeateduseofthestringconcate-\nnationoperator; forconvenience, thatmethodisalsogiveninCodeFragment4.4.\n1 /\u2217\u2217 Uses repeated concatenation to compose a String with n copies of character c. \u2217/\n2 public static String repeat1(char c, int n)\n{\n3 String answer = \"\";\n4 for (int j=0; j < n; j++)\n5 answer += c;\n6 return answer;\n7\n}\nCodeFragment4.4: Composingastringusingrepeated concatenation.\nThe most important aspect of this implementation is that strings in Java are\nimmutable objects. Once created, aninstance cannot bemodified. Thecommand,\nanswer += c, is shorthand for answer = (answer + c). This command does not\ncauseanewcharactertobeaddedtotheexistingStringinstance;insteaditproduces\na new String with the desired sequence of characters, and then it reassigns the\nvariable, answer,torefertothatnewstring.\nIn terms of efficiency, the problem with this interpretation is that the creation\nof a new string as a result of a concatenation, requires time that is proportional\nto the length of the resulting string. The first time through this loop, the result\nhas length 1, the second time through the loop the result has length 2, and so on,\nuntilwereach thefinalstring oflengthn. Therefore, theoveralltimetakenbythis\nalgorithm isproportional to\n1+2+ +n,\n\u00b7\u00b7\u00b7\nwhichwerecognizeasthefamiliarO(n2)summationfromProposition4.3. There-\nfore,thetotaltimecomplexity oftherepeat1algorithm isO(n2).\nWe see this theoretical analysis reflected in the experimental results. The run-\nning timeofaquadratic algorithm should theoretically quadruple ifthe sizeofthe\nproblem doubles, as (2n) 2 =4 n2. (We say \u201ctheoretically,\u201d because this does not\n\u00b7\naccount for lower-order terms thatare hidden bythe asymptotic notation.) Wesee\nsuch an approximate fourfold increase in the running time of repeat1in Table 4.1\nonpage152.\nIncontrast,therunningtimesinthattablefortherepeat2algorithm,whichuses\nJava\u2019s StringBuilder class, demonstrate a trend of approximately doubling each\ntimetheproblemsizedoubles. TheStringBuilderclassreliesonanadvancedtech-\nnique with a worst-case running time of O(n) for composing a string of length n;\nwewilllaterexplorethattechnique asthefocusofSection7.2.1.\nwww.it-ebooks.info\n4.3. AsymptoticAnalysis 173\nThree-Way Set Disjointness\nSupposewearegiventhreesets,A,B,andC,storedinthreedifferentintegerarrays.\nWewillassumethatnoindividual setcontains duplicate values, butthattheremay\nbesomenumbersthatareintwoorthreeofthesets. Thethree-waysetdisjointness\nproblem is to determine if the intersection of the three sets is empty, namely, that\nthere is no element x such that x A, x B, and x C. A simple Java method to\n\u2208 \u2208 \u2208\ndeterminethisproperty isgiveninCodeFragment4.5.\n1 /\u2217\u2217 Returns true if there is no element common to all three arrays. \u2217/\n2 public static boolean disjoint1(int[ ] groupA, int[ ] groupB, int[ ] groupC)\n{\n3 for (int a : groupA)\n4 for (int b : groupB)\n5 for (int c : groupC)\n6 if ((a == b) && (b == c))\n7 return false; // we found a common value\n8 return true; // if we reach this, sets are disjoint\n9\n}\nCodeFragment4.5: Algorithm disjoint1fortesting three-waysetdisjointness.\nThis simple algorithm loops through each possible triple of values from the\nthree sets tosee if those values are equivalent. If each of the original sets has size\nn,thentheworst-case runningtimeofthismethodisO(n3).\nWe can improve upon the asymptotic performance with a simple observation.\nOnceinsidethebodyoftheloopoverB,ifselected elementsaandbdonotmatch\neach other, it is a waste of time to iterate through all values of C looking for a\nmatching triple. An improved solution to this problem, taking advantage of this\nobservation, ispresented inCodeFragment4.6.\n1 /\u2217\u2217 Returns true if there is no element common to all three arrays. \u2217/\n2 public static boolean disjoint2(int[ ] groupA, int[ ] groupB, int[ ] groupC)\n{\n3 for (int a : groupA)\n4 for (int b : groupB)\n5 if (a == b) // only check C when we find match from A and B\n6 for (int c : groupC)\n7 if (a == c) // and thus b == c as well\n8 return false; // we found a common value\n9 return true; // if we reach this, sets are disjoint\n10\n}\nCodeFragment4.6: Algorithm disjoint2fortesting three-waysetdisjointness.\nIntheimprovedversion, itisnotsimplythat wesavetimeifwegetlucky. We\nclaim that the worst-case running time for disjoint2 is O(n2). There are quadrat-\nically many pairs (a,b) to consider. However, if A and B are each sets of distinct\nwww.it-ebooks.info\n174 Chapter4. AlgorithmAnalysis\nelements, there can be at most O(n) such pairs with a equal to b. Therefore, the\ninnermostloop,overC,executesatmostntimes.\nTo account for the overall running time, we examine the time spent executing\neachlineofcode. Themanagement oftheforloopoverArequires O(n)time. The\nmanagement of the for loop over B accounts for a total of O(n2) time, since that\nloop isexecuted ndifferent times. Thetest a == bis evaluated O(n2)times. The\nrest of the time spent depends upon how many matching (a,b) pairs exist. As we\nhave noted, there are at most n such pairs; therefore, the management of the loop\noverC andthecommandswithinthebodyofthatloopuseatmostO(n2)time. By\nourstandard application ofProposition 4.8,thetotaltimespentisO(n2).\nElement Uniqueness\nA problem that is closely related to the three-way set disjointness problem is the\nelement uniqueness problem. In the former, we are given three sets and we pre-\nsumedthatthere werenoduplicates withinasingle set. Intheelement uniqueness\nproblem, wearegivenanarray withnelements andasked whether allelements of\nthatcollection aredistinct fromeachother.\nOur first solution to this problem uses a straightforward iterative algorithm.\nThe unique1 method, given in Code Fragment 4.7, solves the element uniqueness\nproblem by looping through all distinct pairs of indices j<k, checking if any of\nthosepairsrefertoelementsthatareequivalenttoeachother. Itdoesthisusingtwo\nnestedforloops,suchthatthefirstiterationoftheouterloopcausesn 1iterations\n\u2212\nof the inner loop, the second iteration of the outer loop causes n 2 iterations of\n\u2212\nthe inner loop, and so on. Thus, the worst-case running time of this method is\nproportional to\n(n 1)+(n 2)+ +2+1,\n\u2212 \u2212 \u00b7\u00b7\u00b7\nwhichwerecognize asthefamiliarO(n2)summationfromProposition 4.3.\n1 /\u2217\u2217 Returns true if there are no duplicate elements in the array. \u2217/\n2 public static boolean unique1(int[ ] data)\n{\n3 int n = data.length;\n4 for (int j=0; j < n 1; j++)\n\u2212\n5 for (int k=j+1; k < n; k++)\n6 if (data[j] == data[k])\n7 return false; // found duplicate pair\n8 return true; // if we reach this, elements are unique\n9\n}\nCodeFragment4.7: Algorithmunique1fortestingelementuniqueness.\nwww.it-ebooks.info\n4.3. AsymptoticAnalysis 175\nUsing Sorting as a Problem-Solving Tool\nAn even better algorithm for the element uniqueness problem is based on using\nsortingasaproblem-solving tool. Inthiscase,bysortingthearrayofelements,we\nareguaranteed thatanyduplicate elementswillbeplacednexttoeachother. Thus,\nto determine ifthere are any duplicates, all weneed todo isperform asingle pass\noverthesortedarray, lookingforconsecutive duplicates.\nA Java implementation of this algorithm is given in Code Fragment 4.8. (See\nSection3.1.3fordiscussion ofthejava.util.Arraysclass.)\n1 /\u2217\u2217 Returns true if there are no duplicate elements in the array. \u2217/\n2 public static boolean unique2(int[ ] data)\n{\n3 int n = data.length;\n4 int[ ] temp = Arrays.copyOf(data, n); // make copy of data\n5 Arrays.sort(temp); // and sort the copy\n6 for (int j=0; j < n 1; j++)\n\u2212\n7 if (temp[j] == temp[j+1]) // check neighboring entries\n8 return false; // found duplicate pair\n9 return true; // if we reach this, elements are unique\n10\n}\nCodeFragment4.8: Algorithmunique2fortestingelementuniqueness.\nSortingalgorithmswillbethefocusofChapter12. Thebestsortingalgorithms\n(includingthoseusedbyArray.sortinJava)guaranteeaworst-caserunningtimeof\nO(nlogn). Once the data is sorted, the subsequent loop runs in O(n) time, and so\nthe entire unique2algorithm runs inO(nlogn)time. Exercise C-4.35 explores the\nuseofsorting tosolvethethree-waysetdisjointness problem inO(nlogn)time.\nPrefix Averages\nThenextproblem weconsider iscomputing whatareknownasprefixaverages of\na sequence of numbers. Namely, given a sequence x consisting of n numbers, we\nwanttocomputeasequence asuchthata istheaverageofelementsx ,...,x ,for\nj 0 j\nj=0,...,n 1,thatis,\n\u2212 \u2211j x\na = i=0 i .\nj\nj+1\nPrefix averages have many applications in economics and statistics. For example,\ngiven the year-by-year returns of a mutual fund, ordered from recent to past, an\ninvestor will typically want to see the fund\u2019s average annual returns for the most\nrecentyear,themostrecentthreeyears,themostrecentfiveyears,andsoon. Like-\nwise,givenastreamofdailyWebusagelogs,awebsitemanagermaywishtotrack\naverage usage trends over various time periods. We present two implementation\nforcomputingprefixaverages, yetwithsignificantly differentrunning times.\nwww.it-ebooks.info\n176 Chapter4. AlgorithmAnalysis\nA Quadratic-Time Algorithm\nOur first algorithm for computing prefix averages, denoted as prefixAverage1, is\nshowninCodeFragment4.9. Itcomputeseachelementa independently, usingan\nj\ninnerlooptocomputethatpartialsum.\n1 /\u2217\u2217 Returns an array a such that, for all j, a[j] equals the average of x[0], ..., x[j]. \u2217/\n2 public static double[ ] prefixAverage1(double[ ] x)\n{\n3 int n = x.length;\n4 double[ ] a = new double[n]; // filled with zeros by default\n5 for (int j=0; j < n; j++)\n{\n6 double total = 0; // begin computing x[0] + ... + x[j]\n7 for (int i=0; i <= j; i++)\n8 total += x[i];\n9 a[j] = total / (j+1); // record the average\n10\n}\n11 return a;\n12\n}\nCodeFragment4.9: Algorithm prefixAverage1.\nLetusanalyzetheprefixAverage1algorithm.\nTheinitialization ofn = x.lengthatline3andtheeventualreturnofarefer-\n\u2022\nencetoarrayaatline11bothexecuteinO(1)time.\nCreating andinitializing thenewarray, a,atline4canbedonewithinO(n)\n\u2022\ntime,usingaconstant numberofprimitiveoperations perelement.\nThere are twonested forloops, which are controlled, respectively, by coun-\n\u2022\nters j and i. The body of the outer loop, controlled by counter j, is ex-\necuted n times, for j = 0,...,n 1. Therefore, statements total = 0 and\n\u2212\na[j] = total / (j+1) are executed n times each. This implies that these two\nstatements, plusthemanagement ofcounter j intheloop, contribute anum-\nberofprimitiveoperations proportional ton,thatis,O(n)time.\nThebodyoftheinnerloop,whichiscontrolledbycounteri,isexecuted j+1\n\u2022\ntimes,dependingonthecurrentvalueoftheouterloopcounter j. Thus,state-\nment total += x[i], in the inner loop, is executed 1+2+3+ +n times.\n\u00b7\u00b7\u00b7\nByrecalling Proposition 4.3,weknowthat1+2+3+ +n=n(n+1)/2,\n\u00b7\u00b7\u00b7\nwhich implies that the statement in the inner loop contributes O(n2) time.\nAsimilarargument canbedone fortheprimitive operations associated with\nmaintaining counter i,whichalsotakeO(n2)time.\nThe running time of implementation prefixAverage1 is given by the sum of these\nterms. The first term is O(1), the second and third terms are O(n), and the fourth\nterm is O(n2). By a simple application of Proposition 4.8, the running time of\nprefixAverage1isO(n2).\nwww.it-ebooks.info\n4.3. AsymptoticAnalysis 177\nA Linear-Time Algorithm\nAn intermediate value in the computation of the prefix average is the prefix sum\nx +x + +x , denoted as total in our first implementation; this allows us to\n0 1 j\n\u00b7\u00b7\u00b7\ncomputetheprefixaveragea[j] = total / (j + 1). Inourfirstalgorithm,theprefix\nsum iscomputed anew foreach value of j. Thatcontributed O(j)timefor each j,\nleadingtothequadratic behavior.\nFor greater efficiency, we can maintain the current prefix sum dynamically,\neffectively computing x +x + +x astotal+x ,wherevalue totalisequal to\n0 1 j j\n\u00b7\u00b7\u00b7\nthesumx +x + +x ,whencomputedbythepreviouspassoftheloopover j.\n0 1 j\u22121\n\u00b7\u00b7\u00b7\nCode Fragment 4.10 provides a new implementation, denoted as prefixAverage2,\nusingthisapproach.\n1 /\u2217\u2217 Returns an array a such that, for all j, a[j] equals the average of x[0], ..., x[j]. \u2217/\n2 public static double[ ] prefixAverage2(double[ ] x)\n{\n3 int n = x.length;\n4 double[ ] a = new double[n]; // filled with zeros by default\n5 double total = 0; // compute prefix sum as x[0] + x[1] + ...\n6 for (int j=0; j < n; j++)\n{\n7 total += x[j]; // update prefix sum to include x[j]\n8 a[j] = total / (j+1); // compute average based on current sum\n9\n}\n10 return a;\n11\n}\nCodeFragment4.10: AlgorithmprefixAverage2.\nTheanalysis oftherunning timeofalgorithm prefixAverage2follows:\nInitializing variables nandtotalusesO(1)time.\n\u2022\nInitializing thearrayausesO(n)time.\n\u2022\nThereisasingleforloop,whichiscontrolledbycounter j. Themaintenance\n\u2022\nofthatloopcontributes atotalofO(n)time.\nThe body of the loop is executed n times, for j=0,...,n 1. Thus, state-\n\u2022 \u2212\nments total += x[j] and a[j] = total / (j+1) are executed n times each.\nSince each of these statements uses O(1) time per iteration, their overall\ncontribution isO(n)time.\nTheeventualreturnofareference toarrayAusesO(1)time.\n\u2022\nTherunningtimeofalgorithmprefixAverage2isgivenbythesumofthefiveterms.\nThefirstand last areO(1)and the remaining three are O(n). Byasimple applica-\ntionofProposition4.8,therunningtimeofprefixAverage2isO(n),whichismuch\nbetterthanthequadratic timeofalgorithm prefixAverage1.\nwww.it-ebooks.info\n178 Chapter4. AlgorithmAnalysis\n4.4 Simple Justification Techniques\nSometimes,wewillwanttomakeclaimsaboutanalgorithm, suchasshowingthat\nit is correct or that it runs fast. In order to rigorously make such claims, we must\nusemathematicallanguage,andinordertobackupsuchclaims,wemustjustifyor\nproveourstatements. Fortunately, thereareseveralsimplewaystodothis.\n4.4.1 By Example\nSome claims are of the generic form, \u201cThere is an element x in a set S that has\nproperty P.\u201d To justify such a claim, we only need to produce a particular x in S\nthathaspropertyP. Likewise,somehard-to-believeclaimsareofthegenericform,\n\u201cEveryelementxinasetShaspropertyP.\u201d Tojustifythatsuchaclaimisfalse,we\nonly need to produce aparticular x from S that does not have property P. Such an\ninstance iscalledacounterexample.\nExample 4.17: ProfessorAmongusclaimsthateverynumberoftheform2i 1\n\u2212\nisaprime,wheniisanintegergreaterthan1.ProfessorAmongusiswrong.\nJustification: ToproveProfessorAmongusiswrong,wefindacounterexample.\nFortunately, weneednotlooktoofar,for24 1=15=3 5.\n\u2212 \u00b7\n4.4.2 The \u201cContra\u201d Attack\nAnother set of justification techniques involves the use of the negative. The two\nprimary such methods are the use of the contrapositive and the contradiction. To\njustify thestatement \u201cif pistrue, thenqistrue,\u201d weestablish that\u201cifqisnottrue,\nthen p is not true\u201d instead. Logically, these two statements are the same, but the\nlatter, whichiscalledthecontrapositive ofthefirst,maybeeasiertothinkabout.\nExample 4.18: Letaandbbeintegers.Ifabiseven,thenaisevenorbiseven.\nJustification: Tojustify thisclaim, consider thecontrapositive, \u201cIfaisoddand\nbisodd,thenabisodd.\u201d So,supposea=2j+1andb=2k+1,forsomeintegers\njandk. Thenab=4jk+2j+2k+1=2(2jk+ j+k)+1;hence,abisodd.\nBesidesshowingauseofthecontrapositivejustificationtechnique,theprevious\nexample also contains an application of de Morgan\u2019s law. This law helps us deal\nwithnegations, foritstates thatthe negation ofastatement oftheform \u201cporq\u201dis\n\u201cnot p and not q.\u201d Likewise, it states that the negation of a statement of the form\n\u201cpandq\u201dis\u201cnot pornotq.\u201d\nwww.it-ebooks.info\n4.4. SimpleJustificationTechniques 179\nContradiction\nAnother negative justification technique is justification by contradiction, which\nalso often involves using de Morgan\u2019s law. In applying the justification by con-\ntradiction technique, we establish that a statement q is true by first supposing that\nq is false and then showing that this assumption leads to a contradiction (such as\n2=2or1>3). Byreaching such acontradiction, weshow that noconsistent sit-\n6\nuationexistswithqbeingfalse, soqmustbetrue. Ofcourse, inordertoreachthis\nconclusion, wemustbesureoursituationisconsistentbeforeweassumeqisfalse.\nExample 4.19: Letaandbbeintegers.Ifabisodd,thenaisoddandbisodd.\nJustification: Let ab be odd. We wish to show that a is odd and b is odd. So,\nwith the hope of leading to a contradiction, let us assume the opposite, namely,\nsuppose a is even or b is even. In fact, without loss of generality, we can assume\nthat a is even (since the case for b is symmetric). Then a=2j for some integer\nj. Hence, ab=(2j)b=2(jb), that is, ab is even. But this is a contradiction: ab\ncannotsimultaneously beoddandeven. Therefore, aisoddandbisodd.\n4.4.3 Induction and Loop Invariants\nMostoftheclaimswemakeaboutarunningtimeoraspaceboundinvolveaninte-\ngerparametern(usually denotinganintuitivenotionofthe\u201csize\u201doftheproblem).\nMoreover,mostoftheseclaimsareequivalenttosayingsomestatementq(n)istrue\n\u201cfor all n 1.\u201d Since this is making a claim about an infinite set of numbers, we\n\u2265\ncannotjustifythisexhaustively inadirectfashion.\nInduction\nWe can often justify claims such as those above as true, however, by using the\ntechniqueofinduction. Thistechniqueamountstoshowingthat,foranyparticular\nn 1, there is a finite sequence of implications that starts with something known\n\u2265\ntobetrueandultimatelyleadstoshowingthatq(n)istrue. Specifically,webegina\njustificationbyinductionbyshowingthatq(n)istrueforn=1(andpossiblysome\nothervaluesn=2,3,...,k,forsomeconstantk). Thenwejustifythattheinductive\n\u201cstep\u201d istrueforn>k,namely, weshow \u201cifq(j)istrueforall j<n,then q(n)is\ntrue.\u201d Thecombinationofthesetwopiecescompletesthejustificationbyinduction.\nwww.it-ebooks.info\n180 Chapter4. AlgorithmAnalysis\nProposition 4.20: ConsidertheFibonaccifunctionF(n),whichisdefinedsuch\nthatF(1) =1,F(2) = 2,andF(n) = F(n 2)+F(n 1) forn > 2. (SeeSec-\n\u2212 \u2212\ntion2.2.3.)WeclaimthatF(n)<2n.\nJustification: Wewillshowourclaimiscorrectbyinduction.\nBasecases: (n 2). F(1)=1<2=21 andF(2)=2<4=22.\n\u2264\nInduction step: (n>2). Suppose our claim is true for all j<n. Since both n 2\n\u2212\nandn 1arelessthann,wecanapplytheinductiveassumption(sometimescalled\n\u2212\nthe\u201cinductive hypothesis\u201d) toimplythat\nF(n)=F(n 2)+F(n 1)<2n\u22122+2n\u22121.\n\u2212 \u2212\nSince\n2n\u22122+2n\u22121<2n\u22121+2n\u22121=2 2n\u22121=2n,\n\u00b7\nwehavethatF(n)<2n,thusshowingtheinductive hypothesis forn.\nLetusdoanother inductiveargument, thistimeforafactwehaveseenbefore.\nProposition 4.21: (whichisthesameasProposition4.3)\nn n(n+1)\n\u2211i=\n.\n2\ni=1\nJustification: Wewilljustifythisequality byinduction.\nBasecase: n=1. Trivial,for1=n(n+1)/2,ifn=1.\nInduction step: n 2. Assume the inductive hypothesis is true for any j < n.\n\u2265\nTherefore, for j=n 1,wehave\n\u2212\nn\u22121 (n 1)(n 1+1) (n 1)n\n\u2211i=\n\u2212 \u2212 = \u2212 .\n2 2\ni=1\nHence,weobtain\nn n\u22121 (n 1)n 2n+n2 n n2+n n(n+1)\n\u2211i=n+ \u2211i=n+\n\u2212 = \u2212 = = ,\n2 2 2 2\ni=1 i=1\ntherebyprovingtheinductive hypothesis forn.\nWemaysometimes feel overwhelmed by the task of justifying something true\nforalln 1. Weshouldremember,however,theconcretenessoftheinductivetech-\n\u2265\nnique. Itshows that, for anyparticular n, there is afinite step-by-step sequence of\nimplications thatstartswithsomethingtrueandleadstothetruthaboutn. Inshort,\ntheinductiveargumentisatemplateforbuildingasequenceofdirectjustifications.\nwww.it-ebooks.info\n4.4. SimpleJustificationTechniques 181\nLoop Invariants\nThefinaljustificationtechnique wediscussinthissectionistheloopinvariant. To\nprove some statement about a loop is correct, define in terms of a series of\nL L\nsmallerstatements , ,..., ,where:\n0 1 k\nL L L\n1. Theinitialclaim, ,istruebeforetheloopbegins.\n0\nL\n2. If istruebeforeiteration j,then willbetrueafteriteration j.\nj\u22121 j\nL L\n3. Thefinalstatement, ,impliesthedesiredstatement tobetrue.\nk\nL L\nLet us give a simple example of using a loop-invariant argument to justify the\ncorrectness of an algorithm. In particular, we use a loop invariant to justify that\nthe method arrayFind (see Code Fragment 4.11) finds the smallest index at which\nelementvaloccursinarrayA.\n1 /\u2217\u2217 Returns index j such that data[j] == val, or 1 if no such element. \u2217/\n\u2212\n2 public static int arrayFind(int[ ] data, int val)\n{\n3 int n = data.length;\n4 int j = 0;\n5 while (j < n) // val is not equal to any of the first j elements of data\n{\n6 if (data[j] == val)\n7 return j; // a match was found at index j\n8 j++; // continue to next index\n9 // val is not equal to any of the first j elements of data\n10\n}\n11 return 1; // if we reach this, no match found\n\u2212\n12\n}\nCode Fragment 4.11: Algorithm arrayFind for finding the first index at which a\ngivenelementoccursinanarray.\nToshowthatarrayFindiscorrect, weinductively defineaseries ofstatements,\n,thatleadtothecorrectness ofouralgorithm. Specifically, weclaimthefollow-\nj\nL\ningistrueatthebeginning ofiteration jofthewhileloop:\n: val isnotequaltoanyofthefirst jelementsofdata.\nj\nL\nThis claim is true at the beginning of the first iteration of the loop, because j is\n0 and there are no elements among the first 0 in data (this kind of a trivially true\nclaimissaidtoholdvacuously). Initeration j,wecompareelementval toelement\ndata[j];ifthesetwoelementsareequivalent,wereturntheindex j,whichisclearly\ncorrect sincenoearlierelements equalval. Ifthetwoelementsval anddata[j]are\nnotequal,thenwehavefoundonemoreelementnotequaltoval andweincrement\nthe index j. Thus, the claim will be true for this new value of j; hence, it is\nj\nL\ntrueatthebeginningofthenextiteration. Ifthewhileloopterminateswithoutever\nreturning an index in data, then we have j =n. That is, is true\u2014there are no\nn\nL\nelements of data equal to val. Therefore, the algorithm correctly returns 1 to\n\u2212\nindicate thatval isnotindata.\nwww.it-ebooks.info\n182 Chapter4. AlgorithmAnalysis\n4.5 Exercises\nReinforcement\nR-4.1 Graph the functions 8n, 4nlogn, 2n2, n3, and 2n using a logarithmic scale for\nthex-andy-axes;thatis,ifthefunctionvalue f(n)isy,plotthisasapointwith\nx-coordinateatlognandy-coordinateatlogy.\nR-4.2 The numberof operationsexecuted by algorithms A and B is 8nlogn and 2n2,\nrespectively.Determinen suchthatAisbetterthanBforn n .\n0 0\n\u2265\nR-4.3 ThenumberofoperationsexecutedbyalgorithmsA andB is40n2 and2n3, re-\nspectively.Determinen suchthatAisbetterthanBforn n .\n0 0\n\u2265\nR-4.4 Giveanexampleofafunctionthatisplottedthesameonalog-logscaleasitis\nonastandardscale.\nR-4.5 Explainwhytheplotofthefunctionncisastraightlinewithslopeconalog-log\nscale.\nR-4.6 Whatisthesumofalltheevennumbersfrom0to2n,foranyintegern 1?\n\u2265\nR-4.7 Showthatthefollowingtwostatementsareequivalent:\n(a)TherunningtimeofalgorithmAisalwaysO(f(n)).\n(b)Intheworstcase,therunningtimeofalgorithmAisO(f(n)).\nR-4.8 Orderthefollowingfunctionsbyasymptoticgrowthrate.\n4nlogn+2n 210 2logn\n3n+100logn 4n 2n\nn2+10n n3 nlogn\nR-4.9 Giveabig-Ohcharacterization,intermsofn,oftherunningtimeoftheexample1\nmethodshowninCodeFragment4.12.\nR-4.10 Giveabig-Ohcharacterization,intermsofn,oftherunningtimeoftheexample2\nmethodshowninCodeFragment4.12.\nR-4.11 Giveabig-Ohcharacterization,intermsofn,oftherunningtimeoftheexample3\nmethodshowninCodeFragment4.12.\nR-4.12 Giveabig-Ohcharacterization,intermsofn,oftherunningtimeoftheexample4\nmethodshowninCodeFragment4.12.\nR-4.13 Giveabig-Ohcharacterization,intermsofn,oftherunningtimeoftheexample5\nmethodshowninCodeFragment4.12.\nR-4.14 Showthatifd(n)isO(f(n)),thenad(n)isO(f(n)),foranyconstanta>0.\nR-4.15 Show thatif d(n)is O(f(n)) and e(n)is O(g(n)), then the productd(n)e(n) is\nO(f(n)g(n)).\nR-4.16 Showthatifd(n)isO(f(n))ande(n)isO(g(n)),thend(n)+e(n)isO(f(n)+\ng(n)).\nwww.it-ebooks.info\n4.5. Exercises 183\n1 /\u2217\u2217 Returns the sum of the integers in given array. \u2217/\n2 public static int example1(int[ ] arr)\n{\n3 int n = arr.length, total = 0;\n4 for (int j=0; j < n; j++) // loop from 0 to n-1\n5 total += arr[j];\n6 return total;\n7\n}\n8\n9 /\u2217\u2217 Returns the sum of the integers with even index in given array. \u2217/\n10 public static int example2(int[ ] arr)\n{\n11 int n = arr.length, total = 0;\n12 for (int j=0; j < n; j += 2) // note the increment of 2\n13 total += arr[j];\n14 return total;\n15\n}\n16\n17 /\u2217\u2217 Returns the sum of the prefix sums of given array. \u2217/\n18 public static int example3(int[ ] arr)\n{\n19 int n = arr.length, total = 0;\n20 for (int j=0; j < n; j++) // loop from 0 to n-1\n21 for (int k=0; k <= j; k++) // loop from 0 to j\n22 total += arr[j];\n23 return total;\n24\n}\n25\n26 /\u2217\u2217 Returns the sum of the prefix sums of given array. \u2217/\n27 public static int example4(int[ ] arr)\n{\n28 int n = arr.length, prefix = 0, total = 0;\n29 for (int j=0; j < n; j++) // loop from 0 to n-1\n{\n30 prefix += arr[j];\n31 total += prefix;\n32\n}\n33 return total;\n34\n}\n35\n36 /\u2217\u2217 Returns the number of times second array stores sum of prefix sums from first. \u2217/\n37 public static int example5(int[ ] first, int[ ] second) // assume equal-length arrays\n{\n38 int n = first.length, count = 0;\n39 for (int i=0; i < n; i++) // loop from 0 to n-1\n{\n40 int total = 0;\n41 for (int j=0; j < n; j++) // loop from 0 to n-1\n42 for (int k=0; k <= j; k++) // loop from 0 to j\n43 total += first[k];\n44 if (second[i] == total) count++;\n45\n}\n46 return count;\n47\n}\nCodeFragment4.12: Somesamplealgorithmsforanalysis.\nwww.it-ebooks.info\n184 Chapter4. AlgorithmAnalysis\nR-4.17 Showthatifd(n)isO(f(n))ande(n)isO(g(n)),thend(n) e(n)isnotneces-\n\u2212\nsarilyO(f(n) g(n)).\n\u2212\nR-4.18 Showthatifd(n)isO(f(n))and f(n)isO(g(n)),thend(n)isO(g(n)).\nR-4.19 ShowthatO(max f(n),g(n) )=O(f(n)+g(n)).\n{ }\nR-4.20 Showthat f(n)isO(g(n))ifandonlyifg(n)is\u2126(f(n)).\nR-4.21 Showthatif p(n)isapolynomialinn,thenlogp(n)isO(logn).\nR-4.22 Showthat(n+1)5isO(n5).\nR-4.23 Showthat2n+1isO(2n).\nR-4.24 ShowthatnisO(nlogn).\nR-4.25 Showthatn2is\u2126(nlogn).\nR-4.26 Showthatnlognis\u2126(n).\nR-4.27 Showthat f(n) isO(f(n)),if f(n)isapositivenondecreasingfunctionthatis\n\u2308 \u2309\nalwaysgreaterthan1.\nR-4.28 For each function f(n) and time t in the following table, determine the largest\nsizenofaproblemPthatcanbesolvedintimet ifthealgorithmforsolvingP\ntakes f(n)microseconds(oneentryisalreadycompleted).\n1Second 1Hour 1Month 1Century\nlogn 10300000\n\u2248\nn\nnlogn\nn2\n2n\nR-4.29 Algorithm A executes an O(logn)-time computation for each entry of an array\nstoringnelements.Whatisitsworst-caserunningtime?\nR-4.30 Givenann-elementarrayX,AlgorithmBchooseslognelementsinX atrandom\nandexecutesanO(n)-timecalculationforeach. Whatistheworst-caserunning\ntimeofAlgorithmB?\nR-4.31 Givenann-elementarrayXofintegers,AlgorithmCexecutesanO(n)-timecom-\nputationforeachevennumberinX,andanO(logn)-timecomputationforeach\noddnumberinX. Whatarethebest-caseandworst-caserunningtimesofAlgo-\nrithmC?\nR-4.32 Given an n-element array X, Algorithm D calls Algorithm E on each element\nX[i]. AlgorithmE runsin O(i) time whenit iscalled on elementX[i]. What is\ntheworst-caserunningtimeofAlgorithmD?\nwww.it-ebooks.info\n4.5. Exercises 185\nR-4.33 Al and Bob are arguing about their algorithms. Al claims his O(nlogn)-time\nmethodisalwaysfasterthanBob\u2019sO(n2)-timemethod. Tosettletheissue,they\nperform a set of experiments. To Al\u2019s dismay, they find that if n<100, the\nO(n2)-timealgorithmrunsfaster,andonlywhenn 100istheO(nlogn)-time\n\u2265\nonebetter. Explainhowthisispossible.\nR-4.34 Thereisawell-knowncity(whichwillgonamelesshere)whoseinhabitantshave\nthe reputation of enjoying a meal only if that meal is the best they have ever\nexperienced in their life. Otherwise, they hate it. Assuming meal quality is\ndistributed uniformly across a person\u2019s life, describe the expected number of\ntimesinhabitantsofthiscityarehappywiththeirmeals?\nCreativity\nC-4.35 AssumingitispossibletosortnnumbersinO(nlogn)time,showthatitispos-\nsibletosolvethethree-waysetdisjointnessprobleminO(nlogn)time.\nC-4.36 Describeanefficientalgorithmforfindingthetenlargestelementsinanarrayof\nsizen. Whatistherunningtimeofyouralgorithm?\nC-4.37 Give an exampleof a positive function f(n) such that f(n) is neither O(n)nor\n\u2126(n).\nC-4.38 Showthat\u2211n i2 isO(n3).\ni=1\nC-4.39 Showthat\u2211n i/2i<2.\ni=1\nC-4.40 Determinethetotalnumberofgrainsofricerequestedbytheinventorofchess.\nC-4.41 Showthatlog f(n)is\u0398(logf(n))ifb>1isaconstant.\nb\nC-4.42 Describeanalgorithmforfindingboththeminimumandmaximumofnnumbers\nusingfewerthan3n/2comparisons.\nC-4.43 BobbuiltawebsiteandgavetheURLonlytohisnfriends,whichhenumbered\nfrom 1 to n. He told friend number i that he/she can visit the website at most\ni times. Now Bob has a counter,C, keeping track of the total numberof visits\ntothesite (butnottheidentitiesofwhovisits). Whatistheminimumvaluefor\nC such thatBob can know that one of his friendshas visited his/her maximum\nallowednumberoftimes?\nC-4.44 DrawavisualjustificationofProposition4.3analogoustothatofFigure4.3(b)\nforthecasewhennisodd.\nC-4.45 AnarrayAcontainsn 1uniqueintegersintherange[0,n 1],thatis,thereis\n\u2212 \u2212\nonenumberfromthisrangethatisnotinA. DesignanO(n)-timealgorithmfor\nfindingthatnumber. YouareonlyallowedtouseO(1)additionalspacebesides\nthearrayAitself.\nC-4.46 Perform an asymptotic analysis of the insertion-sort algorithm given in Sec-\ntion3.1.2.Whataretheworst-caseandbest-caserunningtimes?\nwww.it-ebooks.info\n186 Chapter4. AlgorithmAnalysis\nC-4.47 Communicationsecurityisextremelyimportantincomputernetworks,andone\nway many network protocols achieve security is to encrypt messages. Typical\ncryptographic schemes for the secure transmission of messages over such net-\nworksarebasedonthefactthatnoefficientalgorithmsareknownforfactoring\nlarge integers. Hence, if we can represent a secret message by a large prime\nnumber p,wecantransmit,overthenetwork,thenumberr= p q,whereq>p\n\u00b7\nisanotherlargeprimenumberthatactsastheencryptionkey. Aneavesdropper\nwhoobtainsthetransmittednumberr onthenetworkwouldhavetofactorr in\nordertofigureoutthesecretmessage p.\nUsingfactoringtofigureoutamessageishardwithoutknowingtheencryption\nkeyq. Tounderstandwhy,considerthefollowingnaivefactoringalgorithm:\nfor (int p=2; p < r; p++)\nif (r % p == 0)\nreturn \"The secret message is p!\";\na. Suppose the eavesdropper\u2019s computer can divide two 100-bit integers in\n\u00b5s(1millionthofasecond). Estimatetheworst-casetimetodecipherthe\nsecretmessage pifthetransmittedmessagerhas100bits.\nb. Whatistheworst-casetimecomplexityoftheabovealgorithm? Sincethe\ninputtothealgorithmisjustonelargenumberr,assumethattheinputsize\nnisthenumberofbytesneededtostorer,thatis,n= (log r)/8 +1,and\n\u230a 2 \u230b\nthateachdivisiontakestimeO(n).\nC-4.48 Alsayshecanprovethatallsheepinaflockarethesamecolor:\nBasecase: Onesheep. Itisclearlythesamecolorasitself.\nInductionstep: A flock of n sheep. Take a sheep, a, out. The remainingn 1\n\u2212\nare all the same color by induction. Now put sheep a back in and take out a\ndifferentsheep, b. By induction,the n 1sheep (nowwith a) are allthe same\n\u2212\ncolor. Therefore, all the sheep in the flock are the same color. What is wrong\nwithAl\u2019s\u201cjustification\u201d?\nC-4.49 Considerthefollowing\u201cjustification\u201dthattheFibonaccifunction,F(n)isO(n):\nBasecase(n 2):F(1)=1andF(2)=2.\nInduction ste \u2264 p (n> 2): Assume claim true for n\u2032 <n. Consider n. F(n)=\nF(n 2)+F(n 1).Byinduction,F(n 2)isO(n 2)andF(n 1)isO(n 1).\n\u2212 \u2212 \u2212 \u2212 \u2212 \u2212\nThen,F(n)isO((n 2)+(n 1)),bytheidentitypresentedinExerciseR-4.16.\n\u2212 \u2212\nTherefore,F(n)isO(n).\nWhatiswrongwiththis\u201cjustification\u201d?\nC-4.50 ConsidertheFibonaccifunction,F(n)(seeProposition4.20).Showbyinduction\nthatF(n)is\u2126((3/2)n).\nC-4.51 Let S be a set of n lines in the planesuch that no two are paralleland no three\nmeetinthesamepoint. Show,byinduction,thatthelinesinSdetermine\u0398(n2)\nintersectionpoints.\nC-4.52 Showthatthesummation\u2211n logiisO(nlogn).\ni=1\nC-4.53 Showthatthesummation\u2211n logiis\u2126(nlogn).\ni=1\nwww.it-ebooks.info\n4.5. Exercises 187\nC-4.54 Let p(x)beapolynomialofdegreen,thatis, p(x)=\u2211n axi.\ni=0 i\na. DescribeasimpleO(n2)-timealgorithmforcomputingp(x).\nb. Describe an O(nlogn)-time algorithm for computing p(x), based upon a\nmoreefficientcalculationofxi.\nc. Nowconsiderarewritingof p(x)as\np(x)=a 0 +x(a 1 +x(a 2 +x(a 3 + +x(a n\u22121 +xa n ) ))),\n\u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7\nwhichisknownasHorner\u2019smethod. Usingthebig-Ohnotation,charac-\nterizethenumberofarithmeticoperationsthismethodexecutes.\nC-4.55 An evil king has n bottles of wine, and a spy has just poisoned one of them.\nUnfortunately,theydonotknowwhichoneitis. Thepoisonisverydeadly;just\nonedropdilutedevenabilliontoonewillstillkill. Evenso,ittakesafullmonth\nfor the poison to take effect. Design a scheme for determining exactly which\noneofthewinebottleswaspoisonedinjustonemonth\u2019stimewhileexpending\nO(logn)tastetesters.\nC-4.56 An array A contains n integers taken from the interval [0,4n], with repetitions\nallowed. Describeanefficientalgorithmfordetermininganintegervaluek that\noccursthemostofteninA. Whatistherunningtimeofyouralgorithm?\nC-4.57 Given an array A of n positive integers, each represented with k= logn +1\n\u2308 \u2309\nbits,describeanO(n)-timemethodforfindingak-bitintegernotinA.\nC-4.58 Arguewhyanysolutiontothepreviousproblemmustrunin\u2126(n)time.\nC-4.59 GivenanarrayAofnarbitraryintegers,designanO(n)-timemethodforfinding\nanintegerthatcannotbeformedasthesumoftwointegersinA.\nProjects\nP-4.60 PerformanexperimentalanalysisofthetwoalgorithmsprefixAverage1andpre-\nfixAverage2, fromSection 4.3.3. Visualize their runningtimesas a functionof\ntheinputsizewithalog-logchart.\nP-4.61 Performanexperimentalanalysisthatcomparestherelativerunningtimesofthe\nmethodsshowninCodeFragment4.12.\nP-4.62 Perform an experimental analysis to test the hypothesis that Java\u2019s Array.sort\nmethodrunsinO(nlogn)timeonaverage.\nP-4.63 Foreachofthealgorithmsunique1andunique2,whichsolvetheelementunique-\nnessproblem,performanexperimentalanalysistodeterminethelargestvalueof\nnsuchthatthegivenalgorithmrunsinoneminuteorless.\nwww.it-ebooks.info\n188 Chapter4. AlgorithmAnalysis\nChapter Notes\nThe big-Oh notation has prompted several comments about its proper use [18, 43, 59].\nKnuth[60,59]definesitusingthenotation f(n)=O(g(n)),butsaysthis\u201cequality\u201disonly\n\u201coneway.\u201d Wehavechosentotakeamorestandardviewofequalityandviewthebig-Oh\nnotationasaset, followingBrassard[18]. Thereaderinterestedinstudyingaverage-case\nanalysisisreferredtothebookchapterbyVitterandFlajolet[93].\nwww.it-ebooks.info\nChapter\n5\nRecursion\nContents\n5.1 Illustrative Examples . . . . . . . . . . . . . . . . . . . . . . 191\n5.1.1 The Factorial Function . . . . . . . . . . . . . . . . . . . 191\n5.1.2 Drawing an English Ruler . . . . . . . . . . . . . . . . . . 193\n5.1.3 Binary Search . . . . . . . . . . . . . . . . . . . . . . . . 196\n5.1.4 File Systems . . . . . . . . . . . . . . . . . . . . . . . . . 198\n5.2 Analyzing Recursive Algorithms . . . . . . . . . . . . . . . 202\n5.3 Further Examples of Recursion . . . . . . . . . . . . . . . . 206\n5.3.1 Linear Recursion . . . . . . . . . . . . . . . . . . . . . . . 206\n5.3.2 Binary Recursion . . . . . . . . . . . . . . . . . . . . . . 211\n5.3.3 Multiple Recursion . . . . . . . . . . . . . . . . . . . . . 212\n5.4 Designing Recursive Algorithms . . . . . . . . . . . . . . . 214\n5.5 Recursion Run Amok . . . . . . . . . . . . . . . . . . . . . 215\n5.5.1 Maximum Recursive Depth in Java . . . . . . . . . . . . . 218\n5.6 Eliminating Tail Recursion . . . . . . . . . . . . . . . . . . 219\n5.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\nwww.it-ebooks.info\n190 Chapter5. Recursion\nOneway todescribe repetition within a computer program is the use ofloops,\nsuch as Java\u2019s while-loop and for-loop constructs described in Section 1.5.2. An\nentirelydifferentwaytoachieverepetitionisthroughaprocessknownasrecursion.\nRecursion is a technique by which a method makes one or more calls to itself\nduring execution, or by which a data structure relies upon smaller instances of\nthe very same type of structure in its representation. There are many examples of\nrecursion inartandnature. Forexample,fractalpatterns arenaturally recursive. A\nphysicalexampleofrecursion usedinartisintheRussianMatryoshka dolls. Each\ndoll is either made of solid wood, or is hollow and contains another Matryoshka\ndollinsideit.\nIn computing, recursion provides an elegant and powerful alternative for per-\nforming repetitive tasks. In fact, a few programming languages (e.g., Scheme,\nSmalltalk) do not explicitly support looping constructs and instead rely directly\non recursion to express repetition. Most modern programming languages support\nfunctional recursion using the identical mechanism that is used to support tradi-\ntionalformsofmethodcalls. Whenoneinvocationofthemethodmakesarecursive\ncall,thatinvocation issuspended untiltherecursivecallcompletes.\nRecursion is an important technique in the study of data structures and algo-\nrithms. We will use it prominently in several later chapters of this book (most\nnotably,Chapters8and12). Inthischapter,webeginwiththefollowingfourillus-\ntrativeexamplesoftheuseofrecursion, providing aJavaimplementation foreach.\nThe factorial function (commonly denoted as n!) is a classic mathematical\n\u2022\nfunction thathasanaturalrecursive definition.\nAnEnglishrulerhasarecursivepatternthatisasimpleexampleofafractal\n\u2022\nstructure.\nBinary search is among the most important computer algorithms. It allows\n\u2022\nus to efficiently locate a desired value in a data set with upwards of billions\nofentries.\nThefilesystem for acomputer has arecursive structure inwhichdirectories\n\u2022\ncan be nested arbitrarily deeply within other directories. Recursive algo-\nrithmsarewidelyusedtoexploreandmanagethesefilesystems.\nWe then describe how to perform a formal analysis of the running time of a\nrecursive algorithm, and we discuss some potential pitfalls when defining recur-\nsions. Inthe balance of the chapter, weprovide many more examples ofrecursive\nalgorithms, organized tohighlight somecommonformsofdesign.\nwww.it-ebooks.info\n5.1. IllustrativeExamples 191\n5.1 Illustrative Examples\n5.1.1 The Factorial Function\nTo demonstrate the mechanics of recursion, we begin with a simple mathematical\nexample ofcomputing the value of the factorial function. Thefactorial of aposi-\ntive integer n, denoted n!, is defined as the product of the integers from 1 to n. If\nn=0,thenn!isdefinedas1byconvention. Moreformally,foranyintegern 0,\n\u2265\n1 ifn=0\nn!=\nn (n 1) (n 2) 3 2 1 ifn 1.\n(cid:26) \u00b7 \u2212 \u00b7 \u2212 \u00b7\u00b7\u00b7 \u00b7 \u00b7 \u2265\nForexample, 5!=5 4 3 2 1 =120. Thefactorial function isimportant because\n\u00b7 \u00b7 \u00b7 \u00b7\nitisknown toequal thenumber ofwaysinwhich ndistinct items can bearranged\ninto a sequence, that is, the number of permutations of n items. For example, the\nthree characters a, b, and c can be arranged in 3!=3 2 1=6 ways: abc, acb,\n\u00b7 \u00b7\nbac,bca,cab,andcba.\nThere is a natural recursive definition for the factorial function. To see this,\nobserve that 5!=5 (4 3 2 1) =5 4!. More generally, for a positive integer n,\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nwecandefinen!toben (n 1)!. Thisrecursivedefinitioncanbeformalizedas\n\u00b7 \u2212\n1 ifn=0\nn!=\nn (n 1)! ifn 1.\n(cid:26) \u00b7 \u2212 \u2265\nThis definition is typical of many recursive definitions of functions. First, we\nhaveoneormorebasecases,whichrefertofixedvaluesofthefunction. Theabove\ndefinition has one base case stating that n!= 1 for n=0. Second, we have one\nor more recursive cases, which define the function interms ofitself. In the above\ndefinition,thereisonerecursivecase,whichindicatesthatn!=n (n 1)!forn 1.\n\u00b7 \u2212 \u2265\nA Recursive Implementation of the Factorial Function\nRecursionisnotjustamathematicalnotation;wecanuserecursiontodesignaJava\nimplementation ofthefactorialfunction, asshowninCodeFragment5.1.\n1 public static int factorial(int n) throws IllegalArgumentException\n{\n2 if (n < 0)\n3 throw new IllegalArgumentException(); // argument must be nonnegative\n4 else if (n == 0)\n5 return 1; // base case\n6 else\n7 return n \u2217 factorial(n 1); // recursive case\n\u2212\n8\n}\nCodeFragment5.1: Arecursiveimplementation ofthefactorial function.\nwww.it-ebooks.info\n192 Chapter5. Recursion\nThis method does not use any explicit loops. Repetition is achieved through\nrepeated recursive invocations of the method. The process is finite because each\ntime the method is invoked, its argument is smaller by one, and when a base case\nisreached, nofurtherrecursivecallsaremade.\nWeillustratetheexecutionofarecursivemethodusingarecursiontrace. Each\nentry of the trace corresponds to a recursive call. Each new recursive method call\nis indicated by a downward arrow to a new invocation. When the method returns,\nanarrowshowingthisreturnisdrawnandthereturnvaluemaybeindicatedalong-\nside this arrow. An example of such a trace for the factorial function is shown in\nFigure5.1.\nreturn 5 \u2217 24 = 120\nfactorial(5)\nreturn 4 \u2217 6 = 24\nfactorial(4)\nreturn 3 \u2217 2 = 6\nfactorial(3)\nreturn 2 \u2217 1 = 2\nfactorial(2)\nreturn 1 \u2217 1 = 1\nfactorial(1)\nreturn 1\nfactorial(0)\nFigure5.1: Arecursion traceforthecallfactorial(5).\nA recursion trace closely mirrors a programming language\u2019s execution of the\nrecursion. InJava,eachtimeamethod(recursiveorotherwise)iscalled,astructure\nknown as an activation record or activation frame is created to store information\nabouttheprogress ofthatinvocation ofthemethod. Thisframestores theparame-\ntersandlocalvariablesspecifictoagivencallofthemethod,andinformationabout\nwhichcommandinthebodyofthemethodiscurrently executing.\nWhen the execution of a method leads to a nested method call, the execution\nofthe former call issuspended and itsframe stores theplace inthe source code at\nwhich the flow of control should continue upon return of the nested call. A new\nframe is then created for the nested method call. This process is used both in the\nstandard case of one method calling a different method, or in the recursive case\nwhere a method invokes itself. The key point is to have a separate frame for each\nactivecall.\nwww.it-ebooks.info\n5.1. IllustrativeExamples 193\n5.1.2 Drawing an English Ruler\nIn the case of computing the factorial function, there is no compelling reason for\npreferringrecursionoveradirectiterationwithaloop. Asamorecomplexexample\nof the use of recursion, consider how to draw the markings of a typical English\nruler. For each inch, we place a tick with a numeric label. We denote the length\nof the tick designating a whole inch as the major tick length. Between the marks\nfor whole inches, the ruler contains a series of minor ticks, placed at intervals of\n1/2inch,1/4inch,andsoon. Asthesizeoftheintervaldecreasesbyhalf,thetick\nlength decreases by one. Figure 5.2 demonstrates several such rulers with varying\nmajorticklengths(although notdrawntoscale).\n---- 0 ----- 0 --- 0\n- - -\n-- -- --\n- - -\n--- --- --- 1\n- - -\n-- -- --\n- - -\n---- 1 ---- --- 2\n- - -\n-- -- --\n- - -\n--- --- --- 3\n- -\n-- --\n- -\n---- 2 ----- 1\n(a) (b) (c)\nFigure 5.2: Three sample outputs of an English ruler drawing: (a) a 2-inch ruler\nwith major tick length 4; (b) a 1-inch ruler with major tick length 5; (c) a 3-inch\nrulerwithmajorticklength3.\nA Recursive Approach to Ruler Drawing\nTheEnglish ruler pattern isasimple example ofafractal, that is, ashape that has\naself-recursive structure atvarious levelsofmagnification. Consider therulewith\nmajor tick length 5 shown in Figure 5.2(b). Ignoring the lines containing 0 and 1,\nlet us consider how to draw the sequence of ticks lying between these lines. The\ncentral tick (at1/2inch) haslength 4. Observe thatthetwopatterns ofticks above\nandbelowthiscentraltickareidentical, andeachhasacentral tickoflength3.\nwww.it-ebooks.info\n194 Chapter5. Recursion\nIngeneral, anintervalwithacentralticklengthL 1iscomposed of:\n\u2265\nAnintervalwithacentralticklengthL 1\n\u2022 \u2212\nAsingletickoflengthL\n\u2022\nAnintervalwithacentralticklengthL 1\n\u2022 \u2212\nAlthough itis possible todraw such aruler using an iterative process (see Ex-\nercise P-5.29), the task is considerably easier to accomplish with recursion. Our\nimplementation consists ofthreemethods, asshowninCodeFragment5.2.\nThemain method, drawRuler, manages the construction ofthe entire ruler. Its\nargumentsspecifythetotalnumberofinchesintherulerandthemajorticklength.\nTheutilitymethod,drawLine,drawsasingletickwithaspecifiednumberofdashes\n(andanoptional integerlabelthatisprinted totherightofthetick).\nTheinterestingworkisdonebytherecursivedrawIntervalmethod. Thismethod\ndraws the sequence of minor ticks within some interval, based upon the length of\nthe interval\u2019s central tick. We rely on the intuition shown at the top of this page,\nand with a base case when L=0 that draws nothing. For L 1, the first and last\n\u2265\nstepsareperformed byrecursively calling drawInterval(L 1). Themiddlestepis\n\u2212\nperformedbycallingmethoddrawLine(L).\n1 /\u2217\u2217 Draws an English ruler for the given number of inches and major tick length. \u2217/\n2 public static void drawRuler(int nInches, int majorLength)\n{\n3 drawLine(majorLength, 0); // draw inch 0 line and label\n4 for (int j = 1; j <= nInches; j++)\n{\n5 drawInterval(majorLength 1); // draw interior ticks for inch\n\u2212\n6 drawLine(majorLength, j); // draw inch j line and label\n7\n}\n8\n}\n9 private static void drawInterval(int centralLength)\n{\n10 if (centralLength >= 1) // otherwise, do nothing\n{\n11 drawInterval(centralLength 1); // recursively draw top interval\n\u2212\n12 drawLine(centralLength); // draw center tick line (without label)\n13 drawInterval(centralLength 1); // recursively draw bottom interval\n\u2212\n14\n}\n15\n}\n16 private static void drawLine(int tickLength, int tickLabel)\n{\n17 for (int j = 0; j < tickLength; j++)\n18 System.out.print(\"-\");\n19 if (tickLabel >= 0)\n20 System.out.print(\" \" + tickLabel);\n21 System.out.print(\"\\n\");\n22\n23 } /\u2217\u2217 Draws a line with the given tick length (but no label). \u2217/\n24 private static void drawLine(int tickLength)\n{\n25 drawLine(tickLength, 1);\n\u2212\n26\n}\nCodeFragment5.2: Arecursiveimplementation ofamethodthatdrawsaruler.\nwww.it-ebooks.info\n5.1. IllustrativeExamples 195\nIllustrating Ruler Drawing Using a Recursion Trace\nThe execution of the recursive drawInterval method can be visualized using a re-\ncursion trace. The trace for drawInterval is more complicated than in the factorial\nexample, however, because each instance makes two recursive calls. To illustrate\nthis,wewillshowtherecursiontraceinaformthatisreminiscent ofanoutlinefor\nadocument. SeeFigure5.3.\nOutput\ndrawInterval(3)\ndrawInterval(2)\ndrawInterval(1)\ndrawInterval(0)\ndrawLine(1)\ndrawInterval(0)\ndrawLine(2)\ndrawInterval(1)\ndrawInterval(0)\ndrawLine(1)\ndrawInterval(0)\ndrawLine(3)\ndrawInterval(2)\n(previouspatternrepeats)\nFigure5.3:ApartialrecursiontraceforthecalldrawInterval(3). Thesecondpattern\nofcallsfordrawInterval(2)isnotshown,butitisidentical tothefirst.\nwww.it-ebooks.info\n196 Chapter5. Recursion\n5.1.3 Binary Search\nIn this section, we describe a classic recursive algorithm, binary search, used to\nefficiently locate a target value within a sorted sequence of n elements stored in\nan array. This is among the most important of computer algorithms, and it is the\nreasonthatwesooftenstoredatainsortedorder(asinFigure5.4).\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n2 4 5 7 8 9 12 14 17 19 22 25 27 28 33 37\nFigure5.4: Values stored in sorted order within an array. The numbers at top are\ntheindices.\nWhen the sequence is unsorted, the standard approach to search for a target\nvalue is to use a loop to examine every element, until either finding the target or\nexhausting the data set. This algorithm is known as linear search, or sequential\nsearch, anditrunsinO(n)time(i.e.,linear time)since everyelement isinspected\nintheworstcase.\nWhenthesequenceissortedandindexable,thereisamoreefficientalgorithm.\n(For intuition, think about how you would accomplish this task by hand!) If we\nconsider anarbitrary element ofthe sequence withvalue v, wecan besure that all\nelementspriortothatinthesequencehavevalueslessthanorequaltov,andthatall\nelements after that element in the sequence have values greater than or equal to v.\nThisobservation allows us toquickly \u201chome in\u201d on asearch target using avariant\nofthechildren\u2019s game\u201chigh-low.\u201d Wecallanelementofthesequenceacandidate\nif, at the current stage of the search, we cannot rule out that this item matches the\ntarget. The algorithm maintains two parameters, low and high, such that all the\ncandidate elements haveindex atleast lowandatmosthigh. Initially, low=0and\nhigh=n 1. We then compare the target value to the median candidate, that is,\n\u2212\ntheelementwithindex\nmid= (low+high)/2 .\n\u230a \u230b\nWeconsiderthreecases:\nIfthetargetequalsthemediancandidate,thenwehavefoundtheitemweare\n\u2022\nlooking for,andthesearchterminates successfully.\nIfthetarget isless thanthemediancandidate, thenwerecur onthefirsthalf\n\u2022\nofthesequence, thatis,ontheintervalofindices fromlowtomid 1.\n\u2212\nIfthetargetisgreaterthanthemediancandidate,thenwerecuronthesecond\n\u2022\nhalfofthesequence, thatis,ontheintervalofindicesfrommid+1tohigh.\nAnunsuccessful searchoccursiflow > high,astheinterval[low,high]isempty.\nwww.it-ebooks.info\n5.1. IllustrativeExamples 197\nThis algorithm is known as binary search. We give a Java implementation in\nCode Fragment 5.3, and an illustration of the execution of the algorithm in Fig-\nure 5.5. Whereas sequential search runs in O(n) time, the more efficient binary\nsearch runs in O(logn) time. This is a significant improvement, given that if n is\n1billion,lognisonly30. (Wedeferourformalanalysisofbinarysearch\u2019srunning\ntimetoProposition 5.2inSection5.2.)\n1 /\u2217\u2217\n2 \u2217 Returns true if the target value is found in the indicated portion of the data array.\n3 \u2217 This search only considers the array portion from data[low] to data[high] inclusive.\n4 \u2217/\n5 public static boolean binarySearch(int[ ] data, int target, int low, int high)\n{\n6 if (low > high)\n7 return false; // interval empty; no match\n8 else\n{\n9 int mid = (low + high) / 2;\n10 if (target == data[mid])\n11 return true; // found a match\n12 else if (target < data[mid])\n13 return binarySearch(data, target, low, mid 1); // recur left of the middle\n\u2212\n14 else\n15 return binarySearch(data, target, mid + 1, high); // recur right of the middle\n16\n}\n17\n}\nCodeFragment5.3: Animplementation ofthebinary search algorithm onasorted\narray.\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n2 4 5 7 8 9 12 14 17 19 22 25 27 28 33 37\nlow mid high\n2 4 5 7 8 9 12 14 17 19 22 25 27 28 33 37\nlow mid high\n2 4 5 7 8 9 12 14 17 19 22 25 27 28 33 37\nlow midhigh\n2 4 5 7 8 9 12 14 17 19 22 25 27 28 33 37\nlow=mid=high\nFigure5.5: Exampleofabinarysearchfortargetvalue22onasortedarraywith16\nelements.\nwww.it-ebooks.info\n198 Chapter5. Recursion\n5.1.4 File Systems\nModern operating systems define file-system directories (also called \u201cfolders\u201d) in\na recursive way. Namely, a file system consists of a top-level directory, and the\ncontents of this directory consists of files and other directories, which in turn can\ncontainfilesandotherdirectories, andsoon. Theoperating systemallowsdirecto-\nries to be nested arbitrarily deeply (as long as there is enough memory), although\nby necessity there must be some base directories that contain only files, not fur-\nther subdirectories. A representation of a portion of such a file system is given in\nFigure5.6.\n/user/rt/courses/\ncs016/ cs252/\ngrades grades\nhomeworks/ programs/ projects/\nhw1 hw2 hw3 pr1 pr2 pr3\npapers/ demos/\nbuylow sellhigh market\nFigure5.6: Aportionofafilesystem demonstrating anestedorganization.\nGiventherecursivenatureofthefile-systemrepresentation, itshouldnotcome\nasasurprisethatmanycommonbehaviorsofanoperatingsystem,suchascopying\na directory or deleting a directory, are implemented with recursive algorithms. In\nthissection,weconsideronesuchalgorithm: computingthetotaldiskusageforall\nfilesanddirectories nestedwithinaparticular directory.\nFor illustration, Figure 5.7 portrays the disk space being used by all entries in\noursamplefilesystem. Wedifferentiatebetweentheimmediatediskspaceusedby\neachentryandthecumulativediskspaceusedbythatentryandallnestedfeatures.\nFor example, the cs016 directory uses only 2K of immediate space, but a total of\n249Kofcumulativespace.\nwww.it-ebooks.info\n5.1. IllustrativeExamples 199\n5124K\n/user/rt/courses/\n1K\n249K 4874K\ncs016/ cs252/\n2K 1K\n10K 229K 4870K\ngrades homeworks/ programs/ projects/ grades\n8K 1K 1K 1K 3K\n82K 4787K\nhw1 hw2 hw3 pr1 pr2 pr3 papers/ demos/\n3K 2K 4K 57K 97K 74K 1K 1K\nbuylow sellhigh market\n26K 55K 4786K\nFigure5.7:ThesameportionofafilesystemgiveninFigure5.6,butwithadditional\nannotations to describe the amount of disk space that is used. Within the icon for\neach file or directory is the amount of space directly used by that artifact. Above\nthe icon for each directory is an indication of the cumulative disk space used by\nthatdirectory andallits(recursive) contents.\nThecumulativediskspaceforanentrycanbecomputedwithasimplerecursive\nalgorithm. It is equal to the immediate disk space used by the entry plus the sum\nof the cumulative disk space usage of any entries that are stored directly within\nthe entry. For example, the cumulative disk space for cs016 is 249K because it\nuses 2K itself, 8K cumulatively in grades, 10K cumulatively in homeworks, and\n229K cumulatively in programs. Pseudocode for this algorithm is given in Code\nFragment5.4.\nAlgorithmDiskUsage(path):\nInput: Astringdesignating apathtoafile-system entry\nOutput: Thecumulativediskspaceusedbythatentryandanynestedentries\ntotal = size(path) immediatediskspaceusedbytheentry\n{ }\nifpathrepresents adirectorythen\nforeachchild entrystoredwithindirectory pathdo\ntotal = total+DiskUsage(child) recursivecall\n{ }\nreturntotal\nCodeFragment5.4: An algorithm for computing the cumulative disk space usage\nnested at a file-system entry. We presume that method size returns the immediate\ndiskspaceofanentry.\nwww.it-ebooks.info\n200 Chapter5. Recursion\nThe java.io.File Class\nTo implement a recursive algorithm for computing disk usage in Java, we rely on\nthe java.io.File class. An instance of this class represents an abstract pathname in\ntheoperating system andallowsforproperties ofthatoperating system entrytobe\nqueried. Wewillrelyonthefollowingmethodsoftheclass:\nnew File(pathString)ornew File(parentFile, childString)\n\u2022\nA new File instance can be constructed either by providing the full path as\na string, or by providing an existing Fileinstance that represents a directory\nandastringthatdesignates thenameofachildentrywithinthatdirectory.\nfile.length()\n\u2022\nReturns theimmediatediskusage (measured inbytes) fortheoperating sys-\ntementryrepresented bytheFileinstance (e.g.,/user/rt/courses).\nfile.isDirectory()\n\u2022\nReturnstrueiftheFileinstance represents adirectory; falseotherwise.\nfile.list()\n\u2022\nReturns an array of strings designating the names of all entries within the\ngiven directory. In our sample file system, if we call this method on the\nFile associated with path /user/rt/courses/cs016, it returns an array with\ncontents: \"grades\",\"homeworks\",\"programs\" .\n{ }\nJava Implementation\nWith use of the Fileclass, wenow convert the algorithm from Code Fragment 5.4\nintotheJavaimplementation ofCodeFragment5.5.\n1 /\u2217\u2217\n2 \u2217 Calculates the total disk usage (in bytes) of the portion of the file system rooted\n3 \u2217 at the given path, while printing a summary akin to the standard 'du' Unix tool.\n4 \u2217/\n5 public static long diskUsage(File root)\n{\n6 long total = root.length(); // start with direct disk usage\n7 if (root.isDirectory()) // and if this is a directory,\n{\n8 for (String childname : root.list()) // then for each child\n{\n9 File child = new File(root, childname); // compose full path to child\n10 total += diskUsage(child); // add child\u2019s usage to total\n11\n}\n12\n}\n13 System.out.println(total + \"\\t\" + root); // descriptive output\n14 return total; // return the grand total\n15\n}\nCodeFragment5.5: Arecursivemethodforreporting diskusageofafilesystem.\nwww.it-ebooks.info\n5.1. IllustrativeExamples 201\nRecursion Trace\nTo produce a different form of a recursion trace, we have included an extraneous\nprint statement within our Java implementation (line 13 of Code Fragment 5.5).\nThe precise format of that output intentionally mirrors the output that is produced\nbyaclassic Unix/Linux utility named du(for \u201cdisk usage\u201d). Itreports theamount\nofdiskspaceusedbyadirectory andallcontents nestedwithin,andcanproduce a\nverbosereport, asgiveninFigure5.8.\nWhen executed on the sample file system portrayed in Figure 5.7, our imple-\nmentationofthediskUsagemethodproducestheresultgiveninFigure5.8. During\ntheexecution ofthealgorithm, exactly one recursive callismadeforeach entryin\nthe portion of the file system that is considered. Because each line is printed just\nbeforereturning fromarecursivecall,thelinesofoutput reflecttheorderinwhich\nthe recursive calls are completed. Notice that itcomputes and reports the cumula-\ntive disk space for a nested entry before computing and reporting the cumulative\ndiskspaceforthedirectorythatcontainsit. Forexample,therecursivecallsregard-\ningentries grades, homeworks, andprograms arecomputed before the cumulative\ntotalforthedirectory /user/rt/courses/cs016 thatcontains them.\n8 /user/rt/courses/cs016/grades\n3 /user/rt/courses/cs016/homeworks/hw1\n2 /user/rt/courses/cs016/homeworks/hw2\n4 /user/rt/courses/cs016/homeworks/hw3\n10 /user/rt/courses/cs016/homeworks\n57 /user/rt/courses/cs016/programs/pr1\n97 /user/rt/courses/cs016/programs/pr2\n74 /user/rt/courses/cs016/programs/pr3\n229 /user/rt/courses/cs016/programs\n249 /user/rt/courses/cs016\n26 /user/rt/courses/cs252/projects/papers/buylow\n55 /user/rt/courses/cs252/projects/papers/sellhigh\n82 /user/rt/courses/cs252/projects/papers\n4786 /user/rt/courses/cs252/projects/demos/market\n4787 /user/rt/courses/cs252/projects/demos\n4870 /user/rt/courses/cs252/projects\n3 /user/rt/courses/cs252/grades\n4874 /user/rt/courses/cs252\n5124 /user/rt/courses/\nFigure 5.8: A report of the disk usage for the file system shown in Figure 5.7, as\ngenerated by our diskUsage method from Code Fragment 5.5, or equivalently by\ntheUnix/Linuxcommandduwithoption-a(whichlistsbothdirectories andfiles).\nwww.it-ebooks.info\n202 Chapter5. Recursion\n5.2 Analyzing Recursive Algorithms\nIn Chapter 4, we introduced mathematical techniques for analyzing the efficiency\nofanalgorithm, baseduponanestimateofthenumberofprimitiveoperations that\nare executed by the algorithm. Weuse notations such asbig-Oh to summarize the\nrelationship betweenthenumberofoperations andtheinputsizeforaproblem. In\nthis section, we demonstrate how to perform this type of running-time analysis to\nrecursivealgorithms.\nWitharecursivealgorithm,wewillaccountforeachoperationthatisperformed\nbasedupontheparticularactivationofthemethodthatmanagestheflowofcontrol\nat the time it is executed. Stated another way, for each invocation of the method,\nweonlyaccountforthenumberofoperationsthatareperformedwithinthebodyof\nthat activation. We can then account for the overall number of operations that are\nexecuted as part of the recursive algorithm by taking the sum, over all activations,\nof the number of operations that take place during each individual activation. (As\nan aside, this is also the way we analyze a nonrecursive method that calls other\nmethodsfromwithinitsbody.)\nTo demonstrate this style of analysis, we revisit the four recursive algorithms\npresented in Sections 5.1.1 through 5.1.4: factorial computation, drawing an En-\nglish ruler, binary search, and computation of the cumulative size of afilesystem.\nIngeneral, wemayrelyontheintuition afforded byarecursion traceinrecogniz-\ning how many recursive activations occur, and how the parameterization of each\nactivation can be used to estimate the number of primitive operations that occur\nwithinthebodyofthatactivation. However,eachoftheserecursivealgorithmshas\nauniquestructure andform.\nComputing Factorials\nItisrelativelyeasytoanalyzetheefficiencyofourmethodforcomputingfactorials,\nasdescribedinSection5.1.1. Asamplerecursiontraceforourfactorialmethodwas\ngiven in Figure 5.1. Tocompute factorial(n), wesee that there are atotal ofn+1\nactivations,astheparameterdecreasesfromninthefirstcall,ton 1inthesecond\n\u2212\ncall,andsoon,untilreaching thebasecasewithparameter 0.\nItisalsoclear,givenanexaminationofthemethodbodyinCodeFragment5.1,\nthat each individual activation of factorial executes a constant number of opera-\ntions. Therefore, weconclude thattheoverallnumberofoperations forcomputing\nfactorial(n)isO(n),astherearen+1activations, eachofwhichaccountsforO(1)\noperations.\nwww.it-ebooks.info\n5.2. AnalyzingRecursiveAlgorithms 203\nDrawing an English Ruler\nInanalyzing theEnglishrulerapplication fromSection5.1.2,weconsiderthefun-\ndamentalquestionofhowmanytotallinesofoutputaregeneratedbyaninitialcall\nto drawInterval(c), where cdenotes thecenter length. Thisis areasonable bench-\nmarkfortheoverallefficiencyofthealgorithmaseachlineofoutputisbasedupon\nacall to the drawLineutility, and each recursive call to drawInterval withnonzero\nparametermakesexactlyonedirectcalltodrawLine.\nSome intuition may be gained by examining the source code and the recur-\nsion trace. We know that a call to drawInterval(c) for c>0 spawns two calls to\ndrawInterval(c 1)and asingle call todrawLine. Wewillrely onthis intuition to\n\u2212\nprovethefollowingclaim.\nProposition 5.1: Forc 0,acalltodrawInterval(c) resultsinprecisely2c 1\n\u2265 \u2212\nlinesofoutput.\nJustification: We provide a formal proof of this claim by induction (see Sec-\ntion 4.4.3). In fact, induction is a natural mathematical technique for proving the\ncorrectness and efficiency of a recursive process. In the case of the ruler, we note\nthatanapplicationofdrawInterval(0)generatesnooutput,andthat20 1=1 1=\n\u2212 \u2212\n0. Thisservesasabasecaseforourclaim.\nMore generally, the number of lines printed by drawInterval(c) is one more\nthantwicethenumbergeneratedbyacalltodrawInterval(c 1),asonecenterline\n\u2212\nisprintedbetweentwosuchrecursivecalls. Byinduction, wehavethatthenumber\noflinesisthus1+2 (2c\u22121 1)=1+2c 2=2c 1.\n\u00b7 \u2212 \u2212 \u2212\nThis proof is indicative of a more mathematically rigorous tool, known as a\nrecurrence equation, that can be used to analyze the running time of a recursive\nalgorithm. ThattechniqueisdiscussedinSection12.1.4,inthecontextofrecursive\nsortingalgorithms.\nPerforming a Binary Search\nWhen considering the running time of the binary search algorithm, as presented\nin Section 5.1.3, we observe that a constant number of primitive operations are\nexecutedduringeachrecursivecallofthebinarysearchmethod. Hence,therunning\ntimeisproportional tothenumberofrecursive callsperformed. Wewillshowthat\nat most logn +1 recursive calls are made during a binary search of a sequence\n\u230a \u230b\nhavingnelements,leading tothefollowingclaim.\nProposition 5.2: ThebinarysearchalgorithmrunsinO(logn)timeforasorted\narraywithnelements.\nwww.it-ebooks.info\n204 Chapter5. Recursion\nJustification: Toprove this claim, acrucial fact is that witheach recursive call\nthenumberofcandidate elementsstilltobesearched isgivenbythevalue\nhigh low+1.\n\u2212\nMoreover, thenumberofremainingcandidates isreduced byatleastone-halfwith\neachrecursive call. Specifically, fromthedefinition ofmid,thenumberofremain-\ningcandidates iseither\nlow+high high low+1\n(mid 1) low+1= low \u2212\n\u2212 \u2212 2 \u2212 \u2264 2\n(cid:22) (cid:23)\nor\nlow+high high low+1\nhigh (mid+1)+1=high \u2212 .\n\u2212 \u2212 2 \u2264 2\n(cid:22) (cid:23)\nInitially, the number of candidates is n; after the first call in a binary search, it is\nat most n/2; after the second call, it is at most n/4; and so on. In general, after\nthe jth call in a binary search, the number of candidate elements remaining is at\nmostn/2j. Intheworstcase(anunsuccessfulsearch),therecursivecallsstopwhen\nthere are no more candidate elements. Hence, the maximum number of recursive\ncallsperformed, isthesmallestintegerrsuchthat\nn\n<1.\n2r\nIn other words (recalling that we omit a logarithm\u2019s base when it is 2), r is the\nsmallestintegersuchthatr>logn. Thus,wehave\nr= logn +1,\n\u230a \u230b\nwhichimpliesthatbinarysearchrunsinO(logn)time.\nComputing Disk Space Usage\nOur final recursive algorithm from Section 5.1 was that for computing the overall\ndisk space usage in aspecified portion ofafilesystem. Tocharacterize the \u201cprob-\nlem size\u201d forour analysis, weletndenote thenumber of file-system entries inthe\nportionofthefilesystemthatisconsidered. (Forexample,thefilesystemportrayed\ninFigure5.6hasn=19entries.)\nTo characterize the cumulative time spent for an initial call to diskUsage, we\nmustanalyzethetotalnumberofrecursiveinvocationsthataremade,aswellasthe\nnumberofoperations thatareexecutedwithinthoseinvocations.\nWe begin by showing that there are precisely n recursive invocations of the\nmethod, in particular, one for each entry in the relevant portion of the file system.\nIntuitively, this is because a call to diskUsage for a particular entry e of the file\nsystemisonlymadefromwithintheforloopofCodeFragment5.5whenprocess-\ning the entry for the unique directory that contains e, and that entry will only be\nexploredonce.\nwww.it-ebooks.info\n5.2. AnalyzingRecursiveAlgorithms 205\nToformalize this argument, wecan definethe nestinglevelofeach entry such\nthat the entry on which webegin has nesting level 0, entries stored directly within\nithave nesting level1, entries stored withinthose entries have nesting level 2, and\nso on. We can prove by induction that there is exactly one recursive invocation of\ndiskUsageuponeachentryatnestinglevelk. Asabasecase,whenk=0,theonly\nrecursive invocation made is the initial one. As the inductive step, once we know\nthere is exactly one recursive invocation for each entry at nesting level k, we can\nclaim that there is exactly one invocation for each entry e at nesting level k+1,\nmadewithintheforloopfortheentryatlevelkthatcontainse.\nHaving established that there is one recursive call for each entry of the file\nsystem,wereturntothequestionoftheoverallcomputationtimeforthealgorithm.\nItwouldbegreatifwecouldarguethatwespendO(1)timeinanysingleinvocation\nof the method, but that is not the case. While there is a constant number of steps\nreflectedinthecalltoroot.length()tocomputethediskusagedirectlyatthatentry,\nwhentheentryisadirectory,thebodyofthediskUsagemethodincludesaforloop\nthat iterates over all entries that are contained within that directory. In the worst\ncase,itispossiblethatoneentryincludes n 1others.\n\u2212\nBasedonthisreasoning, wecouldconclude thatthereareO(n)recursive calls,\neach of which runs in O(n) time, leading to an overall running time that is O(n2).\nWhile this upper bound is technically true, it is not a tight upper bound. Remark-\nably, we can prove the stronger bound that the recursive algorithm for diskUsage\ncompletes in O(n) time! The weaker bound was pessimistic because it assumed\na worst-case number of entries for each directory. While it is possible that some\ndirectories contain a number of entries proportional to n, they cannot all contain\nthat many. Toprove the stronger claim, wechoose toconsider the overall number\nofiterations ofthe for loop across allrecursive calls. Weclaim there are precisely\nn 1 such iterations of that loop overall. We base this claim on the fact that each\n\u2212\niteration ofthatloop makes arecursive calltodiskUsage,and yetwehavealready\nconcluded thatthereareatotalofncallstodiskUsage(including theoriginalcall).\nWetherefore conclude thatthereareO(n)recursivecalls,eachofwhichusesO(1)\ntime outside the loop, and that the overall number of operations due to the loop\nisO(n). Summingallofthesebounds, theoverallnumberofoperations isO(n).\nThe argument we have made is more advanced than with the earlier examples\nof recursion. The idea that we can sometimes get a tighter bound on a series of\noperations by considering the cumulative effect, rather than assuming that each\nachieves a worst case is a technique called amortization; we will see another ex-\nample of such analysis in Section 7.2.3. Furthermore, a file system is an implicit\nexampleofadatastructure knownasatree, andourdiskusagealgorithm isreally\na manifestation of a more general algorithm known as a tree traversal. Trees will\nbe the focus of Chapter 8, and our argument about the O(n) running time of the\ndiskusagealgorithm willbegeneralized fortreetraversals inSection8.4.\nwww.it-ebooks.info\n206 Chapter5. Recursion\n5.3 Further Examples of Recursion\nInthissection,weprovideadditionalexamplesoftheuseofrecursion. Weorganize\nour presentation by considering the maximum number of recursive calls that may\nbestartedfromwithinthebodyofasingleactivation.\nIfarecursivecallstartsatmostoneother, wecallthisalinearrecursion.\n\u2022\nIfarecursivecallmaystarttwoothers,wecallthisabinaryrecursion.\n\u2022\nIfarecursivecallmaystartthreeormoreothers, thisismultiplerecursion.\n\u2022\n5.3.1 Linear Recursion\nIf a recursive method is designed so that each invocation of the body makes at\nmost one new recursive call, this is know as linear recursion. Of the recursions\nwehaveseensofar,theimplementationofthefactorialmethod(Section5.1.1)isa\nclear example of linear recursion. More interestingly, the binary search algorithm\n(Section 5.1.3) is also an example of linear recursion, despite the term \u201cbinary\u201d\nin the name. The code for binary search (Code Fragment 5.3) includes a case\nanalysis,withtwobranchesthatleadtoafurtherrecursivecall,butonlyonebranch\nisfollowedduringaparticular execution ofthebody.\nA consequence of the definition of linear recursion is that any recursion trace\nwillappearasasinglesequenceofcalls,asweoriginallyportrayedforthefactorial\nmethod in Figure 5.1 of Section 5.1.1. Note that the linear recursion terminol-\nogy reflects the structure of the recursion trace, not the asymptotic analysis of the\nrunning time;forexample,wehaveseenthatbinarysearchrunsinO(logn)time.\nSumming the Elements of an Array Recursively\nLinearrecursioncanbeausefultoolforprocessingasequence,suchasaJavaarray.\nSuppose, for example, that we want to compute the sum of an array of n integers.\nWe can solve this summation problem using linear recursion by observing that if\nn=0thesumistrivially 0,andotherwiseitisthesumofthefirstn 1integersin\n\u2212\nthearrayplusthelastvalueinthearray. (SeeFigure5.9.)\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n4 3 6 2 8 9 3 2 8 5 1 7 2 8 3 7\nFigure5.9: Computingthesumofasequencerecursively,byaddingthelastnumber\ntothesumofthefirstn 1.\n\u2212\nwww.it-ebooks.info\n5.3. FurtherExamplesofRecursion 207\nA recursive algorithm for computing the sum of an array of integers based on\nthisintuition isimplemented inCodeFragment5.6.\n1 /\u2217\u2217 Returns the sum of the first n integers of the given array. \u2217/\n2 public static int linearSum(int[ ] data, int n)\n{\n3 if (n == 0)\n4 return 0;\n5 else\n6 return linearSum(data, n 1) + data[n 1];\n\u2212 \u2212\n7\n}\nCodeFragment5.6: Summinganarrayofintegersusinglinearrecursion.\nA recursion trace of the linearSum method for a small example is given in\nFigure 5.10. For an input of size n, the linearSum algorithm makes n+1 method\ncalls. Hence, it will take O(n) time, because it spends a constant amount of time\nperforming the nonrecursive part of each call. Moreover, we can also see that the\nmemory space used by the algorithm (in addition to the array) is also O(n), as we\nuseaconstant amountofmemoryspaceforeachofthen+1framesinthetraceat\nthetimewemakethefinalrecursivecall(withn=0).\nreturn 15 + data[4] = 15 + 8 = 23\nlinearSum(data, 5)\nreturn 13 + data[3] = 13 + 2 = 15\nlinearSum(data, 4)\nreturn 7 + data[2] = 7 + 6 = 13\nlinearSum(data, 3)\nreturn 4 + data[1] = 4 + 3 = 7\nlinearSum(data, 2)\nreturn 0 + data[0] = 0 + 4 = 4\nlinearSum(data, 1)\nreturn 0\nlinearSum(data, 0)\nFigure 5.10: Recursion trace for an execution of linearSum(data, 5) with input\nparameterdata = 4, 3, 6, 2, 8.\nwww.it-ebooks.info\n208 Chapter5. Recursion\nReversing a Sequence with Recursion\nNext, let us consider the problem of reversing the n elements of an array, so that\nthe first element becomes the last, the second element becomes second to the last,\nandsoon. Wecansolvethis problem usinglinear recursion, byobserving thatthe\nreversal ofasequence canbeachieved byswapping thefirstandlastelements and\nthen recursively reversing the remaining elements. We present an implementation\nofthisalgorithm inCodeFragment5.7,using theconvention thatthefirsttimewe\ncallthisalgorithm wedosoasreverseArray(data, 0, n 1).\n\u2212\n1 /\u2217\u2217 Reverses the contents of subarray data[low] through data[high] inclusive. \u2217/\n2 public static void reverseArray(int[ ] data, int low, int high)\n{\n3 if (low < high) // if at least two elements in subarray\n{\n4 int temp = data[low]; // swap data[low] and data[high]\n5 data[low] = data[high];\n6 data[high] = temp;\n7 reverseArray(data, low + 1, high 1); // recur on the rest\n\u2212\n8\n}\n9\n}\nCodeFragment5.7: Reversingtheelementsofanarrayusinglinearrecursion.\nWenotethatwheneverarecursivecallismade,therewillbetwofewerelements\nin the relevant portion of the array. (See Figure 5.11.) Eventually a base case is\nreached when the condition low < high fails, either because low == high in the\ncasethatnisodd,orbecause low == high + 1inthecasethatniseven.\nTheaboveargumentimpliesthattherecursivealgorithmofCodeFragment5.7\nisguaranteedtoterminateafteratotalof1+ n recursivecalls. Becauseeachcall\n2\ninvolves aconstant amountofwork,theentireprocessrunsinO(n)time.\n(cid:4) (cid:5)\n0 1 2 3 4 5 6 7\n4 3 6 2 7 8 9 5\n5 3 6 2 7 8 9 4\n5 9 6 2 7 8 3 4\n5 9 8 2 7 6 3 4\n5 9 8 7 2 6 3 4\nFigure 5.11: A trace of the recursion for reversing a sequence. The highlighted\nportionhasyettobereversed.\nwww.it-ebooks.info\n5.3. FurtherExamplesofRecursion 209\nRecursive Algorithms for Computing Powers\nAsanotherinterestingexampleoftheuseoflinearrecursion,weconsidertheprob-\nlem of raising a number x to an arbitrary nonnegative integer n. That is, we wish\nto compute the power function, defined as power(x,n) =xn. (We use the name\n\u201cpower\u201dforthisdiscussion,todifferentiatefromthepowmethodoftheMathclass,\nwhich provides such functionality.) We will consider two different recursive for-\nmulationsfortheproblem thatleadtoalgorithms withverydifferent performance.\nAtrivialrecursivedefinition followsfromthefactthatxn=x xn\u22121 forn>0.\n\u00b7\n1 ifn=0\npower(x,n)=\nx power(x,n 1) otherwise.\n(cid:26) \u00b7 \u2212\nThisdefinition leadstoarecursivealgorithm showninCodeFragment5.8.\n1 /\u2217\u2217 Computes the value of x raised to the nth power, for nonnegative integer n. \u2217/\n2 public static double power(double x, int n)\n{\n3 if (n == 0)\n4 return 1;\n5 else\n6 return x \u2217 power(x, n 1);\n\u2212\n7\n}\nCodeFragment5.8: Computingthepowerfunctionusingtrivialrecursion.\nA recursive call to this version of power(x,n) runs in O(n) time. Its recursion\ntrace has structure very similar to that of the factorial function from Figure 5.1,\nwiththeparameterdecreasing byonewitheachcall,andconstant workperformed\nateachofn+1levels.\nHowever, there is a much faster way to compute the power function using an\nalternative definition that employs a squaring technique. Let k = n denote the\n2\nflooroftheintegerdivision(equivalentton/2inJavawhennisanint). Weconsider\n(cid:4) (cid:5)\n2\ntheexpression xk 2 . Whenniseven, n = n andtherefore xk 2 = x n 2 =xn.\n2 2\nWhen n is odd,(cid:0) n (cid:1) = n\u22121 and xk 2 =(cid:4) x(cid:5) n\u22121, and therefore x(cid:0) n=(cid:1) xk(cid:16)2 x(cid:17), just as\n2 2 \u00b7\n213= 26 26 2. Thisanalysisleadstothefollowingrecursivedefinition:\n\u00b7 \u00b7 (cid:4) (cid:5) (cid:0) (cid:1) (cid:0) (cid:1)\n(cid:0) (cid:1) 1 ifn=0\npower(x,n)= power x, n 2 x ifn>0isodd\n\uf8f1 2 \u00b7\n\uf8f4 \uf8f2 power x, n 2 ifn>0iseven\n(cid:0) (cid:0) (cid:4)2(cid:5)(cid:1)(cid:1)\nIf wewere to implemen\uf8f4t th(cid:0)is recur(cid:0)sio(cid:4)n m(cid:5)(cid:1)a(cid:1)king tworecursive calls to compute\n\uf8f3\npower(x, n ) power(x, n ), a trace of the recursion would demonstrate O(n)\n2 \u00b7 2\ncalls. We can perform significantly fewer operations by computing power(x, n )\n(cid:4) (cid:5) (cid:4) (cid:5) 2\nand storing it in avariable as a partial result, and then multiplying it by itself. An\n(cid:4) (cid:5)\nimplementation basedonthisrecursivedefinitionisgiveninCodeFragment5.9.\nwww.it-ebooks.info\n210 Chapter5. Recursion\n1 /\u2217\u2217 Computes the value of x raised to the nth power, for nonnegative integer n. \u2217/\n2 public static double power(double x, int n)\n{\n3 if (n == 0)\n4 return 1;\n5 else\n{\n6 double partial = power(x, n/2); // rely on truncated division of n\n7 double result = partial \u2217 partial;\n8 if (n % 2 == 1) // if n odd, include extra factor of x\n9 result \u2217= x;\n10 return result;\n11\n}\n12\n}\nCodeFragment5.9: Computingthepowerfunctionusingrepeated squaring.\nTo illustrate the execution of our improved algorithm, Figure 5.12 provides a\nrecursion traceofthecomputation power(2, 13).\nreturn 64 \u2217 64 \u2217 2 = 8192\npower(2, 13)\nreturn 8 \u2217 8 = 64\npower(2, 6)\nreturn 2 \u2217 2 \u2217 2 = 8\npower(2, 3)\nreturn 1 \u2217 1 \u2217 2 = 2\npower(2, 1)\nreturn 1\npower(2, 0)\nFigure5.12: Recursion traceforanexecution ofpower(2, 13).\nTo analyze the running time of the revised algorithm, we observe that the ex-\nponentineachrecursivecallofmethodpower(x,n)isatmosthalfofthepreceding\nexponent. Aswe saw with the analysis of binary search, the number of times that\nwecandividenbytwobeforegettingtooneorlessisO(logn). Therefore,ournew\nformulation ofpowerresultsinO(logn)recursivecalls. Eachindividual activation\nof the method uses O(1) operations (excluding the recursive call), and so the total\nnumber of operations for computing power(x,n) is O(logn). This is a significant\nimprovementovertheoriginal O(n)-timealgorithm.\nTheimprovedversion alsoprovides significant savinginreducing thememory\nusage. Thefirst version has a recursive depth of O(n), and therefore, O(n) frames\naresimultaneously storedinmemory. Becausetherecursivedepthoftheimproved\nversionisO(logn),itsmemoryusageisO(logn)aswell.\nwww.it-ebooks.info\n5.3. FurtherExamplesofRecursion 211\n5.3.2 Binary Recursion\nWhen a method makes two recursive calls, we say that it uses binary recursion.\nWe have already seen an example of binary recursion when drawing the English\nruler (Section 5.1.2). As another application of binary recursion, let us revisit the\nproblem ofsummingthenintegers ofanarray. Computingthesum ofoneorzero\nvalues istrivial. With twoor more values, wecan recursively compute the sum of\nthe first half, and the sum of the second half, and add those sums together. Our\nimplementation of such an algorithm, in Code Fragment 5.10, is initially invoked\nasbinarySum(data, 0, n 1).\n\u2212\n1 /\u2217\u2217 Returns the sum of subarray data[low] through data[high] inclusive. \u2217/\n2 public static int binarySum(int[ ] data, int low, int high)\n{\n3 if (low > high) // zero elements in subarray\n4 return 0;\n5 else if (low == high) // one element in subarray\n6 return data[low];\n7 else\n{\n8 int mid = (low + high) / 2;\n9 return binarySum(data, low, mid) + binarySum(data, mid+1, high);\n10\n}\n11\n}\nCodeFragment5.10: Summingtheelementsofasequence usingbinaryrecursion.\nTo analyze algorithm binarySum, we consider, for simplicity, the case where\nn is a power of two. Figure 5.13 shows the recursion trace of an execution of\nbinarySum(data, 0, 7). We label each box with the values of parameters low and\nhigh for that call. The size of the range is divided in half at each recursive call,\nandsothedepthoftherecursionis1+log n. Therefore, binarySumusesO(logn)\n2\namount of additional space, which isabig improvement over theO(n) space used\nby the linearSum method of Code Fragment 5.6. However, the running time of\nbinarySumisO(n),asthereare2n 1methodcalls,eachrequiring constant time.\n\u2212\n0,7\n0,3 4,7\n0,1 2,3 4,5 6,7\n0,0 1,1 2,2 3,3 4,4 5,5 6,6 7,7\nFigure5.13: Recursion tracefortheexecution ofbinarySum(data, 0, 7).\nwww.it-ebooks.info\n212 Chapter5. Recursion\n5.3.3 Multiple Recursion\nGeneralizing from binary recursion, we define multiple recursion as a process in\nwhich a method may make more than two recursive calls. Our recursion for an-\nalyzing the disk space usage of a file system (see Section 5.1.4) is an example of\nmultiplerecursion, because thenumberofrecursive callsmadeduringoneinvoca-\ntionwasequaltothenumberofentrieswithinagivendirectoryofthefilesystem.\nAnothercommonapplicationofmultiplerecursioniswhenwewanttoenumer-\nate various configurations in order to solve a combinatorial puzzle. For example,\nthefollowingareallinstances ofwhatareknownassummationpuzzles:\npot + pan = bib\ndog+cat = pig\nboy+girl = baby\nTosolvesuchapuzzle, weneedtoassignauniquedigit(thatis,0,1,...,9)toeach\nletter inthe equation, inorder tomake the equation true. Typically, wesolve such\napuzzle byusingourhumanobservations oftheparticular puzzle wearetrying to\nsolve to eliminate configurations (that is, possible partial assignments of digits to\nletters) until we can work through the feasible configurations that remain, testing\nforthecorrectness ofeachone.\nIf the number of possible configurations is not too large, however, we can use\nacomputertosimplyenumerateallthepossibilities andtesteachone,withoutem-\nploying any human observations. Such an algorithm can use multiple recursion\nto work through the configurations in a systematic way. To keep the description\ngeneral enough to be used with other puzzles, we consider an algorithm that enu-\nmerates and tests all k-length sequences, without repetitions, chosen from a given\nuniverse U. We show pseudocode for such an algorithm in Code Fragment 5.11,\nbuilding thesequence ofkelementswiththefollowingsteps:\n1. Recursively generating thesequences ofk 1elements\n\u2212\n2. Appending toeachsuchsequence anelementnotalreadycontained init.\nThroughout the execution of the algorithm, we use a set U to keep track of the\nelements not contained in the current sequence, so that an element e has not been\nusedyetifandonlyifeisinU.\nAnotherwaytolookatthealgorithm ofCodeFragment5.11isthatitenumer-\nates every possible size-k ordered subset of U, and tests each subset for being a\npossible solutiontoourpuzzle.\nFor summation puzzles, U = 0,1,2,3,4,5,6,7,8,9 and each position in the\n{ }\nsequence corresponds to a given letter. Forexample, the first position could stand\nforb,thesecond foro,thethirdfory,andsoon.\nwww.it-ebooks.info\n5.3. FurtherExamplesofRecursion 213\nAlgorithmPuzzleSolve(k, S,U):\nInput: Anintegerk,sequence S,andsetU\nOutput: An enumeration of all k-length extensions to S using elements in U\nwithoutrepetitions\nforeacheinU do\nAddetotheendofS\nRemoveefromU eisnowbeingused\n{ }\nifk==1then\nTestwhetherSisaconfiguration thatsolvesthepuzzle\nifSsolvesthepuzzlethen\naddStooutput asolution\n{ }\nelse\nPuzzleSolve(k 1,S,U) arecursivecall\n\u2212 { }\nRemoveefromtheendofS\nAddebacktoU eisnowconsidered asunused\n{ }\nCode Fragment 5.11: Solving a combinatorial puzzle by enumerating and testing\nallpossibleconfigurations.\nIn Figure 5.14, we show a recursion trace of a call to PuzzleSolve(3, S, U),\nwhere S is empty and U = a,b,c . During the execution, all the permutations\n{ }\nof the three characters are generated and tested. Note that the initial call makes\nthree recursive calls, each of which in turn makes two more. If we had executed\nPuzzleSolve(3,S,U)ona setU consisting of four elements, the initial call would\nhave made four recursive calls, each of which would have a trace looking like the\noneinFigure5.14.\ninitialcall\nPuzzleSolve(3,(),{a,b,c})\nPuzzleSolve(2,a,{b,c}) PuzzleSolve(2,b,{a,c}) PuzzleSolve(2,c,{a,b})\nPuzzleSolve(1,ab,{c}) PuzzleSolve(1,ba,{c}) PuzzleSolve(1,ca,{b})\nabc bac cab\nPuzzleSolve(1,ac,{b}) PuzzleSolve(1,bc,{a}) PuzzleSolve(1,cb,{a})\nacb bca cba\nFigure5.14: Recursion trace for an execution of PuzzleSolve(3, S,U), where S is\nemptyandU= a,b,c . Thisexecutiongeneratesandtestsallpermutationsofa,b,\n{ }\nandc. Weshowthepermutations generated directlybelowtheirrespective boxes.\nwww.it-ebooks.info\n214 Chapter5. Recursion\n5.4 Designing Recursive Algorithms\nAnalgorithm thatusesrecursion typically hasthefollowingform:\nTestforbasecases. Webeginbytestingforasetofbasecases(thereshould\n\u2022\nbe at least one). These base cases should be defined so that every possible\nchainofrecursivecallswilleventuallyreachabasecase,andthehandlingof\neachbasecaseshouldnotuserecursion.\nRecur. Ifnotabasecase,weperformoneormorerecursivecalls. Thisrecur-\n\u2022\nsive step may involve a test that decides which of several possible recursive\ncallstomake. Weshoulddefineeachpossible recursive callsothatitmakes\nprogress towardsabasecase.\nParameterizing a Recursion\nTo design a recursive algorithm for a given problem, it is useful to think of the\ndifferent ways we might define subproblems that have the same general structure\nastheoriginalproblem. Ifonehasdifficultyfindingtherepetitivestructure needed\ntodesign arecursive algorithm, itis sometimes useful towork out theproblem on\nafewconcreteexamplestoseehowthesubproblems shouldbedefined.\nA successful recursive design sometimes requires that we redefine the origi-\nnal problem to facilitate similar-looking subproblems. Often, this involved repa-\nrameterizing the signature of the method. For example, when performing a bi-\nnary search in an array, a natural method signature for a caller would appear as\nbinarySearch(data, target). However, in Section 5.1.3, we defined our method\nwith calling signature binarySearch(data, target, low, high), using the additional\nparameters to demarcate subarrays as the recursion proceeds. This change in pa-\nrameterization is critical for binary search. Several other examples in this chapter\n(e.g.,reverseArray,linearSum,binarySum)alsodemonstratedtheuseofadditional\nparameters indefiningrecursivesubproblems.\nIfwewishtoprovideacleanerpublic interface toanalgorithm withoutexpos-\ning the user to the recursive parameterization, a standard technique is to make the\nrecursive version private, and to introduce a cleaner public method (that calls the\nprivate onewithappropriate parameters). Forexample, wemightofferthefollow-\ningsimplerversionofbinarySearchforpublicuse:\n/\u2217\u2217 Returns true if the target value is found in the data array. \u2217/\npublic static boolean binarySearch(int[ ] data, int target)\n{\nreturn binarySearch(data, target, 0, data.length 1); // use parameterized version\n\u2212\n}\nwww.it-ebooks.info\n5.5. RecursionRunAmok 215\n5.5 Recursion Run Amok\nAlthough recursion is a very powerful tool, it can easily be misused in various\nways. Inthissection, weexamineseveralcasesinwhichapoorlyimplementedre-\ncursion causes drastic inefficiency, and wediscuss somestrategies forrecognizing\nandavoidsuchpitfalls.\nWe begin by revisiting the element uniqueness problem, defined on page 174\nof Section 4.3.3. We can use the following recursive formulation to determine if\nallnelements ofasequence are unique. Asabasecase, whenn=1, theelements\naretriviallyunique. Forn 2,theelementsareuniqueifandonlyifthefirstn 1\n\u2265 \u2212\nelements areunique, thelastn 1itemsareunique, andthefirstandlastelements\n\u2212\naredifferent (asthatistheonlypairthatwasnotalready checked asasubcase). A\nrecursiveimplementationbasedonthisideaisgiveninCodeFragment5.12,named\nunique3(todifferentiate itfromunique1andunique2fromChapter4).\n1 /\u2217\u2217 Returns true if there are no duplicate values from data[low] through data[high].\u2217/\n2 public static boolean unique3(int[ ] data, int low, int high)\n{\n3 if (low >= high) return true; // at most one item\n4 else if (!unique3(data, low, high 1)) return false; // duplicate in first n 1\n\u2212 \u2212\n5 else if (!unique3(data, low+1, high)) return false; // duplicate in last n 1\n\u2212\n6 else return (data[low] != data[high]); // do first and last differ?\n7\n}\nCodeFragment5.12: Recursiveunique3fortestingelementuniqueness.\nUnfortunately, this is a terribly inefficient use of recursion. The nonrecursive\npartofeachcallusesO(1)time,sotheoverallrunningtimewillbeproportional to\nthetotalnumberofrecursive invocations. Toanalyze theproblem, weletndenote\nthenumberofentriesunderconsideration, thatis,letn=1 + high low.\n\u2212\nIfn=1,thentherunning timeofunique3isO(1),sincetherearenorecursive\ncallsforthiscase. Inthegeneralcase,theimportantobservationisthatasinglecall\ntounique3foraproblemofsizenmayresultintworecursivecallsonproblemsof\nsize n 1. Those two calls with size n 1 could in turn result in four calls (two\n\u2212 \u2212\neach) with a range of size n 2, and thus eight calls with size n 3 and so on.\n\u2212 \u2212\nThus,intheworstcase,thetotalnumberofmethodcallsisgivenbythegeometric\nsummation\n1+2+4+ +2n\u22121,\n\u00b7\u00b7\u00b7\nwhich is equal to 2n 1 by Proposition 4.5. Thus, the running time of method\n\u2212\nunique3 is O(2n). This is an incredibly inefficient method for solving the ele-\nment uniqueness problem. Its inefficiency comes not from the fact that it uses\nrecursion\u2014it comesfromthefactthatitusesrecursionpoorly, whichissomething\nweaddressinExerciseC-5.12.\nwww.it-ebooks.info\n216 Chapter5. Recursion\nAn Inefficient Recursion for Computing Fibonacci Numbers\nIn Section 2.2.3, we introduced a process for generating the progression of Fi-\nbonaccinumbers, whichcanbedefinedrecursively asfollows:\nF = 0\n0\nF = 1\n1\nF = F +F forn>1.\nn n\u22122 n\u22121\nIronically,arecursiveimplementationbaseddirectlyonthisdefinitionresultsinthe\nmethod fibonacciBadshowninCodeFragment 5.13, whichcomputes aFibonacci\nnumberbymakingtworecursivecallsineachnon-base case.\n1 /\u2217\u2217 Returns the nth Fibonacci number (inefficiently). \u2217/\n2 public static long fibonacciBad(int n)\n{\n3 if (n <= 1)\n4 return n;\n5 else\n6 return fibonacciBad(n 2) + fibonacciBad(n 1);\n\u2212 \u2212\n7\n}\nCodeFragment5.13: Computingthenth Fibonaccinumberusingbinaryrecursion.\nUnfortunately, such a direct implementation of the Fibonacci formula results\nin a terribly inefficient method. Computing the nth Fibonacci number in this way\nrequires an exponential number of calls to the method. Specifically, let c denote\nn\nthenumberofcallsperformedintheexecutionoffibonacciBad(n). Then,wehave\nthefollowingvaluesforthec \u2019s:\nn\nc = 1\n0\nc = 1\n1\nc = 1+c +c =1+1+1=3\n2 0 1\nc = 1+c +c =1+1+3=5\n3 1 2\nc = 1+c +c =1+3+5=9\n4 2 3\nc = 1+c +c =1+5+9=15\n5 3 4\nc = 1+c +c =1+9+15=25\n6 4 5\nc = 1+c +c =1+15+25=41\n7 5 6\nc = 1+c +c =1+25+41=67\n8 6 7\nIfwefollowthepatternforward,weseethatthenumberofcallsmorethandoubles\nforeachtwoconsecutive indices. Thatis,c ismorethantwicec ,c ismorethan\n4 2 5\ntwice c , c is more than twice c , and so on. Thus, c >2n/2, which means that\n3 6 4 n\nfibonacciBad(n)makesanumberofcallsthatisexponential inn.\nwww.it-ebooks.info\n5.5. RecursionRunAmok 217\nAn Efficient Recursion for Computing Fibonacci Numbers\nWe were tempted into using the bad recursive formulation because of the way the\nnth Fibonaccinumber,F ,depends onthetwopreviousvalues, F andF . But\nn n\u22122 n\u22121\nnoticethataftercomputingF ,thecalltocomputeF requiresitsownrecursive\nn\u22122 n\u22121\ncall to compute F , as it does not have knowledge of the value of F that was\nn\u22122 n\u22122\ncomputedattheearlierlevelofrecursion. Thatisduplicativework. Worseyet,both\nof those calls will need to (re)compute the value of F , as will the computation\nn\u22123\nof F . This snowballing effect is what leads to the exponential running time of\nn\u22121\nfibonacciBad.\nWe can compute F much more efficiently using a recursion in which each\nn\ninvocation makesonlyonerecursive call. Todoso,weneedtoredefinetheexpec-\ntations of the method. Rather than having the method return asingle value, which\nisthenthFibonaccinumber,wedefinearecursivemethodthatreturnsanarraywith\ntwoconsecutive Fibonaccinumbers F ,F ,usingtheconvention F =0. Al-\nn n\u22121 \u22121\n{ }\nthoughitseemstobeagreaterburdentoreporttwoconsecutiveFibonaccinumbers\ninsteadofone,passingthisextrainformation fromoneleveloftherecursion tothe\nnext makes it much easier to continue the process. (It allows us to avoid having\nto recompute the second value that was already known within the recursion.) An\nimplementation basedonthisstrategyisgiveninCodeFragment5.14.\n1 /\u2217\u2217 Returns array containing the pair of Fibonacci numbers, F(n) and F(n 1). \u2217/\n\u2212\n2 public static long[ ] fibonacciGood(int n)\n{\n3 if (n <= 1)\n{\n4 long[ ] answer = n, 0 ;\n{ }\n5 return answer;\n6 else\n} {\n7 long[ ] temp = fibonacciGood(n 1); // returns F n\u22121 ,F n\u22122\n\u2212 { }\n8 long[ ] answer = temp[0] + temp[1], temp[0] ; // we want F n ,F n\u22121\n{ } { }\n9 return answer;\n10\n}\n11\n}\nCodeFragment5.14: Computingthenth Fibonaccinumberusinglinearrecursion.\nIn terms of efficiency, the difference between the bad and good recursions for\nthis problem is like night and day. The fibonacciBad method uses exponential\ntime. Weclaim that theexecution ofmethod fibonacciGood(n)runs inO(n)time.\nEach recursive call to fibonacciGood decreases the argument n by 1; therefore, a\nrecursion traceincludes aseries ofnmethodcalls. Because thenonrecursive work\nforeachcallusesconstant time,theoverallcomputation executesinO(n)time.\nwww.it-ebooks.info\n218 Chapter5. Recursion\n5.5.1 Maximum Recursive Depth in Java\nAnother danger in the misuse of recursion is known as infinite recursion. If each\nrecursivecallmakesanotherrecursivecall,withouteverreaching abasecase,then\nwe have an infinite series of such calls. This is a fatal error. An infinite recursion\ncan quickly swamp computing resources, not only due to rapid use of the CPU,\nbut because each successive call creates a frame requiring additional memory. A\nblatantexampleofanill-formedrecursion isthefollowing:\n1 /\u2217\u2217 Don't call this (infinite) version. \u2217/\n2 public static int fibonacci(int n)\n{\n3 return fibonacci(n); // After all F does equal F\nn n\n4\n}\nHowever, there are far more subtle errors that can lead to an infinite recursion.\nRevisiting our implementation of binary search (Code Fragment 5.3), when we\nmakearecursive callontherightportion ofthesequence (line15), wespecify the\nsubarray fromindexmid+1tohigh. Hadthatlineinsteadbeenwrittenas\nreturn binarySearch(data, target, mid, high); // sending mid, not mid+1\nthis could result in an infinite recursion. In particular, when searching a range of\ntwoelements, itbecomespossible tomakearecursivecallontheidenticalrange.\nAprogrammer should ensure thateach recursive callisinsomewayprogress-\ning toward a base case (for example, by having a parameter value that decreases\nwith each call). To combat against infinite recursions, the designers of Java made\nan intentional decision to limit the overall space used to store activation frames\nfor simultaneously active method calls. If this limit is reached, the Java Virtual\nMachine throws a StackOverflowError. (We will further discuss the \u201cstack\u201d data\nstructure in Section 6.1.) The precise value of this limit depends upon the Java\ninstallation, butatypicalvaluemightallowupwardof1000simultaneous calls.\nFor many applications of recursion, allowing up to 1000 nested calls suffices.\nForexample,ourbinarySearchmethod(Section5.1.3)hasO(logn)recursivedepth,\nand so for the default recursive limit to be reached, there would need to be 21000\nelements (far,farmorethantheestimated numberofatomsintheuniverse). How-\never, wehave seen several linear recursions that have recursive depth proportional\nton. Java\u2019slimitontherecursivedepthmightdisruptsuchcomputations.\nItispossibletoreconfiguretheJavaVirtualMachinesothatitallowsforgreater\nspacetobedevotedtonestedmethodcalls. Thisisdonebysettingthe-Xssruntime\noption when starting Java, either asacommand-line option orthrough thesettings\nofanIDE.Butitoften possible torely upon theintuition ofarecursive algorithm,\nyettoreimplementitmoredirectlyusingtraditional loopsratherthanmethodcalls\nto express the necessary repetition. We discuss just such an approach to conclude\nthechapter.\nwww.it-ebooks.info\n5.6. EliminatingTailRecursion 219\n5.6 Eliminating Tail Recursion\nThemainbenefit ofarecursive approach toalgorithm design isthatitallowsusto\nsuccinctly take advantage of a repetitive structure present in many problems. By\nmakingouralgorithmdescriptionexploittherepetitivestructureinarecursiveway,\nwe can often avoid complex case analyses and nested loops. This approach can\nleadtomorereadable algorithm descriptions, whilestillbeingquiteefficient.\nHowever, the usefulness of recursion comes at a modest cost. In particular,\ntheJavaVirtualMachine mustmaintain framesthat keeptrack ofthestate ofeach\nnestedcall. Whencomputermemoryisatapremium,itcanbebeneficialtoderive\nnonrecursive implementations ofrecursivealgorithms.\nIn general, we can use the stack data structure, which we will introduce in\nSection6.1,toconvertarecursivealgorithmintoanonrecursivealgorithmbyman-\naging the nesting of the recursive structure ourselves, rather than relying on the\ninterpreter to do so. Although this only shifts the memory usage from the inter-\npreter toourstack, wemaybeabletofurther reduce thememoryusage bystoring\ntheminimalinformation necessary.\nEvenbetter,someformsofrecursioncanbeeliminatedwithoutanyuseofaux-\niliary memory. One such form is known as tail recursion. A recursion is a tail\nrecursion ifanyrecursive call thatismadefromonecontext istheverylastopera-\ntioninthatcontext, withthereturnvalue oftherecursive call(ifany)immediately\nreturned by the enclosing recursion. By necessity, a tail recursion must be a lin-\near recursion (since there is no way to make a second recursive call if you must\nimmediatelyreturntheresultofthefirst).\nOftherecursivemethodsdemonstratedinthischapter,thebinarySearchmethod\nof Code Fragment 5.3 and the reverseArray method of Code Fragment 5.7 are ex-\namples of tail recursion. Several others of our linear recursions are almost like\ntail recursion, but not technically so. For example, our factorial method of Code\nFragment5.1isnotatailrecursion. Itconcludes withthecommand:\nreturn n \u2217 factorial(n 1);\n\u2212\nThis is not a tail recursion because an additional multiplication is performed after\ntherecursive calliscompleted, andtheresult returned isnotthesame. Forsimilar\nreasons, the linearSum method of Code Fragment 5.6, both power methods from\nCodeFragments5.8and5.9,andthefibonacciGoodmethodofCodeFragment5.13\nfailtobetailrecursions.\nTailrecursions arespecial, astheycanbeautomatically reimplemented nonre-\ncursively by enclosing the body in a loop for repetition, and replacing a recursive\ncall with new parameters by a reassignment of the existing parameters to those\nvalues. In fact, many programming language implementations may convert tail\nrecursions inthiswayasanoptimization.\nwww.it-ebooks.info\n220 Chapter5. Recursion\n1 /\u2217\u2217 Returns true if the target value is found in the data array. \u2217/\n2 public static boolean binarySearchIterative(int[ ] data, int target)\n{\n3 int low = 0;\n4 int high = data.length 1;\n\u2212\n5 while (low <= high)\n{\n6 int mid = (low + high) / 2;\n7 if (target == data[mid]) // found a match\n8 return true;\n9 else if (target < data[mid])\n10 high = mid 1; // only consider values left of mid\n\u2212\n11 else\n12 low = mid + 1; // only consider values right of mid\n13\n}\n14 return false; // loop ended without success\n15\n}\nCodeFragment5.15: Anonrecursive implementation ofbinarysearch.\nAs a tangible example, our binarySearch method can be reimplemented as\nshown in Code Fragment 5.15. We initialize variables low and high to represent\nthe full extent of the array just prior to our while loop. Then, during each pass of\nthe loop, we either find the target, or we narrow the range of the candidate subar-\nray. Where we made the recursive call binarySearch(data, target, low, mid 1)\n\u2212\nin the original version, we simply replace high = mid 1 in our new version\n\u2212\nand then continue to the next iteration of the loop. Our original base case con-\ndition of low > high has simply been replaced by the opposite loop condition,\nwhile low <= high. In our new implementation, we return false to designate a\nfailedsearchifthewhileloopendswithouthavingeverreturnedtruefromwithin.\nMost other linear recursions can be expressed quite efficiently with iteration,\neveniftheywerenotformallytailrecursions. Forexample,therearetrivialnonre-\ncursive implementations for computing factorials, computing Fibonacci numbers,\nsumming elements ofan array, or reversing thecontents ofan array. Forexample,\nCode Fragment 5.16 provides anonrecursive method to reverse the contents of an\narray(ascomparedtotheearlierrecursivemethodfromCodeFragment5.7).\n1 /\u2217\u2217 Reverses the contents of the given array. \u2217/\n2 public static void reverseIterative(int[ ] data)\n{\n3 int low = 0, high = data.length 1;\n\u2212\n4 while (low < high) // swap data[low] and data[high]\n{\n5 int temp = data[low];\n6 data[low++] = data[high]; // post-increment of low\n7 data[high ] = temp; // post-decrement of high\n\u2212\u2212\n8\n}\n9\n}\nCodeFragment5.16: Reversingtheelementsofasequenceusingiteration.\nwww.it-ebooks.info\n5.7. Exercises 221\n5.7 Exercises\nReinforcement\nR-5.1 Describearecursivealgorithmforfindingthemaximumelementinanarray,A,\nofnelements. Whatisyourrunningtimeandspaceusage?\nR-5.2 Explainhowtomodifytherecursivebinarysearchalgorithmsothatitreturnsthe\nindexofthetargetinthesequenceor 1(ifthetargetisnotfound).\n\u2212\nR-5.3 Drawtherecursiontraceforthecomputationofpower(2,5),usingthetraditional\nalgorithmimplementedinCodeFragment5.8.\nR-5.4 Drawtherecursiontraceforthecomputationofpower(2,18),usingtherepeated\nsquaringalgorithm,asimplementedinCodeFragment5.9.\nR-5.5 Draw the recursion trace for the execution of reverseArray(data, 0, 4), from\nCodeFragment5.7,onarraydata = 4, 3, 6, 2, 6.\nR-5.6 DrawtherecursiontracefortheexecutionofmethodPuzzleSolve(3,S,U),from\nCodeFragment5.11,whereSisemptyandU = a,b,c,d .\n{ }\nR-5.7 DescribearecursivealgorithmforcomputingthenthHarmonicnumber,defined\nasH =\u2211n 1/k.\nn k=1\nR-5.8 Describearecursivealgorithmforconvertingastringofdigitsintotheintegerit\nrepresents.Forexample,'13531'representstheinteger13,531.\nR-5.9 Developanonrecursiveimplementationoftheversionofthepowermethodfrom\nCodeFragment5.9thatusesrepeatedsquaring.\nR-5.10 Describe a way to use recursion to compute the sum of all the elements in an\nn n(two-dimensional)arrayofintegers.\n\u00d7\nCreativity\nC-5.11 Describearecursivealgorithmtocomputetheintegerpartofthebase-twologa-\nrithmofnusingonlyadditionandintegerdivision.\nC-5.12 Describe an efficient recursive algorithm for solving the element uniqueness\nproblem,whichrunsintimethatisatmostO(n2)intheworstcasewithoutusing\nsorting.\nC-5.13 Givearecursivealgorithmtocomputetheproductoftwopositiveintegers,mand\nn,usingonlyadditionandsubtraction.\nC-5.14 InSection5.2weprovebyinductionthatthenumberoflinesprintedbyacallto\ndrawInterval(c)is2c 1. Anotherinterestingquestionishowmanydashesare\n\u2212\nprintedduringthatprocess.Provebyinductionthatthenumberofdashesprinted\nbydrawInterval(c)is2c+1 c 2.\n\u2212 \u2212\nwww.it-ebooks.info\n222 Chapter5. Recursion\nC-5.15 Write a recursivemethod that will outputall the subsets of a set of n elements\n(withoutrepeatinganysubsets).\nC-5.16 IntheTowersofHanoipuzzle,wearegivenaplatformwiththreepegs,a,b,and\nc,stickingoutofit. Onpegaisastackofndisks,eachlargerthanthenext,so\nthatthesmallestisonthetopandthelargestisonthebottom. Thepuzzleisto\nmove all the disks from peg a to peg c, moving one disk at a time, so that we\nneverplacealargerdiskontopofasmallerone.SeeFigure5.15foranexample\nofthecasen=4.DescribearecursivealgorithmforsolvingtheTowersofHanoi\npuzzleforarbitraryn. (Hint: Considerfirstthesubproblemofmovingallbut\nthenth diskfrompegatoanotherpegusingthethirdas\u201ctemporarystorage.\u201d)\nFigure5.15: Anillustration oftheTowersofHanoipuzzle.\nC-5.17 WriteashortrecursiveJavamethodthattakesacharacterstringsandoutputsits\nreverse.Forexample,thereverseof'pots&pans'wouldbe'snap&stop'.\nC-5.18 WriteashortrecursiveJavamethodthatdeterminesifastringsisapalindrome,\nthat is, it is equalto its reverse. Examplesof palindromesinclude 'racecar'\nand'gohangasalamiimalasagnahog'.\nC-5.19 UserecursiontowriteaJavamethodfordeterminingifastringshasmorevowels\nthanconsonants.\nC-5.20 WriteashortrecursiveJavamethodthatrearrangesanarrayofintegervaluesso\nthatalltheevenvaluesappearbeforealltheoddvalues.\nC-5.21 Given an unsorted array, A, of integers and an integer k, describe a recursive\nalgorithmforrearrangingtheelementsinAsothatallelementslessthanorequal\nto k come beforeanyelementslargerthan k. Whatis the runningtime of your\nalgorithmonanarrayofnvalues?\nC-5.22 Supposeyou are givenan array, A, containingn distinct integersthat are listed\ninincreasingorder.Givenanumberk,describearecursivealgorithmtofindtwo\nintegersinAthatsumtok,ifsuchapairexists. Whatistherunningtimeofyour\nalgorithm?\nC-5.23 DescribearecursivealgorithmthatwillcheckifanarrayAofintegerscontains\nanintegerA[i]thatisthesumoftwointegersthatappearearlierinA,thatis,such\nthatA[i]=A[j]+A[k]for j,k<i.\nwww.it-ebooks.info\nChapterNotes 223\nC-5.24 IsabelhasaninterestingwayofsummingupthevaluesinanarrayAofnintegers,\nwherenisapoweroftwo. ShecreatesanarrayBofhalfthesizeofAandsets\nB[i]= A[2i]+A[2i+1], for i = 0,1,...,(n/2) 1. If B has size 1, then she\n\u2212\noutputsB[0]. Otherwise,shereplacesAwithB,andrepeatstheprocess. Whatis\ntherunningtimeofheralgorithm?\nC-5.25 DescribeafastrecursivealgorithmforreversingasinglylinkedlistL,sothatthe\norderingofthenodesbecomesoppositeofwhatitwasbefore.\nC-5.26 GivearecursivedefinitionofasinglylinkedlistclassthatdoesnotuseanyNode\nclass.\nProjects\nP-5.27 Implement a recursive method with calling signature find(path, filename) that\nreportsallentriesofthefilesystemrootedatthegivenpathhavingthegivenfile\nname.\nP-5.28 Write a programfor solvingsummationpuzzlesby enumeratingandtesting all\npossible configurations. Using your program, solve the three puzzles given in\nSection5.3.3.\nP-5.29 Provide a nonrecursiveimplementationof the drawInterval method for the En-\nglish ruler project of Section 5.1.2. There should be precisely 2c 1 lines of\n\u2212\noutputifcrepresentsthelengthofthecentertick.Ifincrementingacounterfrom\n0to2c 2,thenumberofdashesforeachticklineshouldbeexactlyonemore\n\u2212\nthanthenumberofconsecutive1\u2019sattheendofthebinaryrepresentationofthe\ncounter.\nP-5.30 Write a programthatcansolve instancesofthe TowerofHanoiproblem(from\nExerciseC-5.16).\nChapter Notes\nTheuseofrecursioninprogramsbelongstothefolkloreofcomputerscience(forexample,\nseethearticleofDijkstra[31]). Itisalsoattheheartoffunctionalprogramminglanguages\n(forexample,seethebookbyAbelson,Sussman,andSussman[1]). Interestingly,binary\nsearchwasfirstpublishedin1946,butwasnotpublishedinafullycorrectformuntil1962.\nForfurtherdiscussionsonlessonslearned,seepapersbyBentley[13]andLesuisse[64].\nwww.it-ebooks.info\nwww.it-ebooks.info\nChapter\n6\nStacks, Queues, and Deques\nContents\n6.1 Stacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\n6.1.1 The Stack Abstract Data Type . . . . . . . . . . . . . . . 227\n6.1.2 A Simple Array-Based Stack Implementation . . . . . . . 230\n6.1.3 Implementing a Stack with a Singly Linked List . . . . . . 233\n6.1.4 Reversing an Array Using a Stack . . . . . . . . . . . . . 234\n6.1.5 Matching Parentheses and HTML Tags . . . . . . . . . . 235\n6.2 Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n6.2.1 The Queue Abstract Data Type . . . . . . . . . . . . . . 239\n6.2.2 Array-Based Queue Implementation . . . . . . . . . . . . 241\n6.2.3 Implementing a Queue with a Singly Linked List . . . . . . 245\n6.2.4 A Circular Queue . . . . . . . . . . . . . . . . . . . . . . 246\n6.3 Double-Ended Queues . . . . . . . . . . . . . . . . . . . . . 248\n6.3.1 The Deque Abstract Data Type . . . . . . . . . . . . . . 248\n6.3.2 Implementing a Deque . . . . . . . . . . . . . . . . . . . 250\n6.3.3 Deques in the Java Collections Framework . . . . . . . . . 251\n6.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\nwww.it-ebooks.info\n226 Chapter6. Stacks,Queues,andDeques\n6.1 Stacks\nA stack is a collection of objects that are inserted and removed according to the\nlast-in, first-out (LIFO) principle. A user may insert objects into a stack at any\ntime,butmayonlyaccessorremovethemostrecentlyinsertedobjectthatremains\n(attheso-called\u201ctop\u201dofthestack). Thename\u201cstack\u201disderivedfromthemetaphor\nof a stack of plates in a spring-loaded, cafeteria plate dispenser. In this case, the\nfundamentaloperationsinvolvethe\u201cpushing\u201dand\u201cpopping\u201dofplatesonthestack.\nWhenweneedanewplatefromthedispenser, we\u201cpop\u201dthetopplateoffthestack,\nand when we add a plate, we \u201cpush\u201d it down on the stack to become the new top\nplate. Perhaps an even more amusing example is a PEZ\u00ae candy dispenser, which\nstoresmintcandies inaspring-loaded container that\u201cpops\u201doutthetopmostcandy\ninthestackwhenthetopofthedispenser islifted(seeFigure6.1).\nFigure6.1: A schematic drawing of a PEZ\u00ae dispenser; a physical implementation\nofthestackADT.(PEZ\u00ae isaregistered trademarkofPEZCandy,Inc.)\nStacks are a fundamental data structure. They are used in many applications,\nincluding thefollowing.\nExample 6.1: InternetWebbrowsersstoretheaddressesofrecentlyvisitedsites\nonastack.Eachtimeauservisitsanewsite,thatsite\u2019saddressis\u201cpushed\u201dontothe\nstackofaddresses. Thebrowserthenallowstheuserto\u201cpop\u201dbacktopreviously\nvisitedsitesusingthe\u201cback\u201dbutton.\nExample 6.2: Texteditorsusuallyprovidean\u201cundo\u201dmechanismthatcancelsre-\ncenteditingoperationsandrevertstoformerstatesofadocument.Thisundooper-\nationcanbeaccomplishedbykeepingtextchangesinastack.\nwww.it-ebooks.info\n6.1. Stacks 227\n6.1.1 The Stack Abstract Data Type\nStacks are the simplest of all data structures, yet they are also among the most\nimportant, as they are used in a host of different applications, and as a tool for\nmany more sophisticated data structures and algorithms. Formally, a stack is an\nabstractdatatype(ADT)thatsupports thefollowingtwoupdatemethods:\npush(e): Addselementetothetopofthestack.\npop(): Removesandreturnsthetopelementfromthestack\n(ornullifthestackisempty).\nAdditionally, astacksupportsthefollowingaccessormethodsforconvenience:\ntop(): Returnsthetopelementofthestack,withoutremovingit\n(ornullifthestackisempty).\nsize(): Returnsthenumberofelementsinthestack.\nisEmpty(): Returnsaboolean indicating whetherthestackisempty.\nByconvention, weassumethatelementsaddedtothestackcanhavearbitrarytype\nandthatanewlycreatedstackisempty.\nExample 6.3: Thefollowingtableshowsaseriesofstackoperationsandtheir\neffectsonaninitiallyemptystackSofintegers.\nMethod ReturnValue StackContents\npush(5) \u2013 (5)\npush(3) \u2013 (5, 3)\nsize() 2 (5, 3)\npop() 3 (5)\nisEmpty() false (5)\npop() 5 ()\nisEmpty() true ()\npop() null ()\npush(7) \u2013 (7)\npush(9) \u2013 (7, 9)\ntop() 9 (7, 9)\npush(4) \u2013 (7, 9, 4)\nsize() 3 (7, 9, 4)\npop() 4 (7, 9)\npush(6) \u2013 (7, 9, 6)\npush(8) \u2013 (7, 9, 6, 8)\npop() 8 (7, 9, 6)\nwww.it-ebooks.info\n228 Chapter6. Stacks,Queues,andDeques\nA Stack Interface in Java\nIn order to formalize our abstraction of a stack, we define what is known as its\napplication programming interface (API) in the form of a Java interface, which\ndescribes the names of the methods that the ADTsupports and how they are tobe\ndeclared andused. ThisinterfaceisdefinedinCodeFragment6.1.\nWe rely on Java\u2019s generics framework (described in Section 2.5.2), allow-\ning the elements stored in the stack to belong to any object type <E>. For ex-\nample, a variable representing a stack of integers could be declared with type\nStack<Integer>. The formal type parameter is used as the parameter type for\nthepushmethod,andthereturntypeforbothpopandtop.\nRecall,fromthediscussionofJavainterfacesinSection2.3.1,thattheinterface\nserves as a type definition but that it cannot be directly instantiated. For the ADT\ntobeofanyuse,wemustprovideoneormoreconcreteclasses thatimplementthe\nmethodsoftheinterfaceassociatedwiththatADT.Inthefollowingsubsections,we\nwill give two such implementations of the Stack interface: one that uses an array\nforstorageandanotherthatusesalinkedlist.\nThe java.util.Stack Class\nBecause of the importance of the stack ADT, Java has included, since its original\nversion, a concrete class named java.util.Stack that implements the LIFO seman-\ntics of astack. However, Java\u2019s Stackclass remains only for historic reasons, and\nits interface is not consistent with most other data structures in the Java library.\nIn fact, the current documentation for the Stack class recommends that it not be\nused, as LIFO functionality (and more) is provided by a more general data struc-\ntureknownasadouble-ended queue(whichwedescribeinSection6.3).\nFor the sake of comparison, Table 6.1 provides a side-by-side comparison of\nthe interface for our stack ADT and the java.util.Stack class. In addition to\nsome differences in method names, we note that methods pop and peek of the\njava.util.StackclassthrowacustomEmptyStackExceptionifcalledwhenthestack\nisempty(whereasnullisreturnedinourabstraction).\nOurStackADT Classjava.util.Stack\nsize() size()\nisEmpty() empty()\n\u21d0\npush(e) push(e)\npop() pop()\ntop() peek()\n\u21d0\nTable 6.1: Methods of our stack ADT and corresponding methods of the class\njava.util.Stack,withdifferences highlighted intherightmargin.\nwww.it-ebooks.info\n6.1. Stacks 229\n1 /\u2217\u2217\n2 \u2217 A collection of objects that are inserted and removed according to the last-in\n3 \u2217 first-out principle. Although similar in purpose, this interface differs from\n4 \u2217 java.util.Stack.\n5 \u2217\n6 \u2217 @author Michael T. Goodrich\n7 \u2217 @author Roberto Tamassia\n8 \u2217 @author Michael H. Goldwasser\n9 \u2217/\n10 public interface Stack<E>\n{\n11\n12 /\u2217\u2217\n13 \u2217 Returns the number of elements in the stack.\n14 \u2217 @return number of elements in the stack\n15 \u2217/\n16 int size();\n17\n18 /\u2217\u2217\n19 \u2217 Tests whether the stack is empty.\n20 \u2217 @return true if the stack is empty, false otherwise\n21 \u2217/\n22 boolean isEmpty();\n23\n24 /\u2217\u2217\n25 \u2217 Inserts an element at the top of the stack.\n26 \u2217 @param e the element to be inserted\n27 \u2217/\n28 void push(E e);\n29\n30 /\u2217\u2217\n31 \u2217 Returns, but does not remove, the element at the top of the stack.\n32 \u2217 @return top element in the stack (or null if empty)\n33 \u2217/\n34 E top();\n35\n36 /\u2217\u2217\n37 \u2217 Removes and returns the top element from the stack.\n38 \u2217 @return element removed (or null if empty)\n39 \u2217/\n40 E pop();\n41\n}\nCode Fragment 6.1: Interface Stack documented with comments in Javadoc style\n(Section 1.9.4). Note also the use of the generic parameterized type, E, which\nallowsastacktocontainelementsofanyspecified(reference) type.\nwww.it-ebooks.info\n230 Chapter6. Stacks,Queues,andDeques\n6.1.2 A Simple Array-Based Stack Implementation\nAsourfirstimplementationofthestackADT,westoreelementsinanarray,named\ndata, with capacity N for some fixed N. We oriented the stack so that the bottom\nelement of the stack is always stored in cell data[0], and the top element of the\nstack in cell data[t]for indext that isequal to one less than the current size ofthe\nstack. (SeeFigure6.2.)\ndata: A B C D E F G K L M\n0 1 2 t N 1\n\u2212\nFigure6.2: Representing astackwithanarray;thetopelementisincelldata[t].\nRecalling that arrays start at index 0 in Java, when the stack holds elements\nfromdata[0]todata[t]inclusive,ithassizet+1. Byconvention, whenthestackis\nempty it will havet equal to 1 (and thus has sizet+1, which is 0). A complete\n\u2212\nJava implementation based on this strategy is given in Code Fragment 6.2 (with\nJavadoccommentsomittedduetospaceconsiderations).\n1 public class ArrayStack<E> implements Stack<E>\n{\n2 public static final int CAPACITY=1000; // default array capacity\n3 private E[ ] data; // generic array used for storage\n4 private int t = 1; // index of the top element in stack\n\u2212\n5 public ArrayStack() this(CAPACITY); // constructs stack with default capacity\n{ }\n6 public ArrayStack(int capacity) // constructs stack with given capacity\n{\n7 data = (E[ ]) new Object[capacity]; // safe cast; compiler may give warning\n8\n}\n9 public int size() return (t + 1);\n{ }\n10 public boolean isEmpty() return (t == 1);\n{ \u2212 }\n11 public void push(E e) throws IllegalStateException\n{\n12 if (size() == data.length) throw new IllegalStateException(\"Stack is full\");\n13 data[++t] = e; // increment t before storing new item\n14\n}\n15 public E top()\n{\n16 if (isEmpty()) return null;\n17 return data[t];\n18\n}\n19 public E pop()\n{\n20 if (isEmpty()) return null;\n21 E answer = data[t];\n22 data[t] = null; // dereference to help garbage collection\n23 t ;\n\u2212\u2212\n24 return answer;\n25\n}\n26\n}\nCodeFragment6.2: Array-based implementation oftheStackinterface.\nwww.it-ebooks.info\n6.1. Stacks 231\nA Drawback of This Array-Based Stack Implementation\nThe array implementation of a stack is simple and efficient. Nevertheless, this\nimplementation hasone negativeaspect\u2014it relies onafixed-capacity array, which\nlimitstheultimatesizeofthestack.\nFor convenience, we allow the user of a stack to specify the capacity as a pa-\nrameter to the constructor (and offer a default constructor that uses capacity of\n1,000). Incases whereauserhasagood estimate onthenumberofitemsneeding\nto go inthe stack, the array-based implementation is hard tobeat. However, if the\nestimateiswrong,therecanbegraveconsequences. Iftheapplication needsmuch\nless space than the reserved capacity, memory is wasted. Worse yet, if an attempt\nis made to push an item onto a stack that has already reached its maximum ca-\npacity, theimplementation ofCodeFragment6.2throwsanIllegalStateException,\nrefusingtostorethenewelement. Thus,evenwithitssimplicityandefficiency,the\narray-based stackimplementation isnotnecessarily ideal.\nFortunately,wewilllaterdemonstratetwoapproachesforimplementingastack\nwithoutsuchasizelimitationandwithspacealwaysproportionaltotheactualnum-\nberofelementsstoredinthestack. Oneapproach,giveninthenextsubsectionuses\na singly linked list for storage; in Section 7.2.1, we will provide a more advanced\narray-based approach thatovercomesthelimitofafixedcapacity.\nAnalyzing the Array-Based Stack Implementation\nThe correctness of the methods in the array-based implementation follows from\nourdefinitionofindext. Notewellthatwhenpushinganelement,t isincremented\nbeforeplacingthenewelement,sothatitusesthefirstavailable cell.\nTable 6.2 shows the running times for methods of this array-based stack im-\nplementation. Each method executes a constant number of statements involving\narithmetic operations, comparisons, andassignments, orcalls tosizeandisEmpty,\nwhich both run in constant time. Thus, in this implementation of the stack ADT,\neachmethodrunsinconstant time,thatis,theyeachruninO(1)time.\nMethod RunningTime\nsize O(1)\nisEmpty O(1)\ntop O(1)\npush O(1)\npop O(1)\nTable 6.2: Performance of a stack realized by an array. The space usage is O(N),\nwhereN isthesizeofthearray,determinedatthetimethestackisinstantiated, and\nindependent fromthenumbern N ofelementsthatareactually inthestack.\n\u2264\nwww.it-ebooks.info\n232 Chapter6. Stacks,Queues,andDeques\nGarbage Collection in Java\nWewishtodrawattentiontooneinterestingaspectinvolvingtheimplementationof\nthepopmethodinCodeFragment6.2. Wesetalocalvariable,answer,toreference\nthe element that is being popped, and then we intentionally reset data[t] to nullat\nline22,beforedecrementingt. Theassignmenttonullwasnottechnicallyrequired,\nasourstackwouldstilloperatecorrectly withoutit.\nOur reason for returning the cell to a null reference is to assist Java\u2019s garbage\ncollection mechanism, which searches memory for objects that are no longer ac-\ntively referenced and reclaims their space for future use. (For more details, see\nSection 15.1.3.) If wecontinued to store a reference to the popped element in our\narray, the stack class wouldignore it(eventually overwriting the reference ifmore\nelementsgetaddedtothestack). But,iftherewerenootheractivereferencestothe\nelementintheuser\u2019sapplication, thatspuriousreference inthestack\u2019sarraywould\nstopJava\u2019sgarbagecollector fromreclaiming theelement.\nSample Usage\nWeconcludethissectionbyprovidingademonstrationofcodethatcreatesanduses\naninstance oftheArrayStackclass. Inthisexample, wedeclaretheparameterized\ntypeofthestackastheIntegerwrapperclass. Thiscausesthesignatureofthepush\nmethodtoacceptanIntegerinstanceasaparameter, andforthereturntypeofboth\ntopandpoptobeanInteger. Ofcourse,withJava\u2019sautoboxing andunboxing(see\nSection1.3),aprimitiveintcanbesentasaparametertopush.\nStack<Integer> S = new ArrayStack<>(); // contents: ()\nS.push(5); // contents: (5)\nS.push(3); // contents: (5, 3)\nSystem.out.println(S.size()); // contents: (5, 3) outputs 2\nSystem.out.println(S.pop()); // contents: (5) outputs 3\nSystem.out.println(S.isEmpty()); // contents: (5) outputs false\nSystem.out.println(S.pop()); // contents: () outputs 5\nSystem.out.println(S.isEmpty()); // contents: () outputs true\nSystem.out.println(S.pop()); // contents: () outputs null\nS.push(7); // contents: (7)\nS.push(9); // contents: (7, 9)\nSystem.out.println(S.top()); // contents: (7, 9) outputs 9\nS.push(4); // contents: (7, 9, 4)\nSystem.out.println(S.size()); // contents: (7, 9, 4) outputs 3\nSystem.out.println(S.pop()); // contents: (7, 9) outputs 4\nS.push(6); // contents: (7, 9, 6)\nS.push(8); // contents: (7, 9, 6, 8)\nSystem.out.println(S.pop()); // contents: (7, 9, 6) outputs 8\nCodeFragment6.3: SampleusageofourArrayStackclass.\nwww.it-ebooks.info\n6.1. Stacks 233\n6.1.3 Implementing a Stack with a Singly Linked List\nInthissection, wedemonstrate howtheStackinterface canbeeasilyimplemented\nusing a singly linked list for storage. Unlike our array-based implementation, the\nlinked-list approach has memory usage that is always proportional to the number\nofactualelementscurrently inthestack, andwithoutanarbitrarycapacity limit.\nIndesigning such animplementation, weneed todecide ifthetop ofthestack\nisatthefrontorbackofthelist. Thereisclearlyabestchoicehere,however,since\nwe can insert and delete elements in constant time only at the front. With the top\nofthestackstoredatthefrontofthelist,allmethodsexecuteinconstant time.\nThe Adapter Pattern\nThe adapter design pattern applies to any context where we effectively want to\nmodifyanexisting class sothatitsmethods matchthose ofarelated, butdifferent,\nclass or interface. One general way to apply the adapter pattern is to define a new\nclass in such a way that it contains an instance of the existing class as a hidden\nfield, and then to implement each method of the new class using methods of this\nhidden instance variable. By applying the adapter pattern in this way, we have\ncreated a new class that performs some of the same functions as an existing class,\nbutrepackaged inamoreconvenient way.\nIn the context of the stack ADT, we can adapt our SinglyLinkedList class of\nSection 3.2.1 to define a new LinkedStack class, shown in Code Fragment 6.4.\nThis class declares a SinglyLinkedList named list as a private field, and uses the\nfollowingcorrespondences:\nStackMethod SinglyLinkedListMethod\nsize() list.size()\nisEmpty() list.isEmpty()\npush(e) list.addFirst(e)\npop() list.removeFirst()\ntop() list.first()\n1 public class LinkedStack<E> implements Stack<E>\n{\n2 private SinglyLinkedList<E> list = new SinglyLinkedList<>(); // an empty list\n3 public LinkedStack() // new stack relies on the initially empty list\n{ }\n4 public int size() return list.size();\n{ }\n5 public boolean isEmpty() return list.isEmpty();\n{ }\n6 public void push(E element) list.addFirst(element);\n{ }\n7 public E top() return list.first();\n{ }\n8 public E pop() return list.removeFirst();\n{ }\n9\n}\nCodeFragment6.4: ImplementationofaStackusingaSinglyLinkedListasstorage.\nwww.it-ebooks.info\n234 Chapter6. Stacks,Queues,andDeques\n6.1.4 Reversing an Array Using a Stack\nAs a consequence of the LIFO protocol, a stack can be used as a general toll to\nreverse a data sequence. For example, if the values 1, 2, and 3 are pushed onto a\nstackinthatorder, theywillbepoppedfromthestackintheorder3,2,andthen1.\nWedemonstratethisconceptbyrevisitingtheproblemofreversingtheelements\nofanarray. (Weprovided arecursive algorithm forthis task inSection 5.3.1.) We\ncreate anemptystack forauxiliary storage, push allofthearray elements onto the\nstack,andthenpopthoseelementsoffofthestackwhileoverwritingthecellsofthe\narrayfrombeginningtoend. InCodeFragment6.5,wegiveaJavaimplementation\nofthisalgorithm. WeshowanexampleuseofthismethodinCodeFragment6.6.\n1 /\u2217\u2217 A generic method for reversing an array. \u2217/\n2 public static <E> void reverse(E[ ] a)\n{\n3 Stack<E> buffer = new ArrayStack<>(a.length);\n4 for (int i=0; i < a.length; i++)\n5 buffer.push(a[i]);\n6 for (int i=0; i < a.length; i++)\n7 a[i] = buffer.pop();\n8\n}\nCodeFragment6.5: A generic method that reverses the elements in an array with\nobjectsoftypeE,usingastackdeclared withtheinterface Stack<E>asitstype.\n1 /\u2217\u2217 Tester routine for reversing arrays \u2217/\n2 public static void main(String args[ ])\n{\n3 Integer[ ] a = 4, 8, 15, 16, 23, 42 ; // autoboxing allows this\n{ }\n4 String[ ] s = \"Jack\", \"Kate\", \"Hurley\", \"Jin\", \"Michael\" ;\n{ }\n5 System.out.println(\"a = \" + Arrays.toString(a));\n6 System.out.println(\"s = \" + Arrays.toString(s));\n7 System.out.println(\"Reversing...\");\n8 reverse(a);\n9 reverse(s);\n10 System.out.println(\"a = \" + Arrays.toString(a));\n11 System.out.println(\"s = \" + Arrays.toString(s));\n12\n}\nTheoutputfromthismethodisthefollowing:\na = [4, 8, 15, 16, 23, 42]\ns = [Jack, Kate, Hurley, Jin, Michael]\nReversing...\na = [42, 23, 16, 15, 8, 4]\ns = [Michael, Jin, Hurley, Kate, Jack]\nCodeFragment6.6: Atestofthereversemethodusingtwoarrays.\nwww.it-ebooks.info\n6.1. Stacks 235\n6.1.5 Matching Parentheses and HTML Tags\nIn this subsection, we explore two related applications of stacks, both of which\ninvolvetestingforpairsofmatchingdelimiters. Inourfirstapplication,weconsider\narithmeticexpressionsthatmaycontainvariouspairsofgroupingsymbols,suchas\nParentheses: \u201c(\u201dand\u201c)\u201d\n\u2022\nBraces: \u201c \u201dand\u201c \u201d\n\u2022 { }\nBrackets: \u201c[\u201dand\u201c]\u201d\n\u2022\nEachopening symbol mustmatchitscorresponding closing symbol. Forexample,\naleftbracket,\u201c[,\u201dmustmatchacorrespondingrightbracket,\u201c],\u201dasinthefollowing\nexpression\n[(5+x) (y+z)].\n\u2212\nThefollowingexamplesfurtherillustrate thisconcept:\nCorrect: ()(()) ([()])\n\u2022 { }\nCorrect: ((()(()) ([()]) ))\n\u2022 { }\nIncorrect: )(()) ([()])\n\u2022 { }\nIncorrect: ( [])\n\u2022 { }\nIncorrect: (\n\u2022\nWeleavetheprecisedefinitionofamatchinggroupofsymbolstoExerciseR-6.6.\nAn Algorithm for Matching Delimiters\nAn important task when processing arithmetic expressions is to make sure their\ndelimiting symbols match up correctly. We can use a stack to perform this task\nwithasingleleft-to-right scanoftheoriginalstring.\nEach time we encounter an opening symbol, we push that symbol onto the\nstack, and each time we encounter a closing symbol, we pop a symbol from the\nstack (assuming it is not empty) and check that these two symbols form a valid\npair. Ifwereachtheendoftheexpression andthestackisempty,thentheoriginal\nexpression was properly matched. Otherwise, there must be an opening delimiter\non the stack without a matching symbol. If the length of the original expression\nis n, the algorithm will make at most n calls to push and n calls to pop. Code\nFragment 6.7 presents a Java implementation of such an algorithm. It specifically\nchecksfordelimiterpairs(), ,and[],butcouldeasilybechangedtoaccommo-\n{}\ndate further symbols. Specifically, we define two fixedstrings, \"({[\" and \")}]\",\nthat are intentionally coordinated to reflect the symbol pairs. When examining a\ncharacter of the expression string, we call the indexOf method of the String class\nonthesespecialstringstodetermineifthecharactermatchesadelimiterand,ifso,\nwhichone. MethodindexOfreturnsthetheindexatwhichagivencharacterisfirst\nfoundinastring(or 1ifthecharacter isnotfound).\n\u2212\nwww.it-ebooks.info\n236 Chapter6. Stacks,Queues,andDeques\n1 /\u2217\u2217 Tests if delimiters in the given expression are properly matched. \u2217/\n2 public static boolean isMatched(String expression)\n{\n3 final String opening = \"({[\"; // opening delimiters\n4 final String closing = \")}]\"; // respective closing delimiters\n5 Stack<Character> buffer = new LinkedStack<>();\n6 for (char c : expression.toCharArray())\n{\n7 if (opening.indexOf(c) != 1) // this is a left delimiter\n\u2212\n8 buffer.push(c);\n9 else if (closing.indexOf(c) != 1) // this is a right delimiter\n\u2212 {\n10 if (buffer.isEmpty()) // nothing to match with\n11 return false;\n12 if (closing.indexOf(c) != opening.indexOf(buffer.pop()))\n13 return false; // mismatched delimiter\n14\n}\n15\n}\n16 return buffer.isEmpty(); // were all opening delimiters matched?\n17\n}\nCodeFragment6.7: Methodformatchingdelimitersinanarithmeticexpression.\nMatching Tags in a Markup Language\nAnotherapplicationofmatchingdelimitersisinthevalidationofmarkuplanguages\nsuch asHTMLorXML.HTMListhestandard formatforhyperlinked documents\non the Internet and XML is an extensible markup language used for a variety of\nstructured datasets. WeshowasampleHTMLdocument inFigure6.3.\n<body>\n<center>\nThe Little Boat\n<h1> The Little Boat </h1>\n</center>\n<p> The storm tossed the little The storm tossed the little boat\nboat like a cheap sneaker in an like a cheap sneaker in an\nold washing machine. The three\nold washing machine. The three\ndrunken fishermen were used to\ndrunken fishermen were used to\nsuch treatment, of course, but\nsuchtreatment,ofcourse,butnot\nnot the tree salesman, who even as\nthe tree salesman, who even as\na stowaway now felt that he\nhad overpaid for the voyage. </p> a stowaway now felt that he had\n<ol> overpaidforthevoyage.\n<li> Will the salesman die? </li> 1. Willthesalesmandie?\n<li> What color is the boat? </li>\n2. Whatcoloristheboat?\n<li> And what about Naomi? </li>\n3. AndwhataboutNaomi?\n</ol>\n</body>\n(a) (b)\nFigure6.3: Illustrating (a)anHTMLdocumentand(b)itsrendering.\nwww.it-ebooks.info\n6.1. Stacks 237\nInanHTMLdocument,portionsoftextaredelimitedbyHTMLtags. Asimple\nopening HTMLtag has the form \u201c<name>\u201dand the corresponding closing tag has\nthe form \u201c</name>\u201d. For example, we see the <body> tag on the first line of\nFigure 6.3a, and the matching </body> tag at the close of that document. Other\ncommonlyusedHTMLtagsthatareusedinthisexampleinclude:\n<body>: documentbody\n\u2022\n<h1>: sectionheader\n\u2022\n<center>: centerjustify\n\u2022\n<p>: paragraph\n\u2022\n<ol>: numbered (ordered)list\n\u2022\n<li>: listitem\n\u2022\nIdeally, an HTML document should have matching tags, although most browsers\ntolerate a certain number of mismatching tags. In Code Fragment 6.8, we give a\nJavamethodthatmatchestagsinastringrepresenting anHTMLdocument.\nWe make a left-to-right pass through the raw string, using index j to track\nour progress. The indexOf method of the String class, which optionally accepts a\nstartingindexasasecondparameter,locatesthe'<'and'>'charactersthatdefine\nthe tags. Method substring, also of the String class, returns the substring starting\nat a given index and optionally ending right before another given index. Opening\ntagsarepushedontothestack,andmatchedagainstclosingtagsastheyarepopped\nfromthestack, justaswedidwhenmatchingdelimiters inCodeFragment6.7.\n1 /\u2217\u2217 Tests if every opening tag has a matching closing tag in HTML string. \u2217/\n2 public static boolean isHTMLMatched(String html)\n{\n3 Stack<String> buffer = new LinkedStack<>();\n4 int j = html.indexOf('<'); // find first \u2019<\u2019 character (if any)\n5 while (j != 1)\n\u2212 {\n6 int k = html.indexOf('>', j+1); // find next \u2019>\u2019 character\n7 if (k == 1)\n\u2212\n8 return false; // invalid tag\n9 String tag = html.substring(j+1, k); // strip away < >\n10 if (!tag.startsWith(\"/\")) // this is an opening tag\n11 buffer.push(tag);\n12 else // this is a closing tag\n{\n13 if (buffer.isEmpty())\n14 return false; // no tag to match\n15 if (!tag.substring(1).equals(buffer.pop()))\n16 return false; // mismatched tag\n17\n}\n18 j = html.indexOf('<', k+1); // find next \u2019<\u2019 character (if any)\n19\n}\n20 return buffer.isEmpty(); // were all opening tags matched?\n21\n}\nCodeFragment6.8: MethodfortestingifanHTMLdocumenthasmatchingtags.\nwww.it-ebooks.info\n238 Chapter6. Stacks,Queues,andDeques\n6.2 Queues\nAnotherfundamentaldatastructureisthequeue. Itisaclose\u201ccousin\u201dofthestack,\nbutaqueueisacollectionofobjectsthatareinsertedandremovedaccordingtothe\nfirst-in, first-out (FIFO) principle. That is, elements can be inserted at any time,\nbutonlytheelementthathasbeeninthequeuethelongestcanbenextremoved.\nWe usually say that elements enter a queue at the back and are removed from\nthe front. A metaphor for this terminology is aline ofpeople waiting to get on an\namusement park ride. People waiting for such a ride enter at the back of the line\nand get on the ride from the front of the line. There are many other applications\nof queues (see Figure 6.4). Stores, theaters, reservation centers, and other similar\nservices typically process customer requests according to the FIFO principle. A\nqueue would therefore be a logical choice for a data structure to handle calls to a\ncustomerservicecenter,orawait-listatarestaurant. FIFOqueuesarealsousedby\nmanycomputing devices, such asanetworked printer, oraWebserver responding\ntorequests.\nTickets\n(a)\nC\nall\nC e\nnter\nCall Queue\n(b)\nFigure6.4: Real-worldexamplesofafirst-in,first-outqueue. (a)Peoplewaitingin\nlinetopurchasetickets; (b)phonecallsbeingroutedtoacustomerservicecenter.\nwww.it-ebooks.info\n6.2. Queues 239\n6.2.1 The Queue Abstract Data Type\nFormally, the queue abstract data type defines a collection that keeps objects in a\nsequence, where element access and deletion are restricted to the first element in\nthe queue, and element insertion is restricted to the back of the sequence. This\nrestriction enforces the rule that items are inserted and deleted in a queue accord-\ning to the first-in, first-out (FIFO) principle. The queue abstract data type (ADT)\nsupports thefollowingtwoupdatemethods:\nenqueue(e): Addselementetothebackofqueue.\ndequeue(): Removesandreturnsthefirstelementfromthequeue\n(ornullifthequeueisempty).\nThe queue ADT also includes the following accessor methods (with first being\nanalogous tothestack\u2019stopmethod):\nfirst(): Returns the first element of the queue, without removing it\n(ornullifthequeueisempty).\nsize(): Returnsthenumberofelementsinthequeue.\nisEmpty(): Returnsaboolean indicating whetherthequeueisempty.\nByconvention, weassumethatelementsaddedtothequeuecanhavearbitrary\ntype and that a newly created queue is empty. We formalize the queue ADT with\ntheJavainterface showninCodeFragment6.9.\n1 public interface Queue<E>\n2 /\u2217\u2217 Returns the number of e { lements in the queue. \u2217/\n3 int size();\n4 /\u2217\u2217 Tests whether the queue is empty. \u2217/\n5 boolean isEmpty();\n6 /\u2217\u2217 Inserts an element at the rear of the queue. \u2217/\n7 void enqueue(E e);\n8 /\u2217\u2217 Returns, but does not remove, the first element of the queue (null if empty). \u2217/\n9 E first();\n10 /\u2217\u2217 Removes and returns the first element of the queue (null if empty). \u2217/\n11 E dequeue();\n12\n}\nCode Fragment 6.9: A Queue interface defining the queue ADT, with a standard\nFIFOprotocolforinsertions andremovals.\nwww.it-ebooks.info\n240 Chapter6. Stacks,Queues,andDeques\nExample 6.4: Thefollowingtableshowsaseriesofqueueoperationsandtheir\neffectsonaninitiallyemptyqueueQofintegers.\nMethod ReturnValue first Q last\n\u2190 \u2190\nenqueue(5) \u2013 (5)\nenqueue(3) \u2013 (5, 3)\nsize() 2 (5, 3)\ndequeue() 5 (3)\nisEmpty() false (3)\ndequeue() 3 ()\nisEmpty() true ()\ndequeue() null ()\nenqueue(7) \u2013 (7)\nenqueue(9) \u2013 (7, 9)\nfirst() 7 (7, 9)\nenqueue(4) \u2013 (7, 9, 4)\nThe java.util.Queue Interface in Java\nJava provides a type of queue interface, java.util.Queue, which has functionality\nsimilar to the traditional queue ADT, given above, but the documentation for the\njava.util.Queue interface does not insist that it support only the FIFO principle.\nWhen supporting the FIFOprinciple, the methods ofthe java.util.Queueinterface\nhavetheequivalences withthequeueADTshowninTable6.3.\nThe java.util.Queue interface supports two styles for most operations, which\nvary in the way that they treat exceptional cases. When a queue is empty, the\nremove() and element() methods throw a NoSuchElementException, while the\ncorresponding methods poll()andpeek()return null. Forimplementations witha\nbounded capacity, the add method will throw an IllegalStateException when full,\nwhiletheoffermethodignores thenewelementandreturns falsetosignalthatthe\nelementwasnotaccepted.\nOurQueueADT Interfacejava.util.Queue\nthrowsexceptions returnsspecialvalue\nenqueue(e) add(e) offer(e)\ndequeue() remove() poll()\nfirst() element() peek()\nsize() size()\nisEmpty() isEmpty()\nTable6.3: Methods ofthe queue ADTand corresponding methods ofthe interface\njava.util.Queue,whensupporting theFIFOprinciple.\nwww.it-ebooks.info\n6.2. Queues 241\n6.2.2 Array-Based Queue Implementation\nIn Section 6.1.2, we implemented the LIFO semantics of the Stack ADTusing an\narray (albeit, withafixedcapacity), such that everyoperation executes inconstant\ntime. Inthissection,wewillconsiderhowtouseanarraytoefficientlysupportthe\nFIFOsemanticsoftheQueueADT.\nLet\u2019s assume that as elements are inserted into a queue, we store them in an\narraysuchthatthefirstelementisatindex0,thesecondelementatindex1,andso\non. (SeeFigure6.5.)\ndata: A B C D E F G K L M\n0 1 2 N 1\n\u2212\nFigure6.5: Usingan array to store elements ofaqueue, such that the firstelement\ninserted, \u201cA\u201d,isatcell0,thesecondelementinserted, \u201cB\u201d,atcell1,andsoon.\nWithsuchaconvention, thequestionishowweshouldimplementthedequeue\noperation. Theelementtoberemovedisstoredatindex0ofthearray. Onestrategy\nistoexecutealooptoshiftallotherelementsofthequeueonecelltotheleft,sothat\nthe front of the queue is again aligned with cell 0 of the array. Unfortunately, the\nuseofsuchaloopwouldresultinanO(n)running timeforthedequeuemethod.\nWe can improve on the above strategy by avoiding the loop entirely. We will\nreplace a dequeued element in the array with a null reference, and maintain an\nexplicit variable f to represent the index of the element that is currently at the\nfront of the queue. Such an algorithm for dequeue would run in O(1) time. After\nseveraldequeueoperations,thisapproachmightleadtotheconfigurationportrayed\ninFigure6.6.\ndata: F G K L M\n0 1 2 f N 1\n\u2212\nFigure 6.6: Allowing the front of the queue to drift away from index 0. In this\nrepresentation, index f denotesthelocation ofthefrontofthequeue.\nHowever, there remains a challenge with the revised approach. With an array\nof capacity N, we should be able to store up to N elements before reaching any\nexceptional case. If we repeatedly let the front of the queue drift rightward over\ntime,thebackofthequeuewouldreachtheendoftheunderlying arrayevenwhen\nthere are fewer than N elements currently in the queue. We must decide how to\nstoreadditional elementsinsuchaconfiguration.\nwww.it-ebooks.info\n242 Chapter6. Stacks,Queues,andDeques\nUsing an Array Circularly\nIn developing a robust queue implementation, we allow both the front and back\nof the queue to drift rightward, with the contents of the queue \u201cwrapping around\u201d\nthe endofan array, asnecessary. Assuming that the array hasfixedlength N,new\nelementsareenqueuedtowardthe\u201cend\u201dofthecurrentqueue,progressingfromthe\nfronttoindexN 1andcontinuing atindex0,then1. Figure6.7illustrates sucha\n\u2212\nqueuewithfirstelementFandlastelementR.\ndata: Q R F G K L M N O P\n0 1 2 f N 1\n\u2212\nFigure6.7: Modelingaqueuewithacircular arraythatwrapsaroundtheend.\nImplementing suchacircular viewisrelatively easywiththemodulooperator,\ndenoted with the symbol % in Java. Recall that the modulo operator is computed\nby taking the remainder after an integral division. For example, 14 divided by 3\nhasaquotient of4withremainder 2,thatis, 14 =42. SoinJava,14 / 3evaluates\n3 3\ntothequotient 4,while14 % 3evaluates totheremainder2.\nThe modulo operator is ideal for treating an array circularly. When we de-\nqueue an element and want to \u201cadvance\u201d the front index, we use the arithmetic\nf =(f +1)%N. As a concrete example, if we have an array of length 10, and a\nfrontindex7,wecanadvancethefrontbyformallycomputing(7+1) % 10,which\nis simply 8, as 8 divided by 10 is 0 with a remainder of 8. Similarly, advancing\nindex 8 results in index 9. Butwhen weadvance from index 9(the last one in the\narray), we compute (9+1) % 10, which evaluates to index 0 (as 10 divided by 10\nhasaremainderofzero).\nA Java Queue Implementation\nA complete implementation of a queue ADT using an array in circular fashion is\npresented inCodeFragment6.10. Internally, thequeueclassmaintainsthefollow-\ningthreeinstance variables:\ndata: areferencetotheunderlying array.\nf: anintegerthatrepresents theindex,withinarraydata,ofthefirst\nelementofthequeue(assuming thequeueisnotempty).\nsz: an integer representing the current number of elements stored in\nthequeue(nottobeconfused withthelengthofthearray).\nWeallow the user to specify the capacity of the queue asan optional parameter to\ntheconstructor.\nTheimplementationsofmethodssizeandisEmptyaretrivial,giventheszfield,\nand the implementation of first is simple, given index f. A discussion of update\nmethodsenqueueanddequeuefollowsthepresentation ofthecode.\nwww.it-ebooks.info\n6.2. Queues 243\n1 /\u2217\u2217 Implementation of the queue ADT using a fixed-length array. \u2217/\n2 public class ArrayQueue<E> implements Queue<E>\n{\n3 // instance variables\n4 private E[ ] data; // generic array used for storage\n5 private int f = 0; // index of the front element\n6 private int sz = 0; // current number of elements\n7\n8 // constructors\n9 public ArrayQueue() this(CAPACITY); // constructs queue with default capacity\n{ }\n10 public ArrayQueue(int capacity) // constructs queue with given capacity\n{\n11 data = (E[ ]) new Object[capacity]; // safe cast; compiler may give warning\n12\n}\n13\n14 // methods\n15 /\u2217\u2217 Returns the number of elements in the queue. \u2217/\n16 public int size() return sz;\n{ }\n17\n18 /\u2217\u2217 Tests whether the queue is empty. \u2217/\n19 public boolean isEmpty() return (sz == 0);\n{ }\n20\n21 /\u2217\u2217 Inserts an element at the rear of the queue. \u2217/\n22 public void enqueue(E e) throws IllegalStateException\n{\n23 if (sz == data.length) throw new IllegalStateException(\"Queue is full\");\n24 int avail = (f + sz) % data.length; // use modular arithmetic\n25 data[avail] = e;\n26 sz++;\n27\n}\n28\n29 /\u2217\u2217 Returns, but does not remove, the first element of the queue (null if empty). \u2217/\n30 public E first()\n{\n31 if (isEmpty()) return null;\n32 return data[f];\n33\n}\n34\n35 /\u2217\u2217 Removes and returns the first element of the queue (null if empty). \u2217/\n36 public E dequeue()\n{\n37 if (isEmpty()) return null;\n38 E answer = data[f];\n39 data[f] = null; // dereference to help garbage collection\n40 f = (f + 1) % data.length;\n41 sz ;\n\u2212\u2212\n42 return answer;\n43\n}\nCodeFragment6.10: Array-based implementation ofaqueue.\nwww.it-ebooks.info\n244 Chapter6. Stacks,Queues,andDeques\nAdding and Removing Elements\nThegoal oftheenqueuemethod istoadd anewelement tothe back ofthequeue.\nWeneedtodeterminetheproperindexatwhichtoplacethenewelement. Although\nwe do not explicitly maintain an instance variable for the back of the queue, we\ncomputetheindexofthenextopening basedontheformula:\navail = (f + sz) % data.length;\nNote that we are using the size of the queue as it exists prior to the addition of\nthe new element. As a sanity check, for a queue with capacity 10, current size 3,\nandfirstelementatindex5,itsthreeelements arestoredatindices 5,6,and7,and\nthe nextelement should be added atindex 8, computed as (5+3) % 10. Asacase\nwith wraparound, if the queue has capacity 10, current size 3, and first element at\nindex 8, its three elements are stored at indices 8, 9, and 0, and the next element\nshouldbeaddedatindex1,computedas(8+3) % 10.\nWhenthedequeuemethodiscalled,thecurrentvalueoffdesignates theindex\nof the value that is to be removed and returned. We keep a local reference to the\nelementthatwillbereturned, beforesettingitscellofthearraybacktonull,toaid\nthegarbagecollector. Thentheindexfisupdated toreflecttheremovalofthefirst\nelement, and the presumed promotion of the second element to become the new\nfirst. In most cases, we simply want to increment the index by one, but because\nof the possibility of a wraparound configuration, we rely on modular arithmetic,\ncomputing f = (f+1) % data.length,asoriginally described onpage242.\nAnalyzing the Efficiency of an Array-Based Queue\nTable 6.4 shows the running times of methods in a realization of a queue by an\narray. Aswithourarray-basedstackimplementation, eachofthequeuemethodsin\nthearrayrealizationexecutesaconstantnumberofstatementsinvolvingarithmetic\noperations, comparisons, andassignments. Thus,eachmethodinthisimplementa-\ntionrunsinO(1)time.\nMethod RunningTime\nsize O(1)\nisEmpty O(1)\nfirst O(1)\nenqueue O(1)\ndequeue O(1)\nTable6.4: Performance of a queue realized by an array. Thespace usage is O(N),\nwhere N is the size of the array, determined at the time the queue is created, and\nindependent fromthenumbern<N ofelementsthatareactually inthequeue.\nwww.it-ebooks.info\n6.2. Queues 245\n6.2.3 Implementing a Queue with a Singly Linked List\nAs we did for the stack ADT, we can easily adapt a singly linked list to imple-\nmentthequeueADTwhilesupportingworst-caseO(1)-timeforalloperations,and\nwithoutanyartificiallimitonthecapacity. Thenaturalorientationforaqueueisto\nalignthefrontofthequeuewiththefrontofthelist,andthebackofthequeuewith\nthetailofthelist,becausetheonlyupdateoperationthatsinglylinkedlistssupport\natthebackendisaninsertion. OurJavaimplementation ofaLinkedQueueclassis\ngiveninCode6.11.\n1 /\u2217\u2217 Realization of a FIFO queue as an adaptation of a SinglyLinkedList. \u2217/\n2 public class LinkedQueue<E> implements Queue<E>\n{\n3 private SinglyLinkedList<E> list = new SinglyLinkedList<>(); // an empty list\n4 public LinkedQueue() // new queue relies on the initially empty list\n{ }\n5 public int size() return list.size();\n{ }\n6 public boolean isEmpty() return list.isEmpty();\n{ }\n7 public void enqueue(E element) list.addLast(element);\n{ }\n8 public E first() return list.first();\n{ }\n9 public E dequeue() return list.removeFirst();\n{ }\n10\n}\nCodeFragment6.11: Implementation ofaQueueusingaSinglyLinkedList.\nAnalyzing the Efficiency of a Linked Queue\nAlthough we had not yet introduced asymptotic analysis when we presented our\nSinglyLinkedList implementation in Chapter 3, it is clear upon reexamination that\neachmethodofthatclassrunsinO(1)worst-casetime. Therefore, eachmethodof\nourLinkedQueueadaptation alsorunsinO(1)worst-case time.\nWealso avoid the need to specify a maximum size for the queue, as wasdone\nin the array-based queue implementation. However, this benefit comes with some\nexpense. Because each node stores a next reference, in addition to the element\nreference, a linked list uses more space per element than a properly sized array of\nreferences.\nAlso, although allmethods execute inconstant timeforbothimplementations,\nit seems clear that the operations involving linked lists have a large number of\nprimitive operations per call. For example, adding an element to an array-based\nqueue consists primarily of calculating an index with modular arithmetic, storing\nthe element in the array cell, and incrementing the size counter. For a linked list,\naninsertionincludestheinstantiation andinitialization ofanewnode,relinkingan\nexisting node to the new node, and incrementing the size counter. In practice, this\nmakesthelinked-list methodmoreexpensive thanthearray-based method.\nwww.it-ebooks.info\n246 Chapter6. Stacks,Queues,andDeques\n6.2.4 A Circular Queue\nIn Section 3.3, we implemented a circularly linked list class that supports all be-\nhaviors of a singly linked list, and an additional rotate() method that efficiently\nmoves the first element to the end of the list. We can generalize the Queue in-\nterface to define a new CircularQueue interface with such a behavior, as shown in\nCodeFragment6.12.\n1 public interface CircularQueue<E> extends Queue<E>\n2 /\u2217\u2217 {\n3 \u2217 Rotates the front element of the queue to the back of the queue.\n4 \u2217 This does nothing if the queue is empty.\n5 \u2217/\n6 void rotate();\n7\n}\nCodeFragment6.12:AJavainterface,CircularQueue,thatextendstheQueueADT\nwithanewrotate()method.\nThis interface can easily be implemented by adapting the CircularlyLinkedList\nclassofSection3.3toproduceanewLinkedCircularQueueclass. Thisclasshasan\nadvantage overthetraditional LinkedQueue,becauseacalltoQ.rotate()isimple-\nmented more efficiently than the combination of calls, Q.enqueue(Q.dequeue()),\nbecause no nodes are created, destroyed, or relinked by the implementation of a\nrotateoperation onacircularly linkedlist.\nAcircular queue isanexcellent abstraction forapplications inwhichelements\nare cyclically arranged, such as for multiplayer, turn-based games, or round-robin\nscheduling ofcomputing processes. In theremainder of this section, weprovide a\ndemonstration oftheuseofacircularqueue.\nThe Josephus Problem\nIn the children\u2019s game \u201chot potato,\u201d a group of n children sit in a circle passing\nan object, called the \u201cpotato,\u201d around the circle. The potato begins with a starting\nchildinthecircle,andthechildrencontinuepassingthepotatountilaleaderringsa\nbell,atwhichpointthechildholding thepotato mustleavethegameafterhanding\nthe potato to the next child in the circle. After the selected child leaves, the other\nchildren close up the circle. This process is then continued until there is only one\nchild remaining, whoisdeclared thewinner. Iftheleader always usesthe strategy\nof ringing the bell so that every kth person is removed from the circle, for some\nfixedvaluek,thendeterminingthewinnerforagivenlistofchildrenisknownasthe\nJosephusproblem(namedafteranancientstorywithfarmoresevereconsequences\nthaninthechildren\u2019s game).\nwww.it-ebooks.info\n6.2. Queues 247\nSolving the Josephus Problem Using a Queue\nWecan solve the Josephus problem for a collection of n elements using a circular\nqueue,byassociatingthepotatowiththeelementatthefrontofthequeueandstor-\ningelements inthequeueaccording totheirorderaround thecircle. Thus,passing\nthepotato isequivalent torotating thefirstelementtotheback ofthequeue. After\nthis process has been performed k 1 times, we remove the front element by de-\n\u2212\nqueuingitfromthequeueanddiscarding it. WeshowacompleteJavaprogramfor\nsolving the Josephus problem using this approach in Code Fragment 6.13, which\ndescribes a solution that runs in O(nk) time. (We can solve this problem faster\nusingtechniques beyondthescopeofthisbook.)\n1 public class Josephus\n2 /\u2217\u2217 Computes the wi { nner of the Josephus problem using a circular queue. \u2217/\n3 public static <E> E Josephus(CircularQueue<E> queue, int k)\n{\n4 if (queue.isEmpty()) return null;\n5 while (queue.size() > 1)\n{\n6 for (int i=0; i < k 1; i++) // skip past k-1 elements\n\u2212\n7 queue.rotate();\n8 E e = queue.dequeue(); // remove the front element from the collection\n9 System.out.println(\" \" + e + \" is out\");\n10\n}\n11 return queue.dequeue(); // the winner\n12\n}\n13\n14 /\u2217\u2217 Builds a circular queue from an array of objects. \u2217/\n15 public static <E> CircularQueue<E> buildQueue(E a[ ])\n{\n16 CircularQueue<E> queue = new LinkedCircularQueue<>();\n17 for (int i=0; i<a.length; i++)\n18 queue.enqueue(a[i]);\n19 return queue;\n20\n}\n21\n22 /\u2217\u2217 Tester method \u2217/\n23 public static void main(String[ ] args)\n{\n24 String[ ] a1 = \"Alice\", \"Bob\", \"Cindy\", \"Doug\", \"Ed\", \"Fred\" ;\n{ }\n25 String[ ] a2 = \"Gene\", \"Hope\", \"Irene\", \"Jack\", \"Kim\", \"Lance\" ;\n{ }\n26 String[ ] a3 = \"Mike\", \"Roberto\" ;\n{ }\n27 System.out.println(\"First winner is \" + Josephus(buildQueue(a1), 3));\n28 System.out.println(\"Second winner is \" + Josephus(buildQueue(a2), 10));\n29 System.out.println(\"Third winner is \" + Josephus(buildQueue(a3), 7));\n30\n}\n31\n}\nCode Fragment6.13: A complete Java program for solving the Josephus problem\nusingacircularqueue.\nwww.it-ebooks.info\n248 Chapter6. Stacks,Queues,andDeques\n6.3 Double-Ended Queues\nWe next consider a queue-like data structure that supports insertion and deletion\nat both the front and the back of the queue. Such a structure is called a double-\nended queue, or deque, which is usually pronounced \u201cdeck\u201d to avoid confusion\nwith the dequeue method of the regular queue ADT,which ispronounced like the\nabbreviation \u201cD.Q.\u201d\nThedequeabstract datatypeismoregeneral thanboththestackandthequeue\nADTs. The extra generality can be useful in some applications. For example, we\ndescribed a restaurant using a queue to maintain a waitlist. Occasionally, the first\npersonmightberemovedfromthequeueonlytofindthatatablewasnotavailable;\ntypically, therestaurant willreinsert theperson atthefirstposition inthequeue. It\nmayalsobethatacustomer attheendofthequeue maygrow impatient andleave\nthe restaurant. (We will need an even more general data structure if we want to\nmodelcustomersleaving thequeuefromotherpositions.)\n6.3.1 The Deque Abstract Data Type\nThe deque abstract data type is richer than both the stack and the queue ADTs.\nTo provide a symmetrical abstraction, the deque ADT is defined to support the\nfollowingupdatemethods:\naddFirst(e): Insertanewelementeatthefrontofthedeque.\naddLast(e): Insertanewelementeatthebackofthedeque.\nremoveFirst(): Removeandreturnthefirstelementofthedeque\n(ornullifthedequeisempty).\nremoveLast(): Removeandreturnthelastelementofthedeque\n(ornullifthedequeisempty).\nAdditionally, thedequeADTwillincludethefollowingaccessors:\nfirst(): Returns the first element of the deque, without removing it\n(ornullifthedequeisempty).\nlast(): Returns the last element of the deque, without removing it\n(ornullifthedequeisempty).\nsize(): Returnsthenumberofelementsinthedeque.\nisEmpty(): Returnsaboolean indicating whetherthedequeisempty.\nWeformalizethedequeADTwiththeJavainterfaceshowninCodeFragment6.14.\nwww.it-ebooks.info\n6.3. Double-EndedQueues 249\n1 /\u2217\u2217\n2 \u2217 Interface for a double-ended queue: a collection of elements that can be inserted\n3 \u2217 and removed at both ends; this interface is a simplified version of java.util.Deque.\n4 \u2217/\n5 public interface Deque<E>\n6 /\u2217\u2217 Returns the number of { elements in the deque. \u2217/\n7 int size();\n8 /\u2217\u2217 Tests whether the deque is empty. \u2217/\n9 boolean isEmpty();\n10 /\u2217\u2217 Returns, but does not remove, the first element of the deque (null if empty). \u2217/\n11 E first();\n12 /\u2217\u2217 Returns, but does not remove, the last element of the deque (null if empty). \u2217/\n13 E last();\n14 /\u2217\u2217 Inserts an element at the front of the deque. \u2217/\n15 void addFirst(E e);\n16 /\u2217\u2217 Inserts an element at the back of the deque. \u2217/\n17 void addLast(E e);\n18 /\u2217\u2217 Removes and returns the first element of the deque (null if empty). \u2217/\n19 E removeFirst();\n20 /\u2217\u2217 Removes and returns the last element of the deque (null if empty). \u2217/\n21 E removeLast();\n22\n}\nCodeFragment6.14: A Java interface, Deque, describing the double-ended queue\nADT.Notetheuseofthegenericparameterizedtype,E,allowingadequetocontain\nelementsofanyspecifiedclass.\nExample 6.5: Thefollowingtableshowsaseriesofoperationsandtheireffects\nonaninitiallyemptydequeDofintegers.\nMethod ReturnValue D\naddLast(5) \u2013 (5)\naddFirst(3) \u2013 (3, 5)\naddFirst(7) \u2013 (7, 3, 5)\nfirst() 7 (7, 3, 5)\nremoveLast() 5 (7, 3)\nsize() 2 (7, 3)\nremoveLast() 3 (7)\nremoveFirst() 7 ()\naddFirst(6) \u2013 (6)\nlast() 6 (6)\naddFirst(8) \u2013 (8, 6)\nisEmpty() false (8, 6)\nlast() 6 (8, 6)\nwww.it-ebooks.info\n250 Chapter6. Stacks,Queues,andDeques\n6.3.2 Implementing a Deque\nWecan implement the deque ADTefficiently using either an array or a linked list\nforstoringelements.\nImplementing a Deque with a Circular Array\nIfusinganarray, werecommend arepresentation similartotheArrayQueueclass,\ntreating the array in circular fashion and storing the index of the first element and\nthe current size of the deque as fields; the index of the last element can be calcu-\nlated,asneeded, usingmodulararithmetic.\nOneextraconcernisavoiding useofnegativevalueswiththemodulooperator.\nWhen removing the first element, the front index is advanced in circular fashion,\nwiththeassignment f = (f+1) % N. Butwhenanelement isinserted atthefront,\nthefirstindexmusteffectivelybedecrementedincircularfashionanditisamistake\nto assign f = (f 1) % N. The problem is that when f is 0, the goal should be to\n\u2212\n\u201cdecrement\u201d it to the other end of the array, and thus to index N 1. However, a\n\u2212\ncalculation such as 1 % 10 in Java results in the value 1. A standard way to\n\u2212 \u2212\ndecrement anindex circularly isinstead toassign f = (f 1+N) % N. Adding the\n\u2212\nadditional term of N before the modulus is calculated assures that the result is a\npositivevalue. Weleavedetailsofthisapproach toExerciseP-6.40.\nImplementing a Deque with a Doubly Linked List\nBecause the deque requires insertion and removal at both ends, a doubly linked\nlist is most appropriate for implementing all operations efficiently. In fact, the\nDoublyLinkedList class from Section 3.4.1 already implements the entire Deque\ninterface; we simply need to add the declaration \u201cimplements Deque<E>\u201d to\nthatclassdefinitioninordertouseitasadeque.\nPerformance of the Deque Operations\nTable 6.5 shows the running times of methods for a deque implemented with a\ndoublylinkedlist. NotethateverymethodrunsinO(1)time.\nMethod RunningTime\nsize,isEmpty O(1)\nfirst,last O(1)\naddFirst,addLast O(1)\nremoveFirst,removeLast O(1)\nTable 6.5: Performance of a deque realized by either a circular array or a doubly\nlinked list. Thespace usage for thearray-based implementation isO(N),where N\nisthesizeofthearray,whilethespaceusageofthedoublylinkedlistisO(n)where\nn<N istheactualnumberofelementsinthedeque.\nwww.it-ebooks.info\n6.3. Double-EndedQueues 251\n6.3.3 Deques in the Java Collections Framework\nThe Java Collections Framework includes its own definition of a deque, as the\njava.util.Deque interface, as well as several implementations of the interface in-\ncluding one based on useofacircular array (java.util.ArrayDeque)andone based\non use of adoubly linked list (java.util.LinkedList). So, ifweneed to use adeque\nandwould rather notimplement onefrom scratch, wecansimply useoneofthose\nbuilt-in classes.\nAsisthecasewiththejava.util.Queueclass(seepage240),thejava.util.Deque\nprovides duplicative methods that use different techniques to signal exceptional\ncases. AsummaryofthosemethodsisgiveninTable6.6.\nOurDequeADT Interfacejava.util.Deque\nthrowsexceptions returns specialvalue\nfirst() getFirst() peekFirst()\nlast() getLast() peekLast()\naddFirst(e) addFirst(e) offerFirst(e)\naddLast(e) addLast(e) offerLast(e)\nremoveFirst() removeFirst() pollFirst()\nremoveLast() removeLast() pollLast()\nsize() size()\nisEmpty() isEmpty()\nTable 6.6: Methods of our deque ADT and the corresponding methods of the\njava.util.Dequeinterface.\nWhenattemptingtoaccessorremovethefirstorlastelementofanemptydeque,\nthe methods in the middle column of Table 6.6\u2014that is, getFirst(), getLast(),\nremoveFirst(),andremoveLast()\u2014throwaNoSuchElementException. Themeth-\nods in the rightmost column\u2014that is, peekFirst(), peekLast(), pollFirst(), and\npollLast()\u2014simply return the null reference when a deque is empty. In similar\nmanner, when attempting to add an element to an end of a deque with a capacity\nlimit, the addFirst and addLast methods throw an exception, while the offerFirst\nandofferLastmethodsreturnfalse.\nThemethodsthathandlebadsituations moregracefully (i.e.,withoutthrowing\nexceptions) are useful in applications, known as producer-consumer scenarios, in\nwhichitiscommonforonecomponentofsoftwaretolookforanelementthatmay\nhavebeenplacedinaqueuebyanotherprogram,orinwhichitiscommontotryto\ninsertanitemintoafixed-sizedbufferthatmightbefull. However,havingmethods\nreturn null when empty are not appropriate for applications in which null might\nserveasanactualelementofaqueue.\nwww.it-ebooks.info\n252 Chapter6. Stacks,Queues,andDeques\n6.4 Exercises\nReinforcement\nR-6.1 SupposeaninitiallyemptystackShasperformedatotalof25pushoperations,\n12topoperations,and10popoperations,3ofwhichreturnednulltoindicatean\nemptystack. WhatisthecurrentsizeofS?\nR-6.2 HadthestackofthepreviousproblembeenaninstanceoftheArrayStackclass,\nfrom Code Fragment 6.2, what would be the final value of the instance vari-\nablet?\nR-6.3 Whatvaluesarereturnedduringthefollowingseriesofstackoperations,ifexe-\ncuteduponaninitiallyemptystack?push(5),push(3),pop(),push(2),push(8),\npop(),pop(),push(9),push(1),pop(),push(7),push(6),pop(),pop(),push(4),\npop(),pop().\nR-6.4 Implement a method with signature transfer(S, T) that transfers all elements\nfromstackSontostackT,sothattheelementthatstartsatthetopofSisthefirst\ntobeinsertedontoT,andtheelementatthebottomofSendsupatthetopofT.\nR-6.5 Givearecursivemethodforremovingalltheelementsfromastack.\nR-6.6 Givea preciseandcompletedefinitionoftheconceptofmatchingforgrouping\nsymbolsinanarithmeticexpression.Yourdefinitionmayberecursive.\nR-6.7 SupposeaninitiallyemptyqueueQhasperformedatotalof32enqueueopera-\ntions,10firstoperations,and15dequeueoperations,5ofwhichreturnednullto\nindicateanemptyqueue.WhatisthecurrentsizeofQ?\nR-6.8 HadthequeueofthepreviousproblembeenaninstanceoftheArrayQueueclass,\nfromCodeFragment6.10,withcapacity30neverexceeded,whatwouldbethe\nfinalvalueoftheinstancevariablef?\nR-6.9 Whatvaluesarereturnedduringthefollowingsequenceofqueueoperations,if\nexecuted on an initially empty queue? enqueue(5), enqueue(3), dequeue(),\nenqueue(2), enqueue(8), dequeue(), dequeue(), enqueue(9), enqueue(1),\ndequeue(), enqueue(7), enqueue(6), dequeue(), dequeue(), enqueue(4),\ndequeue(),dequeue().\nR-6.10 GiveasimpleadapterthatimplementsthestackADTwhileusinganinstanceof\nadequeforstorage.\nR-6.11 Give a simple adapterthat implementsthe queueADT while using an instance\nofadequeforstorage.\nR-6.12 What values are returned during the following sequence of deque ADT\noperations, on an initially empty deque? addFirst(3), addLast(8), addLast(9),\naddFirst(1),last(),isEmpty(),addFirst(2),removeLast(),addLast(7),first(),\nlast(),addLast(4),size(),removeFirst(),removeFirst().\nwww.it-ebooks.info\n6.4. Exercises 253\nR-6.13 SupposeyouhaveadequeDcontainingthenumbers(1,2,3,4,5,6,7,8),inthis\norder. Suppose further that you have an initially empty queue Q. Give a code\nfragmentthatusesonlyDandQ(andnoothervariables)andresultsinDstoring\ntheelementsintheorder(1,2,3,5,4,6,7,8).\nR-6.14 RepeatthepreviousproblemusingthedequeDandaninitiallyemptystackS.\nR-6.15 Augment the ArrayQueue implementation with a new rotate() method having\nsemanticsidenticalto the combination,enqueue(dequeue()). But, yourimple-\nmentationshouldbemoreefficientthanmakingtwoseparatecalls(forexample,\nbecausethereisnoneedtomodifythesize).\nCreativity\nC-6.16 SupposeAlicehaspickedthreedistinctintegersandplacedthemintoastackSin\nrandomorder. Writeashort,straightlinepieceofpseudocode(withnoloopsor\nrecursion)thatusesonlyonecomparisonandonlyonevariablex,yetthatresults\nin variable x storing the largest of Alice\u2019s three integers with probability 2/3.\nArguewhyyourmethodiscorrect.\nC-6.17 Showhowtousethetransfermethod,describedinExerciseR-6.4,andtwotem-\nporarystacks,toreplacethecontentsofagivenstackSwiththosesameelements,\nbutinreversedorder.\nC-6.18 InCodeFragment6.8weassumethatopeningtagsinHTMLhaveform<name>,\naswith<li>. Moregenerally,HTMLallowsoptionalattributestobeexpressed\nas partof an openingtag. The generalformused for expressingan attribute is\n<name attribute1=\"value1\" attribute2=\"value2\">; for example, a ta-\nble can be given a border and additional padding by using an opening tag of\n<table border=\"3\" cellpadding=\"5\">. ModifyCodeFragment6.8sothat\nitcanproperlymatchtags,evenwhenanopeningtagmayincludeoneormore\nsuchattributes.\nC-6.19 Postfixnotationisanunambiguouswayofwritinganarithmeticexpressionwith-\noutparentheses.Itisdefinedsothatif\u201c(exp )op(exp )\u201disanormalfullyparen-\n1 2\nthesized expressionwhoseoperationis op, the postfixversionof this is \u201cpexp\n1\npexp op\u201d,wherepexp isthepostfixversionofexp andpexp isthepostfixver-\n2 1 1 2\nsionofexp .Thepostfixversionofasinglenumberorvariableisjustthatnumber\n2\norvariable. So,forexample,thepostfixversionof\u201c((5+2) (8 3))/4\u201dis\u201c5\n\u2217 \u2212\n2 + 8 3 4 /\u201d. Describe a nonrecursiveway of evaluatingan expressionin\n\u2212 \u2217\npostfixnotation.\nC-6.20 SupposeyouhavethreenonemptystacksR,S,andT.Describeasequenceofop-\nerationsthatresultsinSstoringallelementsoriginallyinT belowallofS\u2019sorig-\ninalelements,withbothsetsofthoseelementsintheiroriginalorder. Thefinal\nconfigurationforRshouldbethesameasitsoriginalconfiguration.Forexample,\nifR=(1,2,3),S=(4,5),andT =(6,7,8,9),whenorderedfrombottomtotop,\nthenthefinalconfigurationshouldhaveR=(1,2,3)andS=(6,7,8,9,4,5).\nwww.it-ebooks.info\n254 Chapter6. Stacks,Queues,andDeques\nC-6.21 Describeanonrecursivealgorithmforenumeratingallpermutationsofthenum-\nbers 1,2,...,n usinganexplicitstack.\n{ }\nC-6.22 Alice has three array-based stacks, A, B, andC, such that A has capacity 100,\nB has capacity 5, and C has capacity 3. Initially, A is full, and B and C are\nempty. Unfortunately, the person who programmed the class for these stacks\nmadethepushandpopmethodsprivate.TheonlymethodAlicecanuseisastatic\nmethod,dump(S,T),whichtransfers(byiterativelyapplyingtheprivatepopand\npush methods) elements from stack S to stack T until either S becomesempty\nor T becomesfull. So, for example, starting from ourinitial configurationand\nperformingdump(A,C) resultsin A nowholding97elementsandC holding3.\nDescribeasequenceofdumpoperationsthatstartsfromtheinitialconfiguration\nandresultsinBholding4elementsattheend.\nC-6.23 ShowhowtouseastackSandaqueueQtogenerateallpossiblesubsetsofan\nn-elementsetT nonrecursively.\nC-6.24 Suppose you have a stack S containing n elements and a queue Q that is ini-\ntiallyempty. DescribehowyoucanuseQtoscanStoseeifitcontainsacertain\nelementx, withtheadditionalconstraintthatyouralgorithmmustreturntheel-\nementsbacktoSintheiroriginalorder. YoumayonlyuseS,Q,andaconstant\nnumberofotherprimitivevariables.\nC-6.25 Describe how to implementthe stack ADT usinga single queue as an instance\nvariable, and only constantadditionallocal memorywithin the methodbodies.\nWhatis the runningtime of thepush(), pop(), and top()methodsforyourde-\nsign?\nC-6.26 WhenimplementingtheArrayQueueclass,weinitialized f =0(atline5ofCode\nFragment6.10). Whatwouldhappenhadweinitializedthatfieldtosomeother\npositivevalue? Whatifwehadinitializeditto 1?\n\u2212\nC-6.27 Implementtheclone()methodfortheArrayStack class. (SeeSection3.6fora\ndiscussionofcloningdatastructures.)\nC-6.28 Implementtheclone()methodfortheArrayQueueclass. (SeeSection3.6fora\ndiscussionofcloningdatastructures.)\nC-6.29 Implementamethodwithsignatureconcatenate(LinkedQueue<E> Q2)forthe\nLinkedQueue<E> class thattakes all elements ofQ2 and appendsthem to the\nend of the original queue. The operation should run in O(1) time and should\nresultinQ2beinganemptyqueue.\nC-6.30 Giveapseudocodedescriptionforanarray-basedimplementationofthedouble-\nendedqueueADT.Whatistherunningtimeforeachoperation?\nC-6.31 DescribehowtoimplementthedequeADTusingtwostacksastheonlyinstance\nvariables.Whataretherunningtimesofthemethods?\nC-6.32 SupposeyouhavetwononemptystacksS andT anda dequeD. Describehow\ntouseDsothatSstoresalltheelementsofT belowallofitsoriginalelements,\nwithbothsetsofelementsstillintheiroriginalorder.\nwww.it-ebooks.info\n6.4. Exercises 255\nC-6.33 Alicehastwocircularqueues,CandD,whichcanstoreintegers.BobgivesAlice\n50oddintegersand 50evenintegersandinsists thatshe storesall100integers\ninCandD. TheythenplayagamewhereBobpicksCorDatrandomandthen\nappliesthe rotate() methodto thechosenqueuearandomnumberoftimes. If\nthelastnumbertoberotatedattheendofthisgameisodd,Bobwins.Otherwise,\nAlice wins. How canAlice allocate integerstoqueuesto optimizeherchances\nofwinning?Whatisherchanceofwinning?\nC-6.34 SupposeBob hasfourcowsthathe wantsto take acrossa bridge,butonlyone\nyoke,whichcanholduptotwocows,sidebyside,tiedtotheyoke. Theyokeis\ntoo heavyforhimto carryacrossthe bridge,buthe cantie (anduntie) cowsto\nit in no time at all. Of his fourcows, Mazie can cross the bridgein 2 minutes,\nDaisycancrossitin4minutes,Crazycancrossitin10minutes,andLazycan\ncrossitin20minutes. Ofcourse,whentwocowsaretiedtotheyoke,theymust\ngoatthespeedoftheslowercow. DescribehowBobcangetallhiscowsacross\nthebridgein34minutes.\nProjects\nP-6.35 Implementaprogramthatcaninputanexpressioninpostfixnotation(seeExer-\nciseC-6.19)andoutputitsvalue.\nP-6.36 When a share of commonstock of some companyis sold, thecapitalgain(or,\nsometimes,loss)isthedifferencebetweentheshare\u2019ssellingpriceandtheprice\noriginallypaid to buyit. Thisrule is easy to understandfor a single share, but\nif we sell multiple shares of stock bought over a long period of time, then we\nmustidentifythesharesactuallybeingsold. Astandardaccountingprinciplefor\nidentifying which shares of a stock were sold in such a case is to use a FIFO\nprotocol\u2014theshares sold are the ones thathave been held the longest(indeed,\nthisisthedefaultmethodbuiltintoseveralpersonalfinancesoftwarepackages).\nForexample,supposewebuy100sharesat$20eachonday1,20sharesat$24\nonday2, 200sharesat$36onday3, andthensell 150sharesonday 4at$30\neach. Then applyingthe FIFO protocolmeansthatof the 150 sharessold, 100\nwere bought on day 1, 20 were bought on day 2, and 30 were bought on day\n3. Thecapitalgainin thiscase wouldthereforebe100 10+20 6+30 ( 6),\n\u00b7 \u00b7 \u00b7 \u2212\nor $940. Write a programthat takes as inputa sequence of transactions of the\nform \u201cbuy x share(s) at $y each\u201dor \u201csell x share(s) at $y each,\u201d\nassumingthatthetransactionsoccuronconsecutivedaysandthevaluesxandy\nareintegers.Giventhisinputsequence,theoutputshouldbethetotalcapitalgain\n(orloss)fortheentiresequence,usingtheFIFOprotocoltoidentifyshares.\nP-6.37 DesignanADTforatwo-color,double-stackADTthatconsistsoftwostacks\u2014\none\u201cred\u201dandone\u201cblue\u201d\u2014andhasasitsoperationscolor-codedversionsofthe\nregular stack ADT operations. For example, this ADT should support both a\nredPush operationand a bluePush operation. Givean efficientimplementation\nof this ADT using a single array whose capacity is set at some value N that is\nassumedtoalwaysbelargerthanthesizesoftheredandbluestackscombined.\nwww.it-ebooks.info\n256 Chapter6. Stacks,Queues,andDeques\nP-6.38 TheintroductionofSection6.1notesthatstacksareoftenusedtoprovide\u201cundo\u201d\nsupportinapplicationslikeaWebbrowserortexteditor. Whilesupportforundo\ncan be implemented with an unboundedstack, many applicationsprovideonly\nlimitedsupportforsuchanundohistory,withafixed-capacitystack. Whenpush\nis invoked with the stack at full capacity, rather than throwing an exception, a\nmoretypicalsemanticistoacceptthepushedelementatthetopwhile\u201cleaking\u201d\nthe oldestelementfromthe bottomof the stack to makeroom. Givean imple-\nmentationofsuchaLeakyStackabstraction,usingacirculararray.\nP-6.39 Repeat the previousproblemusing a singly linkedlist for storage, anda maxi-\nmumcapacityspecifiedasaparametertotheconstructor.\nP-6.40 GiveacompleteimplementationoftheDequeADTusingafixed-capacityarray,\nsothateachoftheupdatemethodsrunsinO(1)time.\nChapter Notes\nWewereintroducedtotheapproachofdefiningdatastructuresfirstintermsoftheirADTs\nandthenintermsofconcreteimplementationsbytheclassicbooksbyAho,Hopcroft,and\nUllman[5,6]. ExercisesC-6.22,C-6.33,andC-6.34aresimilartointerviewquestionssaid\nto be froma well-knownsoftware company. For furtherstudyof abstractdata types, see\nLiskovandGuttag[67]andDemurjian[28].\nwww.it-ebooks.info\nChapter\n7\nList and Iterator ADTs\nContents\n7.1 The List ADT . . . . . . . . . . . . . . . . . . . . . . . . . 258\n7.2 Array Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\n7.2.1 Dynamic Arrays . . . . . . . . . . . . . . . . . . . . . . . 263\n7.2.2 Implementing a Dynamic Array . . . . . . . . . . . . . . . 264\n7.2.3 Amortized Analysis of Dynamic Arrays . . . . . . . . . . . 265\n7.2.4 Java\u2019s StringBuilder class . . . . . . . . . . . . . . . . . . 269\n7.3 Positional Lists . . . . . . . . . . . . . . . . . . . . . . . . . 270\n7.3.1 Positions . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n7.3.2 The Positional List Abstract Data Type . . . . . . . . . . 272\n7.3.3 Doubly Linked List Implementation . . . . . . . . . . . . . 276\n7.4 Iterators. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\n7.4.1 The Iterable Interface and Java\u2019s For-Each Loop . . . . . 283\n7.4.2 Implementing Iterators . . . . . . . . . . . . . . . . . . . 284\n7.5 The Java Collections Framework . . . . . . . . . . . . . . . 288\n7.5.1 List Iterators in Java . . . . . . . . . . . . . . . . . . . . 289\n7.5.2 Comparison to Our Positional List ADT . . . . . . . . . . 290\n7.5.3 List-Based Algorithms in the Java Collections Framework . 291\n7.6 Sorting a Positional List . . . . . . . . . . . . . . . . . . . . 293\n7.7 Case Study: Maintaining Access Frequencies . . . . . . . . 294\n7.7.1 Using a Sorted List . . . . . . . . . . . . . . . . . . . . . 294\n7.7.2 Using a List with the Move-to-Front Heuristic . . . . . . . 297\n7.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\nwww.it-ebooks.info\n258 Chapter7. ListandIteratorADTs\n7.1 The List ADT\nIn Chapter 6, we introduced the stack, queue, and deque abstract data types, and\ndiscussedhoweitheranarrayoralinkedlistcouldbeusedforstorageinanefficient\nconcreteimplementationofeach. EachofthoseADTsrepresentsalinearlyordered\nsequence of elements. The deque is the most general of the three, yet even so, it\nonlyallowsinsertions anddeletions atthefrontorbackofasequence.\nInthischapter, weexploreseveralabstractdatatypesthatrepresentalinearse-\nquenceofelements,butwithmoregeneralsupportforaddingorremovingelements\natarbitrarypositions. However,designingasingleabstractionthatiswellsuitedfor\nefficient implementation with either an array or a linked list is challenging, given\ntheverydifferentnatureofthesetwofundamental datastructures.\nLocations within an array are easily described with an integer index. Recall\nthat an index of an element e in a sequence is equal to the number of elements\nbefore e in that sequence. By this definition, the first element of a sequence has\nindex 0, and the last has index n 1, assuming that n denotes the total number of\n\u2212\nelements. Thenotionofanelement\u2019sindexiswelldefinedforalinkedlistaswell,\nalthough we will see that it is not as convenient of a notion, as there is no way to\nefficiently access an element at a given index without traversing a portion of the\nlinkedlistthatdepends uponthemagnitude oftheindex.\nWith that said, Java defines ageneral interface, java.util.List, that includes the\nfollowingindex-based methods(andmore):\nsize(): Returnsthenumberofelementsinthelist.\nisEmpty(): Returnsaboolean indicating whetherthelistisempty.\nget(i): Returns the element of thelist having index i; anerror condition\noccursifiisnotinrange[0,size() 1].\n\u2212\nset(i,e): Replacestheelementatindexiwithe,andreturnstheoldelement\nthat was replaced; an error condition occurs if i is not in range\n[0,size() 1].\n\u2212\nadd(i,e): Inserts a new element e into the list so that it has index i, mov-\ning all subsequent elements one index later in the list; an error\ncondition occursifiisnotinrange[0,size()].\nremove(i): Removes and returns the element at index i, moving all subse-\nquent elements one index earlier in the list; an error condition\noccursifiisnotinrange[0,size() 1].\n\u2212\nWe note that the index of an existing element may change over time, as other\nelementsareaddedorremovedinfrontofit. Wealsodrawattentiontothefactthat\ntherangeofvalidindicesfortheaddmethodincludesthecurrentsizeofthelist,in\nwhichcasethenewelementbecomesthelast.\nwww.it-ebooks.info\n7.1. TheListADT 259\nExample 7.1 demonstrates a series of operations on a list instance, and Code\nFragment 7.1 below provides a formal definition of our simplified version of the\nList interface; we use an IndexOutOfBoundsException to signal an invalid index\nargument.\nExample 7.1: Wedemonstrateoperationsonaninitiallyemptylistofcharacters.\nMethod ReturnValue ListContents\nadd(0, A) \u2013 (A)\nadd(0, B) \u2013 (B, A)\nget(1) A (B, A)\nset(2, C) \u201cerror\u201d (B, A)\nadd(2, C) \u2013 (B, A, C)\nadd(4, D) \u201cerror\u201d (B, A, C)\nremove(1) A (B, C)\nadd(1, D) \u2013 (B, D, C)\nadd(1, E) \u2013 (B, E, D, C)\nget(4) \u201cerror\u201d (B, E, D, C)\nadd(4, F) \u2013 (B, E, D, C, F)\nset(2, G) D (B, E, G, C, F)\nget(2) G (B, E, G, C, F)\n1 /\u2217\u2217 A simplified version of the java.util.List interface. \u2217/\n2 public interface List<E>\n3 /\u2217\u2217 Returns the number o { f elements in this list. \u2217/\n4 int size();\n5\n6 /\u2217\u2217 Returns whether the list is empty. \u2217/\n7 boolean isEmpty();\n8\n9 /\u2217\u2217 Returns (but does not remove) the element at index i. \u2217/\n10 E get(int i) throws IndexOutOfBoundsException;\n11\n12 /\u2217\u2217 Replaces the element at index i with e, and returns the replaced element. \u2217/\n13 E set(int i, E e) throws IndexOutOfBoundsException;\n14\n15 /\u2217\u2217 Inserts element e to be at index i, shifting all subsequent elements later. \u2217/\n16 void add(int i, E e) throws IndexOutOfBoundsException;\n17\n18 /\u2217\u2217 Removes/returns the element at index i, shifting subsequent elements earlier. \u2217/\n19 E remove(int i) throws IndexOutOfBoundsException;\n20\n}\nCodeFragment7.1: AsimpleversionoftheListinterface.\nwww.it-ebooks.info\n260 Chapter7. ListandIteratorADTs\n7.2 Array Lists\nAn obvious choice for implementing the list ADT is to use an array A, where A[i]\nstores(areferenceto)theelementwithindexi. Wewillbeginbyassumingthatwe\nhaveafixed-capacityarray,butinSection7.2.1describeamoreadvancedtechnique\nthat effectively allows an array-based list to have unbounded capacity. Such an\nunbounded list is known as an array list in Java (or a vector in C++ and in the\nearliestversions ofJava).\nWitharepresentation basedonanarrayA,theget(i)andset(i,e)methods are\neasy to implement by accessing A[i] (assuming i is a legitimate index). Methods\nadd(i,e)andremove(i)aremoretimeconsuming,astheyrequireshiftingelements\nup or downto maintain our rule ofalways storing anelement whose list index is i\natindexiofthearray. (SeeFigure7.1.) OurinitialimplementationoftheArrayList\nclassfollowsinCodeFragments7.2and7.3.\n0 1 2 i n 1 N 1\n\u2212 \u2212\n(a)\n0 1 2 i n 1 N 1\n\u2212 \u2212\n(b)\nFigure7.1: Array-based implementation of an array list that is storing n elements:\n(a)shiftingupforaninsertionatindexi;(b)shiftingdownforaremovalatindexi.\n1 public class ArrayList<E> implements List<E>\n{\n2 // instance variables\n3 public static final int CAPACITY=16; // default array capacity\n4 private E[ ] data; // generic array used for storage\n5 private int size = 0; // current number of elements\n6 // constructors\n7 public ArrayList() this(CAPACITY); // constructs list with default capacity\n{ }\n8 public ArrayList(int capacity) // constructs list with given capacity\n{\n9 data = (E[ ]) new Object[capacity]; // safe cast; compiler may give warning\n10\n}\nCodeFragment7.2: An implementation of a simple ArrayList class with bounded\ncapacity. (Continues inCodeFragment7.3.)\nwww.it-ebooks.info\n7.2. ArrayLists 261\n11 // public methods\n12 /\u2217\u2217 Returns the number of elements in the array list. \u2217/\n13 public int size() return size;\n14 /\u2217\u2217 Returns whet { her the array li } st is empty. \u2217/\n15 public boolean isEmpty() return size == 0;\n16 /\u2217\u2217 Returns (but does not r { emove) the element } at index i. \u2217/\n17 public E get(int i) throws IndexOutOfBoundsException\n{\n18 checkIndex(i, size);\n19 return data[i];\n20\n21 } /\u2217\u2217 Replaces the element at index i with e, and returns the replaced element. \u2217/\n22 public E set(int i, E e) throws IndexOutOfBoundsException\n{\n23 checkIndex(i, size);\n24 E temp = data[i];\n25 data[i] = e;\n26 return temp;\n27\n28 } /\u2217\u2217 Inserts element e to be at index i, shifting all subsequent elements later. \u2217/\n29 public void add(int i, E e) throws IndexOutOfBoundsException,\n30 IllegalStateException\n{\n31 checkIndex(i, size + 1);\n32 if (size == data.length) // not enough capacity\n33 throw new IllegalStateException(\"Array is full\");\n34 for (int k=size 1; k >= i; k ) // start by shifting rightmost\n\u2212 \u2212\u2212\n35 data[k+1] = data[k];\n36 data[i] = e; // ready to place the new element\n37 size++;\n38\n39 } /\u2217\u2217 Removes/returns the element at index i, shifting subsequent elements earlier. \u2217/\n40 public E remove(int i) throws IndexOutOfBoundsException\n{\n41 checkIndex(i, size);\n42 E temp = data[i];\n43 for (int k=i; k < size 1; k++) // shift elements to fill hole\n\u2212\n44 data[k] = data[k+1];\n45 data[size 1] = null; // help garbage collection\n\u2212\n46 size ;\n\u2212\u2212\n47 return temp;\n48\n}\n49 // utility method\n50 /\u2217\u2217 Checks whether the given index is in the range [0, n 1]. \u2217/\n\u2212\n51 protected void checkIndex(int i, int n) throws IndexOutOfBoundsException\n{\n52 if (i < 0 i >= n)\n||\n53 throw new IndexOutOfBoundsException(\"Illegal index: \" + i);\n54\n}\n55\n}\nCodeFragment7.3: An implementation of a simple ArrayList class with bounded\ncapacity. (Continued fromCodeFragment7.2.)\nwww.it-ebooks.info\n262 Chapter7. ListandIteratorADTs\nThe Performance of a Simple Array-Based Implementation\nTable7.1showstheworst-caserunningtimesofthemethodsofanarraylistwithn\nelementsrealizedbymeansofanarray. MethodsisEmpty,size,getandsetclearly\nruninO(1)time,buttheinsertionandremovalmethodscantakemuchlongerthan\nthis. In particular, add(i, e) runs in time O(n). Indeed, the worst case for this\noperation occurs when i is 0, since all the existing n elements have to be shifted\nforward. A similar argument applies to method remove(i), which runs in O(n)\ntime, because we have to shift backward n 1 elements in the worst case, when i\n\u2212\nis0. Infact, assuming that each possible index isequally likely tobe passed asan\nargument to these operations, their average running timeis O(n), for wewill have\ntoshiftn/2elementsonaverage.\nMethod RunningTime\nsize() O(1)\nisEmpty() O(1)\nget(i) O(1)\nset(i,e) O(1)\nadd(i,e) O(n)\nremove(i) O(n)\nTable7.1: Performanceofanarraylistwithnelementsrealizedbyafixed-capacity\narray.\nLookingmorecloselyatadd(i,e)andremove(i),wenotethattheyeachrunin\ntime O(n i+1), for only those elements at index i and higher have to be shifted\n\u2212\nup or down. Thus, inserting or removing an item at the end of an array list, us-\ning the methods add(n, e) and remove(n 1) respectively, takes O(1) time each.\n\u2212\nMoreover,thisobservationhasaninterestingconsequencefortheadaptationofthe\narraylistADTtothedequeADTfromSection6.3.1. Ifwedothe\u201cobvious\u201d thing\nand store elements of a deque so that the first element is at index 0 and the last\nelement at index n 1, then methods addLast and removeLast of the deque each\n\u2212\nrun in O(1) time. However, methods addFirst and removeFirst of the deque each\nruninO(n)time.\nActually, withalittleeffort, wecanproduce anarray-based implementation of\nthearraylistADTthatachievesO(1)timeforinsertionsandremovalsatindex0,as\nwellasinsertions andremovals attheendofthearray list. Achieving thisrequires\nthatwegiveuponourrulethatanelementatindexiisstoredinthearrayatindexi,\nhowever,aswewouldhavetouseacirculararrayapproachliketheoneweusedin\nSection 6.2 to implement a queue. We leave the details of this implementation as\nExerciseC-7.25.\nwww.it-ebooks.info\n7.2. ArrayLists 263\n7.2.1 Dynamic Arrays\nTheArrayListimplementation inCodeFragments 7.2and7.3(aswellasthosefor\nastack, queue, and deque from Chapter 6)hasaserious limitation; itrequires that\nafixedmaximumcapacity bedeclared, throwing anexception ifattempting toadd\nan element once full. This is a major weakness, because if a user is unsure of the\nmaximum size that will be reached for a collection, there is risk that either too\nlarge ofanarraywillberequested, causing aninefficient wasteofmemory,orthat\ntoo small of an array will be requested, causing a fatal error when exhausting that\ncapacity.\nJava\u2019s ArrayList class provides a more robust abstraction, allowing a user to\nadd elements tothe list, withnoapparent limit ontheoverall capacity. Toprovide\nthis abstraction, Java relies on an algorithmic sleight of hand that is known as a\ndynamicarray.\nIn reality, elements of an ArrayList are stored in a traditional array, and the\nprecise size of that traditional array must be internally declared in order for the\nsystem to properly allocate a consecutive piece of memory for its storage. For\nexample,Figure7.2displaysanarraywith12cellsthatmightbestoredinmemory\nlocations 2146through2157onacomputersystem.\n4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0\n4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6\n1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\nFigure7.2: Anarrayof12cells,allocatedinmemorylocations2146through2157.\nBecausethesystemmayallocateneighboringmemorylocationstostoreotherdata,\nthecapacityofanarraycannotbeincreased byexpanding intosubsequent cells.\nThefirstkeytoproviding thesemantics ofanunbounded arrayisthatanarray\nlist instance maintains an internal array that often has greater capacity than the\ncurrent length of the list. For example, while a user may have created a list with\nfiveelements,thesystemmayhavereservedanunderlyingarraycapableofstoring\neight object references (rather thanonly five). Thisextra capacity makes iteasyto\naddanewelementtotheendofthelistbyusingthenextavailablecellofthearray.\nIfausercontinuestoaddelementstoalist,allreservedcapacityintheunderly-\ningarraywilleventuallybeexhausted. Inthatcase,theclassrequestsanew,larger\narray from the system, and copies all references from the smaller array into the\nbeginningofthenewarray. Atthatpointintime,theoldarrayisnolongerneeded,\nso it can be reclaimed by the system. Intuitively, this strategy is much like that of\nthehermitcrab,whichmovesintoalargershellwhenitoutgrowsitspreviousone.\nwww.it-ebooks.info\n264 Chapter7. ListandIteratorADTs\n7.2.2 Implementing a Dynamic Array\nWe now demonstrate how our original version of the ArrayList, from Code Frag-\nments 7.2and7.3, canbe transformed to adynamic-array implementation, having\nunboundedcapacity. Werelyonthesameinternalrepresentation, withatraditional\narrayA,thatisinitializedeithertoadefaultcapacityortoonespecifiedasaparam-\netertotheconstructor.\nThekeyistoprovidemeansto\u201cgrow\u201dthearrayA,whenmorespaceisneeded.\nOf course, we cannot actually grow that array, as its capacity is fixed. Instead,\nwhen a call to add a new element risks overflowing the current array, we perform\nthefollowingadditional steps:\n1. AllocateanewarrayBwithlargercapacity.\n2. SetB[k]=A[k],fork=0,...,n 1,wherendenotescurrentnumberofitems.\n\u2212\n3. SetA=B,thatis,wehenceforth usethenewarraytosupportthelist.\n4. Insertthenewelementinthenewarray.\nAnillustration ofthisprocessisshowninFigure7.3.\nA A\nB B A\n(a) (b) (c)\nFigure7.3: An illustration of \u201cgrowing\u201d a dynamic array: (a) create new array B;\n(b) store elements of A inB; (c) reassign reference Ato the new array. Not shown\nisthefuturegarbagecollection oftheoldarray, ortheinsertion ofanewelement.\nCode Fragment 7.4 provides a concrete implementation of a resize method,\nwhichshouldbeincludedasaprotectedmethodwithintheoriginalArrayListclass.\nTheinstancevariabledatacorrespondstoarrayAintheabovediscussion,andlocal\nvariabletempcorresponds toarrayB.\n/\u2217\u2217 Resizes internal array to have given capacity >= size. \u2217/\nprotected void resize(int capacity)\n{\nE[ ] temp = (E[ ]) new Object[capacity]; // safe cast; compiler may give warning\nfor (int k=0; k < size; k++)\ntemp[k] = data[k];\ndata = temp; // start using the new array\n}\nCodeFragment7.4: Animplementation oftheArrayList.resizemethod.\nwww.it-ebooks.info\n7.2. ArrayLists 265\nTheremaining issue toconsider ishow large ofanew array tocreate. Acom-\nmonlyusedruleisforthenewarraytohavetwicethecapacityoftheexistingarray\nthat has been filled. In Section 7.2.3, we will provide a mathematical analysis to\njustifysuchachoice.\nTocompletetherevisiontoouroriginalArrayListimplementation, weredesign\ntheaddmethodsothatitcallsthenewresizeutilitywhendetectingthatthecurrent\narray is filled (rather than throwing an exception). The revised version appears in\nCodeFragment7.5.\n28 /\u2217\u2217 Inserts element e to be at index i, shifting all subsequent elements later. \u2217/\n29 public void add(int i, E e) throws IndexOutOfBoundsException\n{\n30 checkIndex(i, size + 1);\n31 if (size == data.length) // not enough capacity\n32 resize(2 \u2217 data.length); // so double the current capacity\n... // rest of method unchanged...\nCodeFragment7.5: Arevision totheArrayList.addmethod, originally from Code\nFragment 7.3, which calls the resize method of Code Fragment 7.4 when more\ncapacity isneeded.\nFinally,wenotethatouroriginalimplementationoftheArrayListclassincludes\ntwo constructors: a default constructor that uses an initial capacity of 16, and a\nparameterized constructor that allows the caller to specify a capacity value. With\nthe use of dynamic arrays, that capacity is no longer a fixed limit. Still, greater\nefficiencyisachievedwhenauserselectsaninitialcapacitythatmatchestheactual\nsize of a data set, as this can avoid time spent on intermediate array reallocations\nandpotential spacethatiswastedbyhavingtoolargeofanarray.\n7.2.3 Amortized Analysis of Dynamic Arrays\nInthissection,wewillperformadetailedanalysisoftherunningtimeofoperations\non dynamic arrays. As a shorthand notation, let us refer to the insertion of an\nelementtobethelastelementinanarraylistasapushoperation.\nThe strategy of replacing an array with a new, larger array might at first seem\nslow, because a single push operation may require \u2126(n) time to perform, where n\nis the current number of elements in the array. (Recall, from Section 4.3.1, that\nbig-Omega notation, describes an asymptotic lower bound on the running time of\nanalgorithm.) However,bydoublingthecapacityduringanarrayreplacement,our\nnew array allows us to add n further elements before the array must be replaced\nagain. In this way, there are many simple push operations for each expensive one\n(seeFigure7.4). Thisfactallowsustoshowthataseries ofpush operations onan\ninitially emptydynamicarrayisefficientintermsofitstotalrunning time.\nwww.it-ebooks.info\n266 Chapter7. ListandIteratorADTs\nhsup\na\nrof\nsnoitarepo\nevitimirp\n1 2 3 4 5 6 7 8 9 10111213 141516\ncurrent number of elements\nFigure7.4: Runningtimesofaseriesofpushoperations onadynamicarray.\nUsinganalgorithmicdesignpatterncalledamortization,weshowthatperform-\ningasequenceofpushoperationsonadynamicarrayisactuallyquiteefficient. To\nperform an amortized analysis, we use an accounting technique where we view\nthecomputer asacoin-operated appliance that requires the payment ofone cyber-\ndollar for a constant amount of computing time. When an operation is executed,\nweshouldhaveenoughcyber-dollarsavailableinourcurrent\u201cbankaccount\u201dtopay\nforthatoperation\u2019s running time. Thus,thetotalamountofcyber-dollars spentfor\nany computation will be proportional to the total time spent on that computation.\nThebeautyofusingthisanalysismethodisthatwecanoverchargesomeoperations\ninordertosaveupcyber-dollars topayforothers.\nProposition 7.2: LetLbeaninitiallyemptyarraylistwithcapacityone,imple-\nmentedbymeansofadynamicarraythatdoublesinsizewhenfull.Thetotaltime\ntoperformaseriesofnpushoperationsinLisO(n).\nJustification: Letusassume that onecyber-dollar isenough topayfortheexe-\ncution ofeachpushoperation inL,excluding thetimespentforgrowingthearray.\nAlso, let us assume that growing the array from size k to size 2k requires k cyber-\ndollars for the time spent initializing the new array. We shall charge each push\noperation three cyber-dollars. Thus, we overcharge each push operation that does\nnotcauseanoverflowbytwocyber-dollars. Thinkofthetwocyber-dollarsprofited\ninaninsertionthatdoesnotgrowthearrayasbeing\u201cstored\u201dwiththecellinwhich\ntheelementwasinserted. AnoverflowoccurswhenthearrayLhas2i elements,for\nsomeinteger i 0, andthe sizeofthearray used bythearray representing Lis2i.\n\u2265\nThus,doublingthesizeofthearraywillrequire2i cyber-dollars. Fortunately,these\ncyber-dollars canbefoundstoredincells2i\u22121 through 2i 1. (SeeFigure7.5.)\n\u2212\nwww.it-ebooks.info\n7.2. ArrayLists 267\n$ $ $ $\n$ $ $ $\n(a)\n0 1 2 3 4 5 6 7\n$\n$\n(b)\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\nFigure 7.5: Illustration of a series of push operations on a dynamic array: (a) an\n8-cell array isfull, with twocyber-dollars \u201cstored\u201d at cells 4through 7; (b)apush\noperation causes an overflow and a doubling of capacity. Copying the eight old\nelements to the new array is paid for by the cyber-dollars already stored in the\ntable. Inserting the new element is paid for by one of the cyber-dollars charged to\nthecurrentpushoperation, andthetwocyber-dollars profitedarestoredatcell8.\nNotethatthepreviousoverflowoccurredwhenthenumberofelementsbecame\nlarger than 2i\u22121 for the first time, and thus the cyber-dollars stored in cells 2i\u22121\nthrough 2i 1 have not yet been spent. Therefore, we have a valid amortization\n\u2212\nschemeinwhicheach operation ischarged three cyber-dollars andallthecomput-\ning time is paid for. That is, we can pay for the execution of n push operations\nusing 3n cyber-dollars. In other words, the amortized running time of each push\noperation isO(1);hence, thetotalrunningtimeofnpushoperations isO(n).\nGeometric Increase in Capacity\nAlthoughtheproofofProposition7.2reliesonthearraybeingdoubledeachtimeit\nisexpanded,theO(1)amortizedboundperoperationcanbeprovenforanygeomet-\nrically increasing progression of array sizes. (See Section 2.2.3 for discussion of\ngeometric progressions.) When choosing the geometric base, there exists a trade-\noff between runtime efficiency and memory usage. If the last insertion causes a\nresize event, with a base of 2 (i.e., doubling the array), the array essentially ends\nup twice as large as it needs to be. If we instead increase the array by only 25%\nof its current size (i.e., a geometric base of 1.25), we do not risk wasting as much\nmemoryintheend,buttherewillbemoreintermediateresizeeventsalongtheway.\nStillitispossibletoproveanO(1)amortizedbound,usingaconstantfactorgreater\nthanthe3cyber-dollars peroperation usedintheproofofProposition 7.2(seeEx-\nercise R-7.7). Thekeytotheperformance isthattheamount ofadditional spaceis\nproportional tothecurrent sizeofthearray.\nwww.it-ebooks.info\n268 Chapter7. ListandIteratorADTs\nBeware of Arithmetic Progression\nTo avoid reserving too much space at once, it might be tempting to implement a\ndynamic array with a strategy in which a constant number of additional cells are\nreserved each time an array is resized. Unfortunately, the overall performance of\nsuch a strategy is significantly worse. At an extreme, an increase of only one cell\ncauseseachpushoperationtoresizethearray,leadingtoafamiliar1+2+3+ +\n\u00b7\u00b7\u00b7\nnsummation and\u2126(n2)overallcost. Usingincreases of2or3atatimeisslightly\nbetter, asportrayed inFigure7.4,buttheoverallcostremainsquadratic.\nhsup\na\nrof\nsnoitarepo\nevitimirp\n1 2 3 4 5 6 7 8 9 10111213141516\ncurrent number of elements\nhsup\na\nrof\nsnoitarepo\nevitimirp\n1 2 3 4 5 6 7 8 9 10111213141516\ncurrent number of elements\n(a) (b)\nFigure7.6: Running timesofaseries ofpush operations onadynamic array using\narithmetic progression ofsizes. Part(a)assumes anincrease of2inthesizeofthe\narray,whilepart(b)assumesanincrease of3.\nUsing a fixed increment for each resize, and thus an arithmetic progression of\nintermediate array sizes, results in an overall time that is quadratic in the number\nof operations, as shown in the following proposition. In essence, even an increase\nin10,000cellsperresizewillbecomeinsignificant forlargedatasets.\nProposition 7.3: Performingaseriesofnpushoperationsonaninitiallyempty\ndynamicarrayusingafixedincrementwitheachresizetakes\u2126(n2)time.\nJustification: Letc>0representthefixedincrementincapacitythatisusedfor\neachresizeevent. Duringtheseriesofnpushoperations, timewillhavebeenspent\ninitializingarraysofsizec,2c,3c,...,mcform= n/c ,andtherefore,theoverall\n\u2308 \u2309\ntimeisproportional toc+2c+3c+ +mc. ByProposition 4.3,thissumis\n\u00b7\u00b7\u00b7\nm m m(m+1) n(n+1) 1\n\u2211ci =c \u2211i =c cc c n2.\n\u00b7 2 \u2265 2 \u2265 2c\u00b7\ni=1 i=1\nTherefore, performing thenpushoperations takes\u2126(n2)time.\nwww.it-ebooks.info\n7.2. ArrayLists 269\nMemory Usage and Shrinking an Array\nAnother consequence of the rule of a geometric increase in capacity when adding\ntoadynamicarrayisthatthefinalarraysizeisguaranteedtobeproportional tothe\noverall number ofelements. Thatis, the data structure uses O(n)memory. Thisis\naverydesirable property foradatastructure.\nIfacontainer, such asanarray list, provides operations that cause the removal\nofoneormoreelements,greatercaremustbetakentoensurethatadynamicarray\nguarantees O(n)memoryusage. Theriskisthatrepeated insertions maycause the\nunderlyingarraytogrowarbitrarilylarge,andthattherewillnolongerbeapropor-\ntional relationship between the actual number of elements and the array capacity\naftermanyelementsareremoved.\nA robust implementation of such a data structure will shrink the underlying\narray, onoccasion, while maintaining theO(1)amortized bound onindividual op-\nerations. However, care must be taken to ensure that the structure cannot rapidly\noscillate between growing and shrinking the underlying array, in which case the\namortizedboundwouldnotbeachieved. InExerciseC-7.29,weexploreastrategy\nin which the array capacity is halved whenever the number of actual element falls\nbelowone-fourth ofthatcapacity, therebyguaranteeing thatthearraycapacityisat\nmostfourtimesthenumberofelements;weexploretheamortizedanalysisofsuch\nastrategyinExercisesC-7.30andC-7.31.\n7.2.4 Java\u2019s StringBuilder class\nNear the beginning of Chapter 4, we described an experiment in which we com-\npared two algorithms for composing a long string (Code Fragment 4.2). The first\nof those relied on repeated concatenation using the String class, and the second\nreliedonuseofJava\u2019sStringBuilderclass. WeobservedtheStringBuilderwassig-\nnificantly faster, with empirical evidence that suggested a quadratic running time\nfor the algorithm with repeated concatenations, and a linear running time for the\nalgorithmwiththeStringBuilder. Wearenowabletoexplainthetheoreticalunder-\npinning forthoseobservations.\nThe StringBuilder class represents a mutable string by storing characters in a\ndynamic array. With analysis similar to Proposition 7.2, it guarantees that aseries\nofappendoperationsresultinginastringoflengthnexecuteinacombinedtimeof\nO(n). (Insertionsatpositionsotherthantheendofastringbuilderdonotcarrythis\nguarantee, justastheydonotforanArrayList.)\nIn contrast, the repeated use of string concatenation requires quadratic time.\nWe originally analyzed that algorithm on page 172 of Chapter 4. In effect, that\napproach isakintoadynamicarraywithanarithmeticprogression ofsizeone,re-\npeatedlycopying allcharacters fromonearraytoanewarraywithsizeonegreater\nthanbefore.\nwww.it-ebooks.info\n270 Chapter7. ListandIteratorADTs\n7.3 Positional Lists\nWhen working with array-based sequences, integer indices provide an excellent\nmeans for describing thelocation of anelement, or the location atwhich an inser-\ntionordeletion shouldtakeplace. However,numericindicesarenotagoodchoice\nfordescribingpositionswithinalinkedlistbecause,knowingonlyanelement\u2019sin-\ndex,theonlywaytoreachitistotraverse thelistincrementally fromitsbeginning\norend,counting elementsalongtheway.\nFurthermore, indices are not a good abstraction for describing a more local\nview of a position in a sequence, because the index of an entry changes over time\ndue to insertions or deletions that happen earlier in the sequence. For example, it\nmaynotbeconvenient todescribethelocation ofapersonwaitinginlinebasedon\ntheindex,asthatrequiresknowledgeofpreciselyhowfarawaythatpersonisfrom\nthe front of the line. We prefer an abstraction, as characterized in Figure 7.7, in\nwhichthereissomeothermeansfordescribing aposition.\nme\nTickets\nFigure7.7: Wewishtobeable toidentify theposition ofanelementinasequence\nwithout the use of an integer index. The label \u201cme\u201d represents some abstraction\nthatidentifiestheposition.\nOurgoalistodesignanabstractdatatypethatprovidesauserawaytoreferto\nelementsanywhereinasequence,andtoperformarbitraryinsertionsanddeletions.\nThis would allow us to efficiently describe actions such as a person deciding to\nleavethelinebefore reaching thefront, orallowingafriendto\u201ccut\u201dintolineright\nbehindhimorher.\nAs another example, a text document can be viewed as a long sequence of\ncharacters. Awordprocessorusestheabstractionofacursortodescribeaposition\nwithin the document without explicit use of an integer index, allowing operations\nsuch as\u201cdelete thecharacter atthe cursor\u201d or\u201cinsert anew character justafter the\ncursor.\u201d Furthermore, wemaybeabletorefertoaninherentposition withinadoc-\nument,suchasthebeginningofaparticular chapter,withoutrelyingonacharacter\nindex(orevenachapternumber)thatmaychangeasthedocumentevolves.\nwww.it-ebooks.info\n7.3. PositionalLists 271\nFor these reasons, we temporarily forego the index-based methods of Java\u2019s\nformalListinterface,andinsteaddevelopourownabstractdatatypethatwedenote\nas a positional list. Although a positional list is an abstraction, and need not rely\non a linked list for its implementation, we certainly have a linked list in mind as\nwedesign the ADT,ensuring that it takes best advantage of particular capabilities\nof a linked list, such as O(1)-time insertions and deletions at arbitrary positions\n(something thatisnotpossible withanarray-based sequence).\nWe face an immediate challenge in designing the ADT; to achieve constant\ntimeinsertions anddeletions atarbitrary locations, weeffectively needareference\nto the node at which an element is stored. It is therefore very tempting to develop\nan ADTinwhich anode reference serves asthe mechanism for describing aposi-\ntion. Infact,ourDoublyLinkedListclassofSection3.4.1hasmethodsaddBetween\nand remove that accept node references as parameters; however, we intentionally\ndeclared thosemethodsasprivate.\nUnfortunately, the public use of nodes in the ADT would violate the object-\norienteddesignprinciplesofabstractionandencapsulation, whichwereintroduced\ninChapter2. Thereareseveralreasonstopreferthatweencapsulate thenodesofa\nlinkedlist,forbothoursakeandforthebenefitofusersofourabstraction:\nItwillbesimplerforusersofourdatastructure iftheyarenotbotheredwith\n\u2022\nunnecessary details of our implementation, such as low-level manipulation\nof nodes, or our reliance on the use of sentinel nodes. Notice that to use\nthe addBetween method of our DoublyLinkedList class to add a node at the\nbeginning ofasequence, theheadersentinel mustbesentasaparameter.\nWe can provide a more robust data structure if we do not permit users to\n\u2022\ndirectlyaccessormanipulatethenodes. Wecanthenensurethatusersdonot\ninvalidate the consistency of a list by mismanaging the linking of nodes. A\nmoresubtle problem arises ifauserwereallowedtocalltheaddBetweenor\nremovemethodofourDoublyLinkedListclass, sending anodethatdoesnot\nbelong to the given list as a parameter. (Go back and look at that code and\nseewhyitcausesaproblem!)\nBy better encapsulating the internal details of our implementation, we have\n\u2022\ngreaterflexibilitytoredesignthedatastructureandimproveitsperformance.\nInfact,withawell-designedabstraction,wecanprovideanotionofanonnu-\nmericposition,evenifusinganarray-basedsequence. (SeeExerciseC-7.43.)\nTherefore, in defining the positional list ADT, we also introduce the concept\nofaposition, whichformalizes theintuitivenotion ofthe\u201clocation\u201d ofanelement\nrelative toothers inthelist. (Whenwedousealinked listforthe implementation,\nwewilllaterseehowwecanprivatelyusenodereferencesasnaturalmanifestations\nofpositions.)\nwww.it-ebooks.info\n272 Chapter7. ListandIteratorADTs\n7.3.1 Positions\nTo provide a general abstraction for the location of an element within a structure,\nwe define a simple position abstract data type. A position supports the following\nsinglemethod:\ngetElement(): Returnstheelementstoredatthisposition.\nApositionactsasamarkerortokenwithinabroaderpositionallist. Aposition\np,whichisassociated withsomeelementeinalistL,doesnotchange, evenifthe\nindexofechangesinLduetoinsertionsordeletionselsewhereinthelist. Nordoes\nposition pchangeifwereplacetheelementestoredat pwithanotherelement. The\nonly way in which a position becomes invalid is if that position (and its element)\nareexplicitly removedfromthelist.\nHaving a formal definition of a position type allows positions to serve as pa-\nrameters to some methods and return values from other methods of the positional\nlistADT,whichwenextdescribe.\n7.3.2 The Positional List Abstract Data Type\nWenow view apositional list asacollection of positions, each ofwhich stores an\nelement. The accessor methods provided by the positional list ADT include the\nfollowing, foralistL:\nfirst(): ReturnsthepositionofthefirstelementofL(ornullifempty).\nlast(): ReturnsthepositionofthelastelementofL(ornullifempty).\nbefore(p): Returnstheposition ofLimmediatelybeforeposition p\n(ornullif pisthefirstposition).\nafter(p): Returnstheposition ofLimmediatelyafterposition p\n(ornullif pisthelastposition).\nisEmpty(): ReturnstrueiflistLdoesnotcontainanyelements.\nsize(): ReturnsthenumberofelementsinlistL.\nAn error occurs if a position p, sent as a parameter to a method, is not a valid\nposition forthelist.\nNote well that the first() and last()methods of the positional list ADT return\ntheassociated positions, nottheelements. (Thisisincontrast tothecorresponding\nfirstandlastmethods ofthedeque ADT.)Thefirstelement ofapositional listcan\nbe determined by subsequently invoking the getElement method on that position,\nas first().getElement. The advantage of receiving a position as a return value is\nthatwecansubsequently usethatposition totraverse thelist.\nwww.it-ebooks.info\n7.3. PositionalLists 273\nAsademonstrationofatypicaltraversalofapositionallist,CodeFragment7.6\ntraverses a list, named guests, that stores string elements, and prints each element\nwhiletraversing fromthebeginning ofthelisttotheend.\n1 Position<String> cursor = guests.first();\n2 while (cursor != null)\n{\n3 System.out.println(cursor.getElement());\n4 cursor = guests.after(cursor); // advance to the next position (if any)\n5\n}\nCodeFragment7.6: Atraversalofapositional list.\nThiscodereliesontheconventionthatthenullreferenceisreturnedwhentheafter\nmethodiscalleduponthelastposition. (Thatreturnvalueisclearlydistinguishable\nfrom any legitimate position.) The positional list ADTsimilarly indicates that the\nnullvalue is returned when thebefore method is invoked atthe front of thelist, or\nwhenfirstorlastmethodsarecalleduponanemptylist. Therefore,theabovecode\nfragmentworkscorrectly eveniftheguestslistisempty.\nUpdated Methods of a Positional List\nThepositional listADTalsoincludes thefollowingupdatemethods:\naddFirst(e): Insertsanewelementeatthefrontofthelist,returningthe\nposition ofthenewelement.\naddLast(e): Insertsanewelementeatthebackofthelist,returningthe\nposition ofthenewelement.\naddBefore(p,e): Inserts a new element e in the list, just before position p,\nreturning theposition ofthenewelement.\naddAfter(p,e): Inserts a new element e in the list, just after position p,\nreturning theposition ofthenewelement.\nset(p,e): Replaces theelement atposition pwithelement e, return-\ningtheelementformerlyatposition p.\nremove(p): Removes and returns the element at position p in the list,\ninvalidating theposition.\nThere may at first seem to be redundancy in the above repertoire of opera-\ntions for the positional list ADT,since wecanperform operation addFirst(e)with\naddBefore(first(), e), and operation addLast(e) with addAfter(last(), e). But\nthesesubstitutions canonlybedoneforanonemptylist.\nwww.it-ebooks.info\n274 Chapter7. ListandIteratorADTs\nExample 7.4: Thefollowingtableshowsaseriesofoperationsonaninitially\nemptypositionalliststoringintegers. Toidentifypositioninstances,weusevari-\nablessuchaspandq.Foreaseofexposition,whendisplayingthelistcontents,we\nusesubscriptnotationtodenotethepositionstoringanelement.\nMethod ReturnValue ListContents\naddLast(8) p (8p)\nfirst() p (8p)\naddAfter(p,5) q (8p,5q)\nbefore(q) p (8p,5q)\naddBefore(q,3) r (8p,3r,5q)\nr.getElement() 3 (8p,3r,5q)\nafter(p) r (8p,3r,5q)\nbefore(p) null (8p,3r,5q)\naddFirst(9) s (9s,8p,3r,5q)\nremove(last()) 5 (9s,8p,3r)\nset(p,7) 8 (9s,7p,3r)\nremove(q) \u201cerror\u201d (9s,7p,3r)\nJava Interface Definitions\nWe are now ready to formalize the position ADT and positional list ADT. A Java\nPosition interface, representing the position ADT, is given in Code Fragment 7.7.\nFollowingthat,CodeFragment7.8presentsaJavadefinitionforourPositionalList\ninterface. If the getElement() method is called on a Position instance that has\npreviously been removed from its list, an IllegalStateException is thrown. If an\ninvalid Position instance is sent as aparameter toamethod ofa PositionalList, an\nIllegalArgumentExceptionisthrown. (Bothofthoseexceptiontypesaredefinedin\nthestandard Javahierarchy.)\n1 public interface Position<E>\n2 /\u2217\u2217 {\n3 \u2217 Returns the element stored at this position.\n4 \u2217\n5 \u2217 @return the stored element\n6 \u2217 @throws IllegalStateException if position no longer valid\n7 \u2217/\n8 E getElement() throws IllegalStateException;\n9\n}\nCodeFragment7.7: ThePositioninterface.\nwww.it-ebooks.info\n7.3. PositionalLists 275\n1 /\u2217\u2217 An interface for positional lists. \u2217/\n2 public interface PositionalList<E>\n{\n3\n4 /\u2217\u2217 Returns the number of elements in the list. \u2217/\n5 int size();\n6\n7 /\u2217\u2217 Tests whether the list is empty. \u2217/\n8 boolean isEmpty();\n9\n10 /\u2217\u2217 Returns the first Position in the list (or null, if empty). \u2217/\n11 Position<E> first();\n12\n13 /\u2217\u2217 Returns the last Position in the list (or null, if empty). \u2217/\n14 Position<E> last();\n15\n16 /\u2217\u2217 Returns the Position immediately before Position p (or null, if p is first). \u2217/\n17 Position<E> before(Position<E> p) throws IllegalArgumentException;\n18\n19 /\u2217\u2217 Returns the Position immediately after Position p (or null, if p is last). \u2217/\n20 Position<E> after(Position<E> p) throws IllegalArgumentException;\n21\n22 /\u2217\u2217 Inserts element e at the front of the list and returns its new Position. \u2217/\n23 Position<E> addFirst(E e);\n24\n25 /\u2217\u2217 Inserts element e at the back of the list and returns its new Position. \u2217/\n26 Position<E> addLast(E e);\n27\n28 /\u2217\u2217 Inserts element e immediately before Position p and returns its new Position. \u2217/\n29 Position<E> addBefore(Position<E> p, E e)\n30 throws IllegalArgumentException;\n31\n32 /\u2217\u2217 Inserts element e immediately after Position p and returns its new Position. \u2217/\n33 Position<E> addAfter(Position<E> p, E e)\n34 throws IllegalArgumentException;\n35\n36 /\u2217\u2217 Replaces the element stored at Position p and returns the replaced element. \u2217/\n37 E set(Position<E> p, E e) throws IllegalArgumentException;\n38\n39 /\u2217\u2217 Removes the element stored at Position p and returns it (invalidating p). \u2217/\n40 E remove(Position<E> p) throws IllegalArgumentException;\n41\n}\nCodeFragment7.8: ThePositionalListinterface.\nwww.it-ebooks.info\n276 Chapter7. ListandIteratorADTs\n7.3.3 Doubly Linked List Implementation\nNotsurprisingly, ourpreferredimplementationofthePositionalListinterfacerelies\non a doubly linked list. Although we implemented a DoublyLinkedList class in\nChapter3,thatclassdoesnotadheretothePositionalListinterface.\nIn this section, we develop a concrete implementation of the PositionalList\ninterface using a doubly linked list. The low-level details of our new linked-list\nrepresentation, such as the use of header and trailer sentinels, will be identical\nto our earlier version; we refer the reader to Section 3.4 for a discussion of the\ndoublylinkedlistoperations. Whatdiffersinthissectionisourmanagementofthe\npositional abstraction.\nThe obvious way to identify locations within a linked list are node references.\nTherefore, we declare the nested Node class of our linked list so as to implement\nthe Position interface, supporting the required getElement method. So the nodes\nare the positions. Yet, the Node class is declared as private, to maintain proper\nencapsulation. Allofthe public methods ofthe positional list rely onthe Position\ntype, so although we know we are sending and receiving nodes, these are only\nknown to be positions from the outside; as a result, users of our class cannot call\nanymethodotherthangetElement().\nIn Code Fragments 7.9\u20137.12, we define a LinkedPositionalList class, which\nimplementsthepositional listADT.Weprovidethefollowingguidetothatcode:\nCode Fragment 7.9 contains the definition of the nested Node<E> class,\n\u2022\nwhichimplements thePosition<E>interface. Followingthat arethedecla-\nrationoftheinstancevariablesoftheouterLinkedPositionalListclassandits\nconstructor.\nCode Fragment 7.10 begins with two important utility methods that help us\n\u2022\nrobustly cast betweenthePosition andNodetypes. Thevalidate(p)method\niscalledanytimetheusersendsaPositioninstanceasaparameter. Itthrows\nanexceptionifitdeterminesthatthepositionisinvalid,andotherwisereturns\nthat instance, implicitly cast as a Node, so that methods of the Node class\ncansubsequentlybecalled. Theprivateposition(node)methodisusedwhen\nabouttoreturnaPositiontotheuser. Itsprimarypurposeistomakesurethat\nwe do not expose either sentinel node to a caller, returning a null reference\ninsuchacase. Werelyonbothofthese privateutility methodsinthepublic\naccessor methodsthatfollow.\nCodeFragment7.11providesmostofthepublicupdatemethods, relyingon\n\u2022\na private addBetween method to unify the implementations of the various\ninsertion operations.\nCodeFragment7.12providesthepublicremovemethod. Notethatitsetsall\n\u2022\nfields of the removed node back to null\u2014a condition we can later detect to\nrecognize adefunct position.\nwww.it-ebooks.info\n7.3. PositionalLists 277\n1 /\u2217\u2217 Implementation of a positional list stored as a doubly linked list. \u2217/\n2 public class LinkedPositionalList<E> implements PositionalList<E>\n{\n3 //----------------nested Node class ----------------\n4 private static class Node<E> implements Position<E>\n{\n5 private E element; // reference to the element stored at this node\n6 private Node<E> prev; // reference to the previous node in the list\n7 private Node<E> next; // reference to the subsequent node in the list\n8 public Node(E e, Node<E> p, Node<E> n)\n{\n9 element = e;\n10 prev = p;\n11 next = n;\n12\n}\n13 public E getElement() throws IllegalStateException\n{\n14 if (next == null) // convention for defunct node\n15 throw new IllegalStateException(\"Position no longer valid\");\n16 return element;\n17\n}\n18 public Node<E> getPrev()\n{\n19 return prev;\n20\n}\n21 public Node<E> getNext()\n{\n22 return next;\n23\n}\n24 public void setElement(E e)\n{\n25 element = e;\n26\n}\n27 public void setPrev(Node<E> p)\n{\n28 prev = p;\n29\n}\n30 public void setNext(Node<E> n)\n{\n31 next = n;\n32\n}\n33 //-----------end of nested Node class -----------\n}\n34\n35 // instance variables of the LinkedPositionalList\n36 private Node<E> header; // header sentinel\n37 private Node<E> trailer; // trailer sentinel\n38 private int size = 0; // number of elements in the list\n39\n40 /\u2217\u2217 Constructs a new empty list. \u2217/\n41 public LinkedPositionalList()\n{\n42 header = new Node<>(null, null, null); // create header\n43 trailer = new Node<>(null, header, null); // trailer is preceded by header\n44 header.setNext(trailer); // header is followed by trailer\n45\n}\nCodeFragment7.9: Animplementation oftheLinkedPositionalListclass.\n(Continues inCodeFragments7.10\u20137.12.)\nwww.it-ebooks.info\n278 Chapter7. ListandIteratorADTs\n46 // private utilities\n47 /\u2217\u2217 Validates the position and returns it as a node. \u2217/\n48 private Node<E> validate(Position<E> p) throws IllegalArgumentException\n{\n49 if (!(p instanceof Node)) throw new IllegalArgumentException(\"Invalid p\");\n50 Node<E> node = (Node<E>) p; // safe cast\n51 if (node.getNext() == null) // convention for defunct node\n52 throw new IllegalArgumentException(\"p is no longer in the list\");\n53 return node;\n54\n}\n55\n56 /\u2217\u2217 Returns the given node as a Position (or null, if it is a sentinel). \u2217/\n57 private Position<E> position(Node<E> node)\n{\n58 if (node == header node == trailer)\n||\n59 return null; // do not expose user to the sentinels\n60 return node;\n61\n}\n62\n63 // public accessor methods\n64 /\u2217\u2217 Returns the number of elements in the linked list. \u2217/\n65 public int size() return size;\n{ }\n66\n67 /\u2217\u2217 Tests whether the linked list is empty. \u2217/\n68 public boolean isEmpty() return size == 0;\n{ }\n69\n70 /\u2217\u2217 Returns the first Position in the linked list (or null, if empty). \u2217/\n71 public Position<E> first()\n{\n72 return position(header.getNext());\n73\n}\n74\n75 /\u2217\u2217 Returns the last Position in the linked list (or null, if empty). \u2217/\n76 public Position<E> last()\n{\n77 return position(trailer.getPrev());\n78\n}\n79\n80 /\u2217\u2217 Returns the Position immediately before Position p (or null, if p is first). \u2217/\n81 public Position<E> before(Position<E> p) throws IllegalArgumentException\n{\n82 Node<E> node = validate(p);\n83 return position(node.getPrev());\n84\n}\n85\n86 /\u2217\u2217 Returns the Position immediately after Position p (or null, if p is last). \u2217/\n87 public Position<E> after(Position<E> p) throws IllegalArgumentException\n{\n88 Node<E> node = validate(p);\n89 return position(node.getNext());\n90\n}\nCodeFragment7.10: Animplementation oftheLinkedPositionalListclass.\n(ContinuedfromCodeFragment7.9;continuesinCodeFragments7.11and7.12.)\nwww.it-ebooks.info\n7.3. PositionalLists 279\n91 // private utilities\n92 /\u2217\u2217 Adds element e to the linked list between the given nodes. \u2217/\n93 private Position<E> addBetween(E e, Node<E> pred, Node<E> succ)\n{\n94 Node<E> newest = new Node<>(e, pred, succ); // create and link a new node\n95 pred.setNext(newest);\n96 succ.setPrev(newest);\n97 size++;\n98 return newest;\n99\n}\n100\n101 // public update methods\n102 /\u2217\u2217 Inserts element e at the front of the linked list and returns its new Position. \u2217/\n103 public Position<E> addFirst(E e)\n{\n104 return addBetween(e, header, header.getNext()); // just after the header\n105\n}\n106\n107 /\u2217\u2217 Inserts element e at the back of the linked list and returns its new Position. \u2217/\n108 public Position<E> addLast(E e)\n{\n109 return addBetween(e, trailer.getPrev(), trailer); // just before the trailer\n110\n}\n111\n112 /\u2217\u2217 Inserts element e immediately before Position p, and returns its new Position.\u2217/\n113 public Position<E> addBefore(Position<E> p, E e)\n114 throws IllegalArgumentException\n{\n115 Node<E> node = validate(p);\n116 return addBetween(e, node.getPrev(), node);\n117\n}\n118\n119 /\u2217\u2217 Inserts element e immediately after Position p, and returns its new Position. \u2217/\n120 public Position<E> addAfter(Position<E> p, E e)\n121 throws IllegalArgumentException\n{\n122 Node<E> node = validate(p);\n123 return addBetween(e, node, node.getNext());\n124\n}\n125\n126 /\u2217\u2217 Replaces the element stored at Position p and returns the replaced element. \u2217/\n127 public E set(Position<E> p, E e) throws IllegalArgumentException\n{\n128 Node<E> node = validate(p);\n129 E answer = node.getElement();\n130 node.setElement(e);\n131 return answer;\n132\n}\nCodeFragment7.11: Animplementation oftheLinkedPositionalListclass.\n(ContinuedfromCodeFragments7.9and7.10;continuesinCodeFragment7.12.)\nwww.it-ebooks.info\n280 Chapter7. ListandIteratorADTs\n133 /\u2217\u2217 Removes the element stored at Position p and returns it (invalidating p). \u2217/\n134 public E remove(Position<E> p) throws IllegalArgumentException\n{\n135 Node<E> node = validate(p);\n136 Node<E> predecessor = node.getPrev();\n137 Node<E> successor = node.getNext();\n138 predecessor.setNext(successor);\n139 successor.setPrev(predecessor);\n140 size ;\n\u2212\u2212\n141 E answer = node.getElement();\n142 node.setElement(null); // help with garbage collection\n143 node.setNext(null); // and convention for defunct node\n144 node.setPrev(null);\n145 return answer;\n146\n}\n147\n}\nCodeFragment7.12: Animplementation oftheLinkedPositionalListclass.\n(Continued fromCodeFragments7.9\u20137.11.)\nThe Performance of a Linked Positional List\nThe positional list ADT is ideally suited for implementation with a doubly linked\nlist,asalloperationsruninworst-caseconstanttime,asshowninTable7.2. Thisis\nin stark contrast to the ArrayList structure (analyzed in Table 7.1), which requires\nlinear time for insertions or deletions at arbitrary positions, due to the need for a\nlooptoshiftotherelements.\nOf course, our positional list does not support the index-based methods of the\nofficialListinterfaceofSection7.1. Itispossibletoaddsupportforthosemethods\nbytraversing the listwhilecounting nodes (seeExercise C-7.38), but thatrequires\ntimeproportional tothesublistthatistraversed.\nMethod RunningTime\nsize() O(1)\nisEmpty() O(1)\nfirst(),last() O(1)\nbefore(p),after(p) O(1)\naddFirst(e),addLast(e) O(1)\naddBefore(p,e),addAfter(p,e) O(1)\nset(p,e) O(1)\nremove(p) O(1)\nTable 7.2: Performance of a positional list with n elements realized by a doubly\nlinkedlist. ThespaceusageisO(n).\nwww.it-ebooks.info\n7.3. PositionalLists 281\nImplementing a Positional List with an Array\nWe can implement a positional list L using an array A for storage, but some care\nis necessary in designing objects that will serve as positions. At first glance, it\nwould seem that a position p need only store the index i at which its associated\nelement isstored withinthearray. Wecanthenimplement methodgetElement(p)\nsimply by returning A[i]. The problem with this approach is that the index of an\nelement e changes when other insertions or deletions occur before it. If we have\nalready returned a position p associated with element e that stores an outdated\nindex i to a user, the wrong array cell would be accessed when the position was\nused. (Rememberthatpositionsinapositionallistshouldalwaysbedefinedrelative\ntotheirneighboring positions, nottheirindices.)\nHence, if weare going to implement a positional list with an array, weneed a\ndifferentapproach. Werecommendthefollowingrepresentation. Insteadofstoring\ntheelementsofLdirectlyinarrayA,westoreanewkindofpositionobjectineach\ncell of A. A position p stores the element e as well as the current index i of that\nelementwithinthelist. Suchadatastructure isillustrated inFigure7.8.\n(0,JFK) (1,BWI) (2,PVD) (3,SFO)\n0 1 2 3 N 1\n\u2212\nFigure7.8: Anarray-based representation ofapositional list.\nWiththis representation, wecandetermine theindexcurrently associated with\na position, and we can determine the position currently associated with a specific\nindex. Wecan therefore implement an accessor, such as before(p), by finding the\nindexofthegivenpositionandusingthearraytofindtheneighboring position.\nWhen an element is inserted or deleted somewhere in the list, we can loop\nthroughthearraytoupdatetheindexvariablestoredinalllaterpositions inthelist\nthatareshiftedduringtheupdate.\nEfficiency Trade-Offs with an Array-Based Sequence\nInthisarrayimplementationofasequence,theaddFirst,addBefore,addAfter,and\nremovemethodstakeO(n)time,because wehavetoshiftposition objectstomake\nroom for the new position or to fill in the hole created by the removal of the old\nposition (just as in the insert and remove methods based on index). All the other\nposition-based methodstakeO(1)time.\nwww.it-ebooks.info\n282 Chapter7. ListandIteratorADTs\n7.4 Iterators\nAn iterator is a software design pattern that abstracts the process of scanning\nthrough a sequence of elements, one element at a time. The underlying elements\nmightbestoredinacontainer class, streaming through anetwork, orgenerated by\naseriesofcomputations.\nIn order to unify the treatment and syntax for iterating objects in a way that is\nindependent from a specific organization, Java defines the java.util.Iterator inter-\nfacewiththefollowingtwomethods:\nhasNext(): Returns true if there is at least one additional element in the\nsequence, andfalseotherwise.\nnext(): Returnsthenextelementinthesequence.\nThe interface uses Java\u2019s generic framework, with the next() method return-\ning a parameterized element type. For example, the Scanner class (described in\nSection 1.6) formally implements the Iterator<String> interface, with its next()\nmethodreturning aStringinstance.\nIfthenext()methodofaniteratoriscalledwhennofurtherelementsareavail-\nable,aNoSuchElementExceptionisthrown. Ofcourse,thehasNext()methodcan\nbeusedtodetectthatcondition beforecalling next().\nThecombination ofthesetwomethodsallowsageneralloopconstructforpro-\ncessing elements of the iterator. For example, if we let variable, iter, denote an\ninstance oftheIterator<String>type,thenwecanwritethefollowing:\nwhile (iter.hasNext())\n{\nString value = iter.next();\nSystem.out.println(value);\n}\nThe java.util.Iterator interface contains a third method, which is optionally\nsupported bysomeiterators:\nremove(): Removesfromthecollectiontheelementreturnedbythemost\nrecentcalltonext(). ThrowsanIllegalStateExceptionifnext\nhasnotyetbeencalled, orifremovewasalready called since\nthemostrecentcalltonext.\nThis method can be used to filter a collection of elements, for example to dis-\ncardallnegativenumbersfromadataset.\nForthe sakeofsimplicity, wewillnot implement theremove method formost\ndata structures in this book, but we will give two tangible examples later in this\nsection. If removal is not supported, an UnsupportedOperationException is con-\nventionally thrown.\nwww.it-ebooks.info\n7.4. Iterators 283\n7.4.1 The Iterable Interface and Java\u2019s For-Each Loop\nAsingleiteratorinstancesupports onlyonepassthroughacollection; callstonext\ncan be made until all elements have been reported, but there is no way to \u201creset\u201d\ntheiteratorbacktothebeginning ofthesequence.\nHowever, a data structure that wishes to allow repeated iterations can support\na method that returns a new iterator, each time it is called. To provide greater\nstandardization, Java defines another parameterized interface, named Iterable, that\nincludes thefollowingsinglemethod:\niterator(): Returnsaniteratoroftheelementsinthecollection.\nAninstanceofatypicalcollectionclassinJava,suchasanArrayList,isiterable\n(butnotitselfaniterator);itproducesaniteratorforitscollectionasthereturnvalue\nof the iterator() method. Each call to iterator() returns a new iterator instance,\ntherebyallowingmultiple(evensimultaneous) traversals ofacollection.\nJava\u2019s Iterableclass also plays afundamental role insupport of the\u201cfor-each\u201d\nloopsyntax(described inSection1.5.2). Theloopsyntax,\nfor (ElementType variable : collection)\n{\nloopBody // may refer to \u201dvariable\u201d\n}\nissupported foranyinstance, collection, ofaniterableclass. ElementTypemustbe\nthetype ofobject returned byitsiterator, and variable willtake onelement values\nwithintheloopBody. Essentially, thissyntaxisshorthand forthefollowing:\nIterator<ElementType> iter = collection.iterator();\nwhile (iter.hasNext())\n{\nElementType variable = iter.next();\nloopBody // may refer to \u201dvariable\u201d\n}\nWe note that the iterator\u2019s remove method cannot be invoked when using the\nfor-each loop syntax. Instead, we must explicitly use an iterator. As an example,\nthe following loop can be used to remove all negative numbers from an ArrayList\noffloating-point values.\nArrayList<Double> data; // populate with random numbers (not shown)\nIterator<Double> walk = data.iterator();\nwhile (walk.hasNext())\nif (walk.next() < 0.0)\nwalk.remove();\nwww.it-ebooks.info\n284 Chapter7. ListandIteratorADTs\n7.4.2 Implementing Iterators\nTherearetwogeneralstylesforimplementing iterators thatdifferintermsofwhat\nworkisdonewhentheiteratorinstanceisfirstcreated,andwhatworkisdoneeach\ntimetheiteratorisadvanced withacalltonext().\nAsnapshotiteratormaintainsitsownprivatecopyofthesequenceofelements,\nwhichisconstructed atthetimetheiterator objectiscreated. Iteffectively records\na \u201csnapshot\u201d of the sequence of elements at the time the iterator is created, and is\ntherefore unaffected byanysubsequent changestotheprimarycollection thatmay\noccur. Implementingsnapshotiteratorstendstobeveryeasy,asitrequiresasimple\ntraversal of the primary structure. The downside of this style of iterator is that it\nrequires O(n)time andO(n)auxiliary space, upon construction, tocopy andstore\nacollection ofnelements.\nA lazy iterator is one that does not make an upfront copy, instead perform-\ning a piecewise traversal of the primary structure only when the next() method is\ncalled to request another element. The advantage of this style of iterator is that\nit can typically be implemented so the iterator requires only O(1) space and O(1)\nconstruction time. One downside (or feature) of a lazy iterator is that its behavior\nis affected if the primary structure is modified (by means other than by the itera-\ntor\u2019s ownremove method) before the iteration completes. Manyof the iterators in\nJava\u2019s libraries implement a \u201cfail-fast\u201d behavior that immediately invalidates such\naniteratorifitsunderlying collection ismodifiedunexpectedly.\nWe will demonstrate how to implement iterators for both the ArrayList and\nLinkedPositionalList classes as examples. We implement lazy iterators for both,\nincluding support fortheremoveoperation (butwithoutanyfail-fast guarantee).\nIterations with the ArrayList class\nWe begin by discussing iteration for the ArrayList<E> class. Wewill have it im-\nplement the Iterable<E> interface. (In fact, that requirement is already part of\nJava\u2019s List interface.) Therefore, we must add an iterator() method to that class\ndefinition,whichreturnsaninstanceofanobjectthatimplementstheIterator<E>\ninterface. For this purpose, we define a new class, ArrayIterator, as a nonstatic\nnested class of ArrayList (i.e., an inner class, as described in Section 2.6). The\nadvantage ofhaving theiterator asaninner class isthatitcan access private fields\n(suchasthearrayA)thataremembersofthecontaining list.\nOur implementation is given in Code Fragment 7.13. The iterator() method\nof ArrayList returns a new instance of the inner ArrayIterator class. Each iterator\nmaintains afieldjthatrepresents theindexofthenextelementtobereturned. Itis\ninitializedto0,andwhen jreachesthesizeofthelist,therearenomoreelementsto\nreturn. In order to support element removal through the iterator, we also maintain\naboolean variablethatdenoteswhetheracalltoremoveiscurrently permissible.\nwww.it-ebooks.info\n7.4. Iterators 285\n1 //----------------nested ArrayIterator class ----------------\n2 /\u2217\u2217\n3 \u2217 A (nonstatic) inner class. Note well that each instance contains an implicit\n4 \u2217 reference to the containing list, allowing it to access the list's members.\n5 \u2217/\n6 private class ArrayIterator implements Iterator<E>\n{\n7 private int j = 0; // index of the next element to report\n8 private boolean removable = false; // can remove be called at this time?\n9\n10 /\u2217\u2217\n11 \u2217 Tests whether the iterator has a next object.\n12 \u2217 @return true if there are further objects, false otherwise\n13 \u2217/\n14 public boolean hasNext() return j < size; // size is field of outer instance\n{ }\n15\n16 /\u2217\u2217\n17 \u2217 Returns the next object in the iterator.\n18 \u2217\n19 \u2217 @return next object\n20 \u2217 @throws NoSuchElementException if there are no further elements\n21 \u2217/\n22 public E next() throws NoSuchElementException\n{\n23 if (j == size) throw new NoSuchElementException(\"No next element\");\n24 removable = true; // this element can subsequently be removed\n25 return data[j++]; // post-increment j, so it is ready for future call to next\n26\n}\n27\n28 /\u2217\u2217\n29 \u2217 Removes the element returned by most recent call to next.\n30 \u2217 @throws IllegalStateException if next has not yet been called\n31 \u2217 @throws IllegalStateException if remove was already called since recent next\n32 \u2217/\n33 public void remove() throws IllegalStateException\n{\n34 if (!removable) throw new IllegalStateException(\"nothing to remove\");\n35 ArrayList.this.remove(j 1); // that was the last one returned\n\u2212\n36 j ; // next element has shifted one cell to the left\n\u2212\u2212\n37 removable = false; // do not allow remove again until next is called\n38\n}\n39 //------------end of nested ArrayIterator class ------------\n}\n40\n41 /\u2217\u2217 Returns an iterator of the elements stored in the list. \u2217/\n42 public Iterator<E> iterator()\n{\n43 return new ArrayIterator(); // create a new instance of the inner class\n44\n}\nCodeFragment7.13: Code providing support for ArrayList iterators. (This should\nbenestedwithintheArrayListclassdefinitionofCodeFragments7.2and7.3.)\nwww.it-ebooks.info\n286 Chapter7. ListandIteratorADTs\nIterations with the LinkedPositionalList class\nInsupport theconceptofiteration withtheLinkedPositionalListclass,afirstques-\ntioniswhethertosupportiterationoftheelementsofthelistorthepositionsofthe\nlist. If we allow a user to iterate through all positions of the list, those positions\ncouldbeusedtoaccesstheunderlying elements,sosupportforpositioniterationis\nmoregeneral. However,itismorestandardforacontainerclasstosupportiteration\nof the core elements, by default, so that the for-each loop syntax could be used to\nwritecodesuchasthefollowing,\nfor (String guest : waitlist)\nassumingthatvariable waitlisthastypeLinkedPositionalList<String>.\nFor maximum convenience, we will support both forms of iteration. We will\nhave the standard iterator() method return an iterator of the elements of the list,\nso that our list class formally implements the Iterable interface for the declared\nelementtype.\nFor those wishing to iterate through the positions of a list, we will provide a\nnewmethod,positions(). Atfirstglance,itwouldseemanaturalchoiceforsucha\nmethodtoreturnanIterator. However,wepreferforthereturntypeofthatmethod\nto be an instance that is Iterable (and hence, has its own iterator() method that\nreturnsaniteratorofpositions). Ourreasonfortheextralayerofcomplexityisthat\nwewishforusersofourclasstobeabletouseafor-eachloopwithasimplesyntax\nsuchasthefollowing:\nfor (Position<String> p : waitlist.positions())\nForthissyntaxtobelegal,thereturntypeofpositions()mustbeIterable.\nCodeFragment7.14presentsournewsupportfortheiterationofpositions and\nelements of a LinkedPositionalList. We define three new inner classes. The first\nof these is PositionIterator, providing the core functionality of our list iterations.\nWhereas the array list iterator maintained the index of the next element to be re-\nturnedasafield,thisclassmaintainsthepositionofthenextelementtobereturned\n(aswellastheposition ofthemostrecentlyreturned element,tosupportremoval).\nTo support our goal of the positions() method returning an Iterable object,\nwe define a trivial PositionIterable inner class, which simply constructs and re-\nturns a new PositionIterator object each time its iterator() method is called. The\npositions() method of the top-level class returns a new PositionIterable instance.\nOurframeworkreliesheavilyonthesebeinginnerclasses,notstaticnestedclasses.\nFinally, we wish to have the top-level iterator() method return an iterator of\nelements (not positions). Rather than reinvent the wheel, we trivially adapt the\nPositionIteratorclasstodefineanewElementIterator class,whichlazilymanages\na position iterator instance, while returning the element stored at each position\nwhennext()iscalled.\nwww.it-ebooks.info\n7.4. Iterators 287\n1 //----------------nested PositionIteratorclass ----------------\n2 private class PositionIterator implements Iterator<Position<E>>\n{\n3 private Position<E> cursor = first(); // position of the next element to report\n4 private Position<E> recent = null; // position of last reported element\n5 /\u2217\u2217 Tests whether the iterator has a next object. \u2217/\n6 public boolean hasNext() return (cursor != null);\n7 /\u2217\u2217 Returns the next positio { n in the iterator. \u2217/ }\n8 public Position<E> next() throws NoSuchElementException\n{\n9 if (cursor == null) throw new NoSuchElementException(\"nothing left\");\n10 recent = cursor; // element at this position might later be removed\n11 cursor = after(cursor);\n12 return recent;\n13\n14 } /\u2217\u2217 Removes the element returned by most recent call to next. \u2217/\n15 public void remove() throws IllegalStateException\n{\n16 if (recent == null) throw new IllegalStateException(\"nothing to remove\");\n17 LinkedPositionalList.this.remove(recent); // remove from outer list\n18 recent = null; // do not allow remove again until next is called\n19\n}\n20 //------------end of nested PositionIterator class ------------\n}\n21\n22 //----------------nested PositionIterable class ----------------\n23 private class PositionIterable implements Iterable<Position<E>>\n{\n24 public Iterator<Position<E>> iterator() return new PositionIterator();\n{ }\n25 //------------end of nested PositionIterable class ------------\n}\n26\n27 /\u2217\u2217 Returns an iterable representation of the list's positions. \u2217/\n28 public Iterable<Position<E>> positions()\n{\n29 return new PositionIterable(); // create a new instance of the inner class\n30\n}\n31\n32 //----------------nested ElementIterator class ----------------\n33 /\u2217 This class adapts the iteration produced by positions() to return elements. \u2217/\n34 private class ElementIterator implements Iterator<E>\n{\n35 Iterator<Position<E>> posIterator = new PositionIterator();\n36 public boolean hasNext() return posIterator.hasNext();\n{ }\n37 public E next() return posIterator.next().getElement(); // return element!\n{ }\n38 public void remove() posIterator.remove();\n{ }\n39\n}\n40\n41 /\u2217\u2217 Returns an iterator of the elements stored in the list. \u2217/\n42 public Iterator<E> iterator() return new ElementIterator();\n{ }\nCodeFragment7.14:Supportforprovidingiterationsofpositionsandelementsofa\nLinkedPositionalList. (ThisshouldbenestedwithintheLinkedPositionalListclass\ndefinitionofCodeFragments7.9\u20137.12.)\nwww.it-ebooks.info\n288 Chapter7. ListandIteratorADTs\n7.5 The Java Collections Framework\nJava provides many data structure interfaces and classes, which together form the\nJavaCollectionsFramework. Thisframework,whichispartofthejava.utilpack-\nage,includesversionsofseveralofthedatastructuresdiscussedinthisbook,some\nof which we have already discussed and others of which we will discuss later in\nthis book. The root interface in the Java collections framework is named Collec-\ntion. Thisisageneralinterfaceforanydatastructure,suchasalist,thatrepresentsa\ncollection ofelements. TheCollectioninterfaceincludes manymethods, including\nsome we have already seen (e.g., size(), isEmpty(), iterator()). Itis a superinter-\nfaceforotherinterfaces intheJavaCollections Frameworkthatcanholdelements,\nincluding the java.util interfaces Deque, List, and Queue, and other subinterfaces\ndiscussedlaterinthisbook,includingSet(Section10.5.1)andMap(Section10.1).\nThe Java Collections Framework also includes concrete classes implementing\nvariousinterfaceswithacombinationofpropertiesandunderlyingrepresentations.\nWesummarize but afewof those classes inTable 7.3. Foreach, wedenote which\nof the Queue, Deque, or List interfaces are implemented (possibly several). We\nalso discuss several behavioral properties. Some classes enforce, or allow, a fixed\ncapacity limit. Robust classes provide support for concurrency, allowing multiple\nprocesses to share use of a data structure in a thread-safe manner. If the structure\nis designated as blocking, a call to retrieve an element from an empty collection\nwaits until some other process inserts an element. Similarly, a call to insert into a\nfullblocking structure mustwaituntilroombecomesavailable.\nInterfaces Properties Storage\nClass\neueuQ euqeD\ntsiL\ntimiLyticapaC\nefaS-daerhT\ngnikcolB\nyarrA\ntsiLdekniL\nArrayBlockingQueue X X X X X\nLinkedBlockingQueue X X X X X\nConcurrentLinkedQueue X X X\nArrayDeque X X X\nLinkedBlockingDeque X X X X X X\nConcurrentLinkedDeque X X X X\nArrayList X X\nLinkedList X X X X\nTable7.3: SeveralclassesintheJavaCollections Framework.\nwww.it-ebooks.info\n7.5. TheJavaCollectionsFramework 289\n7.5.1 List Iterators in Java\nThejava.util.LinkedListclassdoesnotexposeapositionconcepttousersinitsAPI,\naswedoinourpositionallistADT.Instead,thepreferredwaytoaccessandupdate\na LinkedList object in Java, without using indices, is to use a ListIterator that is\nreturned by the list\u2019s listIterator() method. Such an iterator provides forward and\nbackward traversal methods as well as local update methods. It views its current\nposition as being before the first element, between two elements, or after the last\nelement. Thatis,itusesalistcursor, muchlikeascreen cursorisviewedasbeing\nlocated between two characters on a screen. Specifically, the java.util.ListIterator\ninterface includes thefollowingmethods:\nadd(e): Addstheelementeatthecurrentposition oftheiterator.\nhasNext(): Returns true ifthere is an element after the current position\noftheiterator.\nhasPrevious(): Returnstrueifthereisanelementbeforethecurrentposition\noftheiterator.\nprevious(): Returns the element e before the current position and sets\nthecurrentposition tobebeforee.\nnext(): Returns theelement eafter the current position and sets the\ncurrent positiontobeaftere.\nnextIndex(): Returnstheindexofthenextelement.\npreviousIndex(): Returnstheindexoftheprevious element.\nremove(): Removes the element returned by the most recent next or\npreviousoperation.\nset(e): Replaces theelementreturned bythemostrecentcalltothe\nnextorpreviousoperation withe.\nIt isrisky touse multiple iterators overthe samelist while modifying its contents.\nIfinsertions, deletions,orreplacementsarerequiredatmultiple\u201cplaces\u201dinalist,it\nissafertousepositionstospecifytheselocations. Butthejava.util.LinkedListclass\ndoesnotexposeitsposition objectstotheuser. So,toavoidtherisksofmodifying\na list that has created multiple iterators, the iterators have a \u201cfail-fast\u201d feature that\ninvalidates such an iterator if its underlying collection is modified unexpectedly.\nFor example, if a java.util.LinkedList object L has returned five different iterators\nand one of them modifies L, a ConcurrentModificationException is thrown if any\nof the other four is subsequently used. That is, Java allows many list iterators to\nbe traversing a linked list Lat the same time, but ifone of them modifies L (using\nan add, set, or remove method), then all the other iterators for L become invalid.\nLikewise, if L is modified by one of its own update methods, then all existing\niterators forLimmediatelybecomeinvalid.\nwww.it-ebooks.info\n290 Chapter7. ListandIteratorADTs\n7.5.2 Comparison to Our Positional List ADT\nJava provides functionality similar to ourarray listand positional lists ADTinthe\njava.util.List interface, which is implemented with an array in java.util.ArrayList\nandwithalinked listinjava.util.LinkedList.\nMoreover, Java uses iterators to achieve a functionality similar to what our\npositional list ADT derives from positions. Table 7.4 shows corresponding meth-\nods between our (array and positional) list ADTs and the java.util interfaces List\nand ListIterator interfaces, with notes about their implementations in the java.util\nclassesArrayListandLinkedList.\nPositionalList java.util.List ListIterator\nNotes\nADTMethod Method Method\nsize() size() O(1)time\nisEmpty() isEmpty() O(1)time\nAisO(1),\nget(i)\nLisO(min i,n i )\n{ \u2212 }\nfirst() listIterator() firstelementisnext\nlast() listIterator(size()) lastelementisprevious\nbefore(p) previous() O(1)time\nafter(p) next() O(1)time\nset(p,e) set(e) O(1)time\nAisO(1),\nset(i,e)\nLisO(min i,n i )\n{ \u2212 }\nadd(i,e) O(n)time\naddFirst(e) add(0,e) AisO(n),LisO(1)\naddFirst(e) addFirst(e) onlyexistsinL,O(1)\naddLast(e) add(e) O(1)time\naddLast(e) addLast(e) onlyexistsinL,O(1)\ninsertion isatcursor;\naddAfter(p,e) add(e)\nAisO(n),LisO(1)\ninsertion isatcursor;\naddBefore(p,e) add(e)\nAisO(n),LisO(1)\ndeletionisatcursor;\nremove(p) remove()\nAisO(n),LisO(1)\nAisO(1),\nremove(i)\nLisO(min i,n i )\n{ \u2212 }\nTable 7.4: Correspondences between methods in our positional list ADT and the\njava.util interfaces List and ListIterator. We use A and L as abbreviations for\njava.util.ArrayListandjava.util.LinkedList(ortheirrunning times).\nwww.it-ebooks.info\n7.5. TheJavaCollectionsFramework 291\n7.5.3 List-Based Algorithms in the Java Collections Framework\nInadditiontotheclassesthatareprovidedintheJavaCollectionsFramework,there\nare a number of simple algorithms that it provides as well. These algorithms are\nimplementedasstaticmethodsinthejava.util.Collectionsclass(nottobeconfused\nwiththejava.util.Collectioninterface) andtheyincludethefollowingmethods:\ncopy(L ,L ): Copies all elements of the L list into corresponding in-\ndest src src\ndicesoftheL list.\ndest\ndisjoint(C,D): Returns a boolean value indicating whether the collections\nC andDaredisjoint.\nfill(L,e): ReplaceseachelementofthelistLwithelemente.\nfrequency(C,e): Returns the number of elements in the collectionC that are\nequaltoe.\nmax(C): ReturnsthemaximumelementinthecollectionC,basedon\nthenaturalordering ofitselements.\nmin(C): Returns theminimumelement inthecollectionC,based on\nthenaturalordering ofitselements.\nreplaceAll(L,e, f): ReplaceseachelementinLthatisequaltoewithelement f.\nreverse(L): ReversestheorderingofelementsinthelistL.\nrotate(L,d): Rotates the elements in the list L by the distance d (which\ncanbenegative),inacircularfashion.\nshuffle(L): Pseudorandomly permutes the ordering of the elements in\nthelistL.\nsort(L): SortsthelistL,usingthenaturalordering ofitselements.\nswap(L,i, j): Swaptheelementsatindices iand joflistL.\nwww.it-ebooks.info\n292 Chapter7. ListandIteratorADTs\nConverting Lists into Arrays\nListsareabeautiful concept and theycanbeapplied inanumber ofdifferent con-\ntexts, but there aresome instances where itwouldbe useful ifwecould treat alist\nlike an array. Fortunately, the java.util.Collection interface includes the following\nhelpful methods for generating an array that has the same elements as the given\ncollection:\ntoArray(): Returns an array of elements of type Object containing\nalltheelementsinthiscollection.\ntoArray(A): Returnsanarrayofelementsofthesameelementtypeas\nAcontaining alltheelementsinthiscollection.\nIfthecollection isalist,thenthereturnedarraywillhaveitselementsstoredinthe\nsameorderasthatoftheoriginallist. Thus,ifwehaveausefularray-basedmethod\nthatwewanttouseonalistorothertypeofcollection,thenwecandosobysimply\nusingthatcollection\u2019s toArray()methodtoproduce anarrayrepresentation ofthat\ncollection.\nConverting Arrays into Lists\nInasimilarvein, itisoften useful tobeable toconvert anarray into anequivalent\nlist. Fortunately, thejava.util.Arraysclassincludes thefollowingmethod:\nasList(A): ReturnsalistrepresentationofthearrayA,withthesame\nelementtypeastheelementsofA.\nThe list returned by this method uses the array A as its internal representation for\nthelist. Sothislistisguaranteed tobeanarray-based listandanychangesmadeto\nitwillautomaticallybereflectedinA. Becauseofthesetypesofsideeffects,useof\nthe asList method should always be done with caution, so as to avoid unintended\nconsequences. But,usedwithcare,thismethodcanoftensaveusalotofwork. For\ninstance, the following code fragment could be used to randomly shuffle an array\nofInteger objects, arr:\nInteger[ ] arr = 1, 2, 3, 4, 5, 6, 7, 8 ; // allowed by autoboxing\n{ }\nList<Integer> listArr = Arrays.asList(arr);\nCollections.shuffle(listArr); // this has side effect of shuffling arr\nIt is worth noting that the array A sent to the asList method should be a reference\ntype (hence, our use of Integer rather than int in the above example). This is\nbecausetheListinterfaceisgeneric,andrequiresthattheelementtypebeanobject.\nwww.it-ebooks.info\n7.6. SortingaPositionalList 293\n7.6 Sorting a Positional List\nIn Section 3.1.2, we introduced the insertion-sort algorithm in the context of an\narray-based sequence. Inthissection, wedevelop animplementation thatoperates\nonaPositionalList,relyingonthesamehigh-levelalgorithminwhicheachelement\nisplacedrelativetoagrowingcollection ofpreviously sortedelements.\nWemaintain avariable namedmarker thatrepresents therightmost position of\nthecurrentlysortedportionofalist. Duringeachpass,weconsiderthepositionjust\npastthemarkerasthepivotandconsiderwherethepivot\u2019selementbelongsrelative\ntothesorted portion; weuseanother variable, namedwalk,tomoveleftward from\nthemarker,aslongasthereremainsaprecedingelementwithvaluelargerthanthe\npivot\u2019s. Atypical configuration of these variables is diagrammed in Figure 7.9. A\nJavaimplementation ofthisstrategyisgiveninCode7.15.\nwalk pivot\n15 22 25 29 36 23 53 11 42\nmarker\nFigure7.9: Overview of one step of our insertion-sort algorithm. The shaded ele-\nments,thoseuptoandincludingmarker,havealreadybeensorted. Inthisstep,the\npivot\u2019selementshouldberelocated immediately beforethewalkposition.\n1 /\u2217\u2217 Insertion-sort of a positional list of integers into nondecreasing order \u2217/\n2 public static void insertionSort(PositionalList<Integer> list)\n{\n3 Position<Integer> marker = list.first(); // last position known to be sorted\n4 while (marker != list.last())\n{\n5 Position<Integer> pivot = list.after(marker);\n6 int value = pivot.getElement(); // number to be placed\n7 if (value > marker.getElement()) // pivot is already sorted\n8 marker = pivot;\n9 else // must relocate pivot\n{\n10 Position<Integer> walk = marker; // find leftmost item greater than value\n11 while (walk != list.first() && list.before(walk).getElement() > value)\n12 walk = list.before(walk);\n13 list.remove(pivot); // remove pivot entry and\n14 list.addBefore(walk, value); // reinsert value in front of walk\n15\n}\n16\n}\n17\n}\nCodeFragment7.15: Javacodeforperforminginsertion-sort onapositional list.\nwww.it-ebooks.info\n294 Chapter7. ListandIteratorADTs\n7.7 Case Study: Maintaining Access Frequencies\nThepositional listADTisuseful in anumber ofsettings. Forexample, aprogram\nthat simulates a game of cards could model each person\u2019s hand as a positional list\n(ExerciseP-7.60). Sincemostpeoplekeepcardsofthesamesuittogether,inserting\nandremovingcardsfromaperson\u2019shandcouldbeimplementedusingthemethods\nof the positional list ADT, with the positions being determined by a natural order\nofthesuits. Likewise,asimpletexteditorembedsthenotionofpositionalinsertion\nand deletion, since such editors typically perform all updates relative to a cursor,\nwhichrepresents thecurrentposition inthelistofcharacters oftextbeingedited.\nIn this section, we will consider maintaining a collection of elements while\nkeepingtrackofthenumberoftimeseachelementisaccessed. Keepingsuchaccess\ncounts allows us to know which elements are among the most popular. Examples\nofsuchscenariosincludeaWebbrowserthatkeepstrackofauser\u2019smostaccessed\npages, or a music collection that maintains a list of the most frequently played\nsongsforauser. WewillmodelthiswithanewfavoriteslistADTthatsupportsthe\nsizeandisEmptymethodsaswellasthefollowing:\naccess(e): Accesses the element e, adding it to the favorites list if it is\nnotalready present, andincrementsitsaccesscount.\nremove(e): Removeselementefromthefavorites list,ifpresent.\ngetFavorites(k): Returnsaniterablecollectionofthekmostaccessedelements.\n7.7.1 Using a Sorted List\nOur first approach for managing a list of favorites is to store elements in a linked\nlist, keeping them in nonincreasing order of access counts. We access or remove\nan element by searching the list from the most frequently accessed to the least\nfrequently accessed. Reporting the k most accessed elements is easy, as they are\nthefirstkentriesofthelist.\nTo maintain the invariant that elements are stored in nonincreasing order of\naccesscounts,wemustconsiderhowasingleaccessoperationmayaffecttheorder.\nThe accessed element\u2019s count increases by one, and so it may become larger than\noneormoreofitspreceding neighbors inthelist,thereby violating theinvariant.\nFortunately, wecanreestablish thesortedinvariantusingatechniquesimilarto\nasinglepassoftheinsertion-sort algorithm,introducedintheprevioussection. We\ncanperform abackward traversal ofthe list, starting attheposition oftheelement\nwhose access count has increased, until we locate a valid position after which the\nelementcanberelocated.\nwww.it-ebooks.info\n7.7. CaseStudy:MaintainingAccessFrequencies 295\nUsing the Composition Pattern\nWewishtoimplementafavoriteslistbymakinguseofaPositionalListforstorage.\nIfelementsofthepositionallistweresimplyelementsofthefavoriteslist,wewould\nbe challenged to maintain access counts and to keep the proper count with the\nassociatedelementasthecontentsofthelistarereordered. Weuseageneralobject-\norienteddesignpattern,thecompositionpattern,inwhichwedefineasingleobject\nthatiscomposed oftwoormoreotherobjects. (See,forexample,Section2.5.2.)\nSpecifically, we define a nonpublic nested class, Item, that stores the element\nand its access count as a single instance. We then maintain our favorites list as\na PositionalList of item instances, so that the access count for a user\u2019s element is\nembedded alongside it in our representation. (An Item is never exposed to a user\nofaFavoritesList.)\n1 /\u2217\u2217 Maintains a list of elements ordered according to access frequency. \u2217/\n2 public class FavoritesList<E>\n{\n3 // ----------------nested Item class ----------------\n4 protected static class Item<E>\n{\n5 private E value;\n6 private int count = 0;\n7 /\u2217\u2217 Constructs new item with initial count of zero. \u2217/\n8 public Item(E val) value = val;\n{ }\n9 public int getCount() return count;\n{ }\n10 public E getValue() return value;\n{ }\n11 public void increment() count++;\n{ }\n12 //-----------end of nested Item class -----------\n}\n13\n14 PositionalList<Item<E>> list = new LinkedPositionalList<>(); // list of Items\n15 public FavoritesList() // constructs initially empty favorites list\n{ }\n16\n17 // nonpublic utilities\n18 /\u2217\u2217 Provides shorthand notation to retrieve user's element stored at Position p. \u2217/\n19 protected E value(Position<Item<E>> p) return p.getElement().getValue();\n{ }\n20\n21 /\u2217\u2217 Provides shorthand notation to retrieve count of item stored at Position p. \u2217/\n22 protected int count(Position<Item<E>> p) return p.getElement().getCount();\n{ }\n23\n24 /\u2217\u2217 Returns Position having element equal to e (or null if not found). \u2217/\n25 protected Position<Item<E>> findPosition(E e)\n{\n26 Position<Item<E>> walk = list.first();\n27 while (walk != null && !e.equals(value(walk)))\n28 walk = list.after(walk);\n29 return walk;\n30\n}\nCodeFragment7.16: ClassFavoritesList. (Continues inCodeFragment7.17.)\nwww.it-ebooks.info\n296 Chapter7. ListandIteratorADTs\n31 /\u2217\u2217 Moves item at Position p earlier in the list based on access count. \u2217/\n32 protected void moveUp(Position<Item<E>> p)\n{\n33 int cnt = count(p); // revised count of accessed item\n34 Position<Item<E>> walk = p;\n35 while (walk != list.first() && count(list.before(walk)) < cnt)\n36 walk = list.before(walk); // found smaller count ahead of item\n37 if (walk != p)\n38 list.addBefore(walk, list.remove(p)); // remove/reinsert item\n39\n}\n40\n41 // public methods\n42 /\u2217\u2217 Returns the number of items in the favorites list. \u2217/\n43 public int size() return list.size();\n{ }\n44\n45 /\u2217\u2217 Returns true if the favorites list is empty. \u2217/\n46 public boolean isEmpty() return list.isEmpty();\n{ }\n47\n48 /\u2217\u2217 Accesses element e (possibly new), increasing its access count. \u2217/\n49 public void access(E e)\n{\n50 Position<Item<E>> p = findPosition(e); // try to locate existing element\n51 if (p == null)\n52 p = list.addLast(new Item<E>(e)); // if new, place at end\n53 p.getElement().increment(); // always increment count\n54 moveUp(p); // consider moving forward\n55\n}\n56\n57 /\u2217\u2217 Removes element equal to e from the list of favorites (if found). \u2217/\n58 public void remove(E e)\n{\n59 Position<Item<E>> p = findPosition(e); // try to locate existing element\n60 if (p != null)\n61 list.remove(p);\n62\n}\n63\n64 /\u2217\u2217 Returns an iterable collection of the k most frequently accessed elements. \u2217/\n65 public Iterable<E> getFavorites(int k) throws IllegalArgumentException\n{\n66 if (k < 0 k > size())\n||\n67 throw new IllegalArgumentException(\"Invalid k\");\n68 PositionalList<E> result = new LinkedPositionalList<>();\n69 Iterator<Item<E>> iter = list.iterator();\n70 for (int j=0; j < k; j++)\n71 result.addLast(iter.next().getValue());\n72 return result;\n73\n}\n74\n}\nCodeFragment7.17: ClassFavoritesList. (Continued fromCodeFragment7.16.)\nwww.it-ebooks.info\n7.7. CaseStudy:MaintainingAccessFrequencies 297\n7.7.2 Using a List with the Move-to-Front Heuristic\nThe previous implementation of a favorites list performs the access(e) method in\ntime proportional to the index of ein the favorites list. Thatis, if eisthe kth most\npopular element in the favorites list, then accessing it takes O(k) time. In many\nreal-life access sequences (e.g., Web pages visited by a user), once an element is\naccessed it is more likely to be accessed again in the near future. Such scenarios\naresaidtopossess localityofreference.\nAheuristic, orruleofthumb, thatattemptstotakeadvantage ofthelocality of\nreference that is present in an access sequence is the move-to-front heuristic. To\napply this heuristic, each time weaccess an element wemoveit all the wayto the\nfront ofthelist. Ourhope, ofcourse, isthat thiselement willbeaccessed againin\nthenearfuture. Consider,forexample,ascenarioinwhichwehavenelementsand\nthefollowingseriesofn2 accesses:\nelement1isaccessed ntimes.\n\u2022\nelement2isaccessed ntimes.\n\u2022\n\u2022 \u00b7\u00b7\u00b7\nelementnisaccessed ntimes.\n\u2022\nIf we store the elements sorted by their access counts, inserting each element the\nfirsttimeitisaccessed, then\neachaccesstoelement1runsinO(1)time.\n\u2022\neachaccesstoelement2runsinO(2)time.\n\u2022\n\u2022 \u00b7\u00b7\u00b7\neachaccesstoelementnrunsinO(n)time.\n\u2022\nThus,thetotaltimeforperformingtheseriesofaccesses isproportional to\nn(n+1)\nn+2n+3n+ +n n=n(1+2+3+ +n)=n ,\n\u00b7\u00b7\u00b7 \u00b7 \u00b7\u00b7\u00b7 \u00b7 2\nwhichisO(n3).\nOntheotherhand,ifweusethemove-to-frontheuristic,insertingeachelement\nthefirsttimeitisaccessed, then\neachsubsequent accesstoelement1takesO(1)time.\n\u2022\neachsubsequent accesstoelement2takesO(1)time.\n\u2022\n\u2022 \u00b7\u00b7\u00b7\neachsubsequent accesstoelementnrunsinO(1)time.\n\u2022\nSo the running time for performing all the accesses in this case is O(n2). Thus,\nthe move-to-front implementation has faster access times for this scenario. Still,\nthemove-to-frontapproachisjustaheuristic, forthereareaccesssequenceswhere\nusing the move-to-front approach is slower than simply keeping the favorites list\norderedbyaccesscounts.\nwww.it-ebooks.info\n298 Chapter7. ListandIteratorADTs\nThe Trade-Offs with the Move-to-Front Heuristic\nIf we no longer maintain the elements of the favorites list ordered by their access\ncounts,whenweareaskedtofindthekmostaccessed elements,weneedtosearch\nforthem. WewillimplementthegetFavorites(k)methodasfollows:\n1. Wecopyallentriesofourfavorites listintoanotherlist,namedtemp.\n2. Wescanthetemplistktimes. Ineachscan,wefindtheentrywiththelargest\naccesscount, removethisentryfromtemp,andaddittotheresults.\nThisimplementation ofmethodgetFavorites(k)takesO(kn)time. Thus,whenkis\na constant, method getFavorites(k) runs in O(n) time. This occurs, for example,\nwhenwewanttoget the \u201ctop ten\u201dlist. However, ifk isproportional ton, then the\nmethod getFavorites(k) runs in O(n2) time. This occurs, for example, when we\nwanta\u201ctop25%\u201dlist.\nInChapter9wewillintroduce adatastructure thatwillallowustoimplement\ngetFavoritesinO(n+klogn)time(seeExerciseP-9.51),andmoreadvancedtech-\nniquescouldbeusedtoperform getFavoritesinO(n+klogk)time.\nWecould easily achieve O(nlogn)timeifweuseastandard sorting algorithm\nto reorder the temporary list before reporting the top k (see Chapter 12); this ap-\nproach wouldbepreferred totheoriginal inthecasethatkis\u2126(logn). (Recallthe\nbig-Omeganotationintroduced inSection4.3.1togiveanasymptoticlowerbound\nontherunning timeofanalgorithm.) Thereisaspecialized sorting algorithm (see\nSection12.3.2)thatcantakeadvantageofthefactthataccesscountsareintegersin\nordertoachieveO(n)timeforgetFavorites,foranyvalueofk.\nImplementing the Move-to-Front Heuristic in Java\nWe give an implementation of a favorites list using the move-to-front heuristic in\nCode Fragment 7.18. The new FavoritesListMTF class inherits most of its func-\ntionality fromtheoriginal FavoritesListasabaseclass.\nByour original design, the access method ofthe original class relies on apro-\ntected utility named moveUp to enact the potential shifting of an element forward\nin the list, after its access count had been incremented. Therefore, we implement\nthe move-to-front heuristic by simply overriding the moveUp method so that each\naccessed element is moved directly to the front of the list (if not already there).\nThisactioniseasilyimplemented bymeansofthepositional listADT.\nThe more complex portion of our FavoritesListMTF class is the new defini-\ntion for the getFavorites method. We rely on the first of the approaches outlined\nabove, inserting copies ofthe items into a temporary list and then repeatedly find-\ning, reporting, and removing an element that has the largest access count of those\nremaining.\nwww.it-ebooks.info\n7.7. CaseStudy:MaintainingAccessFrequencies 299\n1 /\u2217\u2217 Maintains a list of elements ordered with move-to-front heuristic. \u2217/\n2 public class FavoritesListMTF<E> extends FavoritesList<E>\n{\n3\n4 /\u2217\u2217 Moves accessed item at Position p to the front of the list. \u2217/\n5 protected void moveUp(Position<Item<E>> p)\n{\n6 if (p != list.first())\n7 list.addFirst(list.remove(p)); // remove/reinsert item\n8\n}\n9\n10 /\u2217\u2217 Returns an iterable collection of the k most frequently accessed elements. \u2217/\n11 public Iterable<E> getFavorites(int k) throws IllegalArgumentException\n{\n12 if (k < 0 k > size())\n||\n13 throw new IllegalArgumentException(\"Invalid k\");\n14\n15 // we begin by making a copy of the original list\n16 PositionalList<Item<E>> temp = new LinkedPositionalList<>();\n17 for (Item<E> item : list)\n18 temp.addLast(item);\n19\n20 // we repeated find, report, and remove element with largest count\n21 PositionalList<E> result = new LinkedPositionalList<>();\n22 for (int j=0; j < k; j++)\n{\n23 Position<Item<E>> highPos = temp.first();\n24 Position<Item<E>> walk = temp.after(highPos);\n25 while (walk != null)\n{\n26 if (count(walk) > count(highPos))\n27 highPos = walk;\n28 walk = temp.after(walk);\n29\n}\n30 // we have now found element with highest count\n31 result.addLast(value(highPos));\n32 temp.remove(highPos);\n33\n}\n34 return result;\n35\n}\n36\n}\nCode Fragment 7.18: Class FavoritesListMTF implementing the move-to-front\nheuristic. This class extends FavoritesList (Code Fragments 7.16 and 7.17) and\noverridesmethodsmoveUpandgetFavorites.\nwww.it-ebooks.info\n300 Chapter7. ListandIteratorADTs\n7.8 Exercises\nReinforcement\nR-7.1 Drawarepresentation,akintoExample7.1,ofaninitiallyemptylistLafterper-\nformingthe followingsequenceofoperations: add(0,4), add(0,3), add(0,2),\nadd(2,1),add(1,5),add(1,6),add(3,7),add(0,8).\nR-7.2 GiveanimplementationofthestackADTusinganarraylistforstorage.\nR-7.3 GiveanimplementationofthedequeADTusinganarraylistforstorage.\nR-7.4 Give a justification of the runningtimes shownin Table 7.1 forthe methodsof\nanarraylistimplementedwitha(nonexpanding)array.\nR-7.5 The java.util.ArrayList includes a method, trimToSize(), that replaces the un-\nderlyingarraywithonewhosecapacitypreciselyequalsthenumberofelements\ncurrently in the list. Implementsuch a method for our dynamic version of the\nArrayListclassfromSection7.2.\nR-7.6 Redo the justification of Proposition 7.2 assuming that the the cost of growing\nthearrayfromsizektosize2kis3kcyber-dollars. Howmuchshouldeachpush\noperationbechargedtomaketheamortizationwork?\nR-7.7 Consider an implementation of the array list ADT using a dynamic array, but\ninsteadofcopyingtheelementsintoanarrayofdoublethesize(thatis,fromNto\n2N)whenitscapacityisreached,wecopytheelementsintoanarraywith N/4\n\u2308 \u2309\nadditionalcells, goingfromcapacityN to N+ N/4 . Show thatperforminga\n\u2308 \u2309\nsequence of n push operations (that is, insertions at the end) still runs in O(n)\ntimeinthiscase.\nR-7.8 SupposewearemaintainingacollectionC ofelementssuchthat,eachtimewe\naddanewelementtothecollection,wecopythecontentsofCintoanewarray\nlist of just the right size. What is the running time of adding n elements to an\ninitiallyemptycollectionCinthiscase?\nR-7.9 The add method for a dynamic array, as described in Code Fragment 7.5, has\nthefollowinginefficiency. Inthecasewhenaresizeoccurs,theresizeoperation\ntakes time to copyall the elementsfrom the old arrayto a new array, and then\nthesubsequentloopinthebodyofaddshiftssomeofthemtomakeroomfora\nnew element. Give an improvedimplementationof theadd method, so that, in\nthecaseofaresize,theelementsarecopiedintotheirfinalplaceinthenewarray\n(thatis,noshiftingisdone).\nR-7.10 ReimplementtheArrayStackclass,fromSection6.1.2,usingdynamicarraysto\nsupportunlimitedcapacity.\nR-7.11 Describe animplementationof the positionallist methodsaddLastandaddBe-\nforerealizedbyusingonlymethodsintheset isEmpty,first,last,before,after,\n{\naddAfter,addFirst .\n}\nwww.it-ebooks.info\n7.8. Exercises 301\nR-7.12 SupposewewanttoextendthePositionalListabstractdatatypewithamethod,\nindexOf(p), that returns the current index of the element stored at position p.\nShowhowtoimplementthismethodusingonlyothermethodsofthePositional-\nListinterface(notdetailsofourLinkedPositionalListimplementation).\nR-7.13 SupposewewanttoextendthePositionalListabstractdatatypewithamethod,\nfindPosition(e), that returns the first position containing an element equal to\ne (or null if no such position exists). Show how to implement this method\nusing only existing methods of the PositionalList interface (not details of our\nLinkedPositionalListimplementation).\nR-7.14 TheLinkedPositionalListimplementationofCodeFragments7.9\u20137.12doesnot\ndo any error checking to test if a given position p is actually a member of the\nrelevantlist. GiveadetailedexplanationoftheeffectofacallL.addAfter(p,e)\nonalistL,yetwithaposition pthatbelongstosomeotherlistM.\nR-7.15 To better model a FIFO queue in which entries may be deleted before reach-\ning the front, design a LinkedPositionalQueueclass that supportsthe complete\nqueue ADT, yet with enqueue returning a position instance and support for a\nnew method, remove(p), that removes the element associated with position p\nfromthequeue. Youmayusetheadapterdesignpattern(Section6.1.3),usinga\nLinkedPositionalListasyourstorage.\nR-7.16 Describe how to implement a method, alternateIterator(), for a positional list\nthatreturnsaniteratorthatreportsonlythoseelementshavingevenindexinthe\nlist.\nR-7.17 Redesign the Progression class, from Section 2.2.3, so that it formally imple-\nmentstheIterator<long>interface.\nR-7.18 The java.util.Collection interface includes a method, contains(o), that returns\ntrueifthecollectioncontainsanyobjectthatequalsObjecto. Implementsucha\nmethodintheArrayListclassofSection7.2.\nR-7.19 The java.util.Collection interface includes a method, clear(), that removes all\nelementsfroma collection. Implementsucha methodin theArrayList class of\nSection7.2.\nR-7.20 Demonstratehowtousethejava.util.Colletions.reversemethodtoreverseanar-\nrayofobjects.\nR-7.21 Given the set of element a,b,c,d,e,f stored in a list, show the final state of\n{ }\nthe list, assuming we use the move-to-front heuristic and access the elements\naccordingtothefollowingsequence:(a,b,c,d,e,f,a,c,f,b,d,e).\nR-7.22 Suppose that we have made kn total accesses to the elements in a list L of n\nelements,forsomeintegerk 1. Whataretheminimumandmaximumnumber\n\u2265\nofelementsthathavebeenaccessedfewerthanktimes?\nR-7.23 Let L be a list of n items maintained according to the move-to-frontheuristic.\nDescribeaseriesofO(n)accessesthatwillreverseL.\nR-7.24 ImplementaresetCounts()methodfortheFavoritesListclassthatresetsallele-\nments\u2019accesscountstozero(whileleavingtheorderofthelistunchanged).\nwww.it-ebooks.info\n302 Chapter7. ListandIteratorADTs\nCreativity\nC-7.25 Give an array-basedlist implementation, with fixed capacity, treating the array\ncircularlysothatitachievesO(1)timeforinsertionsandremovalsatindex0,as\nwellasinsertionsandremovalsattheendofthearraylist. Yourimplementation\nshouldalsoprovideforaconstant-timegetmethod.\nC-7.26 Complete the previous exercise, except using a dynamic array to provide un-\nboundedcapacity.\nC-7.27 ModifyourArrayList implementationtosupporttheCloneableinterface,asde-\nscribedinSection3.6.\nC-7.28 In Section 7.5.3, we demonstrated how the Collections.shuffle method can be\nadapted to shuffle a reference-type array. Give a direct implementation of a\nshufflemethodforan arrayof intvalues. Youmayusethe method,nextInt(n)\nofthe Randomclass, whichreturnsarandomnumberbetween0 andn 1, in-\n\u2212\nclusive. Your method should guarantee that every possible ordering is equally\nlikely.Whatistherunningtimeofyourmethod?\nC-7.29 RevisethearraylistimplementationgiveninSection7.2.1sothatwhentheac-\ntual numberof elements, n, in the arraygoes belowN/4, where N is the array\ncapacity,thearrayshrinkstohalfitssize.\nC-7.30 Provethatwhenusingadynamicarraythatgrowsandshrinksasintheprevious\nexercise, the following series of 2n operationstakes O(n) time: n insertions at\ntheendofaninitiallyemptylist, followedbyndeletions,eachfromtheendof\nthelist.\nC-7.31 Give a formalproof that any sequenceof n push or pop operations(that is, in-\nsertionsordeletionsattheend)onaninitiallyemptydynamicarraytakesO(n)\ntime,ifusingthestrategydescribedinExerciseC-7.29.\nC-7.32 ConsideravariantofExerciseC-7.29,inwhichanarrayofcapacityN isresized\nto capacity precisely that of the number of elements, any time the number of\nelements in the array goes strictly below N/4. Give a formal proof that any\nsequenceofnpushorpopoperationsonaninitiallyemptydynamicarraytakes\nO(n)time.\nC-7.33 ConsideravariantofExerciseC-7.29,inwhichanarrayofcapacityN,isresized\nto capacity precisely that of the number of elements, any time the number of\nelementsinthearraygoesstrictlybelowN/2. Showthatthereexistsasequence\nofnpushandpopoperationsthatrequires\u2126(n2)timetoexecute.\nC-7.34 Describe how to implement the queue ADT using two stacks as instance vari-\nables, such that all queue operations execute in amortized O(1) time. Give a\nformalproofoftheamortizedbound.\nC-7.35 ReimplementtheArrayQueueclass,fromSection6.2.2,usingdynamicarraysto\nsupportunlimitedcapacity.Beespeciallycarefulaboutthetreatmentofacircular\narraywhenresizing.\nwww.it-ebooks.info\n7.8. Exercises 303\nC-7.36 Suppose we want to extend the PositionalList interface to include a method,\npositionAtIndex(i), that returns the position of the element having index i (or\nthrows an IndexOutOfBoundsException, if warranted). Show how to imple-\nment this method, using only existing methods of the PositionalList interface,\nbytraversingtheappropriatenumberofstepsfromthefrontofthelist.\nC-7.37 Repeatthepreviousproblem,butuseknowledgeofthesizeofthelisttotraverse\nfromtheendofthelistthatisclosesttothedesiredindex.\nC-7.38 ExplainhowanyimplementationofthePositionalListADTcanbemadetosup-\nportallmethodsoftheList ADT,describedin Section7.1,assuminganimple-\nmentation is givenfor the positionAtIndex(i) method, proposedin Exercise C-\n7.36.\nC-7.39 SupposewewanttoextendthePositionalListabstractdatatypewithamethod,\nmoveToFront(p), that movesthe element at position p to the front of a list (if\nnotalreadythere),whilekeepingtherelativeorderoftheremainingelementsun-\nchanged.Showhowtoimplementthismethodusingonlyexistingmethodsofthe\nPositionalListinterface(notdetailsofourLinkedPositionalListimplementation).\nC-7.40 Redo the previous problem, but providing an implementation within the class\nLinkedPositionalListthatdoesnotcreateordestroyanynodes.\nC-7.41 ModifyourLinkedPositionalListimplementationtosupporttheCloneableinter-\nface,asdescribedinSection3.6.\nC-7.42 Describeanonrecursivemethodforreversingapositionallistrepresentedwitha\ndoublylinkedlistusingasinglepassthroughthelist.\nC-7.43 Page 281 describes an array-based representation for implementing the posi-\ntionallistADT.GiveapseudocodedescriptionoftheaddBeforemethodforthat\nrepresentation.\nC-7.44 Describe a method for performing a card shuffle of a list of 2n elements, by\nconvertingitintotwolists. AcardshuffleisapermutationwherealistLiscut\nintotwolists,L andL ,whereL isthefirsthalfofLandL isthesecondhalf\n1 2 1 2\nofL, andthenthese twolistsaremergedintoonebytakingthefirstelementin\nL ,thenthefirstelementinL ,followedbythesecondelementinL ,thesecond\n1 2 1\nelementinL ,andsoon.\n2\nC-7.45 How mightthe LinkedPositionalListclass be redesignedto detect the error de-\nscribedinExerciseR-7.14.\nC-7.46 ModifytheLinkedPositionalListclasstosupportamethodswap(p,q)thatcauses\nthe underlyingnodesreferencedbypositions p andqto beexchangedforeach\nother. Relinktheexistingnodes;donotcreateanynewnodes.\nC-7.47 Anarrayissparseifmostofitsentriesarenull.AlistLcanbeusedtoimplement\nsuchanarray,A,efficiently.Inparticular,foreachnonnullcellA[i],wecanstore\napair(i,e)inL,whereeistheelementstoredatA[i]. Thisapproachallowsusto\nrepresentAusingO(m)storage,wheremisthenumberofnonnullentriesinA.\nDescribeandanalyzeefficientwaysofperformingthemethodsofthearraylist\nADTonsucharepresentation.\nwww.it-ebooks.info\n304 Chapter7. ListandIteratorADTs\nC-7.48 DesignacircularpositionallistADTthatabstractsacircularlylinkedlistinthe\nsamewaythatthepositionallistADTabstractsadoublylinkedlist.\nC-7.49 Provideanimplementationofthelistiterator()method,inthecontextoftheclass\nLinkedPositionalList,thatreturnsanobjectthatsupportsthejava.util.ListIterator\ninterfacedescribedinSection7.5.1.\nC-7.50 Describeaschemeforcreatinglistiteratorsthatfailfast,thatis,theyallbecome\ninvalidassoonastheunderlyinglistchanges.\nC-7.51 Thereisasimplealgorithm,calledbubble-sort,forsortingalistLofncompa-\nrable elements. This algorithm scans the list n 1 times, where, in each scan,\n\u2212\nthe algorithm comparesthe current element with the next one and swaps them\niftheyareoutoforder. Givea pseudocodedescriptionofbubble-sortthatisas\nefficientaspossibleassumingLisimplementedwithadoublylinkedlist. What\nistherunningtimeofthisalgorithm?\nC-7.52 RedoExerciseC-7.51assumingLisimplementedwithanarraylist.\nC-7.53 DescribeanefficientmethodformaintainingafavoriteslistL,withthemove-to-\nfrontheuristic,suchthatelementsthathavenotbeenaccessedinthemostrecent\nnaccessesareautomaticallypurgedfromthelist.\nC-7.54 Supposewehaveann-elementlistLmaintainedaccordingtothemove-to-front\nheuristic. Describe a sequence of n2 accesses that is guaranteedto take \u2126(n3)\ntimetoperformonL.\nC-7.55 Ausefuloperationindatabasesisthenaturaljoin.Ifweviewadatabaseasalist\noforderedpairsofobjects,thenthenaturaljoinofdatabasesAandBisthelist\nofallorderedtriples(x,y,z) suchthatthepair(x,y)isinAandthepair(y,z) is\ninB. Describeandanalyzeanefficientalgorithmforcomputingthenaturaljoin\nofalistAofnpairsandalistBofmpairs.\nC-7.56 When Bob wants to send Alice a messageM on the Internet, he breaksM into\nn data packets, numbers the packets consecutively, and injects them into the\nnetwork. WhenthepacketsarriveatAlice\u2019scomputer,theymaybeoutoforder,\nsoAlicemustassemblethesequenceofnpacketsinorderbeforeshecanbesure\nshe has the entire message. Describe an efficient scheme for Alice to do this.\nWhatistherunningtimeofthisalgorithm?\nC-7.57 ImplementtheFavoritesListclassusinganarraylist.\nProjects\nP-7.58 Developanexperiment,usingtechniquessimilar tothoseinSection4.1,totest\nthe efficiencyof n successive callsto theadd methodofan ArrayList, forvari-\nousn,undereachofthefollowingthreescenarios:\na. Eachaddtakesplaceatindex0.\nb. Eachaddtakesplaceatindexsize()/2.\nc. Eachaddtakesplaceatindexsize().\nAnalyzeyourempiricalresults.\nwww.it-ebooks.info\nChapterNotes 305\nP-7.59 ReimplementtheLinkedPositionalListclasssothataninvalidpositionisreported\ninascenariosuchastheonedescribedinExerciseR-7.14.\nP-7.60 Implementa CardHand class thatsupportsa personarranginga groupof cards\nin his or her hand. The simulatorshould representthe sequenceof cardsusing\nasinglepositionallistADTsothatcardsofthesamesuitarekepttogether. Im-\nplementthis strategyby meansof four\u201cfingers\u201d into the hand, one for each of\nthesuitsofhearts,clubs,spades,anddiamonds,sothataddinganewcardtothe\nperson\u2019s hand or playing a correct card from the hand can be done in constant\ntime. Theclassshouldsupportthefollowingmethods:\naddCard(r,s):Addanewcardwithrankrandsuitstothehand.\n\u2022\nplay(s):Removeandreturnacardofsuitsfromtheplayer\u2019shand;ifthere\n\u2022\nisnocardofsuits,thenremoveandreturnanarbitrarycardfromthehand.\niterator(): Returnaniteratorforallcardscurrentlyinthehand.\n\u2022\nsuitIterator(s):Returnaniteratorforallcardsofsuitsthatarecurrentlyin\n\u2022\nthehand.\nP-7.61 Writeasimpletexteditor,whichstoresanddisplaysastringofcharactersusing\nthepositionallistADT,togetherwithacursorobjectthathighlightsapositionin\nthestring. Theeditormustsupportthefollowingoperations:\nleft: Movecursorleftonecharacter(donothingifatbeginning).\n\u2022\nright:Movecursorrightonecharacter(donothingifatend).\n\u2022\ninsert c:Insertthecharactercjustafterthecursor.\n\u2022\ndelete:Deletethecharacterjustafterthecursor(ifnotatend).\n\u2022\nChapter Notes\nThetreatmentofdatastructuresascollections(andotherprinciplesofobject-orientedde-\nsign)canbefoundinobject-orienteddesignbooksbyBooch[16],Budd[19],andLiskov\nandGuttag[67]. ListsanditeratorsarepervasiveconceptsintheJavaCollectionsFrame-\nwork. Our positional list ADT is derived from the \u201cposition\u201d abstraction introduced by\nAho,Hopcroft,andUllman[6],andthelistADTofWood[96]. Implementationsoflists\nviaarraysandlinkedlistsarediscussedbyKnuth[60].\nwww.it-ebooks.info\nwww.it-ebooks.info\nChapter\n8\nTrees\nContents\n8.1 General Trees . . . . . . . . . . . . . . . . . . . . . . . . . 308\n8.1.1 Tree Definitions and Properties . . . . . . . . . . . . . . . 309\n8.1.2 The Tree Abstract Data Type . . . . . . . . . . . . . . . 312\n8.1.3 Computing Depth and Height. . . . . . . . . . . . . . . . 314\n8.2 Binary Trees . . . . . . . . . . . . . . . . . . . . . . . . . . 317\n8.2.1 The Binary Tree Abstract Data Type . . . . . . . . . . . . 319\n8.2.2 Properties of Binary Trees . . . . . . . . . . . . . . . . . 321\n8.3 Implementing Trees . . . . . . . . . . . . . . . . . . . . . . 323\n8.3.1 Linked Structure for Binary Trees . . . . . . . . . . . . . . 323\n8.3.2 Array-Based Representation of a Binary Tree . . . . . . . 331\n8.3.3 Linked Structure for General Trees . . . . . . . . . . . . . 333\n8.4 Tree Traversal Algorithms . . . . . . . . . . . . . . . . . . . 334\n8.4.1 Preorder and Postorder Traversals of General Trees . . . . 334\n8.4.2 Breadth-First Tree Traversal . . . . . . . . . . . . . . . . 336\n8.4.3 Inorder Traversal of a Binary Tree . . . . . . . . . . . . . 337\n8.4.4 Implementing Tree Traversals in Java . . . . . . . . . . . 339\n8.4.5 Applications of Tree Traversals . . . . . . . . . . . . . . . 343\n8.4.6 Euler Tours . . . . . . . . . . . . . . . . . . . . . . . . . 348\n8.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\nwww.it-ebooks.info\n308 Chapter8. Trees\n8.1 General Trees\nProductivity experts say that breakthroughs come by thinking \u201cnonlinearly.\u201d In\nthischapter, wewilldiscuss oneofthemostimportant nonlinear datastructures in\ncomputing\u2014trees. Treestructures areindeed abreakthrough indata organization,\nfor they allow us to implement a host of algorithms much faster than when using\nlinear data structures, such as arrays or linked lists. Trees also provide a natural\norganization for data, and consequently have become ubiquitous structures in file\nsystems, graphical user interfaces, databases, websites, and many other computer\nsystems.\nIt is not always clear what productivity experts mean by \u201cnonlinear\u201d thinking,\nbut when we say that trees are \u201cnonlinear,\u201d we are referring to an organizational\nrelationship that is richer than the simple \u201cbefore\u201d and \u201cafter\u201d relationships be-\ntweenobjectsinsequences. Therelationships inatreearehierarchical,withsome\nobjects being \u201cabove\u201d and some \u201cbelow\u201d others. Actually, the main terminology\nfor tree data structures comes from family trees, with the terms \u201cparent,\u201d \u201cchild,\u201d\n\u201cancestor,\u201d and\u201cdescendant\u201d beingthemostcommonwordsusedtodescriberela-\ntionships. WeshowanexampleofafamilytreeinFigure8.1.\nhtoiabeN radeK leebdA masbiM amhsiM hamuD\nleamhsI\nassaM dadaH ameT ruteJ hsihpaN hamedeK\nzahpilE leueR\nuasE\nhsueJ malaJ haroK nebueR\ncaasI\nnoemiS iveL haduJ naD\nmaharbA\nilathpaN\n)learsI(bocaJ\ndaG rehsA rahcassI\nnarmiZ\nnulubeZ haniD\nabehS\nhpesoJ\nnahskoJ\nnadeD\nnimajneB\nnadeM\nhahpE rehpE\nnaidiM\nhconaH adibA haadlE\nkabhsI hauhS\nFigure 8.1: A family tree showing some descendants of Abraham, as recorded in\nGenesis,chapters 25\u201336.\nwww.it-ebooks.info\n8.1. GeneralTrees 309\n8.1.1 Tree Definitions and Properties\nA tree is an abstract data type that stores elements hierarchically. With the excep-\ntion of the top element, each element in a tree has a parent element and zero or\nmore children elements. A tree is usually visualized by placing elements inside\novals or rectangles, and by drawing the connections between parents and children\nwith straight lines. (See Figure 8.2.) We typically call the top element the root\nof the tree, but it is drawn as the highest element, with the other elements being\nconnected below(justtheopposite ofabotanical tree).\nElectronics R\u2019Us\nR&D Sales Purchasing Manufacturing\nDomestic International TV CD Tuner\nCanada S. America Overseas\nAfrica Europe Asia Australia\nFigure 8.2: A tree with 17 nodes representing the organization of a fictitious cor-\nporation. The root stores Electronics R\u2019Us. The children of the root store R&D,\nSales, Purchasing, and Manufacturing. The internal nodes store Sales, Interna-\ntional, Overseas,Electronics R\u2019Us,andManufacturing.\nFormal Tree Definition\nFormally,wedefineatreeT asasetofnodesstoring elementssuchthatthenodes\nhaveaparent-child relationship thatsatisfiesthefollowingproperties:\nIfT isnonempty,ithasaspecialnode,calledtherootofT,thathasnoparent.\n\u2022\nEach node v ofT different from the root has aunique parent node w; every\n\u2022\nnodewithparentwisachildofw.\nNotethataccording toourdefinition, atreecanbeempty, meaningthatitdoesnot\nhave any nodes. This convention also allows us to define a tree recursively such\nthat a tree T is either empty or consists of a node r, called the root of T, and a\n(possibly empty)setofsubtreeswhoserootsarethechildren ofr.\nwww.it-ebooks.info\n310 Chapter8. Trees\nOther Node Relationships\nTwo nodes that are children of the same parent are siblings. A node v is external\nif v has no children. A node v is internal if it has one or more children. External\nnodesarealsoknownasleaves.\nExample 8.1: In Section 5.1.4, wediscussed the hierarchical relationship be-\ntweenfilesanddirectoriesinacomputer\u2019sfilesystem,althoughatthetimewe\ndidnotemphasizethenomenclatureofafilesystemasatree. InFigure8.3,we\nrevisitanearlierexample. Weseethattheinternalnodesofthetreeareassoci-\natedwithdirectoriesandtheleavesareassociatedwithregularfiles. IntheUnix\nandLinuxoperatingsystems,therootofthetreeisappropriatelycalledthe\u201croot\ndirectory,\u201dandisrepresentedbythesymbol\u201c/.\u201d\n/user/rt/courses/\ncs016/ cs252/\ngrades grades\nhomeworks/ programs/ projects/\nhw1 hw2 hw3 pr1 pr2 pr3\npapers/ demos/\nbuylow sellhigh market\nFigure8.3: Treerepresenting aportionofafilesystem.\nA node u is an ancestor of a node v if u=v or u is an ancestor of the parent\nofv. Conversely,wesaythatanodevisadescendantofanodeuifuisanancestor\nof v. For example, in Figure 8.3, cs252/ is an ancestor of papers/, and pr3 is a\ndescendant ofcs016/. ThesubtreeofT rooted atanodevisthetreeconsisting of\nallthedescendantsofvinT (includingvitself). InFigure8.3,thesubtreerootedat\ncs016/ consists of the nodes cs016/, grades, homeworks/, programs/, hw1, hw2,\nhw3,pr1,pr2,andpr3.\nEdges and Paths in Trees\nAn edge of tree T is a pair of nodes (u,v) such that u is the parent of v, or vice\nversa. A path of T is asequence of nodes such that any two consecutive nodes in\nthe sequence form an edge. For example, the tree in Figure 8.3 contains the path\n(cs252/, projects/,demos/,market).\nwww.it-ebooks.info\n8.1. GeneralTrees 311\nOrdered Trees\nA tree is ordered if there is a meaningful linear order among the children of each\nnode; that is, we purposefully identify the children of a node as being the first,\nsecond, third, and soon. Such anorder isusually visualized by arranging siblings\nlefttoright, according totheirorder.\nExample 8.2: Thecomponentsofastructureddocument,suchasabook,arehier-\narchicallyorganizedasatreewhoseinternalnodesareparts,chapters,andsections,\nandwhoseleavesareparagraphs,tables,figures,andsoon.(SeeFigure8.4.)The\nrootofthetreecorrespondstothebookitself.Wecould,infact,considerexpanding\nthetreefurthertoshowparagraphsconsistingofsentences,sentencesconsistingof\nwords,andwordsconsistingofcharacters.Suchatreeisanexampleofanordered\ntree,becausethereisawell-definedorderamongthechildrenofeachnode.\nBook\nPreface Part A Part B References\n... ... ... ...\n\u00b6 \u00b6 Ch. 1 Ch. 5 Ch. 6 Ch. 9 \u00b6 \u00b6\n... ... ... ...\n\u00a7 1.1 \u00a7 1.4 \u00a7 5.1 \u00a7 5.7 \u00a7 6.1 \u00a7 6.5 \u00a7 9.1 \u00a7 9.6\n... ...\n...\n\u00b6 \u00b6 \u00b6 \u00b6\nFigure8.4: Anorderedtreeassociated withabook.\nLet\u2019s look back at the other examples of trees that we have described thus far,\nand consider whether the order of children is significant. A family tree that de-\nscribes generational relationships, asinFigure8.1, isoften modeled asanordered\ntree,withsiblings orderedaccording totheirbirth.\nIncontrast, anorganizational chartforacompany,asinFigure8.2,istypically\nconsidered an unordered tree. Likewise, when using a tree to describe an inher-\nitance hierarchy, as in Figure 2.7, there is no particular significance to the order\namong the subclasses of a parent class. Finally, we consider the use of a tree in\nmodelingacomputer\u2019sfilesystem,asinFigure8.3. Althoughanoperatingsystem\noftendisplaysentriesofadirectoryinaparticularorder(e.g.,alphabetical, chrono-\nlogical), suchanorderisnottypically inherenttothefilesystem\u2019srepresentation.\nwww.it-ebooks.info\n312 Chapter8. Trees\n8.1.2 The Tree Abstract Data Type\nAs we did with positional lists in Section 7.3, we define a tree ADT using the\nconcept of a position as an abstraction for a node of a tree. An element is stored\nateachposition, andpositions satisfyparent-child relationships thatdefinethetree\nstructure. Aposition objectforatreesupports themethod:\ngetElement(): Returnstheelementstoredatthisposition.\nThe tree ADT then supports the following accessor methods, allowing a user\ntonavigate thevariouspositions ofatreeT:\nroot(): Returnstheposition oftherootofthetree\n(ornullifempty).\nparent(p): Returnstheposition oftheparentofposition p\n(ornullif pistheroot).\nchildren(p): Returns an iterable collection containing the children of\nposition p(ifany).\nnumChildren(p): Returnsthenumberofchildrenofposition p.\nIfatreeT isordered, thenchildren(p)reportsthechildrenof pinorder.\nIn addition to the above fundamental accessor methods, a tree supports the\nfollowingquerymethods:\nisInternal(p): Returnstrueifposition phasatleastonechild.\nisExternal(p): Returnstrueifposition pdoesnothaveanychildren.\nisRoot(p): Returnstrueifposition pistherootofthetree.\nThese methods make programming with trees easier and more readable, since\nwecanusethemintheconditionals ofif statements andwhileloops.\nTrees support a number of more general methods, unrelated to the specific\nstructure ofthetree. Theseincude:\nsize(): Returns the number of positions (and hence elements)\nthatarecontained inthetree.\nisEmpty(): Returns true if the tree does not contain any positions\n(andthusnoelements).\niterator(): Returnsaniteratorforallelementsinthetree\n(sothatthetreeitselfisIterable).\npositions(): Returnsaniterablecollection ofallpositions ofthetree.\nIf an invalid position is sent as a parameter to any method of a tree, then an\nIllegalArgumentExceptionisthrown.\nWe do not define any methods for creating or modifying trees at this point.\nWe prefer to describe different tree update methods in conjunction with specific\nimplementations ofthetreeinterface, andspecificapplications oftrees.\nwww.it-ebooks.info\n8.1. GeneralTrees 313\nA Tree Interface in Java\nIn Code Fragment 8.1, we formalize the Tree ADT by defining the Tree interface\nin Java. We rely upon the same definition of the Position interface as introduced\nfor positional lists in Section 7.3.2. Note well that we declare the Tree interface\nto formally extend Java\u2019s Iterable interface (and we include a declaration of the\nrequired iterator()method).\n1 /\u2217\u2217 An interface for a tree where nodes can have an arbitrary number of children. \u2217/\n2 public interface Tree<E> extends Iterable<E>\n{\n3 Position<E> root();\n4 Position<E> parent(Position<E> p) throws IllegalArgumentException;\n5 Iterable<Position<E>> children(Position<E> p)\n6 throws IllegalArgumentException;\n7 int numChildren(Position<E> p) throws IllegalArgumentException;\n8 boolean isInternal(Position<E> p) throws IllegalArgumentException;\n9 boolean isExternal(Position<E> p) throws IllegalArgumentException;\n10 boolean isRoot(Position<E> p) throws IllegalArgumentException;\n11 int size();\n12 boolean isEmpty();\n13 Iterator<E> iterator();\n14 Iterable<Position<E>> positions();\n15\n}\nCodeFragment8.1: DefinitionoftheTreeinterface.\nAn AbstractTree Base Class in Java\nIn Section 2.3, we discussed the role of interfaces and abstract classes in Java.\nWhile an interface is a type definition that includes public declarations of vari-\nous methods, an interface cannot include definitions for any of those methods. In\ncontrast, an abstract class may define concrete implementations for some of its\nmethods, whileleaving otherabstract methodswithoutdefinition.\nAn abstract class is designed to serve as a base class, through inheritance, for\none or more concrete implementations of an interface. When some of the func-\ntionality of an interface is implemented in an abstract class, less work remains to\ncompleteaconcreteimplementation. ThestandardJavalibrariesincludemanysuch\nabstractclasses,includingseveralwithintheJavaCollectionsFramework. Tomake\ntheirpurposeclear,thoseclassesareconventionallynamedbeginningwiththeword\nAbstract. Forexample, thereisanAbstractCollectionclassthatimplements some\nofthefunctionality oftheCollectioninterface, anAbstractQueueclassthatimple-\nments some of the functionality of the Queue interface, and an AbstractList class\nthatimplementssomeofthefunctionality oftheListinterface.\nwww.it-ebooks.info\n314 Chapter8. Trees\nIn the case of our Tree interface, we will define an AbstractTree base class,\ndemonstrating howmanytree-based algorithms canbedescribed independently of\nthelow-levelrepresentationofatreedatastructure. Infact,ifaconcreteimplemen-\ntationprovidesthreefundamental methods\u2014root(),parent(p),andchildren(p)\u2014\nall other behaviors of the Tree interface can be derived within the AbstractTree\nbaseclass.\nCodeFragment8.2presentsaninitialimplementation ofanAbstractTreebase\nclass that provides the most trivial methods of the Tree interface. We will defer\nuntil Section 8.4 a discussion of general tree-traversal algorithms that can be used\nto produced the positions() iteration within the AbstractTree class. As with our\npositional listADTinChapter7,theiteration ofpositions ofthetreecaneasilybe\nadapted to produce an iteration of the elements of a tree, or even to determine the\nsizeofatree(although ourconcrete treeimplementations willprovidemoredirect\nmeansforreporting thesize).\n1 /\u2217\u2217 An abstract base class providing some functionality of the Tree interface. \u2217/\n2 public abstract class AbstractTree<E> implements Tree<E>\n{\n3 public boolean isInternal(Position<E> p) return numChildren(p) > 0;\n{ }\n4 public boolean isExternal(Position<E> p) return numChildren(p) == 0;\n{ }\n5 public boolean isRoot(Position<E> p) return p == root();\n{ }\n6 public boolean isEmpty() return size() == 0;\n{ }\n7\n}\nCodeFragment8.2: Aninitialimplementation oftheAbstractTreebaseclass. (We\naddadditional functionality tothisclassasthechaptercontinues.)\n8.1.3 Computing Depth and Height\nLet p be a position within tree T. The depth of p is the number of ancestors of\np, other than p itself. For example, in the tree of Figure 8.2, the node storing\nInternational has depth 2. Note that this definition implies that the depth of the\nrootofT is0. Thedepthof pcanalsoberecursively definedasfollows:\nIf pistheroot,thenthedepthof pis0.\n\u2022\nOtherwise,thedepthof pisoneplusthedepthoftheparentof p.\n\u2022\nBased on this definition, we present a simple recursive algorithm, depth, in Code\nFragment8.3,forcomputing thedepth ofaposition pintreeT. Thismethodcalls\nitselfrecursively ontheparentof p,andadds1tothevaluereturned.\nThe running time of depth(p) for position p is O(d +1), where d denotes\np p\nthedepthof pinthetree,becausethealgorithmperformsaconstant-timerecursive\nstepforeachancestorof p. Thus,algorithmdepth(p)runsinO(n)worst-casetime,\nwhere n is the total number of positions of T, because a position of T may have\ndepth n 1 if all nodes form a single branch. Although such a running time is a\n\u2212\nfunctionoftheinputsize,itismoreinformativetocharacterize therunningtimein\ntermsoftheparameterd ,asthisparametermaybemuchsmallerthann.\np\nwww.it-ebooks.info\n8.1. GeneralTrees 315\n1 /\u2217\u2217 Returns the number of levels separating Position p from the root. \u2217/\n2 public int depth(Position<E> p)\n{\n3 if (isRoot(p))\n4 return 0;\n5 else\n6 return 1 + depth(parent(p));\n7\n}\nCodeFragment8.3: Methoddepth,asimplementedwithintheAbstractTreeclass.\nHeight\nWe next define the height of a tree to be equal to the maximum of the depths of\nits positions (or zero, ifthe tree is empty). Forexample, the tree ofFigure 8.2 has\nheight 4, as the node storing Africa (and its siblings) has depth 4. It is easy to see\nthattheposition withmaximumdepthmustbealeaf.\nIn Code Fragment 8.4, wepresent amethod that computes the height ofa tree\nbased on this definition. Unfortunately, such an approach is not very efficient,\nand so name the algorithm heightBad and declare it as a private method of the\nAbstractTreeclass(sothatitcannotbeusedbyothers).\n1 /\u2217\u2217 Returns the height of the tree. \u2217/\n2 private int heightBad() // works, but quadratic worst-case time\n{\n3 int h = 0;\n4 for (Position<E> p : positions())\n5 if (isExternal(p)) // only consider leaf positions\n6 h = Math.max(h, depth(p));\n7 return h;\n8\n}\nCode Fragment 8.4: Method heightBad of the AbstractTree class. Note that this\nmethodcallsthedepthmethodfromCodeFragment8.3.\nAlthough we have not yet defined the positions() method, we will see that it\ncan be implemented such that the entire iteration runs in O(n) time, where n is\nthe number of positions of T. Because heightBad calls algorithm depth(p) on\neach leaf of T, its running time is O(n+\u2211 (d +1)), where L is the set of leaf\np\u2208L p\npositions ofT. Intheworstcase, thesum\u2211 (d +1)isproportional ton2. (See\np\u2208L p\nExerciseC-8.31.) Thus,algorithm heightBadrunsinO(n2)worst-casetime.\nWecan compute theheight ofatree moreefficiently, inO(n)worst-case time,\nby considering a recursive definition. To do this, we will parameterize a function\nbasedonapositionwithinthetree,andcalculatetheheightofthesubtreerootedat\nthatposition. Formally,wedefinetheheightofaposition pinatreeT asfollows:\nIf pisaleaf,thentheheightof pis0.\n\u2022\nOtherwise, the height of p is one more than the maximum of the heights of\n\u2022\np\u2019schildren.\nwww.it-ebooks.info\n316 Chapter8. Trees\nThefollowing proposition relates our original definition of theheight of atree\ntotheheightoftherootpositionusingthisrecursive formula.\nProposition 8.3: TheheightoftherootofanonemptytreeT,accordingtothe\nrecursivedefinition,equalsthemaximumdepthamongallleavesoftreeT.\nWeleavethejustification ofthisproposition asExerciseR-8.3.\nAnimplementation ofarecursive algorithm tocompute theheightofasubtree\nrooted atagivenposition pispresented inCodeFragment8.5. Theoverall height\nofanonempty treecanbecomputedbysending therootofthetreeasaparameter.\n1 /\u2217\u2217 Returns the height of the subtree rooted at Position p. \u2217/\n2 public int height(Position<E> p)\n{\n3 int h = 0; // base case if p is external\n4 for (Position<E> c : children(p))\n5 h = Math.max(h, 1 + height(c));\n6 return h;\n7\n}\nCodeFragment8.5: Methodheightforcomputing theheight ofasubtree rootedat\naposition pofanAbstractTree.\nItisimportant tounderstand whymethodheightismoreefficientthanmethod\nheightBad. Thealgorithm isrecursive, and itprogresses inatop-down fashion. If\nthe method isinitially called on the root of T, itwill eventually becalled once for\neach position of T. This is because the root eventually invokes the recursion on\neach of its children, which in turn invokes the recursion on each of their children,\nandsoon.\nWe can determine the running time of the recursive height algorithm by sum-\nming, over all the positions, the amount of time spent on the nonrecursive part of\neach call. (Review Section 5.2 for analyses of recursive processes.) In our imple-\nmentation, there is a constant amount of work per position, plus the overhead of\ncomputing the maximum over the iteration of children. Although we do not yet\nhaveaconcreteimplementation ofchildren(p),weassumethatsuchaniterationis\nexecuted in O(c +1) time, where c denotes the number of children of p. Algo-\np p\nrithmheight(p)spendsO(c +1)timeateachposition ptocomputethemaximum,\np\nanditsoverallrunningtimeisO(\u2211 (c +1))=O(n+\u2211 c ). Inordertocomplete\np p p p\ntheanalysis, wemakeuseofthefollowingproperty.\nProposition 8.4: LetT beatreewithnpositions,andletc denotethenumberof\np\nchildrenofapositionpofT.Then,summingoverthepositionsofT,\u2211 c =n 1.\np p\n\u2212\nJustification: Each position of T, with the exception of the root, is a child of\nanotherposition, andthuscontributes oneunittotheabovesum.\nBy Proposition 8.4, the running time of algorithm height, when called on the\nrootofT,isO(n),wherenisthenumberofpositions ofT.\nwww.it-ebooks.info\n8.2. BinaryTrees 317\n8.2 Binary Trees\nAbinarytreeisanorderedtreewiththefollowingproperties:\n1. Everynodehasatmosttwochildren.\n2. Eachchildnodeislabeledasbeingeitheraleftchildorarightchild.\n3. Aleftchildprecedes arightchildintheorderofchildren ofanode.\nThesubtreerootedataleftorrightchildofaninternalnodeviscalledaleftsubtree\nor right subtree, respectively, ofv. Abinary tree isproper if each node has either\nzero or two children. Some people also refer to such trees as being full binary\ntrees. Thus, in a proper binary tree, every internal node has exactly two children.\nAbinarytreethatisnotproperisimproper.\nExample 8.5: Animportantclassofbinarytreesarisesincontextswherewewish\ntorepresentanumberofdifferentoutcomesthatcanresultfromansweringaseries\nofyes-or-noquestions.Eachinternalnodeisassociatedwithaquestion.Startingat\ntheroot,wegototheleftorrightchildofthecurrentnode,dependingonwhether\ntheanswertothequestionis\u201cYes\u201dor\u201cNo.\u201d Witheachdecision,wefollowan\nedgefromaparenttoachild,eventuallytracingapathinthetreefromtheroot\ntoaleaf.Suchbinarytreesareknownasdecision trees,becausealeafpositionp\ninsuchatreerepresentsadecisionofwhattodoifthequestionsassociatedwith\np\u2019sancestorsareansweredinawaythatleadsto p. Adecisiontreeisaproper\nbinarytree.Figure8.5illustratesadecisiontreethatprovidesrecommendationsto\naprospectiveinvestor.\nAre you nervous?\nYes No\nWill you need to access most of the\nSavings account.\nmoney within the next 5 years?\nYes No\nAre you willing to accept risks in\nMoney market fund.\nexchange for higher expected returns?\nYes No\nDiversified portfolio with stocks,\nStock portfolio.\nbonds, and short-term instruments.\nFigure8.5: Adecision treeproviding investmentadvice.\nwww.it-ebooks.info\n318 Chapter8. Trees\nExample 8.6: Anarithmeticexpressioncanberepresentedbyabinarytreewhose\nleavesareassociatedwithvariablesorconstants, andwhoseinternalnodesare\nassociatedwithoneoftheoperators+, , ,and/,asdemonstratedinFigure8.6.\n\u2212 \u2217\nEachnodeinsuchatreehasavalueassociatedwithit.\nIfanodeisleaf,thenitsvalueisthatofitsvariableorconstant.\n\u2022\nIfanodeisinternal,thenitsvalueisdefinedbyapplyingitsoperationtothe\n\u2022\nvaluesofitschildren.\nAtypicalarithmeticexpressiontreeisaproperbinarytree,sinceeachoperator\n+, , ,and/takesexactlytwooperands. Ofcourse,ifweweretoallowunary\n\u2212 \u2217\noperators,likenegation( ),asin\u201c x,\u201dthenwecouldhaveanimproperbinary\n\u2212 \u2212\ntree.\n\u2212\n/ +\n+ 6\n\u2217 \u2217\n+ 3 2 3\n\u2212 \u2212\n3 1 9 5 7 4\nFigure 8.6: A binary tree representing an arithmetic expression. This tree repre-\nsentstheexpression ((((3+1) 3)/((9 5)+2)) ((3 (7 4))+6)). Thevalue\n\u2217 \u2212 \u2212 \u2217 \u2212\nassociated withtheinternalnodelabeled \u201c/\u201dis2.\nA Recursive Binary Tree Definition\nIncidentally, we can also define a binary tree in a recursive way. In that case, a\nbinarytreeiseither:\nAnemptytree.\n\u2022\nA nonempty tree having a root node r, which stores an element, and two\n\u2022\nbinarytreesthatarerespectivelytheleftandrightsubtreesofr. Wenotethat\noneorbothofthosesubtrees canbeemptybythisdefinition.\nwww.it-ebooks.info\n8.2. BinaryTrees 319\n8.2.1 The Binary Tree Abstract Data Type\nAsanabstractdatatype,abinarytreeisaspecializationofatreethatsupportsthree\nadditional accessor methods:\nleft(p): Returnstheposition oftheleftchildof p\n(ornullif phasnoleftchild).\nright(p): Returnstheposition oftherightchildof p\n(ornullif phasnorightchild).\nsibling(p): Returnstheposition ofthesiblingof p\n(ornullif phasnosibling).\nJustasinSection8.1.2forthetreeADT,wedonotdefinespecializedupdatemeth-\nods forbinary trees here. Instead, wewillconsider some possible update methods\nwhenwedescribe specificimplementations andapplications ofbinarytrees.\nDefining a BinaryTree Interface\nCode Fragment 8.6 formalizes the binary tree ADT by defining a BinaryTree in-\nterface in Java. This interface extends the Tree interface that was given in Sec-\ntion 8.1.2 to add the three new behaviors. In this way, a binary tree is expected to\nsupportallthefunctionalitythatwasdefinedforgeneraltrees(e.g.,root,isExternal,\nparent),andthenewbehaviors left,right,andsibling.\n1 /\u2217\u2217 An interface for a binary tree, in which each node has at most two children. \u2217/\n2 public interface BinaryTree<E> extends Tree<E>\n3 /\u2217\u2217 Returns the Position of p's left child (or null if n { o child exists). \u2217/\n4 Position<E> left(Position<E> p) throws IllegalArgumentException;\n5 /\u2217\u2217 Returns the Position of p's right child (or null if no child exists). \u2217/\n6 Position<E> right(Position<E> p) throws IllegalArgumentException;\n7 /\u2217\u2217 Returns the Position of p's sibling (or null if no sibling exists). \u2217/\n8 Position<E> sibling(Position<E> p) throws IllegalArgumentException;\n9\n}\nCode Fragment 8.6: A BinaryTree interface that extends the Tree interface from\nCodeFragment8.1.\nDefining an AbstractBinaryTree Base Class\nWe continue our use of abstract base classes to promote greater reusability within\nourcode. TheAbstractBinaryTreeclass, presented inCodeFragment8.7,inherits\nfrom the AbstractTree class from Section 8.1.2. It provides additional concrete\nmethodsthatcanbederivedfromthenewlydeclaredleftandrightmethods(which\nremainabstract).\nwww.it-ebooks.info\n320 Chapter8. Trees\nThenewsiblingmethodisderivedfromacombinationofleft,right,andparent.\nTypically, weidentify thesibling ofaposition pasthe\u201cother\u201d child of p\u2019sparent.\nHowever, p does not have a sibling if it is the root, or if it is the only child of its\nparent.\nWe can also use the presumed left and right methods to provide concrete im-\nplementations of the numChildren and children methods, which are part of the\noriginal Tree interface. Using the terminology of Section 7.4, the implementa-\ntion of the children method relies on producing a snapshot. We create an empty\njava.util.ArrayList,whichqualifiesasbeinganiterablecontainer, andthenaddany\nchildren thatexist,orderedsothataleftchildisreported beforearightchild.\n1 /\u2217\u2217 An abstract base class providing some functionality of the BinaryTree interface.\u2217/\n2 public abstract class AbstractBinaryTree<E> extends AbstractTree<E>\n3 implements BinaryTree<E>\n4 /\u2217\u2217 Returns the Position of p's sibling (or null if no sibling exists). \u2217/ {\n5 public Position<E> sibling(Position<E> p)\n{\n6 Position<E> parent = parent(p);\n7 if (parent == null) return null; // p must be the root\n8 if (p == left(parent)) // p is a left child\n9 return right(parent); // (right child might be null)\n10 else // p is a right child\n11 return left(parent); // (left child might be null)\n12\n13 } /\u2217\u2217 Returns the number of children of Position p. \u2217/\n14 public int numChildren(Position<E> p)\n{\n15 int count=0;\n16 if (left(p) != null)\n17 count++;\n18 if (right(p) != null)\n19 count++;\n20 return count;\n21\n22 } /\u2217\u2217 Returns an iterable collection of the Positions representing p's children. \u2217/\n23 public Iterable<Position<E>> children(Position<E> p)\n{\n24 List<Position<E>> snapshot = new ArrayList<>(2); // max capacity of 2\n25 if (left(p) != null)\n26 snapshot.add(left(p));\n27 if (right(p) != null)\n28 snapshot.add(right(p));\n29 return snapshot;\n30\n}\n31\n}\nCode Fragment 8.7: An AbstractBinaryTree class that extends the AbstractTree\nclassofCodeFragment8.2andimplementstheBinaryTreeinterfaceofCodeFrag-\nment8.6.\nwww.it-ebooks.info\n8.2. BinaryTrees 321\n8.2.2 Properties of Binary Trees\nBinarytrees haveseveral interesting properties dealing withrelationships between\ntheirheightsandnumberofnodes. WedenotethesetofallnodesofatreeT atthe\nsame depth d as level d of T. In a binary tree, level 0 has at most one node (the\nroot), level 1 has at most two nodes (the children of the root), level 2 has at most\nfournodes, andsoon. (SeeFigure8.7.) Ingeneral, leveld hasatmost2d nodes.\n0\n...\n...\n1\n1\n2\n3\n...\n...\nLevel Nodes\n2\n4\n8\nFigure8.7: Maximumnumberofnodesinthelevelsofabinarytree.\nWe can see that the maximum number of nodes on the levels of a binary tree\ngrowsexponentially aswegodownthetree. Fromthissimpleobservation, wecan\nderivethefollowingpropertiesrelatingtheheightofabinarytreeT withitsnumber\nofnodes. Adetailedjustification oftheseproperties isleftasExerciseR-8.8.\nProposition 8.7: LetT beanonemptybinarytree,andletn,n ,n ,andhdenote\nE I\nthenumberofnodes, numberofexternalnodes, numberofinternalnodes, and\nheightofT,respectively.ThenT hasthefollowingproperties:\n1. h+1 n 2h+1 1\n\u2264 \u2264 \u2212\n2. 1 n 2h\nE\n\u2264 \u2264\n3. h n 2h 1\nI\n\u2264 \u2264 \u2212\n4. log(n+1) 1 h n 1\n\u2212 \u2264 \u2264 \u2212\nAlso,ifT isproper,thenT hasthefollowingproperties:\n1. 2h+1 n 2h+1 1\n\u2264 \u2264 \u2212\n2. h+1 n 2h\nE\n\u2264 \u2264\n3. h n 2h 1\nI\n\u2264 \u2264 \u2212\n4. log(n+1) 1 h (n 1)/2\n\u2212 \u2264 \u2264 \u2212\nwww.it-ebooks.info\n322 Chapter8. Trees\nRelating Internal Nodes to External Nodes in a Proper Binary Tree\nIn addition to the earlier binary tree properties, the following relationship exists\nbetweenthenumberofinternal nodesandexternalnodesinaproperbinarytree.\nProposition 8.8: InanonemptyproperbinarytreeT,withn externalnodesand\nE\nn internalnodes,wehaven =n +1.\nI E I\nJustification: Wejustify thisproposition byremoving nodes fromT anddivid-\ning them upinto two\u201cpiles,\u201d aninternal-node pile and anexternal-node pile, until\nT becomesempty. Thepiles areinitially empty. Bytheend, wewillshowthatthe\nexternal-node pilehasonemorenodethantheinternal-node pile. Weconsider two\ncases:\nCase1: If T has only one node v, we remove v and place it on the external-node\npile. Thus, the external-node pile has one node and the internal-node pile is\nempty.\nCase2: Otherwise (T has more than one node), weremove from T an (arbitrary)\nexternal node w and its parent v, which is an internal node. We place w on\nthe external-node pile and v on the internal-node pile. If v has a parent u,\nthen we reconnect u with the former sibling z of w, as shown in Figure 8.8.\nThisoperation, removesoneinternalnodeandoneexternalnode,andleaves\nthetreebeingaproperbinarytree.\nRepeating this operation, we eventually are left with a final tree consisting\nof a single node. Note that the same number of external and internal nodes\nhave been removed and placed on their respective piles by the sequence of\noperations leading to this final tree. Now, we remove the node of the final\ntree and we place it on the external-node pile. Thus, the external-node pile\nhasonemorenodethantheinternal-node pile.\nu u\nv u\nz w z z\n(a) (b) (c)\nFigure 8.8: Operation that removes an external node and its parent node, used in\nthejustification ofProposition 8.8.\nNotethat theabove relationship does nothold, ingeneral, forimproper binary\ntreesandnonbinary trees, although thereareotherinteresting relationships thatdo\nhold. (SeeExercisesC-8.30through C-8.32.)\nwww.it-ebooks.info\n8.3. ImplementingTrees 323\n8.3 Implementing Trees\nTheAbstractTreeandAbstractBinaryTreeclasses thatwehavedefinedthusfarin\nthis chapter are both abstract base classes. Although they provide a great deal of\nsupport, neither of them can be directly instantiated. We have not yet defined key\nimplementation details for how a tree will be represented internally, and how we\ncaneffectivelynavigate betweenparentsandchildren.\nThere are several choices for the internal representation of trees. We describe\nthe most common representations in this section. We begin with the case of a\nbinarytree,sinceitsshapeismorestrictlydefined.\n8.3.1 Linked Structure for Binary Trees\nA natural way to realize a binary tree T is to use a linked structure, with a node\n(see Figure 8.9a) that maintains references to the element stored at a position p\nand to the nodes associated with the children and parent of p. If p is the root\nof T, then the parent field of p is null. Likewise, if p does not have a left child\n(respectively, right child), the associated field is null. The tree itself maintains an\ninstancevariablestoringareferencetotherootnode(ifany),andavariable,called\nsize, that represents the overall number of nodes of T. We show such a linked\nstructure representation ofabinarytreeinFigure8.9b.\n\u2205\nroot\n5\nsize\nparent\n\u2205 \u2205\nleft right\nelement\n\u2205 \u2205 \u2205 \u2205\nBaltimore Chicago New York Providence Seattle\n(a) (b)\nFigure8.9: Alinkedstructure forrepresenting: (a)asinglenode;(b)abinarytree.\nwww.it-ebooks.info\n324 Chapter8. Trees\nOperations for Updating a Linked Binary Tree\nThe Tree and BinaryTree interfaces define a variety of methods for inspecting an\nexisting tree, yet they donot declare any update methods. Presuming that anewly\nconstructed tree is empty, wewould like to have means for changing the structure\nofcontent ofatree.\nAlthoughtheprinciple ofencapsulation suggests thattheoutwardbehaviors of\nanabstractdatatypeneednotdependontheinternalrepresentation,theefficiencyof\ntheoperationsdependsgreatlyupontherepresentation. Wethereforeprefertohave\neachconcreteimplementationofatreeclasssupportthemostsuitablebehaviorsfor\nupdating a tree. In the case of a linked binary tree, we suggest that the following\nupdatemethodsbesupported:\naddRoot(e): Createsarootforanemptytree,storingeastheelement,\nandreturnsthepositionofthatroot;anerroroccursifthe\ntreeisnotempty.\naddLeft(p,e): Creates a left child of position p, storing element e, and\nreturns theposition ofthenewnode;anerroroccursif p\nalready hasaleftchild.\naddRight(p,e): Createsarightchildofposition p,storingelemente,and\nreturns theposition ofthenewnode;anerroroccursif p\nalready hasarightchild.\nset(p,e): Replacestheelementstoredatposition pwithelemente,\nandreturns thepreviously storedelement.\nattach(p,T ,T ): Attaches the internal structure of trees T and T as the\n1 2 1 2\nrespective left and right subtrees of leaf position p and\nresetsT andT toemptytrees;anerrorconditionoccurs\n1 2\nif pisnotaleaf.\nremove(p): Removesthenodeatposition p,replacingitwithitschild\n(ifany),andreturnstheelementthathadbeenstoredatp;\nanerroroccursif phastwochildren.\nWe have specifically chosen this collection of operations because each can be\nimplemented in O(1) worst-case time with our linked representation. The most\ncomplex of these are attach and remove, due to the case analyses involving the\nvarious parent-child relationships andboundary conditions, yetthereremainsonly\naconstantnumberofoperations toperform. (Theimplementation ofbothmethods\ncould be greatly simplified if we used a tree representation with a sentinel node,\nakintoourtreatmentofpositional lists;seeExerciseC-8.38.)\nwww.it-ebooks.info\n8.3. ImplementingTrees 325\nJava Implementation of a Linked Binary Tree Structure\nWe now present a concrete implementation of a LinkedBinaryTree class that im-\nplements the binary tree ADT, and supports the update methods described on the\nprevious page. ThenewclassformallyextendstheAbstractBinaryTreebaseclass,\ninheriting several concrete implementations ofmethods from thatclass (aswellas\ntheformaldesignation thatitimplementstheBinaryTreeinterface).\nThelow-leveldetailsofourlinkedtreeimplementationarereminiscentoftech-\nniquesusedwhenimplementingtheLinkedPositionalListclassinSection7.3.3. We\ndefineanonpublicnestedNodeclasstorepresentanode,andtoserveasaPosition\nfor the public interface. Aswas portrayed in Figure 8.9, a node maintains a refer-\nence to an element, as well as references to its parent, its left child, and its right\nchild (any of which might be null). The tree instance maintains a reference to the\nrootnode(possibly null),andacountofthenumberofnodesinthetree.\nWealsoprovideavalidateutilitythatiscalledanytimeaPositionisreceivedas\naparameter, toensure that itisavalid node. In thecase ofalinked tree, weadopt\na convention in which we set a node\u2019s parent pointer to itself when it is removed\nfromatree,sothatwecanlaterrecognize itasaninvalid position.\nThe entire LinkedBinaryTree class is presented in Code Fragments 8.8\u20138.11.\nWeprovidethefollowingguidetothatcode:\nCode Fragment 8.8 contains the definition of the nested Node class, which\n\u2022\nimplements the Position interface. It also defines a method, createNode,\nthat returns a new node instance. Such a design uses what is known as the\nfactory methodpattern, allowingustolatersubclassourtreeinordertouse\naspecialized nodetype. (SeeSection11.2.1.) CodeFragment8.8concludes\nwith the declaration of the instance variables of the outer LinkedBinaryTree\nclassanditsconstructor.\nCode Fragment 8.9 includes the protected validate(p) method, followed by\n\u2022\ntheaccessorssize,root,left,andright. Wenotethatallothermethodsofthe\nTreeandBinaryTreeinterfacesarederivedfromthesefourconcretemethods,\nviatheAbstractTreeandAbstractBinaryTreebaseclasses.\nCode Fragments 8.10 and 8.11 provide the six update methods for a linked\n\u2022\nbinary tree, as described on the preceding page. We note that the three\nmethods\u2014addRoot,addLeft,andaddRight\u2014eachrelyonuseofthefactory\nmethod,createNode,toproduceanewnodeinstance.\nThe remove method, given at the end of Code Fragment 8.11, intentionally\nsetstheparentfieldofadeletednodetorefertoitself,inaccordancewithour\nconventionalrepresentationofadefunctnode(asdetectedwithinthevalidate\nmethod). Itresetsallotherfieldstonull,toaidingarbagecollection.\nwww.it-ebooks.info\n326 Chapter8. Trees\n1 /\u2217\u2217 Concrete implementation of a binary tree using a node-based, linked structure. \u2217/\n2 public class LinkedBinaryTree<E> extends AbstractBinaryTree<E>\n{\n3\n4 //----------------nested Node class ----------------\n5 protected static class Node<E> implements Position<E>\n{\n6 private E element; // an element stored at this node\n7 private Node<E> parent; // a reference to the parent node (if any)\n8 private Node<E> left; // a reference to the left child (if any)\n9 private Node<E> right; // a reference to the right child (if any)\n10 /\u2217\u2217 Constructs a node with the given element and neighbors. \u2217/\n11 public Node(E e, Node<E> above, Node<E> leftChild, Node<E> rightChild)\n{\n12 element = e;\n13 parent = above;\n14 left = leftChild;\n15 right = rightChild;\n16\n}\n17 // accessor methods\n18 public E getElement() return element;\n{ }\n19 public Node<E> getParent() return parent;\n{ }\n20 public Node<E> getLeft() return left;\n{ }\n21 public Node<E> getRight() return right;\n{ }\n22 // update methods\n23 public void setElement(E e) element = e;\n{ }\n24 public void setParent(Node<E> parentNode) parent = parentNode;\n{ }\n25 public void setLeft(Node<E> leftChild) left = leftChild;\n{ }\n26 public void setRight(Node<E> rightChild) right = rightChild;\n{ }\n27 //-----------end of nested Node class -----------\n}\n28\n29 /\u2217\u2217 Factory function to create a new node storing element e. \u2217/\n30 protected Node<E> createNode(E e, Node<E> parent,\n31 Node<E> left, Node<E> right)\n{\n32 return new Node<E>(e, parent, left, right);\n33\n}\n34\n35 // LinkedBinaryTree instance variables\n36 protected Node<E> root = null; // root of the tree\n37 private int size = 0; // number of nodes in the tree\n38\n39 // constructor\n40 public LinkedBinaryTree() // constructs an empty binary tree\n{ }\nCodeFragment8.8: Animplementation oftheLinkedBinaryTreeclass.\n(Continues inCodeFragments8.9\u20138.11.)\nwww.it-ebooks.info\n8.3. ImplementingTrees 327\n41 // nonpublic utility\n42 /\u2217\u2217 Validates the position and returns it as a node. \u2217/\n43 protected Node<E> validate(Position<E> p) throws IllegalArgumentException\n{\n44 if (!(p instanceof Node))\n45 throw new IllegalArgumentException(\"Not valid position type\");\n46 Node<E> node = (Node<E>) p; // safe cast\n47 if (node.getParent() == node) // our convention for defunct node\n48 throw new IllegalArgumentException(\"p is no longer in the tree\");\n49 return node;\n50\n}\n51\n52 // accessor methods (not already implemented in AbstractBinaryTree)\n53 /\u2217\u2217 Returns the number of nodes in the tree. \u2217/\n54 public int size()\n{\n55 return size;\n56\n}\n57\n58 /\u2217\u2217 Returns the root Position of the tree (or null if tree is empty). \u2217/\n59 public Position<E> root()\n{\n60 return root;\n61\n}\n62\n63 /\u2217\u2217 Returns the Position of p's parent (or null if p is root). \u2217/\n64 public Position<E> parent(Position<E> p) throws IllegalArgumentException\n{\n65 Node<E> node = validate(p);\n66 return node.getParent();\n67\n}\n68\n69 /\u2217\u2217 Returns the Position of p's left child (or null if no child exists). \u2217/\n70 public Position<E> left(Position<E> p) throws IllegalArgumentException\n{\n71 Node<E> node = validate(p);\n72 return node.getLeft();\n73\n}\n74\n75 /\u2217\u2217 Returns the Position of p's right child (or null if no child exists). \u2217/\n76 public Position<E> right(Position<E> p) throws IllegalArgumentException\n{\n77 Node<E> node = validate(p);\n78 return node.getRight();\n79\n}\nCodeFragment8.9: Animplementation oftheLinkedBinaryTreeclass.\n(ContinuedfromCodeFragment8.8;continuesinCodeFragments8.10and8.11.)\nwww.it-ebooks.info\n328 Chapter8. Trees\n80 // update methods supported by this class\n81 /\u2217\u2217 Places element e at the root of an empty tree and returns its new Position. \u2217/\n82 public Position<E> addRoot(E e) throws IllegalStateException\n{\n83 if (!isEmpty()) throw new IllegalStateException(\"Tree is not empty\");\n84 root = createNode(e, null, null, null);\n85 size = 1;\n86 return root;\n87\n}\n88\n89 /\u2217\u2217 Creates a new left child of Position p storing element e; returns its Position. \u2217/\n90 public Position<E> addLeft(Position<E> p, E e)\n91 throws IllegalArgumentException\n{\n92 Node<E> parent = validate(p);\n93 if (parent.getLeft() != null)\n94 throw new IllegalArgumentException(\"p already has a left child\");\n95 Node<E> child = createNode(e, parent, null, null);\n96 parent.setLeft(child);\n97 size++;\n98 return child;\n99\n}\n100\n101 /\u2217\u2217 Creates a new right child of Position p storing element e; returns its Position. \u2217/\n102 public Position<E> addRight(Position<E> p, E e)\n103 throws IllegalArgumentException\n{\n104 Node<E> parent = validate(p);\n105 if (parent.getRight() != null)\n106 throw new IllegalArgumentException(\"p already has a right child\");\n107 Node<E> child = createNode(e, parent, null, null);\n108 parent.setRight(child);\n109 size++;\n110 return child;\n111\n}\n112\n113 /\u2217\u2217 Replaces the element at Position p with e and returns the replaced element. \u2217/\n114 public E set(Position<E> p, E e) throws IllegalArgumentException\n{\n115 Node<E> node = validate(p);\n116 E temp = node.getElement();\n117 node.setElement(e);\n118 return temp;\n119\n}\nCodeFragment8.10: Animplementation oftheLinkedBinaryTreeclass.\n(Continued fromCodeFragments8.8and8.9;continues inCodeFragment8.11.)\nwww.it-ebooks.info\n8.3. ImplementingTrees 329\n120 /\u2217\u2217 Attaches trees t1 and t2 as left and right subtrees of external p. \u2217/\n121 public void attach(Position<E> p, LinkedBinaryTree<E> t1,\n122 LinkedBinaryTree<E> t2) throws IllegalArgumentException\n{\n123 Node<E> node = validate(p);\n124 if (isInternal(p)) throw new IllegalArgumentException(\"p must be a leaf\");\n125 size += t1.size() + t2.size();\n126 if (!t1.isEmpty()) // attach t1 as left subtree of node\n{\n127 t1.root.setParent(node);\n128 node.setLeft(t1.root);\n129 t1.root = null;\n130 t1.size = 0;\n131\n}\n132 if (!t2.isEmpty()) // attach t2 as right subtree of node\n{\n133 t2.root.setParent(node);\n134 node.setRight(t2.root);\n135 t2.root = null;\n136 t2.size = 0;\n137\n}\n138\n139 } /\u2217\u2217 Removes the node at Position p and replaces it with its child, if any. \u2217/\n140 public E remove(Position<E> p) throws IllegalArgumentException\n{\n141 Node<E> node = validate(p);\n142 if (numChildren(p) == 2)\n143 throw new IllegalArgumentException(\"p has two children\");\n144 Node<E> child = (node.getLeft() != null ? node.getLeft() : node.getRight() );\n145 if (child != null)\n146 child.setParent(node.getParent()); // child\u2019s grandparent becomes its parent\n147 if (node == root)\n148 root = child; // child becomes root\n149 else\n{\n150 Node<E> parent = node.getParent();\n151 if (node == parent.getLeft())\n152 parent.setLeft(child);\n153 else\n154 parent.setRight(child);\n155\n}\n156 size ;\n\u2212\u2212\n157 E temp = node.getElement();\n158 node.setElement(null); // help garbage collection\n159 node.setLeft(null);\n160 node.setRight(null);\n161 node.setParent(node); // our convention for defunct node\n162 return temp;\n163\n}\n164 //-----------end of LinkedBinaryTree class -----------\n}\nCodeFragment8.11: Animplementation oftheLinkedBinaryTreeclass.\n(Continued fromCodeFragments8.8\u20138.10.)\nwww.it-ebooks.info\n330 Chapter8. Trees\nPerformance of the Linked Binary Tree Implementation\nTosummarizetheefficienciesofthelinkedstructurerepresentation, weanalyzethe\nrunning times of the LinkedBinaryTree methods, including derived methods that\nareinherited fromtheAbstractTreeandAbstractBinaryTreeclasses:\nThe size method, implemented in LinkedBinaryTree, uses an instance vari-\n\u2022\nable storing the number of nodes of a tree and therefore takes O(1) time.\nMethod isEmpty, inherited from AbstractTree, relies onasingle callto size\nandthustakesO(1)time.\nThe accessor methods root, left, right, and parent are implemented directly\n\u2022\nin LinkedBinaryTree and take O(1) time each. The sibling, children, and\nnumChildrenmethodsarederivedinAbstractBinaryTreeusingonaconstant\nnumberofcallstotheseotheraccessors, sotheyruninO(1)timeaswell.\nTheisInternalandisExternalmethods,inheritedfromtheAbstractTreeclass,\n\u2022\nrelyonacalltonumChildren,andthusruninO(1)timeaswell. TheisRoot\nmethod, also implemented in AbstractTree, relies on a comparison to the\nresultoftherootmethodandrunsinO(1)time.\nTheupdate method, set,clearly runs inO(1)time. Moresignificantly, allof\n\u2022\nthe methods addRoot, addLeft, addRight, attach, and remove run in O(1)\ntime,aseachinvolves relinking onlyaconstant numberofparent-child rela-\ntionships peroperation.\nMethods depth and height were each analyzed in Section 8.1.3. The depth\n\u2022\nmethodatposition prunsinO(d +1)timewhered isitsdepth;theheight\np p\nmethodontherootofthetreerunsinO(n)time.\nThe overall space requirement of this data structure is O(n), for a tree with\nnnodes, asthereisaninstance oftheNodeclassforeverynode, inaddition tothe\ntop-level sizeand root fields. Table8.1summarizes the performance ofthe linked\nstructure implementation ofabinarytree.\nMethod RunningTime\nsize,isEmpty O(1)\nroot,parent,left,right,sibling,children,numChildren O(1)\nisInternal,isExternal,isRoot O(1)\naddRoot,addLeft,addRight,set,attach,remove O(1)\ndepth(p) O(d +1)\np\nheight O(n)\nTable 8.1: Running times for the methods of an n-node binary tree implemented\nwithalinked structure. ThespaceusageisO(n).\nwww.it-ebooks.info\n8.3. ImplementingTrees 331\n8.3.2 Array-Based Representation of a Binary Tree\nAnalternativerepresentation ofabinarytreeT isbasedonawayofnumberingthe\npositionsofT. Foreveryposition pofT,let f(p)betheintegerdefinedasfollows.\nIf pistherootofT,then f(p)=0.\n\u2022\nIf pistheleftchildofpositionq,then f(p)=2f(q)+1.\n\u2022\nIf pistherightchildofposition q,then f(p)=2f(q)+2.\n\u2022\nThe numbering function f is known as a level numbering of the positions in a\nbinary tree T, for it numbers the positions on each level of T in increasing order\nfrom left to right. (See Figure 8.10.) Note well that the level numbering is based\non potential positions within a tree, not the actual shape of a specific tree, so they\narenotnecessarily consecutive. Forexample,inFigure8.10(b),therearenonodes\nwith level numbering 13 or 14, because the node with level numbering 6 has no\nchildren.\n0\n1 2\n(a)\n3 4 5 6\n7 8 9 10 11 12 13 14\n... ...\n0\n\u2212\n1 2\n/ +\n3 4 5 6\n(b) + 6\n\u2217 \u2217\n7 8 9 10 11 12\n+ 3 2 3\n\u2212 \u2212\n15 16 19 20 25 26\n3 1 9 5 7 4\nFigure8.10: Binarytreelevelnumbering: (a)generalscheme;(b)anexample.\nwww.it-ebooks.info\n332 Chapter8. Trees\nThelevelnumberingfunction f suggests arepresentation ofabinarytreeT by\nmeans of an array-based structure A, with the element at position p of T stored at\nindex f(p)ofthearray. Weshowanexampleofanarray-based representation ofa\nbinarytreeinFigure8.11.\n0\n/\n1 2\n+\n\u2217\n3 4 5 6\n+ 4 2\n\u2212\n7 8 11 12\n3 1 9 5\n/ + + 4 2 3 1 9 5\n\u2217 \u2212\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\nFigure8.11: Representation ofabinarytreebymeansofanarray.\nOne advantage of an array-based representation of a binary tree is that a posi-\ntion pcanberepresented bythesingleinteger f(p),andthatposition-based meth-\nodssuchasroot,parent,left,andrightcanbeimplementedusingsimplearithmetic\noperations onthenumber f(p). Basedonourformulaforthelevelnumbering, the\nleft child of p has index 2f(p)+1, the right child of p has index 2f(p)+2, and\ntheparentof phasindex (f(p) 1)/2 . Weleavethedetailsofacompletearray-\n\u230a \u2212 \u230b\nbasedimplementation asExerciseR-8.16.\nThespaceusageofanarray-based representation depends greatlyontheshape\nof the tree. Let n be the number of nodes of T, and let f be the maximum value\nM\nof f(p) over all the nodes of T. The array A requires length N = 1+ f , since\nM\nelements rangefrom A[0]toA[f ]. NotethatAmayhave anumberofemptycells\nM\nthat do not refer to existing positions of T. In fact, in the worst case, N =2n 1,\n\u2212\nthe justification of which is left as an exercise (R-8.14). In Section 9.3, we will\nsee a class of binary trees, called \u201cheaps\u201d for which N =n. Thus, in spite of the\nworst-case space usage, there are applications for which the array representation\nof a binary tree is space efficient. Still, for general binary trees, the exponential\nworst-case spacerequirement ofthisrepresentation isprohibitive.\nAnotherdrawbackofanarrayrepresentationisthatmanyupdateoperationsfor\ntreescannotbeefficientlysupported. Forexample,removinganodeandpromoting\nitschildtakesO(n)timebecauseitisnotjustthechildthatmoveslocations within\nthearray,butalldescendants ofthatchild.\nwww.it-ebooks.info\n8.3. ImplementingTrees 333\n8.3.3 Linked Structure for General Trees\nWhenrepresentingabinarytreewithalinkedstructure,eachnodeexplicitlymain-\ntains fields left and right as references to individual children. For a general tree,\nthereisnoapriorilimitonthenumberofchildrenthatanodemayhave. Anatural\nway to realize a general tree T as a linked structure is to have each node store a\nsingle container of references to its children. For example, a children field of a\nnodecanbeanarrayorlistofreferences tothechildren ofthenode(ifany). Such\nalinkedrepresentation isschematically illustrated inFigure8.12.\nparent\nNew York\nelement\nchildren\nBaltimore Chicago Providence Seattle\n(a) (b)\nFigure8.12: Thelinkedstructureforageneraltree: (a)thestructureofanode;(b)a\nlargerportionofthedatastructure associated withanodeanditschildren.\nTable8.2summarizes theperformance oftheimplementation ofageneral tree\nusing a linked structure. The analysis is left as an exercise (R-8.13), but we note\nthat,byusingacollectiontostorethechildrenofeachposition p,wecanimplement\nchildren(p)bysimplyiteratingthatcollection.\nMethod RunningTime\nsize,isEmpty O(1)\nroot,parent,isRoot,isInternal,isExternal O(1)\nnumChildren(p) O(1)\nchildren(p) O(c +1)\np\ndepth(p) O(d +1)\np\nheight O(n)\nTable 8.2: Running times of the accessor methods of an n-node general tree im-\nplemented with a linked structure. We let c denote the number of children of a\np\nposition p,andd itsdepth. ThespaceusageisO(n).\np\nwww.it-ebooks.info\n334 Chapter8. Trees\n8.4 Tree Traversal Algorithms\nAtraversal ofatreeT isasystematic wayofaccessing, or\u201cvisiting,\u201d alltheposi-\ntions of T. The specific action associated with the \u201cvisit\u201d of a position p depends\non the application of this traversal, and could involve anything from increment-\ning a counter to performing some complex computation for p. In this section, we\ndescribe several common traversal schemes for trees, implement them in the con-\ntext of our various tree classes, and discuss several common applications of tree\ntraversals.\n8.4.1 Preorder and Postorder Traversals of General Trees\nIn a preorder traversal of a tree T, the root of T is visited first and then the sub-\ntrees rooted at its children are traversed recursively. If the tree is ordered, then\nthe subtrees are traversed according to the order of the children. The pseudocode\nfor the preorder traversal of the subtree rooted at a position p is shown in Code\nFragment8.12.\nAlgorithmpreorder(p):\nperformthe\u201cvisit\u201dactionforposition p thishappens beforeanyrecursion\n{ }\nforeachchildcinchildren(p)do\npreorder(c) recursively traversethesubtreerootedatc\n{ }\nCodeFragment8.12: Algorithmpreorderforperformingthepreordertraversalofa\nsubtreerootedatposition pofatree.\nFigure 8.13 portrays the order in which positions of a sample tree are visited\nduringanapplication ofthepreordertraversal algorithm.\nPaper\nTitle Abstract \u00a7 1 \u00a7 2 \u00a7 3 References\n\u00a7 1.1 \u00a7 1.2 \u00a7 2.1 \u00a7 2.2 \u00a7 2.3 \u00a7 3.1 \u00a7 3.2\nFigure8.13: Preorder traversal ofanordered tree, wherethechildren ofeachposi-\ntionareorderedfromlefttoright.\nwww.it-ebooks.info\n8.4. TreeTraversalAlgorithms 335\nPostorder Traversal\nAnother important tree traversal algorithm is the postorder traversal. In some\nsense, this algorithm can be viewed as the opposite of the preorder traversal, be-\ncauseitrecursivelytraversesthesubtreesrootedatthechildrenoftherootfirst,and\nthen visits the root (hence, the name \u201cpostorder\u201d). Pseudocode for the postorder\ntraversal is given in Code Fragment 8.13, and an example of a postorder traversal\nisportrayed inFigure8.14.\nAlgorithmpostorder(p):\nforeachchildcinchildren(p)do\npostorder(c) recursively traversethesubtreerootedatc\n{ }\nperformthe\u201cvisit\u201dactionforposition p thishappens afteranyrecursion\n{ }\nCodeFragment8.13: Algorithmpostorderforperformingthepostordertraversalof\nasubtreerootedatposition pofatree.\nPaper\nTitle Abstract \u00a7 1 \u00a7 2 \u00a7 3 References\n\u00a7 1.1 \u00a7 1.2 \u00a7 2.1 \u00a7 2.2 \u00a7 2.3 \u00a7 3.1 \u00a7 3.2\nFigure8.14: Postordertraversal oftheorderedtreeofFigure8.13.\nRunning-Time Analysis\nBothpreorderandpostordertraversalalgorithmsareefficientwaystoaccessallthe\npositions of a tree. The analysis of either of these traversal algorithms is similar\nto that of algorithm height, given in Code Fragment 8.5 of Section 8.1.3. Ateach\nposition p,thenonrecursivepartofthetraversalalgorithmrequirestimeO(c +1),\np\nwherec isthenumberofchildrenof p,undertheassumptionthatthe\u201cvisit\u201ditself\np\ntakes O(1) time. By Proposition 8.4, the overall running time for the traversal of\ntreeT isO(n),wherenisthenumber ofpositions inthetree. Thisrunning timeis\nasymptotically optimalsincethetraversal mustvisitallnpositions ofthetree.\nwww.it-ebooks.info\n336 Chapter8. Trees\n8.4.2 Breadth-First Tree Traversal\nAlthough the preorder and postorder traversals are common ways of visiting the\npositions of a tree, another approach is to traverse a tree so that we visit all the\npositions atdepthd beforewevisitthepositions atdepthd+1. Suchanalgorithm\nisknownasabreadth-firsttraversal.\nA breadth-first traversal is a common approach used in software for playing\ngames. A game tree represents the possible choices of moves that might be made\nby aplayer (or computer) during agame, withthe root ofthe tree being the initial\nconfiguration for the game. For example, Figure 8.15 displays a partial game tree\nforTic-Tac-Toe.\n1\n2 3 4\nX X\nX\nO O XO X O X X X OX X X X X\nX X O O O O\nO O O\n5 6 7 8 9 10 11 12 13 14 15 16\nFigure8.15: Partial gametree for Tic-Tac-Toewhen ignoring symmetries; annota-\ntionsdenotetheorderinwhichpositionsarevisitedinabreadth-firsttreetraversal.\nAbreadth-firsttraversalofsuchagametreeisoftenperformedbecauseacomputer\nmaybeunabletoexploreacompletegametreeinalimitedamountoftime. Sothe\ncomputerwillconsider allmoves,thenresponses tothosemoves,goingasdeepas\ncomputational timeallows.\nPseudocode for a breadth-first traversal is given in Code Fragment 8.14. The\nprocessisnotrecursive, sincewearenottraversingentiresubtreesatonce. Weuse\na queue to produce aFIFO (i.e., first-in first-out) semantics for the order in which\nwevisitnodes. TheoverallrunningtimeisO(n),duetothencallstoenqueueand\nncallstodequeue.\nAlgorithmbreadthfirst():\nInitialize queueQtocontain root()\nwhileQnotemptydo\np = Q.dequeue() pistheoldestentryinthequeue\n{ }\nperformthe\u201cvisit\u201dactionforposition p\nforeachchildcinchildren(p)do\nQ.enqueue(c) add p\u2019schildrentotheendofthequeueforlatervisits\n{ }\nCodeFragment8.14: Algorithm forperforming abreadth-first traversal ofatree.\nwww.it-ebooks.info\n8.4. TreeTraversalAlgorithms 337\n8.4.3 Inorder Traversal of a Binary Tree\nThe standard preorder, postorder, and breadth-first traversals that were introduced\nfor general trees can be directly applied to binary trees. In this section, we will\nintroduce anothercommontraversal algorithm specifically forabinarytree.\nDuring an inorder traversal, we visit a position between the recursive traver-\nsals of its left and right subtrees. The inorder traversal of a binary tree T can be\ninformally viewedasvisiting thenodesofT \u201cfromlefttoright.\u201d Indeed, forevery\nposition p, the inorder traversal visits pafter allthepositions inthe leftsubtree of\npandbefore allthepositions intheright subtree of p. Pseudocode fortheinorder\ntraversal algorithm is given in Code Fragment 8.15, and an example of an inorder\ntraversal isportrayed inFigure8.16.\nAlgorithminorder(p):\nif phasaleftchildlcthen\ninorder(lc) recursively traversetheleftsubtreeof p\n{ }\nperformthe\u201cvisit\u201dactionforposition p\nif phasarightchildrcthen\ninorder(rc) recursively traverse therightsubtreeof p\n{ }\nCode Fragment 8.15: Algorithm inorder for performing an inorder traversal of a\nsubtreerootedatposition pofabinarytree.\n\u2212\n/ +\n\u00d7 + \u00d7 6\n+ \u2212 \u2212\n3 2 3\n3 1 9 5 7 4\nFigure8.16: Inordertraversalofabinarytree.\nTheinordertraversalalgorithmhasseveralimportantapplications. Whenusing\na binary tree to represent an arithmetic expression, as in Figure 8.16, the inorder\ntraversal visits positions in a consistent order with the standard representation of\ntheexpression, asin3+1 3/9 5+2...(albeitwithoutparentheses).\n\u00d7 \u2212\nwww.it-ebooks.info\n338 Chapter8. Trees\nBinary Search Trees\nAnimportantapplicationoftheinordertraversalalgorithmariseswhenwestorean\norderedsequenceofelementsinabinarytree,definingastructurewecallabinary\nsearch tree. Let S be a set whose unique elements have an order relation. For\nexample, Scould beaset ofintegers. Abinary search tree forS isaproper binary\ntreeT suchthat,foreachinternalposition pofT:\nPosition pstoresanelementofS,denoted ase(p).\n\u2022\nElementsstoredintheleftsubtree of p(ifany)arelessthane(p).\n\u2022\nElementsstoredintherightsubtreeof p(ifany)aregreaterthane(p).\n\u2022\nAnexample of abinary search tree isshown inFigure 8.17. Theabove properties\nassure that an inorder traversal of a binary search tree T visits the elements in\nnondecreasing order.\n58\n31 90\n25 42 62\n12 36 75\nFigure8.17: Abinarysearchtreestoringintegers. Thesolidpathistraversed when\nsearching (successfully) for 42. The dashed path is traversed when searching (un-\nsuccessfully) for70.\nWecanuseabinarysearchtreeT forsetStofindwhetheragivensearchvalue\nvisinS,bytraversing apathdownthetreeT,starting attheroot. Ateachinternal\nposition pencountered,wecompareoursearchvaluevwiththeelemente(p)stored\nat p. Ifv<e(p),thenthesearchcontinuesintheleftsubtreeof p. Ifv=e(p),then\nthe search terminates successfully. If v > e(p), then the search continues in the\nrightsubtree of p. Finally, ifwereachaleaf,thesearchterminates unsuccessfully.\nInother words, abinary search treecanbeviewedasabinary decision tree(recall\nExample 8.5), where the question asked at each internal node is whether the ele-\nment at that node is less than, equal to, or larger than the element being searched\nfor. Weillustrateseveralexamplesofthesearchoperation inFigure8.17.\nNotethattherunningtimeofsearchinginabinarysearchtreeT isproportional\ntotheheightofT. RecallfromProposition8.7thattheheightofabinarytreewith\nnnodes canbe assmallas log(n+1) 1 oraslarge asn 1. Thus, binary search\n\u2212 \u2212\ntrees are most efficient when they have small height. Chapter 11 is devoted to the\nstudyofsearchtrees.\nwww.it-ebooks.info\n8.4. TreeTraversalAlgorithms 339\n8.4.4 Implementing Tree Traversals in Java\nWhenfirstdefiningthetreeADTinSection8.1.2,westatedthattreeT mustinclude\nthefollowingsupporting methods:\niterator(): Returnsaniteratorforallelementsinthetree.\npositions(): Returnsaniterablecollection ofallpositions ofthetree.\nAt that time, we did not make any assumption about the order in which these\niterations report their results. In this section, we will demonstrate how any of the\ntreetraversalalgorithmswehaveintroducedcanbeusedtoproducetheseiterations\nas concrete implementations within the AbstractTree or AbstractBinaryTreebase\nclasses.\nFirst, wenote that an iteration of all elements of a tree can easily be produced\nif we have an iteration of all positions of that tree. Code Fragment 8.16 provides\nan implementation of the iterator() method by adapting an iteration produced by\nthe positions() method. In fact, this is the identical approach we used in Code\nFragment7.14ofSection7.4.2fortheLinkedPositionalListclass.\n1 //----------------nested ElementIterator class ----------------\n2 /\u2217 This class adapts the iteration produced by positions() to return elements. \u2217/\n3 private class ElementIterator implements Iterator<E>\n{\n4 Iterator<Position<E>> posIterator = positions().iterator();\n5 public boolean hasNext() return posIterator.hasNext();\n{ }\n6 public E next() return posIterator.next().getElement(); // return element!\n{ }\n7 public void remove() posIterator.remove();\n{ }\n8\n}\n9\n10 /\u2217\u2217 Returns an iterator of the elements stored in the tree. \u2217/\n11 public Iterator<E> iterator() return new ElementIterator();\n{ }\nCodeFragment8.16:IteratingallelementsofanAbstractTreeinstance,basedupon\naniterationofthepositions ofthetree.\nToimplement thepositions()method, wehave achoice oftree traversal algo-\nrithms. Giventhatthereareadvantagestoeachofthosetraversalorders,weprovide\npublicimplementations ofeachstrategythatcanbecalleddirectlybyauserofour\nclass. We can then trivially adapt one of those as a default order for the positions\nmethodoftheAbstractTreeclass. Forexample, onthefollowingpagewewillde-\nfineapublic method, preorder(), thatreturns an iteration ofthe positions ofatree\ninpreorder; CodeFragment8.17demonstrates howthepositions()methodcanbe\ntriviallydefinedtorelyonthatorder.\npublic Iterable<Position<E>> positions() return preorder();\n{ }\nCode Fragment 8.17: Defining preorder as the default traversal algorithm for the\npublicpositionsmethodofanabstracttree.\nwww.it-ebooks.info\n340 Chapter8. Trees\nPreorder Traversals\nWebeginbyconsideringthepreordertraversalalgorithm. Ourgoalistoprovidea\npublic methodpreorder(),aspartoftheAbstractTreeclass, whichreturns aniter-\nable container ofthe positions ofthetree inpreorder. Foreaseof implementation,\nwe choose to produce a snapshot iterator, as defined in Section 7.4.2, returning\na list of all positions. (Exercise C-8.47 explores the goal of implementing a lazy\niterator thatreportspositions inpreorder.)\nWebegin by defining aprivate utility method, preorderSubtree,given inCode\nFragment 8.18, which allows us to parameterize the recursive process with a spe-\ncific position of the tree that serves as the root of a subtree to traverse. (We also\npass a list as a parameter that serves as a buffer to which \u201cvisited\u201d positions are\nadded.)\n1 /\u2217\u2217 Adds positions of the subtree rooted at Position p to the given snapshot. \u2217/\n2 private void preorderSubtree(Position<E> p, List<Position<E>> snapshot)\n{\n3 snapshot.add(p); // for preorder, we add position p before exploring subtrees\n4 for (Position<E> c : children(p))\n5 preorderSubtree(c, snapshot);\n6\n}\nCodeFragment8.18: Arecursive subroutine forperforming apreorder traversal of\nthe subtree rooted at position p of atree. This code should be included within the\nbodyoftheAbstractTreeclass.\nThe preorderSubtree method follows the high-level algorithm originally de-\nscribed as pseudocode in Code Fragment 8.12. It has an implicit base case, as the\nforloopbodyneverexecutesifapositionhasnochildren.\nThe public preorder method, shown in Code Fragment 8.19, has the respon-\nsibility of creating an empty list for the snapshot buffer, and invoking the recur-\nsive method at the root of the tree (assuming the tree is nonempty). We rely on a\njava.util.ArrayListinstance asanIterableinstance forthesnapshot buffer.\n1 /\u2217\u2217 Returns an iterable collection of positions of the tree, reported in preorder. \u2217/\n2 public Iterable<Position<E>> preorder()\n{\n3 List<Position<E>> snapshot = new ArrayList<>();\n4 if (!isEmpty())\n5 preorderSubtree(root(), snapshot); // fill the snapshot recursively\n6 return snapshot;\n7\n}\nCodeFragment8.19:Apublicmethodthatperformsapreordertraversalofanentire\ntree. ThiscodeshouldbeincludedwithinthebodyoftheAbstractTreeclass.\nwww.it-ebooks.info\n8.4. TreeTraversalAlgorithms 341\nPostorder Traversal\nWe implement a postorder traversal using a similar design as we used for a pre-\norder traversal. The only difference is that a \u201cvisited\u201d position is not added to a\npostorder snapshot until after all of its subtrees have been traversed. Both the re-\ncursiveutilityandthetop-level publicmethodaregiveninCodeFragment8.20.\n1 /\u2217\u2217 Adds positions of the subtree rooted at Position p to the given snapshot. \u2217/\n2 private void postorderSubtree(Position<E> p, List<Position<E>> snapshot)\n{\n3 for (Position<E> c : children(p))\n4 postorderSubtree(c, snapshot);\n5 snapshot.add(p); // for postorder, we add position p after exploring subtrees\n6\n}\n7 /\u2217\u2217 Returns an iterable collection of positions of the tree, reported in postorder. \u2217/\n8 public Iterable<Position<E>> postorder()\n{\n9 List<Position<E>> snapshot = new ArrayList<>();\n10 if (!isEmpty())\n11 postorderSubtree(root(), snapshot); // fill the snapshot recursively\n12 return snapshot;\n13\n}\nCode Fragment8.20: Support for performing a postorder traversal of a tree. This\ncodeshould beincluded withinthebodyoftheAbstractTreeclass.\nBreadth-First Traversal\nOn the following page, we will provide an implementation of the breadth-first\ntraversalalgorithm inthecontextofourAbstractTreeclass(CodeFragment8.21).\nRecallthatthebreadth-first traversalalgorithm isnotrecursive;itreliesonaqueue\nof positions to manage the traversal process. We will use the LinkedQueue class\nfromSection6.2.3,although anyimplementation ofthequeueADTwouldsuffice.\nInorder Traversal for Binary Trees\nThepreorder, postorder, and breadth-first traversal algorithms are applicable toall\ntrees. The inorder traversal algorithm, because it explicitly relies on the notion of\na left and right child of a node, only applies to binary trees. We therefore include\nits definition within the body of the AbstractBinaryTree class. We use a similar\ndesign to our preorder and postorder traversals, with a private recursive utility for\ntraversing subtrees. (SeeCodeFragment8.22.)\nFormanyapplicationsofbinarytrees(forexample,seeChapter11),aninorder\ntraversal is the most natural order. Therefore, Code Fragment 8.22 makes it the\ndefault for the AbstractBinaryTree class by overriding the positions method that\nwasinheritedfromtheAbstractTreeclass. Becausetheiterator()methodrelieson\npositions(),itwillalsouseinorderwhenreporting theelementsofabinarytree.\nwww.it-ebooks.info\n342 Chapter8. Trees\n1 /\u2217\u2217 Returns an iterable collection of positions of the tree in breadth-first order. \u2217/\n2 public Iterable<Position<E>> breadthfirst()\n{\n3 List<Position<E>> snapshot = new ArrayList<>();\n4 if (!isEmpty())\n{\n5 Queue<Position<E>> fringe = new LinkedQueue<>();\n6 fringe.enqueue(root()); // start with the root\n7 while (!fringe.isEmpty())\n{\n8 Position<E> p = fringe.dequeue(); // remove from front of the queue\n9 snapshot.add(p); // report this position\n10 for (Position<E> c : children(p))\n11 fringe.enqueue(c); // add children to back of queue\n12\n}\n13\n}\n14 return snapshot;\n15\n}\nCodeFragment8.21: Animplementation ofabreadth-first traversal ofatree. This\ncodeshould beincluded withinthebodyoftheAbstractTreeclass.\n1 /\u2217\u2217 Adds positions of the subtree rooted at Position p to the given snapshot. \u2217/\n2 private void inorderSubtree(Position<E> p, List<Position<E>> snapshot)\n{\n3 if (left(p) != null)\n4 inorderSubtree(left(p), snapshot);\n5 snapshot.add(p);\n6 if (right(p) != null)\n7 inorderSubtree(right(p), snapshot);\n8\n9 } /\u2217\u2217 Returns an iterable collection of positions of the tree, reported in inorder. \u2217/\n10 public Iterable<Position<E>> inorder()\n{\n11 List<Position<E>> snapshot = new ArrayList<>();\n12 if (!isEmpty())\n13 inorderSubtree(root(), snapshot); // fill the snapshot recursively\n14 return snapshot;\n15\n16 } /\u2217\u2217 Overrides positions to make inorder the default order for binary trees. \u2217/\n17 public Iterable<Position<E>> positions()\n{\n18 return inorder();\n19\n}\nCodeFragment8.22: Support for performing an inorder traversal of a binary tree,\nandformakingthatorderthedefaulttraversalforbinarytrees. Thiscodeshouldbe\nincluded withinthebodyoftheAbstractBinaryTreeclass.\nwww.it-ebooks.info\n8.4. TreeTraversalAlgorithms 343\n8.4.5 Applications of Tree Traversals\nInthissection,wedemonstrateseveralrepresentativeapplicationsoftreetraversals,\nincluding somecustomizations ofthestandard traversal algorithms.\nTable of Contents\nWhenusingatreetorepresent thehierarchical structure ofadocument, apreorder\ntraversalofthetreecanbeusedtoproduceatableofcontentsforthedocument. For\nexample,thetableofcontentsassociatedwiththetreefromFigure8.13isdisplayed\ninFigure8.18. Part(a)ofthatfiguregivesasimplepresentation withoneelement\nperline;part(b)showsamoreattractive presentation, produced byindenting each\nelementbasedonitsdepthwithinthetree.\nPaper Paper\nTitle Title\nAbstract Abstract\n\u00a71 \u00a71\n\u00a71.1 \u00a71.1\n\u00a71.2 \u00a71.2\n\u00a72 \u00a72\n\u00a72.1 \u00a72.1\n... ...\n(a) (b)\nFigure8.18:TableofcontentsforadocumentrepresentedbythetreeinFigure8.13:\n(a)withoutindentation; (b)withindentation basedondepthwithinthetree.\nThe unindented version of the table of contents can be produced with the fol-\nlowingcode,givenatreeTsupporting thepreorder()method:\nfor (Position<E> p : T.preorder())\nSystem.out.println(p.getElement());\nTo produce the presentation of Figure 8.18(b), we indent each element with\na number of spaces equal to twice the element\u2019s depth in the tree (hence, the\nroot element was unindented). If we assume that method, spaces(n), produces a\nstring ofnspaces, wecould replace thebody ofthe aboveloop withthe statement\nSystem.out.println(spaces(2\u2217T.depth(p)) + p.getElement()). Unfortunately, al-\nthough the work to produce the preorder traversal runs in O(n) time, based on the\nanalysis of Section 8.4.1, the calls to depth incur a hidden cost. Making a call to\ndepth from every position of the tree results in O(n2) worst-case time, as noted\nwhenanalyzing thealgorithm heightBadinSection8.1.3.\nwww.it-ebooks.info\n344 Chapter8. Trees\nApreferred approach toproducing anindented table ofcontents istoredesign\na top-down recursion that includes the current depth as an additional parameter.\nSuchan implementation isprovided in CodeFragment 8.23. Thisimplementation\nruns in worst-case O(n) time (except, technically, the time it takes to print strings\nofincreasing lengths).\n1 /\u2217\u2217 Prints preorder representation of subtree of T rooted at p having depth d. \u2217/\n2 public static <E> void printPreorderIndent(Tree<E> T, Position<E> p, int d)\n3 System.out.println(spaces(2\u2217d) + p.getElement()); // indent based on d {\n4 for (Position<E> c : T.children(p))\n5 printPreorderIndent(T, c, d+1); // child depth is d+1\n6\n}\nCode Fragment 8.23: Efficient recursion for printing indented version of a pre-\nordertraversal. Toprint anentire treeT,therecursion should bestarted withform\nprintPreorderIndent(T, T.root(), 0).\nIn the example of Figure 8.18, we were fortunate in that the numbering was\nembedded within the elements ofthe tree. More generally, wemight be interested\ninusingapreorder traversal todisplay thestructure ofatree, withindentation and\nalso explicit numbering that was not present in the tree. For example, we might\ndisplaythetreefromFigure8.2beginning as:\nElectronics R\u2019Us\n1 R&D\n2 Sales\n2.1 Domestic\n2.2 International\n2.2.1 Canada\n2.2.2 S. America\nThis is more challenging, because the numbers used as labels are implicit in\nthe structure of the tree. A label depends on the path from the root to the current\nposition. Toaccomplish our goal, weadd an additional parameter to the recursive\nsignature. We send a list of integers representing the labels leading to a particular\nposition. For example, when visiting the node Domestic above, we will send the\nlistofvalues 2,1 thatcompriseitslabel.\n{ }\nAt the implementation level, we wish to avoid the inefficiency of duplicating\nsuchlistswhensendinganewparameterfromoneleveloftherecursiontothenext.\nA standard solution is to pass the same list instance throughout the recursion. At\none level of the recursion, a new entry is temporarily added to the end of the list\nbefore making further recursive calls. In order to \u201cleave no trace,\u201d the extraneous\nentry must later be removed from the list by the same recursive call that added it.\nAnimplementation basedonthisapproach isgiveninCodeFragment8.24.\nwww.it-ebooks.info\n8.4. TreeTraversalAlgorithms 345\n1 /\u2217\u2217 Prints labeled representation of subtree of T rooted at p having depth d. \u2217/\n2 public static <E>\n3 void printPreorderLabeled(Tree<E> T, Position<E> p, ArrayList<Integer> path)\n{\n4 int d = path.size(); // depth equals the length of the path\n5 System.out.print(spaces(2\u2217d)); // print indentation, then label\n6 for (int j=0; j < d; j++) System.out.print(path.get(j) + (j == d 1 ? \" \" : \".\"));\n\u2212\n7 System.out.println(p.getElement());\n8 path.add(1); // add path entry for first child\n9 for (Position<E> c : T.children(p))\n{\n10 printPreorderLabeled(T, c, path);\n11 path.set(d, 1 + path.get(d)); // increment last entry of path\n12\n}\n13 path.remove(d); // restore path to its incoming state\n14\n}\nCodeFragment8.24: Efficient recursion for printing an indented and labeled pre-\nsentation ofapreordertraversal.\nComputing Disk Space\nInExample8.1, weconsidered the useofatreeasamodel forafile-system struc-\nture, with internal positions representing directories and leaves representing files.\nIn fact, when introducing the use of recursion back in Chapter 5, we specifically\nexaminedthetopicoffilesystems(seeSection5.1.4). Althoughwedidnotexplic-\nitly model it as a tree at that time, we gave an implementation of an algorithm for\ncomputing thediskusage(CodeFragment5.5).\nTherecursivecomputationofdiskspaceisemblematicofapostordertraversal,\naswecannot effectively compute thetotalspace used byadirectory untilafter we\nknow the space that is used by its children directories. Unfortunately, the formal\nimplementation ofpostorder,asgiveninCodeFragment8.20,doesnotsufficefor\nthispurpose. Wewouldliketohaveamechanismforchildrentoreturninformation\nto the parent as part of the traversal process. A custom solution to the disk space\nproblem,witheachlevelofrecursionprovidingareturnvaluetothe(parent)caller,\nisprovided inCodeFragment8.25.\n1 /\u2217\u2217 Returns total disk space for subtree of T rooted at p. \u2217/\n2 public static int diskSpace(Tree<Integer> T, Position<Integer> p)\n{\n3 int subtotal = p.getElement(); // we assume element represents space usage\n4 for (Position<Integer> c : T.children(p))\n5 subtotal += diskSpace(T, c);\n6 return subtotal;\n7\n}\nCode Fragment8.25: Recursive computation of disk space for a tree. We assume\nthateachtreeelementreportsthelocalspaceusedatthatposition.\nwww.it-ebooks.info\n346 Chapter8. Trees\nParenthetic Representations of a Tree\nItisnotpossible toreconstruct ageneral tree, givenonly the preorder sequence of\nelements,asinFigure8.18a. Someadditionalcontextisnecessaryforthestructure\nof the tree to be welldefined. The use of indentation or numbered labels provides\nsuch context, with a very human-friendly presentation. However, there are more\nconcisestringrepresentations oftreesthatarecomputer-friendly.\nIn this section, we explore one such representation. The parenthetic string\nrepresentation P(T) of tree T is recursively defined. If T consists of a single\nposition p,thenP(T)= p.getElement(). Otherwise,itisdefinedrecursively as,\nP(T)= p.getElement()+\"(\"+P(T )+\", \"+ +\", \"+P(T )+\")\"\n1 k\n\u00b7\u00b7\u00b7\nwhere p is the root of T and T ,T ,...,T are the subtrees rooted at the children\n1 2 k\nof p, which are given in order if T is an ordered tree. We are using \u201c+\u201d here to\ndenote string concatenation. As an example, the parenthetic representation of the\ntreeofFigure8.2wouldappearasfollows(linebreaksarecosmetic):\nElectronics R\u2019Us (R&D, Sales (Domestic, International (Canada,\nS. America, Overseas (Africa, Europe, Asia, Australia))),\nPurchasing, Manufacturing (TV, CD, Tuner))\nAlthough the parenthetic representation is essentially a preorder traversal, we\ncannot easily produce the additional punctuation using the formal implementation\nof preorder. The opening parenthesis must be produced just before the loop over\na position\u2019s children, the separating commas between children, and the closing\nparenthesis just after the loop completes. The Java method parenthesize, shown\nin Code Fragment 8.26, is a custom traversal that prints such a parenthetic string\nrepresentation ofatreeT.\n1 /\u2217\u2217 Prints parenthesized representation of subtree of T rooted at p. \u2217/\n2 public static <E> void parenthesize(Tree<E> T, Position<E> p)\n{\n3 System.out.print(p.getElement());\n4 if (T.isInternal(p))\n{\n5 boolean firstTime = true;\n6 for (Position<E> c : T.children(p))\n{\n7 System.out.print( (firstTime ? \" (\" : \", \") ); // determine proper punctuation\n8 firstTime = false; // any future passes will get comma\n9 parenthesize(T, c); // recur on child\n10\n}\n11 System.out.print(\")\");\n12\n}\n13\n}\nCodeFragment8.26: Methodthatprintsparenthetic stringrepresentation ofatree.\nwww.it-ebooks.info\n8.4. TreeTraversalAlgorithms 347\nUsing Inorder Traversal for Tree Drawing\nAninordertraversalcanbeappliedtotheproblemofcomputingagraphicallayout\nof a binary tree, as shown in Figure 8.19. We assume the convention, common\nto computer graphics, that x-coordinates increase left to right and y-coordinates\nincreasetoptobottom,sothattheoriginisintheupperleftcornerofthedrawing.\n0 1 2 3 4 5 6 7 8 9 10 11 12\n0\n1\n2\n3\n4\nFigure8.19: Aninorderdrawingofabinarytree.\nThe geometry is determined by an algorithm that assigns x- and y-coordinates\ntoeachposition pofabinarytreeT usingthefollowingtworules:\nx(p)isthenumberofpositions visitedbefore pinaninordertraversal ofT.\n\u2022\ny(p)isthedepthof pinT.\n\u2022\nCode Fragment 8.27 provides an implementation of a recursive method that\nassignsx-andy-coordinatestopositionsofatreeinthismanner. Depthinformation\nispassedfromoneleveloftherecursion toanother, asdoneinourearlierexample\nforindentation. Tomaintain anaccurate value forthex-coordinate asthetraversal\nproceeds, themethodmustbeprovided withthevalueofxthatshould beassigned\ntotheleftmostnodeofthecurrentsubtree,anditmustreturntoitsparentarevised\nvalueofxthatisappropriate forthefirstnodedrawntotherightofthesubtree.\n1 public static <E> int layout(BinaryTree<E> T, Position<E> p, int d, int x)\n{\n2 if (T.left(p) != null)\n3 x = layout(T, T.left(p), d+1, x); // resulting x will be increased\n4 p.getElement().setX(x++); // post-increment x\n5 p.getElement().setY(d);\n6 if (T.right(p) != null)\n7 x = layout(T, T.right(p), d+1, x); // resulting x will be increased\n8 return x;\n9\n}\nCodeFragment8.27:Recursivemethodforcomputingcoordinatesatwhichtodraw\npositions of a binary tree. We assume that the element type for the tree supports\nsetXandsetYmethods. Theinitialcallshouldbelayout(T, T.root(), 0, 0).\nwww.it-ebooks.info\n348 Chapter8. Trees\n8.4.6 Euler Tours\nThevariousapplications described inSection8.4.5demonstratethegreatpowerof\nrecursivetreetraversals,buttheyalsoshowthatnoteveryapplicationstrictlyfitsthe\nmold of apreorder, postorder, or inorder traversal. Wecan unify the tree-traversal\nalgorithms into a single framework known as an Euler tour traversal. The Euler\ntour traversal of a tree T can be informally defined as a \u201cwalk\u201d around T, where\nwestartbygoingfromtheroottowarditsleftmostchild,viewingtheedgesofT as\nbeing\u201cwalls\u201dthatwealwayskeeptoourleft. (SeeFigure8.20.)\n\u2212\n/ +\n\u00d7 + \u00d7 6\n+ \u2212 \u2212\n3 2 3\n3 1 9 5 7 4\nFigure8.20: Eulertourtraversalofatree.\nThe complexity of the walk is O(n), for a tree with n nodes, because it pro-\ngresses exactly two times along each of the n 1 edges of the tree\u2014once going\n\u2212\ndownward along the edge, and later going upward along the edge. To unify the\nconcept of preorder and postorder traversals, wecan view there being twonotable\n\u201cvisits\u201dtoeachposition p:\nA \u201cpre visit\u201d occurs when first reaching the position, that is, when the walk\n\u2022\npassesimmediately leftofthenodeinourvisualization.\nA\u201cpostvisit\u201doccurswhenthewalklaterproceedsupwardfromthatposition,\n\u2022\nthatis,whenthewalkpassestotherightofthenodeinourvisualization.\nThe process ofan Euler tour can be naturally viewed as recursive. In between\nthe \u201cpre visit\u201d and \u201cpost visit\u201d of a given position will be a recursive tour of each\nofitssubtrees. LookingatFigure8.20asanexample,thereisacontiguousportion\noftheentiretourthatisitselfanEulertourofthesubtreeofthenodewithelement\n\u201c/\u201d. Thattour contains twocontiguous subtours, onetraversing that position\u2019s left\nsubtreeandanother traversing therightsubtree.\nIn the special case of a binary tree, we can designate the time when the walk\npasses immediately below a node as an \u201cin visit\u201d event. This will be just after the\ntourofitsleftsubtree(ifany),butbeforethetourofitsrightsubtree(ifany).\nwww.it-ebooks.info\n8.4. TreeTraversalAlgorithms 349\nThepseudocodeforanEulertourtraversalofasubtreerootedataposition pis\nshowninCodeFragment8.28.\nAlgorithmeulerTour(T, p):\nperformthe\u201cprevisit\u201dactionforposition p\nforeachchildcinT.children(p)do\neulerTour(T,c) recursively tourthesubtreerootedatc\n{ }\nperformthe\u201cpostvisit\u201dactionforposition p\nCodeFragment8.28: AlgorithmeulerTourforperforminganEulertourtraversalof\nasubtreerootedatposition pofatree.\nTheEulertourtraversalextendsthepreorderandpostordertraversals,butitcan\nalso perform other kinds of traversals. Forexample, suppose wewish to compute\nthenumberofdescendants ofeachposition pinann-nodebinarytree. Westartan\nEulertourbyinitializing acounter to0,and thenincrement thecounter during the\n\u201cpre visit\u201d for each position. To determine the number of descendants of a posi-\ntion p,wecomputethedifferencebetweenthevaluesofthecounterfromwhenthe\npre-visit occursandwhenthepost-visit occurs, andadd1(for p). Thissimplerule\ngives us the number of descendants of p, because each node in the subtree rooted\nat piscountedbetween p\u2019svisitontheleftand p\u2019svisitontheright. Therefore,we\nhaveanO(n)-timemethodforcomputingthenumberofdescendants ofeachnode.\nFor the case of a binary tree, we can customize the algorithm to include an\nexplicit\u201cinvisit\u201daction,asshowninCodeFragment8.29.\nAlgorithmeulerTourBinary(T, p):\nperformthe\u201cprevisit\u201dactionforposition p\nif phasaleftchildlcthen\neulerTourBinary(T,lc) recursively tourtheleftsubtreeof p\n{ }\nperformthe\u201cinvisit\u201dactionforposition p\nif phasarightchildrcthen\neulerTourBinary(T,rc) recursively tourtherightsubtreeof p\n{ }\nperformthe\u201cpostvisit\u201dactionforposition p\nCode Fragment 8.29: Algorithm eulerTourBinary for performing an Euler tour\ntraversal ofasubtreerootedatposition pofabinarytree.\nForexample, abinary Eulertourcanproduce atraditional parenthesized arith-\nmetic expression, such as \"((((3+1)x3)/((9-5)+2))-((3x(7-4))+6))\" for\nthetreeinFigure8.20,asfollows:\n\u201cPrevisit\u201daction: iftheposition isinternal, print\u201c(\u201d.\n\u2022\n\u201cInvisit\u201daction: printthevalueoroperatorstoredattheposition.\n\u2022\n\u201cPostvisit\u201daction: iftheposition isinternal, print\u201c)\u201d.\n\u2022\nwww.it-ebooks.info\n350 Chapter8. Trees\n8.5 Exercises\nReinforcement\nR-8.1 ThefollowingquestionsrefertothetreeofFigure8.3.\na. Whichnodeistheroot?\nb. Whataretheinternalnodes?\nc. Howmanydescendantsdoesnodecs016/have?\nd. Howmanyancestorsdoesnodecs016/have?\ne. Whatarethesiblingsofnodehomeworks/?\nf. Whichnodesareinthesubtreerootedatnodeprojects/?\ng. Whatisthedepthofnodepapers/?\nh. Whatistheheightofthetree?\nR-8.2 Showatreeachievingtheworst-caserunningtimeforalgorithmdepth.\nR-8.3 GiveajustificationofProposition8.3.\nR-8.4 What is the running time of a call to T.height(p) when called on a position p\ndistinctfromtherootoftreeT? (SeeCodeFragment8.5.)\nR-8.5 Describeanalgorithm,relyingonlyontheBinaryTreeoperations,thatcountsthe\nnumberofleavesinabinarytreethataretheleftchildoftheirrespectiveparent.\nR-8.6 LetT beann-nodebinarytreethatmaybeimproper. Describehowtorepresent\nT bymeansofaproperbinarytreeT\u2032withO(n)nodes.\nR-8.7 Whataretheminimumandmaximumnumberofinternalandexternalnodesin\nanimproperbinarytreewithnnodes?\nR-8.8 AnswerthefollowingquestionssoastojustifyProposition8.7.\na. What is the minimum number of external nodes for a proper binary tree\nwithheighth? Justifyyouranswer.\nb. What is the maximum number of externalnodes for a properbinary tree\nwithheighth? Justifyyouranswer.\nc. LetT beaproperbinarytreewithheighthandnnodes.Showthat\nlog(n+1) 1 h (n 1)/2.\n\u2212 \u2264 \u2264 \u2212\nd. Forwhichvaluesofnandhcantheabovelowerandupperboundsonhbe\nattainedwithequality?\nR-8.9 GiveaproofbyinductionofProposition8.8.\nR-8.10 Find the value of the arithmetic expression associated with each subtree of the\nbinarytreeofFigure8.6.\nR-8.11 Drawanarithmeticexpressiontreethathasfourexternalnodes,storingthenum-\nbers1,5, 6,and7(witheachnumberstoredinadistinctexternalnode,butnot\nnecessarilyinthisorder),andhasthreeinternalnodes,eachstoringanoperator\nfromtheset +, , ,/ ,sothatthevalueoftherootis21. Theoperatorsmay\n{ \u2212 \u2217 }\nreturnandactonfractions,andanoperatormaybeusedmorethanonce.\nwww.it-ebooks.info\n8.5. Exercises 351\nR-8.12 Drawthebinarytreerepresentationofthefollowingarithmeticexpression:\n\u201c(((5+2) (2 1))/((2+9)+((7 2) 1)) 8)\u201d.\n\u2217 \u2212 \u2212 \u2212 \u2217\nR-8.13 JustifyTable8.2,summarizingtherunningtimeofthemethodsofatreerepre-\nsentedwithalinkedstructure,byproviding,foreachmethod,adescriptionofits\nimplementation,andananalysisofitsrunningtime.\nR-8.14 LetT beabinarytreewithnnodes,andlet f()bethelevelnumberingfunction\nofthepositionsofT,asgiveninSection8.3.2.\na. Showthat,foreveryposition pofT, f(p) 2n 2.\n\u2264 \u2212\nb. Showanexampleofabinarytreewithsevennodesthatattainstheabove\nupperboundon f(p)forsomeposition p.\nR-8.15 Show how to use an Euler tour traversalto computethe level number f(p), as\ndefinedinSection8.3.2,ofeachpositioninabinarytreeT.\nR-8.16 LetT beabinarytreewithnpositionsthatisrealizedwithanarrayrepresentation\nA,andlet f()bethelevelnumberingfunctionofthepositionsofT,asgivenin\nSection8.3.2.Givepseudocodedescriptionsofeachofthemethodsroot,parent,\nleft,right,isExternal,andisRoot.\nR-8.17 Ourdefinitionofthelevelnumberingfunction f(p),asgiveninSection8.3.2,be-\nginswiththeroothavingnumber0. Somepeopleprefertousealevelnumbering\ng(p)inwhichtherootisassignednumber1,becauseitsimplifiesthearithmetic\nforfindingneighboringpositions. RedoExerciseR-8.16,butassumingthatwe\nusealevelnumberingg(p)inwhichtherootisassignednumber1.\nR-8.18 InwhatorderarepositionsvisitedduringapreordertraversalofthetreeofFig-\nure8.6?\nR-8.19 In what order are positions visited during a postorder traversal of the tree of\nFigure8.6?\nR-8.20 LetT beanorderedtreewithmorethanonenode.Isitpossiblethatthepreorder\ntraversalofT visitsthenodesinthesameorderasthepostordertraversalofT?\nIfso,giveanexample;otherwise,explainwhythiscannotoccur. Likewise,isit\npossible that the preordertraversalof T visits the nodesin the reverseorderof\nthepostordertraversalofT? Ifso,giveanexample;otherwise,explainwhythis\ncannotoccur.\nR-8.21 Answer the previousquestion for the case when T is a proper binarytree with\nmorethanonenode.\nR-8.22 DrawabinarytreeT thatsimultaneouslysatisfiesthefollowing:\nEachinternalnodeofT storesasinglecharacter.\n\u2022\nApreordertraversalofT yieldsEXAMFUN.\n\u2022\nAninordertraversalofT yieldsMAFXUEN.\n\u2022\nR-8.23 Considertheexampleofabreadth-firsttraversalgiveninFigure8.15. Usingthe\nannotated numbers from that figure, describe the contents of the queue before\neachpassofthewhileloopinCodeFragment8.14.Togetstarted,thequeuehas\ncontents 1 beforethefirstpass,andcontents 2,3,4 beforethesecondpass.\n{ } { }\nwww.it-ebooks.info\n352 Chapter8. Trees\nR-8.24 Givetheoutputofthemethodparenthesize(T, T.root()),asdescribedinCode\nFragment8.26,whenT isthetreeofFigure8.6.\nR-8.25 Describeamodificationtoparenthesize,fromCodeFragment8.26,thatrelieson\nthelength()methodfortheStringclasstooutputtheparentheticrepresentation\nof a tree with line breaks added to display the tree in a text window that is 80\ncharacterswide.\nR-8.26 Whatistherunningtime ofparenthesize(T, T.root()), asgiveninCodeFrag-\nment8.26,foratreeT withnnodes?\nCreativity\nC-8.27 Describe an efficient algorithm for convertinga fully balanced string of paren-\ntheses into an equivalenttree. The tree associated with such a stringis defined\nrecursively. The outermost pair of balanced parentheses is associated with the\nroot and each substring inside this pair, defined by the substring between two\nbalancedparentheses,isassociatedwithasubtreeofthisroot.\nC-8.28 ThepathlengthofatreeT isthesumofthedepthsofallpositionsinT.Describe\nalinear-timemethodforcomputingthepathlengthofatreeT.\nC-8.29 Definetheinternalpathlength,I(T),ofatreeT tobethesumofthedepthsof\nalltheinternalpositionsinT. Likewise,definetheexternalpathlength,E(T),\nofa treeT tobe thesumofthe depthsofalltheexternalpositionsinT. Show\nthatifT isaproperbinarytreewithnpositions,thenE(T)=I(T)+n 1.\n\u2212\nC-8.30 LetT bea(notnecessarilyproper)binarytreewithnnodes,andletDbethesum\nof the depths of all the external nodes of T. Show that if T has the minimum\nnumber of external nodes possible, then D is O(n) and if T has the maximum\nnumberofexternalnodespossible,thenDisO(nlogn).\nC-8.31 LetT bea(possiblyimproper)binarytreewithnnodes,andletDbethesumof\nthedepthsofalltheexternalnodesofT. DescribeaconfigurationforT suchthat\nDis\u2126(n2). Suchatreewouldbetheworstcasefortheasymptoticrunningtime\nofmethodheightBad(CodeFragment8.4).\nC-8.32 ForatreeT,letn denotethenumberofitsinternalnodes,andletn denotethe\nI E\nnumberofitsexternalnodes. ShowthatifeveryinternalnodeinT hasexactly3\nchildren,thenn =2n +1.\nE I\nC-8.33 Two orderedtrees T\u2032 and T\u2032\u2032 are said to be isomorphic if oneof the following\nholds:\nBothT\u2032andT\u2032\u2032 areempty.\n\u2022 BothT\u2032andT\u2032\u2032 consistofasinglenode\n\u2022 TherootsofT\u2032 andT\u2032\u2032 havethe same numberk 1 ofsubtrees, and the\n\u2022 ith such subtree of T\u2032 is isomorphicto the ith suc \u2265 h subtree of T\u2032\u2032 for i=\n1,...,k.\nDesign an algorithmthattests whethertwo givenorderedtrees are isomorphic.\nWhatistherunningtimeofyouralgorithm?\nwww.it-ebooks.info\n8.5. Exercises 353\nC-8.34 Show that there are more than 2n improper binary trees with n internal nodes\nsuchthatnopairareisomorphic(seeExerciseC-8.33).\nC-8.35 Ifweexcludeisomorphictrees(seeExerciseC-8.33),exactlyhowmanyproper\nbinarytreesexistwithexactly4leaves?\nC-8.36 AddsupportinLinkedBinaryTreeforamethod,pruneSubtree(p),thatremoves\ntheentiresubtreerootedatpositionp,makingsuretomaintainanaccuratecount\nofthesizeofthetree. Whatistherunningtimeofyourimplementation?\nC-8.37 AddsupportinLinkedBinaryTreeforamethod,swap(p,q),thathastheeffectof\nrestructuringthetreesothatthenodereferencedby ptakestheplaceofthenode\nreferencedbyq,andviceversa. Makesuretoproperlyhandlethecasewhenthe\nnodesareadjacent.\nC-8.38 We cansimplifypartsofourLinkedBinaryTreeimplementationifwemakeuse\nofofasinglesentinelnode,suchthatthesentinelistheparentoftherealrootof\nthetree,andtherootisreferencedastheleftchildofthesentinel. Furthermore,\nthesentinelwilltaketheplaceofnullasthevalueoftheleftorrightmemberfor\nanodewithoutsuchachild. Giveanewimplementationoftheupdatemethods\nremoveandattach,assumingsucharepresentation.\nC-8.39 DescribehowtocloneaLinkedBinaryTreeinstancerepresentingaproperbinary\ntree,withuseoftheattachmethod.\nC-8.40 DescribehowtocloneaLinkedBinaryTreeinstancerepresentinga(notnecessar-\nilyproper)binarytree,withuseoftheaddLeftandaddRightmethods.\nC-8.41 ModifytheLinkedBinaryTreeclasstoformallysupporttheCloneableinterface,\nasdescribedinSection3.6.\nC-8.42 Give an efficient algorithm that computes and prints, for every position p of a\ntreeT,theelementof pfollowedbytheheightof p\u2019ssubtree.\nC-8.43 GiveanO(n)-timealgorithmforcomputingthedepthsofallpositionsofa tree\nT,wherenisthenumberofnodesofT.\nC-8.44 The balance factor of an internal position p of a proper binary tree is the dif-\nference between the heights of the right and left subtrees of p. Show how to\nspecializetheEulertourtraversalofSection8.4.6toprintthebalancefactorsof\nalltheinternalnodesofaproperbinarytree.\nC-8.45 DesignalgorithmsforthefollowingoperationsforabinarytreeT:\npreorderNext(p):Returnthepositionvisitedafter pinapreordertraversal\n\u2022\nofT (ornullif pisthelastnodevisited).\ninorderNext(p): Returnthepositionvisitedafter pinaninordertraversal\n\u2022\nofT (ornullif pisthelastnodevisited).\npostorderNext(p):Returnthepositionvisitedafterpinapostordertraver-\n\u2022\nsalofT (ornullif pisthelastnodevisited).\nWhataretheworst-caserunningtimesofyouralgorithms?\nC-8.46 Describe,inpseudocode,anonrecursivemethodforperforminganinordertraver-\nsalofabinarytreeinlineartime.\nwww.it-ebooks.info\n354 Chapter8. Trees\nC-8.47 To implementthe preorder method of the AbstractTree class, we relied on the\nconvenienceofcreatingasnapshot.Reimplementapreordermethodthatcreates\nalazyiterator. (SeeSection7.4.2fordiscussionofiterators.)\nC-8.48 RepeatExerciseC-8.47,implementingthepostordermethodoftheAbstractTree\nclass.\nC-8.49 RepeatExerciseC-8.47,implementingtheAbstractBinaryTree\u2019sinordermethod.\nC-8.50 AlgorithmpreorderDrawdrawsabinarytreeT byassigningx-andy-coordinates\nto each position p such that x(p) is the number of nodes preceding p in the\npreordertraversalofT andy(p)isthedepthof pinT.\na. Show that the drawing of T produced by preorderDraw has no pairs of\ncrossingedges.\nb. RedrawthebinarytreeofFigure8.19usingpreorderDraw.\nC-8.51 Redo the previous problem for the algorithm postorderDraw that is similar to\npreorderDraw except that it assigns x(p) to be the number of nodes preceding\nposition pinthepostordertraversal.\nC-8.52 We can definea binary tree representationT\u2032 foran orderedgeneraltreeT as\nfollows(seeFigure8.21):\nForeachposition pofT,thereisanassociatedposition p\u2032ofT\u2032.\n\u2022 IfpisaleafofT,thenp\u2032inT\u2032doesnothavealeftchild;otherwisetheleft\n\u2022 childof p\u2032isq\u2032,whereqisthefirstchildof pinT.\nIf p has a sibling q orderedimmediatelyafter it in T, then q\u2032 is the right\n\u2022 childof p\u2032inT;otherwise p\u2032doesnothavearightchild.\nGiven such a representationT\u2032 of a generalorderedtreeT, answer each of the\nfollowingquestions:\na. IsapreordertraversalofT\u2032equivalenttoapreordertraversalofT?\nb. IsapostordertraversalofT\u2032equivalenttoapostordertraversalofT?\nc. Is an inorder traversal of T\u2032 equivalent to one of the standard traversals\nofT? Ifso,whichone?\nA A\nB C D B\nE F G E C\nF D\nG\n(a) (b)\nFigure8.21: Representation of a tree with a binary tree: (a) tree T; (b) binary tree\nT\u2032 forT. ThedashededgesconnectnodesofT\u2032 thataresiblings inT.\nwww.it-ebooks.info\n8.5. Exercises 355\nC-8.53 Designanalgorithmfordrawinggeneraltrees,usingastylesimilartotheinorder\ntraversalapproachfordrawingbinarytrees.\nC-8.54 Lettherankofaposition pduringatraversalbedefinedsuchthatthefirstele-\nmentvisited has rank 1, the second elementvisited hasrank 2, and so on. For\neachposition pinatreeT,letpre(p)betherankof pinapreordertraversalof\nT,letpost(p)betherankof pinapostordertraversalofT,letdepth(p)bethe\ndepthof p,andletdesc(p)bethenumberofdescendantsof p,includingpitself.\nDeriveaformuladefiningpost(p)intermsofdesc(p),depth(p),andpre(p),for\neachnodepinT.\nC-8.55 Let T be a tree with n positions. Define the lowest common ancestor (LCA)\nbetweentwopositions pandqasthelowestpositioninT thathasboth pandq\nas descendants(wherewe allowa positionto be a descendantofitself). Given\ntwo positions pandq, describeanefficientalgorithmforfindingtheLCA of p\nandq. Whatistherunningtimeofyouralgorithm?\nC-8.56 Suppose each position p of a binary tree T is labeled with its value f(p) in a\nlevelnumberingofT. Designafastmethodfordetermining f(a)forthelowest\ncommonancestor(LCA),a,oftwopositions pandqinT,given f(p)and f(q).\nYoudonotneedtofindpositiona,justvalue f(a).\nC-8.57 Let T be a binary tree with n positions, and, for any position p in T, let d\np\ndenotethedepthof pinT. Thedistancebetweentwopositions pandqinT is\nd +d 2d , where a is the lowest commonancestor(LCA) of p and q. The\np q a\n\u2212\ndiameter of T is the maximumdistance between two positions in T. Describe\nanefficientalgorithmforfindingthediameterofT. Whatistherunningtimeof\nyouralgorithm?\nC-8.58 TheindentedparentheticrepresentationofatreeT isavariationoftheparen-\nthetic representation of T (see Code Fragment 8.26) that uses indentation and\nlinebreaksasillustratedinFigure8.22. Giveanalgorithmthatprintsthisrepre-\nsentationofatree.\nSales(\nSales Domestic\nInternational(\nCanada\nS.America\nDomestic International\nOverseas(\nAfrica\nEurope\nCanada S. America Overseas Asia\nAustralia\n)\n)\nAfrica Europe Asia Australia\n)\n(a) (b)\nFigure8.22: (a)TreeT;(b)indented parenthetic representation ofT.\nwww.it-ebooks.info\n356 Chapter8. Trees\nC-8.59 As mentioned in Exercise C-6.19, postfix notation is an unambiguous way of\nwriting an arithmetic expression without parentheses. It is defined so that if\n\u201c(exp )op(exp )\u201disanormal(infix)fullyparenthesizedexpressionwithopera-\n1 2\ntionop,thenitspostfixequivalentis\u201cpexp pexp op\u201d,wherepexp isthepostfix\n1 2 1\nversionof exp andpexp is thepostfix versionofexp . Thepostfix versionof\n1 2 2\nasinglenumberorvariableisjustthatnumberorvariable. So,forexample,the\npostfixversionoftheinfixexpression\u201c((5+2) (8 3))/4\u201dis\u201c52+83\n\u2217 \u2212 \u2212\u2217\n4/\u201d. Giveanefficientalgorithmforconvertinganinfixarithmeticexpressionto\nitsequivalentpostfixnotation. (Hint: Firstconverttheinfixexpressionintoits\nequivalentbinarytreerepresentation.)\nC-8.60 LetT beabinarytreewithnpositions.DefineaRomanpositiontobeaposition\np in T, such that the number of descendantsin p\u2019s left subtree differ from the\nnumberofdescendantsin p\u2019srightsubtreebyatmost5. Describealinear-time\nmethodforfindingeachpositionpofT,suchthatpisnotaRomanposition,but\nallof p\u2019sdescendantsareRoman.\nProjects\nP-8.61 Implementthe binary tree ADT using the array-based representationdescribed\ninSection8.3.2.\nP-8.62 Implementthe tree ADT usinga linked structureas describedin Section 8.3.3.\nProvideareasonablesetofupdatemethodsforyourtree.\nP-8.63 ImplementthetreeADTusingthebinarytreerepresentationdescribedinExer-\nciseC-8.52.YoumayadapttheLinkedBinaryTreeimplementation.\nP-8.64 ThememoryusagefortheLinkedBinaryTreeclasscanbestreamlinedbyremov-\ningtheparentreferencefromeachnode,andinsteadimplementingaPositionas\nanobjectthatkeepsa listofnodesrepresentingtheentirepathfromtherootto\nthatposition.ReimplementtheLinkedBinaryTreeclassusingthisstrategy.\nP-8.65 Writeaprogramthattakesasinputafullyparenthesized,arithmeticexpression\nandconvertsittoabinaryexpressiontree. Yourprogramshoulddisplaythetree\ninsomewayandalsoprintthevalueassociatedwiththeroot. Foranadditional\nchallenge, allow the leaves to store variables of the form x , x , x , and so on,\n1 2 3\nwhich are initially 0 and which can be updated interactively by your program,\nwiththecorrespondingupdateintheprintedvalueoftherootoftheexpression\ntree.\nP-8.66 Aslicing floorplandividesarectanglewithhorizontalandverticalsidesusing\nhorizontal and vertical cuts. (See Figure 8.23a.) A slicing floor plan can be\nrepresentedby a properbinary tree, called a slicing tree, whose internalnodes\nrepresentthecuts,andwhoseexternalnodesrepresentthebasicrectanglesinto\nwhichthe floorplan is decomposedbythe cuts. (See Figure8.23b.) Thecom-\npactionproblemforaslicingfloorplanisdefinedasfollows. Assumethateach\nbasicrectangleofaslicingfloorplanisassignedaminimumwidthwandamin-\nimumheighth. Thecompactionproblemistofindthesmallestpossibleheight\nwww.it-ebooks.info\n8.5. Exercises 357\nE F\nA E F\nC D\nA\nB\nB C D\n(a) (b)\nFigure8.23: (a)Slicingfloorplan;(b)slicing treeassociated withthefloorplan.\nandwidthforeachrectangleoftheslicingfloorplanthatiscompatiblewiththe\nminimumdimensionsofthebasicrectangles. Namely,thisproblemrequiresthe\nassignmentof valuesh(p) and w(p) to each position p of the slicing tree such\nthat:\nif p is a leaf whose basic rectangle has mini-\nw\nmumwidthw\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4 \uf8f4 if p is an internal position, associated with\n\uf8f4\nw(p)=\n\uf8f4 \uf8f4\uf8f4\n\uf8f4\nmax(w(\u2113),w(r)) a horizontal cut, with left child \u2113 and right\n\uf8f4 \uf8f4 childr\n\uf8f4\n\uf8f4\n\uf8f2\nif p is an internal position, associated with a\n\uf8f4 \uf8f4\nw(\u2113)+w(r)\nverticalcut,withleftchild\u2113andrightchildr\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 if p is a leaf node whose basic rectangle has\nh\nminimumheighth\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4 \uf8f4 if p is an internal position, associated with\n\uf8f4\nh(p)= \uf8f4 \uf8f4 \uf8f4\uf8f4 h(\u2113)+h(r) a horizontal cut, with left child \u2113 and right\n\uf8f4\n\uf8f4 \uf8f4 childr\n\uf8f4\n\uf8f2\nif p is an internal position, associated with a\n\uf8f4 \uf8f4\n\uf8f4\nmax(h(\u2113),h(r)) verticalcut,withleftchild\u2113andrightchildr\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\uf8f4\n\uf8f4\n\uf8f4\nDesigna\uf8f3datastructureforslicingfloorplansthatsupportstheoperations:\nCreateafloorplanconsistingofasinglebasicrectangle.\n\u2022\nDecomposeabasicrectanglebymeansofahorizontalcut.\n\u2022\nDecomposeabasicrectanglebymeansofaverticalcut.\n\u2022\nAssignminimumheightandwidthtoabasicrectangle.\n\u2022\nDrawtheslicingtreeassociatedwiththefloorplan.\n\u2022\nCompactanddrawthefloorplan.\n\u2022\nwww.it-ebooks.info\n358 Chapter8. Trees\nP-8.67 WriteaprogramthatcanplayTic-Tac-Toeeffectively.(SeeSection3.1.5.)Todo\nthis,youwillneedtocreateagametreeT, whichisatreewhereeachposition\ncorrespondstoagameconfiguration,which,inthiscase,isarepresentationof\nthe Tic-Tac-Toeboard. (See Section 8.4.2.) The rootcorrespondsto the initial\nconfiguration. For each internal position p in T, the children of p correspond\nto the gamestates we canreach from p\u2019s gamestate in a single legalmovefor\ntheappropriateplayer,A(thefirstplayer)orB(thesecondplayer). Positionsat\nevendepthscorrespondtomovesforAandpositionsatodddepthscorrespondto\nmovesforB. Leavesareeitherfinalgamestatesorareatadepthbeyondwhich\nwe do notwant to explore. We score each leaf with a valuethat indicateshow\ngoodthisstateisforplayerA. Inlargegames,likechess,wehavetouseaheuris-\nticscoringfunction,butforsmallgames,likeTic-Tac-Toe,wecanconstructthe\nentiregametreeandscoreleavesas+1,0, 1,indicatingwhetherplayerAhas\n\u2212\nawin,draw,orloseinthatconfiguration. Agoodalgorithmforchoosingmoves\nis minimax. In this algorithm, we assign a score to each internalposition p in\nT, suchthatif p representsA\u2019sturn, we compute p\u2019sscore asthe maximumof\nthescoresof p\u2019schildren(whichcorrespondstoA\u2019soptimalplayfrom p). Ifan\ninternalnode prepresentsB\u2019sturn,thenwecompute p\u2019sscoreastheminimum\nofthescoresof p\u2019schildren(whichcorrespondstoB\u2019soptimalplayfrom p).\nP-8.68 Write a programthat takes as inputa generaltree T and a position p of T and\nconvertsT toanothertreewiththesamesetofpositionadjacencies,butnowwith\npasitsroot.\nP-8.69 Writeaprogramthatdrawsabinarytree.\nP-8.70 Writeaprogramthatdrawsageneraltree.\nP-8.71 Writeaprogramthatcaninputanddisplayaperson\u2019sfamilytree.\nP-8.72 Write a program that visualizes an Euler tour traversal of a properbinary tree,\nincludingthemovementsfromnodetonodeandtheactionsassociatedwithvisits\non the left, from below, and on the right. Illustrate your program by having it\ncompute and display preorder labels, inorder labels, postorder labels, ancestor\ncounts,anddescendantcountsforeachnodeinthetree(notnecessarilyallatthe\nsametime).\nChapter Notes\nDiscussions of the classic preorder, inorder, and postorder tree traversal methods can be\nfoundin Knuth\u2019sFundamentalAlgorithmsbook[60]. The Eulertourtraversaltechnique\ncomesfromtheparallelalgorithmscommunity;itisintroducedbyTarjanandVishkin[86]\nand is discussed by Ja\u00b4Ja\u00b4 [50] and by Karp and Ramachandran [55]. The algorithm for\ndrawinga tree is generallyconsideredto be a partofthe \u201cfolklore\u201dofgraph-drawingal-\ngorithms. The reader interested in graph drawing is referred to the book by Di Battista,\nEades,Tamassia, andTollis[29]andthesurveybyTamassiaandLiotta[85]. Thepuzzle\ninExerciseR-8.11wascommunicatedbyMichaSharir.\nwww.it-ebooks.info\nChapter\n9\nPriority Queues\nContents\n9.1 The Priority Queue Abstract Data Type. . . . . . . . . . . 360\n9.1.1 Priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\n9.1.2 The Priority Queue ADT . . . . . . . . . . . . . . . . . . 361\n9.2 Implementing a Priority Queue . . . . . . . . . . . . . . . . 362\n9.2.1 The Entry Composite . . . . . . . . . . . . . . . . . . . . 362\n9.2.2 Comparing Keys with Total Orders . . . . . . . . . . . . . 363\n9.2.3 The AbstractPriorityQueue Base Class . . . . . . . . . . . 364\n9.2.4 Implementing a Priority Queue with an Unsorted List . . . 366\n9.2.5 Implementing a Priority Queue with a Sorted List . . . . . 368\n9.3 Heaps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\n9.3.1 The Heap Data Structure . . . . . . . . . . . . . . . . . . 370\n9.3.2 Implementing a Priority Queue with a Heap . . . . . . . . 372\n9.3.3 Analysis of a Heap-Based Priority Queue . . . . . . . . . . 379\n\u22c6\n9.3.4 Bottom-Up Heap Construction . . . . . . . . . . . . . 380\n9.3.5 Using the java.util.PriorityQueue Class . . . . . . . . . . . 384\n9.4 Sorting with a Priority Queue. . . . . . . . . . . . . . . . . 385\n9.4.1 Selection-Sort and Insertion-Sort . . . . . . . . . . . . . . 386\n9.4.2 Heap-Sort . . . . . . . . . . . . . . . . . . . . . . . . . . 388\n9.5 Adaptable Priority Queues . . . . . . . . . . . . . . . . . . 390\n9.5.1 Location-Aware Entries . . . . . . . . . . . . . . . . . . . 391\n9.5.2 Implementing an Adaptable Priority Queue . . . . . . . . 392\n9.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395\nwww.it-ebooks.info\n360 Chapter9. PriorityQueues\n9.1 The Priority Queue Abstract Data Type\n9.1.1 Priorities\nIn Chapter 6, we introduced the queue ADT as a collection of objects that are\nadded and removed according to the first-in, first-out (FIFO) principle. A com-\npany\u2019scustomercallcenterembodiessuchamodelinwhichwaitingcustomersare\ntold\u201ccalls willbeanswered intheorderthattheywerereceived.\u201d Inthatsetting, a\nnew call is added to the back of the queue, and each time a customer service rep-\nresentative becomes available, he orsheisconnected withthecall that isremoved\nfromthefrontofthecallqueue.\nInpractice, therearemanyapplications inwhichaqueue-like structure isused\nto manage objects that must be processed in some way, but for which the first-in,\nfirst-outpolicydoesnotsuffice. Consider,forexample,anair-trafficcontrolcenter\nthat has todecide which flightto clear for landing from among many approaching\ntheairport. Thischoicemaybeinfluencedbyfactorssuchaseachplane\u2019sdistance\nfrom the runway, time spent waiting in a holding pattern, or amount of remaining\nfuel. Itisunlikely thatthelandingdecisions arebasedpurelyonaFIFOpolicy.\nThereareothersituationsinwhicha\u201cfirstcome,firstserve\u201dpolicymightseem\nreasonable, yet for which other priorities come into play. To use another airline\nanalogy, suppose a certain flight is fully booked an hour prior to departure. Be-\ncause of the possibility of cancellations, the airline maintains a queue of standby\npassengers hoping to get a seat. Although the priority of a standby passenger is\ninfluenced bythecheck-in timeofthatpassenger, other considerations include the\nfare paid and frequent-flyer status. So it may be that an available seat is given to\na passenger who has arrived later than another, if such a passenger is assigned a\nbetterprioritybytheairlineagent.\nInthischapter,weintroduceanewabstractdatatypeknownasapriorityqueue.\nThis is a collection of prioritized elements that allows arbitrary element insertion,\nand allows the removal of the element that has first priority. When an element is\nadded to a priority queue, the user designates its priority by providing an associ-\nated key. The element with the minimal key will be the next to be removed from\nthequeue (thus, anelement withkey 1willbegiven priority overanelement with\nkey2). Althoughitisquitecommonforprioritiestobeexpressednumerically, any\nJavaobjectmaybeusedasakey,aslongasthereexistsmeanstocompareanytwo\ninstances aandb,inawaythatdefinesanatural orderofthekeys. Withsuchgen-\nerality,applicationsmaydeveloptheirownnotionofpriorityforeachelement. For\nexample,differentfinancialanalystsmayassigndifferentratings(i.e.,priorities)to\naparticular asset,suchasashareofstock.\nwww.it-ebooks.info\n9.1. ThePriorityQueueAbstractDataType 361\n9.1.2 The Priority Queue ADT\nWemodelanelementanditspriority asakey-value composite knownasanentry.\n(However,wedeferuntilSection9.2.1thetechnical definitionoftheEntrytype.)\nWedefinethepriority queueADTtosupportthefollowingmethods:\ninsert(k,v): Createsanentrywithkeykandvaluevinthepriority queue.\nmin(): Returns (but does not remove) a priority queue entry (k,v)\nhavingminimalkey;returnsnullifthepriorityqueueisempty.\nremoveMin(): Removesandreturns anentry(k,v)having minimalkeyfrom\nthepriorityqueue;returnsnullifthepriorityqueueisempty.\nsize(): Returnsthenumberofentriesinthepriority queue.\nisEmpty(): Returns a boolean indicating whether the priority queue is\nempty.\nApriorityqueuemayhavemultipleentrieswithequivalentkeys,inwhichcase\nmethods min and removeMin may report an arbitrary choice among those entry\nhavingminimalkey. Valuesmaybeanytypeofobject.\nIn our initial model for a priority queue, we assume that an element\u2019s key re-\nmainsfixedonceithasbeenaddedtoapriority queue. InSection9.5,weconsider\nanextensionthatallowsausertoupdateanelement\u2019skeywithinthepriorityqueue.\nExample 9.1: Thefollowingtableshowsaseriesofoperationsandtheireffects\nonaninitiallyemptypriorityqueue. The\u201cPriorityQueueContents\u201dcolumnis\nsomewhatdeceivingsinceitshowstheentriessortedbykey. Suchaninternal\nrepresentationisnotrequiredofapriorityqueue.\nMethod ReturnValue PriorityQueueContents\ninsert(5,A) (5,A)\n{ }\ninsert(9,C) (5,A), (9,C)\n{ }\ninsert(3,B) (3,B), (5,A), (9,C)\n{ }\nmin() (3,B) (3,B), (5,A), (9,C)\n{ }\nremoveMin() (3,B) (5,A), (9,C)\n{ }\ninsert(7,D) (5,A), (7,D), (9,C)\n{ }\nremoveMin() (5,A) (7,D), (9,C)\n{ }\nremoveMin() (7,D) (9,C)\n{ }\nremoveMin() (9,C)\n{ }\nremoveMin() null\n{ }\nisEmpty() true\n{ }\nwww.it-ebooks.info\n362 Chapter9. PriorityQueues\n9.2 Implementing a Priority Queue\nInthissection, wediscussseveraltechnicalissuesinvolving theimplementation of\nthe priority queue ADTinJava, and wedefine an abstract base class that provides\nfunctionalitythatissharedbyallpriorityqueueimplementationsinthischapter. We\nthen provide twoconcrete priority queue implementations using apositional list L\n(see Section 7.3) for storage. They differ in whether or not entries are maintained\ninsortedorderaccording totheirkeys.\n9.2.1 The Entry Composite\nOnechallenge inimplementing apriority queueisthatwemustkeeptrackofboth\nan element and its key, even as entries are relocated within a data structure. This\nis reminiscent of a case study from Section 7.7 in which we maintain a list of\nelements with access frequencies. In that setting, we introduced the composition\ndesign pattern, defining an Itemclass that paired each element with itsassociated\ncount in our primary data structure. For priority queues, we use composition to\npairakeykandavaluevasasingleobject. Toformalizethis,wedefinethepublic\ninterface, Entry,showninCodeFragment9.1.\n1 /\u2217\u2217 Interface for a key-value pair. \u2217/\n2 public interface Entry<K,V>\n{\n3 K getKey(); // returns the key stored in this entry\n4 V getValue(); // returns the value stored in this entry\n5\n}\nCodeFragment9.1: Javainterface foranentrystoring akey-valuepair.\nWethenusetheEntrytypeintheformalinterfaceforthepriorityqueue,shown\nin Code Fragment 9.2. This allows us to return both a key and value as a single\nobjectfrommethodssuchasminandremoveMin. Wealsodefinetheinsertmethod\ntoreturn anentry; inamore advanced adaptable priority queue(see Section 9.5),\nthatentrycanbesubsequently updatedorremoved.\n1 /\u2217\u2217 Interface for the priority queue ADT. \u2217/\n2 public interface PriorityQueue<K,V>\n{\n3 int size();\n4 boolean isEmpty();\n5 Entry<K,V> insert(K key, V value) throws IllegalArgumentException;\n6 Entry<K,V> min();\n7 Entry<K,V> removeMin();\n8\n}\nCodeFragment9.2: Javainterface forthepriority queueADT.\nwww.it-ebooks.info\n9.2. ImplementingaPriorityQueue 363\n9.2.2 Comparing Keys with Total Orders\nIn defining the priority queue ADT, we can allow any type of object to serve as a\nkey,butwemustbeabletocomparekeystoeachotherinameaningfulway. More\nso,theresultsofthecomparisonsmustnotbecontradictory. Foracomparisonrule,\nwhich we denote by , to be self-consistent, it must define a total order relation,\n\u2264\nwhichistosaythatitsatisfiesthefollowingproperties foranykeysk ,k ,andk :\n1 2 3\nComparabilityproperty: k k ork k .\n1 2 2 1\n\u2022 \u2264 \u2264\nAntisymmetricproperty: ifk k andk k ,thenk =k .\n1 2 2 1 1 2\n\u2022 \u2264 \u2264\nTransitiveproperty: ifk k andk k ,thenk k .\n1 2 2 3 1 3\n\u2022 \u2264 \u2264 \u2264\nThecomparability property states thatcomparison rule isdefined forevery pairof\nkeys. Notethatthisproperty impliesthefollowingone:\nReflexiveproperty: k k.\n\u2022 \u2264\nA comparison rule, , that defines a total order relation will never lead to a con-\n\u2264\ntradiction. Such a rule defines a linear ordering among a set of keys; hence, if a\n(finite)setofelementshasatotalorderdefinedforit,thenthenotionofaminimal\nkey,k ,iswelldefined,asakeyinwhichk k,foranyotherkeykinourset.\nmin min\n\u2264\nThe Comparable Interface\nJava provides twomeansfor defining comparisons between object types. Thefirst\nof these is that a class may define what is known as the natural ordering of its\ninstancesbyformallyimplementingthejava.lang.Comparableinterface, whichin-\ncludes a single method, compareTo. The syntax a.compareTo(b) must return an\nintegeriwiththefollowingmeaning:\ni<0designates thata<b.\n\u2022\ni=0designates thata=b.\n\u2022\ni>0designates thata>b.\n\u2022\nFor example, the compareTo method of the String class defines the natural\nordering of strings to be lexicographic, which is a case-sensitive extension of the\nalphabetic ordering toUnicode.\nThe Comparator Interface\nIn some applications, we may want to compare objects according to some notion\nother than their natural ordering. For example, we might be interested in which\nof two strings is the shortest, or in defining our own complex rules for judging\nwhich of two stocks is more promising. To support generality, Java defines the\njava.util.Comparator interface. A comparator is an object that is external to the\nclassofthekeysitcompares. Itprovidesamethodwiththesignaturecompare(a,b)\nthat returns an integer with similar meaning to the compareTo method described\nabove.\nwww.it-ebooks.info\n364 Chapter9. PriorityQueues\nAsaconcreteexample,CodeFragment9.3definesacomparatorthatevaluates\nstringsbasedontheirlength(ratherthantheirnaturallexicographic order).\n1 public class StringLengthComparatorimplements Comparator<String>\n2 /\u2217\u2217 Compares two strings according to their lengths. \u2217/ {\n3 public int compare(String a, String b)\n{\n4 if (a.length() < b.length()) return 1;\n\u2212\n5 else if (a.length() == b.length()) return 0;\n6 else return 1;\n7\n}\n8\n}\nCodeFragment9.3: Acomparator thatevaluates stringsbasedontheirlengths.\nComparators and the Priority Queue ADT\nFor a general and reusable form of a priority queue, we allow a user to choose\nanykey type and tosend anappropriate comparator instance asaparameter tothe\npriority queue constructor. The priority queue will use that comparator anytime it\nneedstocomparetwokeystoeachother.\nFor convenience, we also allow a default priority queue to instead rely on the\nnatural ordering forthe givenkeys (assuming those keys comefrom acomparable\nclass). Inthatcase,webuildourowninstanceofaDefaultComparatorclass,shown\ninCodeFragment9.4.\n1 public class DefaultComparator<E> implements Comparator<E>\n{\n2 public int compare(E a, E b) throws ClassCastException\n{\n3 return ((Comparable<E>) a).compareTo(b);\n4\n}\n5\n}\nCode Fragment 9.4: A DefaultComparator class that implements a comparator\nbaseduponthenaturalordering ofitselementtype.\n9.2.3 The AbstractPriorityQueue Base Class\nTomanagetechnical issues commontoallourpriority queueimplementations, we\ndefineanabstract baseclass namedAbstractPriorityQueueinCodeFragment 9.5.\n(SeeSection2.3.3foradiscussion ofabstractbaseclasses.) Thisincludesanested\nPQEntryclassthatimplementsthepublicEntryinterface.\nOurabstract class also declares andinitializes aninstance variable, comp, that\nstoresthecomparatorbeingusedforthepriorityqueue. Wethenprovideaprotected\nmethod,compare,thatinvokes thecomparator onthekeysoftwogivenentries.\nwww.it-ebooks.info\n9.2. ImplementingaPriorityQueue 365\n1 /\u2217\u2217 An abstract base class to assist implementations of the PriorityQueue interface.\u2217/\n2 public abstract class AbstractPriorityQueue<K,V>\n3 implements PriorityQueue<K,V>\n{\n4 //----------------nested PQEntry class ----------------\n5 protected static class PQEntry<K,V> implements Entry<K,V>\n{\n6 private K k; // key\n7 private V v; // value\n8 public PQEntry(K key, V value)\n{\n9 k = key;\n10 v = value;\n11\n}\n12 // methods of the Entry interface\n13 public K getKey() return k;\n{ }\n14 public V getValue() return v;\n{ }\n15 // utilities not exposed as part of the Entry interface\n16 protected void setKey(K key) k = key;\n{ }\n17 protected void setValue(V value) v = value;\n{ }\n18 //-----------end of nested PQEntry class -----------\n}\n19\n20 // instance variable for an AbstractPriorityQueue\n21 /\u2217\u2217 The comparator defining the ordering of keys in the priority queue. \u2217/\n22 private Comparator<K> comp;\n23 /\u2217\u2217 Creates an empty priority queue using the given comparator to order keys. \u2217/\n24 protected AbstractPriorityQueue(Comparator<K> c) comp = c;\n25 /\u2217\u2217 Creates an empty priority queue based on the natu { ral ordering o } f its keys. \u2217/\n26 protected AbstractPriorityQueue() this(new DefaultComparator<K>());\n27 /\u2217\u2217 Method for comparing two entri { es according to key \u2217/ }\n28 protected int compare(Entry<K,V> a, Entry<K,V> b)\n{\n29 return comp.compare(a.getKey(), b.getKey());\n30\n31 } /\u2217\u2217 Determines whether a key is valid. \u2217/\n32 protected boolean checkKey(K key) throws IllegalArgumentException\n{\n33 try\n{\n34 return (comp.compare(key,key) == 0); // see if key can be compared to itself\n35 catch (ClassCastException e)\n} {\n36 throw new IllegalArgumentException(\"Incompatible key\");\n37\n}\n38\n39 } /\u2217\u2217 Tests whether the priority queue is empty. \u2217/\n40 public boolean isEmpty() return size() == 0;\n{ }\n41\n}\nCode Fragment 9.5: The AbstractPriorityQueue class. This provides a nested\nPQEntry class that composes a key and a value into a single object, and support\nfor managing a comparator. For convenience, we also provide an implementation\nofisEmptybasedonapresumedsizemethod.\nwww.it-ebooks.info\n366 Chapter9. PriorityQueues\n9.2.4 Implementing a Priority Queue with an Unsorted List\nInourfirstconcrete implementation ofapriority queue, westore entries withinan\nunsorted linked list. CodeFragment9.6presents ourUnsortedPriorityQueueclass\nas a subclass of the AbstractPriorityQueue class (from Code Fragment 9.5). For\ninternal storage, key-value pairs are represented as composites, using instances of\nthe inherited PQEntry class. These entries are stored within a PositionalList that\nis an instance variable. We assume that the positional list is implemented with a\ndoubly linked list, as in Section 7.3, so that all operations of that ADT execute in\nO(1)time.\nWe begin with an empty list when a new priority queue is constructed. At all\ntimes, the size of the list equals the number of key-value pairs currently stored in\nthe priority queue. For this reason, our priority queue size method simply returns\nthe length of the internal list. By the design of our AbstractPriorityQueue class,\nweinheritaconcreteimplementation oftheisEmptymethodthatreliesonacallto\noursizemethod.\nEachtimeakey-valuepairisaddedtothepriorityqueue,viatheinsertmethod,\nwecreateanewPQEntrycompositeforthegivenkeyandvalue,andaddthatentry\ntotheendofthelist. Suchanimplementation takesO(1)time.\nThe remaining challenge is that when min or removeMin is called, we must\nlocate the entry with minimal key. Because the entries are not sorted, we must\ninspect all entries to find one with a minimal key. For convenience, we define\na private findMin utility that returns the position of an entry with minimal key.\nKnowledge of the position allows the removeMin method to invoke the remove\nmethod onthe positional list. Theminmethod simply uses the position toretrieve\nthe entry when preparing a key-value tuple to return. Due to the loop for finding\nthe minimal key, both min and removeMin methods run in O(n) time, where n is\nthenumberofentriesinthepriority queue.\nA summary of the running times for the UnsortedPriorityQueue class is given\ninTable9.1.\nMethod RunningTime\nsize O(1)\nisEmpty O(1)\ninsert O(1)\nmin O(n)\nremoveMin O(n)\nTable 9.1: Worst-case running times of the methods of a priority queue of size\nn, realized by means of an unsorted, doubly linked list. The space requirement\nisO(n).\nwww.it-ebooks.info\n9.2. ImplementingaPriorityQueue 367\n1 /\u2217\u2217 An implementation of a priority queue with an unsorted list. \u2217/\n2 public class UnsortedPriorityQueue<K,V> extends AbstractPriorityQueue<K,V>\n3 /\u2217\u2217 primary collection of priority queue entries \u2217/ {\n4 private PositionalList<Entry<K,V>> list = new LinkedPositionalList<>();\n5\n6 /\u2217\u2217 Creates an empty priority queue based on the natural ordering of its keys. \u2217/\n7 public UnsortedPriorityQueue() super();\n8 /\u2217\u2217 Creates an empty priority qu { eue using th } e given comparator to order keys. \u2217/\n9 public UnsortedPriorityQueue(Comparator<K> comp) super(comp);\n{ }\n10\n11 /\u2217\u2217 Returns the Position of an entry having minimal key. \u2217/\n12 private Position<Entry<K,V>> findMin() // only called when nonempty\n{\n13 Position<Entry<K,V>> small = list.first();\n14 for (Position<Entry<K,V>> walk : list.positions())\n15 if (compare(walk.getElement(), small.getElement()) < 0)\n16 small = walk; // found an even smaller key\n17 return small;\n18\n}\n19\n20 /\u2217\u2217 Inserts a key-value pair and returns the entry created. \u2217/\n21 public Entry<K,V> insert(K key, V value) throws IllegalArgumentException\n{\n22 checkKey(key); // auxiliary key-checking method (could throw exception)\n23 Entry<K,V> newest = new PQEntry<>(key, value);\n24 list.addLast(newest);\n25 return newest;\n26\n}\n27\n28 /\u2217\u2217 Returns (but does not remove) an entry with minimal key. \u2217/\n29 public Entry<K,V> min()\n{\n30 if (list.isEmpty()) return null;\n31 return findMin().getElement();\n32\n}\n33\n34 /\u2217\u2217 Removes and returns an entry with minimal key. \u2217/\n35 public Entry<K,V> removeMin()\n{\n36 if (list.isEmpty()) return null;\n37 return list.remove(findMin());\n38\n}\n39\n40 /\u2217\u2217 Returns the number of items in the priority queue. \u2217/\n41 public int size() return list.size();\n{ }\n42\n}\nCodeFragment9.6: An implementation of a priority queue using an unsorted list.\nThe parent class AbstractPriorityQueue is given in Code Fragment 9.5, and the\nLinkedPositionalListclassisfromSection7.3.\nwww.it-ebooks.info\n368 Chapter9. PriorityQueues\n9.2.5 Implementing a Priority Queue with a Sorted List\nOurnextimplementationofapriorityqueuealsousesapositionallist,yetmaintains\nentries sorted bynondecreasing keys. Thisensures that thefirstelement ofthelist\nisanentrywiththesmallestkey.\nOurSortedPriorityQueueclassisgiveninCodeFragment9.7. Theimplemen-\ntation of min and removeMin are rather straightforward given knowledge that the\nfirst element of a list has a minimal key. We rely on the first method of the posi-\ntional list to find the position of the first entry, and the remove method to remove\ntheentryfromthelist. Assuming thatthelistisimplemented withadoubly linked\nlist,operations minandremoveMintakeO(1)time.\nThis benefit comes at a cost, however, for method insert now requires that we\nscanthelisttofindtheappropriate positiontoinsertthenewentry. Ourimplemen-\ntation starts at the end of the list, walking backward until the new key is smaller\nthan that of an existing entry; in the worst case, it progresses until reaching the\nfront ofthelist. Therefore, theinsertmethod takes O(n)worst-case time, where n\nisthenumberofentriesinthepriorityqueueatthetimethemethodisexecuted. In\nsummary, when using asorted listtoimplement apriority queue, insertion runs in\nlinear time, whereas finding and removing the minimum can be done in constant\ntime.\nComparing the Two List-Based Implementations\nTable 9.2 compares the running times of the methods of a priority queue realized\nby means of a sorted and unsorted list, respectively. We see an interesting trade-\noff when we use a list to implement the priority queue ADT. An unsorted list\nsupports fastinsertions butslowqueries anddeletions, whereasasortedlistallows\nfastqueriesanddeletions, butslowinsertions.\nMethod UnsortedList SortedList\nsize O(1) O(1)\nisEmpty O(1) O(1)\ninsert O(1) O(n)\nmin O(n) O(1)\nremoveMin O(n) O(1)\nTable 9.2: Worst-case running times of the methods of a priority queue of size n,\nrealized by means of an unsorted or sorted list, respectively. We assume that the\nlistisimplemented byadoubly linkedlist. Thespacerequirement isO(n).\nwww.it-ebooks.info\n9.2. ImplementingaPriorityQueue 369\n1 /\u2217\u2217 An implementation of a priority queue with a sorted list. \u2217/\n2 public class SortedPriorityQueue<K,V> extends AbstractPriorityQueue<K,V>\n3 /\u2217\u2217 primary collection of priority queue entries \u2217/ {\n4 private PositionalList<Entry<K,V>> list = new LinkedPositionalList<>();\n5\n6 /\u2217\u2217 Creates an empty priority queue based on the natural ordering of its keys. \u2217/\n7 public SortedPriorityQueue() super();\n8 /\u2217\u2217 Creates an empty priority { queue using } the given comparator to order keys. \u2217/\n9 public SortedPriorityQueue(Comparator<K> comp) super(comp);\n{ }\n10\n11 /\u2217\u2217 Inserts a key-value pair and returns the entry created. \u2217/\n12 public Entry<K,V> insert(K key, V value) throws IllegalArgumentException\n{\n13 checkKey(key); // auxiliary key-checking method (could throw exception)\n14 Entry<K,V> newest = new PQEntry<>(key, value);\n15 Position<Entry<K,V>> walk = list.last();\n16 // walk backward, looking for smaller key\n17 while (walk != null && compare(newest, walk.getElement()) < 0)\n18 walk = list.before(walk);\n19 if (walk == null)\n20 list.addFirst(newest); // new key is smallest\n21 else\n22 list.addAfter(walk, newest); // newest goes after walk\n23 return newest;\n24\n}\n25\n26 /\u2217\u2217 Returns (but does not remove) an entry with minimal key. \u2217/\n27 public Entry<K,V> min()\n{\n28 if (list.isEmpty()) return null;\n29 return list.first().getElement();\n30\n}\n31\n32 /\u2217\u2217 Removes and returns an entry with minimal key. \u2217/\n33 public Entry<K,V> removeMin()\n{\n34 if (list.isEmpty()) return null;\n35 return list.remove(list.first());\n36\n}\n37\n38 /\u2217\u2217 Returns the number of items in the priority queue. \u2217/\n39 public int size() return list.size();\n{ }\n40\n}\nCode Fragment 9.7: An implementation of a priority queue using a sorted list.\nThe parent class AbstractPriorityQueue is given in Code Fragment 9.5, and the\nLinkedPositionalListclassisfromSection7.3.\nwww.it-ebooks.info\n370 Chapter9. PriorityQueues\n9.3 Heaps\nThe twostrategies for implementing a priority queue ADTin the previous section\ndemonstrate an interesting trade-off. When using an unsorted list to store entries,\nwe can perform insertions in O(1) time, but finding or removing an element with\nminimal key requires an O(n)-time loop through the entire collection. Incontrast,\nif using a sorted list, we can trivially find or remove the minimal element in O(1)\ntime, but adding a new element to the queue may require O(n) time to restore the\nsortedorder.\nInthissection,weprovideamoreefficientrealizationofapriorityqueueusing\nadatastructurecalledabinaryheap. Thisdatastructureallowsustoperformboth\ninsertions and removals in logarithmic time, which is a significant improvement\nover the list-based implementations discussed in Section 9.2. The fundamental\nway the heap achieves this improvement is to use the structure of a binary tree to\nfindacompromisebetweenelementsbeingentirelyunsorted andperfectly sorted.\n9.3.1 The Heap Data Structure\nA heap (see Figure 9.1) is a binary tree T that stores entries at its positions, and\nthatsatisfiestwoadditional properties: arelationalpropertydefinedintermsofthe\nwaykeysarestored inT andastructural property defined intermsoftheshape of\nT itself. Therelational propertyisthefollowing:\nHeap-OrderProperty: In a heap T, for every position p other than the root, the\nkeystoredat pisgreaterthanorequaltothekeystoredat p\u2019sparent.\nAsaconsequence oftheheap-order property, thekeysencountered onapathfrom\nthe root to a leaf of T are in nondecreasing order. Also, a minimal key is always\nstored at the root of T. This makes it easy to locate such an entry when min or\nremoveMin is called, as it is informally said to be \u201cat the top of the heap\u201d (hence,\nthename\u201cheap\u201dforthedatastructure). Bytheway,theheapdatastructuredefined\nhere has nothing todo withthe memoryheap (Section 15.1.2) used in theruntime\nenvironment supporting aprogramming language likeJava.\nForthesakeofefficiency,aswillbecomeclearlater,wewanttheheapT tohave\nassmallaheightaspossible. Weenforcethisrequirementbyinsistingthattheheap\nT satisfyanadditional structural property; itmustbewhatwetermcomplete.\nCompleteBinaryTreeProperty: AheapT withheighthisacompletebinarytree\nif levels 0,1,2,...,h 1 of T have the maximal number of nodes possible\n\u2212\n(namely, level i has 2i nodes, for 0 i h 1) and the remaining nodes at\n\u2264 \u2264 \u2212\nlevelhresideintheleftmostpossible positions atthatlevel.\nwww.it-ebooks.info\n9.3. Heaps 371\n(4,C)\n(5,A) (6,Z)\n(15,K) (9,F) (7,Q) (20,B)\n(16,X) (25,J) (14,E) (12,H) (11,S) (13,W)\nFigure9.1: Exampleofaheapstoring13entrieswithintegerkeys. Thelastposition\nistheonestoringentry(13,W).\nThetreeinFigure9.1iscompletebecauselevels0,1,and2arefull,andthesix\nnodesinlevel3areinthesixleftmostpossiblepositionsatthatlevel. Informalizing\nwhatwemeanbytheleftmostpossiblepositions,werefertothediscussionoflevel\nnumberingfromSection8.3.2,inthecontextofanarray-based representation ofa\nbinarytree. (Infact,inSection9.3.2wewilldiscusstheuseofanarraytorepresent\naheap.) Acompletebinarytreewithnelementsisonethathaspositionswithlevel\nnumbering 0 through n 1. For example, in an array-based representation of the\n\u2212\nabovetree,its13entrieswouldbestoredconsecutively fromA[0]toA[12].\nThe Height of a Heap\nLet h denote the height of T. Insisting that T be complete also has an important\nconsequence, asshowninProposition 9.2.\nProposition 9.2: AheapT storingnentrieshasheighth= logn .\n\u230a \u230b\nJustification: From the fact that T is complete, we know that the number of\nnodesinlevels0throughh 1ofT isprecisely1+2+4+ +2h\u22121=2h 1,and\n\u2212 \u00b7\u00b7\u00b7 \u2212\nthatthenumberofnodesinlevelhisatleast1andatmost2h. Therefore\nn 2h 1+1=2h and n 2h 1+2h=2h+1 1.\n\u2265 \u2212 \u2264 \u2212 \u2212\nBy taking the logarithm of both sides of inequality n 2h, we see that height\n\u2265\nh logn. Byrearrangingtermsandtakingthelogarithmofbothsidesofinequality\n\u2264\nn 2h+1 1, we see that h log(n+1) 1. Since h is an integer, these two\n\u2264 \u2212 \u2265 \u2212\ninequalities implythath= logn .\n\u230a \u230b\nwww.it-ebooks.info\n372 Chapter9. PriorityQueues\n9.3.2 Implementing a Priority Queue with a Heap\nProposition9.2hasanimportantconsequence, foritimpliesthatifwecanperform\nupdate operations on a heap in time proportional to its height, then those opera-\ntions will run in logarithmic time. Let us therefore turn to the problem of how to\nefficientlyperform variouspriorityqueuemethodsusingaheap.\nWewillusethecompositionpatternfromSection9.2.1tostorekey-valuepairs\nas entries in the heap. The size and isEmpty methods can be implemented based\non examination of the tree, and the min operation is equally trivial because the\nheap property assures that the element at the root of the tree has a minimal key.\nThe interesting algorithms are those for implementing the insert and removeMin\nmethods.\nAdding an Entry to the Heap\nLetus consider how to perform insert(k,v) on a priority queue implemented with\naheapT. Westorethepair(k,v)asanentryatanewnodeofthetree. Tomaintain\nthe complete binary tree property, that new node should be placed at a position p\njust beyond the rightmost node at the bottom level of the tree, or as the leftmost\nposition ofanewlevel,ifthebottomlevelisalready full(oriftheheapisempty).\nUp-Heap Bubbling After an Insertion\nAfterthisaction,thetreeT iscomplete,butitmayviolatetheheap-order property.\nHence, unless position p is the root of T (that is, the priority queue was empty\nbeforetheinsertion), wecomparethekeyatposition ptothatof p\u2019sparent, which\nwedenoteasq. Ifkeyk k ,theheap-orderpropertyissatisfiedandthealgorithm\np q\n\u2265\nterminates. If instead k < k , then we need to restore the heap-order property,\np q\nwhichcan belocally achieved byswapping theentries stored atpositions pand q.\n(See Figure 9.2c and d.) This swap causes the new entry to move up one level.\nAgain,theheap-orderpropertymaybeviolated,sowerepeattheprocess,goingup\ninT untilnoviolation oftheheap-order property occurs. (SeeFigure9.2eandh.)\nThe upward movement of the newly inserted entry by means of swaps is con-\nventionally called up-heap bubbling. A swap either resolves the violation of the\nheap-orderpropertyorpropagatesitonelevelupintheheap. Intheworstcase,up-\nheap bubbling causes the new entry to move all the way up to the root of heap T.\nThus,intheworstcase,thenumberofswapsperformedintheexecutionofmethod\ninsertisequaltotheheightofT. ByProposition 9.2,thatboundis logn .\n\u230a \u230b\nwww.it-ebooks.info\n9.3. Heaps 373\n(4,C) (4,C)\n(5,A) (6,Z) (5,A) (6,Z)\n(15,K) (9,F) (7,Q) (20,B) (15,K) (9,F) (7,Q) (20,B)\n(16,X) (25,J) (14,E) (12,H) (11,S) (13,W) (16,X) (25,J) (14,E) (12,H) (11,S) (13,W) (2,T)\n(a) (b)\n(4,C) (4,C)\n(5,A) (6,Z) (5,A) (6,Z)\n(15,K) (9,F) (7,Q) (15,K) (9,F) (7,Q) (2,T)\n(20,B) (2,T)\n(16,X) (25,J) (14,E) (12,H) (11,S) (13,W) (16,X) (25,J) (14,E) (12,H) (11,S) (13,W) (20,B)\n(c) (d)\n(4,C) (4,C)\n(2,T)\n(5,A) (5,A) (2,T)\n(15,K) (9,F) (7,Q) (15,K) (9,F) (7,Q) (6,Z)\n(6,Z)\n(16,X) (25,J) (14,E) (12,H) (11,S) (13,W) (20,B) (16,X) (25,J) (14,E) (12,H) (11,S) (13,W) (20,B)\n(e) (f)\n(2,T)\n(2,T)\n(4,C)\n(5,A) (5,A) (4,C)\n(15,K) (9,F) (7,Q) (6,Z) (15,K) (9,F) (7,Q) (6,Z)\n(16,X) (25,J) (14,E) (12,H) (11,S) (13,W) (20,B) (16,X) (25,J) (14,E) (12,H) (11,S) (13,W) (20,B)\n(g) (h)\nFigure9.2: Insertionofanewentrywithkey2intotheheapofFigure9.1: (a)initial\nheap;(b)afteraddinganewnode;(candd)swaptolocallyrestorethepartialorder\nproperty; (eandf)anotherswap;(gandh)finalswap.\nwww.it-ebooks.info\n374 Chapter9. PriorityQueues\nRemoving the Entry with Minimal Key\nLetusnowturntomethodremoveMinofthepriorityqueueADT.Weknowthatan\nentry with the smallest key is stored at the root r of T (even if there is more than\noneentrywithsmallestkey). However,ingeneral wecannotsimplydeletenoder,\nbecausethiswouldleavetwodisconnected subtrees.\nInstead, weensurethattheshapeoftheheaprespectsthecompletebinarytree\nproperty by deleting the leaf at the last position p of T, defined as the rightmost\nposition at the bottommost level of the tree. To preserve the entry from the last\nposition p, we copy it to the root r (in place of the entry with minimal key that is\nbeingremovedbytheoperation). Figure9.3aandbillustrates anexampleofthese\nsteps,withminimalentry(4,C)beingremovedfromtherootandreplacedbyentry\n(13,W) from the last position. The node at the last position is removed from the\ntree.\nDown-Heap Bubbling After a Removal\nWearenotyetdone,however,foreventhoughT isnowcomplete,itlikelyviolates\nthe heap-order property. If T has only one node (the root), then the heap-order\nproperty is trivially satisfied and the algorithm terminates. Otherwise, we distin-\nguishtwocases,where pinitially denotestherootofT:\nIf phasnorightchild,letcbetheleftchildof p.\n\u2022\nOtherwise(phasbothchildren), letcbeachildof pwithminimalkey.\n\u2022\nIfkeyk k ,theheap-order property issatisfied andthealgorithm terminates. If\np c\n\u2264\ninsteadk >k ,thenweneedtorestoretheheap-orderproperty. Thiscanbelocally\np c\nachieved by swapping the entries stored at p and c. (See Figure 9.3c and d.) It is\nworth noting that when p has two children, we intentionally consider the smaller\nkey of the two children. Not only is the key of c smaller than that of p, it is at\nleastassmallasthekeyatc\u2019ssibling. Thisensures thattheheap-order property is\nlocally restored when that smaller key is promoted above the key that had been at\npandthatatc\u2019ssibling.\nHavingrestoredtheheap-orderpropertyfornode prelativetoitschildren,there\nmaybeaviolation ofthisproperty atc;hence, wemayhavetocontinue swapping\ndown T until no violation of the heap-order property occurs. (See Figure 9.3e\u2013h.)\nThis downward swapping process is called down-heap bubbling. A swap either\nresolvestheviolationoftheheap-orderproperty orpropagates itoneleveldownin\nthe heap. In the worst case, an entry moves all the way down to the bottom level.\n(SeeFigure9.3.) Thus,thenumberofswapsperformedintheexecutionofmethod\nremoveMin is, intheworstcase, equal tothe height ofheap T,that is, itis logn\n\u230a \u230b\nbyProposition 9.2.\nwww.it-ebooks.info\n9.3. Heaps 375\n(4,C)\n(13,W)\n(13,W)\n(5,A) (6,Z) (5,A) (6,Z)\n(15,K) (9,F) (7,Q) (20,B) (15,K) (9,F) (7,Q) (20,B)\n(16,X) (25,J) (14,E) (12,H) (11,S) (16,X) (25,J) (14,E) (12,H) (11,S)\n(a) (b)\n(13,W) (5,A)\n(5,A) (6,Z) (13,W) (6,Z)\n(15,K) (9,F) (7,Q) (20,B) (15,K) (9,F) (7,Q) (20,B)\n(16,X) (25,J) (14,E) (12,H) (11,S) (16,X) (25,J) (14,E) (12,H) (11,S)\n(c) (d)\n(5,A) (5,A)\n(9,F) (6,Z) (9,F) (6,Z)\n(15,K) (13,W) (7,Q) (20,B) (15,K) (13,W) (7,Q) (20,B)\n(16,X) (25,J) (14,E) (12,H) (11,S) (16,X) (25,J) (14,E) (12,H) (11,S)\n(e) (f)\n(5,A) (5,A)\n(9,F) (6,Z) (9,F) (6,Z)\n(15,K) (7,Q) (20,B) (15,K) (12,H) (7,Q) (20,B)\n(12,H)\n(13,W)\n(16,X) (25,J) (14,E) (11,S) (16,X) (25,J) (14,E) (13,W) (11,S)\n(g) (h)\nFigure 9.3: Removal of the entry with the smallest key from a heap: (a and b)\ndeletion of the last node, whose entry gets stored into the root; (c and d) swap to\nlocallyrestoretheheap-orderproperty;(eandf)anotherswap;(gandh)finalswap.\nwww.it-ebooks.info\n376 Chapter9. PriorityQueues\nArray-Based Representation of a Complete Binary Tree\nThearray-basedrepresentationofabinarytree(Section8.3.2)isespeciallysuitable\nfor a complete binary tree. We recall that in this implementation, the elements of\nthe tree are stored in an array-based list A such that the element at position p is\nstoredinAwithindexequaltothelevelnumber f(p)of p,definedasfollows:\nIf pistheroot,then f(p)=0.\n\u2022\nIf pistheleftchildofpositionq,then f(p)=2f(q)+1.\n\u2022\nIf pistherightchildofposition q,then f(p)=2f(q)+2.\n\u2022\nForatreewithofsizen,theelementshavecontiguousindicesintherange[0,n 1]\n\u2212\nandthelastposition ofisalwaysatindexn 1. (SeeFigure9.4.)\n\u2212\n0\n(4,C)\n1 2\n(5,A) (6,Z)\n3 4 5 6\n(15,K) (9,F) (7,Q) (20,B)\n7 8 9 10 11 12\n(16,X) (25,J) (14,E) (12,H) (11,S) (13,W)\n(4,C) (5,A) (6,Z) (15,K) (9,F) (7,Q) (20,B) (16,X) (25,J) (14,E) (12,H) (11,S) (13,W)\n0 1 2 3 4 5 6 7 8 9 10 11 12\nFigure9.4: Array-based representation ofaheap.\nThearray-based heap representation avoids somecomplexities ofalinked tree\nstructure. Specifically, methods insert and removeMin depend on locating the last\nposition ofaheap. Withthearray-based representation ofaheapofsizen,thelast\nposition issimplyatindexn 1. Locating thelastposition inaheapimplemented\n\u2212\nwithalinked treestructurerequires moreeffort. (SeeExerciseC-9.33.)\nIf the size of a priority queue is not known in advance, use of an array-based\nrepresentation doesintroducetheneedtodynamicallyresizethearrayonoccasion,\nas is done with a Java ArrayList. The space usage of such an array-based repre-\nsentation of a complete binary tree with n nodes is O(n), and the time bounds of\nmethodsforaddingorremovingelementsbecomeamortized. (SeeSection7.2.2.)\nJava Heap Implementation\nInCodeFragments9.8and9.9,weprovideaJavaimplementation ofaheap-based\npriorityqueue. Althoughwethinkofourheapasabinarytree,wedonotformally\nwww.it-ebooks.info\n9.3. Heaps 377\nusethebinary treeADT.Weprefer tousethemoreefficient array-based represen-\ntation of a tree, maintaining a Java ArrayList of entry composites. To allow us to\nformalize our algorithms using tree-like terminology of parent, left, and right, the\nclassincludesprotected utilitymethodsthatcomputethelevelnumbering ofapar-\nentorchild ofanother position (lines 10\u201314 ofCodeFragment 9.8). However, the\n\u201cpositions\u201d inthisrepresentation aresimplyintegerindicesintothearray-list.\nOurclassalsohasprotectedutilities swap,upheap,anddownheapforthelow-\nlevel movement of entries within the array-list. A new entry is added the end of\nthe array-list, and then repositioned as needed with upheap. To remove the entry\nwithminimalkey(whichresidesatindex0),wemovethelastentryofthearray-list\nfromindexn 1toindex0,andtheninvoke downheaptoreposition it.\n\u2212\n1 /\u2217\u2217 An implementation of a priority queue using an array-based heap. \u2217/\n2 public class HeapPriorityQueue<K,V> extends AbstractPriorityQueue<K,V>\n3 /\u2217\u2217 primary collection of priority queue entries \u2217/ {\n4 protected ArrayList<Entry<K,V>> heap = new ArrayList<>();\n5 /\u2217\u2217 Creates an empty priority queue based on the natural ordering of its keys. \u2217/\n6 public HeapPriorityQueue() super();\n7 /\u2217\u2217 Creates an empty priority { queue usin } g the given comparator to order keys. \u2217/\n8 public HeapPriorityQueue(Comparator<K> comp) super(comp);\n{ }\n9 // protected utilities\n10 protected int parent(int j) return (j 1) / 2; // truncating division\n11 protected int left(int j) re { turn 2\u2217j + \u2212 1; }\n12 protected int right(int j) { return 2\u2217j + 2; }\n{ }\n13 protected boolean hasLeft(int j) return left(j) < heap.size();\n{ }\n14 protected boolean hasRight(int j) return right(j) < heap.size();\n15 /\u2217\u2217 Exchanges the entries at indices { i and j of the array list. \u2217/ }\n16 protected void swap(int i, int j)\n{\n17 Entry<K,V> temp = heap.get(i);\n18 heap.set(i, heap.get(j));\n19 heap.set(j, temp);\n20\n21 } /\u2217\u2217 Moves the entry at index j higher, if necessary, to restore the heap property. \u2217/\n22 protected void upheap(int j)\n{\n23 while (j > 0) // continue until reaching root (or break statement)\n{\n24 int p = parent(j);\n25 if (compare(heap.get(j), heap.get(p)) >= 0) break; // heap property verified\n26 swap(j, p);\n27 j = p; // continue from the parent's location\n28\n}\n29\n}\nCode Fragment 9.8: Priority queue that uses an array-based heap and extends\nAbstractPriorityQueue(CodeFragment9.5). (Continues inCodeFragment9.9.)\nwww.it-ebooks.info\n378 Chapter9. PriorityQueues\n30 /\u2217\u2217 Moves the entry at index j lower, if necessary, to restore the heap property. \u2217/\n31 protected void downheap(int j)\n{\n32 while (hasLeft(j)) // continue to bottom (or break statement)\n{\n33 int leftIndex = left(j);\n34 int smallChildIndex = leftIndex; // although right may be smaller\n35 if (hasRight(j))\n{\n36 int rightIndex = right(j);\n37 if (compare(heap.get(leftIndex), heap.get(rightIndex)) > 0)\n38 smallChildIndex = rightIndex; // right child is smaller\n39\n}\n40 if (compare(heap.get(smallChildIndex), heap.get(j)) >= 0)\n41 break; // heap property has been restored\n42 swap(j, smallChildIndex);\n43 j = smallChildIndex; // continue at position of the child\n44\n}\n45\n}\n46\n47 // public methods\n48 /\u2217\u2217 Returns the number of items in the priority queue. \u2217/\n49 public int size() return heap.size();\n50 /\u2217\u2217 Returns (but { does not remove) an e } ntry with minimal key (if any). \u2217/\n51 public Entry<K,V> min()\n{\n52 if (heap.isEmpty()) return null;\n53 return heap.get(0);\n54\n55 } /\u2217\u2217 Inserts a key-value pair and returns the entry created. \u2217/\n56 public Entry<K,V> insert(K key, V value) throws IllegalArgumentException\n{\n57 checkKey(key); // auxiliary key-checking method (could throw exception)\n58 Entry<K,V> newest = new PQEntry<>(key, value);\n59 heap.add(newest); // add to the end of the list\n60 upheap(heap.size() 1); // upheap newly added entry\n\u2212\n61 return newest;\n62\n63 } /\u2217\u2217 Removes and returns an entry with minimal key (if any). \u2217/\n64 public Entry<K,V> removeMin()\n{\n65 if (heap.isEmpty()) return null;\n66 Entry<K,V> answer = heap.get(0);\n67 swap(0, heap.size() 1); // put minimum item at the end\n\u2212\n68 heap.remove(heap.size() 1); // and remove it from the list;\n\u2212\n69 downheap(0); // then fix new root\n70 return answer;\n71\n}\n72\n}\nCodeFragment9.9: Priorityqueueimplemented withanarray-based heap(contin-\nuedfromCodeFragment9.8).\nwww.it-ebooks.info\n9.3. Heaps 379\n9.3.3 Analysis of a Heap-Based Priority Queue\nTable9.3 showsthe running timeof thepriority queue ADTmethods for theheap\nimplementation of a priority queue, assuming that two keys can be compared in\nO(1)timeandthattheheapT isimplementedwithanarray-based orlinked-based\ntreerepresentation.\nInshort,eachofthepriorityqueue ADTmethodscanbeperformed inO(1)or\nin O(logn) time, where n is the number of entries at the time the method is exe-\ncuted. Theanalysis oftherunningtimeofthemethodsisbasedonthefollowing:\nTheheapT hasnnodes,eachstoring areference toakey-value entry.\n\u2022\nTheheightofheapT isO(logn),sinceT iscomplete(Proposition 9.2).\n\u2022\nTheminoperation runsinO(1)becausetherootofthetreecontainssuchan\n\u2022\nelement.\nLocating the last position of a heap, as required for insert and removeMin,\n\u2022\ncanbeperformedinO(1)timeforanarray-basedrepresentation, orO(logn)\ntimeforalinked-tree representation. (SeeExerciseC-9.33.)\nIn the worst case, up-heap and down-heap bubbling perform a number of\n\u2022\nswapsequaltotheheightofT.\nMethod RunningTime\nsize,isEmpty O(1)\nmin O(1)\ninsert O(logn)\u2217\nremoveMin O(logn)\u2217\n\u2217amortized, ifusingdynamicarray\nTable 9.3: Performance of a priority queue realized by means of a heap. We let n\ndenote the number of entries in the priority queue at the time an operation is ex-\necuted. The space requirement is O(n). The running time of operations min and\nremoveMin are amortized for an array-based representation, due to occasional re-\nsizingofadynamicarray;thoseboundsareworstcasewithalinkedtreestructure.\nWe conclude that the heap data structure is a very efficient realization of the\npriorityqueueADT,independentofwhethertheheapisimplementedwithalinked\nstructure or an array. The heap-based implementation achieves fast running times\nforbothinsertionandremoval,unliketheimplementationsthatwerebasedonusing\nanunsortedorsortedlist.\nwww.it-ebooks.info\n380 Chapter9. PriorityQueues\n9.3.4 Bottom-Up Heap Construction \u22c6\nIf we start with an initially empty heap, n successive calls to the insert operation\nwill run in O(nlogn) time in the worst case. However, if all n key-value pairs to\nbe stored in the heap are given in advance, such as during the first phase of the\nheap-sortalgorithm (introducedinSection9.4.2),thereisanalternativebottom-up\nconstruction methodthatrunsinO(n)time.\nIn this section, we describe the bottom-up heap construction, and provide an\nimplementation thatcanbeusedbytheconstructor ofaheap-based priorityqueue.\nForsimplicity of exposition, wedescribe this bottom-up heap construction as-\nsuming the number of keys, n, is an integer such that n = 2h+1 1. That is,\n\u2212\nthe heap is a complete binary tree with every level being full, so the heap has\nheight h = log(n+1) 1. Viewed nonrecursively, bottom-up heap construction\n\u2212\nconsists ofthefollowingh+1=log(n+1)steps:\n1. In the first step (see Figure 9.5b), we construct (n+1)/2 elementary heaps\nstoring oneentryeach.\n2. Inthesecondstep(seeFigure9.5c\u2013d),weform(n+1)/4heaps,eachstoring\nthree entries, by joining pairs of elementary heaps and adding a new entry.\nThe new entry is placed at the root and may have to be swapped with the\nentrystoredatachildtopreservetheheap-order property.\n3. In the third step (see Figure 9.5e\u2013f), we form (n+1)/8 heaps, each storing\n7entries, byjoiningpairsof3-entry heaps(constructed inthepreviousstep)\nandaddinganewentry. Thenewentryisplacedinitiallyattheroot,butmay\nhave to move down with a down-heap bubbling to preserve the heap-order\nproperty.\n.\n.\n.\ni. Inthegenericithstep,2 i h,weform(n+1)/2iheaps,eachstoring2i 1\n\u2264 \u2264 \u2212\nentries,byjoiningpairsofheapsstoring(2i\u22121 1)entries(constructedinthe\n\u2212\nprevious step) and adding a new entry. The new entry is placed initially at\ntheroot,butmayhavetomovedownwithadown-heapbubblingtopreserve\ntheheap-order property.\n.\n.\n.\nh+1. In the last step (see Figure 9.5g\u2013h), we form the final heap, storing all the\nn entries, by joining two heaps storing (n 1)/2 entries (constructed in the\n\u2212\nprevious step) and adding a new entry. The new entry is placed initially at\ntheroot,butmayhavetomovedownwithadown-heapbubblingtopreserve\ntheheap-order property.\nWeillustrate bottom-upheapconstruction inFigure9.5forh=3.\nwww.it-ebooks.info\n9.3. Heaps 381\n16 15 4 12 6 7 23 20\n(a) (b)\n25 9 11 17 15 4 6 17\n16 15 4 12 6 7 23 20 16 25 9 12 11 7 23 20\n(c) (d)\n5 8 4 6\n15 4 6 17 15 5 7 17\n16 25 9 12 11 7 23 20 16 25 9 12 11 8 23 20\n(e) (f)\n14 4\n4 6 5 6\n15 5 7 17 15 9 7 17\n16 25 9 12 11 8 23 20 16 25 14 12 11 8 23 20\n(g) (h)\nFigure9.5: Bottom-upconstructionofaheapwith15entries: (aandb)webeginby\nconstructing 1-entry heaps onthebottom level;(c andd)wecombinethese heaps\ninto 3-entry heaps; (e and f) we build 7-entry heaps; (g and h) we create the final\nheap. The paths of the down-heap bubblings are highlighted in (d, f, and h). For\nsimplicity, weonlyshowthekeywithineachnodeinsteadoftheentireentry.\nwww.it-ebooks.info\n382 Chapter9. PriorityQueues\nJava Implementation of a Bottom-Up Heap Construction\nImplementing a bottom-up heap construction is quite easy, given the existence of\na \u201cdown-heap\u201d utility method. The \u201cmerging\u201d of two equally sized heaps that are\nsubtrees of a common position p, as described in the opening of this section, can\nbe accomplished simply by down-heaping p\u2019s entry. For example, that is what\nhappened tothekey14ingoingfromFigure9.5(f)to(g).\nWithourarray-based representation ofaheap, ifweinitially store allnentries\ninarbitraryorderwithinthearray,wecanimplementthebottom-upheapconstruc-\ntion process with a single loop that makes a call to downheap from each position\nof the tree, as long as those calls are ordered starting with the deepest level and\nendingwiththerootofthetree. Infact,thatloopcanstartwiththedeepestinternal\nposition, sincethereisnoeffectwhendown-heap iscalledatanexternalposition.\nInCodeFragment9.10,weaugmenttheoriginalHeapPriorityQueueclassfrom\nSection9.3.2toprovidesupportforthebottom-upconstruction ofaninitialcollec-\ntion. We introduce a nonpublic utility method, heapify, that calls downheap on\neachnonleafposition, beginning withthedeepestandconcluding withacallatthe\nrootofthetree.\nWe introduce an additional constructor for the class that accepts an initial se-\nquence of keys and values, parameterized as two coordinate arrays that are pre-\nsumed to have the same length. We create new entries, pairing the first key with\nthe first value, the second key with the second value, and so on. We then call the\nheapify utility to establish the heap ordering. For brevity, we omit a similar con-\nstructorthatacceptsanondefault comparatorforthepriorityqueue.\n/\u2217\u2217 Creates a priority queue initialized with the given key-value pairs. \u2217/\npublic HeapPriorityQueue(K[ ] keys, V[ ] values)\n{\nsuper();\nfor (int j=0; j < Math.min(keys.length, values.length); j++)\nheap.add(new PQEntry<>(keys[j], values[j]));\nheapify();\n}\n/\u2217\u2217 Performs a bottom-up construction of the heap in linear time. \u2217/\nprotected void heapify()\n{\nint startIndex = parent(size() 1); // start at PARENT of last entry\n\u2212\nfor (int j=startIndex; j >= 0; j ) // loop until processing the root\n\u2212\u2212\ndownheap(j);\n}\nCode Fragment 9.10: Revision to the HeapPriorityQueue class of Code Frag-\nments 9.8 and 9.9, supporting linear-time construction given an initial collection\nofkey-value pairs.\nwww.it-ebooks.info\n9.3. Heaps 383\nAsymptotic Analysis of Bottom-Up Heap Construction\nBottom-up heap construction is asymptotically faster than incrementally inserting\nnentriesintoaninitiallyemptyheap. Intuitively,weareperformingasingledown-\nheap operation at each position in the tree, rather than a single up-heap operation\nfrom each. Since more nodes are closer to the bottom of a tree than the top, the\nsumofthedownwardpathsislinear, asshowninthefollowingproposition.\nProposition 9.3: Bottom-up construction ofaheapwith n entriestakes O(n)\ntime,assumingtwokeyscanbecomparedinO(1)time.\nJustification: The primary cost of the construction is due to the down-heap\nstepsperformedateachnonleafposition. Let\u03c0 denotethepathofT fromnonleaf\nv\nnode v to its \u201cinorder successor\u201d leaf, that is, the path that starts at v, goes to the\nright child of v, and then goes down leftward until it reaches a leaf. Although, \u03c0\nv\nis not necessarily the path followed by the down-heap bubbling step from v, its\nnumber of edges \u03c0 is proportional to the height of the subtree rooted at v, and\nv\nk k\nthusaboundonthecomplexity ofthedown-heap operation atv. Thetotalrunning\ntimeofthebottom-upheapconstructionalgorithmisthereforeboundedbythesum\n\u2211 \u03c0 . For intuition, Figure 9.6 illustrates the justification \u201cvisually,\u201d marking\nv v\nk k\neachedgewiththelabelofthenonleafnodevwhosepath\u03c0 contains thatedge.\nv\nWeclaim thatthepaths\u03c0 forallnonleaf vareedge-disjoint, andthusthesum\nv\nofthepathlengthsisboundedbythenumberoftotaledgesinthetree,henceO(n).\nTo show this, we consider what we term \u201cright-leaning\u201d and \u201cleft-leaning\u201d edges\n(i.e.,thosegoingfromaparenttoaright,respectivelyleft,child). Aparticularright-\nleaning edge e can only be part of the path \u03c0 for node v that is the parent in the\nv\nrelationship representedbye. Left-leaningedgescanbepartitioned byconsidering\nthe leaf that is reached if continuing down leftward until reaching a leaf. Each\nnonleafnodeonlyusesleft-leaningedgesinthegroupleadingtothatnonleafnode\u2019s\ninordersuccessor. Sinceeachnonleafnodemusthaveadifferentinordersuccessor,\nno two such paths can contain the same left-leaning edge. We conclude that the\nbottom-up construction ofheapT takesO(n)time.\n4\n4\n5 6\n5 4 6\n15 9 7 17\n15 5 9 4 7 6 17\n16 25 14 12 11 8 23 20\nFigure 9.6: Visual justification of the linear running time of bottom-up heap con-\nstruction. Eachedgeeislabeled withanodevforwhich\u03c0 containse(ifany).\nv\nwww.it-ebooks.info\n384 Chapter9. PriorityQueues\n9.3.5 Using the java.util.PriorityQueue Class\nThere is no priority queue interface built into Java, but Java does include a class,\njava.util.PriorityQueue, which implements the java.util.Queue interface. Instead\nof adding and removing elements according to the standard FIFO policy used by\nmost queues, the java.util.PriorityQueue class processes its entries according to a\npriority The \u201cfront\u201d of the queue will always be a minimal element, with priori-\nties based either on the natural ordering of the elements, or in accordance with a\ncomparator objectsentasaparameter whenconstructing thepriority queue.\nThemostnotable difference between thejava.util.PriorityQueueclass andour\nownpriority queue ADTisthemodelformanaging keysand values. Whereas our\npublicinterfacedistinguishes betweenkeysandvalues,thejava.util.PriorityQueue\nclassreliesonasingleelementtype. Thatelementiseffectively treatedasakey.\nIf a user wishes to insert distinct keys and values, the burden is on the user to\ndefineandinsertappropriatecompositeobjects,andtoensurethatthoseobjectscan\nbe compared based on their keys. (The Java Collections Framework does include\nits ownentry interface, java.util.Map.Entry,and aconcrete implementation in the\njava.util.AbstractMap.SimpleEntry class; we discuss the map ADT in the next\nchapter.)\nTable 9.4 shows the correspondance between methods of our priority queue\nADT and those of the java.util.PriorityQueue class. The java.util.PriorityQueue\nclass is implemented with a heap, so it guarantees O(logn)-time performance for\nmethods addandremove,andconstant-time performance foraccessors peek,size,\nand isEmpty. In addition, it provides a parameterized method, remove(e), that\nremoves a specific element e from the priority queue. However, that method runs\ninO(n)time,performing asequential searchtolocatetheelementwithintheheap.\n(InSection9.5,weextendourheap-basedpriorityqueueimplementationtosupport\namoreefficientmeansforremovinganarbitrary entry, orforupdating thepriority\nofanexistingentry.)\nOurPriorityQueueADT java.util.PriorityQueueClass\ninsert(k,v) add(new SimpleEntry(k,v))\nmin() peek()\nremoveMin() remove()\nsize() size()\nisEmpty() isEmpty()\nTable 9.4: Methods of our priority queue ADT and the corresponding methods\nwhenusingthejava.util.PriorityQueueclass.\nwww.it-ebooks.info\n9.4. SortingwithaPriorityQueue 385\n9.4 Sorting with a Priority Queue\nOne application of priority queues is sorting, where we are given a sequence of\nelements that can be compared according to a total order relation, and we want to\nrearrange them in increasing order (or at least in nondecreasing order if there are\nties). ThealgorithmforsortingasequenceSwithapriorityqueuePisquitesimple\nandconsists ofthefollowingtwophases:\n1. In the firstphase, weinsert the elements ofS as keys into an initially empty\npriority queue P by means of a series of n insert operations, one for each\nelement.\n2. In the second phase, weextract the elements from Pinnondecreasing order\nbymeansofaseriesofnremoveMinoperations, puttingthembackintoSin\nthatorder.\nA Java implementation of this algorithm is given in Code Fragment 9.11, as-\nsumingthatthesequence isstoredasapositional list. (Codeforadifferent typeof\ncollection, suchasanarrayoranarraylist,wouldbesimilar.)\nThe algorithm works correctly for any priority queue P, no matter how P is\nimplemented. However, the running time of the algorithm is determined by the\nrunning times of operations insert and removeMin, which do depend on how P\nis implemented. Indeed, pqSort should be considered more a sorting \u201cscheme\u201d\nthan a sorting \u201calgorithm,\u201d because it does not specify how the priority queue P\nis implemented. The pqSort scheme is the paradigm of several popular sorting\nalgorithms, including selection-sort, insertion-sort, and heap-sort, which we will\ndiscussinthissection.\n1 /\u2217\u2217 Sorts sequence S, using initially empty priority queue P to produce the order. \u2217/\n2 public static <E> void pqSort(PositionalList<E> S, PriorityQueue<E,?> P)\n{\n3 int n = S.size();\n4 for (int j=0; j < n; j++)\n{\n5 E element = S.remove(S.first());\n6 P.insert(element, null); // element is key; null value\n7\n}\n8 for (int j=0; j < n; j++)\n{\n9 E element = P.removeMin().getKey();\n10 S.addLast(element); // the smallest key in P is next placed in S\n11\n}\n12\n}\nCodeFragment9.11: Animplementation ofapqSortmethodthatsortselementsof\napositional listusinganinitiallyemptypriority queuetoproduce theordering.\nwww.it-ebooks.info\n386 Chapter9. PriorityQueues\n9.4.1 Selection-Sort and Insertion-Sort\nWe next demonstrate how the pqSort scheme results in two classic sorting algo-\nrithmswhenusinganunsorted orsortedlistforapriorityqueue.\nSelection-Sort\nInPhase1ofthepqSortscheme, weinsert allelements intoapriority queue P;in\nPhase 2 we repeatedly remove the minimal element from P using the removeMin\nmethod. IfweimplementPwithanunsortedlist,thenPhase1ofpqSorttakesO(n)\ntime, forwecan insert each element inO(1)time. InPhase2, therunning timeof\neach removeMin operation is proportional to the size of P. Thus, the bottleneck\ncomputation is the repeated \u201cselection\u201d of the minimum element in Phase 2. For\nthisreason, thisalgorithm isbetterknownasselection-sort. (SeeFigure9.7.)\nSequenceS PriorityQueueP\nInput (7, 4, 8, 2, 5, 3, 9) ()\nPhase1 (a) (4, 8, 2, 5, 3, 9) (7)\n(b) (8, 2, 5, 3, 9) (7, 4)\n. . .\n. . .\n. . .\n(g) () (7, 4, 8, 2, 5, 3, 9)\nPhase2 (a) (2) (7, 4, 8, 5, 3, 9)\n(b) (2, 3) (7, 4, 8, 5, 9)\n(c) (2, 3, 4) (7, 8, 5, 9)\n(d) (2, 3, 4, 5) (7, 8, 9)\n(e) (2, 3, 4, 5, 7) (8, 9)\n(f) (2, 3, 4, 5, 7, 8) (9)\n(g) (2, 3, 4, 5, 7, 8, 9) ()\nFigure9.7: Executionofselection-sort onsequence S=(7, 4, 8, 2, 5, 3, 9).\nAs noted above, the bottleneck is in Phase 2 where we repeatedly remove an\nentry with smallest key from the priority queue P. The size of P starts at n and\nincrementally decreases with each removeMin until it becomes 0. Thus, the first\nremoveMinoperation takes timeO(n),thesecond onetakes timeO(n 1),andso\n\u2212\non, until the last (nth)operation takes time O(1). Therefore, the total time needed\nforthesecondphaseis\nn\nO(n+(n 1)+ +2+1)=O \u2211i .\n\u2212 \u00b7\u00b7\u00b7\ni=1 !\nByProposition 4.3, wehave \u2211n i=n(n+1)/2. Thus, Phase 2takes timeO(n2),\ni=1\nasdoestheentireselection-sort algorithm.\nwww.it-ebooks.info\n9.4. SortingwithaPriorityQueue 387\nInsertion-Sort\nIf we implement the priority queue P using a sorted list, then the running time of\nPhase2improvestoO(n),foreachoperationremoveMinonPnowtakesO(1)time.\nUnfortunately, Phase1nowbecomes thebottleneck fortherunning time,since, in\nthe worst case, each insert operation takes timeproportional tothe size ofP. This\nsorting algorithm is therefore better known as insertion-sort (see Figure 9.8), for\nthe bottleneck in this sorting algorithm involves the repeated \u201cinsertion\u201d of a new\nelementattheappropriate position inasortedlist.\nSequenceS PriorityQueueP\nInput (7, 4, 8, 2, 5, 3, 9) ()\nPhase1 (a) (4, 8, 2, 5, 3, 9) (7)\n(b) (8, 2, 5, 3, 9) (4, 7)\n(c) (2, 5, 3, 9) (4, 7, 8)\n(d) (5, 3, 9) (2, 4, 7, 8)\n(e) (3, 9) (2, 4, 5, 7, 8)\n(f) (9) (2, 3, 4, 5, 7, 8)\n(g) () (2, 3, 4, 5, 7, 8, 9)\nPhase2 (a) (2) (3, 4, 5, 7, 8, 9)\n(b) (2, 3) (4, 5, 7, 8, 9)\n. . .\n. . .\n. . .\n(g) (2, 3, 4, 5, 7, 8, 9) ()\nFigure 9.8: Execution of insertion-sort on sequence S = (7, 4, 8, 2, 5, 3, 9). In\nPhase1,werepeatedlyremovethefirstelementofSandinsertitintoP. InPhase2,\nwerepeatedlyperformtheremoveMinoperationonPandaddthereturnedelement\ntotheendofS.\nAnalyzing therunning timeofPhase1ofinsertion-sort, wenotethatitis\nn\nO(1+2+...+(n 1)+n)=O \u2211i .\n\u2212\ni=1 !\nAgain,byrecallingProposition4.3,Phase1runsinO(n2)time,andhence,sodoes\ntheentireinsertion-sort algorithm.\nAlternatively, wecouldchangeourdefinitionofinsertion-sort sothatweinsert\nelements starting from the end of the priority-queue list in Phase 1, in which case\nperforming insertion-sort on a sequence that is already sorted would run in O(n)\ntime. Indeed, therunning timeof insertion-sort in this case isO(n+I), where I is\nthe number of inversions in the sequence, that is, the number of pairs of elements\nthatstartoutintheinputsequence inthewrongrelativeorder.\nwww.it-ebooks.info\n388 Chapter9. PriorityQueues\n9.4.2 Heap-Sort\nAs we have previously observed, realizing a priority queue with a heap has the\nadvantagethatallthemethodsinthepriorityqueueADTruninlogarithmictimeor\nbetter. Hence, this realization issuitable for applications where fast running times\nare sought for all the priority queue methods. Therefore, let us again consider the\npqSortscheme,thistimeusingaheap-based implementation ofthepriorityqueue.\nDuringPhase1,theith insertoperationtakesO(logi)time,sincetheheaphasi\nentriesaftertheoperationisperformed. Therefore,thisphasetakesO(nlogn)time.\n(It could be improved to O(n) with the bottom-up heap construction described in\nSection9.3.4.)\nDuring thesecond phase ofmethod pqSort, the jth removeMin operation runs\nin O(log(n j+1)), since the heap has n j+1entries atthe timethe operation\n\u2212 \u2212\nis performed. Summing over all j, this phase takes O(nlogn) time, so the entire\npriority-queue sorting algorithm runs in O(nlogn) time when we use a heap to\nimplementthepriority queue. Thissortingalgorithm isbetterknownasheap-sort,\nanditsperformance issummarizedinthefollowingproposition.\nProposition 9.4: Theheap-sortalgorithmsortsasequence S ofn elementsin\nO(nlogn)time,assumingtwoelementsofScanbecomparedinO(1)time.\nLetusstressthattheO(nlogn)runningtimeofheap-sortisconsiderably better\nthantheO(n2)runningtimeofselection-sort andinsertion-sort.\nImplementing Heap-Sort In-Place\nIfthesequenceStobesortedisimplementedbymeansofanarray-basedsequence,\nsuch as an ArrayList in Java, we can speed up heap-sort and reduce its space re-\nquirement by a constant factor by using a portion of the array itself to store the\nheap, thus avoiding the use of an auxiliary heap data structure. This is accom-\nplishedbymodifying thealgorithm asfollows:\n1. We redefine the heap operations to be a maximum-oriented heap, with each\nposition key being at least as large as its children. This can be done by re-\ncoding the algorithm, or by providing a new comparator that reverses the\noutcome of each comparison. At any time during the execution of the al-\ngorithm, we use the left portion of S, up to a certain index i 1, to store\n\u2212\nthe entries of the heap, and the right portion of S, from index i to n 1, to\n\u2212\nstore theelements ofthesequence. Thus,thefirstielements ofS(atindices\n0,...,i 1)providethearray-list representation oftheheap.\n\u2212\n2. Inthefirstphaseofthealgorithm,westartwithanemptyheapandmovethe\nboundary betweentheheapandthesequence fromlefttoright,onestepata\ntime. Instepi,fori=1,...,n,weexpand theheapbyadding theelementat\nindexi 1.\n\u2212\nwww.it-ebooks.info\n9.4. SortingwithaPriorityQueue 389\n3. In the second phase of the algorithm, we start with an empty sequence and\nmovetheboundarybetweentheheapandthesequencefromrighttoleft,one\nstepatatime. Atstepi,fori=1,...,n,weremoveamaximalelementfrom\ntheheapandstoreitatindexn i.\n\u2212\nIn general, we say that a sorting algorithm is in-place if it uses only a small\namountofmemoryinadditiontothesequencestoringtheobjectstobesorted. The\nvariation of heap-sort above qualifies as in-place; instead of transferring elements\nout of the sequence and then back in, wesimply rearrange them. Weillustrate the\nsecondphaseofin-place heap-sort inFigure9.9.\n9\n(a) 9 7 5 2 6 4 7 5\n2 6 4\n7\n(b) 7 6 5 2 4 9 6 5\n2 4\n6\n(c) 6 4 5 2 7 9 4 5\n2\n5\n(d) 5 4 2 6 7 9\n4 2\n4\n(e) 4 2 5 6 7 9\n2\n(f) 2 4 5 6 7 9 2\nFigure 9.9: Phase 2 of an in-place heap-sort. The heap portion of each sequence\nrepresentationishighlighted. Thebinarytreethateachsequence(implicitly)repre-\nsentsisdiagrammedwiththemostrecentpathofdown-heapbubblinghighlighted.\nwww.it-ebooks.info\n390 Chapter9. PriorityQueues\n9.5 Adaptable Priority Queues\nThe methods of the priority queue ADT given in Section 9.1.2 are sufficient for\nmost basic applications of priority queues, such as sorting. However, there are\nsituations inwhichadditional methodswouldbeuseful, asshownbythescenarios\nbelowinvolving thestandby airlinepassenger application.\nAstandbypassengerwithapessimisticattitudemaybecometiredofwaiting\n\u2022\nand decide to leave ahead of the boarding time, requesting to be removed\nfromthewaitinglist. Thus,wewouldliketoremovefromthepriorityqueue\ntheentryassociatedwiththispassenger. OperationremoveMindoesnotsuf-\nfice since the passenger leaving does not necessarily have first priority. In-\nstead, wewantanewoperation, remove,thatremovesanarbitrary entry.\nAnother standby passenger finds her gold frequent-flyer card and shows it\n\u2022\nto the agent. Thus, her priority has to be modified accordingly. To achieve\nthis change of priority, we would like to have a new operation replaceKey\nallowingustoreplacethekeyofanexistingentrywithanewkey.\nFinally,athirdstandbypassengernoticeshernameismisspelledontheticket\n\u2022\nand asks it to be corrected. To perform this change, we need to update the\npassenger\u2019s record. Hence, we would like to have a new operation replace-\nValue,allowingustoreplacethevalueofanexistingentrywithanewvalue.\nThe Adaptable Priority Queue ADT\nThe above scenarios motivate the definition of a new adaptable priority queue\nADT that extends the priority queue ADT with additional functionality. We will\nsee another application of adaptable priority queues when implementing certain\ngraphalgorithmsinSections14.6.2and14.7.1.\nIn order to implement methods remove, replaceKey, and replaceValue effi-\nciently, weneed amechanism forfindingauser\u2019s element within apriority queue,\nideallyinawaythatavoidsperformingalinearsearchthroughtheentirecollection.\nIn the original definition of the priority queue ADT, a call to insert(k, v) formally\nreturns an instance of type Entry to the user. In order to be able to update or re-\nmove an entry in our new adaptable priority queue ADT,the user must retain that\nEntryobjectasatokenthatcanbesentbackasaparametertoidentifytherelevant\nentry. Formally,theadaptable priority queueADTincludes thefollowing methods\n(inadditiontothoseofthestandard priorityqueue):\nremove(e): Removesentryefromthepriorityqueue.\nreplaceKey(e,k): Replacesthekeyofexisting entryewithk.\nreplaceValue(e,v): Replacesthevalueofexistingentryewithv.\nAnerror occurs witheach ofthese methods ifparameter eis invalid (for example,\nbecauseithadpreviously beenremovedfromthepriorityqueue).\nwww.it-ebooks.info\n9.5. AdaptablePriorityQueues 391\n9.5.1 Location-Aware Entries\nTo allow an entry instance to encode a location within a priority queue, we ex-\ntend the PQEntry class (originally defined with the AbstractPriorityQueue base\nclass), adding a third field that designates the current index of an entry within the\narray-based representation oftheheap, asshowninFigure9.10. (Thisapproach is\nsimilar to our recommendation, on page 281, for implementing the positional list\nabstraction withanarray.)\ntoken\n(4,C,0) (5,A,1) (6,Z,2) (15,K,3) (9,F,4) (7,Q,5) (20,B,6) (16,X,7)\n0 1 2 3 4 5 6 7\nFigure9.10:Representingaheapusinganarrayoflocation-awareentries. Thethird\nfieldofeach entry instance corresponds tothe index of that entry within thearray.\nIdentifiertokenispresumedtobeanentryreference intheuser\u2019sscope.\nWhenweperform priority queue operations onour heap, causing entries tobe\nrelocated withinour structure, wemustmake sure toupdate thethird fieldofeach\naffected entrytoreflectitsnewindexwithinthearray. Asanexample,Figure9.11\nshowsthestateoftheaboveheapafteracalltoremoveMin(). Theheapoperation\ncauses the minimal entry, (4,C), to be removed, and the last entry, (16,X), to be\ntemporarily moved from the last position to the root, followed by a down-heap\nbubblephase. Duringthedown-heap,element(16,X)isswappedwithitsleftchild,\n(5,A), at index 1 of the list, then swapped with its right child, (9,F), at index 4 of\nthe list. In the final configuration, the last field for all affected entries has been\nmodifiedtoreflecttheirnewlocation.\ntoken\n(5,A,0) (9,F,1) (6,Z,2) (15,K,3) (16,X,4) (7,Q,5) (20,B,6)\n0 1 2 3 4 5 6 7\nFigure9.11: TheresultofacalltoremoveMin()ontheheaporiginallyportrayedin\nFigure9.10. Identifiertokencontinuestoreferencethesameentryasintheoriginal\nconfiguration, but the placement of that entry in the array has changed, as has the\nthirdfieldoftheentry.\nwww.it-ebooks.info\n392 Chapter9. PriorityQueues\n9.5.2 Implementing an Adaptable Priority Queue\nCode Fragments 9.12 and 9.13 present a Java implementation of an adaptable pri-\nority queue, as a subclass of the HeapPriorityQueue class from Section 9.3.2. We\nbegin by defining a nested AdaptablePQEntry class (lines 5\u201315) that extends the\ninherited PQEntry class, augmenting it with an additional index field. The inher-\nited insert method is overridden, so that wecreate and initialize an instance of the\nAdaptablePQEntryclass(nottheoriginal PQEntryclass).\nAnimportantaspectofourdesignisthattheoriginal HeapPriorityQueueclass\nreliesexclusivelyonaprotectedswapmethodforalllow-leveldatamovementdur-\ningup-heapordown-heapoperations. TheAdaptablePriorityQueueclassoverrides\nthatutility inordertoupdatethestored indices ofourlocation-aware entries when\ntheyarerelocated (asdiscussed onthepreviouspage).\nWhen an entry is sent as a parameter to remove, replaceKey, or replaceValue,\nwerelyonthenewindexfieldofthatentry todesignate wheretheelement resides\nin the heap (a fact that is easily validated). When a key of an existing entry is\nreplaced, that new key may violate the heap-order property by being either too\nbig or too small. We provide a new bubble utility that determines whether an up-\nheap ordown-heap bubbling stepiswarranted. Whenremoving anarbitrary entry,\nwe replace it with the last entry in the heap (to maintain the complete binary tree\nproperty) and perform the bubbling step, since the displaced element may have a\nkeythatistoolargeortoosmallforitsnewlocation.\nPerformance of Adaptable Priority Queue Implementations\nThe performance of an adaptable priority queue by means of our location-aware\nheapstructureissummarizedinTable9.5. Thenewclassprovidesthesameasymp-\ntotic efficiency and space usage asthe nonadaptive version, and provides logarith-\nmic performance for the new locator-based remove and replaceKey methods, and\nconstant-time performance forthenewreplaceValuemethod.\nMethod RunningTime\nsize,isEmpty,min O(1)\ninsert O(logn)\nremove O(logn)\nremoveMin O(logn)\nreplaceKey O(logn)\nreplaceValue O(1)\nTable9.5: Runningtimesofthemethodsofanadaptablepriorityqueuewithsizen,\nrealized by means of our array-based heap representation. The space requirement\nisO(n).\nwww.it-ebooks.info\n9.5. AdaptablePriorityQueues 393\n1 /\u2217\u2217 An implementation of an adaptable priority queue using an array-based heap. \u2217/\n2 public class HeapAdaptablePriorityQueue<K,V> extends HeapPriorityQueue<K,V>\n3 implements AdaptablePriorityQueue<K,V>\n{\n4\n5 //----------------nested AdaptablePQEntry class ----------------\n6 /\u2217\u2217 Extension of the PQEntry to include location information. \u2217/\n7 protected static class AdaptablePQEntry<K,V> extends PQEntry<K,V>\n{\n8 private int index; // entry\u2019s current index within the heap\n9 public AdaptablePQEntry(K key, V value, int j)\n{\n10 super(key, value); // this sets the key and value\n11 index = j; // this sets the new field\n12\n}\n13 public int getIndex() return index;\n{ }\n14 public void setIndex(int j) index = j;\n{ }\n15 //-----------end of nested AdaptablePQEntry class -----------\n}\n16\n17 /\u2217\u2217 Creates an empty adaptable priority queue using natural ordering of keys. \u2217/\n18 public HeapAdaptablePriorityQueue() super();\n19 /\u2217\u2217 Creates an empty adaptable priority { queue usin } g the given comparator. \u2217/\n20 public HeapAdaptablePriorityQueue(Comparator<K> comp) super(comp);\n{ }\n21\n22 // protected utilites\n23 /\u2217\u2217 Validates an entry to ensure it is location-aware. \u2217/\n24 protected AdaptablePQEntry<K,V> validate(Entry<K,V> entry)\n25 throws IllegalArgumentException\n{\n26 if (!(entry instanceof AdaptablePQEntry))\n27 throw new IllegalArgumentException(\"Invalid entry\");\n28 AdaptablePQEntry<K,V> locator = (AdaptablePQEntry<K,V>) entry; // safe\n29 int j = locator.getIndex();\n30 if (j >= heap.size() heap.get(j) != locator)\n||\n31 throw new IllegalArgumentException(\"Invalid entry\");\n32 return locator;\n33\n}\n34\n35 /\u2217\u2217 Exchanges the entries at indices i and j of the array list. \u2217/\n36 protected void swap(int i, int j)\n{\n37 super.swap(i,j); // perform the swap\n38 ((AdaptablePQEntry<K,V>) heap.get(i)).setIndex(i); // reset entry's index\n39 ((AdaptablePQEntry<K,V>) heap.get(j)).setIndex(j); // reset entry's index\n40\n}\nCodeFragment9.12: An implementation of an adaptable priority queue. (Contin-\nues in Code Fragment 9.13.) This extends the HeapPriorityQueue class of Code\nFragments9.8and9.9.\nwww.it-ebooks.info\n394 Chapter9. PriorityQueues\n41 /\u2217\u2217 Restores the heap property by moving the entry at index j upward/downward.\u2217/\n42 protected void bubble(int j)\n{\n43 if (j > 0 && compare(heap.get(j), heap.get(parent(j))) < 0)\n44 upheap(j);\n45 else\n46 downheap(j); // although it might not need to move\n47\n}\n48\n49 /\u2217\u2217 Inserts a key-value pair and returns the entry created. \u2217/\n50 public Entry<K,V> insert(K key, V value) throws IllegalArgumentException\n{\n51 checkKey(key); // might throw an exception\n52 Entry<K,V> newest = new AdaptablePQEntry<>(key, value, heap.size());\n53 heap.add(newest); // add to the end of the list\n54 upheap(heap.size() 1); // upheap newly added entry\n\u2212\n55 return newest;\n56\n}\n57\n58 /\u2217\u2217 Removes the given entry from the priority queue. \u2217/\n59 public void remove(Entry<K,V> entry) throws IllegalArgumentException\n{\n60 AdaptablePQEntry<K,V> locator = validate(entry);\n61 int j = locator.getIndex();\n62 if (j == heap.size() 1) // entry is at last position\n\u2212\n63 heap.remove(heap.size() 1); // so just remove it\n\u2212\n64 else\n{\n65 swap(j, heap.size() 1); // swap entry to last position\n\u2212\n66 heap.remove(heap.size() 1); // then remove it\n\u2212\n67 bubble(j); // and fix entry displaced by the swap\n68\n}\n69\n}\n70\n71 /\u2217\u2217 Replaces the key of an entry. \u2217/\n72 public void replaceKey(Entry<K,V> entry, K key)\n73 throws IllegalArgumentException\n{\n74 AdaptablePQEntry<K,V> locator = validate(entry);\n75 checkKey(key); // might throw an exception\n76 locator.setKey(key); // method inherited from PQEntry\n77 bubble(locator.getIndex()); // with new key, may need to move entry\n78\n}\n79\n80 /\u2217\u2217 Replaces the value of an entry. \u2217/\n81 public void replaceValue(Entry<K,V> entry, V value)\n82 throws IllegalArgumentException\n{\n83 AdaptablePQEntry<K,V> locator = validate(entry);\n84 locator.setValue(value); // method inherited from PQEntry\n85\n}\nCodeFragment9.13: Animplementation ofanadaptablepriorityqueue(continued\nfromCodeFragment9.12).\nwww.it-ebooks.info\n9.6. Exercises 395\n9.6 Exercises\nReinforcement\nR-9.1 Howlongwouldittaketoremovethe logn smallestelementsfromaheapthat\n\u2308 \u2309\ncontainsnentries,usingtheremoveMinoperation?\nR-9.2 SupposeyousetthekeyforeachpositionpofabinarytreeT equaltoitspreorder\nrank.UnderwhatcircumstancesisT aheap?\nR-9.3 WhatdoeseachremoveMincallreturnwithinthefollowingsequenceofpriority\nqueue ADT operations: insert(5, A), insert(4, B), insert(7, F), insert(1, D),\nremoveMin(),insert(3,J),insert(6,L),removeMin(),\nremoveMin(),insert(8,G),removeMin(),insert(2,H),removeMin(),\nremoveMin()?\nR-9.4 Anairportisdevelopingacomputersimulationofair-trafficcontrolthathandles\neventssuch aslandingsand takeoffs. Eacheventhasatime stamp thatdenotes\nthetimewhentheeventwilloccur. Thesimulationprogramneedstoefficiently\nperformthefollowingtwofundamentaloperations:\nInsertaneventwithagiventimestamp(thatis,addafutureevent).\n\u2022\nExtracttheeventwithsmallesttimestamp(thatis,determinethenextevent\n\u2022\ntoprocess).\nWhichdatastructureshouldbeusedfortheaboveoperations?Why?\nR-9.5 TheminmethodfortheUnsortedPriorityQueueclassexecutesinO(n)time,as\nanalyzedinTable9.2.Giveasimplemodificationtotheclasssothatminrunsin\nO(1)time. Explainanynecessarymodificationstoothermethodsoftheclass.\nR-9.6 CanyouadaptyoursolutiontothepreviousproblemtomakeremoveMinrunin\nO(1)timefortheUnsortedPriorityQueueclass? Explainyouranswer.\nR-9.7 Illustratetheexecutionoftheselection-sortalgorithmonthefollowinginputse-\nquence:(22, 15, 36, 44, 10, 3, 9, 13, 29, 25).\nR-9.8 Illustrate the executionof the insertion-sortalgorithmon the inputsequenceof\nthepreviousproblem.\nR-9.9 Giveanexampleofaworst-casesequencewithnelementsforinsertion-sort,and\nshowthatinsertion-sortrunsin\u2126(n2)timeonsuchasequence.\nR-9.10 Atwhichpositionsofaheapmightthethirdsmallestkeybestored?\nR-9.11 Atwhichpositionsofaheapmightthelargestkeybestored?\nR-9.12 Considerasituationinwhichauserhasnumerickeysandwishestohaveapri-\norityqueuethatismaximum-oriented. Howcouldastandard(min-oriented)pri-\norityqueuebeusedforsuchapurpose?\nR-9.13 Illustratetheexecutionofthein-placeheap-sortalgorithmonthefollowinginput\nsequence:(2, 5, 16, 4, 10, 23, 39, 18, 26, 15).\nwww.it-ebooks.info\n396 Chapter9. PriorityQueues\nR-9.14 LetT beacompletebinarytreesuchthatposition pstoresanelementwithkey\nf(p),where f(p)isthelevelnumberof p(seeSection8.3.2). IstreeT aheap?\nWhyorwhynot?\nR-9.15 Explainwhythe descriptionof down-heapbubblingdoesnotconsiderthe case\ninwhichposition phasarightchildbutnotaleftchild.\nR-9.16 Is there a heap H storing seven entries with distinct keys such that a preorder\ntraversalofH yieldstheentriesofH inincreasingordecreasingorderbykey?\nHowaboutaninordertraversal? Howaboutapostordertraversal? Ifso,givean\nexample;ifnot,saywhy.\nR-9.17 LetH beaheapstoring15entriesusingthearray-basedrepresentationofacom-\npletebinarytree. Whatisthesequenceofindicesofthearraythatarevisitedin\napreordertraversalofH? WhataboutaninordertraversalofH? Whatabouta\npostordertraversalofH?\nn\nR-9.18 Showthatthesum\u2211logi,appearingintheanalysisofheap-sort,is\u2126(nlogn).\ni=1\nR-9.19 Billclaimsthatapreordertraversalofaheapwilllistitskeysinnondecreasing\norder.Drawanexampleofaheapthatproveshimwrong.\nR-9.20 Hillaryclaimsthatapostordertraversalofaheapwilllistitskeysinnonincreas-\ningorder.Drawanexampleofaheapthatprovesherwrong.\nR-9.21 Illustrateallthestepsoftheadaptablepriorityqueuecallremove(e)forentrye\nstoring(16,X)intheheapofFigure9.1.\nR-9.22 IllustrateallthestepsoftheadaptablepriorityqueuecallreplaceKey(e,18)for\nentryestoring(5, A)intheheapofFigure9.1.\nR-9.23 Draw an example of a heap whose keys are all the odd numbers from 1 to 59\n(with no repeats), such that the insertion of an entry with key 32 would cause\nup-heapbubblingtoproceedallthewayuptoachildoftheroot(replacingthat\nchild\u2019skeywith32).\nR-9.24 Describe a sequence of n insertions in a heap that requires \u2126(nlogn) time to\nprocess.\nCreativity\nC-9.25 Show how to implement the stack ADT using only a priority queue and one\nadditionalintegerinstancevariable.\nC-9.26 Show how to implementthe FIFO queue ADT using only a priorityqueueand\noneadditionalintegerinstancevariable.\nC-9.27 ProfessorIdlesuggeststhefollowingsolutiontothepreviousproblem.Whenever\nanentryisinsertedintothequeue,itisassignedakeythatisequaltothecurrent\nsizeofthequeue.DoessuchastrategyresultinFIFOsemantics? Provethatitis\nsoorprovideacounterexample.\nwww.it-ebooks.info\n9.6. Exercises 397\nC-9.28 ReimplementtheSortedPriorityQueueusingaJavaarray.Makesuretomaintain\nremoveMin\u2019sO(1)performance.\nC-9.29 GiveanalternativeimplementationoftheHeapPriorityQueue\u2019supheapmethod\nthatusesrecursion(andnoloop).\nC-9.30 GiveanimplementationoftheHeapPriorityQueue\u2019sdownheapmethodthatuses\nrecursion(andnoloop).\nC-9.31 AssumethatweareusingalinkedrepresentationofacompletebinarytreeT,and\nanextrareferencetothelastnodeofthattree. Showhowtoupdatethereference\ntothelastnodeafteroperationsinsertorremoveinO(logn)time,wherenisthe\ncurrentnumberofnodesofT. Besuretohandleallpossiblecases,asillustrated\ninFigure9.12.\nC-9.32 When using a linked-tree representation for a heap, an alternative method for\nfindingthelastnodeduringaninsertioninaheapT istostore,inthelastnode\nand each leaf node of T, a reference to the leaf node immediately to its right\n(wrappingto the first node in the nextlower levelfor the rightmostleaf node).\nShowhowtomaintainsuchreferencesinO(1)timeperoperationofthepriority\nqueueADTassumingthatT isimplementedwithalinkedstructure.\nC-9.33 Wecanrepresentapathfromtheroottoagivennodeofabinarytreebymeansof\nabinarystring,where0means\u201cgototheleftchild\u201dand1means\u201cgototheright\nchild.\u201dForexample,thepathfromtheroottothenodestoring(8,W)intheheap\nofFigure9.12aisrepresentedby\u201c101.\u201d DesignanO(logn)-timealgorithmfor\nfindingthelastnodeofacompletebinarytreewithnnodes,basedontheabove\nrepresentation. Showhowthisalgorithmcanbeusedintheimplementationofa\ncompletebinarytreebymeansofalinkedstructurethatdoesnotkeepanexplicit\nreferencetothelastnodeinstance.\nC-9.34 Given a heap H and a key k, give an algorithmto computeall the entriesin H\nhavingakeylessthanorequaltok. Forexample,giventheheapofFigure9.12a\nandqueryk=7,thealgorithmshouldreporttheentrieswithkeys2,4,5,6,and7\n(butnotnecessarilyinthisorder).Youralgorithmshouldrunintimeproportional\ntothenumberofentriesreturned,andshouldnotmodifytheheap.\n(2,B) (4,C)\n(5,A) (4,C) (5,A) (6,Z)\n(15,K) (9,F) (7,Q) (6,Z) (15,K) (9,F) (7,Q) (20,B)\nw w z\n(16,X) (25,J) (14,E) (12,H) (11,S) (8,W) (20,B) (10,L) (16,X) (25,J) (14,E) (12,H)\nz\n(a) (b)\nFigure 9.12: Two cases of updating the last node in a complete binary tree after\noperation insertorremove. Nodewisthelastnodebeforeoperation insertorafter\noperationremove. Nodezisthelastnodeafteroperationinsertorbeforeoperation\nremove.\nwww.it-ebooks.info\n398 Chapter9. PriorityQueues\nC-9.35 ProvideajustificationofthetimeboundsinTable9.5.\nC-9.36 Giveanalternativeanalysisofbottom-upheapconstructionbyshowingthefol-\nlowingsummationisO(1),foranypositiveintegerh:\nh\n\u2211 i/2i .\ni=1\n(cid:0) (cid:1)\nC-9.37 Supposetwobinarytrees,T andT ,holdentriessatisfyingtheheap-orderprop-\n1 2\nerty(butnotnecessarilythecompletebinarytreeproperty). Describeamethod\nfor combining T and T into a binary tree T, whose nodes hold the union of\n1 2\ntheentriesinT andT andalsosatisfytheheap-orderproperty. Youralgorithm\n1 2\nshouldrun in time O(h +h ) where h andh are the respectiveheightsof T\n1 2 1 2 1\nandT .\n2\nC-9.38 TamarindoAirlineswantstogivea first-classupgradecoupontotheirtoplogn\nfrequentflyers, basedonthenumberofmilesaccumulated,wheren isthetotal\nnumberoftheairlines\u2019frequentflyers. Thealgorithmtheycurrentlyuse,which\nruns in O(nlogn) time, sorts the flyers by the number of miles flown and then\nscansthesortedlisttopickthetoplognflyers. Describeanalgorithmthatiden-\ntifiesthetoplognflyersinO(n)time.\nC-9.39 Explainhowtheklargestelementsfromanunorderedcollectionofsizencanbe\nfoundintimeO(n+klogn)usingamaximum-orientedheap.\nC-9.40 Explainhowtheklargestelementsfromanunorderedcollectionofsizencanbe\nfoundintimeO(nlogk)usingO(k)auxiliaryspace.\nC-9.41 Writea comparatorfornonnegativeintegersthatdeterminesorderbasedonthe\nnumberof1\u2019sineachinteger\u2019sbinaryexpansion,sothati< j ifthenumberof\n1\u2019sin the binaryrepresentationof iis less than the numberof1\u2019s in the binary\nrepresentationof j.\nC-9.42 Implementthe binarySearch algorithm (see Section 5.1.3) using a Comparator\nforanarraywithelementsofgenerictypeE.\nC-9.43 Given a class, MinPriorityQueue, that implements the minimum-oriented pri-\nority queueADT, providean implementationof aMaxPriorityQueue class that\nadaptstoprovideamaximum-orientedabstractionwithmethodsinsert,max,and\nremoveMax.Yourimplementationshouldnotmakeanyassumptionaboutthein-\nternalworkingsoftheoriginalMinPriorityQueueclass,northetypeofkeysthat\nmightbeused.\nC-9.44 Describeanin-placeversionoftheselection-sortalgorithmforanarraythatuses\nonlyO(1)spaceforinstancevariablesinadditiontothearray.\nC-9.45 AssumingtheinputtothesortingproblemisgiveninanarrayA, describehow\ntoimplementtheinsertion-sortalgorithmusingonlythearrayAandatmostsix\nadditional(base-type)variables.\nC-9.46 Giveanalternatedescriptionofthein-placeheap-sortalgorithmusingthestan-\ndardminimum-orientedpriorityqueue(insteadofamaximum-orientedone).\nwww.it-ebooks.info\n9.6. Exercises 399\nC-9.47 Agroupofchildrenwanttoplayagame,calledUnmonopoly,whereineachturn\nthe player with the most money must give half of his/her money to the player\nwith the least amountof money. Whatdata structure(s)shouldbe used to play\nthisgameefficiently?Why?\nC-9.48 Anonlinecomputersystemfortradingstocksneedstoprocessordersoftheform\n\u201cbuy100sharesat$xeach\u201dor\u201csell100sharesat$yeach.\u201d Abuyorderfor$x\ncan only be processed if there is an existing sell order with price $y such that\ny x. Likewise,asellorderfor$ycanonlybeprocessedifthereisanexisting\n\u2264\nbuy order with price $x such that y x. If a buy or sell order is entered but\n\u2264\ncannotbeprocessed,itmustwaitforafutureorderthatallowsittobeprocessed.\nDescribeaschemethatallowsbuyandsellorderstobeenteredinO(logn)time,\nindependentofwhetherornottheycanbeimmediatelyprocessed.\nC-9.49 Extendasolutiontothepreviousproblemsothatusersareallowedtoupdatethe\npricesfortheirbuyorsellordersthathaveyettobeprocessed.\nProjects\nP-9.50 Implementthein-placeheap-sortalgorithm.Experimentallycompareitsrunning\ntimewiththatofthestandardheap-sortthatisnotin-place.\nP-9.51 UsetheapproachofeitherExerciseC-9.39orC-9.40toreimplementthemethod\ngetFavoritesoftheFavoritesListMTFclassfromSection7.7.2. Makesurethat\nresultsaregeneratedfromlargesttosmallest.\nP-9.52 DevelopaJavaimplementationofanadaptablepriorityqueuethatisbasedonan\nunsortedlistandsupportslocation-awareentries.\nP-9.53 Write an applet or stand-alone graphical program that animates a heap. Your\nprogram should support all the priority queue operations and should visualize\ntheswapsintheup-heapanddown-heapbubblings.(Extra:Visualizebottom-up\nheapconstructionaswell.)\nP-9.54 Write a program that can process a sequence of stock buy and sell orders as\ndescribedinExerciseC-9.48.\nP-9.55 One of the main applications of priority queues is in operating systems\u2014for\nschedulingjobsonaCPU.Inthisprojectyouaretobuildaprogramthatsched-\nulessimulated CPU jobs. Yourprogramshouldrunin a loop, each iterationof\nwhich correspondsto a time slice for the CPU. Each job is assigned a priority,\nwhichisanintegerbetween 20(highestpriority)and19(lowestpriority),inclu-\n\u2212\nsive. Fromamongalljobswaitingtobeprocessedinatimeslice,theCPUmust\nworkona jobwith highestpriority. Inthissimulation,eachjobwillalsocome\nwithalengthvalue,whichisanintegerbetween1and100,inclusive,indicating\nthenumberoftimeslicesthatareneededtoprocessthisjob. Forsimplicity,you\nmayassumejobscannotbeinterrupted\u2014onceitisscheduledontheCPU,ajob\nrunsforanumberoftimeslicesequaltoitslength. Yoursimulatormustoutput\nthe name of the job runningon the CPU in each time slice and must processa\nsequenceofcommands,onepertimeslice,eachofwhichisoftheform\u201caddjob\nnamewithlengthnandpriority p\u201dor\u201cnonewjobthisslice\u201d.\nwww.it-ebooks.info\n400 Chapter9. PriorityQueues\nP-9.56 LetSbeasetofnpointsintheplanewithdistinctintegerx-andy-coordinates.\nLet T be a completebinarytree storing the pointsfromS atits externalnodes,\nsuch that the points are ordered left to right by increasing x-coordinates. For\neachnodevinT,letS(v)denotethesubsetofSconsistingofpointsstoredinthe\nsubtreerootedatv. FortherootrofT,definetop(r)tobethepointinS=S(r)\nwithmaximaly-coordinate.Foreveryothernodev,definetop(r)tobethepoint\ninSwithhighesty-coordinateinS(v)thatisnotalsothehighesty-coordinatein\nS(u),whereuistheparentofvinT (ifsuchapointexists). Suchlabelingturns\nT intoaprioritysearchtree. Describealinear-timealgorithmforturningT into\naprioritysearchtree. Implementthisapproach.\nChapter Notes\nKnuth\u2019s book on sorting and searching [61] describes the motivation and history for the\nselection-sort, insertion-sort, and heap-sort algorithms. The heap-sort algorithm is due\nto Williams [95], and the linear-time heap construction algorithm is due to Floyd [35].\nAdditional algorithms and analyses for heaps and heap-sort variations can be found in\npapersbyBentley[14],Carlsson[21],GonnetandMunro[39],McDiarmidandReed[69],\nandSchafferandSedgewick[82].\nwww.it-ebooks.info\nChapter\n10\nMaps, Hash Tables, and Skip Lists\nContents\n10.1 Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 402\n10.1.1 The Map ADT . . . . . . . . . . . . . . . . . . . . . . . 403\n10.1.2 Application: Counting Word Frequencies . . . . . . . . . . 405\n10.1.3 An AbstractMap Base Class . . . . . . . . . . . . . . . . 406\n10.1.4 A Simple Unsorted Map Implementation . . . . . . . . . . 408\n10.2 Hash Tables . . . . . . . . . . . . . . . . . . . . . . . . . . 410\n10.2.1 Hash Functions . . . . . . . . . . . . . . . . . . . . . . . 411\n10.2.2 Collision-HandlingSchemes . . . . . . . . . . . . . . . . . 417\n10.2.3 Load Factors, Rehashing, and Efficiency . . . . . . . . . . 420\n10.2.4 Java Hash Table Implementation . . . . . . . . . . . . . . 422\n10.3 Sorted Maps . . . . . . . . . . . . . . . . . . . . . . . . . . 428\n10.3.1 Sorted Search Tables . . . . . . . . . . . . . . . . . . . . 429\n10.3.2 Two Applications of Sorted Maps . . . . . . . . . . . . . 433\n10.4 Skip Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436\n10.4.1 Search and Update Operations in a Skip List . . . . . . . 438\n\u22c6\n10.4.2 Probabilistic Analysis of Skip Lists . . . . . . . . . . . . 442\n10.5 Sets, Multisets, and Multimaps . . . . . . . . . . . . . . . 445\n10.5.1 The Set ADT . . . . . . . . . . . . . . . . . . . . . . . . 445\n10.5.2 The Multiset ADT . . . . . . . . . . . . . . . . . . . . . 447\n10.5.3 The Multimap ADT . . . . . . . . . . . . . . . . . . . . . 448\n10.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451\nwww.it-ebooks.info\n402 Chapter10. Maps,HashTables,andSkipLists\n10.1 Maps\nAmapisanabstractdatatypedesignedtoefficientlystoreandretrievevaluesbased\nupon a uniquely identifying search key for each. Specifically, a map stores key-\nvaluepairs(k,v),whichwecallentries,wherekisthekeyandvisitscorresponding\nvalue. Keys are required to be unique, so that the association of keys to values\ndefines a mapping. Figure 10.1 provides a conceptual illustration of a map using\nthe file-cabinet metaphor. For a more modern metaphor, think about the web as\nbeing a map whose entries are the web pages. The key of a page is its URL (e.g.,\nhttp://datastructures.net/)anditsvalueisthepagecontent.\nFigure10.1: A conceptual illustration of the map ADT.Keys (labels) are assigned\ntovalues(folders)byauser. Theresultingentries(labeledfolders)areinsertedinto\nthemap(filecabinet). Thekeyscanbeusedlatertoretrieveorremovevalues.\nMaps are also known as associative arrays, because the entry\u2019s key serves\nsomewhat like an index into the map, in that it assists the map in efficiently lo-\ncating theassociated entry. However, unlike astandard array, akey ofamapneed\nnot be numeric, and is does not directly designate a position within the structure.\nCommonapplications ofmapsinclude thefollowing:\nA university\u2019s information system relies on some form of a student ID as a\n\u2022\nkey that is mapped to that student\u2019s associated record (such as the student\u2019s\nname,address, andcoursegrades)serving asthevalue.\nThedomain-namesystem(DNS)mapsahostname,suchaswww.wiley.com,\n\u2022\ntoanInternet-Protocol (IP)address, suchas208.215.179.146.\nAsocialmediasitetypicallyreliesona(nonnumeric) usernameasakeythat\n\u2022\ncanbeefficientlymappedtoaparticular user\u2019sassociated information.\nA company\u2019s customer base may be stored as a map, with a customer\u2019s ac-\n\u2022\ncount number or unique user ID as a key, and a record with the customer\u2019s\ninformation as a value. The map would allow a service representative to\nquicklyaccessacustomer\u2019s record,giventhekey.\nAcomputer graphics system maymap acolor name, such as 'turquoise',\n\u2022\ntothetriple ofnumbers that describes the color\u2019s RGB(red-green-blue) rep-\nresentation, suchas(64, 224, 208).\nwww.it-ebooks.info\n10.1. Maps 403\n10.1.1 The Map ADT\nSince a map stores a collection of objects, it should be viewed as a collection of\nkey-value pairs. AsanADT,amapM supportsthefollowingmethods:\nsize(): ReturnsthenumberofentriesinM.\nisEmpty(): Returnsaboolean indicating whetherM isempty.\nget(k): Returnsthevaluevassociatedwithkeyk,ifsuchanentryexists;\notherwise returnsnull.\nput(k,v): IfM doesnothaveanentrywithkeyequaltok,thenaddsentry\n(k,v) to M and returns null; else, replaces with v the existing\nvalueoftheentrywithkeyequaltokandreturns theoldvalue.\nremove(k): Removes from M the entry with key equal to k, and returns its\nvalue;ifM hasnosuchentry, thenreturnsnull.\nkeySet(): ReturnsaniterablecollectioncontainingallthekeysstoredinM.\nvalues(): Returnsaniterablecollectioncontainingallthevaluesofentries\nstored in M (with repetition if multiple keys map to the same\nvalue).\nentrySet(): Returns an iterable collection containing all the key-value en-\ntriesinM.\nMaps in the java.util Package\nOurdefinitionofthemapADTisasimplifiedversionofthejava.util.Mapinterface.\nFortheelementsoftheiterationreturnedbyentrySet,wewillrelyonthecomposite\nEntry interface introduced in Section 9.2.1 (the java.util.Map relies on the nested\njava.util.Map.Entryinterface).\nNoticethat eachoftheoperations get(k),put(k,v),and remove(k)returns the\nexisting value associated with key k, if the map has such an entry, and otherwise\nreturns null. This introduces ambiguity inan application for which nullisallowed\nas a natural value associated with a key k. That is, if an entry (k,null) exists in a\nmap,thentheoperationget(k)willreturnnull,notbecauseitcouldn\u2019tfindthekey,\nbutbecause itfoundthekeyandisreturning itsassociated value.\nSome implementations of the java.util.Map interface explicitly forbid use of\na null value (and null keys, for that matter). However, to resolve the ambiguity\nwhennullisallowable,theinterfacecontainsabooleanmethod,containsKey(k)to\ndefinitively check whether k exists as a key. (We leave implementation of such a\nmethodasanexercise.)\nwww.it-ebooks.info\n404 Chapter10. Maps,HashTables,andSkipLists\nExample 10.1: Inthefollowing,weshowtheeffectofaseriesofoperationson\naninitiallyemptymapstoringentrieswithintegerkeysandsingle-charactervalues.\nMethod ReturnValue Map\nisEmpty() true\n{}\nput(5,A) null (5,A)\n{ }\nput(7,B) null (5,A),(7,B)\n{ }\nput(2,C) null (5,A),(7,B),(2,C)\n{ }\nput(8,D) null (5,A),(7,B),(2,C),(8,D)\n{ }\nput(2,E) C (5,A),(7,B),(2,E),(8,D)\n{ }\nget(7) B (5,A),(7,B),(2,E),(8,D)\n{ }\nget(4) null (5,A),(7,B),(2,E),(8,D)\n{ }\nget(2) E (5,A),(7,B),(2,E),(8,D)\n{ }\nsize() 4 (5,A),(7,B),(2,E),(8,D)\n{ }\nremove(5) A (7,B),(2,E),(8,D)\n{ }\nremove(2) E (7,B),(8,D)\n{ }\nget(2) null (7,B),(8,D)\n{ }\nremove(2) null (7,B),(8,D)\n{ }\nisEmpty() false (7,B),(8,D)\n{ }\nentrySet() (7,B),(8,D) (7,B),(8,D)\n{ } { }\nkeySet() 7,8 (7,B),(8,D)\n{ } { }\nvalues() B,D (7,B),(8,D)\n{ } { }\nA Java Interface for the Map ADT\nA formal definition of a Java interface for our version of the map ADT is given\nin Code Fragment 10.1. It uses the generics framework (Section 2.5.2), with K\ndesignating thekeytypeandVdesignating thevaluetype.\n1 public interface Map<K,V>\n{\n2 int size();\n3 boolean isEmpty();\n4 V get(K key);\n5 V put(K key, V value);\n6 V remove(K key);\n7 Iterable<K> keySet();\n8 Iterable<V> values();\n9 Iterable<Entry<K,V>> entrySet();\n10\n}\nCodeFragment10.1: Javainterface foroursimplifiedversionofthemapADT.\nwww.it-ebooks.info\n10.1. Maps 405\n10.1.2 Application: Counting Word Frequencies\nAs a case study for using a map, consider the problem of counting the number\nofoccurrences ofwordsinadocument. Thisisastandard taskwhenperforming a\nstatisticalanalysisofadocument,forexample,whencategorizinganemailornews\narticle. A map is an ideal data structure to use here, for we can use words as keys\nandwordcountsasvalues. Weshowsuchanapplication inCodeFragment10.2.\nWebeginwithanemptymap,mappingwordstotheirintegerfrequencies. (We\nrely on the ChainHashMap class that will be introduced in Section 10.2.4.) We\nfirstscanthroughtheinput,consideringadjacentalphabeticcharacterstobewords,\nwhich we then convert to lowercase. For each word found, we attempt to retrieve\nits current frequency from the map using the get method, with a yet unseen word\nhaving frequency zero. We then (re)set its frequency to be one more to reflect the\ncurrent occurrence oftheword. Afterprocessing theentireinput, weloopthrough\ntheentrySet()ofthemaptodetermine whichwordhasthemostoccurrences.\n1 /\u2217\u2217 A program that counts words in a document, printing the most frequent. \u2217/\n2 public class WordCount\n{\n3 public static void main(String[ ] args)\n{\n4 Map<String,Integer> freq = new ChainHashMap<>(); // or any concrete map\n5 // scan input for words, using all nonletters as delimiters\n6 Scanner doc = new Scanner(System.in).useDelimiter(\"[^a-zA-Z]+\");\n7 while (doc.hasNext())\n{\n8 String word = doc.next().toLowerCase(); // convert next word to lowercase\n9 Integer count = freq.get(word); // get the previous count for this word\n10 if (count == null)\n11 count = 0; // if not in map, previous count is zero\n12 freq.put(word, 1 + count); // (re)assign new count for this word\n13\n}\n14 int maxCount = 0;\n15 String maxWord = \"no word\";\n16 for (Entry<String,Integer> ent : freq.entrySet()) // find max-count word\n17 if (ent.getValue() > maxCount)\n{\n18 maxWord = ent.getKey();\n19 maxCount = ent.getValue();\n20\n}\n21 System.out.print(\"The most frequent word is '\" + maxWord);\n22 System.out.println(\"' with \" + maxCount + \" occurrences.\");\n23\n}\n24\n}\nCode Fragment 10.2: A program for counting word frequencies in a document,\nprinting the mostfrequent word. Thedocument isparsed using the Scanner class,\nfor which we change the delimiter for separating tokens from whitespace to any\nnonletter. Wealsoconvertwordstolowercase.\nwww.it-ebooks.info\n406 Chapter10. Maps,HashTables,andSkipLists\n10.1.3 An AbstractMap Base Class\nIntheremainderofthischapter(andthenext),wewillbeprovidingmanydifferent\nimplementations of the map ADT using a variety of data structures, each with its\nown trade-off of advantages and disadvantages. As we have done in earlier chap-\nters, we rely on a combination of abstract and concrete classes in the interest of\ngreatercodereuse. Figure10.2provides apreviewofthoseclasses.\n\u226ainterface\u226b \u226ainterface\u226b\nMap SortedMap\n(Section10.1.1) (Section10.3)\nAbstractMap AbstractSortedMap\n(Section10.1.3) (Section10.3)\nUnsortedTableMap AbstractHashMap SortedTableMap TreeMap\n(Section10.1.4) (Section10.2.4) (Section10.3.1) (Chapter11)\n(additionalsubclasses)\nChainHashMap ProbeHashMap\n(Section10.2.4) (Section10.2.4)\nFigure10.2:Ourhierarchyofmaptypes(withreferencestowheretheyaredefined).\nWebegin,inthissection,bydesigninganAbstractMapbaseclassthatprovides\nfunctionality that is shared by all of our map implementations. More specifically,\nthebaseclass(giveninCodeFragment10.3)provides thefollowingsupport:\nAnimplementationoftheisEmptymethod,baseduponthepresumedimple-\n\u2022\nmentation ofthesizemethod.\nA nested MapEntry class that implements the public Entry interface, while\n\u2022\nproviding acomposite forstoring key-valueentriesinamapdatastructure.\nConcrete implementations ofthekeySet andvaluesmethods, based uponan\n\u2022\nadaptiontotheentrySetmethod. Inthisway,concretemapclassesneedonly\nimplementtheentrySetmethodtoprovideallthreeformsofiteration.\nWeimplement theiterations using the technique introduced inSection 7.4.2\n(at that time providing an iteration of all elements of a positional list given\naniteration ofallpositions ofthelist).\nwww.it-ebooks.info\n10.1. Maps 407\n1 public abstract class AbstractMap<K,V> implements Map<K,V>\n{\n2 public boolean isEmpty() return size() == 0;\n{ }\n3 //----------------nested MapEntry class ----------------\n4 protected static class MapEntry<K,V> implements Entry<K,V>\n{\n5 private K k; // key\n6 private V v; // value\n7 public MapEntry(K key, V value)\n{\n8 k = key;\n9 v = value;\n10\n}\n11 // public methods of the Entry interface\n12 public K getKey() return k;\n{ }\n13 public V getValue() return v;\n{ }\n14 // utilities not exposed as part of the Entry interface\n15 protected void setKey(K key) k = key;\n{ }\n16 protected V setValue(V value)\n{\n17 V old = v;\n18 v = value;\n19 return old;\n20\n}\n21 //-----------end of nested MapEntry class -----------\n}\n22\n23 // Support for public keySet method...\n24 private class KeyIterator implements Iterator<K>\n{\n25 private Iterator<Entry<K,V>> entries = entrySet().iterator(); // reuse entrySet\n26 public boolean hasNext() return entries.hasNext();\n{ }\n27 public K next() return entries.next().getKey(); // return key!\n{ }\n28 public void remove() throw new UnsupportedOperationException();\n{ }\n29\n}\n30 private class KeyIterable implements Iterable<K>\n{\n31 public Iterator<K> iterator() return new KeyIterator();\n{ }\n32\n}\n33 public Iterable<K> keySet() return new KeyIterable();\n{ }\n34\n35 // Support for public values method...\n36 private class ValueIterator implements Iterator<V>\n{\n37 private Iterator<Entry<K,V>> entries = entrySet().iterator(); // reuse entrySet\n38 public boolean hasNext() return entries.hasNext();\n{ }\n39 public V next() return entries.next().getValue(); // return value!\n{ }\n40 public void remove() throw new UnsupportedOperationException();\n{ }\n41\n}\n42 private class ValueIterable implements Iterable<V>\n{\n43 public Iterator<V> iterator() return new ValueIterator();\n{ }\n44\n}\n45 public Iterable<V> values() return new ValueIterable();\n{ }\n46\n}\nCodeFragment10.3: Implementation oftheAbstractMapbaseclass.\nwww.it-ebooks.info\n408 Chapter10. Maps,HashTables,andSkipLists\n10.1.4 A Simple Unsorted Map Implementation\nWe demonstrate the use of the AbstractMap class with a very simple concrete\nimplementation of the map ADTthat relies on storing key-value pairs in arbitrary\norderwithinaJavaArrayList. ThepresentationofsuchanUnsortedTableMapclass\nisgiveninCodeFragments10.4and10.5.\nEachofthefundamental methodsget(k),put(k,v),andremove(k)requires an\ninitial scan of the array to determine whether an entry with key equal to k exists.\nFor this reason, we provide a nonpublic utility, findIndex(key), that returns the\nindex atwhich such an entry is found, or 1if nosuch entry is found. (SeeCode\n\u2212\nFragment10.4.)\nTherestoftheimplementationisrathersimple. Onesubtletyworthmentioning\nisthewayinwhichweremoveanentryfromthearraylist. Althoughwecoulduse\ntheremovemethodoftheArrayListclass,thatwouldresultinanunnecessary loop\nto shift all subsequent entries to the left. Because the map isunordered, weprefer\ntofillthevacatedcellofthearraybyrelocatingthelastentrytothatlocation. Such\nanupdatesteprunsinconstanttime.\nUnfortunately, the UnsortedTableMap class on the whole is not very efficient.\nOn a map with n entries, each of the fundamental methods takes O(n) time in the\nworstcasebecauseoftheneedtoscanthroughtheentirelistwhensearchingforan\nexisting entry. Fortunately, aswediscuss inthenextsection, thereisamuchfaster\nstrategyforimplementing themapADT.\n1 public class UnsortedTableMap<K,V> extends AbstractMap<K,V>\n2 /\u2217\u2217 Underlying storage for the map of entries. \u2217/ {\n3 private ArrayList<MapEntry<K,V>> table = new ArrayList<>();\n4\n5 /\u2217\u2217 Constructs an initially empty map. \u2217/\n6 public UnsortedTableMap()\n{ }\n7\n8 // private utility\n9 /\u2217\u2217 Returns the index of an entry with equal key, or 1 if none found. \u2217/\n\u2212\n10 private int findIndex(K key)\n{\n11 int n = table.size();\n12 for (int j=0; j < n; j++)\n13 if (table.get(j).getKey().equals(key))\n14 return j;\n15 return 1; // special value denotes that key was not found\n\u2212\n16\n}\nCode Fragment 10.4: An implementation of a map using a Java ArrayList as an\nunsortedtable. (ContinuesinCodeFragment10.5.) TheparentclassAbstractMap\nisgiveninCodeFragment10.3.\nwww.it-ebooks.info\n10.1. Maps 409\n17 /\u2217\u2217 Returns the number of entries in the map. \u2217/\n18 public int size() return table.size();\n19 /\u2217\u2217 Returns the v { alue associated with t } he specified key (or else null). \u2217/\n20 public V get(K key)\n{\n21 int j = findIndex(key);\n22 if (j == 1) return null; // not found\n\u2212\n23 return table.get(j).getValue();\n24\n25 } /\u2217\u2217 Associates given value with given key, replacing a previous value (if any). \u2217/\n26 public V put(K key, V value)\n{\n27 int j = findIndex(key);\n28 if (j == 1)\n\u2212 {\n29 table.add(new MapEntry<>(key, value)); // add new entry\n30 return null;\n31 else // key already exists\n}\n32 return table.get(j).setValue(value); // replaced value is returned\n33\n34 } /\u2217\u2217 Removes the entry with the specified key (if any) and returns its value. \u2217/\n35 public V remove(K key)\n{\n36 int j = findIndex(key);\n37 int n = size();\n38 if (j == 1) return null; // not found\n\u2212\n39 V answer = table.get(j).getValue();\n40 if (j != n 1)\n\u2212\n41 table.set(j, table.get(n 1)); // relocate last entry to \u2019hole\u2019 created by removal\n\u2212\n42 table.remove(n 1); // remove last entry of table\n\u2212\n43 return answer;\n44\n}\n45 // Support for public entrySet method...\n46 private class EntryIterator implements Iterator<Entry<K,V>>\n{\n47 private int j=0;\n48 public boolean hasNext() return j < table.size();\n{ }\n49 public Entry<K,V> next()\n{\n50 if (j == table.size()) throw new NoSuchElementException();\n51 return table.get(j++);\n52\n}\n53 public void remove() throw new UnsupportedOperationException();\n{ }\n54\n}\n55 private class EntryIterable implements Iterable<Entry<K,V>>\n{\n56 public Iterator<Entry<K,V>> iterator() return new EntryIterator();\n{ }\n57\n58 } /\u2217\u2217 Returns an iterable collection of all key-value entries of the map. \u2217/\n59 public Iterable<Entry<K,V>> entrySet() return new EntryIterable();\n{ }\n60\n}\nCode Fragment 10.5: An implementation of a map using a Java ArrayList as an\nunsorted table(continued fromCodeFragment10.4).\nwww.it-ebooks.info\n410 Chapter10. Maps,HashTables,andSkipLists\n10.2 Hash Tables\nIn this section, we introduce one of the most efficient data structures for imple-\nmenting a map, and the one that is used most in practice. This structure is known\nasahashtable.\nIntuitively, amapM supports the abstraction of using keys as\u201caddresses\u201d that\nhelp locate an entry. As a mental warm-up, consider a restricted setting in which\na map with n entries uses keys that are known to be integers in a range from 0 to\nN 1forsomeN n. Inthiscase, wecanrepresent themapusingalookuptable\n\u2212 \u2265\noflengthN,asdiagrammed inFigure10.3.\n0 1 2 3 4 5 6 7 8 9 10\nD Z C Q\nFigure10.3:Alookuptablewithlength11foramapcontainingentries(1,D),(3,Z),\n(6,C),and(7,Q).\nInthisrepresentation, westorethevalueassociatedwithkeykatindexkofthe\ntable(presumingthatwehaveadistinctwaytorepresentanemptyslot). Basicmap\noperations get,put,andremovecanbeimplemented inO(1)worst-casetime.\nThere aretwochallenges in extending this framework to themore general set-\ntingofamap. First,wemaynotwishtodevoteanarrayoflengthN ifitisthecase\nthat N n. Second, we do not in general require that a map\u2019s keys be integers.\n\u226b\nThe novel concept for a hash table is the use of a hash function to map general\nkeystocorresponding indicesinatable. Ideally,keyswillbewelldistributedinthe\nrangefrom0toN 1byahashfunction, butinpracticetheremaybetwoormore\n\u2212\ndistinct keysthatgetmappedtothesameindex. Asaresult, wewillconceptualize\nour table as a bucket array, as shown in Figure 10.4, in which each bucket may\nmanageacollectionofentriesthataresenttoaspecificindexbythehashfunction.\n(Tosavespace,anemptybucketmaybereplaced byanullreference.)\n0 1 2 3 4 5 6 7 8 9 10\n(1,D) (25,C) (6,A) (7,Q)\n(3,F) (39,C)\n(14,Z)\nFigure10.4: Abucketarrayofcapacity 11withentries(1,D),(25,C),(3,F),(14,Z),\n(6,A),(39,C),and(7,Q),usingasimplehashfunction.\nwww.it-ebooks.info\n10.2. HashTables 411\n10.2.1 Hash Functions\nThe goal of a hash function, h, is to map each key k to an integer in the range\n[0,N 1], where N is the capacity of the bucket array for a hash table. Equipped\n\u2212\nwith such a hash function, h, the main idea of this approach is to use the hash\nfunction value, h(k), as an index into our bucket array, A, instead of the key k\n(which may not be appropriate for direct use as an index). That is, we store the\nentry(k,v)inthebucketA[h(k)].\nIf there are two or more keys with the same hash value, then two different\nentrieswillbemappedtothesamebucketinA. Inthiscase,wesaythatacollision\nhas occurred. Tobe sure, there are ways of dealing with collisions, which wewill\ndiscuss later, but the best strategy isto try to avoid them inthe first place. Wesay\nthat a hash function is \u201cgood\u201d if it maps the keys in our map so as to sufficiently\nminimize collisions. For practical reasons, we also would like a hash function to\nbefastandeasytocompute.\nIt is common to view the evaluation of a hash function, h(k), as consisting of\ntwo portions\u2014a hash code that maps a key k to an integer, and a compression\nfunctionthatmapsthehashcodetoanintegerwithinarangeofindices,[0,N 1],\n\u2212\nforabucketarray. (SeeFigure10.5.)\nArbitrary Objects\nhashcode\n2 1 0 1 2\n\u00b7\u00b7\u00b7 \u2212 \u2212 \u00b7\u00b7\u00b7\ncompressionfunction\n0 1 2 N 1\n\u00b7\u00b7\u00b7 \u2212\nFigure10.5: Twopartsofahashfunction: ahashcodeandacompressionfunction.\nTheadvantageofseparatingthehashfunctionintotwosuchcomponentsisthat\nthe hash code portion of that computation is independent of a specific hash table\nsize. This allows the development of a general hash code for each object that can\nbe used for a hash table of any size; only the compression function depends upon\nthetable size. Thisisparticularly convenient, because theunderlying bucket array\nfor a hash table may be dynamically resized, depending on the number of entries\ncurrently storedinthemap. (SeeSection10.2.3.)\nwww.it-ebooks.info\n412 Chapter10. Maps,HashTables,andSkipLists\nHash Codes\nThe first action that a hash function performs is to take an arbitrary key k in our\nmapandcomputeanintegerthatiscalledthehashcodefork;thisintegerneednot\nbeintherange[0,N 1],andmayevenbenegative. Wedesirethatthesetofhash\n\u2212\ncodes assigned to our keys should avoid collisions as much as possible. For if the\nhash codes ofourkeys cause collisions, thenthere isnohope forourcompression\nfunction to avoid them. In this subsection, we begin by discussing the theory of\nhashcodes. Followingthat, wediscuss practical implementations ofhashcodesin\nJava.\nTreating the Bit Representation as an Integer\nTobegin,wenotethat,foranydatatypeX thatisrepresentedusingatmostasmany\nbits as our integer hash codes, wecan simply take as a hash code for X an integer\ninterpretation of its bits. Java relies on 32-bit hash codes, so for base types byte,\nshort, int, and char, we can achieve a good hash code simply by casting a value\ntoint. Likewise, foravariable xofbasetype float,wecanconvert xtoaninteger\nusingacalltoFloat.floatToIntBits(x),andthenusethisintegerasx\u2019shashcode.\nForatypewhosebitrepresentation islonger thanadesired hash code(suchas\nJava\u2019s long and double types), the above scheme is not immediately applicable.\nOnepossibilityistouseonlythehigh-order32bits(orthelow-order32bits). This\nhash code, of course, ignores half of the information present in the original key,\nand if many of the keys in our map only differ in these bits, then they will collide\nusingthissimplehashcode.\nAbetterapproachistocombineinsomewaythehigh-orderandlow-orderpor-\ntions of a 64-bit key to form a 32-bit hash code, which takes all the original bits\ninto consideration. A simple implementation is to add the two components as 32-\nbitnumbers(ignoringoverflow),ortotaketheexclusive-orofthetwocomponents.\nTheseapproachesofcombiningcomponentscanbeextendedtoanyobjectxwhose\nbinary representation can be viewed as an n-tuple (x ,x ,...,x ) of 32-bit inte-\n0 1 n\u22121\ngers,forexample,byformingahashcodeforxas\u2211n\u22121x,orasx x x ,\ni=0 i 0 \u2295 1 \u2295\u00b7\u00b7\u00b7\u2295 n\u22121\nwhere the symbol represents the bitwise exclusive-or operation (which is the\n\u2295\n\u02c6operator inJava).\nPolynomial Hash Codes\nThesummationandexclusive-orhashcodes,describedabove,arenotgoodchoices\nforcharacterstringsorothervariable-length objectsthatcanbeviewedastuplesof\nthe form (x ,x ,...,x ), where the order of the x\u2019s is significant. For example,\n0 1 n\u22121 i\nconsider a 16-bit hash code for a character string s that sums the Unicode values\nof the characters in s. This hash code unfortunately produces lots of unwanted\nwww.it-ebooks.info\n10.2. HashTables 413\ncollisions for common groups of strings. In particular, \"temp01\" and \"temp10\"\ncollide using thisfunction, asdo\"stop\",\"tops\",\"pots\",and\"spot\". Abetter\nhash code should somehow take into consideration the positions of the x\u2019s. An\ni\nalternative hash code, which does exactly this, is to choose a nonzero constant,\na=1,anduseasahashcodethevalue\n6\nx an\u22121+x an\u22122+ +x a+x .\n0 1 n\u22122 n\u22121\n\u00b7\u00b7\u00b7\nMathematically speaking, this is simply a polynomial in a that takes the compo-\nnents(x ,x ,...,x )ofanobjectxasitscoefficients. Thishashcodeistherefore\n0 1 n\u22121\ncalled apolynomial hashcode. ByHorner\u2019s rule(see ExerciseC-4.54), thispoly-\nnomialcanbecomputedas\nx +a(x +a(x + +a(x +a(x +ax )) )).\nn\u22121 n\u22122 n\u22123 2 1 0\n\u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7\nIntuitively,apolynomialhashcodeusesmultiplicationbydifferentpowersasa\nwaytospreadouttheinfluenceofeachcomponent acrosstheresulting hashcode.\nOf course, on a typical computer, evaluating a polynomial will be done using\nthefinitebitrepresentation forahashcode;hence,thevaluewillperiodically over-\nflowthe bits used foran integer. Since weare more interested in agood spread of\nthe object xwith respect toother keys, wesimply ignore such overflows. Still, we\nshould be mindful that such overflows are occurring and choose the constant a so\nthat it has some nonzero, low-order bits, which will serve to preserve some of the\ninformation contentevenasweareinanoverflowsituation.\nWe have done some experimental studies that suggest that 33, 37, 39, and 41\nare particularly good choices for a when working with character strings that are\nEnglish words. In fact, ina list ofover 50,000 English words formed asthe union\nofthewordlistsprovided intwovariantsofUnix,wefoundthattaking atobe33,\n37,39,or41produced fewerthan7collisions ineachcase!\nCyclic-Shift Hash Codes\nA variant of the polynomial hash code replaces multiplication by a with a cyclic\nshift ofapartial sum by acertain number of bits. Forexample, a5-bit cyclic shift\nof the 32-bit value 00111101100101101010100010101000 is achieved by taking\ntheleftmost fivebits andplacing those onthe rightmost side oftherepresentation,\nresultingin10110010110101010001010100000111. Whilethisoperationhaslittle\nnaturalmeaningintermsofarithmetic, itaccomplishes thegoalofvaryingthebits\nofthecalculation. InJava,acyclicshiftofbitscanbeaccomplishedthroughcareful\nuseofthebitwiseshiftoperators.\nwww.it-ebooks.info\n414 Chapter10. Maps,HashTables,andSkipLists\nAn implementation of a cyclic-shift hash code computation for a character\nstringinJavaappears asfollows:\nstatic int hashCode(String s)\n{\nint h=0;\nfor (int i=0; i<s.length(); i++)\n{\nh = (h << 5) (h >>> 27); // 5-bit cyclic shift of the running sum\n|\nh += (int) s.charAt(i); // add in next character\n}\nreturn h;\n}\nAswiththetraditional polynomial hashcode, fine-tuning isrequired whenusing a\ncyclic-shift hash code, as we must wisely choose the amount to shift by for each\nnewcharacter. Ourchoiceofa5-bitshiftisjustifiedbyexperimentsrunonalistof\njust over 230,000 English words, comparing the number of collisions for various\nshiftamounts(seeTable10.1).\nCollisions\nShift Total Max\n0 234735 623\n1 165076 43\n2 38471 13\n3 7174 5\n4 1379 3\n5 190 3\n6 502 2\n7 560 2\n8 5546 4\n9 393 3\n10 5194 5\n11 11559 5\n12 822 2\n13 900 4\n14 2001 4\n15 19251 8\n16 211781 37\nTable 10.1: Comparison of collision behavior for the cyclic-shift hash code as ap-\npliedtoalistof230,000Englishwords. The\u201cTotal\u201dcolumnrecordsthetotalnum-\nberofwordsthatcollidewithatleastoneother,andthe\u201cMax\u201dcolumnrecordsthe\nmaximumnumberofwordscollidingatanyonehashcode. Notethatwithacyclic\nshiftof0,thishashcoderevertstotheonethatsimplysumsallthecharacters.\nwww.it-ebooks.info\n10.2. HashTables 415\nHash Codes in Java\nThe notion of hash codes are an integral part of the Java language. The Object\nclass,whichservesasanancestorofallobjecttypes,includesadefaulthashCode()\nmethod that returns a 32-bit integer of type int, which serves as an object\u2019s hash\ncode. ThedefaultversionofhashCode()providedbytheObjectclassisoftenjust\nanintegerrepresentation derivedfromtheobject\u2019s memoryaddress.\nHowever, we must be careful if relying on the default version of hashCode()\nwhen authoring a class. For hashing schemes to be reliable, it is imperative that\nanytwoobjects that areviewedas\u201cequal\u201d toeach other have the samehash code.\nThis is important because if an entry is inserted into a map, and a later search is\nperformed on akey that isconsidered equivalent to that entry\u2019s key, the mapmust\nrecognize this as a match. (See, for example, the UnsortedTableMap.findIndex\nmethodinCodeFragment10.4.) Therefore, whenusing ahashtabletoimplement\na map, wewant equivalent keys to have the same hash code so that they are guar-\nanteed to map to the same bucket. More formally, if a class defines equivalence\nthrough the equals method (see Section 3.5), then that class should also provide a\nconsistent implementation of the hashCode method, such that if x.equals(y) then\nx.hashCode() == y.hashCode().\nAs an example, Java\u2019s String class defines the equals method so that two in-\nstancesareequivalent iftheyhaveprecisely thesamesequence ofcharacters. That\nclass also overrides the hashCode method to provide consistent behavior. In fact,\nthe implementation of hash codes for the String class is excellent. If we repeat\ntheexperiment fromthepreviouspageusingJava\u2019simplementation ofhashcodes,\nthere are only 12 collisions among more than 230,000 words. Java\u2019s primitive\nwrapperclassesalsodefinehashCode,usingtechniques described onpage412.\nAsanexampleofhowtoproperlyimplementhashCodeforauser-definedclass,\nwe will revisit the SinglyLinkedList class from Chapter 3. We defined the equals\nmethod for that class, in Section 3.5.2, so that two lists are equivalent if they rep-\nresent equal-length sequences of elements that are pairwise equivalent. We can\ncompute a robust hash code for a list by taking the exclusive-or of its elements\u2019\nhashcodes, whileperformingacyclicshift. (SeeCodeFragment10.6.)\n1 public int hashCode()\n{\n2 int h = 0;\n3 for (Node walk=head; walk != null; walk = walk.getNext())\n{\n4 h \u02c6= walk.getElement().hashCode(); // bitwise exclusive-or with element\u2019s code\n5 h = (h << 5) (h >>> 27); // 5-bit cyclic shift of composite code\n|\n6\n}\n7 return h;\n8\n}\nCode Fragment 10.6: A robust implementation of the hashCode method for the\nSinglyLinkedListclassfromChapter3.\nwww.it-ebooks.info\n416 Chapter10. Maps,HashTables,andSkipLists\nCompression Functions\nThe hash code for a key k will typically not be suitable for immediate use with a\nbucketarray, becausetheintegerhashcodemaybenegativeormayexceedtheca-\npacityofthebucketarray. Thus,oncewehavedeterminedanintegerhashcodefor\nakeyobjectk,thereisstilltheissueofmappingthatintegerintotherange[0,N 1].\n\u2212\nThis computation, known as a compression function, is the second action per-\nformed as part of an overall hash function. A good compression function is one\nthatminimizesthenumberofcollisions foragivensetofdistincthashcodes.\nThe Division Method\nAsimplecompression function isthedivisionmethod,whichmapsanintegerito\nimod N,\nwhereN,thesizeofthebucketarray,isafixedpositiveinteger. Additionally, ifwe\ntakeN tobeaprimenumber,thenthiscompressionfunctionhelps\u201cspreadout\u201dthe\ndistribution of hashed values. Indeed, if N is not prime, then there is greater risk\nthatpatternsinthedistribution ofhashcodeswillberepeatedinthedistribution of\nhash values, thereby causing collisions. For example, if we insert keys with hash\ncodes 200,205,210,215,220,...,600 into a bucket array of size 100, then each\n{ }\nhash code will collide with three others. But if we use a bucket array of size 101,\nthen there willbeno collisions. Ifahash function ischosen well, it should ensure\nthattheprobability oftwodifferentkeysgettinghashedtothesamebucketis1/N.\nChoosing N to be a prime number is not always enough, however, for if there is\na repeated pattern of hash codes of the form pN+qfor several different p\u2019s, then\ntherewillstillbecollisions.\nThe MAD Method\nA more sophisticated compression function, which helps eliminate repeated pat-\nternsinasetofintegerkeys,istheMultiply-Add-and-Divide (or\u201cMAD\u201d)method.\nThismethodmapsanintegerito\n[(ai+b) mod p]mod N,\nwhere N is the size of the bucket array, p is a prime number larger than N, and a\nand b are integers chosen at random from the interval [0,p 1], with a>0. This\n\u2212\ncompression functionischoseninordertoeliminaterepeated patterns inthesetof\nhashcodesandgetusclosertohavinga\u201cgood\u201dhashfunction,thatis,onesuchthat\ntheprobability anytwodifferentkeyscollideis1/N. Thisgoodbehaviorwouldbe\nthesameaswewouldhaveifthesekeyswere\u201cthrown\u201dintoAuniformlyatrandom.\nwww.it-ebooks.info\n10.2. HashTables 417\n10.2.2 Collision-Handling Schemes\nThemainideaofahashtableistotakeabucketarray,A,andahashfunction,h,and\nuse them to implement a map by storing each entry (k,v) in the \u201cbucket\u201d A[h(k)].\nThissimpleideaischallenged,however,whenwehavetwodistinctkeys,k andk ,\n1 2\nsuch that h(k )=h(k ). Theexistence of such collisions prevents us from simply\n1 2\ninserting anewentry(k,v)directly intothebucket A[h(k)]. Italsocomplicates our\nprocedure forperforming insertion, search, anddeletion operations.\nSeparate Chaining\nA simple and efficient way for dealing with collisions is to have each bucket A[j]\nstore its own secondary container, holding all entries (k,v) such that h(k)= j. A\nnatural choice for the secondary container is a small map instance implemented\nusing an unordered list, as described in Section 10.1.4. This collision resolution\nruleisknownasseparate chaining,andisillustrated inFigure10.6.\n0 1 2 3 4 5 6 7 8 9 10 11 12\nA\n54 18 10 25\n28 36 38\n41 12\n90\nFigure 10.6: A hash table of size 13, storing 10 entries with integer keys, with\ncollisionsresolvedbyseparatechaining. Thecompressionfunctionish(k)=k mod\n13. Forsimplicity, wedonotshowthevaluesassociated withthekeys.\nIn the worstcase, operations on an individual bucket take timeproportional to\nthesizeofthebucket. Assumingweuseagoodhashfunctiontoindexthenentries\nof our map in a bucket array of capacity N, the expected size of a bucket is n/N.\nTherefore,ifgivenagoodhashfunction,thecoremapoperationsruninO( n/N ).\n\u2308 \u2309\nTheratio \u03bb=n/N, called the load factor of the hash table, should be bounded by\nasmall constant, preferably below 1. Aslong as \u03bb isO(1), the core operations on\nthehashtableruninO(1)expected time.\nwww.it-ebooks.info\n418 Chapter10. Maps,HashTables,andSkipLists\nOpen Addressing\nTheseparate chaining rule has many nice properties, such asaffording simple im-\nplementationsofmapoperations, butitneverthelesshasoneslightdisadvantage: It\nrequirestheuseofanauxiliary datastructuretoholdentrieswithcollidingkeys. If\nspace is at apremium (for example, if weare writing a program for a small hand-\nhelddevice),thenwecanusethealternativeapproachofstoringeachentrydirectly\nin a table slot. This approach saves space because no auxiliary structures are em-\nployed, but it requires a bit more complexity to properly handle collisions. There\nare several variants of this approach, collectively referred to as open addressing\nschemes, which we discuss next. Open addressing requires that the load factor is\nalwaysatmost1andthatentries arestored directly inthecells ofthebucket array\nitself.\nLinear Probing and Its Variants\nA simple method for collision handling with open addressing is linear probing.\nWiththisapproach,ifwetrytoinsertanentry(k,v)intoabucketA[j]thatisalready\noccupied, where j=h(k),thenwenexttryA[(j+1)mod N]. IfA[(j+1)mod N]\nis also occupied, then we try A[(j+2)mod N], and so on, until we find an empty\nbucket thatcanaccept thenewentry. Oncethisbucket islocated, wesimplyinsert\ntheentrythere. Ofcourse,thiscollisionresolutionstrategyrequiresthatwechange\nthe implementation when searching for an existing key\u2014the first step of all get,\nput,orremoveoperations. Inparticular,toattempttolocateanentrywithkeyequal\ntok,wemustexamineconsecutive slots, starting fromA[h(k)],untilweeither find\nan entry with an equal key or we find an empty bucket. (See Figure 10.7.) The\nname\u201clinearprobing\u201dcomesfromthefactthataccessingacellofthebucketarray\ncanbeviewedasa\u201cprobe,\u201dandthatconsecutive probesoccurinneighboring cells\n(whenviewedcircularly).\nMustprobe4times\nNewelementwith beforefindingemptyslot\nkey=15tobeinserted\n0 1 2 3 4 5 6 7 8 9 10\n13 26 5 37 16 21\nFigure10.7: Insertion intoahash tablewithinteger keysusing linear probing. The\nhashfunction ish(k)=k mod11. Valuesassociated withkeysarenotshown.\nwww.it-ebooks.info\n10.2. HashTables 419\nToimplement adeletion, wecannot simply removeafound entry from its slot\nin the array. For example, after the insertion of key 15 portrayed in Figure 10.7,\nif the entry with key 37 were trivially deleted, a subsequent search for 15 would\nfail because that search would start by probing at index 4, then index 5, and then\nindex6,atwhichanemptycellisfound. Atypicalwaytogetaroundthisdifficulty\nis to replace a deleted entry with a special \u201cdefunct\u201d sentinel object. With this\nspecial marker possibly occupying spaces inour hash table, wemodify our search\nalgorithm so that the search for a key k will skip over cells containing the defunct\nsentinel and continue probing until reaching the desired entry or an empty bucket\n(or returning back to where we started from). Additionally, our algorithm for put\nshouldrememberadefunctlocationencountered duringthesearchfork,sincethis\nisavalidplacetoputanewentry(k,v),ifnoexistingentryisfoundbeyondit.\nAlthough use of an open addressing scheme can save space, linear probing\nsuffersfromanadditionaldisadvantage. Ittendstoclustertheentriesofamapinto\ncontiguousruns,whichmayevenoverlap(particularlyifmorethanhalfofthecells\ninthehashtableareoccupied). Suchcontiguous runsofoccupied hashcellscause\nsearches toslowdownconsiderably.\nAnotheropenaddressingstrategy,knownasquadraticprobing,iterativelytries\nthebucketsA[(h(k)+f(i)) mod N],fori=0,1,2,...,where f(i)=i2,untilfinding\nan empty bucket. As with linear probing, the quadratic probing strategy compli-\ncates the removal operation, but it does avoid the kinds of clustering patterns that\noccurwithlinearprobing. Nevertheless,itcreatesitsownkindofclustering,called\nsecondary clustering, wherethesetoffilledarraycellsstillhasanonuniform pat-\ntern,evenifweassumethattheoriginalhashcodesaredistributeduniformly. When\nN isprimeandthebucketarrayislessthanhalffull,thequadratic probingstrategy\nis guaranteed to find an empty slot. However, this guarantee is not valid once the\ntablebecomesatleasthalffull,orifN isnotchosenasaprimenumber;weexplore\nthecauseofthistypeofclustering inanexercise(C-10.42).\nAnopenaddressingstrategythatdoesnotcauseclusteringofthekindproduced\nbylinearprobingorthekindproduced byquadratic probingisthedoublehashing\nstrategy. Inthis approach, wechoose asecondary hash function, h\u2032, and if hmaps\nsome key k to a bucket A[h(k)] that is already occupied, then we iteratively try\nthe buckets A[(h(k)+ f(i)) mod N] next, for i=1,2,3,..., where f(i)=i h\u2032(k).\n\u00b7\nIn this scheme, the secondary hash function is not allowed to evaluate to zero; a\ncommon choice ish\u2032(k)=q (k mod q), forsome prime number q<N. Also, N\n\u2212\nshouldbeaprime.\nAnother approach to avoid clustering with open addressing is to iteratively try\nbuckets A[(h(k)+ f(i)) mod N] where f(i) is based on a pseudorandom number\ngenerator, providing arepeatable, but somewhat arbitrary, sequence of subsequent\nprobesthatdepends uponbitsoftheoriginalhashcode.\nwww.it-ebooks.info\n420 Chapter10. Maps,HashTables,andSkipLists\n10.2.3 Load Factors, Rehashing, and Efficiency\nIn the hash table schemes described thus far, it is important that the load factor,\n\u03bb=n/N, be kept below 1. With separate chaining, as \u03bb gets very close to 1, the\nprobability ofacollision greatly increases, whichaddsoverheadtoouroperations,\nsince we must revert to linear-time list-based methods in buckets that have col-\nlisions. Experiments and average-case analyses suggest that we should maintain\n\u03bb<0.9forhashtables withseparate chaining. (Bydefault, Java\u2019simplementation\nusesseparate chaining with\u03bb<0.75.)\nWithopenaddressing, ontheotherhand,astheloadfactor\u03bbgrowsbeyond0.5\nandstartsapproaching1,clustersofentriesinthebucketarraystarttogrowaswell.\nThese clusters cause the probing strategies to \u201cbounce around\u201d the bucket array\nfor a considerable amount of time before they find an empty slot. In Exercise C-\n10.42,weexplorethedegradationofquadraticprobingwhen\u03bb 0.5. Experiments\n\u2265\nsuggestthatweshouldmaintain\u03bb<0.5foranopenaddressingschemewithlinear\nprobing, andperhaps onlyabithigherforotheropenaddressing schemes.\nIf an insertion causes the load factor of a hash table to go above the specified\nthreshold, thenitiscommontoresizethetable(toregainthespecifiedloadfactor)\nand to reinsert all objects into this new table. Although we need not define a new\nhash code for each object, wedo need toreapply anew compression function that\ntakes intoconsideration thesizeofthenewtable. Rehashing willgenerally scatter\nthe entries throughout the new bucket array. When rehashing to a new table, it is\na good requirement for the new array\u2019s size to be a prime number approximately\ndouble theprevious size(seeExerciseC-10.32). Inthat way,thecostofrehashing\nall the entires in the table can be amortized against the timeused toinsert them in\nthefirstplace(aswithdynamicarrays; seeSection7.2.1).\nEfficiency of Hash Tables\nAlthough the details of the average-case analysis of hashing are beyond the scope\nof this book, its probabilistic basis is quite intuitive. If our hash function is good,\nthen we expect the entries to be uniformly distributed in the N cells of the bucket\narray. Thus, to store n entries, the expected number of keys in a bucket would\nbe n/N ,whichisO(1)ifnisO(N).\n\u2308 \u2309\nThecosts associated with aperiodic rehashing (whenresizing atable after oc-\ncasional insertions or deletions) can beaccounted for separately, leading to an ad-\nditional O(1)amortizedcostforputandremove.\nIn the worst case, a poor hash function could map every entry to the same\nbucket. This would result in linear-time performance for the core map operations\nwithseparate chaining, orwithanyopenaddressing modelinwhichthesecondary\nsequence of probes depends only on the hash code. A summary of these costs is\ngiveninTable10.2.\nwww.it-ebooks.info\n10.2. HashTables 421\nUnsorted HashTable\nMethod\nList expected worstcase\nget O(n) O(1) O(n)\nput O(n) O(1) O(n)\nremove O(n) O(1) O(n)\nsize,isEmpty O(1) O(1) O(1)\nentrySet,keySet,values O(n) O(n) O(n)\nTable10.2: Comparison of the running times of the methods of a map realized by\nmeans of an unsorted list (as in Section 10.1.4) or a hash table. We let n denote\nthe number of entries in the map, and we assume that the bucket array supporting\nthe hash table ismaintained such that itscapacity isproportional tothe number of\nentriesinthemap.\nAn Anecdote About Hashing and Computer Security\nIn a 2003 academic paper, researchers discuss the possibility of exploiting a hash\ntable\u2019sworst-caseperformancetocauseadenial-of-service(DoS)attackofInternet\ntechnologies. Since many published algorithms compute hash codes with a deter-\nministic function, an attacker could precompute avery large number ofmoderate-\nlength strings that all hash to the identical 32-bit hash code. (Recall that by any\nof the hashing schemes we describe, other than double hashing, if two keys are\nmappedtothesamehashcode,theywillbeinseparableinthecollisionresolution.)\nThis concern was brought to the attention of the Java development team, and that\nofmanyotherprogramminglanguages,butdeemedaninsignificantriskatthetime\nbymost. (KudostothePerlteamforimplementing afixin2003.)\nIn late 2011, another team of researchers demonstrated an implementation of\njust such an attack. Web servers allow a series of key-value parameters to be em-\nbedded in a URL using a syntax such as ?key1=val1&key2=val2&key3=val3.\nThosekey-valuepairsarestringsandatypicalWebserverimmediatelystoresthem\nin a hash-map. Servers already place a limit on the length and number of such\nparameters, toavoid overload, but they presume that the total insertion timein the\nmapwillbelinearinthenumberofentries, giventheexpected constant-time oper-\nations. However,ifallkeysweretocollide,theinsertionsintothemapwillrequire\nquadratic time,causing theservertoperform aninordinate amountofwork.\nIn 2012, the OpenJDK team announced the following resolution: they dis-\ntributed a security patch that includes an alternative hash function that introduces\nrandomization into the computation of hash codes, making it less tractable to re-\nverseengineer asetofcolliding strings. However,toavoidbreaking existingcode,\nthenewfeatureisdisabled bydefaultinJavaSE7and,whenenabled, isonlyused\nfor hashing strings and only when a table size grows beyond a certain threshold.\nEnhancedhashing willbeenabled inJavaSE8foralltypesanduses.\nwww.it-ebooks.info\n422 Chapter10. Maps,HashTables,andSkipLists\n10.2.4 Java Hash Table Implementation\nIn this section, we develop two implementations of a hash table, one using sep-\narate chaining and the other using open addressing with linear probing. While\nthese approaches to collision resolution are quite different, there are manyhigher-\nlevelcommonalities tothetwohashing algorithms. Forthat reason, weextend the\nAbstractMapclass(fromCodeFragment10.3)todefineanewAbstractHashMap\nclass(seeCodeFragment10.7),whichprovidesmuchofthefunctionalitycommon\ntoourtwohashtableimplementations.\nWe will begin by discussing what this abstract class does not do\u2014it does not\nprovideanyconcreterepresentationofatableof\u201cbuckets.\u201d Withseparatechaining,\neach bucket will be a secondary map. With open addressing, however, there is no\ntangible container foreach bucket; the\u201cbuckets\u201d are effectively interleaved dueto\nthe probing sequences. In our design, the AbstractHashMap class presumes the\nfollowingtobeabstractmethods\u2014to beimplemented byeachconcretesubclass:\ncreateTable(): This method should create an initially empty table having\nsizeequaltoadesignated capacityinstance variable.\nbucketGet(h,k): This method should mimic the semantics of the public get\nmethod, butforakeykthatisknowntohashtobucketh.\nbucketPut(h,k,v): This method should mimic the semantics of the public put\nmethod, butforakeykthatisknowntohashtobucketh.\nbucketRemove(h,k): Thismethodshouldmimicthesemantics ofthepublic\nremovemethod,butforakeykknowntohashtobucketh.\nentrySet(): Thisstandardmapmethoditeratesthroughallentriesofthe\nmap. Wedonotdelegatethisonaper-bucket basisbecause\n\u201cbuckets\u201d inopenaddressing arenotinherently disjoint.\nWhat the AbstractHashMap class does provide is mathematical support in\nthe form of a hash compression function using a randomized Multiply-Add-and-\nDivide(MAD)formula,andsupportforautomaticallyresizingtheunderlyinghash\ntablewhentheloadfactorreachesacertainthreshold.\nThehashValuemethodreliesonanoriginal key\u2019shashcode, asreturned byits\nhashCode()method,followedbyMADcompressionbasedonaprimenumberand\nthescaleandshiftparameters thatarerandomlychosenintheconstructor.\nTo manage the load factor, the AbstractHashMap class declares a protected\nmember,n,whichshouldequalthecurrentnumberofentriesinthemap;however,\nit must rely on the subclasses to update this field from within methods bucketPut\nandbucketRemove. Iftheloadfactorofthetableincreasesbeyond0.5,werequest\na bigger table (using the createTable method) and reinsert all entries into the new\ntable. (For simplicity, this implementation uses tables of size 2k+1, even though\nthesearenotgenerally prime.)\nwww.it-ebooks.info\n10.2. HashTables 423\n1 public abstract class AbstractHashMap<K,V> extends AbstractMap<K,V>\n{\n2 protected int n = 0; // number of entries in the dictionary\n3 protected int capacity; // length of the table\n4 private int prime; // prime factor\n5 private long scale, shift; // the shift and scaling factors\n6 public AbstractHashMap(int cap, int p)\n{\n7 prime = p;\n8 capacity = cap;\n9 Random rand = new Random();\n10 scale = rand.nextInt(prime 1) + 1;\n\u2212\n11 shift = rand.nextInt(prime);\n12 createTable();\n13\n}\n14 public AbstractHashMap(int cap) this(cap, 109345121); // default prime\n{ }\n15 public AbstractHashMap() this(17); // default capacity\n{ }\n16 // public methods\n17 public int size() return n;\n{ }\n18 public V get(K key) return bucketGet(hashValue(key), key);\n{ }\n19 public V remove(K key) return bucketRemove(hashValue(key), key);\n{ }\n20 public V put(K key, V value)\n{\n21 V answer = bucketPut(hashValue(key), key, value);\n22 if (n > capacity / 2) // keep load factor <= 0.5\n23 resize(2 \u2217 capacity 1); // (or find a nearby prime)\n\u2212\n24 return answer;\n25\n}\n26 // private utilities\n27 private int hashValue(K key)\n28 return (int) ((Math.abs(key { .hashCode()\u2217scale + shift) % prime) % capacity);\n29\n}\n30 private void resize(int newCap)\n{\n31 ArrayList<Entry<K,V>> buffer = new ArrayList<>(n);\n32 for (Entry<K,V> e : entrySet())\n33 buffer.add(e);\n34 capacity = newCap;\n35 createTable(); // based on updated capacity\n36 n = 0; // will be recomputed while reinserting entries\n37 for (Entry<K,V> e : buffer)\n38 put(e.getKey(), e.getValue());\n39\n}\n40 // protected abstract methods to be implemented by subclasses\n41 protected abstract void createTable();\n42 protected abstract V bucketGet(int h, K k);\n43 protected abstract V bucketPut(int h, K k, V v);\n44 protected abstract V bucketRemove(int h, K k);\n45\n}\nCode Fragment 10.7: A base class for our hash table implementations, extending\ntheAbstractMapclassfromCodeFragment10.3.\nwww.it-ebooks.info\n424 Chapter10. Maps,HashTables,andSkipLists\nSeparate Chaining\nTo represent each bucket for separate chaining, we use an instance of the simpler\nUnsortedTableMap class from Section 10.1.4. This technique, in which we use a\nsimplesolution toaproblem tocreate anew,moreadvanced solution, isknownas\nbootstrapping. The advantage of using a map for each bucket is that it becomes\neasy to delegate responsibilities for top-level map operations to the appropriate\nbucket.\nThe entire hash table is then represented as a fixed-capacity array A of the\nsecondary maps. Each cell, A[h], is initially a null reference; we only create a\nsecondary mapwhenanentryisfirsthashedtoaparticular bucket.\nAs a general rule, we implement bucketGet(h, k) by calling A[h].get(k), we\nimplement bucketPut(h, k, v) by calling A[h].put(k, v), and bucketRemove(h, k)\nbycallingA[h].remove(k). However,careisneeded fortworeasons.\nFirst, because we choose to leave table cells as null until a secondary map is\nneeded, each of these fundamental operations must begin by checking to see if\nA[h] is null. In the case of bucketGet and bucketRemove, if the bucket does not\nyet exist, we can simply return null as there can not be any entry matching key k.\nIn the case of bucketPut, a new entry must be inserted, so we instantiate a new\nUnsortedTableMapforA[h]beforecontinuing.\nThe second issue is that, in our AbstractHashMap framework, the subclass\nhastheresponsibility toproperly maintaintheinstance variable nwhenanentryis\nnewly inserted or deleted. Remember that when put(k, v) is called on a map, the\nsizeofthemaponlyincreasesifkeykisnewtothemap(otherwise,thevalueofan\nexisting entryisreassigned). Similarly, acalltoremove(k)onlydecreases thesize\nofthemapwhenanentry withkeyequal tok isfound. Inourimplementation, we\ndetermine the change in theoverall size ofthe map, by determining ifthere isany\nchangeinthesizeoftherelevantsecondary mapbeforeandafteranoperation.\nCode Fragment 10.8 provides a complete definition for our ChainHashMap\nclass,whichimplementsahashtablewithseparatechaining. Ifweassumethatthe\nhash function performs well, a map with n entries and a table of capacity N will\nhaveanexpectedbucketsizeofn/N (recall,thisisitsloadfactor). Soeventhough\nthe individual buckets, implemented as UnsortedTableMap instances, are not par-\nticularly efficient, each bucket has expected O(1) size, provided that n is O(N),\nas inour implementation. Therefore, the expected running timeof operations get,\nput, and remove for this map is O(1). The entrySet method (and thus the related\nkeySetandvalues)runsinO(n+N)time,asitloopsthroughthelengthofthetable\n(withlengthN)andthroughallbuckets (whichhavecumulativelengthsn).\nwww.it-ebooks.info\n10.2. HashTables 425\n1 public class ChainHashMap<K,V> extends AbstractHashMap<K,V>\n{\n2 // a fixed capacity array of UnsortedTableMap that serve as buckets\n3 private UnsortedTableMap<K,V>[ ] table; // initialized within createTable\n4 public ChainHashMap() super();\n{ }\n5 public ChainHashMap(int cap) super(cap);\n{ }\n6 public ChainHashMap(int cap, int p) super(cap, p);\n7 /\u2217\u2217 Creates an empty table having leng { th equal to curre } nt capacity. \u2217/\n8 protected void createTable()\n{\n9 table = (UnsortedTableMap<K,V>[ ]) new UnsortedTableMap[capacity];\n10\n11 } /\u2217\u2217 Returns value associated with key k in bucket with hash value h, or else null. \u2217/\n12 protected V bucketGet(int h, K k)\n{\n13 UnsortedTableMap<K,V> bucket = table[h];\n14 if (bucket == null) return null;\n15 return bucket.get(k);\n16\n17 } /\u2217\u2217 Associates key k with value v in bucket with hash value h; returns old value. \u2217/\n18 protected V bucketPut(int h, K k, V v)\n{\n19 UnsortedTableMap<K,V> bucket = table[h];\n20 if (bucket == null)\n21 bucket = table[h] = new UnsortedTableMap<>();\n22 int oldSize = bucket.size();\n23 V answer = bucket.put(k,v);\n24 n += (bucket.size() oldSize); // size may have increased\n\u2212\n25 return answer;\n26\n27 } /\u2217\u2217 Removes entry having key k from bucket with hash value h (if any). \u2217/\n28 protected V bucketRemove(int h, K k)\n{\n29 UnsortedTableMap<K,V> bucket = table[h];\n30 if (bucket == null) return null;\n31 int oldSize = bucket.size();\n32 V answer = bucket.remove(k);\n33 n = (oldSize bucket.size()); // size may have decreased\n\u2212 \u2212\n34 return answer;\n35\n36 } /\u2217\u2217 Returns an iterable collection of all key-value entries of the map. \u2217/\n37 public Iterable<Entry<K,V>> entrySet()\n{\n38 ArrayList<Entry<K,V>> buffer = new ArrayList<>();\n39 for (int h=0; h < capacity; h++)\n40 if (table[h] != null)\n41 for (Entry<K,V> entry : table[h].entrySet())\n42 buffer.add(entry);\n43 return buffer;\n44\n}\n45\n}\nCodeFragment10.8:Aconcretehashmapimplementationusingseparatechaining.\nwww.it-ebooks.info\n426 Chapter10. Maps,HashTables,andSkipLists\nLinear Probing\nOur implementation of a ProbeHashMap class, using open addressing with linear\nprobing, isgiveninCodeFragments10.9and10.10. Inordertosupport deletions,\nweuseatechnique described inSection10.2.2inwhichweplaceaspecialmarker\nin a table location at which an entry has been deleted, so that we can distinguish\nbetween it and a location that has always been empty. To this end, we create a\nfixedentryinstance,DEFUNCT,asasentinel(disregardinganykeyorvaluestored\nwithin),andusereferences tothatinstancetomarkvacatedcells.\nThe most challenging aspect of open addressing is to properly trace the series\nofprobeswhencollisions occurduringasearchforanexistingentry,orplacement\nofanewentry. Tothisend,thethreeprimarymapoperations eachrelyonautility,\nfindSlot, that searches for an entry with key k in \u201cbucket\u201d h (that is, where h is\nthe index returned by the hash function for key k). When attempting to retrieve\nthe value associated with a given key, we must continue probing until we find the\nkey, oruntil wereach atable slot with anullreference. Wecannot stop the search\nupon reaching an DEFUNCT sentinel, because it represents a location that may\nhavebeenfilledatthetimethedesiredentrywasonceinserted.\nWhenakey-value pairisbeingplacedinthemap,wemustfirstattempttofind\nanexistingentrywiththegivenkey,sothatwemightoverwriteitsvalue. Therefore,\nwemustsearchbeyondanyoccurrencesoftheDEFUNCTsentinelwheninserting.\nHowever, if no match is found, we prefer to repurpose the first slot marked with\nDEFUNCT,ifany,whenplacingthenewelementinthetable. ThefindSlotmethod\nenactsthislogic,continuinganunsuccessfulsearchuntilfindingatrulyemptyslot,\nandreturning theindexofthefirstavailableslotforaninsertion.\nWhendeletinganexistingentrywithinbucketRemove,weintentionallysetthe\ntableentrytotheDEFUNCTsentinelinaccordance withourstrategy.\n1 public class ProbeHashMap<K,V> extends AbstractHashMap<K,V>\n{\n2 private MapEntry<K,V>[ ] table; // a fixed array of entries (all initially null)\n3 private MapEntry<K,V> DEFUNCT = new MapEntry<>(null, null); //sentinel\n4 public ProbeHashMap() super();\n{ }\n5 public ProbeHashMap(int cap) super(cap);\n{ }\n6 public ProbeHashMap(int cap, int p) super(cap, p);\n7 /\u2217\u2217 Creates an empty table having leng { th equal to curre } nt capacity. \u2217/\n8 protected void createTable()\n{\n9 table = (MapEntry<K,V>[ ]) new MapEntry[capacity]; // safe cast\n10\n11 } /\u2217\u2217 Returns true if location is either empty or the \u201ddefunct\u201d sentinel. \u2217/\n12 private boolean isAvailable(int j)\n{\n13 return (table[j] == null table[j] == DEFUNCT);\n||\n14\n}\nCode Fragment 10.9: Concrete ProbeHashMap class that uses linear probing for\ncollision resolution. (Continues inCodeFragment10.10.)\nwww.it-ebooks.info\n10.2. HashTables 427\n15 /\u2217\u2217 Returns index with key k, or (a+1) such that k could be added at index a. \u2217/\n\u2212\n16 private int findSlot(int h, K k)\n{\n17 int avail = 1; // no slot available (thus far)\n\u2212\n18 int j = h; // index while scanning table\n19 do\n{\n20 if (isAvailable(j)) // may be either empty or defunct\n{\n21 if (avail == 1) avail = j; // this is the first available slot!\n\u2212\n22 if (table[j] == null) break; // if empty, search fails immediately\n23 else if (table[j].getKey().equals(k))\n}\n24 return j; // successful match\n25 j = (j+1) % capacity; // keep looking (cyclically)\n26 while (j != h); // stop if we return to the start\n}\n27 return (avail + 1); // search has failed\n\u2212\n28\n29 } /\u2217\u2217 Returns value associated with key k in bucket with hash value h, or else null. \u2217/\n30 protected V bucketGet(int h, K k)\n{\n31 int j = findSlot(h, k);\n32 if (j < 0) return null; // no match found\n33 return table[j].getValue();\n34\n35 } /\u2217\u2217 Associates key k with value v in bucket with hash value h; returns old value. \u2217/\n36 protected V bucketPut(int h, K k, V v)\n{\n37 int j = findSlot(h, k);\n38 if (j >= 0) // this key has an existing entry\n39 return table[j].setValue(v);\n40 table[ (j+1)] = new MapEntry<>(k, v); // convert to proper index\n\u2212\n41 n++;\n42 return null;\n43\n44 } /\u2217\u2217 Removes entry having key k from bucket with hash value h (if any). \u2217/\n45 protected V bucketRemove(int h, K k)\n{\n46 int j = findSlot(h, k);\n47 if (j < 0) return null; // nothing to remove\n48 V answer = table[j].getValue();\n49 table[j] = DEFUNCT; // mark this slot as deactivated\n50 n ;\n\u2212\u2212\n51 return answer;\n52\n53 } /\u2217\u2217 Returns an iterable collection of all key-value entries of the map. \u2217/\n54 public Iterable<Entry<K,V>> entrySet()\n{\n55 ArrayList<Entry<K,V>> buffer = new ArrayList<>();\n56 for (int h=0; h < capacity; h++)\n57 if (!isAvailable(h)) buffer.add(table[h]);\n58 return buffer;\n59\n}\n60\n}\nCodeFragment10.10: Concrete ProbeHashMap class that uses linear probing for\ncollision resolution (continued fromCodeFragment10.9).\nwww.it-ebooks.info\n428 Chapter10. Maps,HashTables,andSkipLists\n10.3 Sorted Maps\nThetraditionalmapADTallowsausertolookupthevalueassociatedwithagiven\nkey,butthesearchforthatkeyisaformknownasanexactsearch. Inthissection,\nwe will introduce an extension known as the sorted map ADT that includes all\nbehaviors ofthestandardmap,plusthefollowing:\nfirstEntry(): Returns the entry with smallest key value (or null, if the\nmapisempty).\nlastEntry(): Returns the entry with largest key value (or null, if the\nmapisempty).\nceilingEntry(k): Returnstheentrywiththeleastkeyvaluegreaterthanor\nequaltok(ornull,ifnosuchentryexists).\nfloorEntry(k): Returnstheentrywiththegreatestkeyvaluelessthanor\nequaltok(ornull,ifnosuchentryexists).\nlowerEntry(k): Returnstheentrywiththegreatest keyvaluestrictly less\nthank(ornull,ifnosuchentryexists).\nhigherEntry(k): Returnstheentrywiththeleastkeyvaluestrictly greater\nthank(ornullifnosuchentryexists).\nsubMap(k ,k ): Returnsaniterationofallentrieswithkeygreaterthanor\n1 2\nequaltok ,butstrictlylessthank .\n1 2\nWe note that the above methods are included within the java.util.NavigableMap\ninterface (whichextendsthesimplerjava.util.SortedMapinterface).\nTomotivatetheuseofasortedmap,consideracomputersystemthatmaintains\ninformationabouteventsthathaveoccurred(suchasfinancialtransactions), witha\ntime stamp marking the occurrence ofeach event. If the timestamps were unique\nforaparticularsystem,wecouldorganizeamapwithatimestampservingasakey,\nand a record about the event that occurred at that time as the value. A particular\ntimestampcouldserveasareferenceIDforanevent,inwhichcasewecanquickly\nretrieve information about that event from the map. However, the (unsorted) map\nADT does not provide any way to get a list of all events ordered by the time at\nwhichtheyoccur,ortosearchforwhicheventoccurredclosesttoaparticulartime.\nInfact,hash-basedimplementationsofthemapADTintentionally scatterkeysthat\nmay seem very \u201cnear\u201d to each other in the original domain, so that they are more\nuniformlydistributed inahashtable.\nwww.it-ebooks.info\n10.3. SortedMaps 429\n10.3.1 Sorted Search Tables\nSeveral data structures can efficiently support the sorted map ADT, and we will\nexaminesomeadvancedtechniquesinSection10.4andChapter11. Inthissection,\nwewillbegin byexploring asimpleimplementation ofasortedmap. Westorethe\nmap\u2019s entries in an array list A so that they are in increasing order of their keys.\n(SeeFigure10.8.) Werefertothisimplementation asasortedsearchtable.\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n2 4 5 7 8 9 12 14 17 19 22 25 27 28 33 37\nFigure10.8: Realizationofamapbymeansofasortedsearchtable. Weshowonly\nthekeysforthismap,soastohighlight theirordering.\nAswasthecasewiththeunsortedtablemapofSection10.1.4,thesortedsearch\ntablehasaspacerequirementthatisO(n). Theprimaryadvantageofthisrepresen-\ntation, and ourreason forinsisting thatAbearray-based, isthatitallowsustouse\nthebinarysearchalgorithm foravarietyofefficientoperations.\nBinary Search and Inexact Searches\nWeoriginallypresentedthebinarysearchalgorithminSection5.1.3,asameansfor\ndetecting whether agiventarget isstored withinasorted sequence. Inouroriginal\npresentation (Code Fragment 5.3 on page 197), a binarySearch method returned\ntrueorfalsetodesignate whetherthedesiredtargetwasfound.\nTheimportant realization isthat, whileperforming abinary search, wecanin-\nsteadreturntheindexatornearwhereatargetmightbefound. Duringasuccessful\nsearch, thestandard implementation determines theprecise index atwhich thetar-\nget is found. During an unsuccessful search, although the target is not found, the\nalgorithm will effectively determine a pair of indices designating elements of the\ncollection thatarejustlessthanorjustgreaterthanthemissingtarget.\nIn Code Fragments 10.11 and 10.12, we present a complete implementation\nof a class, SortedTableMap, that supports the sorted map ADT. The most notable\nfeature of our design is the inclusion of a findIndex utility method. This method\nuses the recursive binary search algorithm, but returns the index of the leftmost\nentry in the search range having key greater than or equal to k; if no entry in the\nsearch range has such a key, wereturn the index just beyond the end of the search\nrange. Bythisconvention,ifanentryhasthetargetkey,thesearchreturnstheindex\nofthatentry. (Recallthatkeysareuniqueinamap.) Ifthekeyisabsent,themethod\nreturnstheindexatwhichanewentrywiththatkeywouldbeinserted.\nwww.it-ebooks.info\n430 Chapter10. Maps,HashTables,andSkipLists\n1 public class SortedTableMap<K,V> extends AbstractSortedMap<K,V>\n{\n2 private ArrayList<MapEntry<K,V>> table = new ArrayList<>();\n3 public SortedTableMap() super();\n{ }\n4 public SortedTableMap(Comparator<K> comp) super(comp);\n5 /\u2217\u2217 Returns the smallest index for range table[low { ..high] inclusive } storing an entry\n6 with a key greater than or equal to k (or else index high+1, by convention). \u2217/\n7 private int findIndex(K key, int low, int high)\n{\n8 if (high < low) return high + 1; // no entry qualifies\n9 int mid = (low + high) / 2;\n10 int comp = compare(key, table.get(mid));\n11 if (comp == 0)\n12 return mid; // found exact match\n13 else if (comp < 0)\n14 return findIndex(key, low, mid 1); // answer is left of mid (or possibly mid)\n\u2212\n15 else\n16 return findIndex(key, mid + 1, high); // answer is right of mid\n17\n18 } /\u2217\u2217 Version of findIndex that searches the entire table \u2217/\n19 private int findIndex(K key) return findIndex(key, 0, table.size() 1);\n20 /\u2217\u2217 Returns the number of en { tries in the map. \u2217/ \u2212 }\n21 public int size() return table.size();\n22 /\u2217\u2217 Returns the v { alue associated with t } he specified key (or else null). \u2217/\n23 public V get(K key)\n{\n24 int j = findIndex(key);\n25 if (j == size() compare(key, table.get(j)) != 0) return null; // no match\n||\n26 return table.get(j).getValue();\n27\n28 } /\u2217\u2217 Associates the given value with the given key, returning any overridden value.\u2217/\n29 public V put(K key, V value)\n{\n30 int j = findIndex(key);\n31 if (j < size() && compare(key, table.get(j)) == 0) // match exists\n32 return table.get(j).setValue(value);\n33 table.add(j, new MapEntry<K,V>(key,value)); // otherwise new\n34 return null;\n35\n36 } /\u2217\u2217 Removes the entry having key k (if any) and returns its associated value. \u2217/\n37 public V remove(K key)\n{\n38 int j = findIndex(key);\n39 if (j == size() compare(key, table.get(j)) != 0) return null; // no match\n||\n40 return table.remove(j).getValue();\n41\n}\nCode Fragment 10.11: An implementation of the SortedTableMap class. (Con-\ntinues in Code Fragment 10.12.) The AbstractSortedMap base class (available\nonline), providestheutilitymethod,compare,basedonagivencomparator.\nwww.it-ebooks.info\n10.3. SortedMaps 431\n42 /\u2217\u2217 Utility returns the entry at index j, or else null if j is out of bounds. \u2217/\n43 private Entry<K,V> safeEntry(int j)\n{\n44 if (j < 0 j >= table.size()) return null;\n||\n45 return table.get(j);\n46\n47 } /\u2217\u2217 Returns the entry having the least key (or null if map is empty). \u2217/\n48 public Entry<K,V> firstEntry() return safeEntry(0);\n49 /\u2217\u2217 Returns the entry having the { greatest key (or null if } map is empty). \u2217/\n50 public Entry<K,V> lastEntry() return safeEntry(table.size() 1);\n51 /\u2217\u2217 Returns the entry with least { key greater than or equal to giv \u2212 en ke } y (if any). \u2217/\n52 public Entry<K,V> ceilingEntry(K key)\n{\n53 return safeEntry(findIndex(key));\n54\n55 } /\u2217\u2217 Returns the entry with greatest key less than or equal to given key (if any). \u2217/\n56 public Entry<K,V> floorEntry(K key)\n{\n57 int j = findIndex(key);\n58 if (j == size() ! key.equals(table.get(j).getKey()))\n||\n59 j ; // look one earlier (unless we had found a perfect match)\n\u2212\u2212\n60 return safeEntry(j);\n61\n62 } /\u2217\u2217 Returns the entry with greatest key strictly less than given key (if any). \u2217/\n63 public Entry<K,V> lowerEntry(K key)\n{\n64 return safeEntry(findIndex(key) 1); // go strictly before the ceiling entry\n\u2212\n65\n}\n66 public Entry<K,V> higherEntry(K key)\n67 /\u2217\u2217 Returns the entry with least key stric { tly greater than given key (if any). \u2217/\n68 int j = findIndex(key);\n69 if (j < size() && key.equals(table.get(j).getKey()))\n70 j++; // go past exact match\n71 return safeEntry(j);\n72\n}\n73 // support for snapshot iterators for entrySet() and subMap() follow\n74 private Iterable<Entry<K,V>> snapshot(int startIndex, K stop)\n{\n75 ArrayList<Entry<K,V>> buffer = new ArrayList<>();\n76 int j = startIndex;\n77 while (j < table.size() && (stop == null compare(stop, table.get(j)) > 0))\n||\n78 buffer.add(table.get(j++));\n79 return buffer;\n80\n}\n81 public Iterable<Entry<K,V>> entrySet() return snapshot(0, null);\n{ }\n82 public Iterable<Entry<K,V>> subMap(K fromKey, K toKey)\n{\n83 return snapshot(findIndex(fromKey), toKey);\n84\n}\n85\n}\nCodeFragment10.12:AnimplementationoftheSortedTableMapclass(continued\nfromCodeFragment10.11).\nwww.it-ebooks.info\n432 Chapter10. Maps,HashTables,andSkipLists\nAnalysis\nWe conclude by analyzing the performance of our SortedTableMap implementa-\ntion. A summary of the running times for all methods of the sorted map ADT\n(including thetraditional mapoperations) isgiveninTable10.3. Itshould beclear\nthatthesize,firstEntry,andlastEntrymethodsruninO(1)time,andthatiterating\nthekeysofthetableineitherdirection canbeperformed inO(n)time.\nTheanalysisforthevariousformsofsearchalldependonthefactthatabinary\nsearch on a table with n entries runs in O(logn) time. This claim was originally\nshown as Proposition 5.2 in Section 5.2, and that analysis clearly applies to our\nfindIndexmethodaswell. Wetherefore claimanO(logn)worst-caserunningtime\nfor methods get, ceilingEntry, floorEntry, lowerEntry, and higherEntry. Each of\nthesemakesasinglecalltofindIndex,followedbyaconstantnumberofadditional\nsteps to determine the appropriate answer based on the index. The analysis of\nsubMap is a bit more interesting. It begins with a binary search to find the first\nitemwithintherange(ifany). Afterthat,itexecutesaloopthattakesO(1)timeper\niteration to gather subsequent values until reaching the end of the range. If there\naresitemsreportedintherange, thetotalrunning timeisO(s+logn).\nIn contrast to the efficient search operations, update operations for a sorted\ntable may take considerable time. Although binary search can help identify the\nindexatwhichanupdateoccurs,bothinsertions anddeletionsrequire,intheworst\ncase,thatlinearlymanyexistingelementsbeshiftedinordertomaintainthesorted\norder of thetable. Specifically, thepotential call totable.addfrom within put and\ntable.removefromwithinremoveleadtoO(n)worst-casetime. (Seethediscussion\nofcorresponding operations oftheArrayListclassinSection7.2.)\nIn conclusion, sorted tables are primarily used in situations where we expect\nmanysearches butrelatively fewupdates.\nMethod RunningTime\nsize O(1)\nget O(logn)\nput O(n);O(logn)ifmaphasentrywithgivenkey\nremove O(n)\nfirstEntry,lastEntry O(1)\nceilingEntry,floorEntry,\nO(logn)\nlowerEntry,higherEntry\nsubMap O(s+logn)wheresitemsarereported\nentrySet,keySet,values O(n)\nTable 10.3: Performance of a sorted map, as implemented with SortedTableMap.\nWe use n to denote the number of items in the map at the time the operation is\nperformed. Thespacerequirement isO(n).\nwww.it-ebooks.info\n10.3. SortedMaps 433\n10.3.2 Two Applications of Sorted Maps\nIn this section, we explore applications in which there is particular advantage to\nusing a sorted map rather than a traditional (unsorted) map. To apply a sorted\nmap, keys must come from a domain that is totally ordered. Furthermore, to take\nadvantage of the inexact or range searches afforded by a sorted map, there should\nbesomereasonwhynearbykeyshaverelevance toasearch.\nFlight Databases\nThere are several websites on the Internet that allow users to perform queries on\nflight databases to find flights between various cities, typically with the intent to\nbuyaticket. Tomakeaquery,auserspecifiesoriginanddestinationcities,adepar-\nture date, and a departure time. To support such queries, we can model the flight\ndatabase asamap, where keys areFlightobjects that contain fields corresponding\ntothesefourparameters. Thatis,akeyisatuple\nk=(origin,destination,date,time).\nAdditionalinformationaboutaflight,suchastheflightnumber,thenumberofseats\nstill available in first (F) and coach (Y)class, the flight duration, and the fare, can\nbestoredinthevalueobject.\nFinding a requested flight is not simply a matter of finding an exact match for\na requested query. Although a user typically wants to exactly match the origin\nand destination cities, he or she may have flexibility for the departure date, and\ncertainly will have some flexibility for the departure time on a specific day. We\ncanhandle such aquery byordering ourkeyslexicographically. Then, anefficient\nimplementation for a sorted map would be a good way to satisfy users\u2019 queries.\nFor instance, given a user query key k, we could call ceilingEntry(k) to return the\nfirst flight between the desired cities, having a departure date and time matching\nthe desired query or later. Better yet, with well-constructed keys, we could use\nsubMap(k , k ) to find all flights within a given range of times. For example, if\n1 2\nk1 = (ORD, PVD, 05May, 09:30), and k2 = (ORD, PVD, 05May, 20:00), a re-\nspectivecalltosubMap(k ,k )mightresultinthefollowingsequenceofkey-value\n1 2\npairs:\n(ORD, PVD, 05May, 09:53) : (AA 1840, F5, Y15, 02:05, $251),\n(ORD, PVD, 05May, 13:29) : (AA 600, F2, Y0, 02:16, $713),\n(ORD, PVD, 05May, 17:39) : (AA 416, F3, Y9, 02:09, $365),\n(ORD, PVD, 05May, 19:50) : (AA 1828, F9, Y25, 02:13, $186)\nwww.it-ebooks.info\n434 Chapter10. Maps,HashTables,andSkipLists\nMaxima Sets\nLifeisfulloftrade-offs. Weoftenhavetotradeoffadesiredperformancemeasure\nagainstacorrespondingcost. Suppose,forthesakeofanexample,weareinterested\nin maintaining a database rating automobiles by their maximum speeds and their\ncost. Wewouldliketoallowsomeonewithacertainamountofmoneytoqueryour\ndatabase tofindthefastestcartheycanpossibly afford.\nWe can model such a trade-off problem as this by using a key-value pair to\nmodel the two parameters that we are trading off, which in this case would be the\npair (cost,speed) for each car. Notice that some cars are strictly better than other\ncars using this measure. For example, a car with cost-speed pair (30000,100) is\nstrictly better than a car with cost-speed pair (40000,90). At the same time, there\naresomecarsthatarenotstrictlydominatedbyanothercar. Forexample,acarwith\ncost-speedpair(30000,100)maybebetterorworsethanacarwithcost-speedpair\n(40000,120), dependingonhowmuchmoneywehavetospend. (SeeFigure10.9.)\necnamrofreP\nh\ng\nf\np\ne\nd\nc\nb\na\nCost\nFigure 10.9: Illustrating the cost-performance trade-off with pairs represented by\npoints intheplane. Noticethat point pisstrictly better than points c,d,ande, but\nmaybebetterorworsethanpoints a,b, f,g,andh,depending onthepriceweare\nwillingtopay. Thus, ifweweretoadd ptoourset, wecould removethepoints c,\nd,ande,butnottheothers.\nFormally, we say a cost-performance pair (a,b) dominates pair (c,d)=(a,b)\n6\nif a c and b d, that is, if the first pair has no greater cost and at least as good\n\u2264 \u2265\nperformance. Apair (a,b) is called a maximum pair if it is not dominated by any\nother pair. We are interested in maintaining the set of maxima of a collection of\ncost-performance pairs. That is, we would like to add new pairs to this collection\n(forexample,whenanewcarisintroduced),andtoquerythiscollectionforagiven\ndollaramount,d,tofindthefastestcarthatcostsnomorethand dollars.\nwww.it-ebooks.info\n10.3. SortedMaps 435\nMaintaining a Maxima Set with a Sorted Map\nWecanstorethesetofmaximapairsinasortedmapsothatthecostisthekeyfield\nandperformance(speed)isthevalue. Wecanthenimplementoperationsadd(c,p),\nwhich adds a new cost-performance entry (c,p), and best(c), which returns the\nentry having best performance of those with cost at most c. Code Fragment 10.13\nprovidesanimplementation ofsuchaCostPerformanceDatabaseclass.\n1 /\u2217\u2217 Maintains a database of maximal (cost,performance) pairs. \u2217/\n2 public class CostPerformanceDatabase\n{\n3\n4 SortedMap<Integer,Integer> map = new SortedTableMap<>();\n5\n6 /\u2217\u2217 Constructs an initially empty database. \u2217/\n7 public CostPerformanceDatabase()\n{ }\n8\n9 /\u2217\u2217 Returns the (cost,performance) entry with largest cost not exceeding c.\n10 \u2217 (or null if no entry exist with cost c or less).\n11 \u2217/\n12 public Entry<Integer,Integer> best(int cost)\n{\n13 return map.floorEntry(cost);\n14\n}\n15\n16 /\u2217\u2217 Add a new entry with given cost c and performance p. \u2217/\n17 public void add(int c, int p)\n{\n18 Entry<Integer,Integer> other = map.floorEntry(c); // other is at least as cheap\n19 if (other != null && other.getValue() >= p) // if its performance is as good,\n20 return; // (c,p) is dominated, so ignore\n21 map.put(c, p); // else, add (c,p) to database\n22 // and now remove any entries that are dominated by the new one\n23 other = map.higherEntry(c); // other is more expensive than c\n24 while (other != null && other.getValue() <= p) // if not better performance\n{\n25 map.remove(other.getKey()); // remove the other entry\n26 other = map.higherEntry(c);\n27\n}\n28\n}\n29\n}\nCodeFragment10.13: Animplementation of aclass maintaining a set of maximal\ncost-performance entriesusingasortedmap.\nUnfortunately, if we implement the sorted map using the SortedTableMap\nclass, the add behavior has O(n) worst-case running time. If, on the other hand,\nwe implement the map using a skip list, which we next describe, we can perform\nbest(c)queriesinO(logn)expected timeandadd(c,p)updatesinO((1+r)logn)\nexpectedtime,wherer isthenumberofpointsremoved.\nwww.it-ebooks.info\n436 Chapter10. Maps,HashTables,andSkipLists\n10.4 Skip Lists\nInSection 10.3.1, wesaw that asorted table willallow O(logn)-time searches via\nthebinarysearchalgorithm. Unfortunately,updateoperationsonasortedtablehave\nO(n) worst-case running time because of the need to shift elements. In Chapter 7\nwe demonstrated that linked lists support very efficient update operations, as long\nas the position within the list is identified. Unfortunately, we cannot perform fast\nsearchesonastandardlinkedlist;forexample,thebinarysearchalgorithmrequires\nanefficientmeansfordirectaccessing anelementofasequence byindex.\nAninterestingdatastructureforefficientlyrealizingthesortedmapADTisthe\nskip list. Skip lists provide a clever compromise to efficiently support search and\nupdate operations; they are implemented as the java.util.ConcurrentSkipListMap\nclass. A skip list S for a map M consists of a series of lists S ,S ,...,S . Each\n0 1 h\n{ }\nlistS storesasubsetoftheentriesofMsortedbyincreasingkeys,plusentrieswith\ni\ntwosentinelkeysdenoted and+ ,where issmallerthaneverypossible\n\u2212\u221e \u221e \u2212\u221e\nkeythatcanbeinserted inM and+ islargerthaneverypossible keythatcanbe\n\u221e\ninserted inM. Inaddition, thelistsinSsatisfythefollowing:\nListS contains everyentryofthemapM (plussentinels and+ ).\n0\n\u2022 \u2212\u221e \u221e\nFori=1,...,h 1,listS contains(inadditionto and+ )arandomly\ni\n\u2022 \u2212 \u2212\u221e \u221e\ngenerated subsetoftheentriesinlistS .\ni\u22121\nListS contains only and+ .\nh\n\u2022 \u2212\u221e \u221e\nAn example of a skip list is shown in Figure 10.10. It is customary to visualize a\nskiplistSwithlistS atthebottomandlistsS ,...,S aboveit. Also,werefertoh\n0 1 h\nastheheightofskiplistS.\nIntuitively, the lists are set up so that S contains roughly alternate entries\ni+1\nofS. However,thehalvingofthenumberofentriesfromonelisttothenextisnot\ni\nenforced as an explicit property of skip lists; instead, randomization is used. As\nS 5 -\u221e +\u221e\nS 4 -\u221e 17 +\u221e\nS 3 -\u221e 17 25 55 +\u221e\nS 2 -\u221e 17 25 31 55 +\u221e\nS 1 -\u221e 12 17 25 31 44 55 +\u221e\nS 0 -\u221e 12 17 20 25 31 38 39 44 50 55 +\u221e\nFigure 10.10: Example of a skip list storing 10 entries. For simplicity, we show\nonlytheentries\u2019 keys,nottheirassociated values.\nwww.it-ebooks.info\n10.4. SkipLists 437\nwe shall see in the details of the insertion method, the entries in S are chosen\ni+1\nat random from the entries in S by picking each entry from S to also be in S\ni i i+1\nwith probability 1/2. That is, in essence, we \u201cflip a coin\u201d for each entry in S and\ni\nplace that entry in S if the coin comes up \u201cheads.\u201d Thus, we expect S to have\ni+1 1\nabout n/2 entries, S to have about n/4 entries, and, in general, S to have about\n2 i\nn/2i entries. Asaconsequence, weexpecttheheighthofStobeaboutlogn.\nFunctions thatgenerate random-like numbers arebuilt into mostmodern com-\nputers, because they are used extensively in computer games, cryptography, and\ncomputer simulations. Some functions, called pseudorandom number genera-\ntors, generate such numbers, starting with an initial seed. (See discussion of the\njava.util.Random class in Section 3.1.3.) Other methods use hardware devices to\nextract \u201ctrue\u201d random numbers from nature. In any case, we will assume that our\ncomputerhasaccesstonumbersthataresufficiently randomforouranalysis.\nAnadvantageofusingrandomizationindatastructureandalgorithmdesignis\nthatthestructures andmethodsthatresultcanbesimpleandefficient. Theskiplist\nhas the same logarithmic time bounds for searching as is achieved by the binary\nsearchalgorithm,yetitextendsthatperformancetoupdatemethodswheninserting\nor deleting entries. Nevertheless, the bounds are expected for the skip list, while\nbinarysearchofasortedtablehasaworst-casebound.\nA skip list makes random choices in arranging its structure in such a way that\nsearch andupdate timesareO(logn)onaverage, wherenisthenumberofentries\ninthemap. Interestingly, thenotionofaveragetimecomplexityusedheredoesnot\ndepend on the probability distribution of the keys in the input. Instead, it depends\non the use of a random-number generator in the implementation of the insertions\ntohelpdecide wheretoplacethenewentry. Therunning timeisaveraged overall\npossible outcomesoftherandom numbersusedwheninserting entries.\nAs with the position abstraction used for lists and trees, we view a skip list\nas a two-dimensional collection of positions arranged horizontally into levels and\nvertically into towers. Each level is a list S and each tower contains positions\ni\nstoring the same entry across consecutive lists. The positions in a skip list can be\ntraversed usingthefollowingoperations:\nnext(p): Returnstheposition following ponthesamelevel.\nprev(p): Returnstheposition preceding ponthesamelevel.\nabove(p): Returnstheposition above pinthesametower.\nbelow(p): Returnstheposition below pinthesametower.\nWeconventionallyassumethattheseoperationsreturnnullifthepositionrequested\ndoesnotexist. Withoutgoingintothedetails,wenotethatwecaneasilyimplement\naskiplistbymeansofalinkedstructuresuchthattheindividual traversalmethods\neach take O(1) time, given askip-list position p. Such alinked structure is essen-\ntially acollection ofhdoubly linked lists aligned attowers, which arealsodoubly\nlinkedlists.\nwww.it-ebooks.info\n438 Chapter10. Maps,HashTables,andSkipLists\n10.4.1 Search and Update Operations in a Skip List\nThe skip-list structure affords simple map search and update algorithms. In fact,\nalloftheskip-listsearchandupdatealgorithmsarebasedonanelegantSkipSearch\nmethodthattakesakeykandfindstheposition poftheentryinlistS thathasthe\n0\nlargestkeylessthanorequaltok(whichispossibly ).\n\u2212\u221e\nSearching in a Skip List\nSuppose weare given a search key k. Webegin the SkipSearch method by setting\na position variable p to the topmost, left position in the skip list S, called the start\nposition of S. That is, the start position is the position of S storing the special\nh\nentrywithkey . Wethenperformthefollowingsteps(seeFigure10.11),where\n\u2212\u221e\nkey(p)denotesthekeyoftheentryatposition p:\n1. If S.below(p) is null, then the search terminates\u2014we are at the bottom and\nhavelocatedtheentryinSwiththelargestkeylessthanorequaltothesearch\nkeyk. Otherwise, wedrop downtothenextlowerlevelinthepresent tower\nbysetting p=S.below(p).\n2. Startingatposition p,wemove pforwarduntilitisattherightmostposition\nonthepresentlevelsuchthatkey(p) k. Wecallthisthescanforwardstep.\n\u2264\nNote that such a position always exists, since each level contains the keys\n+ and . It may be that p remains where it started after we perform\n\u221e \u2212\u221e\nsuchaforwardscanforthislevel.\n3. Returntostep1.\nS 5 -\u221e +\u221e\nS 4 -\u221e 17 +\u221e\nS 3 -\u221e 17 25 55 +\u221e\nS 2 -\u221e 17 25 31 55 +\u221e\nS 1 -\u221e 12 17 25 31 44 55 +\u221e\nS 0 -\u221e 12 17 20 25 31 38 39 44 50 55 +\u221e\nFigure 10.11: Example of a search in a skip list. The positions examined when\nsearching forkey50arehighlighted.\nWegiveapseudocodedescriptionoftheskip-listsearchalgorithm,SkipSearch,\ninCodeFragment10.14. Giventhismethod,weperformthemapoperation get(k)\nby computing p=SkipSearch(k) and testing whether or not key(p)=k. If these\ntwokeysareequal,wereturntheassociated value;otherwise, wereturnnull.\nwww.it-ebooks.info\n10.4. SkipLists 439\nAlgorithmSkipSearch(k):\nInput: Asearchkeyk\nOutput: Position pinthebottomlistS withthelargestkeyhavingkey(p) k\n0\n\u2264\np = s beginatstartposition\n{ }\nwhile below(p)=null do\n6\np = below(p) dropdown\n{ }\nwhilek key(next(p))do\n\u2265\np = next(p) scanforward\n{ }\nreturn p\nCodeFragment10.14: Algorithm tosearch askip list S forkey k. Variable sholds\nthestartposition ofS.\nAsitturnsout,theexpectedrunningtimeofalgorithmSkipSearchonaskiplist\nwithnentries isO(logn). Wepostpone thejustification ofthisfact,however, until\nafterwediscusstheimplementationoftheupdatemethodsforskiplists. Navigation\nstartingatthepositionidentifiedbySkipSearch(k)canbeeasilyusedtoprovidethe\nadditional formsofsearchesinthesortedmapADT(e.g.,ceilingEntry,subMap).\nInsertion in a Skip List\nTheexecution of the map operation put(k,v) begins with acall to SkipSearch(k).\nThisgivesustheposition pofthebottom-level entrywiththelargestkeylessthan\norequaltok (notethat pmayholdthespecial entrywithkey ). Ifkey(p)=k,\n\u2212\u221e\nthe associated value is overwritten with v. Otherwise, we need to create a new\ntowerforentry(k,v). Weinsert(k,v)immediatelyafterposition pwithinS . After\n0\ninserting the new entry at the bottom level, we use randomization to decide the\nheightofthetowerforthenewentry. We\u201cflip\u201dacoin,andiftheflipcomesuptails,\nthen we stop here. Else (the flip comes up heads), we backtrack to the previous\n(next higher) level and insert (k,v) in this level at the appropriate position. We\nagain flip a coin; if it comes up heads, we go to the next higher level and repeat.\nThus,wecontinuetoinsertthenewentry(k,v)inlistsuntilwefinallygetaflipthat\ncomesuptails. Welinktogetherallthereferences tothenewentry(k,v)createdin\nthis process to create its tower. A fair coin flip can be simulated with Java\u2019s built-\nin pseudorandom number generator java.util.Random by calling nextBoolean(),\nwhichreturnstrueorfalse,eachwithprobability 1/2.\nWegivetheinsertionalgorithmforaskiplistSinCodeFragment10.15andwe\nillustrate it in Figure 10.12. The algorithm uses an insertAfterAbove(p, q, (k,v))\nmethod that inserts aposition storing the entry (k,v) after position p (on the same\nlevel as p) and above position q, returning the new position r (and setting internal\nreferences sothat next,prev, above,andbelowmethods willworkcorrectly for p,\nq, and r). The expected running time ofthe insertion algorithm on askip list with\nnentriesisO(logn),asweshowinSection10.4.2.\nwww.it-ebooks.info\n440 Chapter10. Maps,HashTables,andSkipLists\nAlgorithmSkipInsert(k, v):\nInput: Keykandvaluev\nOutput: Topmostposition oftheentryinsertedintheskiplist\np = SkipSearch(k) position inbottom listwithlargest keylessthank\n{ }\nq = null currentnodeofnewentry\u2019stower\n{ }\ni = 1 currentheightofnewentry\u2019stower\n\u2212 { }\nrepeat\ni = i+1 increaseheightofnewentry\u2019stower\n{ }\nifi h then\n\u2265\nh = h+1 addanewleveltotheskiplist\n{ }\nt = next(s)\ns = insertAfterAbove(null,s,( ,null)) growleftmosttower\n\u2212\u221e { }\ninsertAfterAbove(s,t,(+ ,null)) growrightmosttower\n\u221e { }\nq = insertAfterAbove(p,q,(k,v)) addnodetonewentry\u2019stower\n{ }\nwhileabove(p)==nulldo\np = prev(p) scanbackward\n{ }\np = above(p) jumpuptohigherlevel\n{ }\nuntilcoinFlip()==tails\nn = n+1\nreturnq topnodeofnewentry\u2019stower\n{ }\nCodeFragment10.15: Insertion inaskiplistofentry(k,v)Weassumetheskiplist\ndoes not have an entry with key k. Method coinFlip() returns \u201cheads\u201d or \u201ctails\u201d,\neach with probability 1/2. Instance variables n, h, and s respectively hold the\nnumberofentries, theheight,andthestartnodeoftheskiplist.\nS\n5\n-\u221e +\u221e\nS 4 -\u221e 17 +\u221e\nS 3 -\u221e 17 25 42 55 +\u221e\nS 2 -\u221e 17 25 31 42 55 +\u221e\nS 1 -\u221e 12 17 25 31 42 44 55 +\u221e\nS 0 -\u221e 12 17 20 25 31 38 39 42 44 50 55 +\u221e\nFigure 10.12: Insertion of an entry with key 42 into the skip list of Figure 10.10\nusingmethodSkipInsert(CodeFragment10.15). Weassumethattherandom\u201ccoin\nflips\u201dforthenewentry cameupheadsthree timesinarow,followed bytails. The\npositions visited are highlighted in blue. The positions of the tower of the new\nentry (variable q) are drawn with thick lines, and the positions preceding them\n(variable p)areflagged.\nwww.it-ebooks.info\n10.4. SkipLists 441\nRemoval in a Skip List\nLike the search and insertion algorithms, the removal algorithm for a skip list is\nquite simple. In fact, itis eveneasier than the insertion algorithm. Toperform the\nmap operation remove(k), we will begin by executing method SkipSearch(k). If\nthe returned position p stores an entry with key different from k, we return null.\nOtherwise, we remove p and all the positions above p, which are easily accessed\nby using aboveoperations toclimb up the towerof this entry inS starting atposi-\ntion p. While removing levels ofthe tower, wereestablish links between the hori-\nzontalneighbors ofeachremovedposition. Theremovalalgorithm isillustrated in\nFigure10.13andadetaileddescription ofitisleftasanexercise(R-10.24). Aswe\nshow in the next subsection, the remove operation in a skip list with n entries has\nO(logn)expectedrunning time.\nBefore we give this analysis, however, there are some minor improvements to\ntheskip-list datastructure wewould liketodiscuss. First,wedonotactually need\nto store references to values at the levels of the skip list above the bottom level,\nbecause all that is needed at these levels are references to keys. In fact, we can\nmore efficiently represent a tower as a single object, storing the key-value pair,\nand maintaining j previous references and j next references if the tower reaches\nlevelS . Second,forthehorizontalaxes,itispossibletokeepthelistsinglylinked,\nj\nstoringonlythenextreferences. Wecanperforminsertionsandremovalsinstrictly\na top-down, scan-forward fashion. We explore the details of this optimization in\nExercise C-10.55. Neither of these optimizations improve the asymptotic perfor-\nmance of skip lists by more than a constant factor, but these improvements can,\nnevertheless, be meaningful in practice. In fact, experimental evidence suggests\nthat optimized skip lists are faster in practice than AVL trees and other balanced\nsearchtrees,whicharediscussed inChapter11.\nS\n5\n-\u221e +\u221e\nS 4 -\u221e 17 +\u221e\nS 3 -\u221e 17 25 42 55 +\u221e\nS 2 -\u221e 17 25 31 42 55 +\u221e\nS 1 -\u221e 12 17 25 31 42 44 55 +\u221e\nS 0 -\u221e 12 17 20 25 31 38 39 42 44 50 55 +\u221e\nFigure10.13: Removalof the entry with key 25 from the skip list ofFigure 10.12.\nThe positions visited after the search for the position of S holding the entry are\n0\nhighlighted inblue. Thepositions removedaredrawnwithdashedlines.\nwww.it-ebooks.info\n442 Chapter10. Maps,HashTables,andSkipLists\nMaintaining the Topmost Level\nA skip list S must maintain a reference to the start position (the topmost, leftmost\nposition inS)asaninstance variable, andmusthaveapolicy foranyinsertion that\nwishestocontinue growingthetowerforanewentrypastthetoplevelofS. There\naretwopossible coursesofactionwecantake,bothofwhichhavetheirmerits.\nOnepossibility istorestrict thetoplevel, h,tobekeptatsomefixedvaluethat\nisafunction ofn,thenumberofentriescurrently inthemap(fromtheanalysis we\nwillseethath=max 10,2 logn isareasonablechoice,andpickingh=3 logn\n{ \u2308 \u2309} \u2308 \u2309\nis even safer). Implementing this choice means that wemust modify the insertion\nalgorithm tostopinserting anew position once wereach thetopmost level(unless\nlogn < log(n+1) ,inwhichcasewecannowgoatleastonemorelevel,since\n\u2308 \u2309 \u2308 \u2309\ntheboundontheheightisincreasing).\nThe other possibility is to let an insertion continue growing a tower as long\nas heads keep getting returned from the random number generator. This is the\napproach taken by algorithm SkipInsert of Code Fragment 10.15. As we show in\nthe analysis of skip lists, the probability that an insertion will go to a level that is\nmorethanO(logn)isverylow,sothisdesignchoiceshouldalsowork.\nEither choice will still result in the expected O(logn) time to perform search,\ninsertion, andremoval,aswewillshowinthenextsection.\n10.4.2 Probabilistic Analysis of Skip Lists \u22c6\nAs we have shown above, skip lists provide a simple implementation of a sorted\nmap. In terms of worst-case performance, however, skip lists are not a superior\ndata structure. In fact, if we do not officially prevent an insertion from continu-\ning significantly past the current highest level, then the insertion algorithm can go\ninto what is almost an infinite loop (it is not actually an infinite loop, however,\nsince the probability of having a fair coin repeatedly come up heads forever is 0).\nMoreover, we cannot infinitely add positions to a list without eventually running\nout of memory. In any case, if we terminate position insertion at the highest level\nh, then the worst-case running time for performing the get, put, and remove map\noperations in a skip list S withn entries and height h is O(n+h). This worst-case\nperformance occurs when the tower of every entry reaches level h 1, where h is\n\u2212\nthe height of S. However, this event has very low probability. Judging from this\nworst case, we might conclude that the skip-list structure is strictly inferior to the\nothermapimplementations discussed earlierinthischapter. Butthiswouldnotbe\nafairanalysis, forthisworst-case behavior isagrossoverestimate.\n\u22c6Weuseastar(\u22c6)toindicatesectionscontainingmaterialmoreadvancedthanthematerialinthe\nrestofthechapter;thismaterialcanbeconsideredoptionalinafirstreading.\nwww.it-ebooks.info\n10.4. SkipLists 443\nBounding the Height of a Skip List\nBecausetheinsertionstepinvolvesrandomization,amoreaccurateanalysisofskip\nlistsinvolvesabitofprobability. Atfirst,thismightseemlikeamajorundertaking,\nfor a complete and thorough probabilistic analysis could require deep mathemat-\nics (and, indeed, there are several such deep analyses that have appeared in data\nstructures researchliterature). Fortunately, suchananalysis isnotnecessary toun-\nderstand theexpected asymptotic behavior ofskiplists. Theinformalandintuitive\nprobabilisticanalysiswegivebelowusesonlybasicconceptsofprobabilitytheory.\nLet us begin by determining the expected value of the height h of a skip list S\nwithnentries(assumingthatwedonotterminateinsertionsearly). Theprobability\nthatagivenentryhasatowerofheighti 1isequal totheprobability ofgetting i\n\u2265\nconsecutive headswhenflippingacoin, thatis,thisprobability is1/2i. Hence,the\nprobability P thatlevelihasatleastoneposition isatmost\ni\nn\nP ,\ni \u2264 2i\nbecausetheprobability thatanyoneofndifferent eventsoccursisatmostthesum\noftheprobabilities thateachoccurs.\nTheprobability thattheheight hofSislarger than iisequal totheprobability\nthatlevelihasatleastoneposition, thatis,itisnomorethanP. Thismeansthath\ni\nislargerthan,say,3lognwithprobability atmost\nn\nP\n3logn \u2264 23logn\nn 1\n= = .\nn3 n2\nFor example, if n=1000, this probability is a one-in-a-million long shot. More\ngenerally, given a constant c>1, h is larger than clogn with probability at most\n1/nc\u22121. Thatis, the probability that his smaller than clognisatleast 1 1/nc\u22121.\n\u2212\nThus,withhighprobability, theheighthofSisO(logn).\nAnalyzing Search Time in a Skip List\nNext, consider the running time of a search in skip list S, and recall that such a\nsearchinvolvestwonestedwhileloops. Theinnerloopperformsascanforwardon\nalevelofSaslongasthenextkeyisnogreaterthanthesearchkeyk,andtheouter\nloopdrops downtothenextlevelandrepeats thescan forwarditeration. Sincethe\nheight h of S is O(logn) with high probability, the number of drop-down steps is\nO(logn)withhighprobability.\nwww.it-ebooks.info\n444 Chapter10. Maps,HashTables,andSkipLists\nSowehaveyettobound thenumberofscan-forward stepswemake. Letn be\ni\nthenumberofkeysexaminedwhilescanningforwardatleveli. Observethat,after\nthe key at the starting position, each additional key examined in a scan-forward at\nlevel i cannot also belong to level i+1. If any of these keys were on the previous\nlevel, we would have encountered them in the previous scan-forward step. Thus,\ntheprobabilitythatanykeyiscountedinn is1/2. Therefore,theexpectedvalueof\ni\nn is exactly equal to the expected number of times wemust flipa fair coin before\ni\nit comes up heads. This expected value is 2. Hence, the expected amount of time\nspentscanningforwardatanyleveliisO(1). SinceShasO(logn)levelswithhigh\nprobability, a search in S takes expected time O(logn). By a similar analysis, we\ncanshowthattheexpected runningtimeofaninsertionoraremovalisO(logn).\nSpace Usage in a Skip List\nFinally, let us turn to the space requirement of a skip list S with n entries. As we\nobserved above, the expected number of positions at level i is n/2i, which means\nthattheexpectedtotalnumberofpositions inSis\nh n h 1\n\u2211 =n\u2211\n.\n2i 2i\ni=0 i=0\nUsingProposition 4.5ongeometricsummations, wehave\nh 1 1 h+1 1 1\n\u2211 = 2 \u2212 =2 1 <2 forallh 0.\n2i 1 1 \u00b7 \u22122h+1 \u2265\ni=0 (cid:0) (cid:1)2\u2212 (cid:18) (cid:19)\nHence,theexpected spacerequirement ofSisO(n).\nTable10.4summarizestheperformance ofasortedmaprealizedbyaskiplist.\nMethod RunningTime\nsize,isEmpty O(1)\nget O(logn)expected\nput O(logn)expected\nremove O(logn)expected\nfirstEntry,lastEntry O(1)\nceilingEntry,floorEntry\nO(logn)expected\nlowerEntry, higherEntry\nsubMap O(s+logn)expected, withsentriesreported\nentrySet,keySet,values O(n)\nTable10.4: Performanceofasortedmapimplemented withaskiplist. Weusento\ndenotethenumberofentriesinthedictionaryatthetimetheoperationisperformed.\nTheexpected spacerequirement isO(n).\nwww.it-ebooks.info\n10.5. Sets,Multisets,andMultimaps 445\n10.5 Sets, Multisets, and Multimaps\nWe conclude this chapter by examining several additional abstractions that are\ncloselyrelated tothemapADT,andthatcanbeimplementedusingdatastructures\nsimilartothoseforamap.\nA set is an unordered collection of elements, without duplicates, that typi-\n\u2022\ncally supports efficient membership tests. In essence, elements of a set are\nlikekeysofamap,butwithoutanyauxiliary values.\nAmultiset(alsoknownasabag)isaset-likecontainerthatallowsduplicates.\n\u2022\nA multimap is similar to a traditional map, in that it associates values with\n\u2022\nkeys;however,inamultimapthesamekeycanbemappedtomultiplevalues.\nForexample, the index of this book (page 714) mapsa given term to one or\nmorelocations atwhichthetermoccurselsewhereinthebook.\n10.5.1 The Set ADT\nTheJavaCollectionsFrameworkdefinesthejava.util.Setinterface,whichincludes\nthefollowingfundamental methods:\nadd(e): AddstheelementetoS(ifnotalready present).\nremove(e): RemovestheelementefromS(ifitispresent).\ncontains(e): ReturnswhethereisanelementofS.\niterator(): ReturnsaniteratoroftheelementsofS.\nThere is also support for the traditional mathematical set operations of union,\nintersection, andsubtraction oftwosetsSandT:\nS T = e: eisinSoreisinT ,\n\u222a { }\nS T = e: eisinSandeisinT ,\n\u2229 { }\nS T = e: eisinSandeisnotinT .\n\u2212 { }\nIn the java.util.Set interface, these operations are provided through the following\nmethods, ifexecutedonasetS:\naddAll(T): Updates S to also include all elements of set T, effec-\ntivelyreplacing SbyS T.\n\u222a\nretainAll(T): Updates S so that it only keeps those elements that are\nalsoelementsofsetT,effectively replacing SbyS T.\n\u2229\nremoveAll(T): UpdatesSbyremovinganyofitselementsthatalsooccur\ninsetT,effectively replacing SbyS T.\n\u2212\nwww.it-ebooks.info\n446 Chapter10. Maps,HashTables,andSkipLists\nThetemplatemethodpatterncanbeappliedtoimplementeachofthemethods\naddAll,retainAll,andremoveAllusingonlycallstothemorefundamentalmethods\nadd, remove, contains, and iterator. In fact, the java.util.AbstractSet class pro-\nvides such implementations. To demonstrate the technique, we could implement\ntheaddAllmethodinthecontextofasetclassasfollows:\npublic void addAll(Set<E> other)\n{\nfor (E element : other) // rely on iterator( ) method of other\nadd(element); // duplicates will be ignored by add\n}\nTheremoveAllandretailAllmethods canbeimplemented withsimilartechniques,\nalthough abitmorecareisneededforretainAll, toavoidremovingelementswhile\niteratingoverthesameset(seeExerciseC-10.59). Theefficiencyofthesemethods\nfor a concrete set implementation will depend on the underlying efficiency of the\nfundamental methodsuponwhichtheyrely.\nSorted Sets\nFor the standard set abstraction, there is no explicit notion of keys being ordered;\nallthatisassumedisthattheequalsmethodcandetectequivalent elements.\nIf,however,elementscomefromaComparableclass(orasuitableComparator\nobjectisprovided), wecanextendthenotionofasettodefinethesortedsetADT,\nincluding thefollowingadditional methods:\nfirst(): ReturnsthesmallestelementinS.\nlast(): ReturnsthelargestelementinS.\nceiling(e): Returnsthesmallestelementgreaterthanorequaltoe.\nfloor(e): Returnsthelargestelementlessthanorequaltoe.\nlower(e): Returnsthelargestelementstrictlylessthane.\nhigher(e): Returnsthesmallestelementstrictlygreaterthane.\nsubSet(e ,e ): Returns aniteration ofallelements greater thanorequal\n1 2\ntoe ,butstrictlylessthane .\n1 2\npollFirst(): ReturnsandremovesthesmallestelementinS.\npollLast(): ReturnsandremovesthelargestelementinS.\nIntheJavaCollection Framework,theabovemethodsareincludedinacombi-\nnationofthejava.util.SortedSetandjava.util.NavigableSetinterfaces.\nwww.it-ebooks.info\n10.5. Sets,Multisets,andMultimaps 447\nImplementing Sets\nAlthoughasetisacompletelydifferentabstractionthanamap,thetechniquesused\ntoimplementthetwocanbequitesimilar. Ineffect,asetissimplyamapinwhich\n(unique) keysdonothaveassociated values.\nTherefore, anydata structure used toimplement amap can bemodified to im-\nplement the set ADT with similar performance guarantees. As a trivial adaption\nof a map, each set element can be stored as a key, and the null reference can be\nstoredasan(irrelevant) value. Ofcourse, suchanimplementation isunnecessarily\nwasteful; amoreefficientsetimplementation should abandon theEntrycomposite\nandstoresetelementsdirectly inadatastructure.\nThe Java Collections Framework includes the following set implementations,\nmirroringsimilardatastructures usedformaps:\njava.util.HashSet provides an implementation of the (unordered) set ADT\n\u2022\nwithahashtable.\njava.util.concurrent.ConcurrentSkipListSet provides an implementation of\n\u2022\nthesortedsetADTusingaskiplist.\njava.util.TreeSet provides an implementation of the sorted set ADTusing a\n\u2022\nbalanced searchtree. (SearchtreesarethefocusofChapter11.)\n10.5.2 The Multiset ADT\nBeforediscussingmodelsforamultisetabstraction,wemustcarefullyconsiderthe\nnotion of \u201cduplicate\u201d elements. Throughout the Java Collections Framework, ob-\njects are considered equivalent to each other based on the standard equals method\n(see Section 3.5). For example, keys of a map must be unique, but the notion of\nuniqueness allows distinct yet equivalent objects to be matched. This is impor-\ntant for many typical uses of maps. For example, when strings are used as keys,\nthe instance ofthe string \"October\" that isused wheninserting anentry maynot\nbe the same instance of \"October\" that is used when later retrieving the associ-\nated value. The call birthstones.get(\"October\") will succeed in such a scenario\nbecausestrings areconsidered equaltoeachother.\nIn the context of multisets, if we represent a collection that appears through\nthe notion of equivalence as a,a,a,a,b,c,c , we must decide if we want a data\n{ }\nstructure to explicitly maintain each instance of a (because each might be distinct\nthough equivalent), or just that there exist four occurrences. In either case, amul-\ntiset can be implemented by directly adapting a map. We can use one element\nfrom a group of equivalent occurrences as the key in a map, with the associated\nvalue either a secondary container containing all of the equivalent instances, or a\ncount of the number of occurrences. Note that our word-frequency application in\nSection10.1.2usesjustsuchamap,associating stringswithcounts.\nwww.it-ebooks.info\n448 Chapter10. Maps,HashTables,andSkipLists\nTheJavaCollectionsFrameworkdoesnotincludeanyformofamultiset. How-\never, implementations exist in several widely used, open source Java collections\nlibraries. The Apache Commons defines Bag and SortedBag interfaces that cor-\nrespond respectively to unsorted and sorted multisets. The Google Core Libraries\nfor Java (named Guava) includes Multisetand SortedMultisetinterfaces forthese\nabstractions. Both of those libraries take the approach of modeling a multiset as\na collection of elements having multiplicities, and both offer several concrete im-\nplementations usingstandarddatastructures. Informalizing theabstract datatype,\nthe Multiset interface of the Guava library includes the following behaviors (and\nmore):\nadd(e): Addsasingleoccurrences ofetothemultiset.\ncontains(e): Returnstrueifthemultisetcontains anelementequaltoe.\ncount(e): Returnsthenumberofoccurrences ofeinthemultiset.\nremove(e): Removesasingleoccurrence ofefromthemultiset.\nremove(e,n): Removesnoccurrences ofefromthemultiset.\nsize(): Returns the number of elements of the multiset (including\nduplicates).\niterator(): Returnsaniterationofallelementsofthemultiset\n(repeating thosewithmultiplicity greaterthanone).\nThe multiset ADT also includes the notion of an immutable Entry that repre-\nsentsanelementanditscount,andtheSortedMultisetinterfaceincludesadditional\nmethodssuchasfirstEntryandlastEntry.\n10.5.3 The Multimap ADT\nLike a map, a multimap stores entries that are key-value pairs (k,v), where k is\nthe key and v is the value. Whereas a map insists that entries have unique keys,\na multimap allows multiple entries to have the same key, much like an English\ndictionary, which allows multiple definitions for the same word. That is, we will\nallowamultimaptocontain entries(k,v)and(k,v\u2032)havingthesamekey.\nTherearetwostandardapproachesforrepresentingamultimapasavariationof\natraditionalmap. Oneistoredesigntheunderlyingdatastructuretoallowseparate\nentries tobestored forpairs suchas(k,v)and (k,v\u2032). Theother istomapkeyk to\nasecondary container ofallvaluesassociated withthatkey(e.g., v,v\u2032 ).\n{ }\nMuch as it is missing a formal abstraction for a multiset, the Java Collections\nFrameworkdoesnotincludeanymultisetinterfacenorimplementations. However,\nas we will soon demonstrate, it is easy to represent a multiset by adapting other\ncollection classesthatareincluded inthejava.utilpackage.\nwww.it-ebooks.info\n10.5. Sets,Multisets,andMultimaps 449\nToformalize themultimapabstract datatype, weconsider asimplified version\noftheMultimapinterface included inGoogle\u2019sGuavalibrary. Amongitsmethods\narethefollowing:\nget(k): Returns acollection ofall values associated withkey k inthe\nmultimap.\nput(k,v): Adds a new entry to the multimap associating key k with\nvaluev,withoutoverwritinganyexistingmappings forkeyk.\nremove(k,v): Removesanentrymappingkeyktovaluevfromthemultimap\n(ifoneexists).\nremoveAll(k): Removesallentrieshavingkeyequaltokfromthemultimap.\nsize(): Returnsthenumberofentriesofthemultiset\n(including multipleassociations).\nentries(): Returnsacollection ofallentries inthemultimap.\nkeys(): Returnsacollection ofkeysforallentriesinthemultimap\n(including duplicates forkeyswithmultiplebindings).\nkeySet(): Returnsanonduplicative collection ofkeysinthemultimap.\nvalues(): Returnsacollection ofvaluesforallentriesinthemultimap.\nInCodeFragments 10.16 and10.17, weprovide animplementation ofaclass,\nHashMultimap, that uses a java.util.HashMap to map each key to a secondary\nArrayList of all values that are associated with the key. For brevity, we omit the\nformality of defining a Multimap interface, and we provide the entries() method\nastheonlyformofiteration.\n1 public class HashMultimap<K,V>\n{\n2 Map<K,List<V>> map = new HashMap<>(); // the primary map\n3 int total = 0; // total number of entries in the multimap\n4 /\u2217\u2217 Constructs an empty multimap. \u2217/\n5 public HashMultimap()\n6 /\u2217\u2217 Returns the total nu { mb } er of entries in the multimap. \u2217/\n7 public int size() return total;\n8 /\u2217\u2217 Returns whet { her the multima } p is empty. \u2217/\n9 public boolean isEmpty() return (total == 0);\n10 /\u2217\u2217 Returns a (possibly emp { ty) iteration of all value } s associated with the key. \u2217/\n11 Iterable<V> get(K key)\n{\n12 List<V> secondary = map.get(key);\n13 if (secondary != null)\n14 return secondary;\n15 return new ArrayList<>(); // return an empty list of values\n16\n}\nCodeFragment10.16:Animplementationofamultimapasanadaptationofclasses\nfromthejava.utilpackage. (ContinuesinCodeFragment10.17.)\nwww.it-ebooks.info\n450 Chapter10. Maps,HashTables,andSkipLists\n17 /\u2217\u2217 Adds a new entry associating key with value. \u2217/\n18 void put(K key, V value)\n{\n19 List<V> secondary = map.get(key);\n20 if (secondary == null)\n{\n21 secondary = new ArrayList<>();\n22 map.put(key, secondary); // begin using new list as secondary structure\n23\n}\n24 secondary.add(value);\n25 total++;\n26\n27 } /\u2217\u2217 Removes the (key,value) entry, if it exists. \u2217/\n28 boolean remove(K key, V value)\n{\n29 boolean wasRemoved = false;\n30 List<V> secondary = map.get(key);\n31 if (secondary != null)\n{\n32 wasRemoved = secondary.remove(value);\n33 if (wasRemoved)\n{\n34 total ;\n\u2212\u2212\n35 if (secondary.isEmpty())\n36 map.remove(key); // remove secondary structure from primary map\n37\n}\n38\n}\n39 return wasRemoved;\n40\n41 } /\u2217\u2217 Removes all entries with the given key. \u2217/\n42 Iterable<V> removeAll(K key)\n{\n43 List<V> secondary = map.get(key);\n44 if (secondary != null)\n{\n45 total = secondary.size();\n\u2212\n46 map.remove(key);\n47 else\n}\n48 secondary = new ArrayList<>(); // return empty list of removed values\n49 return secondary;\n50\n51 } /\u2217\u2217 Returns an iteration of all entries in the multimap. \u2217/\n52 Iterable<Map.Entry<K,V>> entries()\n{\n53 List<Map.Entry<K,V>> result = new ArrayList<>();\n54 for (Map.Entry<K,List<V>> secondary : map.entrySet())\n{\n55 K key = secondary.getKey();\n56 for (V value : secondary.getValue())\n57 result.add(new AbstractMap.SimpleEntry<K,V>(key,value));\n58\n}\n59 return result;\n60\n}\n61\n}\nCodeFragment10.17:Animplementationofamultimapasanadaptationofclasses\nfromthejava.utilpackage. (Continued fromCodeFragment10.16.)\nwww.it-ebooks.info\n10.6. Exercises 451\n10.6 Exercises\nReinforcement\nR-10.1 What is the worst-case runningtime for insertingn key-valuepairs into an ini-\ntiallyemptymapMthatisimplementedwiththeUnsortedTableMapclass?\nR-10.2 Reimplement the UnsortedTableMap class using the PositionalList class from\nSection7.3ratherthananArrayList.\nR-10.3 The use of null values in a map is problematic, as there is then no way to dif-\nferentiate whether a null value returned by the call get(k) represents the legit-\nimate value of an entry (k,null), or designates that key k was not found. The\njava.util.Mapinterfaceincludesabooleanmethod,containsKey(k),thatresolves\nanysuchambiguity.ImplementsuchamethodfortheUnsortedTableMapclass.\nR-10.4 Whichofthehashtablecollision-handlingschemescouldtoleratea loadfactor\nabove1andwhichcouldnot?\nR-10.5 What would be a good hash code for a vehicle identification number that is a\nstringofnumbersandlettersoftheform\u201c9X9XX99X9XX999999,\u201dwherea\u201c9\u201d\nrepresentsadigitandan\u201cX\u201drepresentsaletter?\nR-10.6 Draw the 11-entry hash table that results from using the hash function, h(i)=\n(3i+5)mod11, to hash thekeys12, 44, 13, 88, 23, 94, 11, 39, 20, 16, and 5,\nassumingcollisionsarehandledbychaining.\nR-10.7 What is the result of the previousexercise, assuming collisions are handled by\nlinearprobing?\nR-10.8 ShowtheresultofExerciseR-10.6,assumingcollisionsarehandledbyquadratic\nprobing,uptothepointwherethemethodfails.\nR-10.9 What is the result of Exercise R-10.6 when collisions are handled by double\nhashingusingthesecondaryhashfunctionh\u2032 (k)=7 (kmod7)?\n\u2212\nR-10.10 Whatistheworst-casetimeforputtingnentriesinaninitiallyemptyhashtable,\nwithcollisionsresolvedbychaining?Whatisthebestcase?\nR-10.11 ShowtheresultofrehashingthehashtableshowninFigure10.6intoatableof\nsize19usingthenewhashfunctionh(k)=3kmod17.\nR-10.12 ModifythePairclassfromCodeFragment2.17onpage92sothatitprovidesa\nnaturaldefinitionforboththeequals()andhashCode()methods.\nR-10.13 Considerlines31\u201333ofCodeFragment10.8inourimplementationoftheclass\nChainHashMap. Weusethedifferenceinthesizeofasecondarybucketbefore\nandafteracalltobucket.remove(k)toupdatethevariablen. Ifwereplacethose\nthreelineswiththefollowing,doestheclassbehaveproperly?Explain.\nV answer = bucket.remove(k);\nif (answer != null) // value of removed entry\nn ; // size has decreased\n\u2212\u2212\nwww.it-ebooks.info\n452 Chapter10. Maps,HashTables,andSkipLists\nR-10.14 OurAbstractHashMapclassmaintainsaloadfactor\u03bb 0.5. Reimplementthat\n\u2264\nclass to allow the user to specify the maximum load, and adjust the concrete\nsubclassesaccordingly.\nR-10.15 Giveapseudocodedescriptionofaninsertionintoahashtablethatusesquadratic\nprobingtoresolvecollisions,assumingwealsousethetrickofreplacingdeleted\nentrieswithaspecial\u201cavailable\u201dobject.\nR-10.16 ModifyourProbeHashMaptousequadraticprobing.\nR-10.17 Explainwhyahashtableisnotsuitedtoimplementasortedmap.\nR-10.18 Whatistheworst-caseasymptoticrunningtimeforperformingndeletionsfrom\naSortedTableMapinstancethatinitiallycontains2nentries?\nR-10.19 Implementthe containKey(k) method, as describedin Exercise R-10.3, for the\nSortedTableClass.\nR-10.20 Describehowasortedlistimplementedasadoublylinkedlistcouldbeusedto\nimplementthesortedmapADT.\nR-10.21 ConsiderthefollowingvariantofthefindIndexmethodoftheSortedTableMap\nclass,originallygiveninCodeFragment10.11:\n1 private int findIndex(K key, int low, int high)\n{\n2 if (high < low) return high + 1;\n3 int mid = (low + high) / 2;\n4 if (compare(key, table.get(mid)) < 0)\n5 return findIndex(key, low, mid 1);\n\u2212\n6 else\n7 return findIndex(key, mid + 1, high);\n8\n}\nDoes this always producethe same result as the original version? Justify your\nanswer.\nR-10.22 What is the expected running time of the methods for maintaining a maxima\nsetifwe insertnpairssuchthateachpairhaslowercostandperformancethan\none before it? What is contained in the sorted map at the end of this series of\noperations? Whatifeachpairhadalowercostandhigherperformancethanthe\nonebeforeit?\nR-10.23 Drawtheresultafterperformingthefollowingseriesofoperationsontheskiplist\nshowninFigure10.13:remove(38),put(48,x),put(24,y),remove(55). Usean\nactualcoinfliptogeneraterandombitsasneeded(andreportyoursequenceof\nflips).\nR-10.24 Giveapseudocodedescriptionoftheremovemapoperationforaskiplist.\nR-10.25 Give a description, in pseudocode,forimplementingtheremoveAll methodfor\nthesetADT,usingonlytheotherfundamentalmethodsoftheset.\nR-10.26 Giveadescription,inpseudocode,forimplementingtheretainAllmethodforthe\nsetADT,usingonlytheotherfundamentalmethodsoftheset.\nwww.it-ebooks.info\n10.6. Exercises 453\nR-10.27 Ifwe letn denotethesize ofset S, andm denotethesize ofsetT, whatwould\nbetherunningtimeoftheoperationS.addAll(T), asimplementedonpage446,\nifbothsetswereimplementedasskiplists?\nR-10.28 Ifwe letn denotethesize ofset S, andm denotethesize ofsetT, whatwould\nbetherunningtimeoftheoperationS.addAll(T), asimplementedonpage446,\nifbothsetswereimplementedusinghashing?\nR-10.29 Ifwe letn denotethesize ofset S, andm denotethesize ofsetT, whatwould\nbe therunningtime ofthe operationS.removeAll(T) whenbothsets areimple-\nmentedusinghashing?\nR-10.30 IfweletndenotethesizeofsetS,andmdenotethesizeofsetT,whatwouldbe\ntherunningtimeoftheoperationS.retainAll(T)whenbothsetsareimplemented\nusinghashing?\nR-10.31 Whatabstractionwouldyouusetomanageadatabaseoffriends\u2019birthdaysinor-\ndertosupportefficientqueriessuchas\u201cfindallfriendswhosebirthdayistoday\u201d\nand\u201cfindthefriendwhowillbethenexttocelebrateabirthday\u201d?\nCreativity\nC-10.32 For an ideal compression function, the capacity of the bucket array for a hash\ntableshouldbeaprimenumber. Therefore,weconsidertheproblemoflocating\naprimenumberinarange[M,2M]. Implementamethodforfindingsuchaprime\nby using the sieve algorithm. In this algorithm, we allocate a 2M cell boolean\narrayA,suchthatcelliisassociatedwiththeintegeri.Wetheninitializethearray\ncellstoallbe\u201ctrue\u201dandwe\u201cmarkoff\u201dallthecellsthataremultiplesof2,3,5,\n7, andso on. Thisprocesscanstopafteritreachesa numberlargerthan\u221a2M.\n(Hint:Considerabootstrappingmethodforfindingtheprimesupto\u221a2M.)\nC-10.33 Considerthegoalofaddingentry(k,v)toamaponlyiftheredoesnotyetexist\nsome other entrywith key k. For a map M (withoutnull values), this mightbe\naccomplishedasfollows.\nif(M.get(k)== null)\nM.put(k,v);\nWhile this accomplishes the goal, its efficiency is less than ideal, as time will\nbe spent on the failed search during the get call, and again during the put call\n(which always beginsby trying to locate an existing entry with the given key).\nToavoidthisinefficiency,somemapimplementationssupportacustommethod\nputIfAbsent(k,v)thataccomplishesthisgoal. Givensuchanimplementationof\nputIfAbsentfortheUnsortedTableMapclass.\nC-10.34 RepeatExerciseC-10.33fortheChainHashMapclass.\nC-10.35 RepeatExerciseC-10.33fortheProbeHashMapclass.\nC-10.36 Describe how to redesign the AbstractHashMap frameworkto include support\nforamethod,containsKey,asdescribedinExerciseR-10.3.\nwww.it-ebooks.info\n454 Chapter10. Maps,HashTables,andSkipLists\nC-10.37 ModifytheChainHashMapclassinaccordancewithyourdesignfortheprevious\nexercise.\nC-10.38 ModifytheProbeHashMapclassinaccordancewithExerciseC-10.36.\nC-10.39 RedesigntheAbstractHashMapclasssothatithalvesthecapacityofthetableif\ntheloadfactorfallsbelow0.25. Yoursolutionmustnotinvolveanychangesto\ntheconcreteProbeHashMapandChainHashMapclasses.\nC-10.40 Thejava.util.HashMapclassusesseparatechaining,butwithoutanyexplicitsec-\nondarystructures. The table is an array of entries, and each entry has an addi-\ntional next field that can reference another entry in that bucket. In this way,\nthe entry instances can be threaded as a singly linked list. Reimplement our\nChainHashMapclassusingsuchanapproach.\nC-10.41 Describe how to perform a removal from a hash table that uses linear probing\nto resolvecollisionswhere we do notuse a specialmarker to representdeleted\nelements. That is, we must rearrange the contents so that it appears that the\nremovedentrywasneverinsertedinthefirstplace.\nC-10.42 The quadratic probing strategy has a clustering problem related to the way it\nlooksforopenslots. Namely,whena collisionoccursatbucketh(k), itchecks\nbucketsA[(h(k)+i2)modN],fori=1,2,...,N 1.\n\u2212\na. Showthati2 modN willassume atmost(N+1)/2distinctvalues, forN\nprime,asirangesfrom1toN 1. Asapartofthisjustification,notethat\ni2 modN=(N i)2 modN fo \u2212 ralli.\n\u2212\nb. A betterstrategyis to choosea primeN such thatN mod4=3 andthen\ntocheckthebucketsA[(h(k) i2)modN]asirangesfrom1to(N 1)/2,\n\u00b1 \u2212\nalternating between plus and minus. Show that this alternate version is\nguaranteedtocheckeverybucketinA.\nC-10.43 Redesign our ProbeHashMap class so that the sequence of secondary probes\nfor collision resolution can be more easily customized. Demonstrate your new\ndesignbyprovidingseparateconcretesubclassesforlinearprobingandquadratic\nprobing.\nC-10.44 Thejava.util.LinkedHashMapclassisasubclassofthestandardHashMapclass\nthatretainstheexpectedO(1)performancefortheprimarymapoperationswhile\nguaranteeingthatiterationsreportentriesof the mapaccordingto first-in, first-\nout (FIFO) principle. That is, the key that has been in the map the longest is\nreported first. (The order is unaffected when the value for an existing key is\nchanged.)Describeanalgorithmicapproachforachievingsuchperformance.\nC-10.45 Developalocation-awareversionoftheUnsortedTableMapclasssothatanop-\nerationremove(e)forexistingEntryecanbeimplementedinO(1)time.\nC-10.46 RepeatthepreviousexercisefortheProbeHashMapclass.\nC-10.47 RepeatExerciseC-10.45fortheChainHashMapclass.\nwww.it-ebooks.info\n10.6. Exercises 455\nC-10.48 Althoughkeysinamaparedistinct,thebinarysearchalgorithmcanbeapplied\ninamoregeneralsettinginwhichanarraystorespossiblyduplicativeelements\ninnondecreasingorder.Considerthegoalofidentifyingtheindexoftheleftmost\nelement with key greater than or equal to given k. Does the findIndex method\nas given in Code Fragment 10.11 guarantee such a result? Does the findIndex\nmethod as givenin Exercise R-10.21guarantee such a result? Justify your an-\nswers.\nC-10.49 SupposewearegiventwosortedsearchtablesSandT,eachwithnentries(with\nSandT beingimplementedwitharrays). DescribeanO(log2n)-timealgorithm\nforfindingthekth smallestkeyintheunionofthekeysfromSandT (assuming\nnoduplicates).\nC-10.50 GiveanO(logn)-timesolutionforthepreviousproblem.\nC-10.51 Give an alternative implementation of the SortedTableMap\u2019s entrySet method\nthatcreatesalazyiteratorratherthanasnapshot. (SeeSection7.4.2fordiscus-\nsionofiterators.)\nC-10.52 RepeatthepreviousexercisefortheChainHashMapclass.\nC-10.53 RepeatExerciseC-10.51fortheProbeHashMapclass.\nC-10.54 GivenadatabaseDofncost-performancepairs(c,p),describeanalgorithmfor\nfindingthemaximapairsofCinO(nlogn)time.\nC-10.55 Show thatthe methodsabove(p) and before(p) are notactuallyneededto effi-\ncientlyimplementamapusingaskiplist. Thatis,wecanimplementinsertions\nand deletions in a skip list using a strictly top-down, scan-forward approach,\nwithouteverusingtheaboveorbeforemethods. (Hint: Intheinsertionalgo-\nrithm,firstrepeatedlyflipthecointodeterminethelevelwhereyoushouldstart\ninsertingthenewentry.)\nC-10.56 Describe how to modify the skip-list data structure to support the method me-\ndian(),whichreturnsthepositionoftheelementinthe\u201cbottom\u201dlistS atindex\n0\nn/2 ,ShowthatyourimplementationofthismethodrunsinO(logn)expected\n\u230a \u230b\ntime.\nC-10.57 Describehowtomodifyaskip-listrepresentationsothatindex-basedoperations,\nsuch as retrieving the entry at index j, can be performed in O(logn) expected\ntime.\nC-10.58 Suppose that each row of an n n array A consists of 1\u2019s and 0\u2019s such that, in\n\u00d7\nanyrowofA,allthe1\u2019scomebeforeany0\u2019sinthatrow. AssumingAisalready\nin memory, describe a method running in O(nlogn) time (not O(n2) time) for\ncountingthenumberof1\u2019sinA.\nC-10.59 Givea concreteimplementationof theretainAll methodfortheset ADT,using\nonlytheotherfundamentalmethodsoftheset. Youaretoassumethattheunder-\nlyingsetimplementationusesfail-fastiterators(seeSection7.4.2).\nwww.it-ebooks.info\n456 Chapter10. Maps,HashTables,andSkipLists\nC-10.60 Consider sets whose elements are integers in the range [0,N 1]. A popular\n\u2212\nscheme for representinga set A of this type is by means of a booleanarray, B,\nwhere we say that x is in A if and only if B[x]=true. Since each cell of B\ncan be representedwith a single bit, B is sometimesreferredto as a bit vector.\nDescribeandanalyzeefficientalgorithmsforperformingthemethodsoftheset\nADTassumingthisrepresentation.\nC-10.61 Aninvertedfileisacriticaldatastructureforimplementingapplicationssuchan\nindexofabookorasearchengine.GivenadocumentD,whichcanbeviewedas\nanunordered,numberedlistofwords,aninvertedfileisanorderedlistofwords,\nL,suchthat,foreachwordwinL,westoretheindicesoftheplacesinDwhere\nwappears.DesignanefficientalgorithmforconstructingLfromD.\nC-10.62 The operationget(k) for our multimapADT is responsible for returninga col-\nlectionofallvaluescurrentlyassociatedwithkeyk. Designavariationofbinary\nsearch for performing this operation on a sorted search table that includes du-\nplicates, and show that it runs in time O(s+logn), where n is the number of\nelementsinthedictionaryandsisthenumberofentrieswithgivenkeyk.\nC-10.63 Describeanefficientmultimapstructureforstoringnentriesthathaveanasso-\nciated set of r<n keys that come from a total order. That is, the set of keys\nis smaller than the numberof entries. Yourstructure should performoperation\ngetAll in O(logr+s) expectedtime, wheres is the numberof entriesreturned,\noperationentrySet()inO(n)time,andtheremainingoperationsofthemultimap\nADTinO(logr)expectedtime.\nC-10.64 Describe an efficientmultimapstructureforstoringn entrieswhose r<n keys\nhave distinct hash codes. Your structure should perform operation getAll in\nO(1+s) expected time, where s is the number of entries returned, operation\nentrySet()inO(n)time,andtheremainingoperationsofthemultimapADTin\nO(1)expectedtime.\nProjects\nP-10.65 An interesting strategy for hashing with open addressing is known as cuckoo\nhashing. Two independent hash functions are computed for each key, and an\nelementisalwaysstoredinoneofthetwocellsindicatedbythosehashfunctions.\nWhen a new element is inserted, if either of those two cells is available, it is\nplacedthere. Otherwise,itisplacedintooneofitschoiceoflocations,evicting\nanother entry. The evicted entry is then placed in its alternate choice of cells,\npotentiallyevictingyetanotherentry. Thiscontinuesuntilanopencellisfound,\noraninfiniteloopisdetected(inwhichcase,twonewhashfunctionsarechosen\nand all entries are deleted and reinserted). It can be shown that as long as the\nloadfactorofthetableremainsbelow0.5,thenaninsertionsucceedsinexpected\nconstanttime.Noticethatasearchcanbeperformedinworst-caseconstanttime,\nbecauseitcanonlybestoredinoneoftwopossiblelocations. Giveacomplete\nmapimplementationbasedonthisstrategy.\nwww.it-ebooks.info\n10.6. Exercises 457\nP-10.66 An interesting strategy for hashing with separate chaining is known as power-\nof-two-choiceshashing. Twoindependenthashfunctionsarecomputedforeach\nkey,andanewlyinsertedelementisplacedintothechoiceofthetwoindicated\nbucketsthatcurrentlyhasthefewestentries. Giveacompletemapimplementa-\ntionbasedonthisstrategy.\nP-10.67 Implementa LinkedHashMapclass, asdescribedinExerciseC-10.44,ensuring\nthattheprimarymapoperationsruninO(1)expectedtime.\nP-10.68 PerformexperimentsonourChainHashMapandProbeHashMapclassestomea-\nsureitsefficiencyusingrandomkeysetsandvaryinglimitsontheloadfactor(see\nExerciseR-10.14).\nP-10.69 Perform a comparativeanalysis that studies the collision rates for varioushash\ncodes for character strings, such as polynomialhash codes for differentvalues\nof the parameter a. Use a hash table to determine collisions, but only count\ncollisionswheredifferentstringsmaptothesamehashcode(notiftheymapto\nthesamelocationinthishashtable).Testthesehashcodesontextfilesfoundon\ntheInternet.\nP-10.70 Performacomparativeanalysisasinthepreviousexercise,butfor10-digittele-\nphonenumbersinsteadofcharacterstrings.\nP-10.71 DesignaJavaclassthatimplementstheskip-listdatastructure. Usethisclassto\ncreateacompleteimplementationofthesortedmapADT.\nP-10.72 Extend the previousproject by providinga graphicalanimation of the skip-list\noperations. Visualizehowentriesmoveuptheskiplistduringinsertionsandare\nlinkedoutoftheskiplistduringremovals. Also,inasearchoperation,visualize\nthescan-forwardanddrop-downactions.\nP-10.73 Describe how to use a skip list to implementthe arraylist ADT, so that index-\nbasedinsertionsandremovalsbothruninO(logn)expectedtime.\nP-10.74 Write a spell-checkerclass that stores a lexicon of words,W, in a set, and im-\nplementsamethod,check(s),whichperformsaspellcheckonthestringswith\nrespect to the set of words, W. If s is in W, then the call to check(s) returns\na list containingonly s, as it is assumed to be spelled correctly in this case. If\ns is not in W, then the call to check(s) returns a list of every word in W that\nmightbe a correctspelling ofs. Yourprogramshouldbeable to handleall the\ncommonwaysthatsmightbeamisspellingofawordinW,includingswapping\nadjacentcharactersin a word, insertinga single characterin betweentwo adja-\ncentcharactersinaword,deletingasinglecharacterfromaword,andreplacing\na character in a word with another character. For an extra challenge, consider\nphoneticsubstitutionsaswell.\nwww.it-ebooks.info\n458 Chapter10. Maps,HashTables,andSkipLists\nChapter Notes\nHashingisawell-studiedtechnique.Thereaderinterestedinfurtherstudyisencouragedto\nexplorethebookbyKnuth[61],aswellasthebookbyVitterandChen[92]. Thedenial-\nof-servicevulnerabilityexploitingtheworst-caseperformanceofhashtableswasfirstde-\nscribedbyCrosbyandWallach[27],andlaterdemonstratedbyKlinkandWa\u00a8lde[58]. The\nremedyadoptedbytheOpenJDKteamforJavaisdescribedin[76].\nSkiplistswereintroducedbyPugh[80]. Ouranalysisofskiplistsisasimplification\nof a presentationgiven by Motwaniand Raghavan [75]. For a more in-depthanalysis of\nskiplists,pleaseseethevariousresearchpapersonskipliststhathaveappearedinthedata\nstructuresliterature[56,77,78]. ExerciseC-10.42wascontributedbyJamesLee.\nwww.it-ebooks.info\nChapter\n11\nSearch Trees\nContents\n11.1 Binary Search Trees . . . . . . . . . . . . . . . . . . . . . . 460\n11.1.1 Searching Within a Binary Search Tree . . . . . . . . . . . 461\n11.1.2 Insertions and Deletions . . . . . . . . . . . . . . . . . . . 463\n11.1.3 Java Implementation . . . . . . . . . . . . . . . . . . . . 466\n11.1.4 Performance of a Binary Search Tree . . . . . . . . . . . . 470\n11.2 Balanced Search Trees . . . . . . . . . . . . . . . . . . . . 472\n11.2.1 Java Framework for Balancing Search Trees . . . . . . . . 475\n11.3 AVL Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . 479\n11.3.1 Update Operations . . . . . . . . . . . . . . . . . . . . . 481\n11.3.2 Java Implementation . . . . . . . . . . . . . . . . . . . . 486\n11.4 Splay Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . 488\n11.4.1 Splaying . . . . . . . . . . . . . . . . . . . . . . . . . . . 488\n11.4.2 When to Splay. . . . . . . . . . . . . . . . . . . . . . . . 492\n11.4.3 Java Implementation . . . . . . . . . . . . . . . . . . . . 494\n\u22c6\n11.4.4 Amortized Analysis of Splaying . . . . . . . . . . . . . 495\n11.5 (2,4) Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . 500\n11.5.1 Multiway Search Trees . . . . . . . . . . . . . . . . . . . 500\n11.5.2 (2,4)-Tree Operations . . . . . . . . . . . . . . . . . . . . 503\n11.6 Red-Black Trees . . . . . . . . . . . . . . . . . . . . . . . . 510\n11.6.1 Red-Black Tree Operations . . . . . . . . . . . . . . . . . 512\n11.6.2 Java Implementation . . . . . . . . . . . . . . . . . . . . 522\n11.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 525\nwww.it-ebooks.info\n460 Chapter11. SearchTrees\n11.1 Binary Search Trees\nIn Chapter 8 we introduced the tree data structure and demonstrated a variety of\napplications. Oneimportant use isasa search tree (as described onpage 338). In\nthis chapter, we use a search-tree structure to efficiently implement a sorted map.\nThethreemostfundamental methodsofofamap(seeSection10.1.1)are:\nget(k): Returns the value v associated with key k, if such an entry exists;\notherwise returnsnull.\nput(k,v): Associates value v with key k, replacing and returning any existing\nvalueifthemapalreadycontains anentrywithkeyequaltok.\nremove(k): Removes the entry with key equal to k, if one exists, and returns its\nvalue;otherwisereturnsnull.\nThe sorted map ADT includes additional functionality (see Section 10.3), guar-\nanteeing that an iteration reports keys in sorted order, and supporting additional\nsearches suchashigherEntry(k)andsubMap(k ,k ).\n1 2\nBinarytreesareanexcellentdatastructure forstoringentriesofamap,assum-\ning we have an order relation defined on the keys. In this chapter, we define a\nbinarysearchtreeasaproper binarytree(seeSection8.2)suchthateachinternal\nposition pstoresakey-valuepair(k,v)suchthat:\nKeysstoredintheleftsubtree of parelessthank.\n\u2022\nKeysstoredintherightsubtreeof paregreaterthank.\n\u2022\nAn example of such a binary search tree is given in Figure 11.1. Notice that the\nleavesofthetreeserveonlyas\u201cplaceholders.\u201d Theiruseassentinelssimplifiesthe\npresentation ofseveralofoursearchandupdatealgorithms. Withcare,theycanbe\nrepresented asnullreferences inpractice, thereby reducing thenumberofnodesin\nhalf(sincetherearemoreleavesthaninternalnodesinaproperbinarytree).\n44\n17 88\n8 32 65 97\n28 54 82 93\n21 29 76\n80\nFigure11.1: Abinary searchtreewithinteger keys. Weomitthedisplay ofassoci-\natedvaluesinthischapter, sincetheyarenotrelevant totheorderofentries within\nasearchtree.\nwww.it-ebooks.info\n11.1. BinarySearchTrees 461\n11.1.1 Searching Within a Binary Search Tree\nThe most important consequence of the structural property of a binary search tree\nis its namesake search algorithm. We can attempt to locate a particular key in a\nbinary search tree by viewing itas a decision tree (recall Figure 8.5). In this case,\nthe question asked at each internal position p is whether the desired key k is less\nthan, equal to, or greater than the key stored at position p, which we denote as\nkey(p). If the answer is \u201cless than,\u201d then the search continues in the left subtree.\nIf the answer is \u201cequal,\u201d then the search terminates successfully. If the answer is\n\u201cgreater than,\u201dthenthesearch continues intherightsubtree. Finally, ifwereach a\nleaf,thenthesearchterminatesunsuccessfully. (SeeFigure11.2.)\n44 44\n17 88 17 88\n8 32 65 97 8 32 65 97\n28 54 82 93 28 54 82 93\n21 29 76 21 29 76\n80 80\n(a) (b)\nFigure 11.2: (a) A successful search for key 65 in a binary search tree; (b) an\nunsuccessful searchforkey68thatterminates attheleaftotheleftofthekey76.\nWedescribethisapproachinCodeFragment11.1. Ifkeykoccursinasubtree\nrooted at p, a call to TreeSearch(p, k) results in the position at which the key is\nfound. For an unsuccessful search, the TreeSearch algorithm returns the final leaf\nexplored on the search path (which we will later make use of when determining\nwheretoinsertanewentryinasearchtree).\nAlgorithmTreeSearch(p, k):\nif pisexternalthen\nreturn p unsuccessful search\n{ }\nelseifk==key(p)then\nreturn p successful search\n{ }\nelseifk<key(p)then\nreturnTreeSearch(left(p),k) recuronleftsubtree\n{ }\nelse weknowthatk>key(p)\n{ }\nreturnTreeSearch(right(p),k) recuronrightsubtree\n{ }\nCodeFragment11.1: Recursivesearchinabinarysearchtree.\nwww.it-ebooks.info\n462 Chapter11. SearchTrees\nAnalysis of Binary Tree Searching\nThe analysis of the worst-case running time of searching in a binary search tree\nT is simple. Algorithm TreeSearch is recursive and executes a constant number\nof primitive operations for each recursive call. Each recursive call of TreeSearch\nis made on a child of the previous position. That is, TreeSearch is called on the\npositions of a path of T that starts at the root and goes down one level at a time.\nThus,thenumberofsuchpositionsisboundedbyh+1,wherehistheheightofT.\nIn other words, since we spend O(1) time per position encountered in the search,\nthe overall search runs in O(h) time, where h is the height of the binary search\ntreeT. (SeeFigure11.3.)\nHeight Timeperlevel\nO(1)\nTreeT:\nO(1)\nh\nO(1)\nTotaltime: O(h)\nFigure11.3: Illustrating the running time of searching ina binary search tree. The\nfigureusesastandardvisualization shortcutofabinarysearchtreeasabigtriangle\nandapathfromtherootasazig-zag line.\nIn the context of the sorted map ADT, the search will be used as a subroutine\nforimplementingthegetmethod,aswellasfortheputandremovemethods,since\neach of these begins by trying to locate an existing entry with the given key. We\nwilllaterdemonstratehowtoimplementsortedmapoperations,suchaslowerEntry\nand higherEntry, by navigating within the tree after performing astandard search.\nAlloftheseoperations willruninworst-caseO(h)timeforatreewithheighth.\nAdmittedly,theheighthofT canbeaslargeasthenumberofentries,n,butwe\nexpect that it is usually much smaller. Later in this chapter we will show various\nstrategies tomaintainanupperboundofO(logn)ontheheightofasearchtreeT.\nwww.it-ebooks.info\n11.1. BinarySearchTrees 463\n11.1.2 Insertions and Deletions\nBinarysearchtreesallowimplementations oftheputandremoveoperations using\nalgorithms thatarefairlystraightforward, although nottrivial.\nInsertion\nThemapoperation put(k,v)beginswithasearchforanentrywithkeyk. Iffound,\nthat entry\u2019s existing value is reassigned. Otherwise, the new entry can be inserted\ninto the underlying tree by expanding the leaf that was reached at the end of the\nfailedsearch intoaninternal node. Thebinary search-tree property issustained by\nthat placement (note that it is placed exactly where a search would expect it). Let\nusassumeaproperbinarytreesupports thefollowingupdateoperation:\nexpandExternal(p,e): Stores entry e at the external position p, and expands p\ntobeinternal, havingtwonewleavesaschildren.\nWe can then describe the TreeInsert algorithm with the pseudocode given in in\nCode Fragment 11.2. An example of insertion into a binary search tree is shown\ninFigure11.4.\nAlgorithmTreeInsert(k, v):\nInput: Asearchkeyktobeassociated withvaluev\np = TreeSearch(root(),k)\nifk==key(p)then\nChange p\u2019svalueto(v)\nelse\nexpandExternal(p,(k,v))\nCode Fragment 11.2: Algorithm for inserting a key-value pair into a map that is\nrepresented asabinarysearchtree.\n44 44\n17 88 17 88\n8 32 65 97 8 32 65 97\n28 54 82 93 28 54 82 93\n21 29 76 21 29 76\n80 68 80\n(a) (b)\nFigure11.4: Insertion of an entry with key 68 into the search tree of Figure 11.2.\nFindingthepositiontoinsertisshownin(a),andtheresulting treeisshownin(b).\nwww.it-ebooks.info\n464 Chapter11. SearchTrees\nDeletion\nDeleting an entry from a binary search tree is a bit more complex than inserting a\nnew entry because the position of anentry to bedeleted might beanywhere in the\ntree(asopposedtoinsertions,whichalwaysoccurataleaf). Todeleteanentrywith\nkey k, we begin by calling TreeSearch(root(), k) to find the position p storing an\nentrywithkeyequaltok(ifany). Ifthesearchreturnsanexternalnode, thenthere\nisnoentrytoremove. Otherwise, wedistinguish betweentwocases(ofincreasing\ndifficulty):\nIf at most one of the children of position p is internal, the deletion of the\n\u2022\nentryatposition piseasilyimplemented(seeFigure11.5). Letposition rbe\nachildof pthatisinternal (oranarbitrary child, ifbothareleaves). Wewill\nremove pandtheleafthatisr\u2019ssibling,whilepromotingrupwardtotakethe\nplaceof p. Wenotethatallremainingancestor-descendant relationships that\nremain inthetreeaftertheoperation existed before theoperation; therefore,\nthebinarysearch-tree propertyismaintained.\nIf position p has two children, we cannot simply remove the node from the\n\u2022\ntreesincethiswouldcreatea\u201chole\u201dandtwoorphaned children. Instead, we\nproceed asfollows(seeFigure11.6):\nWe locate position r containing the entry having the greatest key that\n\u25e6\nis strictly less than that of position p (its so-called predecessor in the\nordering ofkeys). Thatpredecessor willalwaysbelocatedintheright-\nmostinternalposition oftheleftsubtreeofposition p.\nWe use r\u2019s entry as a replacement for the one being deleted at posi-\n\u25e6\ntion p. Because r has the immediately preceding key in the map, any\nentries in p\u2019s right subtree will have keys greater than r and any other\nentries in p\u2019s left subtree will have keys less than r. Therefore, the\nbinarysearch-tree propertyissatisfiedafterthereplacement.\nHaving used r\u2019s entry as a replacement for p, we instead delete the\n\u25e6\nnode at position r from the tree. Fortunately, since r was located as\nthe rightmost internal position in asubtree, r does not have aninternal\nrightchild. Therefore,itsdeletioncanbeperformedusingthefirst(and\nsimpler)approach.\nAs with searching and insertion, this algorithm for a deletion involves the\ntraversal of a single path downward from the root, possibly moving an entry be-\ntweentwopositionsofthispath,andremovinganodefromthatpathandpromoting\nitschild. Therefore, itexecutesintimeO(h)wherehistheheightofthetree.\nwww.it-ebooks.info\n11.1. BinarySearchTrees 465\n44 44\n17 88 17 88\np r\n8 32 65 97 8 28 65 97\nr\n28 54 82 93 21 29 54 82 93\n21 29 76 76\n68 80 68 80\n(a) (b)\nFigure11.5: Deletion from the binary search tree of Figure 11.4b, where the entry\nto delete (with key 32) is stored at a position p with one child r: (a) before the\ndeletion; (b)afterthedeletion.\n44\np\n17 88 44\np\n8 28 65 97 17 82\nr\n21 29 54 82 93 8 28 65 97\nr\n76 21 29 54 76 93\n68 80 68 80\n(a) (b)\nFigure11.6: Deletion from the binary search tree of Figure 11.5b, where the entry\ntodelete (withkey 88)isstored ataposition pwithtwochildren, and replaced by\nitspredecessor r: (a)beforethedeletion; (b)afterthedeletion.\nwww.it-ebooks.info\n466 Chapter11. SearchTrees\n11.1.3 Java Implementation\nIn Code Fragments 11.3 through 11.6 we define a TreeMap class that implements\nthe sorted map ADT while using a binary search tree for storage. The TreeMap\nclassisdeclaredasachildoftheAbstractSortedMapbaseclass,therebyinheriting\nsupport for performing comparisons based upon a given (or default) Comparator,\nanestedMapEntryclassforstoringkey-valuepairs,andconcreteimplementations\nof methods keySet and values based upon the entrySet method, which we will\nprovide. (SeeFigure10.2onpage406foranoverviewofourentiremaphierarchy.)\nForrepresentingthetreestructure,ourTreeMapclassmaintainsaninstanceofa\nsubclassoftheLinkedBinaryTreeclassfromSection8.3.1. Inthisimplementation,\nwe choose to represent the search tree as a proper binary tree, with explicit leaf\nnodes inthebinary treeassentinels, andmapentries stored onlyatinternal nodes.\n(Weleavethetaskofamorespace-efficient implementation toExerciseP-11.55.)\nTheTreeSearch algorithm of CodeFragment 11.1is implemented as aprivate\nrecursive method, treeSearch(p, k). That method either returns aposition with an\nentryequal tokeyk,orelsethelastposition thatisvisited onthesearch path. The\nmethodisnotonlyusedforalloftheprimarymapoperations,get(k),put(k,v),and\nremove(k), but for most of the sorted map methods, as the final internal position\nvisited during an unsuccessful search has either the greatest key less than k or the\nleastkeygreaterthank.\nFinally,wenotethatourTreeMapclassisdesignedsothatitcanbesubclassed\nto implement various forms of balanced search trees. We discuss the balancing\nframeworkmorethoroughlyinSection11.2,buttherearetwoaspectsofthedesign\nthatimpactthecodepresentedinthissection. First,ourtreememberistechnically\ndeclaredasaninstanceofaBalanceableBinaryTreeclass,whichisaspecialization\noftheLinkedBinaryTreeclass;however,werelyonlyontheinherited behaviors in\nthis section. Second, our code is peppered withcalls topresumed methods named\nrebalanceAccess, rebalanceInsert, and rebalanceDelete; these methods do not do\nanything inthisclass,buttheyserveashooksthatcanlaterbecustomized.\nWeconclude withabriefguidetotheorganization ofourcode.\nCodeFragment11.3: Beginning of TreeMap class, including constructors, size\nmethod, andexpandExternalandtreeSearchutilities.\nCodeFragment11.4: Mapoperations get(k),put(k,v),andremove(k).\nCodeFragment11.5: SortedmapADTmethodslastEntry(),floorEntry(k),and\nlowerEntry(k), and protected utility treeMax. Symmet-\nricmethods firstEntry(),ceilingEntry(k),higherEntry(k),\nandtreeMinareprovidedonline.\nCodeFragment11.6: Support for producing an iteration of all entries (method\nentrySetofthemapADT),orofaselectedrangeofentries\n(methodsubMap(k ,k )ofthesortedmapADT).\n1 2\nwww.it-ebooks.info\n11.1. BinarySearchTrees 467\n1 /\u2217\u2217 An implementation of a sorted map using a binary search tree. \u2217/\n2 public class TreeMap<K,V> extends AbstractSortedMap<K,V>\n{\n3 // To represent the underlying tree structure, we use a specialized subclass of the\n4 // LinkedBinaryTree class that we name BalanceableBinaryTree (see Section 11.2).\n5 protected BalanceableBinaryTree<K,V> tree = new BalanceableBinaryTree<>();\n6\n7 /\u2217\u2217 Constructs an empty map using the natural ordering of keys. \u2217/\n8 public TreeMap()\n{\n9 super(); // the AbstractSortedMap constructor\n10 tree.addRoot(null); // create a sentinel leaf as root\n11\n12 } /\u2217\u2217 Constructs an empty map using the given comparator to order keys. \u2217/\n13 public TreeMap(Comparator<K> comp)\n{\n14 super(comp); // the AbstractSortedMap constructor\n15 tree.addRoot(null); // create a sentinel leaf as root\n16\n17 } /\u2217\u2217 Returns the number of entries in the map. \u2217/\n18 public int size()\n{\n19 return (tree.size() 1) / 2; // only internal nodes have entries\n\u2212\n20\n21 } /\u2217\u2217 Utility used when inserting a new entry at a leaf of the tree \u2217/\n22 private void expandExternal(Position<Entry<K,V>> p, Entry<K,V> entry)\n{\n23 tree.set(p, entry); // store new entry at p\n24 tree.addLeft(p, null); // add new sentinel leaves as children\n25 tree.addRight(p, null);\n26\n}\n27\n28 // Omitted from this code fragment, but included in the online version of the code,\n29 // are a series of protected methods that provide notational shorthands to wrap\n30 // operations on the underlying linked binary tree. For example, we support the\n31 // protected syntax root() as shorthand for tree.root() with the following utility:\n32 protected Position<Entry<K,V>> root() return tree.root();\n{ }\n33\n34 /\u2217\u2217 Returns the position in p's subtree having given key (or else the terminal leaf).\u2217/\n35 private Position<Entry<K,V>> treeSearch(Position<Entry<K,V>> p, K key)\n{\n36 if (isExternal(p))\n37 return p; // key not found; return the final leaf\n38 int comp = compare(key, p.getElement());\n39 if (comp == 0)\n40 return p; // key found; return its position\n41 else if (comp < 0)\n42 return treeSearch(left(p), key); // search left subtree\n43 else\n44 return treeSearch(right(p), key); // search right subtree\n45\n}\nCodeFragment11.3: BeginningofaTreeMapclassbasedonabinarysearchtree.\nwww.it-ebooks.info\n468 Chapter11. SearchTrees\n46 /\u2217\u2217 Returns the value associated with the specified key (or else null). \u2217/\n47 public V get(K key) throws IllegalArgumentException\n{\n48 checkKey(key); // may throw IllegalArgumentException\n49 Position<Entry<K,V>> p = treeSearch(root(), key);\n50 rebalanceAccess(p); // hook for balanced tree subclasses\n51 if (isExternal(p)) return null; // unsuccessful search\n52 return p.getElement().getValue(); // match found\n53\n54 } /\u2217\u2217 Associates the given value with the given key, returning any overridden value.\u2217/\n55 public V put(K key, V value) throws IllegalArgumentException\n{\n56 checkKey(key); // may throw IllegalArgumentException\n57 Entry<K,V> newEntry = new MapEntry<>(key, value);\n58 Position<Entry<K,V>> p = treeSearch(root(), key);\n59 if (isExternal(p)) // key is new\n{\n60 expandExternal(p, newEntry);\n61 rebalanceInsert(p); // hook for balanced tree subclasses\n62 return null;\n63 else // replacing existing key\n} {\n64 V old = p.getElement().getValue();\n65 set(p, newEntry);\n66 rebalanceAccess(p); // hook for balanced tree subclasses\n67 return old;\n68\n}\n69\n70 } /\u2217\u2217 Removes the entry having key k (if any) and returns its associated value. \u2217/\n71 public V remove(K key) throws IllegalArgumentException\n{\n72 checkKey(key); // may throw IllegalArgumentException\n73 Position<Entry<K,V>> p = treeSearch(root(), key);\n74 if (isExternal(p)) // key not found\n{\n75 rebalanceAccess(p); // hook for balanced tree subclasses\n76 return null;\n77 else\n} {\n78 V old = p.getElement().getValue();\n79 if (isInternal(left(p)) && isInternal(right(p))) // both children are internal\n{\n80 Position<Entry<K,V>> replacement = treeMax(left(p));\n81 set(p, replacement.getElement());\n82 p = replacement;\n83 // now p has at most one child that is an internal node\n}\n84 Position<Entry<K,V>> leaf = (isExternal(left(p)) ? left(p) : right(p));\n85 Position<Entry<K,V>> sib = sibling(leaf);\n86 remove(leaf);\n87 remove(p); // sib is promoted in p\u2019s place\n88 rebalanceDelete(sib); // hook for balanced tree subclasses\n89 return old;\n90\n}\n91\n}\nCodeFragment11.4: Primarymapoperations fortheTreeMapclass.\nwww.it-ebooks.info\n11.1. BinarySearchTrees 469\n92 /\u2217\u2217 Returns the position with the maximum key in subtree rooted at Position p. \u2217/\n93 protected Position<Entry<K,V>> treeMax(Position<Entry<K,V>> p)\n{\n94 Position<Entry<K,V>> walk = p;\n95 while (isInternal(walk))\n96 walk = right(walk);\n97 return parent(walk); // we want the parent of the leaf\n98\n99 } /\u2217\u2217 Returns the entry having the greatest key (or null if map is empty). \u2217/\n100 public Entry<K,V> lastEntry()\n{\n101 if (isEmpty()) return null;\n102 return treeMax(root()).getElement();\n103\n104 } /\u2217\u2217 Returns the entry with greatest key less than or equal to given key (if any). \u2217/\n105 public Entry<K,V> floorEntry(K key) throws IllegalArgumentException\n{\n106 checkKey(key); // may throw IllegalArgumentException\n107 Position<Entry<K,V>> p = treeSearch(root(), key);\n108 if (isInternal(p)) return p.getElement(); // exact match\n109 while (!isRoot(p))\n{\n110 if (p == right(parent(p)))\n111 return parent(p).getElement(); // parent has next lesser key\n112 else\n113 p = parent(p);\n114\n}\n115 return null; // no such floor exists\n116\n117 } /\u2217\u2217 Returns the entry with greatest key strictly less than given key (if any). \u2217/\n118 public Entry<K,V> lowerEntry(K key) throws IllegalArgumentException\n{\n119 checkKey(key); // may throw IllegalArgumentException\n120 Position<Entry<K,V>> p = treeSearch(root(), key);\n121 if (isInternal(p) && isInternal(left(p)))\n122 return treeMax(left(p)).getElement(); // this is the predecessor to p\n123 // otherwise, we had failed search, or match with no left child\n124 while (!isRoot(p))\n{\n125 if (p == right(parent(p)))\n126 return parent(p).getElement(); // parent has next lesser key\n127 else\n128 p = parent(p);\n129\n}\n130 return null; // no such lesser key exists\n131\n}\nCodeFragment11.5:AsampleofthesortedmapoperationsfortheTreeMapclass.\nThesymmetrical utility, treeMin,andpublic methods firstEntry,ceilingEntry, and\nhigherEntryareavailable online.\nwww.it-ebooks.info\n470 Chapter11. SearchTrees\n132 /\u2217\u2217 Returns an iterable collection of all key-value entries of the map. \u2217/\n133 public Iterable<Entry<K,V>> entrySet()\n{\n134 ArrayList<Entry<K,V>> buffer = new ArrayList<>(size());\n135 for (Position<Entry<K,V>> p : tree.inorder())\n136 if (isInternal(p)) buffer.add(p.getElement());\n137 return buffer;\n138\n139 } /\u2217\u2217 Returns an iterable of entries with keys in range [fromKey, toKey). \u2217/\n140 public Iterable<Entry<K,V>> subMap(K fromKey, K toKey)\n{\n141 ArrayList<Entry<K,V>> buffer = new ArrayList<>(size());\n142 if (compare(fromKey, toKey) < 0) // ensure that fromKey < toKey\n143 subMapRecurse(fromKey, toKey, root(), buffer);\n144 return buffer;\n145\n}\n146 private void subMapRecurse(K fromKey, K toKey, Position<Entry<K,V>> p,\n147 ArrayList<Entry<K,V>> buffer)\n{\n148 if (isInternal(p))\n149 if (compare(p.getElement(), fromKey) < 0)\n150 // p's key is less than fromKey, so any relevant entries are to the right\n151 subMapRecurse(fromKey, toKey, right(p), buffer);\n152 else\n{\n153 subMapRecurse(fromKey, toKey, left(p), buffer); // first consider left subtree\n154 if (compare(p.getElement(), toKey) < 0) // p is within range\n{\n155 buffer.add(p.getElement()); // so add it to buffer, and consider\n156 subMapRecurse(fromKey, toKey, right(p), buffer); // right subtree as well\n157\n}\n158\n}\n159\n}\nCodeFragment11.6: TreeMapoperationssupportingiterationoftheentiremap,or\naportionofthemapwithagivenkeyrange.\n11.1.4 Performance of a Binary Search Tree\nAnanalysis oftheoperations ofourTreeMap classisgiveninTable11.1. Almost\nall operations have a worst-case running time that depends on h, where h is the\nheightofthecurrenttree. Thisisbecausemostoperationsrelyontraversingapath\nfromtherootofthetree,andthemaximumpathlengthwithinatreeisproportional\nto the height of the tree. Most notably, our implementations of map operations\nget, put, and remove, and most of the sorted map operations, each begins with\na call to the treeSearch utility. Similar paths are traced when searching for the\nminimum ormaximum entry in asubtree, a task used when finding a replacement\nduringadeletionorinfindingtheoverallfirstorlastentryinthemap. Aniteration\nof the entire map is accomplished in O(n) time using an inorder traversal of the\nunderlying tree, andthe recursive subMapimplementation can beshown torun in\nO(s+h)worst-caseboundforacallthatreportssresults(seeExerciseC-11.34).\nwww.it-ebooks.info\n11.1. BinarySearchTrees 471\nMethod RunningTime\nsize,isEmpty O(1)\nget,put,remove O(h)\nfirstEntry,lastEntry O(h)\nceilingEntry,floorEntry,lowerEntry,higherEntry O(h)\nsubMap O(s+h)\nentrySet,keySet,values O(n)\nTable11.1: Worst-case running times of the operations for a TreeMap. Wedenote\nthecurrentheightofthetreewithh,andthenumberofentriesreportedbysubMap\nass. ThespaceusageisO(n),wherenisthenumberofentriesstoredinthemap.\nAbinarysearchtreeT isthereforeanefficientimplementation ofamapwithn\nentriesonlyifitsheightissmall. Inthebestcase,T hasheighth= log(n+1) 1,\n\u2308 \u2309\u2212\nwhich yields logarithmic-time performance formostofthe mapoperations. Inthe\nworst case, however, T has height n, in which case it would look and feel like\nan ordered list implementation of a map. Such a worst-case configuration arises,\nfor example, if we insert entries with keys in increasing or decreasing order. (See\nFigure11.7.)\n10\n20\n30\n40\nFigure11.7: Exampleofabinarysearchtreewithlinearheight,obtained byinsert-\ningentriesinincreasing orderoftheirkeys.\nWe can nevertheless take comfort that, on average, a binary search tree with\nn keys generated from a random series of insertions and removals of keys has ex-\npectedheightO(logn);thejustificationofthisstatementisbeyondthescopeofthe\nbook, requiring careful mathematical language to precisely define what we mean\nbyarandomseriesofinsertionsandremovals,andsophisticatedprobabilitytheory.\nIn applications where one cannot guarantee the random nature of updates, it\nis better to rely on variations of search trees, presented in the remainder of this\nchapter, that guarantee a worst-case height of O(logn), and thus O(logn) worst-\ncasetimeforsearches, insertions, anddeletions.\nwww.it-ebooks.info\n472 Chapter11. SearchTrees\n11.2 Balanced Search Trees\nIn the closing of the previous section, wenoted that ifwe could assume arandom\nseriesofinsertions andremovals,thestandardbinarysearchtreesupportsO(logn)\nexpectedrunningtimesforthebasicmapoperations. However,wemayonlyclaim\nO(n)worst-casetime,becausesomesequencesofoperationsmayleadtoanunbal-\nancedtreewithheightproportional ton.\nIntheremainderofthischapter,wewillexplorefoursearch-treealgorithmsthat\nprovide stronger performance guarantees. Three of the four data structures (AVL\ntrees, splay trees, and red-black trees) are based on augmenting a standard binary\nsearchtreewithoccasional operations toreshapethetreeandreduceitsheight.\nTheprimaryoperationtorebalanceabinarysearchtreeisknownasarotation.\nDuring a rotation, we \u201crotate\u201d a child to be above its parent, as diagrammed in\nFigure11.8.\ny x\nx y\nT T\n3 1\nT T T T\n1 2 2 3\nFigure 11.8: A rotation operation in a binary search tree. A rotation can be per-\nformedtotransformtheleftformationintotheright,ortherightformationintothe\nleft. Notethat allkeys insubtree T havekeys less than that ofposition x, all keys\n1\ninsubtree T have keys that arebetween those of positions xand y, andall keysin\n2\nsubtreeT havekeysthataregreaterthanthatofposition y.\n3\nTo maintain the binary search-tree property through a rotation, we note that\nif position x was a left child of position y prior to a rotation (and therefore the\nkey of x is less than the key of y), then y becomes the right child of x after the\nrotation, and vice versa. Furthermore, we must relink the subtree of entries with\nkeys that lie between the keys of the two positions that are being rotated. For\nexample, inFigure11.8thesubtree labeledT represents entries withkeysthatare\n2\nknown to be greater than that of position x and less than that of position y. In the\nfirstconfiguration ofthat figure, T istheright subtree ofposition x; in the second\n2\nconfiguration, itistheleftsubtreeofposition y.\nBecause a single rotation modifies a constant number of parent-child relation-\nships,itcanbeimplemented inO(1)timewithalinkedbinarytreerepresentation.\nwww.it-ebooks.info\n11.2. BalancedSearchTrees 473\nIn the context of a tree-balancing algorithm, a rotation allows the shape of a\ntree tobemodifiedwhilemaintaining thesearch-tree property. Ifused wisely, this\noperation can be performed to avoid highly unbalanced tree configurations. For\nexample, arightward rotation fromthefirstformation ofFigure11.8tothesecond\nreduces the depth of each node in subtree T by one, while increasing the depth\n1\nof each node in subtree T by one. (Note that the depth of nodes in subtree T are\n3 2\nunaffected bytherotation.)\nOneormorerotationscanbecombinedtoprovidebroaderrebalancingwithina\ntree. Onesuchcompoundoperationweconsiderisatrinoderestructuring. Forthis\nmanipulation, weconsiderapositionx,itsparenty,anditsgrandparentz. Thegoal\nis to restructure the subtree rooted at z in order to reduce the overall path length\nto x and its subtrees. Pseudocode for a restructure(x) method is given in Code\nFragment11.7andillustrated inFigure11.9. Indescribing atrinode restructuring,\nwetemporarily renamethe positions x, y, andzasa,b, and c,sothat aprecedes b\nand b precedes c in an inorder traversal of T. There are four possible orientations\nmapping x, y, and z to a, b, and c, as shown in Figure 11.9, which are unified\ninto one caseby ourrelabeling. Thetrinode restructuring replaces zwiththenode\nidentified asb, makes thechildren ofthisnode beaandc, and makes thechildren\nof a and c be the four previous children of x, y, and z (other than x and y), while\nmaintaining theinorderrelationships ofallthenodesinT.\nAlgorithmrestructure(x):\nInput: A position x of a binary search tree T that has both a parent y and a\ngrandparent z\nOutput: Tree T after a trinode restructuring (which corresponds to a single or\ndoublerotation) involving positions x,y,andz\n1: Let (a, b, c) be a left-to-right (inorder) listing of the positions x, y, and z, and\nlet(T ,T ,T ,T )bealeft-to-right (inorder) listingofthefoursubtrees ofx,y,\n1 2 3 4\nandznotrootedatx,y,orz.\n2: Replacethesubtreerootedatzwithanewsubtreerootedatb.\n3: Letabetheleftchild ofbandletT 1 andT 2 betheleftand rightsubtrees ofa,\nrespectively.\n4: LetcbetherightchildofbandletT 3 andT 4 betheleftandrightsubtreesofc,\nrespectively.\nCodeFragment11.7: Thetrinoderestructuring operation inabinarysearchtree.\nIn practice, the modification of a tree T caused by a trinode restructuring op-\neration can be implemented through case analysis either as asingle rotation (as in\nFigure 11.9a and b)oras adouble rotation (asin Figure 11.9c and d). Thedouble\nrotation ariseswhenpositionxhasthemiddleofthethreerelevantkeysandisfirst\nrotatedaboveitsparent,andthenabovewhatwasoriginallyitsgrandparent. Inany\nofthecases, thetrinode restructuring iscompleted withO(1)running time.\nwww.it-ebooks.info\n474 Chapter11. SearchTrees\na=z singlerotation b=y\nb=y a=z c=x\nc=x\nT\n1\nT T T T T\n2 1 2 3 4\nT T\n3 4\n(a)\nc=z singlerotation b=y\nb=y a=x c=z\na=x\nT\n4\nT T T T T\n3 1 2 3 4\nT T\n1 2\n(b)\na=z doublerotation b=x\nc=y a=z c=y\nb=x\nT\n1\nT T T T T\n4 1 2 3 4\nT T\n2 3\n(c)\nc=z doublerotation b=x\na=y a=y c=z\nb=x\nT\n4\nT T T T T\n1 1 2 3 4\nT T\n2 3\n(d)\nFigure 11.9: Schematic illustration of a trinode restructuring operation: (a and b)\nrequireasinglerotation; (candd)requireadoublerotation.\nwww.it-ebooks.info\n11.2. BalancedSearchTrees 475\n11.2.1 Java Framework for Balancing Search Trees\nOurTreeMapclass (introduced inSection 11.1.3) isafully functional mapimple-\nmentation. However,therunningtimeforitsoperationsdependontheheightofthe\ntree,andintheworst-case,thatheightmaybeO(n)foramapwithnentries. There-\nfore, we have intentionally designed the TreeMap class in a way that allows it to\nbeeasilyextendedtoprovidemoreadvancedtree-balancingstrategies. Inlatersec-\ntions of this chapter, we will implement subclasses AVLTreeMap, SplayTreeMap,\nandRBTreeMap. Inthissection,wedescribethreeimportantformsofsupportthat\ntheTreeMapclassoffersthesesubclasses.\nHooks for Rebalancing Operations\nOurimplementationofthebasicmapoperationsinSection11.1.3includesstrategic\ncallstothreenonpublic methodsthatserveashooksforrebalancing algorithms:\nAcalltorebalanceInsert(p)ismadefromwithintheputmethod,afteranew\n\u2022\nnodeisaddedtothetreeatposition p(line61ofCodeFragment11.4).\nA call to rebalanceDelete(p)is madefrom within the remove method, after\n\u2022\na node is deleted from the tree (line 88 of Code Fragment 11.4); position p\nidentifiesthechildoftheremovednodethatwaspromotedinitsplace.\nAcalltorebalanceAccess(p)ismadebyanycalltoget,put,orremovethat\n\u2022\ndoes not result in a structural change. Position p, which could be internal\nor external, represents the deepest node ofthe tree that wasaccessed during\nthe operation. Thishook is specifically used by the splay tree structure (see\nSection11.4)torestructureatreesothatmorefrequentlyaccessednodesare\nbrought closertotheroot.\nWithin our TreeMap class, we provide the trivial declarations of these three\nmethods, having bodies that donothing, as shown inCode Fragment 11.8. Asub-\nclass of TreeMap may override any of these methods to implement a nontrivial\naction to rebalance atree. This isanother example of the template method design\npattern,asoriginally discussed inSection2.3.3.\nprotected void rebalanceInsert(Position<Entry<K,V>> p)\n{ }\nprotected void rebalanceDelete(Position<Entry<K,V>> p)\n{ }\nprotected void rebalanceAccess(Position<Entry<K,V>> p)\n{ }\nCode Fragment 11.8: Trivial definitions of TreeMap methods that serve as hooks\nfor our rebalancing framework. These methods may be overridden by subclasses\ninordertoperform appropriate rebalancing operations.\nwww.it-ebooks.info\n476 Chapter11. SearchTrees\nProtected Methods for Rotating and Restructuring\nTo support common restructuring operations, our TreeMap class relies on storing\nthe tree as an instance of a new nested class, BalanceableBinaryTree (shown in\nCode Fragments 11.9 and 11.10). That class is a specialization of the original\nLinkedBinaryTreeclassfromSection8.3.1. Thisnewclassprovidesprotectedutil-\nity methods rotate and restructure that, respectively, implement a single rotation\nand a trinode restructuring (described at the beginning of Section 11.2). Although\nthesemethodsarenotinvokedbythestandardTreeMapoperations, theirinclusion\nsupports greatercodereuse, astheyareavailabletoallbalanced-tree subclasses.\nThesemethodsareimplementedinCodeFragment11.10. Tosimplifythecode,\nwe define an additional relink utility that properly links parent and child nodes to\neach other. The focus of the rotate method then becomes redefining the relation-\nship between the parent and child, relinking a rotated node directly to its original\ngrandparent, and shifting the \u201cmiddle\u201d subtree (that labeled as T in Figure 11.8)\n2\nbetweentherotated nodes.\nForthetrinoderestructuring, wedeterminewhethertoperformasingleordou-\nble rotation, as originally described in Figure 11.9. The four cases in that figure\ndemonstrate a downward path z to y to x that are respectively right-right, left-left,\nright-left, and left-right. The first two patterns, with matching orientation, war-\nrant a single rotation moving y upward, while the last two patterns, with opposite\norientations, warrantadoublerotation movingxupward.\nSpecialized Nodes with an Auxiliary Data Member\nManytree-balancing strategies requirethatsomeformofauxiliary \u201cbalancing\u201d in-\nformation be stored at nodes of a tree. To ease the burden on the balanced-tree\nsubclasses, we choose to add an auxiliary integer value to every node within the\nBalanceableSearchTree class. This is accomplished by defining a new BSTNode\nclass,whichitselfinherits fromthenestedLinkedBinaryTree.Nodeclass. Thenew\nclass declares the auxiliary variable, and provides methods for getting and setting\nitsvalue.\nWe draw attention to an important subtlety in our design, including that of\nthe original LinkedBinaryTree subclass. Whenever a low-level operation on an\nunderlying linked tree requires a new node, we must ensure that the correct type\nof node is created. That is, for our balanceable tree, we need each node to be\na BTNode, which includes the auxiliary field. However, the creation of nodes\noccurs within low-level operations, such as addLeft and addRight, that reside in\ntheoriginalLinkedBinaryTreeclass.\nwww.it-ebooks.info\n11.2. BalancedSearchTrees 477\nWe rely on a technique known as the factory method design pattern. The\nLinkedBinaryTreeclassincludes aprotected method,createNode(originally given\nat lines 30\u201333 of Code Fragment 8.8), that is responsible for instantiating a new\nnodeoftheappropriatetype. Therestofthecodeinthatclassmakessuretoalways\nusethecreateNodemethodwhenanewnodeisneeded.\nIn the LinkedBinaryTree class, the createNode method returns a simple Node\ninstance. In our new BalanceableBinaryTree class, we override the createNode\nmethod (see lines 22\u201327 in Code Fragment 11.9), so that a new instance of the\nBSTNodeclass isreturned. In this way, weeffectively change the behavior ofthe\nlow-level operations in the LinkedBinaryTree class so that it uses instances of our\nspecializednodeclass,andtherefore,thateverynodeinourbalancedtreesincludes\nsupportforthenewauxiliary field.\n1 /\u2217\u2217 A specialized version of LinkedBinaryTree with support for balancing. \u2217/\n2 protected static class BalanceableBinaryTree<K,V>\n3 extends LinkedBinaryTree<Entry<K,V>>\n{\n4 //--------------nested BSTNode class --------------\n5 // this extends the inherited LinkedBinaryTree.Node class\n6 protected static class BSTNode<E> extends Node<E>\n{\n7 int aux=0;\n8 BSTNode(E e, Node<E> parent, Node<E> leftChild, Node<E> rightChild)\n{\n9 super(e, parent, leftChild, rightChild);\n10\n}\n11 public int getAux() return aux;\n{ }\n12 public void setAux(int value) aux = value;\n{ }\n13 //--------- end of nested BSTNode class ---------\n}\n14\n15 // positional-based methods related to aux field\n16 public int getAux(Position<Entry<K,V>> p)\n{\n17 return ((BSTNode<Entry<K,V>>) p).getAux();\n18\n}\n19 public void setAux(Position<Entry<K,V>> p, int value)\n{\n20 ((BSTNode<Entry<K,V>>) p).setAux(value);\n21\n}\n22 // Override node factory function to produce a BSTNode (rather than a Node)\n23 protected\n24 Node<Entry<K,V>> createNode(Entry<K,V> e, Node<Entry<K,V>> parent,\n25 Node<Entry<K,V>> left, Node<Entry<K,V>> right)\n{\n26 return new BSTNode<>(e, parent, left, right);\n27\n}\nCodeFragment11.9: TheBalanceableBinaryTreeclass, whichisnestedwithinthe\nTreeMapclassdefinition. (Continues inCodeFragment11.10.)\nwww.it-ebooks.info\n478 Chapter11. SearchTrees\n28 /\u2217\u2217 Relinks a parent node with its oriented child node. \u2217/\n29 private void relink(Node<Entry<K,V>> parent, Node<Entry<K,V>> child,\n30 boolean makeLeftChild)\n{\n31 child.setParent(parent);\n32 if (makeLeftChild)\n33 parent.setLeft(child);\n34 else\n35 parent.setRight(child);\n36\n37 } /\u2217\u2217 Rotates Position p above its parent. \u2217/\n38 public void rotate(Position<Entry<K,V>> p)\n{\n39 Node<Entry<K,V>> x = validate(p);\n40 Node<Entry<K,V>> y = x.getParent(); // we assume this exists\n41 Node<Entry<K,V>> z = y.getParent(); // grandparent (possibly null)\n42 if (z == null)\n{\n43 root = x; // x becomes root of the tree\n44 x.setParent(null);\n45 else\n}\n46 relink(z, x, y == z.getLeft()); // x becomes direct child of z\n47 // now rotate x and y, including transfer of middle subtree\n48 if (x == y.getLeft())\n{\n49 relink(y, x.getRight(), true); // x\u2019s right child becomes y\u2019s left\n50 relink(x, y, false); // y becomes x\u2019s right child\n51 else\n} {\n52 relink(y, x.getLeft(), false); // x\u2019s left child becomes y\u2019s right\n53 relink(x, y, true); // y becomes left child of x\n54\n}\n55\n56 } /\u2217\u2217 Performs a trinode restructuring of Position x with its parent/grandparent. \u2217/\n57 public Position<Entry<K,V>> restructure(Position<Entry<K,V>> x)\n{\n58 Position<Entry<K,V>> y = parent(x);\n59 Position<Entry<K,V>> z = parent(y);\n60 if ((x == right(y)) == (y == right(z))) // matching alignments\n{\n61 rotate(y); // single rotation (of y)\n62 return y; // y is new subtree root\n63 else // opposite alignments\n} {\n64 rotate(x); // double rotation (of x)\n65 rotate(x);\n66 return x; // x is new subtree root\n67\n}\n68\n}\n69\n}\nCode Fragment 11.10: The BalanceableBinaryTree class, which is nested within\ntheTreeMapclassdefinition (continued fromCodeFragment11.9).\nwww.it-ebooks.info\n11.3. AVLTrees 479\n11.3 AVL Trees\nThe TreeMap class, which uses a standard binary search tree as its data structure,\nshould be an efficient map data structure, but its worst-case performance for the\nvarious operations is linear time, because it is possible that a series of operations\nresults in atree withlinear height. In this section, wedescribe a simple balancing\nstrategythatguaranteesworst-caselogarithmicrunningtimeforallthefundamental\nmapoperations.\nDefinition of an AVL Tree\nThe simple correction is to add a rule to the binary search-tree definition that will\nmaintain a logarithmic height for the tree. Recall that we defined the height of a\nsubtree rootedatposition pofatreetobethenumberofedgesonthelongestpath\nfrom ptoaleaf(seeSection8.1.3). Bythisdefinition, aleafpositionhasheight0.\nInthissection,weconsiderthefollowingheight-balanceproperty,whichchar-\nacterizesthestructure ofabinarysearchtreeT intermsoftheheightsofitsnodes.\nHeight-BalanceProperty: For every internal position p of T, the heights of the\nchildren of pdifferbyatmost1.\nAnybinary search tree T that satisfies the height-balance property is said to be an\nAVL tree, named after the initials of its inventors: Adel\u2019son-Vel\u2019skii and Landis.\nAnexampleofanAVLtreeisshowninFigure11.10.\n4\n44\n2 3\n17 78\n1 2 1\n32 50 88\n1 1\n48 62\nFigure11.10: AnexampleofanAVLtree. Thekeysoftheentriesareshowninside\nthenodes, andtheheights ofthenodesareshownabovethenodes(allleaves have\nheight0).\nwww.it-ebooks.info\n480 Chapter11. SearchTrees\nAnimmediateconsequenceoftheheight-balancepropertyisthatasubtreeofan\nAVLtreeisitselfanAVLtree. Theheight-balance property alsohastheimportant\nconsequence ofkeepingtheheightsmall,asshowninthefollowingproposition.\nProposition 11.1: TheheightofanAVLtreestoringnentriesisO(logn).\nJustification: Instead oftrying tofindanupper bound on theheight ofanAVL\ntree directly, it turns out to be easier to work on the \u201cinverse problem\u201d of finding\na lower bound on the minimum number of internal nodes, denoted as n(h), of an\nAVLtreewithheighth. Wewillshowthatn(h)growsatleastexponentially. From\nthis,itwillbeaneasysteptoderivethattheheightofanAVLtreestoringnentries\nisO(logn).\nWebeginbynotingthatn(1)=1andn(2)=2,becauseanAVLtreeofheight1\nmusthaveexactlyoneinternalnodeandanAVLtreeofheight2musthaveatleast\ntwointernal nodes. Now,anAVLtree withthe minimum number ofnodes having\nheight h for h 3, is such that both its subtrees are AVL trees with the minimum\n\u2265\nnumberofnodes: onewithheighth 1andtheotherwithheighth 2. Takingthe\n\u2212 \u2212\nrootintoaccount,weobtainthefollowingformulathatrelatesn(h)ton(h 1)and\n\u2212\nn(h 2),forh 3:\n\u2212 \u2265\nn(h)=1+n(h 1)+n(h 2). (11.1)\n\u2212 \u2212\nAtthispoint,thereaderfamiliarwiththepropertiesofFibonacciprogressions(Sec-\ntions 2.2.3 and 5.5) will already see that n(h) is a function exponential in h. To\nformalizethatobservation, weproceed asfollows.\nFormula 11.1 implies that n(h) is a strictly increasing function of h. Thus, we\nknow that n(h 1)>n(h 2). Replacing n(h 1) with n(h 2) in Formula 11.1\n\u2212 \u2212 \u2212 \u2212\nanddropping the1,weget,forh 3,\n\u2265\nn(h) > 2 n(h 2). (11.2)\n\u00b7 \u2212\nFormula11.2indicatesthatn(h)atleastdoubleseachtimehincreasesby2,which\nintuitively meansthatn(h)growsexponentially. Toshowthisfactinaformalway,\nweapplyFormula11.2repeatedly, yielding thefollowingseriesofinequalities:\nn(h) > 2 n(h 2)\n\u00b7 \u2212\n> 4 n(h 4)\n\u00b7 \u2212\n> 8 n(h 6)\n\u00b7 \u2212\n.\n.\n.\n> 2i n(h 2i). (11.3)\n\u00b7 \u2212\nThatis,n(h)>2i n(h 2i),foranyintegeri,suchthath 2i 1. Sincewealready\n\u00b7 \u2212 \u2212 \u2265\nknow the values ofn(1) and n(2), wepick iso thath 2i isequal to either 1or2.\n\u2212\nwww.it-ebooks.info\n11.3. AVLTrees 481\nThatis,wepick\nh\ni= 1.\n2 \u2212\n(cid:24) (cid:25)\nBysubstituting theabovevalueofiinFormula11.3,weobtain, forh 3,\n\u2265\nh\nn(h) > 2 \u23082 h \u2309 \u22121 n h 2 +2\n\u00b7 \u2212 2\n(cid:18) (cid:24) (cid:25) (cid:19)\n2 \u23082 h \u2309 \u22121n(1)\n\u2265\n22\nh\u22121.\n(11.4)\n\u2265\nBytakinglogarithmsofbothsidesofFormula11.4,weobtain\nh\nlog(n(h)) > 1,\n2\u2212\nfromwhichweget\nh < 2log(n(h))+2, (11.5)\nwhichimpliesthatanAVLtreestoring nentrieshasheightatmost2logn+2.\nByProposition11.1andtheanalysisofbinarysearchtreesgiveninSection11.1,\nthe operation get, in a map implemented with an AVLtree, runs in time O(logn),\nwherenisthe number ofentries inthe map. Ofcourse, westill have toshow how\ntomaintaintheheight-balance property afteraninsertion ordeletion.\n11.3.1 Update Operations\nGiven a binary search tree T, we say that a position is balanced if the absolute\nvalue ofthedifference between theheights ofitschildren isatmost1,and wesay\nthat it is unbalanced otherwise. Thus, the height-balance property characterizing\nAVLtreesisequivalent tosayingthateverypositionisbalanced.\nTheinsertionanddeletionoperationsforAVLtreesbeginsimilarlytothecorre-\nspondingoperationsfor(standard)binarysearchtrees,butwithpost-processing for\neach operation to restore the balance of any portions of the tree that are adversely\naffectedbythechange.\nInsertion\nSupposethattreeT satisfiestheheight-balance property,andhenceisanAVLtree,\npriortotheinsertion ofanewentry. Aninsertion ofanewentryinabinarysearch\ntree, as described in Section 11.1.2, results in a leaf position p being expanded\nto become internal, with two new external children. This action may violate the\nheight-balance property (see, for example, Figure 11.11a), yet the only positions\nthat may become unbalanced are ancestors of p, because those are the only posi-\ntionswhosesubtreeshavechanged. Therefore,letusdescribehowtorestructure T\ntofixanyunbalance thatmayhaveoccurred.\nwww.it-ebooks.info\n482 Chapter11. SearchTrees\n5 4\n44 44\n2 4 2 3\n17 78 z 17 62 x\n1 3 1 1 2 2\n32 50 y 88 32 50 y 78 z\n1 2 1 1 1\n48 62 x 48 54 88\n1\nT4 T3\n54\nT1 T3 T1 T2 T4\nT2\n(a) (b)\nFigure 11.11: An example insertion of an entry with key 54 in the AVL tree of\nFigure 11.10: (a) after adding a new node for key 54, the nodes storing keys 78\nand 44 become unbalanced; (b) a trinode restructuring restores the height-balance\nproperty. We show the heights of nodes above them, and we identify the nodes x,\ny,andzandsubtrees T ,T ,T ,andT participating inthetrinoderestructuring.\n1 2 3 4\nWe restore the balance of the nodes in the binary search tree T by a simple\n\u201csearch-and-repair\u201d strategy. Inparticular,letzbethefirstpositionweencounterin\ngoingupfrom ptowardtherootofT suchthatzisunbalanced(seeFigure11.11a.)\nAlso, let y denote the child of z with greater height (and note that y must be an\nancestor of p). Finally, let x be the child of y with greater height (there cannot be\natieandposition xmustalsobeanancestor of p,possibly pitself). Werebalance\nthesubtreerootedatzbycallingthetrinoderestructuringmethod,restructure(x),\noriginally described in Section 11.2. An example of such a restructuring in the\ncontextofanAVLinsertion isportrayed inFigure11.11.\nTo formally argue the correctness of this process in reestablishing the AVL\nheight-balanceproperty,weconsidertheimplicationofzbeingthenearestancestor\nof p that became unbalanced after the insertion of p. It must be that the height\nof y increased by one due to the insertion and that it is now 2 greater than its\nsibling. Since y remains balanced, it must be that it formerly had subtrees with\nequal heights, and that the subtree containing x has increased its height by one.\nThat subtree increased either because x= p, and thus its height changed from 0\nto 1, or because x previously had equal-height subtrees and the height of the one\ncontaining phasincreasedby1. Lettingh 0denotetheheightofthetallestchild\n\u2265\nofx,thisscenariomightbeportrayed asinFigure11.12.\nAfter the trinode restructuring, each of x, y, and z is balanced. Furthermore,\nthe root of the subtree after the restructuring has height h+2, which is precisely\ntheheight that zhadbefore theinsertion ofthenewentry. Therefore, anyancestor\nof z that became temporarily unbalanced becomes balanced again, and this one\nrestructuring restores theheight-balance property globally.\nwww.it-ebooks.info\n11.3. AVLTrees 483\nh+2\nh+1\nh z\nh\ny h\nh 1 x h 1\n\u2212 \u2212\nT\n1\nT\n4\nT T\n2 3\n(a)\nh+3\nh+2\nh z\nh+1\ny h\nh 1 x h\n\u2212\nT\n1\nT\n4\nT\n2\nT\n3\n(b)\nh+2\nh+1 h+1\nx\nh z h 1 h y h\n\u2212\nT\n2\nT T T\n1 3 4\n(c)\nFigure11.12: Rebalancing ofasubtree during atypical insertion intoanAVLtree:\n(a) before the insertion; (b) after an insertion in subtree T causes imbalance at z;\n3\n(c)afterrestoring balancewithtrinoderestructuring. Noticethattheoverallheight\nofthesubtree aftertheinsertion isthesameasbeforetheinsertion.\nwww.it-ebooks.info\n484 Chapter11. SearchTrees\nDeletion\nRecall that a deletion from a regular binary search tree results in the structural\nremoval of a node having either zero or one internal children. Such a change may\nviolate the height-balance property in an AVL tree. In particular, if position p\nrepresents a (possibly external) child of the removed node in tree T, there may be\nan unbalanced node on the path from p to the root of T. (See Figure 11.13a.) In\nfact, there can beatmostone such unbalanced node. (Thejustification ofthis fact\nisleftasExerciseC-11.41.)\n4 4\n44 z 62 y\n1 3 3 2\n17 62 y z 44 78 x\n2 2 1 2 0 1\n32 50 78 x 17 50 88\n1 1 1 1 1\nT1\n48 54 88 48 54\nT3\nT3 T1 T4\nT2\nT4\nT2\n(a) (b)\nFigure11.13:Deletionoftheentrywithkey32fromtheAVLtreeofFigure11.11b:\n(a) after removing the node storing key 32, the root becomes unbalanced; (b) a\ntrinoderestructuring ofx,y,andzrestorestheheight-balance property.\nAswithinsertion, weusetrinode restructuring torestore balance inthetreeT.\nIn particular, let z be the first unbalanced position encountered going up from p\ntowardtherootofT,andletybethatchildofzwithgreaterheight(ywillnotbean\nancestor of p). Furthermore, letxbethechildofydefinedasfollows: ifoneofthe\nchildrenofyistallerthantheother,letxbethetallerchildofy;else(bothchildren\nofyhavethesameheight), letxbethechildofyonthesamesideasy(thatis,ify\nistheleftchildofz,letxbetheleftchildofy,elseletxbetherightchildofy). We\nthenperform arestructure(x)operation. (SeeFigure11.13b.)\nThe restructured subtree is rooted at the middle position denoted as b in the\ndescription of the trinode restructuring operation. The height-balance property is\nguaranteed to be locally restored within the subtree of b. (See Exercises R-11.11\nandR-11.12.) Unfortunately,thistrinoderestructuringmayreducetheheightofthe\nsubtree rooted atbby1,whichmaycauseanancestor ofbtobecomeunbalanced.\nSo,afterrebalancingz,wecontinuewalkingupT lookingforunbalancedpositions.\nIf we find another, we perform a restructure operation to restore its balance, and\ncontinue marching upT looking formore,allthewaytotheroot. Sincetheheight\nof T is O(logn), where n is the number of entries, by Proposition 11.1, O(logn)\ntrinoderestructurings aresufficienttorestoretheheight-balance property.\nwww.it-ebooks.info\n11.3. AVLTrees 485\nPerformance of AVL Trees\nBy Proposition 11.1, the height of an AVL tree with n entries is guaranteed to\nbe O(logn). Because the standard binary search-tree operation had running times\nbounded by the height (see Table 11.1), and because the additional work in main-\ntainingbalancefactorsandrestructuring anAVLtreecanbeboundedbythelength\nof a path in the tree, the traditional map operations run in worst-case logarithmic\ntime with an AVL tree. We summarize these results in Table 11.2, and illustrate\nthisperformance inFigure11.14.\nMethod RunningTime\nsize,isEmpty O(1)\nget,put,remove O(logn)\nfirstEntry,lastEntry O(logn)\nceilingEntry,floorEntry,lowerEntry,higherEntry O(logn)\nsubMap O(s+logn)\nentrySet,keySet,values O(n)\nTable11.2: Worst-case running timesofoperations forann-entry sorted mapreal-\nizedasanAVLtreeT,withsdenoting thenumberofentriesreported bysubMap.\nHeight Timeperlevel\nO(1)\nAVLTreeT:\nO(1)\nO(logn)\ndownphase\nO(1)\nupphase\nWorst-casetime: O(logn)\nFigure11.14: Illustrating therunning timeofsearches andupdates inanAVLtree.\nThe time performance is O(1) per level, broken into a down phase, which typi-\ncallyinvolvessearching,andanupphase,whichtypicallyinvolvesupdatingheight\nvaluesandperforminglocaltrinoderestructurings (rotations).\nwww.it-ebooks.info\n486 Chapter11. SearchTrees\n11.3.2 Java Implementation\nA complete implementation of an AVLTreeMap class is provided in Code Frag-\nments 11.11 and 11.12. It inherits from the standard TreeMap class and relies on\nthe balancing framework described in Section 11.2.1. Wehighlight twoimportant\naspects of our implementation. First, the AVLTreeMap uses the node\u2019s auxiliary\nbalancingvariabletostoretheheightofthesubtreerootedatthatnode,withleaves\nhaving abalance factor of0bydefault. Wealso provide several utilities involving\nheightsofnodes(seeCodeFragment11.11).\nToimplement thecorelogic oftheAVLbalancing strategy, wedefineautility,\nnamedrebalance,thatsufficestorestoretheheight-balance propertyafteraninser-\ntionoradeletion(seeCodeFragment11.11). Althoughtheinheritedbehaviors for\ninsertionanddeletionarequitedifferent,thenecessarypost-processing foranAVL\ntree can be unified. In both cases, we trace an upward path from the position p at\nwhichthechangetookplace,recalculating theheightofeachpositionbasedonthe\n(updated) heights of its children. We perform a trinode restructuring operation if\nan imbalanced position is reached. The upward march from p continues until we\nreach an ancestor with height that was unchanged by the map operation, or with\nheight that was restored to its previous value by a trinode restructuring operation,\nor until reaching the root of the tree (in which case the overall height of the tree\nhasincreased byone). Toeasilydetectthestopping condition, werecordthe\u201cold\u201d\nheight of a position, as it existed before the insertion or deletion operation begin,\nandcomparethattothenewlycalculated heightafterapossible restructuring.\n1 /\u2217\u2217 An implementation of a sorted map using an AVL tree. \u2217/\n2 public class AVLTreeMap<K,V> extends TreeMap<K,V>\n3 /\u2217\u2217 Constructs an empty map using the natural ordering of { keys. \u2217/\n4 public AVLTreeMap() super();\n5 /\u2217\u2217 Constructs an emp { ty map usin } g the given comparator to order keys. \u2217/\n6 public AVLTreeMap(Comparator<K> comp) super(comp);\n7 /\u2217\u2217 Returns the height of the given tree positi { on. \u2217/ }\n8 protected int height(Position<Entry<K,V>> p)\n{\n9 return tree.getAux(p);\n10\n11 } /\u2217\u2217 Recomputes the height of the given position based on its children's heights. \u2217/\n12 protected void recomputeHeight(Position<Entry<K,V>> p)\n{\n13 tree.setAux(p, 1 + Math.max(height(left(p)), height(right(p))));\n14\n15 } /\u2217\u2217 Returns whether a position has balance factor between 1 and 1 inclusive. \u2217/\n\u2212\n16 protected boolean isBalanced(Position<Entry<K,V>> p)\n{\n17 return Math.abs(height(left(p)) height(right(p))) <= 1;\n\u2212\n18\n}\nCodeFragment11.11: AVLTreeMapclass. (Continues inCodeFragment11.12.)\nwww.it-ebooks.info\n11.3. AVLTrees 487\n19 /\u2217\u2217 Returns a child of p with height no smaller than that of the other child. \u2217/\n20 protected Position<Entry<K,V>> tallerChild(Position<Entry<K,V>> p)\n{\n21 if (height(left(p)) > height(right(p))) return left(p); // clear winner\n22 if (height(left(p)) < height(right(p))) return right(p); // clear winner\n23 // equal height children; break tie while matching parent's orientation\n24 if (isRoot(p)) return left(p); // choice is irrelevant\n25 if (p == left(parent(p))) return left(p); // return aligned child\n26 else return right(p);\n27\n28 } /\u2217\u2217\n29 \u2217 Utility used to rebalance after an insert or removal operation. This traverses the\n30 \u2217 path upward from p, performing a trinode restructuring when imbalance is found,\n31 \u2217 continuing until balance is restored.\n32 \u2217/\n33 protected void rebalance(Position<Entry<K,V>> p)\n{\n34 int oldHeight, newHeight;\n35 do\n{\n36 oldHeight = height(p); // not yet recalculated if internal\n37 if (!isBalanced(p)) // imbalance detected\n{\n38 // perform trinode restructuring, setting p to resulting root,\n39 // and recompute new local heights after the restructuring\n40 p = restructure(tallerChild(tallerChild(p)));\n41 recomputeHeight(left(p));\n42 recomputeHeight(right(p));\n43\n}\n44 recomputeHeight(p);\n45 newHeight = height(p);\n46 p = parent(p);\n47 while (oldHeight != newHeight && p != null);\n}\n48\n49 } /\u2217\u2217 Overrides the TreeMap rebalancing hook that is called after an insertion. \u2217/\n50 protected void rebalanceInsert(Position<Entry<K,V>> p)\n{\n51 rebalance(p);\n52\n53 } /\u2217\u2217 Overrides the TreeMap rebalancing hook that is called after a deletion. \u2217/\n54 protected void rebalanceDelete(Position<Entry<K,V>> p)\n{\n55 if (!isRoot(p))\n56 rebalance(parent(p));\n57\n}\n58\n}\nCodeFragment11.12: AVLTreeMapclass(continued fromCodeFragment11.11).\nwww.it-ebooks.info\n488 Chapter11. SearchTrees\n11.4 Splay Trees\nThenextsearch-treestructurewestudyisknownasaasplaytree. Thisstructureis\nconceptually quitedifferentfromtheotherbalancedsearchtreeswewilldiscussin\nthischapter, forasplaytreedoesnotstrictlyenforcealogarithmicupperboundon\ntheheight ofthetree. Infact, noadditional height, balance, orother auxiliary data\nneedbestoredwiththenodesofthistree.\nThe efficiency of splay trees is due to a certain move-to-root operation, called\nsplaying, that is performed at the bottommost position p reached during every in-\nsertion,deletion,orevenasearch. (Inessence,thisisavariantofthemove-to-front\nheuristic that we explored for lists in Section 7.7.2.) Intuitively, a splay operation\ncauses morefrequently accessed elements toremainnearer totheroot, thereby re-\nducingthetypicalsearchtimes. Thesurprisingthingaboutsplayingisthatitallows\nustoguaranteealogarithmicamortizedrunningtime,forinsertions, deletions, and\nsearches.\n11.4.1 Splaying\nGiven a node x of a binary search tree T, wesplay x by moving x to the root of T\nthrough asequence ofrestructurings. Theparticular restructurings weperform are\nimportant, for it is not sufficient to move x to the root of T by just any sequence\nof restructurings. The specific operation we perform to move x up depends upon\ntherelativepositionsofx,itsparenty,andx\u2019sgrandparent z(ifitexists). Thereare\nthreecasesthatwewillconsider.\nzig-zig: The node x and its parent y are both left children or both right children.\n(See Figure 11.15.) We promote x, making y a child of x and z a child of y,\nwhilemaintaining theinorderrelationships ofthenodesinT.\n10 30\nz x\n20 20\ny y\n30 10\nx z\nT T\n1 4\nT T\n2 3\nT T T T\n3 4 1 2\n(a) (b)\nFigure11.15: Zig-zig: (a) before; (b) after. There is another symmetric configura-\ntionwherexandyareleftchildren.\nwww.it-ebooks.info\n11.4. SplayTrees 489\nzig-zag: One of x and y is a left child and the other is a right child. (See Fig-\nure 11.16.) In this case, we promote x by making x have y and z as its chil-\ndren,whilemaintaining theinorderrelationships ofthenodesinT.\n10\nz\n30 20\ny x\n20 10 30\nx z y\nT\n1\nT\n4\nT T T T T T\n2 3 1 2 3 4\n(a) (b)\nFigure11.16: Zig-zag: (a) before; (b)after. There isanother symmetric configura-\ntionwherexisarightchildandyisaleftchild.\nzig: xdoes nothave agrandparent. (SeeFigure11.17.) Inthiscase, weperform a\nsingle rotation topromotexovery,makingyachildofx,whilemaintaining\ntherelativeinorderrelationships ofthenodesinT.\n10 20\ny x\n20 10\nx y\nT T\n1 3\nT T T T\n2 3 1 2\n(a) (b)\nFigure11.17: Zig: (a) before; (b) after. There is another symmetric configuration\nwherexisoriginally aleftchildofy.\nWeperform azig-zigorazig-zag whenxhasagrandparent, andweperform a\nzigwhenxhasaparentbutnotagrandparent. Asplayingstepconsistsofrepeating\ntheserestructurings atxuntilxbecomestherootofT. Anexampleofthesplaying\nofanodeisshowninFigures11.18and11.19.\nwww.it-ebooks.info\n490 Chapter11. SearchTrees\n8\n3 10\n4 11\n6 12\n5 7 16\n13 17\n14\n(a)\n8\n3 10\n4 11\n6 12\n5 7 14\n13 16\n17\n(b)\n8\n3 10\n4 11\n6 12\n5 7 14\n13 16\n17\n(c)\nFigure11.18: Example of splaying a node: (a) splaying the node storing 14 starts\nwithazig-zag; (b)after the zig-zag; (c)the nextstep willbeazig-zig. (Continues\ninFigure11.19.)\nwww.it-ebooks.info\n11.4. SplayTrees 491\n8\n3 10\n4 14\n6 12 16\n5 7 11 13 17\n(d)\n8\n3 10\n4 14\n6 12 16\n5 7 11 13 17\n(e)\n14\n10 16\n8 12 17\n3 11 13\n4\n6\n5 7\n(f)\nFigure11.19: Example of splaying a node:(d) after the zig-zig; (e) the next step is\nagainazig-zig; (f)afterthezig-zig. (Continued fromFigure11.18.)\nwww.it-ebooks.info\n492 Chapter11. SearchTrees\n11.4.2 When to Splay\nTherulesthatdictatewhensplaying isperformedareasfollows:\nWhen searching for key k, if k is found at position p, we splay p, else we\n\u2022\nsplaytheparentoftheleafpositionatwhichthesearchterminatesunsuccess-\nfully. For example, the splaying in Figures 11.18 and 11.19 would be per-\nformedaftersearching successfully forkey14orunsuccessfully forkey15.\nWhen inserting key k, we splay the newly created internal node where k\n\u2022\ngets inserted. For example, the splaying in Figures 11.18 and 11.19 would\nbe performed if 14 were the newly inserted key. We show a sequence of\ninsertions inasplaytreeinFigure11.20.\n1\n1 3\n3 1\n(a) (b) (c)\n3 2\n2\n1 1 3\n1 3\n2 4\n(d) (e) (f)\n4\n3\n2\n1\n(g)\nFigure 11.20: A sequence of insertions in a splay tree: (a) initial tree; (b) after\ninserting 3,butbeforeazigstep;(c)aftersplaying; (d)afterinserting2,butbefore\na zig-zag step; (e) after splaying; (f) after inserting 4, but before a zig-zig step;\n(g)aftersplaying.\nwww.it-ebooks.info\n11.4. SplayTrees 493\nWhen deleting a key k, we splay the position p that is the parent of the re-\n\u2022\nmovednode;recallthatbytheremovalalgorithm forbinarysearchtrees,the\nremovednodemaybethatoriginallycontainingk,oradescendantnodewith\nareplacement key. Anexampleofsplaying following adeletion isshownin\nFigure11.21.\n8\n7\n3 10 3 10\n7\n4 11 4 11\np\n6 6\nw\n5 5\n(a) (b)\n7 7\n6 10 6 10\n4 11 4 11\n3 5 3 5\n(c) (d)\n6\n4 7\n3 5 10\n11\n(e)\nFigure11.21: Deletion from a splay tree: (a) the deletion of 8 from the root node\nis performed by moving to the root the key of its inorder predecessor w, deleting\nw,andsplaying theparent pofw;(b)splaying pstartswithazig-zig; (c)after the\nzig-zig;(d)thenextstepisazig;(e)afterthezig.\nwww.it-ebooks.info\n494 Chapter11. SearchTrees\n11.4.3 Java Implementation\nAlthough the mathematical analysis of a splay tree\u2019s performance is complex (see\nSection 11.4.4), the implementation of splay trees is a rather simple adaptation to\na standard binary search tree. Code Fragment 11.13 provides a complete imple-\nmentationofaSplayTreeMapclass,basedupontheunderlying TreeMapclassand\nuseofthebalancing frameworkdescribed inSection 11.2.1. Notethattheoriginal\nTreeMapclassmakescallstotherebalanceAccessmethod,notjustfromwithinthe\nget method, but also within the put method when modifying the value associated\nwithanexistingkey,andwithinafailedremoveoperation.\n1 /\u2217\u2217 An implementation of a sorted map using a splay tree. \u2217/\n2 public class SplayTreeMap<K,V> extends TreeMap<K,V>\n3 /\u2217\u2217 Constructs an empty map using the natural ordering of { keys. \u2217/\n4 public SplayTreeMap() super();\n5 /\u2217\u2217 Constructs an empty { map using } the given comparator to order keys. \u2217/\n6 public SplayTreeMap(Comparator<K> comp) super(comp);\n7 /\u2217\u2217 Utility used to rebalance after a map opera { tion. \u2217/ }\n8 private void splay(Position<Entry<K,V>> p)\n{\n9 while (!isRoot(p))\n{\n10 Position<Entry<K,V>> parent = parent(p);\n11 Position<Entry<K,V>> grand = parent(parent);\n12 if (grand == null) // zig case\n13 rotate(p);\n14 else if ((parent == left(grand)) == (p == left(parent))) // zig-zig case\n{\n15 rotate(parent); // move PARENT upward\n16 rotate(p); // then move p upward\n17 else // zig-zag case\n} {\n18 rotate(p); // move p upward\n19 rotate(p); // move p upward again\n20\n}\n21\n}\n22\n}\n23 // override the various TreeMap rebalancing hooks to perform the appropriate splay\n24 protected void rebalanceAccess(Position<Entry<K,V>> p)\n{\n25 if (isExternal(p)) p = parent(p);\n26 if (p != null) splay(p);\n27\n}\n28 protected void rebalanceInsert(Position<Entry<K,V>> p)\n{\n29 splay(p);\n30\n}\n31 protected void rebalanceDelete(Position<Entry<K,V>> p)\n{\n32 if (!isRoot(p)) splay(parent(p));\n33\n}\n34\n}\nCodeFragment11.13: Acompleteimplementation oftheSplayTreeMapclass.\nwww.it-ebooks.info\n11.4. SplayTrees 495\n11.4.4 Amortized Analysis of Splaying \u22c6\nAfterazig-zig orzig-zag, thedepthofposition pdecreases bytwo,andafterazig\nthe depth of p decreases by one. Thus, if p has depth d, splaying p consists of a\nsequence of d/2 zig-zigs and/or zig-zags, plus one final zig if d is odd. Since a\n\u230a \u230b\nsinglezig-zig, zig-zag, orzigaffectsaconstant numberofnodes, itcanbedonein\nO(1) time. Thus, splaying a position p in a binary search tree T takes time O(d),\nwhere d is thedepth of pinT. Inother words, the timeforperforming asplaying\nstepforaposition pisasymptoticallythesameasthetimeneededjusttoreachthat\nposition inatop-downsearchfromtherootofT.\nWorst-Case Time\nIn the worst case, the overall running time of a search, insertion, or deletion in a\nsplay tree of height h is O(h), since the position we splay might be the deepest\nposition in the tree. Moreover, it is possible for h to be as large as n, as shown in\nFigure11.20. Thus,fromaworst-casepointofview,asplaytreeisnotanattractive\ndatastructure.\nIn spite of its poor worst-case performance, a splay tree performs well in an\namortized sense. That is, in a sequence of intermixed searches, insertions, and\ndeletions, eachoperationtakesonaveragelogarithmictime. Weperformtheamor-\ntizedanalysis ofsplaytreesusingtheaccounting method.\nAmortized Performance of Splay Trees\nForouranalysis,wenotethatthetimeforperformingasearch,insertion,ordeletion\nis proportional to the time for the associated splaying. So let us consider only\nsplaying time.\nLet T be a splay tree with n keys, and let w be a node of T. We define the\nsize n(w) of w as the number of nodes in the subtree rooted at w. Note that this\ndefinition implies that thesize of aninternal node isone morethan thesum ofthe\nsizesofitschildren. Wedefinetherankr(w)ofanodewasthelogarithminbase2\nofthesizeofw,thatis,r(w)=log(n(w)). Clearly,therootofT hasthemaximum\nsize,n,andthemaximumrank,logn,whileeachleafhassize1andrank0.\nWe use cyber-dollars to pay for the work we perform in splaying a position p\nin T, and we assume that one cyber-dollar pays for a zig, while two cyber-dollars\npay for a zig-zig or a zig-zag. Hence, the cost of splaying a position at depth d is\nd cyber-dollars. Wekeepavirtualaccountstoringcyber-dollars ateachpositionof\nT. Notethatthisaccountexistsonlyforthepurposeofouramortizedanalysis, and\ndoesnotneedtobeincludedinadatastructure implementing thesplaytreeT.\nwww.it-ebooks.info\n496 Chapter11. SearchTrees\nAn Accounting Analysis of Splaying\nWhen weperform asplaying, wepay a certain number of cyber-dollars (the exact\nvalueofthepaymentwillbedeterminedattheendofouranalysis). Wedistinguish\nthreecases:\nIfthepaymentisequaltothesplaying work,thenweuseitalltopayforthe\n\u2022\nsplaying.\nIfthepaymentisgreaterthanthesplayingwork,wedeposittheexcessinthe\n\u2022\naccounts ofseveralnodes.\nIfthepaymentislessthanthesplayingwork,wemakewithdrawalsfromthe\n\u2022\naccounts ofseveralnodestocoverthedeficiency.\nWeshowbelowthatapaymentofO(logn)cyber-dollars peroperationissufficient\nto keep the system working, that is, to ensure that each node keeps a nonnegative\naccountbalance.\nAn Accounting Invariant for Splaying\nWe use a scheme in which transfers are made between the accounts of the nodes\ntoensurethattherewillalwaysbeenoughcyber-dollars towithdrawforpayingfor\nsplaying workwhenneeded.\nIn order to use the accounting method to perform our analysis of splaying, we\nmaintainthefollowinginvariant:\nBeforeandafterasplaying,eachnodewofT hasr(w)cyber-dollars\ninitsaccount.\nNotethattheinvariant is\u201cfinancially sound,\u201dsinceitdoesnotrequireustomakea\npreliminary deposittoendowatreewithzerokeys.\nLetr(T)bethesumoftheranksofallthenodesofT. Topreservetheinvariant\nafterasplaying, wemustmakeapaymentequaltothesplayingworkplusthetotal\nchangeinr(T). Werefertoasinglezig,zig-zig, orzig-zagoperation inasplaying\nas asplaying substep. Also, wedenote the rank of a node w ofT before and after\na splaying substep with r(w) and r\u2032(w), respectively. The following proposition\ngives an upper bound on the change of r(T) caused by a single splaying substep.\nWewillrepeatedlyusethislemmainouranalysisofafullsplayingofanodetothe\nroot.\nwww.it-ebooks.info\n11.4. SplayTrees 497\nProposition 11.2: Let\u03b4bethevariationofr(T)causedbyasinglesplayingsub-\nstep(azig,zig-zig,orzig-zag)foranodexinT.Wehavethefollowing:\n\u03b4 3(r\u2032(x) r(x)) 2ifthesubstepisazig-zigorzig-zag.\n\u2022 \u2264 \u2212 \u2212\n\u03b4 3(r\u2032(x) r(x))ifthesubstepisazig.\n\u2022 \u2264 \u2212\nJustification: Weusethefactthat,ifa>0,b>0,andc>a+b,\nloga+logb<2logc 2. (11.6)\n\u2212\nLetusconsider thechangeinr(T)caused byeachtypeofsplaying substep.\nzig-zig: (Recall Figure 11.15.) Since the size of each node is one more than the\nsize of its two children, note that only the ranks of x, y, and z change in a\nzig-zig operation, where y is the parent of x and z is the parent of y. Also,\nr\u2032(x)=r(z),r\u2032(y) r\u2032(x),andr(x) r(y). Thus,\n\u2264 \u2264\n\u03b4 = r\u2032(x)+r\u2032(y)+r\u2032(z) r(x) r(y) r(z)\n\u2212 \u2212 \u2212\n= r\u2032(y)+r\u2032(z) r(x) r(y)\n\u2212 \u2212\nr\u2032(x)+r\u2032(z) 2r(x). (11.7)\n\u2264 \u2212\nNote that n(x)+n\u2032(z)<n\u2032(x). Thus, r(x)+r\u2032(z)<2r\u2032(x) 2, as per For-\n\u2212\nmula11.6;thatis,\nr\u2032(z)<2r\u2032(x) r(x) 2.\n\u2212 \u2212\nThisinequality andFormula11.7imply\n\u03b4 r\u2032(x)+(2r\u2032(x) r(x) 2) 2r(x)\n\u2264 \u2212 \u2212 \u2212\n3(r\u2032(x) r(x)) 2.\n\u2264 \u2212 \u2212\nzig-zag: (Recall Figure 11.16.) Again, bythe definition ofsize and rank, only the\nranksofx,y,andzchange,whereydenotestheparentofxandzdenotesthe\nparentofy. Also,r(x)<r(y)<r(z)=r\u2032(x). Thus,\n\u03b4 = r\u2032(x)+r\u2032(y)+r\u2032(z) r(x) r(y) r(z)\n\u2212 \u2212 \u2212\n= r\u2032(y)+r\u2032(z) r(x) r(y)\n\u2212 \u2212\nr\u2032(y)+r\u2032(z) 2r(x). (11.8)\n\u2264 \u2212\nNote that n\u2032(y)+n\u2032(z)<n\u2032(x); hence, r\u2032(y)+r\u2032(z)<2r\u2032(x) 2, as per For-\n\u2212\nmula11.6. Thus,\n\u03b4 2r\u2032(x) 2 2r(x)\n\u2264 \u2212 \u2212\n= 2(r\u2032(x) r(x)) 2 3(r\u2032(x) r(x)) 2.\n\u2212 \u2212 \u2264 \u2212 \u2212\nzig: (Recall Figure11.17.) Inthis case, only the ranks ofxand ychange, where y\ndenotes theparentofx. Also,r\u2032(y) r(y)andr\u2032(x) r(x). Thus,\n\u2264 \u2265\n\u03b4 = r\u2032(y)+r\u2032(x) r(y) r(x)\n\u2212 \u2212\nr\u2032(x) r(x)\n\u2264 \u2212\n3(r\u2032(x) r(x)).\n\u2264 \u2212\nwww.it-ebooks.info\n498 Chapter11. SearchTrees\nProposition 11.3: LetT beasplaytreewithroott,andlet\u2206bethetotalvariation\nofr(T)causedbysplayinganodexatdepthd.Wehave\n\u2206 3(r(t) r(x)) d+2.\n\u2264 \u2212 \u2212\nJustification: Splaying node x consists of c= d/2 splaying substeps, each\n\u2308 \u2309\nof which is a zig-zig or a zig-zag, except possibly the last one, which is a zig if\nd is odd. Let r (x)=r(x) be the initial rank of x, and for i=1,...,c, let r(x) be\n0 i\nthe rank of x after the ith substep and \u03b4 be the variation of r(T) caused by the ith\ni\nsubstep. ByProposition 11.2,thetotalvariation \u2206ofr(T)caused bysplaying xis\nc\n\u2206 = \u2211\u03b4\ni\ni=1\nc\n2+ \u22113(r(x) r (x)) 2\ni i\u22121\n\u2264 \u2212 \u2212\ni=1\n= 3(r (x) r (x)) 2c+2\nc 0\n\u2212 \u2212\n3(r(t) r(x)) d+2.\n\u2264 \u2212 \u2212\nByProposition 11.3, ifwemake apayment of3(r(t) r(x))+2 cyber-dollars\n\u2212\ntowards the splaying of node x, we have enough cyber-dollars to maintain the in-\nvariant, keeping r(w) cyber-dollars at each node w in T, and pay for the entire\nsplaying work, which costs d cyber-dollars. Since the size of the root t is n, its\nrank r(t) = logn. Given that r(x) 0, the payment to be made for splaying is\n\u2265\nO(logn) cyber-dollars. Tocomplete our analysis, wehave tocompute the cost for\nmaintaining theinvariant whenanodeisinserted ordeleted.\nWhen inserting a new node w into a splay tree with n keys, the ranks of all\nthe ancestors of w are increased. Namely, let w ,w,...,w be the ancestors of w,\n0 i d\nwhere w =w, w is the parent of w , and w is the root. For i=1,...,d, let\n0 i i\u22121 d\nn\u2032(w) and n(w) be the size of w before and after the insertion, respectively, and\ni i i\nletr\u2032(w)andr(w)betherankofw beforeandaftertheinsertion. Wehave\ni i i\nn\u2032(w)=n(w)+1.\ni i\nAlso, since n(w)+1 n(w ), for i=0,1,...,d 1, we have the following for\ni i+1\n\u2264 \u2212\neachiinthisrange:\nr\u2032(w)=log(n\u2032(w))=log(n(w)+1) log(n(w ))=r(w ).\ni i i i+1 i+1\n\u2264\nThus,thetotalvariation ofr(T)causedbytheinsertion is\nd d\u22121\n\u2211 r\u2032(w) r(w) r\u2032(w )+ \u2211 (r(w ) r(w))\ni i d i+1 i\n\u2212 \u2264 \u2212\ni=1 i=1\n(cid:0) (cid:1) = r\u2032(w ) r(w )\nd 0\n\u2212\nlogn.\n\u2264\nTherefore,apaymentofO(logn)cyber-dollarsissufficienttomaintaintheinvariant\nwhenanewnodeisinserted.\nwww.it-ebooks.info\n11.4. SplayTrees 499\nWhen deleting anode w from a splay tree with n keys, the ranks of all the an-\ncestors ofwaredecreased. Thus,thetotalvariation ofr(T)caused bythedeletion\nis negative, and we do not need to make any payment to maintain the invariant\nwhen a node is deleted. Therefore, we may summarize our amortized analysis in\nthefollowingproposition (whichissometimescalledthe\u201cbalanceproposition\u201d for\nsplaytrees):\nProposition 11.4: Considerasequenceofmoperationsonasplaytree,eachone\nasearch,insertion,ordeletion,startingfromasplaytreewithzerokeys.Also,let\nn bethenumberofkeysinthetreeafteroperationi,andnbethetotalnumberof\ni\ninsertions.Thetotalrunningtimeforperformingthesequenceofoperationsis\nm\nO m+ \u2211logn ,\ni\ni=1 !\nwhichisO(mlogn).\nIn other words, the amortized running time of performing a search, insertion,\nor deletion in a splay tree is O(logn), where n is the size of the splay tree at the\ntime. Thus, a splay tree can achieve logarithmic-time amortized performance for\nimplementing asorted mapADT. Thisamortized performance matchestheworst-\ncase performance of AVL trees, (2,4) trees, and red-black trees, but it does so\nusing asimple binary tree that does not need anyextra balance information stored\nat each of its nodes. In addition, splay trees have a number of other interesting\nproperties thatarenotsharedbytheseotherbalanced searchtrees. Weexploreone\nsuch additional property in the following proposition (which is sometimes called\nthe\u201cStaticOptimality\u201dproposition forsplaytrees):\nProposition 11.5: Considerasequenceofmoperationsonasplaytree,eachone\nasearch,insertion,ordeletion,startingfromasplaytreeT withzerokeys.Also,let\nf(i)denotethenumberoftimestheentryiisaccessedinthesplaytree,thatis,its\nfrequency,andletndenotethetotalnumberofentries.Assumingthateachentryis\naccessedatleastonce,thenthetotalrunningtimeforperformingthesequenceof\noperationsis\nn\nO m+ \u2211 f(i)log(m/f(i)) .\ni=1 !\nWeomittheproofofthisproposition,butitisnotashardtojustifyasonemight\nimagine. The remarkable thing is that this proposition states that the amortized\nrunning timeofaccessing anentryiisO(log(m/f(i))).\nwww.it-ebooks.info\n500 Chapter11. SearchTrees\n11.5 (2,4) Trees\nIn this section, we will consider a data structure known as a (2,4) tree. It is a\nparticularexampleofamoregeneralstructureknownasamultiwaysearchtree,in\nwhich internal nodes may have more than two children. Other forms of multiway\nsearchtreeswillbediscussed inSection15.3.\n11.5.1 Multiway Search Trees\nRecallthatgeneraltreesaredefinedsothatinternalnodesmayhavemanychildren.\nInthissection, wediscuss howgeneraltreescanbeusedasmultiwaysearch trees.\nMap entries stored in a search tree are pairs of the form (k,v), where k is the key\nandvisthevalueassociated withthekey.\nDefinition of a Multiway Search Tree\nLetw be a node of an ordered tree. Wesay that w is a d-node if w has d children.\nWe define a multiway search tree to be an ordered tree T that has the following\nproperties, whichareillustrated inFigure11.22a:\nEachinternalnodeofT hasatleasttwochildren. Thatis,eachinternalnode\n\u2022\nisad-nodesuchthatd 2.\n\u2265\nEachinternal d-node wofT withchildren c ,...,c stores anordered setof\n1 d\n\u2022\nd 1key-valuepairs(k ,v ),...,(k ,v ),wherek k .\n1 1 d\u22121 d\u22121 1 d\u22121\n\u2212 \u2264\u00b7\u00b7\u00b7\u2264\nLet us conventionally define k = and k =+ . For each entry (k,v)\n0 d\n\u2022 \u2212\u221e \u221e\nstored at a node in the subtree of w rooted at c, i=1,...,d, we have that\ni\nk k k.\ni\u22121 i\n\u2264 \u2264\nThat is, if wethink ofthe set of keys stored at was including the special fictitious\nkeys k = and k =+ , then a key k stored in the subtree of T rooted at a\n0 d\n\u2212\u221e \u221e\nchild node c must be \u201cin between\u201d two keys stored at w. This simple viewpoint\ni\ngives rise to the rule that a d-node stores d 1 regular keys, and it also forms the\n\u2212\nbasisofthealgorithm forsearching inamultiwaysearchtree.\nBy the above definition, the external nodes of a multiway search do not store\nanydataandserveonlyas\u201cplaceholders.\u201d Aswithourconventionforbinarysearch\ntrees (Section 11.1), these can bereplaced by nullreferences inpractice. Abinary\nsearch tree can be viewed as a special case of a multiway search tree, where each\ninternalnodestoresoneentryandhastwochildren.\nWhetherinternalnodesofamultiwaytreehavetwochildrenormany,however,\nthere is an interesting relationship between the number of key-value pairs and the\nnumberofexternalnodesinamultiwaysearchtree.\nProposition 11.6: Ann-entrymultiwaysearchtreehasn+1externalnodes.\nWeleavethejustification ofthisproposition asanexercise(C-11.49).\nwww.it-ebooks.info\n11.5. (2,4)Trees 501\n22\n5 10 25\n3 4 6 8 14 23 24 27\n11 13 17\n(a)\n22\n5 10 25\n3 4 6 8 14 23 24 27\n11 13 17\n(b)\n22\n5 10 25\n3 4 6 8 14 23 24 27\n11 13 17\n(c)\nFigure11.22: (a)AmultiwaysearchtreeT;(b)searchpathinT forkey12(unsuc-\ncessfulsearch); (c)searchpathinT forkey24(successful search).\nwww.it-ebooks.info\n502 Chapter11. SearchTrees\nSearching in a Multiway Tree\nSearchingforanentrywithkeykinamultiwaysearchtreeT issimple. Weperform\nsuchasearchbytracingapathinT startingattheroot. (SeeFigure11.22bandc.)\nWhenweareatad-nodewduringthissearch,wecomparethekeykwiththekeys\nk ,...,k stored atw. Ifk=k for somei, the search issuccessfully completed.\n1 d\u22121 i\nOtherwise, we continue the search in the child c of w such that k < k < k.\ni i\u22121 i\n(Recall that we conventionally define k = and k = + .) If we reach an\n0 d\n\u2212\u221e \u221e\nexternal node, then weknow that there is no entry with key k in T, and the search\nterminatesunsuccessfully.\nData Structures for Representing Multiway Search Trees\nInSection 8.3.3, wediscuss alinked data structure for representing ageneral tree.\nThis representation can also be used for a multiway search tree. When using a\ngeneral tree to implement a multiway search tree, we must store at each node one\normorekey-valuepairsassociated withthatnode. Thatis,weneedtostorewithw\nareference tosomecollection thatstorestheentriesforw.\nDuring a search for key k in a multiway search tree, the primary operation\nneededwhennavigatinganodeisfindingthesmallestkeyatthatnodethatisgreater\nthan or equal to k. Forthis reason, itis natural to model the information at anode\nitself as a sorted map, allowing use of the ceilingEntry(k) method. We say such\na map serves as a secondary data structure to support the primary data structure\nrepresented by the entire multiway search tree. This reasoning may at first seem\nlike a circular argument, since we need a representation of a (secondary) ordered\nmaptorepresent a(primary) ordered map. Wecanavoid anycircular dependence,\nhowever, byusing thebootstrapping technique, whereweuseasimplesolution to\naproblem tocreateanew,moreadvanced solution.\nIn the context of a multiway search tree, a natural choice for the secondary\nstructure ateachnode istheSortedTableMapofSection 10.3.1. Because wewant\nto determine the associated value in case of a match for key k, and otherwise the\ncorresponding child c such that k < k < k, we recommend having each key\ni i\u22121 i\nk in the secondary structure map to the pair (v,c). With such a realization of a\ni i i\nmultiway search tree T, processing a d-node w while searching for an entry of T\nwithkeyk canbeperformed using abinary search operation inO(logd)time. Let\nd denotethemaximumnumberofchildrenofanynodeofT,andlethdenotethe\nmax\nheight of T. The search time in a multiway search tree is therefore O(hlogd ).\nmax\nIfd isaconstant, therunningtimeforperforming asearchisO(h).\nmax\nThe primary efficiency goal for a multiway search tree is to keep the height\nas small as possible. We will next discuss a strategy that caps d at 4 while\nmax\nguaranteeing a height h that is logarithmic in n, the total number of entries stored\ninthemap.\nwww.it-ebooks.info\n11.5. (2,4)Trees 503\n11.5.2 (2,4)-Tree Operations\nOneform ofamultiway search treethat keeps thetreebalanced whileusing small\nsecondary data structures at each node is the (2,4) tree, also known as a 2-4 tree\nor 2-3-4 tree. This data structure achieves these goals by maintaining two simple\nproperties (seeFigure11.23):\nSizeProperty: Everyinternalnodehasatmostfourchildren.\nDepthProperty: Alltheexternalnodeshavethesamedepth.\n12\n5 10 15\n3 4 6 7 8 11 13 14 17\nFigure11.23: A(2,4)tree.\nAgain,weassumethatexternalnodesareemptyand,forthesakeofsimplicity,\nwe describe our search and update methods assuming that external nodes are real\nnodes, althoughthislatterrequirement isnotstrictly needed.\nEnforcing the size property for (2,4) trees keeps the nodes in the multiway\nsearch tree simple. It also gives rise to the alternative name \u201c2-3-4 tree,\u201d since it\nimpliesthateachinternal nodeinthetreehas2,3,or4children. Anotherimplica-\ntion of this rule is that wecan represent the secondary map stored at each internal\nnodeusinganunorderedlistoranorderedarray,andstillachieveO(1)-timeperfor-\nmance for all operations (since d =4). The depth property, on the other hand,\nmax\nenforces animportantboundontheheightofa(2,4)tree.\nProposition 11.7: Theheightofa(2,4)treestoringnentriesisO(logn).\nJustification: Lethbethe height of a(2,4) treeT storing nentries. Wejustify\ntheproposition byshowingtheclaim\n1\nlog(n+1) h log(n+1). (11.9)\n2 \u2264 \u2264\nTo justify this claim note first that, by the size property, we can have at most\n4 nodes at depth 1, at most 42 nodes at depth 2, and so on. Thus, the number of\nexternalnodesinT isatmost4h. Likewise,bythedepthpropertyandthedefinition\nwww.it-ebooks.info\n504 Chapter11. SearchTrees\nofa(2,4) tree, wemusthaveatleast 2nodes atdepth 1,atleast22 nodes atdepth\n2,andsoon. Thus,thenumberofexternalnodesinT isatleast2h. Inaddition, by\nProposition 11.6,thenumberofexternalnodesinT isn+1. Therefore,weobtain\n2h n+1 4h.\n\u2264 \u2264\nTakingthelogarithm inbase2ofthetermsfortheaboveinequalities, wegetthat\nh log(n+1) 2h,\n\u2264 \u2264\nwhichjustifiesourclaim(Formula11.9)whentermsarerearranged.\nProposition11.7statesthatthesizeanddepthpropertiesaresufficientforkeep-\ning a multiway tree balanced. Moreover, this proposition implies that performing\na search in a (2,4) tree takes O(logn) time and that the specific realization of the\nsecondarystructuresatthenodesisnotacrucialdesignchoice,sincethemaximum\nnumberofchildren d isaconstant.\nmax\nMaintainingthesizeanddepthpropertiesrequiressomeeffortafterperforming\ninsertions anddeletionsina(2,4)tree,however. Wediscusstheseoperations next.\nInsertion\nTo insert a new entry (k,v), with key k, into a (2,4) tree T, we first perform a\nsearch for k. Assuming that T has no entry with key k, this search terminates\nunsuccessfully at an external node z. Let w be the parent of z. We insert the new\nentryintonodewandaddanewchildy(anexternalnode)towontheleftofz.\nOurinsertionmethodpreservesthedepthproperty,sinceweaddanewexternal\nnode at the same level as existing external nodes. Nevertheless, it may violate the\nsize property. Indeed, if a node w was previously a 4-node, then it would become\na 5-node after the insertion, which causes the tree T to no longer be a (2,4) tree.\nThis type of violation of the size property is called an overflow at node w, and it\nmustberesolved inorder torestore theproperties ofa(2,4)tree. Letc ,...,c be\n1 5\nthechildrenofw,andletk ,...,k bethekeysstoredatw. Toremedytheoverflow\n1 4\natnodew,weperformasplitoperation onwasfollows(seeFigure11.24):\nReplacewwithtwonodesw\u2032 andw\u2032\u2032,where\n\u2022\nw\u2032 isa3-node withchildren c ,c ,c storingkeysk andk .\n1 2 3 1 2\n\u25e6\nw\u2032\u2032 isa2-nodewithchildren c ,c storingkeyk .\n4 5 4\n\u25e6\nIfwistherootofT,createanewrootnodeu;else,letubetheparentofw.\n\u2022\nInsert keyk into uandmakew\u2032 andw\u2032\u2032 children ofu,sothatifwwaschild\n3\n\u2022\niofu,thenw\u2032 andw\u2032\u2032 becomechildreniandi+1ofu,respectively.\nAsaconsequence ofasplitoperation onnodew,anew overflowmayoccur atthe\nparent uofw. Ifsuch anoverflow occurs, it triggers inturn asplit atnode u. (See\nFigure11.25.) Asplitoperationeithereliminatestheoverfloworpropagatesitinto\ntheparent ofthecurrent node. Weshowasequence ofinsertions ina(2,4) treein\nFigure11.26.\nwww.it-ebooks.info\n11.5. (2,4)Trees 505\nu u u\nh h h h h k h\n1 2 1 2 1 3 2\nk\nw w 3 w\u2032 w\u2032\u2032\nk k k k k k k k k k\n1 2 3 4 1 2 4 1 2 4\nc c c c c c c c c c c c c c c\n1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n(a) (b) (c)\nFigure11.24:Anodesplit: (a)overflowata5-nodew;(b)thethirdkeyofwinserted\nintotheparentuofw;(c)nodewreplacedwitha3-nodew\u2032 anda2-nodew\u2032\u2032.\n5 10 12 5 10 12\n3 4 6 7 8 11 13 14 15 3 4 6 7 8 11 13 14 15 17\n(a) (b)\n5 10 12 5 10 12 15\n15\n3 4 6 7 8 11 13 14 17 3 4 6 7 8 11 13 14 17\n(c) (d)\n12\n12\n5 10 15 5 10 15\n3 4 6 7 8 11 13 14 17 3 4 6 7 8 11 13 14 17\n(e) (f)\nFigure11.25: An insertion in a (2,4) tree that causes a cascading split: (a) before\ntheinsertion; (b)insertion of17, causing anoverflow;(c)asplit; (d)afterthesplit\nanewoverflowoccurs;(e)anothersplit,creating anewrootnode;(f)finaltree.\nwww.it-ebooks.info\n506 Chapter11. SearchTrees\n4 4 6 4 6 12 4 6 12 15\n(a) (b) (c) (d)\n12\n12\n4 6 15 4 6 15\n(e) (f)\n12 12\n3 4 6 15 3 4 5 6 15\n(g) (h)\n12 5 12\n5\n3 4 6 15 3 4 6 15\n(i) (j)\n5 12 5 12\n3 4 6 10 15 3 4 6 8 10 15\n(k) (l)\nFigure 11.26: A sequence of insertions into a (2,4) tree: (a) initial tree with one\nentry; (b) insertion of 6; (c) insertion of 12; (d) insertion of 15, which causes an\noverflow;(e)split,whichcausesthecreationofanewrootnode;(f)afterthesplit;\n(g)insertionof3;(h)insertionof5,whichcausesanoverflow;(i)split;(j)afterthe\nsplit;(k)insertion of10;(l)insertion of8.\nwww.it-ebooks.info\n11.5. (2,4)Trees 507\nAnalysis of Insertion in a (2,4) Tree\nBecause d isatmost 4, theoriginal search for theplacement ofnew keyk uses\nmax\nO(1)timeateachlevel, andthusO(logn)timeoverall, since theheight ofthetree\nisO(logn)byProposition 11.7.\nThe modifications to a single node to insert a new key and child can be im-\nplemented to run in O(1) time, as can a single split operation. The number of\ncascadingsplitoperationsisboundedbytheheightofthetree,andsothatphaseof\ntheinsertionprocessalsorunsinO(logn)time. Therefore,thetotaltimetoperform\naninsertionina(2,4)treeisO(logn).\nDeletion\nLet us now consider the removal of an entry with key k from a (2,4) tree T. We\nbegin such an operation by performing a search in T for an entry with key k. Re-\nmovinganentryfroma(2,4)treecanalwaysbereducedtothecasewheretheentry\nto be removed is stored at a node w whose children are external nodes. Suppose,\nfor instance, that the entry with key k that we wish to remove is stored in the ith\nentry (k,v) at a node z that has internal children. In this case, we swap the entry\ni i\n(k,v)withanappropriate entrythatisstoredatanodewwithexternalchildrenas\ni i\nfollows(seeFigure11.27d):\n1. Wefindtherightmostinternalnodewinthesubtreerootedattheith childof\nz,notingthatthechildren ofnodewareallexternal nodes.\n2. Weswaptheentry(k,v)atzwiththelastentryofw.\ni i\nOnce we ensure that the entry to remove is stored at a node w with only external\nchildren (because either it was already at w or we swapped it into w), we simply\nremovetheentryfromwandremovetheexternalnodethatistheith childofw.\nRemoving an entry (and a child) from a node w as described above preserves\nthedepthproperty,forwealwaysremoveanexternalchildfromanodewwithonly\nexternalchildren. However,inremovingsuchanexternalnode,wemayviolatethe\nsizeproperty atw. Indeed, ifwwaspreviously a2-node, thenitbecomes a1-node\nwith no entries after the removal (Figure 11.27a and d), which is not allowed in\na (2,4) tree. This type of violation of the size property is called an underflow at\nnode w. To remedy an underflow, we check whether an immediate sibling of w\nis a 3-node or a 4-node. If we find such a sibling s, then we perform a transfer\noperation, inwhichwemoveachildofstow,akeyofstotheparentuofwands,\nandakeyofutow. (SeeFigure11.27bandc.) Ifwhasonlyonesibling,orifboth\nimmediatesiblingsofware2-nodes,thenweperformafusionoperation, inwhich\nwemergewwithasibling,creatinganewnodew\u2032,andmoveakeyfromtheparent\nuofwtow\u2032. (SeeFigure11.27eandf.)\nwww.it-ebooks.info\n508 Chapter11. SearchTrees\n12 12\nu\n5 10 15 10 15\n5\n4 w 6 s\n6 8 11 13 14 17 8 11 13 14 17\n(a) (b)\n12\n12\nu 11\n6 10 15 6 10 15\nw s\n5 8 11 13 14 17 5 8 13 14 17\n(c) (d)\n11 11\nu u\n6 15 6 15\n10\nw w\u2032\n5 8 13 14 17 5 8 10 13 14 17\n(e) (f)\n11 11\n6 15 6 15\n13\n5 8 10 14 17 5 8 10 14 17\n(g) (h)\nFigure11.27: Asequence ofremovals from a(2,4) tree: (a)removal of4, causing\nan underflow; (b) atransfer operation; (c) after the transfer operation; (d) removal\nof 12, causing an underflow; (e) a fusion operation; (f) after the fusion operation;\n(g)removalof13;(h)afterremoving13.\nwww.it-ebooks.info\n11.5. (2,4)Trees 509\nAfusionoperationatnodewmaycauseanewunderflowtooccurattheparent\nuofw, which inturn triggers atransfer or fusion atu. (SeeFigure 11.28.) Hence,\nthe number of fusion operations is bounded by the height of the tree, which is\nO(logn)byProposition11.7. Ifanunderflowpropagatesallthewayuptotheroot,\nthentherootissimplydeleted. (SeeFigure11.28candd.)\n11 11\nu\n6 15 6\n14 15\nw\n5 8 10 17 5 8 10 17\n(a) (b)\nu\n11\nw\n6 6 11\n5 8 10 15 17 5 8 10 15 17\n(c) (d)\nFigure11.28: Apropagating sequence offusions ina(2,4)tree: (a)removalof14,\nwhichcausesanunderflow;(b)fusion,whichcausesanotherunderflow;(c)second\nfusionoperation, whichcausestheroottoberemoved;(d)finaltree.\nPerformance of (2,4) Trees\nTheasymptotic performance ofa(2,4)treeisidentical tothatofanAVLtree(see\nTable 11.2) in terms of the sorted map ADT, with guaranteed logarithmic bounds\nfor most operations. The time complexity analysis for a (2,4) tree having n key-\nvaluepairsisbasedonthefollowing:\nTheheightofa(2,4)treestoring nentriesisO(logn),byProposition 11.7.\n\u2022\nAsplit,transfer, orfusionoperation takesO(1)time.\n\u2022\nAsearch,insertion, orremovalofanentryvisitsO(logn)nodes.\n\u2022\nThus,(2,4)treesprovideforfastmapsearchandupdateoperations. (2,4)trees\nalsohaveaninteresting relationship tothedatastructure wediscuss next.\nwww.it-ebooks.info\n510 Chapter11. SearchTrees\n11.6 Red-Black Trees\nAlthough AVL trees and (2,4) trees have a number of nice properties, they also\nhave some disadvantages. For instance, AVL trees may require many restructure\noperations (rotations) tobeperformed afteradeletion, and(2,4)treesmayrequire\nmanysplitorfusing operations tobeperformed afteraninsertion orremoval. The\ndata structure we discuss in this section, the red-black tree, does not have these\ndrawbacks;itusesO(1)structuralchangesafteranupdateinordertostaybalanced.\nFormally,ared-black treeisabinarysearchtree(seeSection11.1)withnodes\ncoloredredandblackinawaythatsatisfiesthefollowingproperties:\nRootProperty: Therootisblack.\nExternalProperty: Everyexternal nodeisblack.\nRedProperty: Thechildren ofarednodeareblack.\nDepthProperty: All external nodes have the same black depth, defined as the\nnumberofproperancestors thatareblack.\nAnexampleofared-black treeisshowninFigure11.29.\n12\n5 15\n3 10 13 17\n4 7 11 14\n6 8\nFigure11.29:Anexampleofared-blacktree,with\u201cred\u201dnodesdrawninwhite. The\ncommonblackdepthforthistreeis3.\nWe can make the red-black tree definition more intuitive by noting an inter-\nesting correspondence between red-black trees and (2,4) trees. Namely, given a\nred-black tree, we can construct a corresponding (2,4) tree by merging every red\nnode w into its parent, storing the entry from w at its parent, and with the chil-\ndrenofwbecomingorderedchildrenoftheparent. Forexample,thered-blacktree\nin Figure 11.29 corresponds to the (2,4) tree from Figure 11.23, as illustrated in\nFigure 11.30. The depth property of the red-black tree corresponds to the depth\nproperty of the (2,4) tree since exactly one black node of the red-black tree con-\ntributes toeachnodeofthecorresponding (2,4)tree.\nwww.it-ebooks.info\n11.6. Red-BlackTrees 511\n12\n5 15\n3 10 13 17\n4 7 11 14\n6 8\nFigure 11.30: An illustration of the correspondance between the red-black tree of\nFigure11.29andthe(2,4)treeofFigure11.23,basedonthehighlighted grouping\nofrednodeswiththeirblackparents.\nConversely,wecantransformany(2,4)treeintoacorrespondingred-blacktree\nbycoloring eachnodewblackandthenperforming thefollowing transformations,\nasillustrated inFigure11.31.\nIfwisa2-node, thenkeepthe(black)children ofwasis.\n\u2022\nIf w is a 3-node, then create a new red node y, give w\u2019s last two (black)\n\u2022\nchildren toy,andmakethefirstchildofwandybethetwochildren ofw.\nIf w is a 4-node, then create two new red nodes y and z, give w\u2019s first two\n\u2022\n(black) children toy, givew\u2019slasttwo(black) children toz,and makeyand\nzbethetwochildren ofw.\nNoticethatarednodealwayshasablackparentinthisconstruction.\n15 15\n\u2190\u2192\n(a)\n13 14 13 14\n\u2190\u2192\nor\n14 13\n(b)\n6 7 8 7\n\u2190\u2192\n6 8\n(c)\nFigure11.31: Correspondence between nodes of a (2,4) tree and a red-black tree:\n(a)2-node;(b)3-node;(c)4-node.\nwww.it-ebooks.info\n512 Chapter11. SearchTrees\nProposition 11.8: Theheightofared-blacktreestoringnentriesisO(logn).\nJustification: LetT beared-black treestoring nentries, andlethbetheheight\nofT. Wejustifythisproposition byestablishing thefollowingfact:\nlog(n+1) h 2log(n+1).\n\u2264 \u2264\nLet d be the common black depth of all the external nodes of T. Let T\u2032 be the\n(2,4) tree associated with T, and let h\u2032 be the height of T\u2032. Because of the corre-\nspondencebetweenred-blacktreesand(2,4)trees,weknowthath\u2032=d. Hence,by\nProposition11.7,d=h\u2032 log(n+1). Bytheredproperty,h 2d. Thus,weobtain\n\u2264 \u2264\nh 2log(n+1). Theotherinequality,log(n+1) h,followsfromProposition8.7\n\u2264 \u2264\nandthefactthatT hasninternalnodes.\n11.6.1 Red-Black Tree Operations\nThealgorithm forsearching inared-black treeT isthesameasthatforastandard\nbinary search tree (Section 11.1). Thus, searching in a red-black tree takes time\nproportional totheheightofthetree,whichisO(logn)byProposition 11.8.\nThecorrespondencebetween(2,4)treesandred-blacktreesprovidesimportant\nintuition thatwewilluseinourdiscussion ofhowtoperform updates inred-black\ntrees;infact,theupdatealgorithmsforred-blacktreescanseemmysteriouslycom-\nplex without this intuition. Split and fuse operations of a (2,4) tree will be effec-\ntivelymimickedbyrecoloring neighboring red-black treenodes. Arotation within\na red-black tree will be used to change orientations of a 3-node between the two\nformsshowninFigure11.31(b).\nInsertion\nConsider the insertion of a key-value pair (k,v) into a red-black tree T. The al-\ngorithm initially proceeds as in a standard binary search tree (Section 11.1.2).\nNamely, we search for k in T and if we reach an external node, we replace this\nnode with an internal node x, storing the entry and having two external children.\nIf this is the first entry in T, and thus x is the root, we color it black. In all other\ncases, wecolor xred. Thataction corresponds toinserting (k,v)intoanode ofthe\n(2,4)treeT\u2032atthelowestinternallevel. Theinsertionpreservestherootanddepth\nproperties ofT,butitmayviolatetheredproperty. Indeed, ifxisnottherootofT\nanditsparent yisred, then wehave aparent andachild (namely, yandx) thatare\nboth red. Note that by the root property, y cannot be the root of T, and by the red\nproperty (which waspreviously satisfied), the parent zofymust beblack. Sincex\nanditsparentarered,butx\u2019sgrandparentzisblack,wecallthisviolationofthered\nproperty adoubleredatnodex. Toremedyadoublered,weconsidertwocases.\nwww.it-ebooks.info\n11.6. Red-BlackTrees 513\nCase1: TheSiblingsofyisBlack. (See Figure 11.32.) In this case, the double\nred denotes the fact that we have added the new node to a corresponding\n3-node of the (2,4) tree T\u2032, effectively creating a malformed 4-node. This\nformation has one red node, y, that is the parent of another red node, x;\nwe want the two red nodes to be siblings instead. To fix this problem, we\nperform atrinode restructuring ofT. Thetrinode restructuring (introduced\nin Section 11.2) is done by the operation restructure(x), which consists of\nthefollowingsteps(seeagainFigure11.32):\nTake node x, its parent y, and grandparent z, and temporarily relabel\n\u2022\nthem as a, b, and c, in left-to-right order, so that a, b, and c will be\nvisitedinthisorderbyaninordertreetraversal.\nReplace the grandparent z with the node labeled b, and make nodes a\n\u2022\nandcthechildren ofb,keeping inorderrelationships unchanged.\nAfterperformingtherestructure(x)operation,wecolorbblackandwecolor\naand cred. Thus, the restructuring eliminates thedouble-red problem. No-\ntice that the portion of any path through the restructured part of the tree is\nincident toexactly oneblack node, bothbefore andafterthetrinode restruc-\nturing. Therefore, theblackdepthofthetreeisunaffected.\nz z z z\n30 30 10 10\ny y y y\n20 10 20 30\ns s s s\nx x x x\n10 20 30 20\n(a)\nb\n20\na c\n10 30\n(b)\nFigure 11.32: Restructuring a red-black tree to remedy a double red: (a) the four\nconfigurations forx,y,andzbeforerestructuring; (b)afterrestructuring.\nwww.it-ebooks.info\n514 Chapter11. SearchTrees\nCase2: TheSiblingsofyisRed. (SeeFigure11.33.) Inthiscase,thedouble red\ndenotes an overflow in the corresponding (2,4) tree T\u2032. To fixthe problem,\nweperform theequivalent ofasplit operation. Namely, wedoarecoloring:\nwe color y and s black and their parent z red (unless z is the root, in which\ncase, it remains black). Notice that unless z is the root, the portion of any\npath through the affected part of the tree is incident to exactly one black\nnode, both before andafter therecoloring. Therefore, theblack depth ofthe\ntree is unaffected by the recoloring unless z is the root, in which case it is\nincreased byone.\nHowever, it is possible that the double-red problem reappears after such a\nrecoloring, albeit higher up in the tree T, since z may have a red parent. If\nthedouble-redproblemreappearsatz,thenwerepeattheconsiderationofthe\ntwo cases at z. Thus, a recoloring either eliminates the double-red problem\nat node x, or propagates it to the grandparent z of x. We continue going\nupT performing recolorings untilwefinallyresolvethedouble-red problem\n(with either a final recoloring or a trinode restructuring). Thus, the number\nof recolorings caused by an insertion is no more than half the height of tree\nT,thatis,O(logn)byProposition 11.8.\nz\n30\ny s\n10 20 30 40\n20 40\nx\n10\n(a)\nz\n30\n...30... y s\n20 40\nx\n10 20 40 10\n(b)\nFigure11.33: Recoloring to remedy the double-red problem: (a) before recoloring\nandthecorresponding 5-node intheassociated (2,4)treebeforethesplit;(b)after\nrecoloring andthecorresponding nodesintheassociated (2,4)treeafterthesplit.\nAs further examples, Figures 11.34 and 11.35 show a sequence of insertion\noperations inared-black tree.\nwww.it-ebooks.info\n11.6. Red-BlackTrees 515\n4 4 4 7\n7 7 4 12\n12\n(a) (b) (c) (d)\n7 7 7 7\n4 12 4 12 4 12 4 12\n15 15 3 15 3 5 15\n(e) (f) (g) (h)\n7 7\n4 12 4 14\n3 5 15 3 5 12 15\n14\n(i) (j)\n7 7\n4 14 4 14\n3 5 12 15 3 5 12 15\n18 18\n(k) (l)\nFigure11.34: Asequence ofinsertions inared-blacktree: (a)initialtree;(b)inser-\ntionof7;(c)insertion of12,whichcauses adouble red;(d)afterrestructuring; (e)\ninsertion of 15, which causes a double red; (f) after recoloring (the root remains\nblack); (g) insertion of 3; (h) insertion of 5; (i) insertion of 14, which causes a\ndouble red; (j) after restructuring; (k) insertion of 18, which causes a double red;\n(l)afterrecoloring. (Continues inFigure11.35.)\nwww.it-ebooks.info\n516 Chapter11. SearchTrees\n7 7\n4 14 4 14\n3 5 12 15 3 5 12 16\n18 15 18\n16\n(m) (n)\n7 7\n4 14 4 14\n3 5 12 16 3 5 12 16\n15 18 15 18\n17 17\n(o) (p)\n14\n7 16\n4 12 15 18\n3 5 17\n(q)\nFigure 11.35: A sequence of insertions in a red-black tree (continued from Fig-\nure 11.34): (m)insertion of 16, which causes a double red; (n) after restructuring;\n(o) insertion of17, which causes adouble red; (p) after recoloring there isagain a\ndoublered,tobehandledbyarestructuring; (q)afterrestructuring.\nwww.it-ebooks.info\n11.6. Red-BlackTrees 517\nDeletion\nDeleting anentry withkeyk from ared-black tree T initially proceeds asfor abi-\nnarysearchtree(Section11.1.2). Structurally, theprocessresultsintheremovalof\naninternal node (either that originally containing keyk orits inorder predecessor)\ntogether withachildthatisexternal, andthepromotionofitsotherchild.\nIftheremovedinternal node wasred, thisstructural change doesnotaffectthe\nblack depths of any paths in the tree, nor introduce any red violations, and so the\nresultingtreeremainsavalidred-blacktree. Inthecorresponding(2,4)treeT\u2032,this\ncasedenotestheshrinking ofa4-nodeor3-node. Iftheremovedinternalnodewas\nblack,itmusthavehadblackheight1,andthereforeeitherbothofitschildrenwere\nexternal,orithadoneredchildthatwasaninternalnodewithtwoexternalchildren.\nInthelattercase,theremovednoderepresents theblackpartofacorresponding 3-\nnode, and we restore the red-black properties by recoloring the promoted child to\nbeblack.\nThemostcomplexcaseiswhentheremovednodewasblackandhadtwoexter-\nnal children. In the corresponding (2,4) tree, this denotes the removal of an entry\nfrom a 2-node. Without rebalancing, such a change results in a deficit of one for\nthe black depth of the external position p that is the promoted child of the deleted\ninternal node. Topreserve thedepth property, wetemporarily assign thepromoted\nleaf a fictitious double black color. A double black in T denotes an underflow in\nthecorresponding (2,4)treeT\u2032. Toremedyadouble-black problem atanarbitrary\nposition p,wewillconsider threecases.\nCase1: TheSiblingyofpisBlackandhasaRedChildx. (SeeFigure11.36.)\nWeperform atrinoderestructuring, asoriginally described inSection11.2.\nThe operation restructure(x) takes the node x, its parent y, and grandparent\nz, labels them temporarily lefttoright asa, b, andc, andreplaces zwiththe\nnodelabeledb,makingittheparentoftheothertwo. Wecoloraandcblack,\nandgivebtheformercolorofz.\nNotice that thepath to pin the result includes one additional black node af-\nter the restructure, while the number of black nodes on paths to any of the\nother three subtrees illustrated in Figure 11.36 remains unchanged. There-\nfore,wereturn ptobecolored(regular)black,andthedouble-blackproblem\niseliminated.\nResolving this case corresponds to a transfer operation in the (2,4) tree T\u2032\nbetween two children of node z. The fact that y has a red child assures us\nthat it represents either a 3-node or a 4-node. In effect, the entry previously\nstored at z is demoted to become a new 2-node to resolve the deficiency,\nwhile an entry stored at y or its child is promoted to take the place of the\nentrypreviously storedatz.\nwww.it-ebooks.info\n518 Chapter11. SearchTrees\nz\n...30...\n30\np\ny\n10 40\n10 20 x\n20\n40\n(a)\nz\n...30...\n30\np\ny\n20 40\n10 20 x\n10\n40\n(b)\nb\n...20...\n20\na c\n10 30\n10 30 p\n40\n40\n(c)\nFigure11.36:Restructuringofared-blacktreetoremedythedouble-blackproblem:\n(a) and (b) configurations before the restructuring, where p is a right child and\nthe associated nodes inthecorresponding (2,4) tree before the transfer (twoother\nsymmetric configurations where p is a left child are possible); (c) configuration\nafter the restructuring and the associated nodes in the corresponding (2,4) tree\nafter the transfer. The gray color for node z in parts (a) and (b) and for node b in\npart(c)denotesthefactthatthisnodemaybecoloredeitherredorblack.\nwww.it-ebooks.info\n11.6. Red-BlackTrees 519\nCase2: TheSiblingyofpisBlackandBothChildrenofyareBlack.\nWedoarecoloring, beginningbychangingthecolorof pfromdoubleblack\nto black and the color of y from black to red. This does not create any red\nviolation, becausebothchildrenofyareblack. Tocounteractthedecreasein\nblackdepthforpathspassingthroughyor p,weconsiderthecommonparent\nof pandy,whichwedenoteasz. Ifzisred,wecoloritblackandtheproblem\nhasbeenresolved(seeFigure11.37a). Ifzisblack,wecoloritdoubleblack,\nthereby propagating theproblem higherupthetree(seeFigure11.37b).\nResolving this case corresponds to a fusion operation in the corresponding\n(2,4) tree T\u2032, as y must represent a 2-node. The case where the problem\npropagates upwardiswhenparentzalsorepresents a2-node.\nz z\ny 30 p y 30 p\n20 40 20 40\n(a)\nz\nz\ny 30 p y 30 p\n20 40 20 40\n(b)\nFigure11.37: A recoloring operation, which has neutral effect on the black depth\nfor paths: (a) when z is originally red, the recoloring resolves the double-black\nproblem, ending the process; (b) when z is originally black, it becomes double-\nblack,requiring acascading remedy.\nCase3: SiblingyofpisRed. (SeeFigure11.38.)\nLet z denote the common parent of y and p, and note that z must be black,\nbecause y is red. The combination of y and z represents a 3-node in the\ncorresponding (2,4) tree T\u2032. Inthis case, weperform arotation about yand\nz,andthenrecoloryblackandzred. Thisdenotesareorientationofa3-node\ninthecorresponding (2,4)treeT\u2032.\nWe now reconsider the double-black problem at p. After the adjustment,\nthe sibling of p is black, and either Case 1 or Case 2 applies. Furthermore,\nthe next application will be the last, because Case 1 is always terminal and\nCase2willbeterminalgiventhattheparentof pisnowred.\nwww.it-ebooks.info\n520 Chapter11. SearchTrees\ny\nz 20 z\ny 30 p 30 p\n20 40 40\nFigure 11.38: A rotation and recoloring about red node y and black node z in the\npresence of a double-black problem (a symmetric configuration is possible). This\namounts to a change of orientation in the corresponding 3-node of a (2,4) tree.\nThisoperation does not affect theblack depth of anypaths through this portion of\nthe tree, but after the operation, one of the other resolutions to the double-black\nproblem maybeapplied, asthesiblingof pwillbeblack.\nIn Figure 11.39, we show a sequence of deletions on a red-black tree. We\nillustrateaCase1restructuringinparts(c)and(d). WeillustrateaCase2recoloring\ninparts(f)and(g). Finally,weshowanexampleofaCase3rotationbetweenparts\n(i)and(j),concluding withaCase2recoloring inpart(k).\nPerformance of Red-Black Trees\nTheasymptotic performance of ared-black tree is identical to that of an AVLtree\nor a (2,4) tree in terms of the sorted map ADT, with guaranteed logarithmic time\nbounds for most operations. (See Table 11.2 for a summary of the AVL perfor-\nmance.) The primary advantage of a red-black tree is that an insertion or deletion\nrequires only a constant number of restructuring operations. (This is in contrast\ntoAVLtreesand(2,4)trees,bothofwhichrequire alogarithmic numberofstruc-\nturalchangespermapoperationintheworstcase.) Thatis,aninsertionordeletion\nin a red-black tree requires logarithmic time for a search, and may require a loga-\nrithmic number of recoloring operations that cascade upward. Weformalize these\nfactswiththefollowingpropositions.\nProposition 11.9: Theinsertionofanentryinared-blacktreestoringnentries\ncanbedoneinO(logn) timeandrequiresO(logn) recoloringsandatmostone\ntrinoderestructuring.\nProposition 11.10: Thealgorithmfordeletinganentryfromared-blacktree\nwithn entriestakesO(logn) timeandperformsO(logn) recoloringsandatmost\ntworestructuringoperations.\nTheproofsofthesepropositions areleftasExercisesR-11.26andR-11.27.\nwww.it-ebooks.info\n11.6. Red-BlackTrees 521\n14 14\n7 16 7 16\n4 12 15 18 4 12 15 18\n3 5 17 5 17\n(a) (b)\n14\n14\n5 16\n7 16\n4 7 15 18\n4 15 18\n17\n5 17\n(c) (d)\n14\n14 14\n5 16\n5 16 5 16\n4 7 15 18\n4 7 15 4 7 15\n(e) (f) (g)\n14 14 5\n5\n5 16 5 4 14\n4 14\n4 7 4 7 7\n7\n(h) (i) (j) (k)\nFigure11.39: Asequence ofdeletions fromared-black tree: (a)initial tree; (b)re-\nmovalof 3; (c)removal of12, causing ablack deficit tothe right of7(handled by\nrestructuring); (d)afterrestructuring; (e)removalof17;(f)removalof18,causing\nablackdeficittotherightof16(handledbyrecoloring);(g)afterrecoloring;(h)re-\nmoval of 15; (i) removal of 16, causing a black deficit to the right of 14 (handled\ninitiallybyarotation);(j)aftertherotationtheblackdeficitneedstobehandledby\narecoloring; (k)aftertherecoloring.\nwww.it-ebooks.info\n522 Chapter11. SearchTrees\n11.6.2 Java Implementation\nIn this section, we will provide an implementation of a RBTreeMap class that in-\nherits from thestandard TreeMap class and relies onthe balancing framework de-\nscribed inSection11.2.1. Inthatframework, each nodestores anauxiliary integer\nthatcan beused formaintaining balance information. Forared-black tree, weuse\nthat integer to represent color, choosing to let value 0 (the default) designate the\ncolorblack,andvalue1thecolorred;withthisconvention, anynewlycreated leaf\ninthetreewillbeblack.\nOur implementation begins in Code Fragment 11.14, with constructors for an\nempty map, and a series of convenient utilities for managing the auxiliary field to\nrepresent color information. That code fragment continues with support for rebal-\nancingthetreeafteraninsertionisperformed. Whenanentryhasbeeninsertedina\ntreebythestandard search-tree algorithm, itwillbestoredatapreviously external\nnode that was converted to an internal node with two new external children. The\nrebalanceInserthookisthencalled,allowingustheopportunity tomodifythetree.\nExceptforthespecialcasewherethenewelementisattheroot,wechangethecolor\nofthenodewiththenewelementtored(ithadbeenblackwhenaleaf),andthenwe\nconsiderthepossibility thatwehaveadouble-red violation. TheresolveRedutility\nclosely follows the case analysis described inSection 11.6.1, recurring in the case\nwhentheredviolation ispropagated upward.\nCode Fragment 11.15 manages the rebalancing process after a deletion, based\nupon the case analysis described in Section 11.6.1. If the removed node was red,\nthen no other action is necessary; however, if the removed node was black, we\nmust consider a way to restore the depth property. An additional challenge is that\nbythetimetherebalanceDeletemethodiscalled,anodehasalreadybeenremoved\nfrom the tree (this hook is invoked on the promoted child of that removed node).\nFortunately, we can infer the properties of the removed node based upon the red-\nblacktreeproperties, whichweresatisfiedbeforethedeletion.\nIn particular, let p denote the promoted child of the removed node. If a black\nnode with a red child has been deleted, then p will be that red child; we remedy\nthis by coloring p black. Otherwise, if p is not the root, let s denote the removed\nnode\u2019s sibling (which will appear as p\u2019s sibling after the deletion). If the deleted\nnodewasblackwithtwoblackchildren, wemusttreat pasadoubleblacknodeto\nberemedied. Thisisthecaseif,andonlyif,itssibling\u2019ssubtreehasablackinternal\nnode(becausethered-black depthproperty wassatisfiedpriortothedeletion). We\ntherefore test whether s is a black internal node, or a red internal node with an\ninternalnodeasachild(whichmustbeblackduetotheredproperty ofthetree).\nWe are able to detect the double-black problem within the rebalanceDelete\nmethodofCodeFragment11.15,andwerelyontherecursiveremedyDoubleBlack\nmethodofthatcodefragmenttoresolvetheproblem.\nwww.it-ebooks.info\n11.6. Red-BlackTrees 523\n1 /\u2217\u2217 An implementation of a sorted map using a red-black tree. \u2217/\n2 public class RBTreeMap<K,V> extends TreeMap<K,V>\n3 /\u2217\u2217 Constructs an empty map using the natural ordering o { f keys. \u2217/\n4 public RBTreeMap() super();\n5 /\u2217\u2217 Constructs an emp { ty map usi } ng the given comparator to order keys. \u2217/\n6 public RBTreeMap(Comparator<K> comp) super(comp);\n{ }\n7 // we use the inherited aux field with convention that 0=black and 1=red\n8 // (note that new leaves will be black by default, as aux=0)\n9 private boolean isBlack(Position<Entry<K,V>> p) return tree.getAux(p)==0;\n{ }\n10 private boolean isRed(Position<Entry<K,V>> p) return tree.getAux(p)==1;\n{ }\n11 private void makeBlack(Position<Entry<K,V>> p) tree.setAux(p, 0);\n{ }\n12 private void makeRed(Position<Entry<K,V>> p) tree.setAux(p, 1);\n{ }\n13 private void setColor(Position<Entry<K,V>> p, boolean toRed)\n{\n14 tree.setAux(p, toRed ? 1 : 0);\n15\n16 } /\u2217\u2217 Overrides the TreeMap rebalancing hook that is called after an insertion. \u2217/\n17 protected void rebalanceInsert(Position<Entry<K,V>> p)\n{\n18 if (!isRoot(p))\n{\n19 makeRed(p); // the new internal node is initially colored red\n20 resolveRed(p); // but this may cause a double-red problem\n21\n}\n22\n23 } /\u2217\u2217 Remedies potential double-red violation above red position p. \u2217/\n24 private void resolveRed(Position<Entry<K,V>> p)\n{\n25 Position<Entry<K,V>> parent,uncle,middle,grand; // used in case analysis\n26 parent = parent(p);\n27 if (isRed(parent)) // double-red problem exists\n{\n28 uncle = sibling(parent);\n29 if (isBlack(uncle)) // Case 1: misshapen 4-node\n{\n30 middle = restructure(p); // do trinode restructuring\n31 makeBlack(middle);\n32 makeRed(left(middle));\n33 makeRed(right(middle));\n34 else // Case 2: overfull 5-node\n} {\n35 makeBlack(parent); // perform recoloring\n36 makeBlack(uncle);\n37 grand = parent(parent);\n38 if (!isRoot(grand))\n{\n39 makeRed(grand); // grandparent becomes red\n40 resolveRed(grand); // recur at red grandparent\n41\n}\n42\n}\n43\n}\n44\n}\nCode Fragment 11.14: The RBTreeMap class. (Continues in Code Frag-\nment11.15.)\nwww.it-ebooks.info\n524 Chapter11. SearchTrees\n45 /\u2217\u2217 Overrides the TreeMap rebalancing hook that is called after a deletion. \u2217/\n46 protected void rebalanceDelete(Position<Entry<K,V>> p)\n{\n47 if (isRed(p)) // deleted parent was black\n48 makeBlack(p); // so this restores black depth\n49 else if (!isRoot(p))\n{\n50 Position<Entry<K,V>> sib = sibling(p);\n51 if (isInternal(sib) && (isBlack(sib) isInternal(left(sib))))\n52 remedyDoubleBlack(p); || // sib's subtree has nonzero black height\n53\n}\n54\n}\n55\n56 /\u2217\u2217 Remedies a presumed double-black violation at the given (nonroot) position. \u2217/\n57 private void remedyDoubleBlack(Position<Entry<K,V>> p)\n{\n58 Position<Entry<K,V>> z = parent(p);\n59 Position<Entry<K,V>> y = sibling(p);\n60 if (isBlack(y))\n{\n61 if (isRed(left(y)) isRed(right(y))) // Case 1: trinode restructuring\n|| {\n62 Position<Entry<K,V>> x = (isRed(left(y)) ? left(y) : right(y));\n63 Position<Entry<K,V>> middle = restructure(x);\n64 setColor(middle, isRed(z)); // root of restructured subtree gets z's old color\n65 makeBlack(left(middle));\n66 makeBlack(right(middle));\n67 else // Case 2: recoloring\n} {\n68 makeRed(y);\n69 if (isRed(z))\n70 makeBlack(z); // problem is resolved\n71 else if (!isRoot(z))\n72 remedyDoubleBlack(z); // propagate the problem\n73\n}\n74 else // Case 3: reorient 3-node\n} {\n75 rotate(y);\n76 makeBlack(y);\n77 makeRed(z);\n78 remedyDoubleBlack(p); // restart the process at p\n79\n}\n80\n}\n81\n}\nCode Fragment 11.15: Support for deletion in the RBTreeMap class (continued\nfromCodeFragment11.14).\nwww.it-ebooks.info\n11.7. Exercises 525\n11.7 Exercises\nReinforcement\nR-11.1 Ifweinserttheentries(1,A),(2,B),(3,C),(4,D),and(5,E),inthisorder,into\naninitiallyemptybinarysearchtree,whatwillitlooklike?\nR-11.2 Insert,intoanemptybinarysearchtree,entrieswithkeys30,40,24,58,48,26,\n11,13(inthisorder).Drawthetreeaftereachinsertion.\nR-11.3 Howmanydifferentbinarysearchtreescanstorethekeys 1,2,3 ?\n{ }\nR-11.4 Dr.Amongusclaimsthattheorderinwhichafixedsetofentriesisinsertedinto\na binary search tree does not matter\u2014the same tree results every time. Give a\nsmallexamplethatprovesheiswrong.\nR-11.5 Dr.Amongusclaimsthattheorderinwhichafixedsetofentriesisinsertedinto\nanAVLtreedoesnotmatter\u2014thesameAVLtreeresultseverytime.Giveasmall\nexamplethatprovesheiswrong.\nR-11.6 Our implementationof the treeSearch utility, from Code Fragment11.3, relies\nonrecursion.Foralargeunbalancedtree,itispossiblethatJava\u2019scallstackwill\nreachitslimitduetotherecursivedepth. Giveanalternativeimplementationof\nthatmethodthatdoesnotrelyontheuseofrecursion.\nR-11.7 DoesthetrinoderestructuringinFigure11.11relyonasingleordoublerotation?\nWhatabouttherestructuringinFigure11.13?\nR-11.8 DrawtheAVLtreeresultingfromtheinsertionofanentrywithkey52intothe\nAVLtreeofFigure11.13b.\nR-11.9 DrawtheAVLtreeresultingfromtheremovaloftheentrywithkey62fromthe\nAVLtreeofFigure11.13b.\nR-11.10 Explainwhyperformingarotationinann-nodebinarytreewhenusingthearray-\nbasedrepresentationofSection8.3.2takes\u2126(n)time.\nR-11.11 ConsideradeletionoperationinanAVLtreethattriggersatrinoderestructuring\nforthecaseinwhichbothchildrenofthenodedenotedasyhaveequalheights.\nGiveaschematicfigure,inthestyleofFigure11.12,showingthetreebeforeand\nafterthedeletion. Whatistheneteffectoftheheightoftherebalancedsubtree\nduetotheoperation?\nR-11.12 Repeatthepreviousproblem,consideringthecaseinwhichy\u2019schildrenstartwith\ndifferentheights.\nR-11.13 The rules for a deletion in an AVL tree specifically require that when the two\nsubtreesofthenodedenotedasyhaveequalheight,childxshouldbechosentobe\n\u201caligned\u201dwithy(sothatxandyarebothleftchildrenorbothrightchildren).To\nbetterunderstandthisrequirement,repeatExerciseR-11.11assumingwepicked\nthemisalignedchoiceofx. WhymighttherebeaprobleminrestoringtheAVL\npropertywiththatchoice?\nwww.it-ebooks.info\n526 Chapter11. SearchTrees\nR-11.14 Whatdoesasplaytreelooklikeifitsentriesareaccessedinincreasingorderby\ntheirkeys?\nR-11.15 Performthefollowingsequenceofoperationsinaninitiallyemptysplaytreeand\ndrawthetreeaftereachsetofoperations.\na. Insertkeys0,2,4,6,8,10,12,14,16,18,inthisorder.\nb. Searchforkeys1,3,5,7,9,11,13,15,17,19,inthisorder.\nc. Deletekeys0,2,4,6,8,10,12,14,16,18,inthisorder.\nR-11.16 The splay tree does not have good performancefor the sorted map operations,\nbecause those methods lack calls to the rebalanceAccess hook. Reimplement\nTreeMaptoincludesuchcalls.\nR-11.17 IsthesearchtreeofFigure11.22(a)a(2,4)tree? Whyorwhynot?\nR-11.18 Analternativewayofperformingasplitatanodewina(2,4)treeistopartition\nwinto w\u2032 andw\u2032\u2032, with w\u2032 beinga 2-nodeandw\u2032\u2032 a 3-node. Whichofthe keys\nk ,k ,k ,ork dowestoreatw\u2019sparent?Why?\n1 2 3 4\nR-11.19 Dr.Amongusclaimsthata(2,4)treestoringasetofentrieswillalwayshavethe\nsame structure, regardlessof the order in which the entries are inserted. Show\nthatheiswrong.\nR-11.20 Drawfourdifferentred-blacktreesthatcorrespondtothesame(2,4)tree.\nR-11.21 ConsiderthesetofkeysK= 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 .\n{ }\na. Drawa(2,4)treestoringKasitskeysusingthefewestnumberofnodes.\nb. Drawa(2,4)treestoringKasitskeysusingthegreatestnumberofnodes.\nR-11.22 Consider the sequence of keys (5,16,22,45,2,10,18,30,50,12,1). Draw the\nresultofinsertingentrieswiththesekeys(inthegivenorder)into\na. Aninitiallyempty(2,4)tree.\nb. Aninitiallyemptyred-blacktree.\nR-11.23 For the following statements about red-black trees, provide a justification for\neachtruestatementandacounterexampleforeachfalseone.\na. Asubtreeofared-blacktreeisitselfared-blacktree.\nb. Thesiblingofanexternalnodeiseitherexternaloritisred.\nc. Thereisaunique(2,4)treeassociatedwithagivenred-blacktree.\nd. Thereisauniquered-blacktreeassociatedwithagiven(2,4)tree.\nR-11.24 ConsideratreeT storing100,000entries. Whatistheworst-caseheightofT in\nthefollowingcases?\na. T isabinarysearchtree.\nb. T isanAVLtree.\nc. T isasplaytree.\nd. T isa(2,4)tree.\ne. T isared-blacktree.\nR-11.25 Drawanexampleofared-blacktreethatisnotanAVLtree.\nR-11.26 GiveaproofofProposition11.9\nR-11.27 GiveaproofofProposition11.10\nwww.it-ebooks.info\n11.7. Exercises 527\nCreativity\nC-11.28 Explain whyyou would get the same outputin an inorderlisting of the entries\ninabinarysearchtree,T,independentofwhetherT ismaintainedtobeanAVL\ntree,splaytree,orred-blacktree.\nC-11.29 ExplainhowtouseanAVLtreeorared-blacktreetosortncomparableelements\ninO(nlogn)timeintheworstcase.\nC-11.30 Canwe useasplaytreetosortncomparableelementsinO(nlogn)timein the\nworstcase? Whyorwhynot?\nC-11.31 Implementa putIfAbsent method, as originally described in Exercise C-10.33,\nfortheTreeMapclass.\nC-11.32 Show that any n-node binary tree can be convertedto any other n-node binary\ntreeusingO(n)rotations.\nC-11.33 ForakeykthatisnotfoundinbinarysearchtreeT,provethatboththegreatest\nkeylessthankandtheleastkeygreaterthanklieonthepathtracedbythesearch\nfork.\nC-11.34 In Section 11.1.4we claim that the subMap methodof a binarysearch tree, as\nimplemented in Code Fragment 11.6, executes in O(s+h) time where s is the\nnumber of entries contained within the submap and h is the height of the tree.\nProvethisresult,byarguingaboutthemaximumnumberoftimestherecursive\nsubmethodcanbecalledonpositionsthatarenotincludedwithinthesubmap.\nC-11.35 ConsiderasortedmapthatisimplementedwithastandardbinarysearchtreeT.\nDescribe howto performan operationremoveSubMap(k , k ) thatremovesall\n1 2\ntheentrieswhosekeysfallwithinsubMap(k ,k ),inworst-casetimeO(s+h),\n1 2\nwheresisthenumberofentriesremovedandhistheheightofT.\nC-11.36 Repeat the previous problem using an AVL tree, achieving a running time of\nO(slogn). Whydoesn\u2019tthesolutiontothepreviousproblemtriviallyresultinan\nO(s+logn)algorithmforAVLtrees?\nC-11.37 SupposewewishtosupportanewmethodcountRange(k ,k )thatdetermines\n1 2\nhow many keys of a sorted map fall in the specified range. We could clearly\nimplement this in O(s+h) time by adapting our approach to subMap. De-\nscribe how to modifythe search-treestructureto supportO(h) worst-case time\nforcountRange.\nC-11.38 Ifthe approachdescribedin thepreviousproblemwereimplementedaspartof\ntheTreeMapclass,whatadditionalmodifications(ifany)wouldbenecessarytoa\nsubclasssuchasAVLTreeMapinordertomaintainsupportforthenewmethod?\nC-11.39 Draw a schematic of an AVL tree such that a single remove operation could\nrequire \u2126(logn) trinode restructurings (or rotations) from a leaf to the root in\nordertorestoretheheight-balanceproperty.\nC-11.40 ShowthatthenodesthatbecometemporarilyunbalancedinanAVLtreeduring\naninsertionmaybenonconsecutiveonthepathfromthenewlyinsertednodeto\ntheroot.\nwww.it-ebooks.info\n528 Chapter11. SearchTrees\nC-11.41 ShowthatatmostonenodeinanAVLtreebecomestemporarilyunbalancedafter\ntheimmediatedeletionofanodeaspartofthestandardremovemapoperation.\nC-11.42 InourAVLimplementation,eachnodestorestheheightofitssubtree,whichis\nanarbitrarilylargeinteger. ThespaceusageforanAVLtreecanbereducedby\ninsteadstoringthebalancefactorofanode,whichisdefinedastheheightofits\nleft subtree minus the heightof its right subtree. Thus, the balance factor of a\nnodeisalwaysequalto 1,0,or1,exceptduringaninsertionorremoval,when\n\u2212\nitmaybecometemporarilyequalto 2or+2. ReimplementtheAVLTreeMap\n\u2212\nclassstoringbalancefactorsratherthansubtreeheights.\nC-11.43 Ifwemaintainareferencetothepositionoftheleftmostnodeofabinarysearch\ntree, then operation firstEntry can be performed in O(1) time. Describe how\ntheimplementationoftheothermapmethodsneedtobemodifiedtomaintaina\nreferencetotheleftmostposition.\nC-11.44 Ifthe approachdescribedin thepreviousproblemwereimplementedaspartof\ntheTreeMapclass,whatadditionalmodifications(ifany)wouldbenecessaryto\nasubclasssuchasAVLTreeMapinordertoaccuratelymaintainthereferenceto\ntheleftmostposition?\nC-11.45 Describeamodificationtothebinarysearch-treedatastructurethatwouldsup-\nport the following two index-based operations for a sorted map in O(h) time,\nwherehistheheightofthetree.\natIndex(i): Returntheposition poftheentryatindexiofasortedmap.\nindexOf(p): Returntheindexioftheentryatposition pofasortedmap.\nC-11.46 Drawasplaytree,T ,togetherwiththesequenceofupdatesthatproducedit,and\n1\nared-blacktree,T ,onthesamesetoftenentries,suchthatapreordertraversal\n2\nofT wouldbethesameasapreordertraversalofT .\n1 2\nC-11.47 Let T andU be (2,4) trees storing n and m entries, respectively, such that all\ntheentriesinT havekeyslessthanthekeysofalltheentriesinU. Describean\nO(logn+logm)-time methodfor joining T andU into a single tree thatstores\nalltheentriesinT andU.\nC-11.48 LetT beared-blacktreestoringnentries,andletkbethekeyofanentryinT.\nShowhowtoconstructfromT,inO(logn)time,twored-blacktreesT\u2032 andT\u2032\u2032,\nsuchthatT\u2032containsallthekeysofT lessthank,andT\u2032\u2032containsallthekeysof\nT greaterthank. ThisoperationdestroysT.\nC-11.49 Provethatann-entrymultiwaysearchtreehasn+1externalnodes.\nC-11.50 The booleanindicatorused to marknodesin a red-blacktree as being\u201cred\u201dor\n\u201cblack\u201disnotstrictlyneededwhenwehavedistinctkeys. Describeaschemefor\nimplementingared-blacktreewithoutaddinganyextraspacetostandardbinary\nsearch-treenodes.\nC-11.51 ShowthatthenodesofanyAVLtreeT canbecolored\u201cred\u201dand\u201cblack\u201dsothat\nT becomesared-blacktree.\nwww.it-ebooks.info\n11.7. Exercises 529\nC-11.52 The standardsplaying step requirestwo passes, onedownwardpass to find the\nnode x to splay, followed by an upward pass to splay the node x. Describe a\nmethod for splaying and searching for x in one downward pass. Each substep\nnowrequiresthatyouconsiderthenexttwonodesinthepathdowntox,witha\npossiblezigsubstepperformedattheend. Describehowtoperformthezig-zig,\nzig-zag,andzigsteps.\nC-11.53 Consideravariationofsplaytrees,calledhalf-splaytrees,wheresplayinganode\natdepthd stopsassoonasthenodereachesdepth d/2 . Performanamortized\n\u230a \u230b\nanalysisofhalf-splaytrees.\nC-11.54 Describeasequenceofaccessestoann-nodesplaytreeT, wherenisodd,that\nresults in T consisting of a single chain of nodes such that the path down T\nalternatesbetweenleftchildrenandrightchildren.\nProjects\nP-11.55 Reimplement the TreeMap class using null references in place of explicit sen-\ntinelsfortheleavesofatree.\nP-11.56 Modify the TreeMap implementation to support location-aware entries. Pro-\nvide methods firstEntry(), lastEntry(), findEntry(k), before(e), after(e), and\nremove(e), with all but the last of these returning an Entry instance, and the\nlatterthreeacceptinganEntryeasaparameter.\nP-11.57 PerformanexperimentalstudytocomparethespeedofourAVLtree,splaytree,\nandred-blacktreeimplementationsforvarioussequencesofoperations.\nP-11.58 Redothepreviousexercise,includinganimplementationofskiplists. (SeeEx-\nerciseP-10.71.)\nP-11.59 ImplementtheSortedMapADTusinga(2,4)tree. (SeeSection10.3.)\nP-11.60 Write a Java class that can take anyred-blacktree andconvertit into its corre-\nsponding(2,4)treeandcantakeany(2,4)treeandconvertitintoitscorrespond-\ningred-blacktree.\nP-11.61 In describingmultisets andmultimapsin Section 10.5.3, we describe a general\napproach for adapting a traditional map by storing all duplicates within a sec-\nondary containeras a value in the map. Give an alternative implementationof\na multimapusinga binarysearchtreesuchthateachentryofthe mapisstored\nat a distinct node of the tree. With the existence of duplicates, we redefine the\nsearch-treepropertysothatallentriesintheleftsubtreeofapositionpwithkeyk\nhavekeysthatarelessthanorequaltok,whileallentriesintherightsubtreeof\nphavekeysthataregreaterthanorequaltok. Usethepublicinterfacegivenin\nSection10.5.3.\nP-11.62 Prepare an implementation of splay trees that uses top-down splaying as de-\nscribedinExerciseC-11.52.Performextensiveexperimentalstudiestocompare\nitsperformancetothestandardbottom-upsplayingimplementedinthischapter.\nwww.it-ebooks.info\n530 Chapter11. SearchTrees\nP-11.63 The mergeable heap ADT is an extension of the priority queue ADT consist-\ning of operations insert(k, v), min(), removeMin(), and merge(h), where the\nmerge(h)operationsperformsaunionofthemergeableheaphwiththepresent\none,incorporatingallentriesintothecurrentonewhileemptyingh. Describea\nconcreteimplementationofthemergeableheapADTthatachievesO(logn)per-\nformanceforallitsoperations,wherendenotesthesizeoftheresultingheapfor\nthemergeoperation.\nP-11.64 Writeaprogramthatperformsasimplen-bodysimulation,called\u201cJumpingLep-\nrechauns.\u201dThissimulationinvolvesnleprechauns,numbered1ton.Itmaintains\na gold valueg foreach leprechauni, which beginswith each leprechaunstart-\ni\ning out with a million dollars worth of gold, that is, g =1,000,000 for each\ni\ni=1,2,...,n. In addition, the simulation also maintains, for each leprechaun,\ni, a place on the horizon, which is represented as a double-precision floating-\npointnumber,x. Ineachiterationofthesimulation,thesimulationprocessesthe\ni\nleprechaunsin order. Processing a leprechaun i during this iteration begins by\ncomputinganewplaceonthehorizonfori,whichisdeterminedbytheassign-\nment\nx = x +rg,\ni i i\nwhererisarandomfloating-pointnumberbetween 1and1. Theleprechauni\n\u2212\nthenstealshalfthegoldfromthenearestleprechaunsoneitherside ofhimand\nadds this gold to his gold value, g. Write a programthat can performa series\ni\nofiterationsinthissimulationforagivennumber,n,ofleprechauns. Youmust\nmaintainthesetofhorizonpositionsusingasortedmapdatastructuredescribed\ninthischapter.\nChapter Notes\nSome of the data structures discussed in this chapter are extensively covered by Knuth\nin his Sorting and Searchingbook [61], and by Mehlhorn in [71]. AVL trees are due to\nAdel\u2019son-Vel\u2019skiiandLandis[2],whoinventedthisclassofbalancedsearchtreesin1962.\nBinarysearchtrees,AVLtrees,andhashingaredescribedinKnuth\u2019sSortingandSearch-\ning[61]book.Average-heightanalysesforbinarysearchtreescanbefoundinthebooksby\nAho,Hopcroft,andUllman[6]andCormen,Leiserson,RivestandStein[25]. Thehand-\nbookbyGonnetandBaeza-Yates[38]containsanumberoftheoreticalandexperimental\ncomparisonsamongmapimplementations. Aho, Hopcroft,andUllman[5]discuss(2,3)\ntrees,whicharesimilarto(2,4)trees. Red-blacktreesweredefinedbyBayer[10]. Vari-\nationsandinterestingpropertiesofred-blacktreesarepresentedinapaperbyGuibasand\nSedgewick[42]. Thereaderinterestedinlearningmoreaboutdifferentbalancedtreedata\nstructuresisreferredtothebooksbyMehlhorn[71]andTarjan[88],andthebookchapter\nbyMehlhornandTsakalidis[73]. Knuth[61]isexcellentadditionalreadingthatincludes\nearlyapproachestobalancingtrees. SplaytreeswereinventedbySleatorandTarjan[83]\n(seealso[88]).\nwww.it-ebooks.info\nChapter\n12\nSorting and Selection\nContents\n12.1 Merge-Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . 532\n12.1.1 Divide-and-Conquer . . . . . . . . . . . . . . . . . . . . . 532\n12.1.2 Array-Based Implementation of Merge-Sort . . . . . . . . 537\n12.1.3 The Running Time of Merge-Sort . . . . . . . . . . . . . 538\n\u22c6\n12.1.4 Merge-Sort and Recurrence Equations . . . . . . . . . . 540\n12.1.5 Alternative Implementations of Merge-Sort . . . . . . . . 541\n12.2 Quick-Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . 544\n12.2.1 Randomized Quick-Sort . . . . . . . . . . . . . . . . . . . 551\n12.2.2 Additional Optimizations for Quick-Sort . . . . . . . . . . 553\n12.3 Studying Sorting through an Algorithmic Lens . . . . . . . 556\n12.3.1 Lower Bound for Sorting . . . . . . . . . . . . . . . . . . 556\n12.3.2 Linear-Time Sorting: Bucket-Sort and Radix-Sort . . . . . 558\n12.4 Comparing Sorting Algorithms . . . . . . . . . . . . . . . . 561\n12.5 Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563\n12.5.1 Prune-and-Search . . . . . . . . . . . . . . . . . . . . . . 563\n12.5.2 Randomized Quick-Select . . . . . . . . . . . . . . . . . . 564\n12.5.3 Analyzing Randomized Quick-Select . . . . . . . . . . . . 565\n12.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 566\nwww.it-ebooks.info\n532 Chapter12. SortingandSelection\n12.1 Merge-Sort\nWe have introduced several sorting algorithms thus far, including insertion-sort\n(see Sections 3.1.2, 7.6, and 9.4.1); selection-sort (see Section 9.4.1); bubble-sort\n(see Exercise C-7.51); and heap-sort (see Section 9.4.2). In this chapter, we will\npresent four other sorting algorithms, called merge-sort, quick-sort, bucket-sort,\nand radix-sort, and then discuss the advantages and disadvantages of the various\nalgorithms inSection12.4.\n12.1.1 Divide-and-Conquer\nThefirsttwoalgorithmswedescribeinthischapter,merge-sortandquick-sort, use\nrecursion in an algorithmic design pattern called divide-and-conquer. We have\nalready seen thepower ofrecursion in describing algorithms inanelegant manner\n(see Chapter 5). The divide-and-conquer pattern consists of the following three\nsteps:\n1. Divide: If the input size is smaller than a certain threshold (say, one or two\nelements), solve the problem directly using a straightforward method and\nreturn the solution so obtained. Otherwise, divide the input data into twoor\nmoredisjointsubsets.\n2. Conquer: Recursivelysolvethesubproblems associated withthesubsets.\n3. Combine: Takethe solutions to the subproblems and merge them into a so-\nlutiontotheoriginal problem.\nUsing Divide-and-Conquer for Sorting\nWe first describe the merge-sort algorithm at a high level, without focusing on\nwhether the data is anarray or linked list. (We willsoon give concrete implemen-\ntations foreach.) Tosort asequence S withnelements using thethree divide-and-\nconquer steps,themerge-sort algorithm proceeds asfollows:\n1. Divide: If S has zero or one element, return S immediately; it is already\nsorted. Otherwise (S has at least two elements), remove all the elements\nfrom S and put them into two sequences, S and S , each containing about\n1 2\nhalf of the elements of S; that is, S contains the first n/2 elements of S,\n1\n\u230a \u230b\nandS contains theremaining n/2 elements.\n2\n\u2308 \u2309\n2. Conquer: Recursivelysortsequences S andS .\n1 2\n3. Combine: Put the elements back into S by merging the sorted sequences S\n1\nandS intoasortedsequence.\n2\nInreference tothedividestep,werecallthatthenotation x indicates thefloorof\n\u230a \u230b\nx,thatis,thelargest integerk,suchthatk x. Similarly,thenotation x indicates\n\u2264 \u2308 \u2309\ntheceilingofx,thatis,thesmallestintegerm,suchthatx m.\n\u2264\nwww.it-ebooks.info\n12.1. Merge-Sort 533\nWecanvisualizeanexecutionofthemerge-sortalgorithmbymeansofabinary\ntreeT,calledthemerge-sorttree. EachnodeofT representsarecursiveinvocation\n(or call) of the merge-sort algorithm. We associate with each node v of T the\nsequence S that is processed by the invocation associated with v. The children of\nnodevareassociated withtherecursive callsthatprocess thesubsequences S and\n1\nS of S. The external nodes of T are associated with individual elements of S,\n2\ncorresponding toinstances ofthealgorithm thatmakenorecursive calls.\nFigure 12.1 summarizes an execution of the merge-sort algorithm by showing\ntheinput and output sequences processed ateachnode ofthe merge-sort tree. The\nstep-by-stepevolutionofthemerge-sorttreeisshowninFigures12.2through12.4.\nThis algorithm visualization in terms of the merge-sort tree helps us analyze\nthe running time of the merge-sort algorithm. In particular, since the size of the\ninput sequence roughly halves at each recursive call of merge-sort, the height of\nthemerge-sort treeisaboutlogn(recallthatthebaseoflogis2ifomitted).\n85 24 63 45 17 31 96 50\n85 24 63 45 17 31 96 50\n85 24 63 45 17 31 96 50\n85 24 63 45 17 31 96 50\n(a)\n17 24 31 45 50 63 85 96\n24 45 63 85 17 31 50 96\n24 85 45 63 17 31 50 96\n85 24 63 45 17 31 96 50\n(b)\nFigure 12.1: Merge-sort tree T for an execution of the merge-sort algorithm on\na sequence with 8 elements: (a) input sequences processed at each node of T;\n(b)outputsequences generated ateachnodeofT.\nwww.it-ebooks.info\n534 Chapter12. SortingandSelection\n85 24 63 45 17 31 96 50 17 31 96 50\n85 24 63 45\n(a) (b)\n17 31 96 50 17 31 96 50\n63 45 63 45\n85 24 24\n85\n(c) (d)\n17 31 96 50 17 31 96 50\n63 45 63 45\n85 24 85\n24\n(e) (f)\nFigure 12.2: Visualization of an execution of merge-sort. Each node of the tree\nrepresentsarecursivecallofmerge-sort. Thenodesdrawnwithdashedlinesrepre-\nsentcallsthathavenotbeenmadeyet. Thenodedrawnwiththicklinesrepresents\nthecurrent call. Theempty nodes drawnwiththinlines represent completed calls.\nTheremainingnodes(drawnwiththinlinesandnotempty)represent callsthatare\nwaitingforachildcalltoreturn. (Continues inFigure12.3.)\nwww.it-ebooks.info\n12.1. Merge-Sort 535\n17 31 96 50 17 31 96 50\n24 85 63 45 24 85\n63 45\n(g) (h)\n17 31 96 50 17 31 96 50\n24 85 24 85\n45 63\n63 45\n(i) (j)\n17 31 96 50 17 31 96 50\n24 85 24 45 63 85\n45 63\n(k) (l)\nFigure 12.3: Visualization of an execution of merge-sort. (Combined with Fig-\nures12.2and12.4.)\nwww.it-ebooks.info\n536 Chapter12. SortingandSelection\n24 45 63 85 24 45 63 85\n17 31 96 50 17 31 50 96\n(m) (n)\n24 45 63 85 17 31 50 96 17 24 31 45 50 63 85 96\n(o) (p)\nFigure 12.4: Visualization of an execution of merge-sort (continued from Fig-\nure 12.3). Several calls are omitted between (m) and (n). Note the merging of\ntwohalvesperformedinstep(p).\nProposition 12.1: Themerge-sorttreeassociatedwithanexecutionofmerge-\nsortonasequenceofsizenhasheight logn .\n\u2308 \u2309\nWeleavethejustificationofProposition12.1asasimpleexercise(R-12.1). We\nwillusethisproposition toanalyzetherunningtimeofthemerge-sort algorithm.\nHaving given an overview of merge-sort and an illustration of how it works,\nlet us consider each of the steps of this divide-and-conquer algorithm in more de-\ntail. Dividing asequence of sizeninvolves separating itatthe element withindex\nn/2 , andrecursive callscanbestartedbypassing thesesmallersequences aspa-\n\u2308 \u2309\nrameters. The difficult step is combining the two sorted sequences into a single\nsorted sequence. Thus, before we present our analysis of merge-sort, we need to\nsaymoreabouthowthisisdone.\nwww.it-ebooks.info\n12.1. Merge-Sort 537\n12.1.2 Array-Based Implementation of Merge-Sort\nWebeginbyfocusing onthecasewhenasequence ofitemsisrepresented withan\narray. The merge method (Code Fragment 12.1) is responsible for the subtask of\nmergingtwopreviouslysortedsequences, S andS ,withtheoutputcopiedintoS.\n1 2\nWecopyoneelementduringeachpassofthewhileloop,conditionallydetermining\nwhether the next element should be taken from S or S . The divide-and-conquer\n1 2\nmerge-sort algorithm isgiveninCodeFragment12.2.\nWe illustrate a step of the merge process in Figure 12.5. During the process,\nindex i represents the number of elements of S that have been copied to S, while\n1\nindex jrepresentsthenumberofelementsofS thathavebeencopiedtoS. Assum-\n2\ning S and S both have atleast one uncopied element, wecopy the smaller of the\n1 2\ntwo elements being considered. Since i+ j objects have been previously copied,\nthe next element is placed in S[i+ j]. (For example, when i+ j is 0, the next ele-\nmentiscopiedtoS[0]). Ifwereachtheendofoneofthesequences, wemustcopy\nthenextelementfromtheother.\n1 /\u2217\u2217 Merge contents of arrays S1 and S2 into properly sized array S. \u2217/\n2 public static <K> void merge(K[ ] S1, K[ ] S2, K[ ] S, Comparator<K> comp)\n{\n3 int i = 0, j = 0;\n4 while (i + j < S.length)\n{\n5 if (j == S2.length (i < S1.length && comp.compare(S1[i], S2[j]) < 0))\n||\n6 S[i+j] = S1[i++]; // copy ith element of S1 and increment i\n7 else\n8 S[i+j] = S2[j++]; // copy jth element of S2 and increment j\n9\n}\n10\n}\nCodeFragment12.1: Animplementation ofthemergeoperation foraJavaarray.\n0 1 2 3 4 5 6 0 1 2 3 4 5 6\nS 1 2 5 8 11 12 14 15 S 1 2 5 8 11 12 14 15\ni i\n0 1 2 3 4 5 6 0 1 2 3 4 5 6\nS 2 3 9 10 18 19 22 25 S 2 3 9 10 18 19 22 25\nj j\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 0 1 2 3 4 5 6 7 8 9 10 11 12 13\nS 2 3 5 8 9 S 2 3 5 8 9 10\ni+j i+j\n(a) (b)\nFigure12.5: A step in the merge of two sorted arrays for which S [j]<S [i]. We\n2 1\nshowthearraysbeforethecopystepin(a)andafteritin(b).\nwww.it-ebooks.info\n538 Chapter12. SortingandSelection\n1 /\u2217\u2217 Merge-sort contents of array S. \u2217/\n2 public static <K> void mergeSort(K[ ] S, Comparator<K> comp)\n{\n3 int n = S.length;\n4 if (n < 2) return; // array is trivially sorted\n5 // divide\n6 int mid = n/2;\n7 K[ ] S1 = Arrays.copyOfRange(S, 0, mid); // copy of first half\n8 K[ ] S2 = Arrays.copyOfRange(S, mid, n); // copy of second half\n9 // conquer (with recursion)\n10 mergeSort(S1, comp); // sort copy of first half\n11 mergeSort(S2, comp); // sort copy of second half\n12 // merge results\n13 merge(S1, S2, S, comp); // merge sorted halves back into original\n14\n}\nCodeFragment12.2: Animplementation oftherecursive merge-sort algorithm for\naJavaarray(usingthemergemethoddefinedinCodeFragment12.1).\nWe note that methods merge and mergeSort rely on use of a Comparator in-\nstance to compare a pair of generic objects that are presumed to belong to a total\norder. This is the same approach we introduced when defining priority queues in\nSection9.2.2,andwhenstudyingimplementingsortedmapsinChapters10and11.\n12.1.3 The Running Time of Merge-Sort\nWe begin by analyzing the running time of the merge algorithm. Let n and n\n1 2\nbethenumberofelements ofS andS ,respectively. Itisclearthattheoperations\n1 2\nperformedinsideeachpassofthewhilelooptakeO(1)time. Thekeyobservationis\nthatduringeachiterationoftheloop,oneelementiscopiedfromeitherS orS into\n1 2\nS (and that element is considered no further). Therefore, the number of iterations\noftheloopisn +n . Thus,therunningtimeofalgorithm mergeisO(n +n ).\n1 2 1 2\nHaving analyzed the running time of the merge algorithm used to combine\nsubproblems, let us analyze the running time of the entire merge-sort algorithm,\nassumingitisgivenaninputsequenceofnelements. Forsimplicity,werestrictour\nattention tothecasewherenisapowerof2. Weleaveittoanexercise(R-12.3)to\nshowthattheresultofouranalysis alsoholdswhennisnotapowerof2.\nWhen evaluating the merge-sort recursion, we rely on the analysis technique\nintroduced in Section 5.2. We account for the amount of time spent within each\nrecursive call, but excluding any time spent waiting for successive recursive calls\nto terminate. In the case of our mergeSort method, we account for the time to\ndivide the sequence into two subsequences, and the call to merge to combine the\ntwosortedsequences, butweexcludethetworecursivecallstomergeSort.\nwww.it-ebooks.info\n12.1. Merge-Sort 539\nA merge-sort tree T, as portrayed in Figures 12.2 through 12.4, can guide our\nanalysis. Considerarecursivecallassociatedwithanodevofthemerge-sorttreeT.\nThe divide step at node v is straightforward; this step runs in time proportional to\nthesizeofthesequenceforv,basedontheuseofslicingtocreatecopiesofthetwo\nlist halves. Wehave already observed that the merging step also takes time that is\nlinear in the size of the merged sequence. If we let i denote the depth of node v,\nthe time spent at node v is O(n/2i), since the size of the sequence handled by the\nrecursivecallassociated withvisequalton/2i.\nLookingatthetreeT moreglobally,asshowninFigure12.6,weseethat,given\nour definition of\u201ctime spent at anode,\u201d the running timeof merge-sort isequal to\nthesumofthetimesspentatthenodesofT. ObservethatT hasexactly2i nodesat\ndepth i. This simple observation has an important consequence, for it implies that\ntheoveralltimespentatallthenodesofT atdepthiisO(2i n/2i),whichisO(n).\n\u00b7\nByProposition 12.1, the height of T is logn . Thus, since the time spent at each\n\u2308 \u2309\nofthe logn +1levelsofT isO(n),wehavethefollowingresult:\n\u2308 \u2309\nProposition 12.2: Algorithmmerge-sortsortsasequenceSofsizeninO(nlogn)\ntime,assumingtwoelementsofScanbecomparedinO(1)time.\nHeight Timeperlevel\nn O(n)\nn/2 n/2 O(n)\nO(logn)\nn/4 n/4 n/4 n/4 O(n)\nTotaltime: O(nlogn)\nFigure12.6: A visual analysis of the running time of merge-sort. Each node rep-\nresents the time spent in a particular recursive call, labeled with the size of its\nsubproblem.\nwww.it-ebooks.info\n540 Chapter12. SortingandSelection\n12.1.4 Merge-Sort and Recurrence Equations \u22c6\nThereisanotherwaytojustifythattherunningtimeofthemerge-sortalgorithm is\nO(nlogn)(Proposition12.2). Namely,wecandealmoredirectlywiththerecursive\nnatureofthemerge-sortalgorithm. Inthissection,wewillpresentsuchananalysis\nof the running time of merge-sort, and in so doing, introduce the mathematical\nconceptofarecurrenceequation(alsoknownasrecurrencerelation).\nLet the function t(n) denote the worst-case running time of merge-sort on an\ninput sequence of size n. Since merge-sort is recursive, we can characterize func-\ntiont(n)by meansofanequation wherethe functiont(n)isrecursively expressed\nin terms of itself. In order to simplify our characterization of t(n), let us restrict\nourattentiontothecasewhennisapowerof2. (Weleavetheproblemofshowing\nthat our asymptotic characterization still holds in the general case as an exercise.)\nInthiscase,wecanspecifythedefinitionoft(n)as\nb ifn 1\nt(n) = \u2264\n2t(n/2)+cn otherwise.\n(cid:26)\nAn expression such as the one above is called a recurrence equation, since the\nfunction appears onboththeleft-andright-hand sidesoftheequalsign. Although\nsuch a characterization is correct and accurate, what we really desire is a big-Oh\ntype of characterization oft(n) that does not involve the function t(n) itself. That\nis,wewantaclosed-form characterization oft(n).\nWecanobtainaclosed-formsolutionbyapplyingthedefinitionofarecurrence\nequation, assuming n is relatively large. For example, after one more application\noftheequation above,wecanwriteanewrecurrence fort(n)as\nt(n) = 2(2t(n/22)+(cn/2))+cn\n= 22t(n/22)+2(cn/2)+cn = 22t(n/22)+2cn.\nIf we apply the equation again, we get t(n)=23t(n/23)+3cn. At this point, we\nshouldseeapatternemerging, sothatafterapplying thisequation itimes,weget\nt(n) = 2it(n/2i)+icn.\nTheissuethatremains,then,istodeterminewhentostopthisprocess. Toseewhen\nto stop, recall that we switch to the closed form t(n)=b when n 1, which will\n\u2264\noccur when 2i =n. In other words, this will occur when i= logn. Making this\nsubstitution, then,yields\nt(n) = 2lognt(n/2logn)+(logn)cn\n= nt(1)+cnlogn\n= nb+cnlogn.\nThatis,wegetanalternativejustification ofthefactthatt(n)isO(nlogn).\nwww.it-ebooks.info\n12.1. Merge-Sort 541\n12.1.5 Alternative Implementations of Merge-Sort\nSorting Linked Lists\nThe merge-sort algorithm can easily be adapted to use any form of a basic queue\nasitscontainer type. InCodeFragment12.3, weprovide such animplementation,\nbased on use of the LinkedQueue class from Section 6.2.3. The O(nlogn) bound\nfor merge-sort from Proposition 12.2 applies to this implementation aswell, since\neach basic operation runs in O(1) time when implemented with a linked list. We\nshowanexampleexecution ofthisversionofthemergealgorithm inFigure12.7.\n1 /\u2217\u2217 Merge contents of sorted queues S1 and S2 into empty queue S. \u2217/\n2 public static <K> void merge(Queue<K> S1, Queue<K> S2, Queue<K> S,\n3 Comparator<K> comp)\n{\n4 while (!S1.isEmpty() && !S2.isEmpty())\n{\n5 if (comp.compare(S1.first(), S2.first()) < 0)\n6 S.enqueue(S1.dequeue()); // take next element from S1\n7 else\n8 S.enqueue(S2.dequeue()); // take next element from S2\n9\n}\n10 while (!S1.isEmpty())\n11 S.enqueue(S1.dequeue()); // move any elements that remain in S1\n12 while (!S2.isEmpty())\n13 S.enqueue(S2.dequeue()); // move any elements that remain in S2\n14\n}\n15\n16 /\u2217\u2217 Merge-sort contents of queue. \u2217/\n17 public static <K> void mergeSort(Queue<K> S, Comparator<K> comp)\n{\n18 int n = S.size();\n19 if (n < 2) return; // queue is trivially sorted\n20 // divide\n21 Queue<K> S1 = new LinkedQueue<>(); // (or any queue implementation)\n22 Queue<K> S2 = new LinkedQueue<>();\n23 while (S1.size() < n/2)\n24 S1.enqueue(S.dequeue()); // move the first n/2 elements to S1\n25 while (!S.isEmpty())\n26 S2.enqueue(S.dequeue()); // move remaining elements to S2\n27 // conquer (with recursion)\n28 mergeSort(S1, comp); // sort first half\n29 mergeSort(S2, comp); // sort second half\n30 // merge results\n31 merge(S1, S2, S, comp); // merge sorted halves back into original\n32\n}\nCodeFragment12.3: Animplementation ofmerge-sort usingabasicqueue.\nwww.it-ebooks.info\n542 Chapter12. SortingandSelection\nS1 24 45 63 85 S1 24 45 63 85\nS2 17 31 50 96 S2 31 50 96\nS S 17\n(a) (b)\nS1 45 63 85 S1 45 63 85\nS2 31 50 96 S2 50 96\nS 17 24 S 17 24 31\n(c) (d)\nS1 63 85 S1 63 85\nS2 50 96 S2 96\nS 17 24 31 45 S 17 24 31 45 50\n(e) (f)\nS1 85\nS1\nS2 96\nS2 96\nS 17 24 31 45 50 63 85\nS 17 24 31 45 50 63\n(g) (h)\nS1\nS2\nS 17 24 31 45 50 63 85 96\n(i)\nFigure12.7: Example of an execution of the merge algorithm, as implemented in\nCodeFragment12.3usingqueues.\nwww.it-ebooks.info\n12.1. Merge-Sort 543\nA Bottom-Up (Nonrecursive) Merge-Sort\nThereisanonrecursiveversionofarray-basedmerge-sort,whichrunsinO(nlogn)\ntime. It is a bit faster than recursive merge-sort in practice, as it avoids the extra\noverheads of recursive calls and temporary memory at each level. The main idea\nistoperformmerge-sortbottom-up, performingthemergeslevelbylevelgoingup\nthe merge-sort tree. Given an input array of elements, we begin by merging every\nsuccessivepairofelementsintosortedrunsoflengthtwo. Wemergetheserunsinto\nrunsoflengthfour,mergethesenewrunsintorunsoflengtheight,andsoon,until\nthe array is sorted. To keep the space usage reasonable, wedeploy a second array\nthatstoresthemergedruns(swapping inputandoutputarraysaftereachiteration).\nWe give a Java implementation in Code Fragment 12.4, using the built-in method\nSystem.arraycopytocopyarangeofcellsbetweentwoarrays. Asimilarbottom-up\napproach canbeusedforsorting linkedlists. (SeeExerciseC-12.30.)\n1 /\u2217\u2217 Merges in[start..start+inc 1] and in[start+inc..start+2\u2217inc 1] into out. \u2217/\n\u2212 \u2212\n2 public static <K> void merge(K[ ] in, K[ ] out, Comparator<K> comp,\n3 int start, int inc)\n{\n4 int end1 = Math.min(start + inc, in.length); // boundary for run 1\n5 int end2 = Math.min(start + 2 \u2217 inc, in.length); // boundary for run 2\n6 int x=start; // index into run 1\n7 int y=start+inc; // index into run 2\n8 int z=start; // index into output\n9 while (x < end1 && y < end2)\n10 if (comp.compare(in[x], in[y]) < 0)\n11 out[z++] = in[x++]; // take next from run 1\n12 else\n13 out[z++] = in[y++]; // take next from run 2\n14 if (x < end1) System.arraycopy(in, x, out, z, end1 x); // copy rest of run 1\n\u2212\n15 else if (y < end2) System.arraycopy(in, y, out, z, end2 y);// copy rest of run 2\n\u2212\n16\n17 } /\u2217\u2217 Merge-sort contents of data array. \u2217/\n18 public static <K> void mergeSortBottomUp(K[ ] orig, Comparator<K> comp)\n{\n19 int n = orig.length;\n20 K[ ] src = orig; // alias for the original\n21 K[ ] dest = (K[ ]) new Object[n]; // make a new temporary array\n22 K[ ] temp; // reference used only for swapping\n23 for (int i=1; i < n; i \u2217= 2) // each iteration sorts all runs of length i\n24 for (int j=0; j < n; j += { 2\u2217i) // each pass merges two runs of length i\n25 merge(src, dest, comp, j, i);\n26 temp = src; src = dest; dest = temp; // reverse roles of the arrays\n27\n}\n28 if (orig != src)\n29 System.arraycopy(src, 0, orig, 0, n); // additional copy to get result to original\n30\n}\nCodeFragment12.4: Animplementationofthenonrecursivemerge-sortalgorithm.\nwww.it-ebooks.info\n544 Chapter12. SortingandSelection\n12.2 Quick-Sort\nThe next sorting algorithm we discuss is called quick-sort. Like merge-sort, this\nalgorithm is also based onthe divide-and-conquer paradigm, but ituses this tech-\nnique in a somewhat opposite manner, as all the hard work is done before the\nrecursivecalls.\nHigh-Level Description of Quick-Sort\nThe quick-sort algorithm sorts a sequence S using a simple recursive approach.\nThe main idea is to apply the divide-and-conquer technique, whereby we divide\nS into subsequences, recur to sort each subsequence, and then combine the sorted\nsubsequences by a simple concatenation. In particular, the quick-sort algorithm\nconsists ofthefollowingthreesteps(seeFigure12.8):\n1. Divide: If S has at least two elements (nothing needs to be done if S has\nzero or one element), select a specific element x from S, which is called the\npivot. Asiscommonpractice, choose thepivot xtobethelastelement inS.\nRemovealltheelementsfromSandputthemintothreesequences:\nL,storingtheelementsinSlessthanx\n\u2022\nE,storingtheelementsinSequaltox\n\u2022\nG,storing theelementsinSgreaterthanx\n\u2022\nOfcourse, ifthe elements ofS are distinct, then E holds just one element\u2014\nthepivotitself.\n2. Conquer: Recursivelysortsequences LandG.\n3. Combine: PutbacktheelementsintoSinorderbyfirstinsertingtheelements\nofL,thenthoseofE,andfinallythoseofG.\n1.Splitusingpivotx\nE(=x)\n2.Recur 2.Recur\nL(<x) G(>x)\n3.Concatenate\nFigure12.8: Avisualschematicofthequick-sort algorithm.\nwww.it-ebooks.info\n12.2. Quick-Sort 545\nLikemerge-sort,theexecutionofquick-sortcanbevisualizedbymeansofabi-\nnaryrecursiontree,calledthequick-sorttree. Figure12.9summarizesanexecution\nofthequick-sortalgorithmbyshowingtheinputandoutputsequencesprocessedat\neach node of the quick-sort tree. The step-by-step evolution of the quick-sort tree\nisshowninFigures12.10,12.11,and12.12.\nUnlike merge-sort, however, the height of the quick-sort tree associated with\nan execution of quick-sort is linear in the worst case. This happens, for example,\nifthesequence consists ofndistinct elementsandisalreadysorted. Indeed, inthis\ncase,thestandardchoiceofthelastelementaspivotyieldsasubsequenceLofsize\nn 1, while subsequence E has size 1 and subsequence Ghas size 0. Ateach call\n\u2212\nof quick-sort on subsequence L, the size decreases by 1. Hence, the height of the\nquick-sort treeisn 1.\n\u2212\n85 24 63 45 17 31 96 50\n24 45 17 31 85 63 96\n24 17 45 85 63\n24 85\n(a)\n17 24 31 45 50 63 85 96\n17 24 31 45 63 85 96\n17 24 45 63 85\n24 85\n(b)\nFigure12.9: Quick-sorttreeT foranexecutionofthequick-sort algorithm onase-\nquencewith8elements: (a)inputsequencesprocessedateachnodeofT;(b)output\nsequencesgeneratedateachnodeofT. Thepivotusedateachleveloftherecursion\nisshowninbold.\nwww.it-ebooks.info\n546 Chapter12. SortingandSelection\n85 24 63 45 17 31 96 50 24 45 17 31 50 85 63 96\n(a) (b)\n50 85 63 96 50 85 63 96\n24 45 17 31 24 17 31 45\n(c) (d)\n50 85 63 96 50 85 63 96\n31 45 31 45\n24 17 17 24\n(e) (f)\nFigure 12.10: Visualization of quick-sort. Each node of the tree represents a re-\ncursive call. Thenodes drawn withdashed lines represent calls that have notbeen\nmadeyet. Thenode drawnwiththick linesrepresents therunning call. Theempty\nnodesdrawnwiththinlinesrepresentterminatedcalls. Theremainingnodesrepre-\nsentsuspended calls(that is, activecallsthat arewaitingforachild calltoreturn).\nNotethedividestepsperformedin(b),(d),and(f). (Continues inFigure12.11.)\nwww.it-ebooks.info\n12.2. Quick-Sort 547\n50 85 63 96 50 85 63 96\n31 45 31 45\n17 24 17 24\n(g) (h)\n50 85 63 96 50 85 63 96\n31 45 31 45\n17 17 24\n24\n(i) (j)\n50 85 63 96 50 85 63 96\n31 45 17 24 31 45\n17 24\n(k) (l)\nFigure12.11: Visualization of an execution of quick-sort. Note the concatenation\nstepperformed in(k). (Continues inFigure12.12.)\nwww.it-ebooks.info\n548 Chapter12. SortingandSelection\n50 85 63 96 50 85 63 96\n17 24 31 17 24 31 45\n45\n(m) (n)\n50 85 63 96 17 24 31 45 50 85 63 96\n17 24 31 45\n(o) (p)\n17 24 31 45 50 63 85 96 17 24 31 45 50 63 85 96\n(q) (r)\nFigure12.12: Visualizationofanexecutionofquick-sort. Severalcallsbetween(p)\nand (q) have been omitted. Note the concatenation steps performed in (o) and (r).\n(Continued fromFigure12.11.)\nwww.it-ebooks.info\n12.2. Quick-Sort 549\nPerforming Quick-Sort on General Sequences\nIn Code Fragment 12.5, we give an implementation of the quick-sort algorithm\nthat works on any sequence type that operates as a queue. This particular version\nreliesontheLinkedQueueclassfromSection6.2.3;weprovideamorestreamlined\nimplementation ofquick-sort usinganarray-based sequence inSection12.2.2.\nOur implementation chooses the first item of the queue as the pivot (since it\nis easily accessible), and then it divides sequence S into queues L, E, and G of\nelements that are respectively less than, equal to, and greater than the pivot. We\nthen recur on the L and G lists, and transfer elements from the sorted lists L, E,\nand G back to S. All of the queue operations run in O(1) worst-case time when\nimplementedwithalinkedlist.\n1 /\u2217\u2217 Quick-sort contents of a queue. \u2217/\n2 public static <K> void quickSort(Queue<K> S, Comparator<K> comp)\n{\n3 int n = S.size();\n4 if (n < 2) return; // queue is trivially sorted\n5 // divide\n6 K pivot = S.first(); // using first as arbitrary pivot\n7 Queue<K> L = new LinkedQueue<>();\n8 Queue<K> E = new LinkedQueue<>();\n9 Queue<K> G = new LinkedQueue<>();\n10 while (!S.isEmpty()) // divide original into L, E, and G\n{\n11 K element = S.dequeue();\n12 int c = comp.compare(element, pivot);\n13 if (c < 0) // element is less than pivot\n14 L.enqueue(element);\n15 else if (c == 0) // element is equal to pivot\n16 E.enqueue(element);\n17 else // element is greater than pivot\n18 G.enqueue(element);\n19\n}\n20 // conquer\n21 quickSort(L, comp); // sort elements less than pivot\n22 quickSort(G, comp); // sort elements greater than pivot\n23 // concatenate results\n24 while (!L.isEmpty())\n25 S.enqueue(L.dequeue());\n26 while (!E.isEmpty())\n27 S.enqueue(E.dequeue());\n28 while (!G.isEmpty())\n29 S.enqueue(G.dequeue());\n30\n}\nCodeFragment12.5: Quick-sort forasequence Simplemented asaqueue.\nwww.it-ebooks.info\n550 Chapter12. SortingandSelection\nRunning Time of Quick-Sort\nWe can analyze the running time of quick-sort with the same technique used for\nmerge-sort inSection 12.1.3. Namely, wecanidentify thetimespent ateachnode\nofthequick-sort treeT andsumuptherunning timesforallthenodes.\nExamining Code Fragment 12.5, wesee that the divide step and the final con-\ncatenation of quick-sort can be implemented in linear time. Thus, the time spent\nat a node v of T is proportional to the input size s(v) of v, defined as the size of\nthe sequence handled by the call of quick-sort associated with node v. Since sub-\nsequence E has at least one element (the pivot), the sum of the input sizes of the\nchildren ofvisatmosts(v) 1.\n\u2212\nLet s denote the sum of the input sizes of the nodes at depth i for a particular\ni\nquick-sort treeT. Clearly,s =n,sincetherootrofT isassociated withtheentire\n0\nsequence. Also, s n 1, since the pivot is not propagated to the children of r.\n1\n\u2264 \u2212\nMoregenerally, itmustbethats <s since theelements ofthesubsequences at\ni i\u22121\ndepthiallcomefromdistinctsubsequences atdepthi 1,andatleastoneelement\n\u2212\nfrom depth i 1 does not propagate to depth ibecause itis in aset E (in fact, one\n\u2212\nelementfromeachnodeatdepthi 1doesnotpropagate todepthi).\n\u2212\nWecan therefore bound the overall running time ofanexecution ofquick-sort\nasO(n h)wherehistheoverall height ofthequick-sort treeT forthat execution.\n\u00b7\nUnfortunately,intheworstcase,theheightofaquick-sorttreeisn 1,asobserved\n\u2212\nin Section 12.2. Thus, quick-sort runs in O(n2) worst-case time. Paradoxically,\nif we choose the pivot as the last element of the sequence, this worst-case behav-\nior occurs for problem instances when sorting should be easy\u2014if the sequence is\nalreadysorted.\nGiven its name, we would expect quick-sort to run quickly, and it often does\nin practice. The best case for quick-sort on a sequence of distinct elements oc-\ncurs when subsequences L and G have roughly the same size. In that case, as\nwesawwithmerge-sort, thetree hasheight O(logn)and therefore quick-sort runs\nin O(nlogn) time; we leave the justification of this fact as an exercise (R-12.12).\nMore so, we can observe an O(nlogn) running time even if the split between L\nand G isnot as perfect. Forexample, ifevery divide step caused one subsequence\nto have one-fourth of those elements and the other to have three-fourths of the\nelements, theheight ofthetreewould remainO(logn)andthus theoverallperfor-\nmanceO(nlogn).\nWewillseeinthe nextsection that introducing randomization inthechoice of\na pivot will makes quick-sort essentially behave in this way on average, with an\nexpectedrunning timethatisO(nlogn).\nwww.it-ebooks.info\n12.2. Quick-Sort 551\n12.2.1 Randomized Quick-Sort\nOne common method for analyzing quick-sort is to assume that the pivot will al-\nwaysdividethesequence inareasonably balancedmanner. However,wefeelsuch\nanassumptionwouldpresupposeknowledgeabouttheinputdistributionthatistyp-\nically not available. Forexample, wewould have to assume that wewillrarely be\ngiven \u201calmost\u201d sorted sequences to sort, which are actually common in many ap-\nplications. Fortunately, this assumption is not needed in order for us to match our\nintuition toquick-sort\u2019s behavior.\nIn general, we desire some way of getting close to the best-case running time\nforquick-sort. Thewaytogetclosetothebest-case running time,ofcourse, isfor\nthe pivot to divide the input sequence S almost equally. If this outcome were to\noccur, then it would result in arunning time that isasymptotically the sameas the\nbest-case running time. That is, having pivots close to the \u201cmiddle\u201d of the set of\nelementsleadstoanO(nlogn)runningtimeforquick-sort.\nPicking Pivots at Random\nSincethegoalofthepartitionstepofthequick-sortmethodistodividethesequence\nSwithsufficientbalance,letusintroducerandomizationintothealgorithmandpick\nas the pivot a random element of the input sequence. That is, instead of picking\nthepivot asthefirstorlastelementofS,wepick anelement ofSatrandom asthe\npivot, keeping the rest of the algorithm unchanged. This variation of quick-sort is\ncalled randomized quick-sort. The following proposition shows that the expected\nrunningtimeofrandomizedquick-sortonasequencewithnelementsisO(nlogn).\nThisexpectationistakenoverallthepossiblerandomchoicesthealgorithmmakes,\nand is independent of any assumptions about the distribution of the possible input\nsequences thealgorithm islikelytobegiven.\nProposition 12.3: Theexpectedrunningtimeofrandomizedquick-sortonase-\nquenceSofsizenisO(nlogn).\nJustification: LetS be a sequence with n elements and let T be the binary tree\nassociated withanexecution ofrandomized quick-sort onS. First,weobserve that\ntherunningtimeofthealgorithmisproportionaltothenumberofcomparisonsper-\nformed. WeconsidertherecursivecallassociatedwithanodeofT andobservethat\nduringthecall,allcomparisonsarebetweenthepivotelementandanotherelement\noftheinputofthecall. Thus,wecanevaluatethetotalnumberofcomparisonsper-\nformed by the algorithm as \u2211 C(x), whereC(x) is the number of comparisons\ns\u2208S\ninvolvingxasanonpivotelement. Next,wewillshowthatforeveryelementx S,\n\u2208\nthe expected value of C(x) is O(logn). Since the expected value of a sum is the\nsum of the expected values of its terms, an O(logn) bound on the expected value\nofC(x)impliesthatrandomized quick-sort runsinexpectedO(nlogn)time.\nwww.it-ebooks.info\n552 Chapter12. SortingandSelection\nToshowthat theexpected valueofC(x)isO(nlogn)foranyx, wefixanarbi-\ntraryelementxandconsiderthepathofnodesinthetreeT associatedwithrecursive\ncalls for which x is part of the input sequence. (See Figure 12.13.) By definition,\nC(x)isequaltothatpathlength,asxwilltakepartinonenonpivotcomparisonper\nlevelofthetreeuntilitischosenasthepivotoristheonlyelementthatremains.\nLet n denote the input size for the node of that path at depth d of tree T, for\nd\n0 d C(x). Sinceallelements areintheinitial recursive call, n =n. Weknow\n0\n\u2264 \u2264\nthattheinputsizeforanyrecursivecallisatleastonelessthanthesizeofitsparent,\nand thus that n n 1 for any d <C(x). In the worst case, this implies that\nd+1 d\n\u2264 \u2212\nC(x) n 1,astherecursiveprocess stopsifn =1orifxischosen asthepivot.\nd\n\u2264 \u2212\nWe can show the stronger claim that the expected value of C(x) is O(logn)\nbased on the random selection of a pivot at each level. The choice of pivot at\ndepth d of this path is considered \u201cgood\u201d if n 3n /4. The choice of a pivot\nd+1 d\n\u2264\nwillbegoodwithprobability atleast1/2,asthereareatleastn /2elementsinthe\nd\ninput that, if chosen as pivot, will result in at least n /4 elements begin placed in\nd\neachsubproblem, therebyleaving xinagroupwithatmost3n /4elements.\nd\nWe conclude by noting that there can be at most log n such good pivot\n4/3\nchoices before x is isolated. Since a choice is good with probability at least 1/2,\ntheexpected numberofrecursive callsbefore achieving log ngoodchoices isat\n4/3\nmost2log n,whichimpliesthatC(x)isO(logn).\n4/3\nWith a more rigorous analysis, we can show that the running time of random-\nizedquick-sort isO(nlogn)withhighprobability. (SeeExerciseC-12.55.)\n4 10 17 24 31 45 50 63 85 96\n4 10 17 24 31 45 63 85 96\n4 10 17 24 31 63 96\n4 85 24 31\n10 24\nFigure12.13: Anillustration oftheanalysisofProposition 12.3foranexecutionof\nrandomized quick-sort. Wefocusonelementx=31,whichhasvalueC(x)=3,as\nit is the nonpivot element in a comparison with 50, 45, and 17. By our notation,\nn =10,n =6,n =5,andn =2,andthepivotchoicesof50and17aregood.\n0 1 2 3\nwww.it-ebooks.info\n12.2. Quick-Sort 553\n12.2.2 Additional Optimizations for Quick-Sort\nAn algorithm is in-place if it uses only a small amount of memory in addition\nto that needed for the original input. Our implementation of heap-sort, from Sec-\ntion9.4.2,isanexampleofsuchanin-placesortingalgorithm. Ourimplementation\nofquick-sortfromCodeFragment12.5doesnotqualifyasin-placebecauseweuse\nadditionalcontainersL,E,andGwhendividingasequenceSwithineachrecursive\ncall. Quick-sortofanarray-basedsequencecanbeadaptedtobein-place,andsuch\nanoptimization isusedinmostdeployed implementations.\nPerforming the quick-sort algorithm in-place requires a bit of ingenuity, how-\never, for we must use the input sequence itself to store the subsequences for all\ntherecursivecalls. Weshowalgorithm quickSortInPlace,whichperformsin-place\nquick-sort ofanarray, inCodeFragment12.6. In-place quick-sort modifiesthein-\nputsequence usingelementswapping anddoesnotexplicitly createsubsequences.\nInstead, a subsequence of the input sequence is implicitly represented by a range\nof positions specified by a leftmost index a and a rightmost index b. The divide\n1 /\u2217\u2217 Sort the subarray S[a..b] inclusive. \u2217/\n2 private static <K> void quickSortInPlace(K[ ] S, Comparator<K> comp,\n3 int a, int b)\n{\n4 if (a >= b) return; // subarray is trivially sorted\n5 int left = a;\n6 int right = b 1;\n\u2212\n7 K pivot = S[b];\n8 K temp; // temp object used for swapping\n9 while (left <= right)\n{\n10 // scan until reaching value equal or larger than pivot (or right marker)\n11 while (left <= right && comp.compare(S[left], pivot) < 0) left++;\n12 // scan until reaching value equal or smaller than pivot (or left marker)\n13 while (left <= right && comp.compare(S[right], pivot) > 0) right ;\n\u2212\u2212\n14 if (left <= right) // indices did not strictly cross\n{\n15 // so swap values and shrink range\n16 temp = S[left]; S[left] = S[right]; S[right] = temp;\n17 left++; right ;\n\u2212\u2212\n18\n}\n19\n}\n20 // put pivot into its final place (currently marked by left index)\n21 temp = S[left]; S[left] = S[b]; S[b] = temp;\n22 // make recursive calls\n23 quickSortInPlace(S, comp, a, left 1);\n\u2212\n24 quickSortInPlace(S, comp, left + 1, b);\n25\n}\nCode Fragment 12.6: In-place quick-sort for an array S. The entire array can be\nsortedasquickSortInPlace(S, comp, 0, S.length 1).\n\u2212\nwww.it-ebooks.info\n554 Chapter12. SortingandSelection\nstep is performed by scanning the array simultaneously using local variables left,\nwhich advances forward, and right, which advances backward, swapping pairs of\nelements that are in reverse order, as shown in Figure 12.14. When these two in-\ndicespasseachother,thedivisionstepiscompleteandthealgorithmcompletesby\nrecurring on these two sublists. There is no explicit \u201ccombine\u201d step, because the\nconcatenation ofthetwosublists isimplicittothein-placeuseoftheoriginallist.\nIt isworth noting that if asequence has duplicate values, weare not explicitly\ncreatingthreesublistsL,E,andG,asinouroriginalquick-sortdescription. Wein-\nstead allow elements equal tothe pivot (other than thepivot itself) tobedispersed\nacrossthetwosublists. ExerciseR-12.11explores thesubtlety ofourimplementa-\ntion in the presence of duplicate keys, and Exercise C-12.34 describes an in-place\nalgorithm thatstrictly partitions intothreesublists L,E,andG.\n85 24 63 45 17 31 96 50\nl r\n(a)\n85 24 63 45 17 31 96 50\nl r\n(b)\n31 24 63 45 17 85 96 50\nl r\n(c)\n31 24 63 45 17 85 96 50\nl r\n(d)\n31 24 17 45 63 85 96 50\nl,r\n(e)\n31 24 17 45 63 85 96 50\nr < l\n(f)\n31 24 17 45 50 85 96 63\n(g)\nFigure12.14:Dividestepofin-placequick-sort,usingindexlasshorthandforiden-\ntifier left, and index r as shorthand for identifier right. Index l scans the sequence\nfromlefttoright, andindexr scansthesequence fromrighttoleft. Aswapisper-\nformedwhenl isatanelementaslargeasthepivotandr isatanelementassmall\nasthepivot. Afinalswapwiththepivot,inpart(f),completesthedividestep.\nwww.it-ebooks.info\n12.2. Quick-Sort 555\nAlthough the implementation we describe in this section for dividing the se-\nquence into twopieces is in-place, wenote that the complete quick-sort algorithm\nneeds space for a stack proportional to the depth of the recursion tree, which in\nthiscasecanbeaslargeasn 1. Admittedly,theexpectedstackdepthisO(logn),\n\u2212\nwhich is small compared to n. Nevertheless, a simple trick lets us guarantee the\nstacksizeisO(logn). Themainideaistodesignanonrecursiveversionofin-place\nquick-sortusinganexplicitstacktoiterativelyprocesssubproblems(eachofwhich\ncanberepresented withapairofindices marking subarray boundaries). Eachiter-\nation involves popping the top subproblem, splitting it in two(if itis big enough),\nand pushing the two new subproblems. The trick is that when pushing the new\nsubproblems, weshould firstpushthelarger subproblem andthenthesmallerone.\nIn this way, the sizes of the subproblems will at least double as we go down the\nstack;hence,thestackcanhavedepthatmostO(logn). Weleavethedetailsofthis\nimplementation asanexercise(P-12.59).\nPivot Selection\nOurimplementationinthissectionblindlypicksthelastelementasthepivotateach\nlevelofthequick-sort recursion. Thisleavesitsusceptible tothe\u0398(n2)-timeworst\ncase, mostnotably whentheoriginal sequence isalready sorted, reverse sorted, or\nnearlysorted.\nAsdescribedinSection12.2.1,thiscanbeimproveduponbyusingarandomly\nchosen pivot for each partition step. In practice, another common technique for\nchoosing a pivot is to use the median of tree values, taken respectively from the\nfront, middle, andtailofthearray. Thismedian-of-three heuristic willmoreoften\nchoose agood pivotandcomputing amedianofthree mayrequire loweroverhead\nthan selecting a pivot with a random number generator. For larger data sets, the\nmedianofmorethanthreepotential pivotsmightbecomputed.\nHybrid Approaches\nAlthough quick-sort has very good performance on large data sets, it has rather\nhigh overhead on relatively small data sets. For example, the process of quick-\nsortingasequence ofeightelements, asillustrated inFigures12.10through 12.12,\ninvolves considerable bookkeeping. In practice, a simple algorithm like insertion-\nsort(Section7.6)willexecutefasterwhensortingsuchashortsequence.\nIt is therefore common, in optimized sorting implementations, to use a hybrid\napproach,withadivide-and-conquer algorithmuseduntilthesizeofasubsequence\nfalls below some threshold (perhaps 50 elements); insertion-sort can be directly\ninvoked upon portions with length below the threshold. We will further discuss\nsuchpractical considerations inSection12.4, whencomparing theperformance of\nvarioussortingalgorithms.\nwww.it-ebooks.info\n556 Chapter12. SortingandSelection\n12.3 Studying Sorting through an Algorithmic Lens\nRecappingourdiscussionsonsortingtothispoint,wehavedescribedseveralmeth-\nodswitheither aworstcaseorexpected running timeofO(nlogn)onaninput se-\nquence of size n. These methods include merge-sort and quick-sort, described in\nthischapter,aswellasheap-sort(Section9.4.2). Inthissection,wewillstudysort-\ningasanalgorithmic problem,addressing generalissuesaboutsortingalgorithms.\n12.3.1 Lower Bound for Sorting\nA natural first question to ask is whether we can sort any faster than O(nlogn)\ntime. Interestingly,ifthecomputationalprimitiveusedbyasortingalgorithmisthe\ncomparison oftwoelements, this isinfactthebest wecando\u2014comparison-based\nsorting has an \u2126(nlogn) worst-case lower bound on its running time. (Recall the\nnotation \u2126()from Section 4.3.1.) Tofocus onthemaincostofcomparison-based\n\u00b7\nsorting, letusonlycountcomparisons, forthesakeofalowerbound.\nSuppose we are given a sequence S = (x ,x ,...,x ) that we wish to sort,\n0 1 n\u22121\nand assume that all the elements of S are distinct (this is not really a restriction\nsince we are deriving a lower bound). We do not care if S is implemented as an\narray or a linked list, for the sake of our lower bound, since we are only counting\ncomparisons. Eachtimeasorting algorithm compares twoelements x andx (that\ni j\nis,itasks,\u201cisx <x ?\u201d),therearetwooutcomes: \u201cyes\u201dor\u201cno.\u201d Basedontheresult\ni j\nof this comparison, the sorting algorithm may perform some internal calculations\n(which weare not counting here) and willeventually perform another comparison\nbetween twootherelements ofS,whichagainwillhavetwooutcomes. Therefore,\nwecan represent acomparison-based sorting algorithm withadecision treeT (re-\ncall Example 8.5). That is, each internal node v inT corresponds toa comparison\nandtheedgesfrompositionvtoitschildrencorrespondtothecomputations result-\ningfromeithera\u201cyes\u201dor\u201cno\u201danswer. Itisimportanttonotethatthehypothetical\nsortingalgorithminquestionprobablyhasnoexplicitknowledgeofthetreeT. The\ntreesimplyrepresentsallthepossiblesequencesofcomparisonsthatasortingalgo-\nrithmmightmake,startingfromthefirstcomparison(associated withtheroot)and\nendingwiththelastcomparison (associated withtheparentofanexternalnode).\nEach possible initial order, or permutation, of the elements in S will cause\nour hypothetical sorting algorithm toexecute aseries ofcomparisons, traversing a\npath inT from the roottosome external node. Letusassociate witheach external\nnode v in T, then, the set of permutations of S that cause our sorting algorithm to\nend up in v. The most important observation in our lower-bound argument is that\neach external node v in T can represent the sequence of comparisons for at most\none permutation of S. The justification for this claim is simple: If two different\nwww.it-ebooks.info\n12.3. StudyingSortingthroughanAlgorithmicLens 557\npermutations P andP ofSareassociated withthesameexternal node, thenthere\n1 2\nare at least two objects x and x , such that x is before x in P but x is after x\ni j i j 1 i j\ninP . Atthesametime, theoutput associated withvmustbeaspecific reordering\n2\nofS,witheitherx orx appearingbeforetheother. ButifP andP bothcausethe\ni j 1 2\nsortingalgorithmtooutputtheelementsofSinthisorder,thenthatimpliesthereis\nawaytotrickthealgorithm intooutputting x andx inthewrongorder. Sincethis\ni j\ncannot beallowedbyacorrect sorting algorithm, each external node ofT mustbe\nassociated withexactly onepermutation ofS. Weusethisproperty ofthedecision\ntreeassociated withasortingalgorithm toprovethefollowingresult:\nProposition 12.4: Therunningtimeofanycomparison-basedalgorithmforsort-\ningann-elementsequenceis\u2126(nlogn)intheworstcase.\nJustification: The running time of a comparison-based sorting algorithm must\nbe greater than or equal to the height of the decision tree T associated with this\nalgorithm, as described above. (See Figure 12.15.) By the argument above, each\nexternal node in T must be associated with one permutation of S. Moreover, each\npermutation of S must result in a different external node of T. The number of\npermutations of n objects is n! = n(n 1)(n 2) 2 1. Thus, T must have at\n\u2212 \u2212 \u00b7\u00b7\u00b7 \u00b7\nleastn!externalnodes. ByProposition 8.7,theheightofT isatleastlog(n!). This\nimmediately justifies the proposition, because there are at least n/2 terms that are\ngreaterthanorequalton/2intheproduct n!;hence,\nn n n n\nlog(n!) log 2 = log ,\n\u2265 2 2 2\n(cid:18) (cid:19)\n(cid:16) (cid:17)\nwhichis\u2126(nlogn).\nMinimumHeight\n(i.e.,worst-caserunningtime)\nxi<xj?\nxa<xb? xc<xd?\nlog(n!)\nxe<xf ? xg<xh? xk<xl? xm<xn?\nn!\nFigure12.15: Visualizingthelowerboundforcomparison-based sorting.\nwww.it-ebooks.info\n558 Chapter12. SortingandSelection\n12.3.2 Linear-Time Sorting: Bucket-Sort and Radix-Sort\nIn the previous section, we showed that \u2126(nlogn) time is necessary, in the worst\ncase, tosort ann-element sequence withacomparison-based sorting algorithm. A\nnaturalquestion toask,then,iswhetherthereareotherkindsofsortingalgorithms\nthat can be designed to run asymptotically faster than O(nlogn) time. Interest-\ningly, such algorithms exist, but they require special assumptions about the input\nsequencetobesorted. Evenso,suchscenariosoftenariseinpractice,suchaswhen\nsortingintegersfromaknownrangeorsortingcharacterstrings,sodiscussingthem\nis worthwhile. In this section, wewill consider the problem of sorting a sequence\nofentries, eachakey-valuepair,wherethekeyshavearestricted type.\nBucket-Sort\nConsider asequence S of nentries whose keys are integers inthe range [0,N 1],\n\u2212\nforsome integer N 2, and suppose that S should be sorted according tothe keys\n\u2265\nof the entries. Inthis case, it ispossible to sort S in O(n+N)time. Itmight seem\nsurprising, but this implies, for example, that if N is O(n), then we can sort S in\nO(n)time. Ofcourse,thecrucialpointisthat,becauseoftherestrictiveassumption\nabouttheformatoftheelements, wecanavoidusingcomparisons.\nThemainidea istouse analgorithm called bucket-sort, whichisnot based on\ncomparisons, but on using keys as indices into a bucket array B that has cells in-\ndexed from 0 to N 1. An entry with key k is placed in the \u201cbucket\u201d B[k], which\n\u2212\nitself is a sequence (of entries with key k). After inserting each entry of the input\nsequenceSintoitsbucket,wecanputtheentriesbackintoSinsortedorderbyenu-\nmerating the contents of the buckets B[0],B[1],...,B[N 1] in order. We describe\n\u2212\nthebucket-sort algorithm inCodeFragment12.7.\nAlgorithmbucketSort(S):\nInput: SequenceSofentries withintegerkeysintherange[0,N 1]\n\u2212\nOutput: SequenceSsortedinnondecreasing orderofthekeys\nletBbeanarrayofnsequences, eachofwhichisinitiallyempty\nforeachentryeinSdo\nletkdenotethekeyofe\nremoveefromSandinsertitattheendofbucket (sequence) B[k]\nfori = 0ton 1do\n\u2212\nforeachentryeinsequence B[i]do\nremoveefromB[i]andinsertitattheendofS\nCodeFragment12.7: Bucket-sort.\nwww.it-ebooks.info\n12.3. StudyingSortingthroughanAlgorithmicLens 559\nIt is easy to see that bucket-sort runs in O(n+N) time and uses O(n+N)\nspace. Hence, bucket-sort is efficient when the range N of values for the keys is\nsmall compared to the sequence size n, say N =O(n) or N =O(nlogn). Still, its\nperformance deteriorates asN growscomparedton.\nAn important property of the bucket-sort algorithm is that it works correctly\nevenifthere aremanydifferent elements withthesamekey. Indeed, wedescribed\nitinawaythatanticipates suchoccurrences.\nStable Sorting\nWhensortingkey-valuepairs,animportantissueishowequalkeysarehandled. Let\nS=((k ,v ),...,(k ,v ))beasequence ofsuchentries. Wesaythatasorting\n0 0 n\u22121 n\u22121\nalgorithm is stable if, for any two entries (k,v) and (k ,v ) of S such that k =k\ni i j j i j\nand (k,v) precedes (k ,v ) in S before sorting (that is, i< j), entry (k,v) also\ni i j j i i\nprecedes entry (k ,v ) after sorting. Stability is important for a sorting algorithm\nj j\nbecause applications may want to preserve the initial order of elements with the\nsamekey.\nOurinformaldescription ofbucket-sort inCodeFragment12.7guarantees sta-\nbilityaslongasweensurethatallsequencesactasqueues,withelementsprocessed\nand removed from the front of a sequence and inserted at the back. That is, when\ninitiallyplacingelementsofSintobuckets,weshouldprocessSfromfronttoback,\nandadd eachelement tothe endofitsbucket. Subsequently, whentransferring el-\nementsfromthebucketsbacktoS,weshouldprocesseachB[i]fromfronttoback,\nwiththoseelementsaddedtotheendofS.\nRadix-Sort\nOne of the reasons that stable sorting is so important is that it allows the bucket-\nsortapproachtobeappliedtomoregeneralcontextsthantosortintegers. Suppose,\nfor example, that we want to sort entries with keys that are pairs (k,l), where k\nand l are integers in the range [0,N 1], for some integer N 2. In a context\n\u2212 \u2265\nsuchasthis,itiscommontodefineanorderonthesekeysusingthelexicographic\n(dictionary) convention, where(k ,l )<(k ,l )ifk <k orifk =k andl <l\n1 1 2 2 1 2 1 2 1 2\n(seepage363). Thisisapairwiseversionofthelexicographiccomparisonfunction,\nwhichcanbeapplied toequal-length character strings, ortotuplesoflengthd.\nTheradix-sort algorithm sorts asequence S ofentries withkeysthatare pairs,\nby applying astable bucket-sort on the sequence twice; first using one component\nof the pair as the key when ordering and then using the second component. But\nwhich order is correct? Should we first sort on the k\u2019s (the first component) and\nthenonthel\u2019s(thesecondcomponent), orshould itbetheotherwayaround?\nwww.it-ebooks.info\n560 Chapter12. SortingandSelection\nTo gain intuition before answering this question, we consider the following\nexample.\nExample 12.5: ConsiderthefollowingsequenceS(weshowonlythekeys):\nS=((3,3),(1,5),(2,5),(1,2),(2,3),(1,7),(3,2),(2,2)).\nIfwesortSstablyonthefirstcomponent,thenwegetthesequence\nS =((1,5),(1,2),(1,7),(2,5),(2,3),(2,2),(3,3),(3,2)).\n1\nIfwethenstablysortthissequenceS usingthesecondcomponent,wegetthe\n1\nsequence\nS =((1,2),(2,2),(3,2),(2,3),(3,3),(1,5),(2,5),(1,7)),\n1,2\nwhichisunfortunatelynotasortedsequence.Ontheotherhand,ifwefirststably\nsortSusingthesecondcomponent,thenwegetthesequence\nS =((1,2),(3,2),(2,2),(3,3),(2,3),(1,5),(2,5),(1,7)).\n2\nIfwethenstablysortsequenceS usingthefirstcomponent,wegetthesequence\n2\nS =((1,2),(1,5),(1,7),(2,2),(2,3),(2,5),(3,2),(3,3)),\n2,1\nwhichisindeedsequenceSlexicographicallyordered.\nSo, from this example, we are led to believe that we should first sort using\nthe second component and then again using the first component. This intuition is\nexactly right. By first stably sorting by the second component and then again by\nthe first component, we guarantee that if two entries are equal in the second sort\n(by the first component), then their relative order in the starting sequence (which\nis sorted by the second component) is preserved. Thus, the resulting sequence is\nguaranteedtobesortedlexicographically everytime. Weleavetoasimpleexercise\n(R-12.19) the determination of how this approach can be extended to triples and\notherd-tuplesofnumbers. Wecansummarizethissectionasfollows:\nProposition 12.6: LetSbeasequenceofnkey-valuepairs,eachofwhichhasa\nkey(k ,k ,...,k ),wherek isanintegerintherange[0,N 1]forsomeinteger\n1 2 d i\n\u2212\nN 2.WecansortSlexicographicallyintimeO(d(n+N))usingradix-sort.\n\u2265\nRadix-sort can be applied to any key that can be viewed as a composite of\nsmaller pieces that are to be sorted lexicographically. For example, we can apply\nit to sort character strings of moderate length, as each individual character can be\nrepresented as an integer value. (Some care is needed to properly handle strings\nwithvarying lengths.)\nwww.it-ebooks.info\n12.4. ComparingSortingAlgorithms 561\n12.4 Comparing Sorting Algorithms\nAtthis point, itmight be useful for us totake amoment and consider allthe algo-\nrithmswehavestudiedinthisbooktosortann-elementsequence.\nConsidering Running Time and Other Factors\nWe have studied several methods, such as insertion-sort and selection-sort, that\nhaveO(n2)-timebehaviorintheaverageandworstcase. Wehavealsostudiedsev-\neral methods with O(nlogn)-time behavior, including heap-sort, merge-sort, and\nquick-sort. Finally, the bucket-sort and radix-sort methods run in linear time for\ncertaintypesofkeys. Certainly,theselection-sort algorithmisapoorchoiceinany\napplication, sinceitrunsinO(n2)timeeveninthebestcase. But,oftheremaining\nsortingalgorithms, whichisthebest?\nAs with many things in life, there is no clear \u201cbest\u201d sorting algorithm from\ntheremainingcandidates. Therearetrade-offsinvolvingefficiency,memoryusage,\nandstability. Thesortingalgorithm bestsuitedforaparticular application depends\non the properties of that application. In fact, the default sorting algorithm used\nby computing languages and systems has evolved greatly over time. We can offer\nsome guidance and observations, therefore, based on the known properties of the\n\u201cgood\u201dsorting algorithms.\nInsertion-Sort\nIf implemented well, the running time of insertion-sort is O(n+m), where m is\nthe number of inversions (that is, the number of pairs of elements out of order).\nThus,insertion-sort isanexcellent algorithm forsorting smallsequences (say, less\nthan50elements),becauseinsertion-sortissimpletoprogram,andsmallsequences\nnecessarily have few inversions. Also, insertion-sort is quite effective for sorting\nsequences thatarealready\u201calmost\u201dsorted. By\u201calmost,\u201dwemeanthatthenumber\nofinversions issmall. ButtheO(n2)-timeperformance ofinsertion-sort makesita\npoorchoiceoutside ofthesespecialcontexts.\nHeap-Sort\nHeap-sort, on the other hand, runs in O(nlogn) time in the worst case, which is\noptimalforcomparison-basedsortingmethods. Heap-sortcaneasilybemadetoex-\necutein-place,andisanaturalchoiceonsmall-andmedium-sizedsequences,when\ninputdatacanfitintomainmemory. However,heap-sort tends tobeoutperformed\nby both quick-sort and merge-sort on larger sequences. Astandard heap-sort does\nnotprovideastablesort,becauseoftheswapping ofelements.\nwww.it-ebooks.info\n562 Chapter12. SortingandSelection\nQuick-Sort\nAlthough its O(n2)-time worst-case performance makes quick-sort susceptible in\nreal-timeapplications wherewemustmakeguaranteesonthetimeneededtocom-\nplete asorting operation, we expect its performance to beO(nlogn) time, and ex-\nperimentalstudieshaveshownthatitoutperformsbothheap-sortandmerge-sorton\nmanytests. Quick-sortdoesnotnaturallyprovideastablesort,duetotheswapping\nofelementsduringthepartitioning step.\nFordecadesquick-sortwasthedefaultchoiceforageneral-purpose,in-memory\nsorting algorithm. Quick-sort was included as the qsort sorting utility provided\nin C language libraries, and was the basis for sorting utilities on Unix operating\nsystems for manyyears. Ithas long been the standard algorithm for sorting arrays\nofprimitivetypeinJava. (Wediscusssorting ofobjecttypesbelow.)\nMerge-Sort\nMerge-sort runs in O(nlogn) time in the worst case. It is quite difficult to make\nmerge-sortrunin-placeforarrays,andwithoutthatoptimizationtheextraoverhead\nofallocateatemporaryarray,andcopyingbetweenthearraysislessattractivethan\nin-place implementations ofheap-sort andquick-sort forsequences thatcanfiten-\ntirelyinacomputer\u2019s mainmemory. Evenso,merge-sort isanexcellentalgorithm\nfor situations where the input is stratified across various levels of the computer\u2019s\nmemoryhierarchy(e.g.,cache,mainmemory,externalmemory). Inthesecontexts,\nthewaythatmerge-sortprocessesrunsofdatainlongmergestreamsmakesthebest\nuse ofall the data brought asablock into alevel of memory, thereby reducing the\ntotalnumberofmemorytransfers.\nTheGNUsortingutility(andmostcurrentversionsoftheLinuxoperatingsys-\ntem)reliesonamultiwaymerge-sort variant. Tim-sort(designedbyTimPeters)is\nahybridapproachthatisessentiallyabottom-upmerge-sortthattakesadvantageof\ninitial runs inthe data whileusing insertion-sort tobuild additional runs. Tim-sort\nhas been the standard sorting algorithm in Python since 2003, and it has become\nthedefaultalgorithm forsortingarraysofobjecttypes,asofJavaSE7.\nBucket-Sort and Radix-Sort\nFinally, ifanapplication involves sortingentries withsmallinteger keys,character\nstrings, or d-tuples ofkeys from adiscrete range, then bucket-sort orradix-sort is\nanexcellentchoice,foritrunsinO(d(n+N))time,where[0,N 1]istherangeof\n\u2212\nintegerkeys(andd=1forbucketsort). Thus,ifd(n+N)issignificantly \u201cbelow\u201d\nthenlognfunction,thenthissortingmethodshouldrunfasterthanevenquick-sort,\nheap-sort, ormerge-sort.\nwww.it-ebooks.info\n12.5. Selection 563\n12.5 Selection\nAsimportantasitis,sortingisnottheonlyinterestingproblemdealingwithatotal\norder relation on a set of elements. There are a number of applications in which\nwe are interested in identifying a single element in terms of its rank relative to\nthe sorted order of the entire set. Examples include identifying the minimum and\nmaximum elements, but wemay also be interested in, say, identifying the median\nelement,thatis,theelementsuchthathalfoftheotherelementsaresmallerandthe\nremaining half are larger. In general, queries that ask for an element with a given\nrankarecalledorderstatistics.\nDefining the Selection Problem\nIn this section, we discuss the general order-statistic problem of selecting the kth\nsmallest element from an unsorted collection of n comparable elements. This is\nknown as the selection problem. Of course, we can solve this problem by sorting\nthe collection and then indexing into the sorted sequence at index k 1. Using\n\u2212\nthebestcomparison-based sorting algorithms, thisapproach wouldtake O(nlogn)\ntime, which is obviously an overkill for the cases where k=1 or k =n (or even\nk =2, k=3, k =n 1, or k =n 5), because we can easily solve the selection\n\u2212 \u2212\nproblem for these values of k in O(n) time. Thus, a natural question to ask is\nwhether we can achieve an O(n) running time for all values of k (including the\ninteresting caseoffindingthemedian,wherek= n/2 ).\n\u230a \u230b\n12.5.1 Prune-and-Search\nWecan indeed solve theselection problem inO(n)timeforanyvalue ofk. More-\nover,thetechniqueweusetoachievethisresultinvolves aninteresting algorithmic\ndesign pattern. This design pattern is known as prune-and-search or decrease-\nand-conquer. In applying this design pattern, we solve a given problem that is\ndefined on a collection of n objects by pruning away a fraction of the n objects\nand recursively solving the smaller problem. When we have finally reduced the\nproblem to one defined on a constant-sized collection of objects, we then solve\ntheproblemusingsomebrute-force method. Returning backfromalltherecursive\ncalls completes the construction. In some cases, we can avoid using recursion, in\nwhich case wesimply iterate theprune-and-search reduction step until wecan ap-\nplyabrute-forcemethodandstop. Incidentally,thebinarysearchmethoddescribed\ninSection5.1.3isanexampleoftheprune-and-search designpattern.\nwww.it-ebooks.info\n564 Chapter12. SortingandSelection\n12.5.2 Randomized Quick-Select\nIn applying the prune-and-search pattern to finding the kth smallest element in an\nunordered sequence of n elements, we describe a simple and practical algorithm,\nknown as randomized quick-select. This algorithm runs in O(n) expected time,\ntaken over all possible random choices made by the algorithm; this expectation\ndoes not depend whatsoever on any randomness assumptions about the input dis-\ntribution. We note though that randomized quick-select runs in O(n2) time in the\nworst case, the justification of which is left as an exercise (R-12.25). We also\nprovide an exercise (C-12.56) for modifying randomized quick-select to define a\ndeterministic selection algorithm thatrunsinO(n)worst-case time. Theexistence\nof this deterministic algorithm is mostly of theoretical interest, however, since the\nconstant factorhiddenbythebig-Ohnotation isrelativelylargeinthatcase.\nSuppose we are given an unsorted sequence S of n comparable elements to-\ngether with an integer k [1,n]. At a high level, the quick-select algorithm for\n\u2208\nfinding the kth smallest element in S is similar to the randomized quick-sort algo-\nrithmdescribedinSection12.2.1. Wepicka\u201cpivot\u201delementfromSatrandomand\nusethistosubdivideSintothreesubsequences L,E,andG,storingtheelementsof\nSless than, equal to, andgreater thanthepivot, respectively. Intheprune step, we\ndetermine which of these subsets contains the desired element, based onthe value\nofkandthesizesofthosesubsets. Wethenrecurontheappropriate subset, noting\nthatthedesiredelement\u2019srankinthesubsetmaydifferfromitsrankinthefullset.\nPseudocode forrandomized quick-select isshowninCodeFragment12.8.\nAlgorithmquickSelect(S,k):\nInput: SequenceSofncomparableelements, andanintegerk [1,n]\n\u2208\nOutput: Thekth smallestelementofS\nifn==1then\nreturnthe(first)elementofS.\npickarandom(pivot)elementxofSanddivideSintothreesequences:\nL,storingtheelementsinSlessthanx\n\u2022\nE,storing theelementsinSequaltox\n\u2022\nG,storingtheelementsinSgreaterthanx\n\u2022\nifk L then\n\u2264| |\nreturnquickSelect(L,k)\nelseifk L + E then\n\u2264| | | |\nreturnx eachelementinE isequaltox\n{ }\nelse\nreturnquickSelect(G,k L E ) notethenewselection parameter\n\u2212| |\u2212| | { }\nCodeFragment12.8: Randomizedquick-select algorithm.\nwww.it-ebooks.info\n12.5. Selection 565\n12.5.3 Analyzing Randomized Quick-Select\nShowing that randomized quick-select runs in O(n) time requires a simple prob-\nabilistic argument. The argument is based on the linearity of expectation, which\nstatesthatifX andY arerandomvariables andcisanumber,then\nE(X+Y)=E(X)+E(Y) and E(cX)=cE(X),\nwhereweuseE( )todenote theexpected valueoftheexpression .\nZ Z\nLett(n)betherunningtimeofrandomizedquick-selectonasequenceofsizen.\nSincethisalgorithm depends onrandom events,itsrunningtime,t(n),isarandom\nvariable. WewanttoboundE(t(n)),theexpectedvalueoft(n). Saythatarecursive\ncall of our algorithm is \u201cgood\u201d if it partitions S so that the size of each of L and\nG is at most 3n/4. Clearly, a recursive call is good with probability at least 1/2.\nLet g(n) denote the number of consecutive recursive calls we make, including the\npresent one, before we get a good one. Then we can characterize t(n) using the\nfollowingrecurrenceequation:\nt(n) bn g(n)+t(3n/4),\n\u2264 \u00b7\nwhereb 1isaconstant. Applyingthelinearity ofexpectation forn>1,weget\n\u2265\nE(t(n)) E(bn g(n)+t(3n/4))=bn E(g(n))+E(t(3n/4)).\n\u2264 \u00b7 \u00b7\nSincearecursivecallisgoodwithprobability atleast1/2,andwhetherarecursive\ncall is good ornot isindependent ofits parent call being good, the expected value\nof g(n) is at most the expected number of times we must flip a fair coin before it\ncomes up \u201cheads.\u201d That is, E(g(n)) 2. Thus, if we let T(n) be shorthand for\n\u2264\nE(t(n)),thenwecanwritethecaseforn>1as\nT(n) T(3n/4)+2bn.\n\u2264\nTo convert this relation into a closed form, let us iteratively apply this inequality\nassumingnislarge. So,forexample,aftertwoapplications,\nT(n) T((3/4)2n)+2b(3/4)n+2bn.\n\u2264\nAtthispoint,weshouldseethatthegeneralcaseis\n\u2308log n\u2309\n4/3\nT(n) 2bn \u2211 (3/4)i.\n\u2264 \u00b7\ni=0\nIn other words, the expected running time is at most 2bn times a geometric sum\nwhosebaseisapositivenumberlessthan1. Thus,byProposition4.5,T(n)isO(n).\nProposition 12.7: Theexpectedrunningtimeofrandomizedquick-selectona\nsequenceSofsizenisO(n),assumingtwoelementsofScanbecomparedinO(1)\ntime.\nwww.it-ebooks.info\n566 Chapter12. SortingandSelection\n12.6 Exercises\nReinforcement\nR-12.1 GiveacompletejustificationofProposition12.1.\nR-12.2 Inthemerge-sorttreeshowninFigures12.2through12.4,someedgesaredrawn\nas arrows. What is the meaning of a downwardarrow? How aboutan upward\narrow?\nR-12.3 Showthattherunningtimeofthemerge-sortalgorithmonann-elementsequence\nisO(nlogn),evenwhennisnotapowerof2.\nR-12.4 Isourarray-basedimplementationofmerge-sortgiveninSection12.1.2stable?\nExplainwhyorwhynot.\nR-12.5 Isourlinked-list-basedimplementationofmerge-sort(CodeFragment12.3)sta-\nble? Explainwhyorwhynot.\nR-12.6 An algorithmthat sorts key-valueentries by key is said to be straggling if any\ntimetwoentriese ande haveequalkeys,bute appearsbeforee intheinput,\ni j i j\nthen the algorithm places e after e in the output. Describe a change to the\ni j\nmerge-sortalgorithminSection12.1tomakeitstraggling.\nR-12.7 Supposewearegiventwon-elementsortedsequencesAandBeachwithdistinct\nelements,butpotentiallysomeelementsthatareinbothsequences. Describean\nO(n)-timemethodforcomputingasequencerepresentingtheunionA B(with\n\u222a\nnoduplicates)asasortedsequence.\nR-12.8 GivepseudocodedescriptionsfortheretainAllandremoveAllmethodsoftheset\nADT,assumingweusesortedsequencestoimplementsets.\nR-12.9 Supposewemodifythedeterministicversionofthequick-sortalgorithmsothat,\ninstead of selecting the last element in an n-elementsequence as the pivot, we\nchoosethe elementatindex n/2 . Whatis the runningtime ofthisversionof\n\u230a \u230b\nquick-sortonasequencethatisalreadysorted?\nR-12.10 Consideramodificationofthedeterministicversionofthequick-sortalgorithm\nwherewechoosetheelementatindex n/2 asourpivot. Describethekindof\nsequencethatwouldcausethisversion \u230a ofqu \u230b ick-sorttorunin\u2126(n2)time.\nR-12.11 SupposethemethodquickSortInPlaceisexecutedonasequencewithduplicate\nelements. Provethatthealgorithmstillcorrectlysortstheinputsequence. What\nhappensinthepartitionstepwhenthereareelementsequaltothepivot? Whatis\ntherunningtimeofthealgorithmifalltheinputelementsareequal?\nR-12.12 Showthatthebest-caserunningtimeofquick-sortonasequenceofsizenwith\ndistinctelementsis\u2126(nlogn).\nR-12.13 If the outermost while loop of our implementation of quickSortInPlace (line 9\nof Code Fragment12.6)were changedto use conditionleft < right, instead of\ncondition left <= right, there would be a flaw. Explain the flaw and give a\nspecificinputsequenceonwhichsuchanimplementationfails.\nwww.it-ebooks.info\n12.6. Exercises 567\nR-12.14 If the conditional at line 14 of our quickSortInPlace implementation of Code\nFragment12.6werechangedtouseconditionleft < right, insteadofcondition\nleft <= right, therewouldbeaflaw. Explaintheflawandgiveaspecificinput\nsequenceonwhichsuchanimplementationfails.\nR-12.15 Followingouranalysisofrandomizedquick-sortinSection12.2.1,showthatthe\nprobabilitythatagiveninputelementxbelongstomorethan2lognsubproblems\ninsizegroupiisatmost1/n2.\nR-12.16 Ofthen!possibleinputstoagivencomparison-basedsortingalgorithm,whatis\ntheabsolutemaximumnumberofinputsthatcouldbecorrectlysortedwithjust\nncomparisons?\nR-12.17 Jonathanhasacomparison-basedsortingalgorithmthatsortsthefirstkelements\nofasequenceofsizeninO(n)time.Giveabig-Ohcharacterizationofthebiggest\nthatkcanbe.\nR-12.18 Isthebucket-sortalgorithmin-place?Whyorwhynot?\nR-12.19 Describearadix-sortmethodforlexicographicallysortingasequenceSoftriplets\n(k,l,m), wherek, l, andm areintegersin therange[0,N 1], forN 2. How\n\u2212 \u2265\ncould this scheme be extended to sequences of d-tuples (k ,k ,...,k ), where\n1 2 d\neachk isanintegerintherange[0,N 1]?\ni\n\u2212\nR-12.20 SupposeSisasequenceofnvalues,eachequalto0or1. Howlongwillittake\ntosortSwiththemerge-sortalgorithm?Whataboutquick-sort?\nR-12.21 SupposeSisasequenceofnvalues,eachequalto0or1. Howlongwillittake\ntosortSstablywiththebucket-sortalgorithm?\nR-12.22 GivenasequenceSofnvalues,eachequalto0or1,describeanin-placemethod\nforsortingS.\nR-12.23 Giveanexampleinputthatrequiresmerge-sortandheap-sorttotakeO(nlogn)\ntimetosort,butinsertion-sortrunsinO(n)time.Whatifyoureversethislist?\nR-12.24 Whatisthebestalgorithmforsortingeachofthefollowing:generalcomparable\nobjects, long character strings, 32-bit integers, double-precision floating-point\nnumbers,andbytes? Justifyyouranswer.\nR-12.25 Showthattheworst-caserunningtimeofquick-selectonann-elementsequence\nis\u2126(n2).\nCreativity\nC-12.26 Describeandanalyzeanefficientmethodforremovingallduplicatesfromacol-\nlectionAofnelements.\nC-12.27 Augmentthe PositionalList class (see Section 7.3) to supporta method named\nsort thatsorts the elementsof a list by relinkingexisting nodes; you are notto\ncreateanynewnodes. Youmayuseyourchoiceofsortingalgorithm.\nwww.it-ebooks.info\n568 Chapter12. SortingandSelection\nC-12.28 Lindaclaimsto havean algorithmthattakesaninputsequenceS andproduces\nanoutputsequenceT thatisasortingofthenelementsinS.\na. Giveanalgorithm,isSorted,thattestsinO(n)timeifT issorted.\nb. Explain why the algorithm isSorted is notsufficient to provea particular\noutputT toLinda\u2019salgorithmisasortingofS.\nc. Describe what additional information Linda\u2019s algorithm could output so\nthatheralgorithm\u2019scorrectnesscouldbeestablishedonanygivenSandT\ninO(n)time.\nC-12.29 Augmentthe PositionalList class (see Section 7.3) to supporta method named\nmergewiththefollowingbehavior.IfAandBarePositionalListinstanceswhose\nelementsaresorted,thesyntaxA.merge(B)shouldmergeallelementsofBinto\nA so that A remains sorted and B becomes empty. Your implementation must\naccomplishthemergebyrelinkingexistingnodes;youarenottocreateanynew\nnodes.\nC-12.30 Implementabottom-upmerge-sortforacollectionofitemsbyplacingeachitem\ninitsownqueue,andthenrepeatedlymergingpairsofqueuesuntilallitemsare\nsortedwithinasinglequeue.\nC-12.31 Modify our in-place quick-sortimplementationof Code Fragment12.6 to be a\nrandomizedversionofthealgorithm,asdiscussedinSection12.2.1.\nC-12.32 Consider a version of deterministic quick-sort where we pick as our pivot the\nmedian of the d last elements in the input sequence of n elements, for a fixed,\nconstantoddnumberd 3. Whatistheasymptoticworst-caserunningtimeof\n\u2265\nquick-sortinthiscase?\nC-12.33 Anotherwaytoanalyzerandomizedquick-sortistousearecurrenceequation.\nInthiscase,weletT(n)denotetheexpectedrunningtimeofrandomizedquick-\nsort,andweobservethat,becauseoftheworst-casepartitionsforgoodandbad\nsplits,wecanwrite\n1 1\nT(n) (T(3n/4)+T(n/4))+ (T(n 1))+bn,\n\u2264 2 2 \u2212\nwherebnisthetimeneededtopartitionalistforagivenpivotandconcatenate\ntheresultsublistsaftertherecursivecallsreturn. Show,byinduction,thatT(n)\nisO(nlogn).\nC-12.34 Ourhigh-leveldescriptionofquick-sortdescribespartitioningtheelementsinto\nthreesetsL,E,andG,havingkeyslessthan,equalto,orgreaterthanthepivot,\nrespectively. However, our in-place quick-sort implementation of Code Frag-\nment12.6doesnotgatherallelementsequaltothepivotintoasetE. Analterna-\ntivestrategyforanin-place,three-waypartitionisasfollows. Loopthroughthe\nelementsfromlefttorightmaintainingindicesa,b,andcandtheinvariantthat\nelements with index i such that 0 i<a are strictly less than the pivot, those\n\u2264\nwitha i<bareequaltothepivot,andthosewithindexb i<carestrictly\n\u2264 \u2264\ngreaterthanthepivot;elementswithindexc i<nareyetunclassified.Ineach\n\u2264\npassoftheloop,classifyoneadditionalelement,performingaconstantnumber\nofswapsasneeded.Implementanin-placequick-sortusingthisstrategy.\nwww.it-ebooks.info\n12.6. Exercises 569\nC-12.35 Supposewearegivenann-elementsequenceSsuchthateachelementinSrep-\nresentsadifferentvoteforpresident,whereeachvoteisgivenasanintegerrep-\nresenting a particular candidate, yet the integers may be arbitrarily large (even\nif the numberofcandidatesis not). Design anO(nlogn)-time algorithmto see\nwhowinstheelectionSrepresents,assumingthecandidatewiththemostvotes\nwins.\nC-12.36 Consider the voting problem from Exercise C-12.35, but now suppose that we\nknowthe numberk<n of candidatesrunning, eventhoughthe integerIDs for\nthosecandidatescanbearbitrarilylarge. DescribeanO(nlogk)-timealgorithm\nfordeterminingwhowinstheelection.\nC-12.37 ConsiderthevotingproblemfromExerciseC-12.35,butnowsupposethe inte-\ngers1tokareusedtoidentifyk<ncandidates.DesignanO(n)-timealgorithm\ntodeterminewhowinstheelection.\nC-12.38 Showthatanycomparison-basedsortingalgorithmcanbemadetobestablewith-\noutaffectingitsasymptoticrunningtime.\nC-12.39 SupposewearegiventwosequencesAandBofnelements,possiblycontaining\nduplicates,onwhichatotalorderrelationisdefined. Describeanefficientalgo-\nrithmfordeterminingif AandB containthesame setofelements. Whatis the\nrunningtimeofthismethod?\nC-12.40 GivenanarrayAofnintegersintherange[0,n2 1],describeasimplemethod\n\u2212\nforsortingAinO(n)time.\nC-12.41 LetS ,S ,...,S bekdifferentsequenceswhoseelementshaveintegerkeysinthe\n1 2 k\nrange[0,N 1],forsomeparameterN 2. Describeanalgorithmthatproduces\n\u2212 \u2265\nkrespectivesortedsequencesinO(n+N)time,wherendenotesthesumofthe\nsizesofthosesequences.\nC-12.42 GivenasequenceSofnelements,onwhichatotalorderrelationisdefined,de-\nscribeanefficientmethodfordeterminingwhethertherearetwoequalelements\ninS. Whatistherunningtimeofyourmethod?\nC-12.43 Let S be a sequence of n elements on which a total order relation is defined.\nRecall that an inversion in S is a pair of elements x and y such that x appears\nbefore y in S but x>y. Describe an algorithm running in O(nlogn) time for\ndeterminingthenumberofinversionsinS.\nC-12.44 LetSbeasequenceofnintegers.Describeamethodforprintingoutallthepairs\nofinversionsinSinO(n+k)time,wherekisthenumberofsuchinversions.\nC-12.45 Let S be a random permutation of n distinct integers. Argue that the expected\nrunningtimeofinsertion-sortonSis\u2126(n2). (Hint:Notethathalfoftheelements\nrankedinthetophalfofasortedversionofSareexpectedtobeinthefirsthalf\nofS.)\nC-12.46 LetAandB betwosequencesofnintegerseach. Givenan integerm, describe\nanO(nlogn)-timealgorithmfordeterminingifthereisanintegerainAandan\nintegerbinBsuchthatm=a+b.\nwww.it-ebooks.info\n570 Chapter12. SortingandSelection\nC-12.47 Given two sets A and B represented as sorted sequences, describe an efficient\nalgorithmforcomputingA B, whichis the setof elementsthatare in A or B,\n\u2295\nbutnotinboth.\nC-12.48 Given a set of n integers, describe and analyze a fast method for finding the\nlogn integersclosesttothemedian.\n\u2308 \u2309\nC-12.49 Bob has a set A of n nuts and a set B of n bolts, such that each nut in A has a\nuniquematchingboltinB. Unfortunately,thenutsinAalllookthesame,andthe\nboltsinBalllookthesameaswell. TheonlykindofacomparisonthatBobcan\nmakeistotakeanut-boltpair(a,b),suchthataisinAandbisinB,andtestit\ntosee ifthethreadsofaarelarger,smaller,ora perfectmatchwiththethreads\nofb. DescribeandanalyzeanefficientalgorithmforBobtomatchupallofhis\nnutsandbolts.\nC-12.50 Our quick-select implementation can be made more space-efficient by initially\ncomputingonlythecountsforsetsL,E,andG,andcreatingonlythenewsubset\nthatwillbeneededforrecursion.Implementsuchaversion.\nC-12.51 Describeanin-placeversionofthequick-selectalgorithminpseudocode,assum-\ningthatyouareallowedtomodifytheorderofelements.\nC-12.52 ShowhowtouseadeterministicO(n)-timeselectionalgorithmtosortasequence\nofnelementsinO(nlogn)-worst-casetime.\nC-12.53 GivenanunsortedsequenceSofncomparableelements,andanintegerk,givean\nO(nlogk)-expected-timealgorithmforfindingtheO(k)elementsthathaverank\nn/k ,2 n/k ,3 n/k ,andsoon.\n\u2308 \u2309 \u2308 \u2309 \u2308 \u2309\nC-12.54 Spacealienshavegivenusamethod,alienSplit,thatcantakeasequenceSofn\nintegersandpartitionSinO(n)timeintosequencesS ,S ,...,S ofsizeatmost\n1 2 k\nn/k each,suchthattheelementsinS arelessthanorequaltoeveryelementin\ni\n\u2308 \u2309\nS ,fori=1,2,...,k 1,forafixednumber,k<n.ShowhowtousealienSplit\ni+1\n\u2212\ntosortSinO(nlogn/logk)time.\nC-12.55 Showthatrandomizedquick-sortrunsinO(nlogn)timewithprobabilityatleast\n1 1/n,thatis,withhighprobability,byansweringthefollowing:\n\u2212\na. Foreachinputelementx,defineC (x)tobea0/1randomvariablethatis\ni,j\n1ifandonlyifelementxisin j+1subproblemsthathavesizessuchthat\n(3/4)i+1n<s (3/4)in. ArguewhyweneednotdefineC for j>n.\ni,j\n\u2264\nb. LetX be anindependent0/1randomvariablethatis 1 with probability\ni,j\n1/2j,andletL= log n .Arguethat\u2211L\u22121\u2211n C (x) \u2211L\u22121\u2211n X .\n\u2308 4/3 \u2309 i=0 j=0 i,j \u2264 i=0 j=0 i,j\nc. Showthattheexpectedvalueof\u2211L\u22121\u2211n X is(2 1/2n)L.\ni=0 j=0 i,j \u2212\nd. Show that the probabilitythat \u2211L \u2211n X >4L is at most 1/n2, using\ni=0 j=0 i,j\nthe Chernoff bound that states that if X is the sum of a finite number\nof independent0/1 random variables, having expected value \u00b5>0, then\nPr(X >2\u00b5)<(4/e) \u2212\u00b5,wheree=2.71828128....\ne. Arguethatrandomizedquick-sortrunsinO(nlogn)timewithprobability\natleast1 1/n.\n\u2212\nwww.it-ebooks.info\n12.6. Exercises 571\nC-12.56 We canmakethequick-selectalgorithmdeterministic,bychoosingthepivotof\nann-elementsequenceasfollows:\nPartitionthesetSinto n/5 groupsofsize5each(exceptpossibly\n\u2308 \u2309\nforonegroup).Sorteachlittlesetandidentifythemedianelementin\nthisset. Fromthissetof n/5 \u201cbaby\u201dmedians,applytheselection\n\u2308 \u2309\nalgorithmrecursivelyto find the median of the baby medians. Use\nthiselementasthepivotandproceedasinthequick-selectalgorithm.\nShowthatthisdeterministicquick-selectalgorithmrunsinO(n)timebyanswer-\ningthefollowingquestions(pleaseignorefloorandceilingfunctionsifthatsim-\nplifiesthemathematics,fortheasymptoticsarethesameeitherway):\na. Howmanybabymediansarelessthanorequaltothechosenpivot? How\nmanyaregreaterthanorequaltothepivot?\nb. For each baby median less than or equal to the pivot, how many other\nelements are less than or equal to the pivot? Is the same true for those\ngreaterthanorequaltothepivot?\nc. Argue why the method for finding the deterministic pivot and using it to\npartitionStakesO(n)time.\nd. Basedontheseestimates,writearecurrenceequationtoboundtheworst-\ncase runningtimet(n)forthis selectionalgorithm(notethatin the worst\ncasetherearetworecursivecalls\u2014onetofindthemedianofthebabyme-\ndiansandonetorecuronthelargerofLandG).\ne. Usingthisrecurrenceequation,showbyinductionthatt(n)isO(n).\nC-12.57 SupposeweareinterestedindynamicallymaintainingasetSofintegers,which\nisinitiallyempty,whilesupportingthefollowingtwooperations:\nadd(v): AddsvaluevtosetS.\nmedian(): Returnsthe currentmedian valueof the set. For a set with\nevencardinality,wedefinethemedianastheaverageofthe\ntwomostcentralvalues.\nWewillstoreeachelementofthesetinoneoftwopriorityqueues:amin-oriented\npriority queue, Q+, of all elements greater than or equal to the currentmedian\nvalue,andamax-orientedpriorityqueue,Q\u2212,ofallelementslessthanthecurrent\nmedianvalue.\na. Explainhowtoperformtheoperationmedian()inO(1)timegivensucha\nrepresentation.\nb. ExplainhowtoperformtheoperationS.add(k)inO(logn)time,wherenis\nthecurrentcardinalityoftheset,whilemaintainingsucharepresentation.\nC-12.58 As a generalization of the previous problem, revisit Exercise C-11.45, which\ninvolvesperforminggeneralselectionqueriesonadynamicsetofvalues.\nwww.it-ebooks.info\n572 Chapter12. SortingandSelection\nProjects\nP-12.59 Implement a nonrecursive, in-place version of the quick-sort algorithm, as de-\nscribedattheendofSection12.2.2.\nP-12.60 Experimentallycomparetheperformanceofin-placequick-sortandaversionof\nquick-sortthatisnotin-place.\nP-12.61 Performaseriesofbenchmarkingtestsonaversionofmerge-sortandquick-sort\nto determine which one is faster. Your tests should include sequences that are\n\u201crandom\u201daswellas\u201calmost\u201dsorted.\nP-12.62 Implement deterministic and randomized versions of the quick-sort algorithm\nandperformaseriesofbenchmarkingteststoseewhichoneisfaster. Yourtests\nshouldincludesequencesthatarevery\u201crandom\u201dlookingaswellasonesthatare\n\u201calmost\u201dsorted.\nP-12.63 Implementanin-placeversionofinsertion-sortandanin-placeversionofquick-\nsort. Perform benchmarkingtests to determine the range of values of n where\nquick-sortisonaveragebetterthaninsertion-sort.\nP-12.64 Design and implement a version of the bucket-sort algorithm for sorting a list\nof n entries with integer keys taken from the range [0,N 1], for N 2. The\n\u2212 \u2265\nalgorithmshouldruninO(n+N)time.\nP-12.65 Implementananimationofoneofthesortingalgorithmsdescribedinthischap-\nter,illustratingkeypropertiesofthealgorithminanintuitivemanner.\nP-12.66 Design and implement two versions of the bucket-sort algorithm in Java, one\nforsortinganarrayofbytevaluesandoneforsortinganarrayofshortvalues.\nExperimentallycomparethe performanceof your implementationswith that of\nthemethod,java.util.Arrays.sort.\nChapter Notes\nKnuth\u2019s classic text on Sorting and Searching [61] contains an extensive history of the\nsorting problem and algorithms for solving it. Huang and Langston [49] show how to\nmerge two sorted lists in-place in linear time. The standard quick-sort algorithm is due\nto Hoare [45]. Several optimizations for quick-sort are described by Bentley and McIl-\nroy [15]. More information about randomized algorithms can be found in the book by\nMotwaniand Raghavan[75]. The quick-sortanalysisgivenin this chapteris a combina-\ntionoftheanalysisgiveninanearlierJavaeditionofthisbookandtheanalysisofKleinberg\nand Tardos[57]. Exercise C-12.33is due to Littman. GonnetandBaeza-Yates[38] ana-\nlyzeandcompareexperimentallyseveralsortingalgorithms.Theterm\u201cprune-and-search\u201d\ncomesoriginallyfromthecomputationalgeometryliterature(suchasintheworkofClark-\nson[22]andMegiddo[70]). Theterm\u201cdecrease-and-conquer\u201disfromLevitin[66].\nwww.it-ebooks.info\nChapter\n13\nText Processing\nContents\n13.1 Abundance of Digitized Text . . . . . . . . . . . . . . . . . 574\n13.1.1 Notations for Character Strings . . . . . . . . . . . . . . . 575\n13.2 Pattern-Matching Algorithms . . . . . . . . . . . . . . . . . 576\n13.2.1 Brute Force . . . . . . . . . . . . . . . . . . . . . . . . . 576\n13.2.2 The Boyer-Moore Algorithm . . . . . . . . . . . . . . . . 578\n13.2.3 The Knuth-Morris-Pratt Algorithm . . . . . . . . . . . . . 582\n13.3 Tries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 586\n13.3.1 Standard Tries . . . . . . . . . . . . . . . . . . . . . . . . 586\n13.3.2 Compressed Tries . . . . . . . . . . . . . . . . . . . . . . 590\n13.3.3 Suffix Tries . . . . . . . . . . . . . . . . . . . . . . . . . 592\n13.3.4 Search Engine Indexing . . . . . . . . . . . . . . . . . . . 594\n13.4 Text Compression and the Greedy Method . . . . . . . . . 595\n13.4.1 The Huffman Coding Algorithm . . . . . . . . . . . . . . 596\n13.4.2 The Greedy Method . . . . . . . . . . . . . . . . . . . . . 597\n13.5 Dynamic Programming . . . . . . . . . . . . . . . . . . . . 598\n13.5.1 Matrix Chain-Product . . . . . . . . . . . . . . . . . . . . 598\n13.5.2 DNA and Text Sequence Alignment . . . . . . . . . . . . 601\n13.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605\nwww.it-ebooks.info\n574 Chapter13. TextProcessing\n13.1 Abundance of Digitized Text\nDespite the wealth of multimedia information, text processing remains one of the\ndominant functions of computers. Computers are used to edit, store, and display\ndocuments,andtotransportfilesovertheInternet. Furthermore,digitalsystemsare\nusedtoarchiveawiderangeoftextualinformation,andnewdataisbeinggenerated\nat arapidly increasing pace. A large corpus can readily surpass apetabyte of data\n(which is equivalent to a thousand terabytes, or a million gigabytes). Common\nexamplesofdigitalcollections thatincludetextualinformation are:\nSnapshotsoftheWorldWideWeb,asInternetdocumentformatsHTMLand\n\u2022\nXMLareprimarilytextformats,withaddedtagsformultimediacontent\nAlldocuments storedlocallyonauser\u2019scomputer\n\u2022\nEmailarchives\n\u2022\nCompilations ofstatusupdates onsocialnetworking sitessuchasFacebook\n\u2022\nFeedsfrommicroblogging sitessuchasTwitterandTumblr\n\u2022\nThese collections include written text from hundreds of international languages.\nFurthermore, thereare large datasets (such asDNA)thatcanbeviewed computa-\ntionally as\u201cstrings\u201d eventhoughtheyarenotlanguage.\nIn this chapter, we explore some of the fundamental algorithms that can be\nusedtoefficientlyanalyzeandprocesslargetextualdatasets. Inadditiontohaving\ninteresting applications, text-processing algorithms also highlight some important\nalgorithmic designpatterns.\nWe begin by examining the problem of searching for a pattern as a substring\nof a larger piece of text, for example, when searching for a word in a document.\nThe pattern-matching problem gives rise to the brute-force method, which is of-\nten inefficient but has wide applicability. We continue by describing more effi-\ncientalgorithmsforsolvingthepattern-matchingproblem,andweexamineseveral\nspecial-purpose data structures that can be used to better organize textual data in\nordertosupportmoreefficientruntimequeries.\nBecause of the massive size of textual data sets, the issue of compression is\nimportant, both in minimizing the number of bits that need to be communicated\nthrough a network and to reduce the long-term storage requirements for archives.\nFor text compression, we can apply the greedy method, which often allows us to\napproximate solutions to hard problems, and for some problems (such as in text\ncompression) actuallygivesrisetooptimalalgorithms.\nFinally,weintroducedynamicprogramming,analgorithmictechniquethatcan\nbeappliedincertainsettingstosolveaprobleminpolynomialtime,whichappears\natfirsttorequireexponential timetosolve. Wedemonstrate theapplication onthis\ntechnique to the problem of finding partial matches between strings that may be\nsimilarbutnotperfectlyaligned. Thisproblemariseswhenmakingsuggestionsfor\namisspelled word,orwhentryingtomatchrelated geneticsamples.\nwww.it-ebooks.info\n13.1. AbundanceofDigitizedText 575\n13.1.1 Notations for Character Strings\nWhendiscussingalgorithmsfortextprocessing,weusecharacterstringsasamodel\nfor text. Character strings can come from a wide variety of sources, including\nscientific, linguistic, andInternet applications. Indeed, the following areexamples\nofsuchstrings:\nS = \"CGTAAACTGCTTTAATCAAACGC\"\nT = \"http://www.wiley.com\"\nThe first string, S, comes from DNA applications, and the second string, T, is the\nInternetaddress (URL)forthepublisher ofthisbook.\nTo allow fairly general notions of a string in our algorithm descriptions, we\nonly assume that characters of a string come from a known alphabet, which we\ndenote as \u03a3. For example, in the context of DNA, there are four symbols in the\nstandard alphabet, \u03a3= A,C,G,T . Thisalphabet \u03a3can, ofcourse, beasubset of\n{ }\nthe ASCIIorUnicode character sets, but itcould also be something more general.\nAlthoughweassumethatanalphabethasafixedfinitesize,denotedas \u03a3 ,thatsize\n| |\ncan be nontrivial, as with Java\u2019s treatment of the Unicode alphabet, which allows\nmore than amillion distinct characters. Wetherefore consider the impact of \u03a3 in\n| |\nourasymptotic analysisoftext-processing algorithms.\nJava\u2019s String class provides support for representing an immutable sequence\nof characters, while its StringBuilder class supports mutable character sequences\n(see Section 1.3). For much of this chapter, we rely on the more primitive rep-\nresentation of a string as a char array, primarily because it allows us to use the\nstandard indexing notation S[i], rather than the String class\u2019s more cumbersome\nsyntax, S.charAt(i).\nInordertodiscusspiecesofastring,wedenoteasasubstringofann-character\nstringPastringoftheformP[i]P[i+1]P[i+2] P[j],forsome0 i j n 1.\n\u00b7\u00b7\u00b7 \u2264 \u2264 \u2264 \u2212\nTo simplify the notation for referring to such substrings in prose, we let P[i..j]\ndenote the substring of P from index i to index j inclusive. We note that string is\ntechnically a substring of itself (taking i=0 and j=n 1), so if we want to rule\n\u2212\nthisout asapossibility, wemustrestrict thedefinition toproper substrings, which\nrequirethateitheri>0or j<n 1. Weusetheconventionthatifi> j,thenP[i..j]\n\u2212\nisequaltothenullstring,whichhaslength0.\nInaddition, inordertodistinguishsomespecialkindsofsubstrings, letusrefer\nto any substring of the form P[0..j], for 0 j n 1, as a prefix of P, and any\n\u2264 \u2264 \u2212\nsubstring oftheformP[i..n 1],for0 i n 1,asasuffixofP. Forexample,if\n\u2212 \u2264 \u2264 \u2212\nweagain take P to be the string of DNAgiven above, then \"CGTAA\"is a prefix of\nP,\"CGC\"isasuffixofP,and\"TTAATC\"isa(proper)substring ofP. Notethatthe\nnullstringisaprefixandasuffixofanyotherstring.\nwww.it-ebooks.info\n576 Chapter13. TextProcessing\n13.2 Pattern-Matching Algorithms\nIn the classic pattern-matching problem, we are given a text string of length n\nand a pattern string of length m n, and must determine whether the pattern is a\n\u2264\nsubstring ofthetext. Ifso,wemaywanttofindthelowestindex withinthetextat\nwhichthepatternbegins,orperhapsallindicesatwhichthepattern begins.\nThe pattern-matching problem is inherent to many behaviors of Java\u2019s String\nclass, such as text.contains(pattern) and text.indexOf(pattern), and is a subtask\nof more complex string operations such as text.replace(pattern, substitute) and\ntext.split(pattern).\nIn this section, we present three pattern-matching algorithms, with increasing\nlevels ofsophistication. Ourimplementations report theindex that begins the left-\nmostoccurrence ofthepattern, iffound. Forafailedsearch, weadopttheconven-\ntionsoftheindexOfmethodofJava\u2019sStringclass,returning 1asasentinel.\n\u2212\n13.2.1 Brute Force\nThe brute-force algorithmic design pattern is a powerful technique for algorithm\ndesignwhenwehavesomethingwewishtosearchfororwhenwewishtooptimize\nsome function. When applying this technique in a general situation, we typically\nenumerateallpossibleconfigurations oftheinputsinvolvedandpickthebestofall\ntheseenumeratedconfigurations.\nIn applying this technique to design a brute-force pattern-matching algorithm,\nwederivewhatisprobablythefirstalgorithmthatwemightthinkofforsolvingthe\nproblem\u2014we simply test all the possible placements of the pattern relative to the\ntext. Animplementation ofthisalgorithm isshowninCodeFragment13.1.\n1 /\u2217\u2217 Returns the lowest index at which substring pattern begins in text (or else 1).\u2217/\n\u2212\n2 public static int findBrute(char[ ] text, char[ ] pattern)\n{\n3 int n = text.length;\n4 int m = pattern.length;\n5 for (int i=0; i <= n m; i++) // try every starting index within text\n\u2212 {\n6 int k = 0; // k is index into pattern\n7 while (k < m && text[i+k] == pattern[k])// kth character of pattern matches\n8 k++;\n9 if (k == m) // if we reach the end of the pattern,\n10 return i; // substring text[i..i+m-1] is a match\n11\n}\n12 return 1; // search failed\n\u2212\n13\n}\nCodeFragment13.1: Animplementation ofthebrute-force pattern-matching algo-\nrithm. (Weusecharacter arraysratherthanstrings tosimplifyindexingnotation.)\nwww.it-ebooks.info\n13.2. Pattern-MatchingAlgorithms 577\nPerformance\nThe analysis of the brute-force pattern-matching algorithm could not be simpler.\nIt consists of two nested loops, with the outer loop indexing through all possible\nstarting indices ofthepattern inthetext, andtheinner loopindexing through each\ncharacter of the pattern, comparing it to its potentially corresponding character\nin the text. Thus, the correctness of the brute-force pattern-matching algorithm\nfollowsimmediatelyfromthisexhaustive searchapproach.\nTherunningtimeofbrute-force patternmatchingintheworstcaseisnotgood,\nhowever,becausewecanperformuptomcharactercomparisonsforeachcandidate\nalignment of the pattern within the text. Referring to Code Fragment 13.1, wesee\nthattheouterforloopisexecutedatmostn m+1times,andtheinnerwhileloop\n\u2212\nis executed at most m times. Thus, the worst-case running time of the brute-force\nmethodisO(nm).\nExample 13.1: Supposewearegiventhetextstring\ntext = \"abacaabaccabacabaabb\"\nandthepatternstring\npattern = \"abacab\"\nFigure13.1illustratestheexecutionofthebrute-forcepattern-matchingalgorithm\nonthisselectionoftextandpattern.\nText: a b a c a a b a c c a b a c a b a a b b\n1 2 3 4 5 6\nPattern: a b a c a b\n7\na b a c a b\n8 9\na b a c a b\n10\na b a c a b\n11comparisonsnotshown\n22 23 24 25 26 27\na b a c a b\nFigure13.1: Examplerunofthebrute-force pattern-matching algorithm. Thealgo-\nrithmperforms27character comparisons, indicated abovewithnumericallabels.\nwww.it-ebooks.info\n578 Chapter13. TextProcessing\n13.2.2 The Boyer-Moore Algorithm\nAtfirst,itmightseem thatitisalwaysnecessary toexamineeverycharacter inthe\ntextinordertolocateapatternasasubstringortoruleoutitsexistence. Butthisis\nnotalwaysthecase. TheBoyer-Moore pattern-matching algorithm, whichwewill\nstudy in this section, can sometimes avoid examining a significant fraction of the\ncharacter in the text. In this section, we will describe a simplified version of the\noriginal algorithm byBoyerandMoore.\nThemainideaoftheBoyer-Moorealgorithm istoimprovetherunningtimeof\nthebrute-forcealgorithmbyaddingtwopotentiallytime-savingheuristics. Roughly\nstated, theseheuristics areasfollows:\nLooking-GlassHeuristic: Whentestingapossibleplacementofthepatternagainst\nthetext,performthecomparisons againstthepatternfromright-to-left.\nCharacter-JumpHeuristic: Duringthetestingofapossible placement ofthepat-\nternwithinthetext,amismatchofcharactertext[i]=cwiththecorresponding\ncharacter pattern[k]ishandled asfollows. Ifcisnotcontained anywhere in\nthe pattern, then shift the pattern completely past text[i] = c. Otherwise,\nshiftthepattern untilanoccurrence ofcharactercgetsalignedwithtext[i].\nWewillformalize theseheuristics shortly, butatanintuitivelevel,theyworkasan\nintegrated team to allow us to avoid comparisons with whole groups of characters\ninthetext. Inparticular,whenamismatchisfoundneartherightendofthepattern,\nwemayenduprealigningthepatternbeyondthemismatch,withouteverexamining\nseveral characters of the text preceding the mismatch. For example, Figure 13.2\ndemonstrates a few simple applications of these heuristics. Notice that when the\ncharacterseandimismatchattherightendoftheoriginalplacementofthepattern,\nweslide thepattern beyond themismatched character, without everexamining the\nfirstfourcharacters ofthetext.\nText: \u00b7 \u00b7 \u00b7 \u00b7 e \u00b7 \u00b7 \u00b7 \u00b7 s \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nPattern: s u s h i\ns u s h i\ns u s h i\nFigure 13.2: A simple example demonstrating the intuition of the Boyer-Moore\npattern-matching algorithm. The original comparison results in a mismatch with\ncharacter eof thetext. Because that character isnowhere inthe pattern, the entire\npattern is shifted beyond its location. The second comparison is also a mismatch,\nbutthemismatchedcharactersoccurselsewhereinthepattern. Thepatternisthen\nshifted so that its last occurrence of s is aligned with the corresponding s in the\ntext. Theremainderoftheprocessisnotillustrated inthisfigure.\nwww.it-ebooks.info\n13.2. Pattern-MatchingAlgorithms 579\nTheexampleofFigure13.2isratherbasic,becauseitonlyinvolvesmismatches\nwith the last character of the pattern. More generally, when a match is found for\nthat last character, the algorithm continues by trying to extend the match with the\nsecond-to-lastcharacterofthepatterninitscurrentalignment. Thatprocesscontin-\nues until either matching the entire pattern, orfinding amismatch atsomeinterior\nposition ofthepattern.\nIfamismatchisfound,andthemismatchedcharacterofthetextdoesnotoccur\nin the pattern, we shift the entire pattern beyond that location, as originally illus-\ntrated inFigure 13.2. Ifthe mismatched character occurs elsewhere inthe pattern,\nwe must consider two possible subcases depending on whether its last occurrence\nisbeforeorafterthecharacterofthepatternthatwasmismatched. Thosetwocases\nareillustrated inFigure13.3.\nIn the case of Figure 13.3(b), we slide the pattern only one unit. It would\nbe more productive to slide it rightward until finding another occurrence of mis-\nmatched character text[i] in the pattern, but we do not wish to take time to search\nText: \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 a \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\n\u2032\ni i\nPattern: \u00b7 a \u00b7 \u00b7 b \u00b7\n(a) j k\nm\u2212(j+1)\n\u00b7 a \u00b7 \u00b7 b \u00b7\nj+1\nText: \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 a \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\n\u2032\ni i\nPattern: \u00b7 \u00b7 \u00b7 \u00b7 b a\n(b) k j\nm\u2212k\n\u00b7 \u00b7 \u00b7 \u00b7 b a\nk\nFigure13.3: Additional rules for the character-jump heuristic of the Boyer-Moore\nalgorithm. We let i represent the index of the mismatched character in the text, k\nrepresent the corresponding index in the pattern, and j represent the index of the\nlast occurrence of text[i] within the pattern. We distinguish two cases: (a) j <k,\nin which case we shift the pattern by k j units, and thus, index i advances by\n\u2212\nm (j+1) units; (b) j >k, in which case we shift the pattern by one unit, and\n\u2212\nindexiadvances bym kunits.\n\u2212\nwww.it-ebooks.info\n580 Chapter13. TextProcessing\nfor another occurrence. The efficiency of the Boyer-Moore algorithm relies on\nquickly determining where a mismatched character occurs elsewhere in the pat-\ntern. Inparticular, wedefineafunctionlast(c)as\nIfcisinthepattern, last(c)istheindexofthelast(rightmost) occurrence of\n\u2022\ncinthepattern. Otherwise,weconventionally definelast(c)= 1.\n\u2212\nIfweassumethatthealphabetisoffixed,finitesize,andthatcharacterscanbe\nconverted to indices of an array (for example, by using their character code), the\nlast function can be easily implemented as a lookup table with worst-case O(1)-\ntimeaccesstothevaluelast(c). However,thetablewouldhavelengthequaltothe\nsizeofthealphabet(ratherthanthesizeofthepattern),andtimewouldberequired\ntoinitialize theentiretable.\nWe prefer to use a hash table to represent the last function, with only those\ncharactersfromthepatternoccurringinthemap. Thespaceusageforthisapproach\nisproportional tothenumberofdistinctalphabetsymbolsthatoccurinthepattern,\nand thus O(max(m, \u03a3 )). The expected lookup time remains O(1) (as does the\n| |\nworst-case, if we consider \u03a3 a constant). Our complete implementation of the\n| |\nBoyer-Moore pattern-matching algorithm isgiveninCodeFragment13.2.\n1 /\u2217\u2217 Returns the lowest index at which substring pattern begins in text (or else 1).\u2217/\n\u2212\n2 public static int findBoyerMoore(char[ ] text, char[ ] pattern)\n{\n3 int n = text.length;\n4 int m = pattern.length;\n5 if (m == 0) return 0; // trivial search for empty string\n6 Map<Character,Integer> last = new HashMap<>(); // the 'last' map\n7 for (int i=0; i < n; i++)\n8 last.put(text[i], 1); // set 1 as default for all text characters\n\u2212 \u2212\n9 for (int k=0; k < m; k++)\n10 last.put(pattern[k], k); // rightmost occurrence in pattern is last\n11 // start with the end of the pattern aligned at index m 1 of the text\n\u2212\n12 int i = m 1; // an index into the text\n\u2212\n13 int k = m 1; // an index into the pattern\n\u2212\n14 while (i < n)\n{\n15 if (text[i] == pattern[k]) // a matching character\n{\n16 if (k == 0) return i; // entire pattern has been found\n17 i ; // otherwise, examine previous\n\u2212\u2212\n18 k ; // characters of text/pattern\n\u2212\u2212\n19 else\n} {\n20 i += m Math.min(k, 1 + last.get(text[i])); // case analysis for jump step\n\u2212\n21 k = m 1; // restart at end of pattern\n\u2212\n22\n}\n23\n}\n24 return 1; // pattern was never found\n\u2212\n25\n}\nCodeFragment13.2: Animplementation oftheBoyer-Moore algorithm.\nwww.it-ebooks.info\n13.2. Pattern-MatchingAlgorithms 581\nThe correctness of the Boyer-Moore pattern-matching algorithm follows from\nthefactthateachtimethemethodmakesashift,itisguaranteed notto\u201cskip\u201dover\nany possible matches. For last(c) is the location of the last occurrence of c in the\npattern. In Figure 13.4, we illustrate the execution of the Boyer-Moore pattern-\nmatchingalgorithm onaninputstringsimilartoExample13.1.\nc a b c d\nlast(c) 4 5 3 1\n\u2212\nText: a b a c a a b a d c a b a c a b a a b b\n1\nPattern: a b a c a b\n4 3 2 13 12 11 10 9 8\na b a c a b a b a c a b\n5 7\na b a c a b a b a c a b\n6\na b a c a b\nFigure 13.4: An illustration of the Boyer-Moore pattern-matching algorithm, in-\ncluding a summary of the last(c) function. The algorithm performs 13 character\ncomparisons, whichareindicated withnumericallabels.\nPerformance\nIfusingatraditionallookuptable,theworst-caserunningtimeoftheBoyer-Moore\nalgorithm is O(nm+ \u03a3 ). The computation of the last function takes O(m+ \u03a3 )\n| | | |\ntime, although the dependence on \u03a3 is removed if using a hash table. The actual\n| |\nsearch for the pattern takes O(nm) time in the worst case\u2014the same as the brute-\nforcealgorithm. AnexamplethatachievestheworstcaseforBoyer-Moore is\nn\ntext = aaaaaa a\n\u00b7\u00b7\u00b7\nm\u22121\npattern = zbaa }|a {\n\u00b7\u00b7\u00b7\nThe worst-case performance, however, is unlikely to be achieved for English text;\nz }| {\ninthatcase, theBoyer-Moore algorithm isoftenabletoskiplargeportions oftext.\nExperimental evidence on English text shows that the average number of compar-\nisonsdonepercharacter is0.24forafive-character patternstring.\nWehaveactuallypresentedasimplifiedversionoftheBoyer-Moorealgorithm.\nThe original algorithm achieves worst-case running time O(n+m+ \u03a3 ) by using\n| |\nan alternative shift heuristic for a partially matched text string, whenever it shifts\nthe pattern more than the character-jump heuristic. This alternative shift heuristic\nis based on applying the main idea from the Knuth-Morris-Pratt pattern-matching\nalgorithm, whichwediscussnext.\nwww.it-ebooks.info\n582 Chapter13. TextProcessing\n13.2.3 The Knuth-Morris-Pratt Algorithm\nIn examining the worst-case performances of the brute-force and Boyer-Moore\npattern-matchingalgorithmsonspecificinstancesoftheproblem,suchasthatgiven\ninExample13.1,weshould noticeamajorinefficiency (atleastintheworstcase).\nFor a certain alignment of the pattern, if we find several matching characters but\nthen detect a mismatch, we ignore all the information gained by the successful\ncomparisons afterrestarting withthenextincremental placementofthepattern.\nTheKnuth-Morris-Pratt(or\u201cKMP\u201d)algorithm,discussedinthissection,avoids\nthiswasteofinformation and, insodoing, itachieves arunning timeofO(n+m),\nwhich is asymptotically optimal. That is, in the worst case any pattern-matching\nalgorithm will have to examine all the characters of the text and all the characters\nof the pattern at least once. The main idea of the KMP algorithm is to precom-\npute self-overlaps between portions ofthe pattern sothat whenamismatch occurs\nat one location, we immediately know the maximum amount to shift the pattern\nbeforecontinuing thesearch. AmotivatingexampleisshowninFigure13.5.\nText: a t c a m a l g a m a \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nPattern: a m a l g a m a t i o n\na m a l g a m a t i o n\na m a l g a m a t i o n\nFigure13.5: Amotivating examplefortheKnuth-Morris-Pratt algorithm. Ifamis-\nmatch occurs at the indicated location, the pattern could be shifted to the second\nalignment, without explicit need to recheck the partial match with the prefix ama.\nIf the mismatched character is not an l, then the next potential alignment of the\npatterncantakeadvantage ofthecommona.\nThe Failure Function\nToimplement the KMP algorithm, we will precompute a failure function, f, that\nindicates theproper shift ofthepattern upon afailed comparison. Specifically, the\nfailurefunction f(k)isdefinedasthelengthofthelongestprefixofthepatternthat\nis a suffix of the substring pattern[1..k] (note that we did not include pattern[0]\nhere, since wewill shift at least one unit). Intuitively, if wefind a mismatch upon\ncharacter pattern[k+1], the function f(k) tells us how many of the immediately\npreceding characters can be reused to restart the pattern. Example 13.2 describes\nthevalueofthefailure functionfortheexamplepatternfromFigure13.5.\nwww.it-ebooks.info\n13.2. Pattern-MatchingAlgorithms 583\nExample 13.2: Considerthepattern\"amalgamation\" fromFigure13.5. The\nKnuth-Morris-Pratt(KMP)failurefunction, f(k),forthestringP isasshownin\nthefollowingtable:\nk 0 1 2 3 4 5 6 7 8 9 10 11\nP[k] a m a l g a m a t i o n\nf(k) 0 0 1 0 0 1 2 3 0 0 0 0\nImplementation\nOur implementation of the KMP pattern-matching algorithm is shown in Code\nFragment 13.3. It relies on a utility method, computeFailKMP, discussed on the\nnextpage,tocomputethefailurefunction efficiently.\nThe mainpart of the KMPalgorithm isits whileloop, each iteration of which\nperformsacomparisonbetweenthecharacteratindex jinthetextandthecharacter\natindexkinthepattern. Iftheoutcomeofthiscomparisonisamatch,thealgorithm\nmoves on to the next characters in both (or reports a match if reaching the end of\nthe pattern). If the comparison failed, the algorithm consults the failure function\nforanewcandidatecharacterinthepattern,orstartsoverwiththenextindexinthe\ntextiffailingonthefirstcharacter ofthepattern(sincenothingcanbereused).\n1 /\u2217\u2217 Returns the lowest index at which substring pattern begins in text (or else 1).\u2217/\n\u2212\n2 public static int findKMP(char[ ] text, char[ ] pattern)\n{\n3 int n = text.length;\n4 int m = pattern.length;\n5 if (m == 0) return 0; // trivial search for empty string\n6 int[ ] fail = computeFailKMP(pattern); // computed by private utility\n7 int j = 0; // index into text\n8 int k = 0; // index into pattern\n9 while (j < n)\n{\n10 if (text[j] == pattern[k]) // pattern[0..k] matched thus far\n{\n11 if (k == m 1) return j m + 1; // match is complete\n\u2212 \u2212\n12 j++; // otherwise, try to extend match\n13 k++;\n14 else if (k > 0)\n}\n15 k = fail[k 1]; // reuse suffix of P[0..k-1]\n\u2212\n16 else\n17 j++;\n18\n}\n19 return 1; // reached end without match\n\u2212\n20\n}\nCodeFragment13.3: Animplementation ofthe KMP pattern-matching algorithm.\nThecomputeFailKMPutilitymethodisgiveninCodeFragment13.4.\nwww.it-ebooks.info\n584 Chapter13. TextProcessing\nConstructing the KMP Failure Function\nToconstructthefailurefunction,weusethemethodshowninCodeFragment13.4,\nwhichisa\u201cbootstrapping\u201dprocessthatcomparesthepatterntoitselfasintheKMP\nalgorithm. Eachtimewehavetwocharactersthatmatch,weset f(j)=k+1. Note\nthat since we have j > k throughout the execution of the algorithm, f(k 1) is\n\u2212\nalwayswelldefinedwhenweneedtouseit.\n1 private static int[ ] computeFailKMP(char[ ] pattern)\n{\n2 int m = pattern.length;\n3 int[ ] fail = new int[m]; // by default, all overlaps are zero\n4 int j = 1;\n5 int k = 0;\n6 while (j < m) // compute fail[j] during this pass, if nonzero\n{\n7 if (pattern[j] == pattern[k]) // k + 1 characters match thus far\n{\n8 fail[j] = k + 1;\n9 j++;\n10 k++;\n11 else if (k > 0) // k follows a matching prefix\n}\n12 k = fail[k 1];\n\u2212\n13 else // no match found starting at j\n14 j++;\n15\n}\n16 return fail;\n17\n}\nCodeFragment13.4:AnimplementationofthecomputeFailKMPutilityinsupport\noftheKMPpattern-matching algorithm. Notehowthealgorithmusestheprevious\nvaluesofthefailurefunction toefficientlycomputenewvalues.\nPerformance\nExcluding the computation of the failure function, the running time of the KMP\nalgorithm isclearly proportional tothenumberofiterations ofthewhileloop. For\nthesake oftheanalysis, letusdefines= j k. Intuitively, sisthetotalamountby\n\u2212\nwhichthepatternhasbeenshiftedwithrespecttothetext. Notethatthroughoutthe\nexecutionofthealgorithm, wehaves n. Oneofthefollowingthreecasesoccurs\n\u2264\nateachiterationoftheloop.\nIftext[j]=pattern[k],then jandkeachincreaseby1,thussisunchanged.\n\u2022\nIf text[j]=pattern[k] and k>0, then j does not change and s increases by\n\u2022 6\nat least 1, since in this case s changes from j k to j f(k 1); note that\n\u2212 \u2212 \u2212\nthisisanaddition ofk f(k 1),whichispositivebecause f(k 1)<k.\n\u2212 \u2212 \u2212\nIftext[j]=pattern[k]andk=0,then j increases by1andsincreases by1,\n\u2022 6\nsincekdoesnotchange.\nwww.it-ebooks.info\n13.2. Pattern-MatchingAlgorithms 585\nThus, at each iteration of the loop, either j or s increases by at least 1 (possibly\nboth); hence, the total number of iterations of the while loop in the KMP pattern-\nmatching algorithm is at most 2n. Achieving this bound, of course, assumes that\nwehavealreadycomputedthefailurefunction forthepattern.\nThealgorithmforcomputingthefailurefunctionrunsinO(m)time. Itsanalysis\nis analogous to that of the main KMP algorithm, yet with a pattern of length m\ncomparedtoitself. Thus,wehave:\nProposition 13.3: TheKnuth-Morris-Prattalgorithmperformspatternmatching\nonatextstringoflengthnandapatternstringoflengthminO(n+m)time.\nThecorrectnessofthisalgorithmfollowsfromthedefinitionofthefailurefunc-\ntion. Any comparisons that are skipped are actually unnecessary, for the failure\nfunction guarantees that all the ignored comparisons are redundant\u2014they would\ninvolve comparingthesamematchingcharacters overagain.\nIn Figure 13.6, we illustrate the execution of the KMP pattern-matching algo-\nrithm on the same input strings as in Example 13.1. Note the use of the failure\nfunction to avoid redoing one of the comparisons between a character of the pat-\nternandacharacterofthetext. Alsonotethatthealgorithmperformsfeweroverall\ncomparisons thanthebrute-force algorithm runonthesamestrings(Figure13.1).\nk 0 1 2 3 4 5\nFailurefunction: pattern[k] a b a c a b\nf(k) 0 0 1 0 1 2\nText: a b a c a a b a c c a b a c a b a a b b\n1 2 3 4 5 6\nPattern: a b a c a b\n7\na b a c a b\n8 9 10 11 12\na b a c a b\nnocomparison\n13\nperformed\na b a c a b\n14 15 16 17 18 19\na b a c a b\nFigure13.6: An illustration of the KMP pattern-matching algorithm. The primary\nalgorithm performs 19character comparisons, whichare indicated withnumerical\nlabels. (Additionalcomparisonswouldbeperformedduringthecomputationofthe\nfailurefunction.)\nwww.it-ebooks.info\n586 Chapter13. TextProcessing\n13.3 Tries\nThepattern-matchingalgorithmspresentedinSection13.2speedupthesearchina\ntextbypreprocessing thepattern(tocomputethelastfunction intheBoyer-Moore\nalgorithm orthefailurefunction intheKnuth-Morris-Pratt algorithm). Inthissec-\ntion, we take a complementary approach, namely, we present string searching al-\ngorithms thatpreprocess thetext,rather thanthepattern. Thisapproach issuitable\nfor applications in which many queries are performed on a fixed text, so that the\ninitial cost of preprocessing the text is compensated by a speedup in each subse-\nquent query (for example, a website that offers pattern matching in Shakespeare\u2019s\nHamletorasearchengine thatoffersWebpagescontaining thetermHamlet).\nA trie (pronounced \u201ctry\u201d) is a tree-based data structure for storing strings in\norder to support fast pattern matching. The main application for tries is in infor-\nmation retrieval. Indeed, the name \u201ctrie\u201d comes from the word \u201cretrieval.\u201d In an\ninformation retrieval application, suchasasearchforacertainDNAsequence ina\ngenomicdatabase,wearegivenacollectionSofstrings,alldefinedusingthesame\nalphabet. Theprimaryqueryoperations thattriessupport arepattern matchingand\nprefixmatching. Thelatter operation involves being givenastring X,andlooking\nforallthestringsinSthatbeingwithX.\n13.3.1 Standard Tries\nLet S be a set of s strings from alphabet \u03a3 such that no string in S is a prefix\nof another string. A standard trie for S is an ordered tree T with the following\nproperties (seeFigure13.7):\nEachnodeofT,excepttheroot,islabeledwithacharacterof\u03a3.\n\u2022\nThechildren ofaninternalnodeofT havedistinct labels.\n\u2022\nT hassleaves,eachassociatedwithastringofS,suchthattheconcatenation\n\u2022\nofthelabelsofthenodesonthepathfromtheroottoaleafvofT yieldsthe\nstringofSassociated withv.\nThus, atrieT represents the strings ofS withpaths from the root tothe leaves\nof T. Note the importance of assuming that no string in S is a prefix of another\nstring. This ensures that each string of S is uniquely associated with a leaf of T.\n(ThisissimilartotherestrictionforprefixcodeswithHuffmancoding,asdescribed\nin Section 13.4.) We can always satisfy this assumption by adding a special char-\nacterthatisnotintheoriginal alphabet\u03a3attheendofeachstring.\nAn internal node in a standard trie T can have anywhere between 1 and \u03a3\n| |\nchildren. There is an edge going from the root r to one of its children for each\ncharacter that is first in some string in the collection S. In addition, a path from\nthe root of T to an internal node v at depth k corresponds to a k-character prefix\nwww.it-ebooks.info\n13.3. Tries 587\nb s\ne i u e t\na l d l y l o\nr l l l c p\nk\nFigure13.7:Standardtrieforthestrings bear,bell,bid,bull,buy,sell,stock,stop .\n{ }\nX[0..k 1]ofastringX ofS. Infact,foreachcharactercthatcanfollowtheprefix\n\u2212\nX[0..k 1] in a string of the set S, there is a child of v labeled with character c.\n\u2212\nIn this way, a trie concisely stores the common prefixes that exist among a set of\nstrings.\nAs a special case, if there are only two characters in the alphabet, then the\ntrie isessentially abinary tree, withsome internal nodes possibly having only one\nchild(thatis,itmaybeanimproperbinarytree). Ingeneral, althoughitispossible\nthat an internal node has up to \u03a3 children, in practice the average degree of such\n| |\nnodes islikely tobemuchsmaller. Forexample, thetrieshowninFigure 13.7has\nseveral internal nodes with only one child. Onlarger data sets, the average degree\nof nodes is likely to get smaller at greater depths of the tree, because there may\nbe fewer strings sharing the common prefix, and thus fewer continuations of that\npattern. Furthermore,inmanylanguages, therewillbecharactercombinations that\nareunlikely tonaturally occur.\nThe following proposition provides some important structural properties of a\nstandard trie:\nProposition 13.4: AstandardtriestoringacollectionSofsstringsoftotallength\nnfromanalphabet\u03a3hasthefollowingproperties:\nTheheightofT isequaltothelengthofthelongeststringinS.\n\u2022\nEveryinternalnodeofT hasatmost \u03a3 children.\n\u2022 | |\nT hassleaves.\n\u2022\nThenumberofnodesofT isatmostn+1.\n\u2022\nThe worst case for the number of nodes of a trie occurs when no two strings\nshare a common nonempty prefix; that is, except for the root, all internal nodes\nhaveonechild.\nwww.it-ebooks.info\n588 Chapter13. TextProcessing\nAtrieT forasetSofstringscanbeusedtoimplementasetormapwhosekeys\nare the strings of S. Namely, we perform a search in T for a string X by tracing\ndown from the root the path indicated by the characters in X. If this path can be\ntracedandterminates ataleafnode,thenweknowX isastringinS. Forexample,\nin the trie in Figure 13.7, tracing the path for \u201cbull\u201d ends up at a leaf. If the path\ncannot be traced or the path can be traced but terminates at an internal node, then\nX is not a string in S. In the example in Figure 13.7, the path for \u201cbet\u201d cannot be\ntraced and the path for \u201cbe\u201d ends at an internal node. Neither such word is in the\nsetS.\nIt is easy to see that the running time of the search for a string of length m is\nO(m \u03a3 ), because we visit at most m+1 nodes of T and we spend O(\u03a3 ) time\n\u00b7| | | |\nateachnodedetermining thechildhaving thesubsequent character asalabel. The\nO(\u03a3 ) upper bound on the time to locate a child with a given label is achievable,\n| |\neven if the children of a node are unordered, since there are at most \u03a3 children.\n| |\nWe can improve the time spent at a node to be O(log \u03a3 ) or expected O(1), by\n| |\nmappingcharacterstochildrenusingasecondarysearchtableorhashtableateach\nnode,orbyusingadirectlookuptableofsize \u03a3 ateachnode,if \u03a3 issufficiently\n| | | |\nsmall (as is the case for DNA strings). For these reasons, we typically expect a\nsearchforastringoflengthmtoruninO(m)time.\nFrom the discussion above, it follows that we can use a trie to perform a spe-\ncial type of pattern matching, called wordmatching, where wewant to determine\nwhetheragivenpattern matchesoneofthewordsofthetextexactly. Wordmatch-\ning differs from standard pattern matching because the pattern cannot match an\narbitrary substring of the text\u2014only one of its words. To accomplish this, each\nwordoftheoriginaldocumentmustbeaddedtothetrie. (SeeFigure13.8.) Asim-\npleextension ofthis scheme supports prefix-matching queries. However, arbitrary\noccurrences ofthepattern inthetext(forexample, thepattern isaproper suffixof\nawordorspanstwowords)cannotbeefficientlyperformed.\nTo construct a standard trie for a set S of strings, we can use an incremental\nalgorithmthatinsertsthestringsoneatatime. Recalltheassumptionthatnostring\nof S is a prefix of another string. To insert a string X into the current trie T, we\ntrace the path associated with X in T, creating a new chain of nodes to store the\nremaining characters of X when we get stuck. The running time to insert X with\nlengthmissimilartoasearch,withworst-caseO(m \u03a3 )performance,orexpected\n\u00b7| |\nO(m)ifusingsecondaryhashtablesateachnode. Thus,constructingtheentiretrie\nforsetStakesexpectedO(n)time,wherenisthetotallengthofthestringsofS.\nThereisapotentialspaceinefficiencyinthestandardtriethathaspromptedthe\ndevelopment of the compressed trie, which is also known (for historical reasons)\nasthePatriciatrie. Namely,therearepotentially alotofnodesinthestandard trie\nthathaveonlyonechild,andtheexistenceofsuchnodesisawaste. Wediscussthe\ncompressed trienext.\nwww.it-ebooks.info\n13.3. Tries 589\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22\ns e e a b e a r ? s e l l s t o c k !\n23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45\ns e e a b u l l ? b u y s t o c k !\n46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68\nb i d s t o c k ! b i d s t o c k !\n69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88\nh e a r t h e b e l l ? s t o p !\n(a)\nb h s\ne i u e e t\na l d l y a e l o\n47,58 36 0,24\nr l l r l c p\n6 78 30 69 12 84\nk\n17,40,51,62\n(b)\nFigure 13.8: Word matching with a standard trie: (a) text to be searched (articles\nandprepositions, whicharealsoknownasstopwords, excluded); (b)standard trie\nfor the words in the text, with leaves augmented with indications of the index at\nwhichthegivenworkbeginsinthetext. Forexample,theleaffortheword\u201cstock\u201d\nnotesthatthewordbeginsatindices 17,40,51,and62ofthetext.\nwww.it-ebooks.info\n590 Chapter13. TextProcessing\n13.3.2 Compressed Tries\nAcompressedtrieissimilartoastandardtriebutitensuresthateachinternalnode\nin the trie has at least two children. It enforces this rule by compressing chains of\nsingle-child nodes into individual edges. (See Figure 13.9.) Let T be a standard\ntrie. Wesaythat aninternal node vof T isredundant ifvhas one child and isnot\nthe root. For example, the trie of Figure 13.7 has eight redundant nodes. Let us\nalsosaythatachainofk 2edges,\n\u2265\n(v ,v )(v ,v ) (v ,v ),\n0 1 1 2 k\u22121 k\n\u00b7\u00b7\u00b7\nisredundantif:\nv isredundant fori=1,...,k 1.\ni\n\u2022 \u2212\nv andv arenotredundant.\n0 k\n\u2022\nWe can transform T into a compressed trie by replacing each redundant chain\n(v ,v ) (v ,v ) of k 2 edges into a single edge (v ,v ), relabeling v with\n0 1 k\u22121 k 0 k k\n\u00b7\u00b7\u00b7 \u2265\ntheconcatenation ofthelabelsofnodesv ,...,v .\n1 k\nb s\ne id u ell to\nar ll ll y ck p\nFigure13.9: Compressed trie for the strings bear, bell, bid, bull, buy, sell, stock,\n{\nstop . (Compare this with the standard trie shown in Figure 13.7.) Notice that, in\n}\nadditiontocompressionattheleaves,theinternalnodewithlabel\u201cto\u201dissharedby\nwords\u201cstock\u201dand\u201cstop\u201d.\nThus,nodesinacompressed triearelabeledwithstrings, whicharesubstrings\nofstringsinthecollection,ratherthanwithindividualcharacters. Theadvantageof\nacompressedtrieoverastandardtrieisthatthenumberofnodesofthecompressed\ntrie is proportional to the number of strings and not to their total length, as shown\ninthefollowingproposition (comparewithProposition 13.4).\nProposition 13.5: AcompressedtriestoringacollectionS ofsstringsfroman\nalphabetofsizedhasthefollowingproperties:\nEveryinternalnodeofT hasatleasttwochildrenandmostdchildren.\n\u2022\nT hassleavesnodes.\n\u2022\nThenumberofnodesofT isO(s).\n\u2022\nwww.it-ebooks.info\n13.3. Tries 591\nThe attentive reader may wonder whether the compression of paths provides\nany significant advantage, since it is offset by a corresponding expansion of the\nnodelabels. Indeed,acompressedtrieistrulyadvantageousonlywhenitisusedas\nanauxiliaryindexstructure overacollection ofstringsalreadystoredinaprimary\nstructure, andisnotrequiredtoactuallystoreallthecharacters ofthestringsinthe\ncollection.\nSuppose,forexample,thatthecollection SofstringsisanarrayofstringsS[0],\nS[1], ..., S[s 1]. Instead of storing the label X of a node explicitly, we represent\n\u2212\nit implicitly by a combination of three integers (i, j,k), such that X = S[i][j..k];\nthatis, X isthesubstring ofS[i]consisting ofthecharacters from the jth tothekth\ninclusive. (See the example in Figure 13.10. Also compare with the standard trie\nofFigure13.8.)\n0 1 2 3 4 0 1 2 3 0 1 2 3\nS[0]= s e e S[4]= b u l l S[7]= h e a r\nS[1]= b e a r S[5]= b u y S[8]= b e l l\nS[2]= s e l l S[6]= b i d S[9]= s t o p\nS[3]= s t o c k\n(a)\n1,0,0 7,0,3 0,0,0\n1,1,1 6,1,2 4,1,1 0,1,1 3,1,2\n1,2,3 8,2,3 4,2,3 5,2,2 0,2,2 2,2,3 3,3,4 9,3,3\n(b)\nFigure13.10: (a) Collection S of strings stored in an array. (b) Compact represen-\ntationofthecompressed trieforS.\nThisadditional compression schemeallowsustoreduce thetotalspace forthe\ntrie itself from O(n) for the standard trie to O(s) for the compressed trie, where n\nis the total length of the strings in S and s is the number of strings in S. We must\nstillstorethedifferent strings inS,ofcourse, butwenevertheless reduce thespace\nforthetrie.\nSearching inacompressed trieisnot necessarily faster than inastandard tree,\nsince there is still need to compare every character of the desired pattern with the\npotentially multicharacter labelswhiletraversing pathsinthetrie.\nwww.it-ebooks.info\n592 Chapter13. TextProcessing\n13.3.3 Suffix Tries\nOne of the primary applications for tries is for the case when the strings in the\ncollectionSareallthesuffixesofastringX. Suchatrieiscalledthesuffixtrie(also\nknown as a suffix tree or position tree) of string X. For example, Figure 13.11a\nshowsthesuffixtriefortheeightsuffixesofstring\u201cminimize.\u201d Forasuffixtrie,the\ncompactrepresentation presented intheprevious sectioncanbefurther simplified.\nNamely, the label of each vertex is a pair \u201cj..k\u201d indicating the string X[j..k]. (See\nFigure 13.11b.) Tosatisfy the rule that no suffix of X is a prefix of another suffix,\nwecanaddaspecialcharacter,denotedwith$,thatisnotintheoriginalalphabet\u03a3\nattheendofX (andthustoeverysuffix). Thatis,ifstringX haslengthn,webuild\natrieforthesetofnstringsX[j..n 1]$,for j=0,...,n 1.\n\u2212 \u2212\nSaving Space\nUsingasuffixtrieallowsustosavespaceoverastandardtriebyusingseveralspace\ncompression techniques, including thoseusedforthecompressed trie.\nTheadvantageofthecompactrepresentationoftriesnowbecomesapparentfor\nsuffixtries. SincethetotallengthofthesuffixesofastringX oflengthnis\nn(n+1)\n1+2+ +n= ,\n\u00b7\u00b7\u00b7 2\nstoring all the suffixes of X explicitly would take O(n2) space. Even so, the suf-\nfix trie represents these strings implicitly in O(n) space, as formally stated in the\nfollowingproposition.\nProposition 13.6: ThecompactrepresentationofasuffixtrieT forastringX of\nlengthnusesO(n)space.\nConstruction\nWe can construct the suffix trie for a string of length n with an incremental algo-\nrithm like the one given in Section 13.3.1. This construction takes O(\u03a3 n2) time\n| |\nbecause the total length of the suffixes is quadratic in n. However, the (compact)\nsuffixtrieforastringoflengthncanbeconstructedinO(n)timewithaspecialized\nalgorithm, different from the one for general tries. This linear-time construction\nalgorithm is fairly complex, however, and is not reported here. Still, we can take\nadvantage oftheexistence ofthisfastconstruction algorithm whenwewanttouse\nasuffixtrietosolveotherproblems.\nwww.it-ebooks.info\n13.3. Tries 593\ne i mi nimize ze\nmize nimize ze nimize ze\n(a)\n7..7 1..1 0..1 2..7 6..7\n4..7 2..7 6..7 2..7 6..7\n0 1 2 3 4 5 6 7\nm i n i m i z e\n(b)\nFigure13.11: (a)SuffixtrieT forthestring X =\"minimize\". (b)Compactrepre-\nsentation ofT,wherepair j..kdenotesthesubstring X[j..k]inthereference string.\nUsing a Suffix Trie\nThesuffixtrieT forastring X canbeusedtoefficientlyperform pattern-matching\nqueries ontextX. Namely, wecandetermine whetherapattern isasubstring ofX\nby trying to trace a path associated with P in T. P is a substring of X if and only\nif such a path can be traced. The search down the trie T assumes that nodes in T\nstore some additional information, with respect to the compact representation of\nthesuffixtrie:\nIf node v has label j..k andY is the string of length y associated with\nthepathfromtheroottov(included), thenX[k y+1..k]=Y.\n\u2212\nThisproperty ensures thatwecancomputethestartindexofthepattern inthetext\nwhenamatchoccursinO(m)time.\nwww.it-ebooks.info\n594 Chapter13. TextProcessing\n13.3.4 Search Engine Indexing\nThe World Wide Web contains a huge collection of text documents (Web pages).\nInformation about these pages are gathered by a program called a Web crawler,\nwhich then stores thisinformation in aspecial dictionary database. A Websearch\nengine allows users to retrieve relevant information from this database, thereby\nidentifying relevant pages on the Web containing given keywords. In this section,\nwewillpresentasimplifiedmodelofasearchengine.\nInverted Files\nThecoreinformationstoredbyasearchengineisamap,calledaninvertedindexor\ninvertedfile,storingkey-valuepairs(w,L),wherewisawordandLisacollection\nof pages containing word w. The keys (words) in this map are called index terms\nandshouldbeasetofvocabularyentriesandpropernounsaslargeaspossible. The\nvaluesinthismaparecalledoccurrencelistsandshouldcoverasmanyWebpages\naspossible.\nWecanefficientlyimplementaninvertedindexwithadatastructureconsisting\nofthefollowing:\n1. Anarraystoringtheoccurrence listsoftheterms(innoparticular order).\n2. Acompressedtrieforthesetofindexterms,whereeachleafstorestheindex\noftheoccurrence listoftheassociated term.\nThereasonforstoring theoccurrence listsoutside thetrieistokeepthesizeofthe\ntrie data structure sufficiently small to fit in internal memory. Instead, because of\ntheirlargetotalsize,theoccurrence listshavetobestoredondisk.\nWith our data structure, a query for a single keyword is similar to a word-\nmatching query (Section 13.3.1). Namely, we find the keyword in the trie and we\nreturntheassociated occurrence list.\nWhen multiple keywords are given and the desired output are the pages con-\ntaining all the given keywords, we retrieve the occurrence list of each keyword\nusing the trie and return their intersection. To facilitate the intersection computa-\ntion,eachoccurrencelistshouldbeimplementedwithasequencesortedbyaddress\norwithamap,toallowefficientsetoperations.\nIn addition to the basic task of returning a list of pages containing given key-\nwords,searchenginesprovideanimportantadditionalservicebyrankingthepages\nreturned by relevance. Devising fast and accurate ranking algorithms for search\nengines is a major challenge for computer researchers and electronic commerce\ncompanies.\nwww.it-ebooks.info\n13.4. TextCompressionandtheGreedyMethod 595\n13.4 Text Compression and the Greedy Method\nIn this section, we will consider the important task of text compression. In this\nproblem, we are given a string X defined over some alphabet, such as the ASCII\norUnicode character sets, andwewanttoefficiently encode X into asmall binary\nstring Y (using only the characters 0 and 1). Text compression is useful in any\nsituation where wewish to reduce bandwidth for digital communications, so asto\nminimizethetimeneededtotransmitourtext. Likewise,textcompressionisuseful\nforstoringlargedocumentsmoreefficiently,soastoallowafixed-capacitystorage\ndevicetocontain asmanydocuments aspossible.\nThemethodfortextcompressionexploredinthissectionistheHuffmancode.\nStandard encoding schemes, such as ASCII, use fixed-length binary strings to en-\ncode characters (with 7 or 8 bits in the traditional or extended ASCII systems,\nrespectively). The Unicode system was originally proposed as a 16-bit fixed-\nlength representation, although common encodings reduce the space usage by al-\nlowing common groups of characters, such as those from the ASCII system, with\nfewer bits. The Huffman code saves space over a fixed-length encoding by using\nshort code-word strings to encode high-frequency characters and long code-word\nstrings to encode low-frequency characters. Furthermore, the Huffman code uses\navariable-length encoding specifically optimized for a given string X over any al-\nphabet. The optimization is based on the use of character frequencies, where we\nhave, for each character c, a count f(c) of the number of times c appears in the\nstringX.\nTo encode the string X, we convert each character in X to a variable-length\ncode-word, and we concatenate all these code-words in order to produce the en-\ncodingY for X. In order to avoid ambiguities, we insist that no code-word in our\nencoding be a prefix of another code-word in our encoding. Such a code is called\naprefixcode,anditsimplifiesthedecoding ofY toretrieveX. (SeeFigure13.12.)\nEven with this restriction, the savings produced by a variable-length prefix code\ncan be significant, particularly if there is a wide variance in character frequencies\n(asisthecasefornaturallanguage textinalmosteverywrittenlanguage).\nHuffman\u2019s algorithm for producing an optimal variable-length prefix code for\nX is based on the construction of a binary tree T that represents the code. Each\nedge inT represents abitinacode-word, withanedge toaleft child representing\na \u201c0\u201d and an edge to a right child representing a \u201c1\u201d. Each leaf v is associated\nwith a specific character, and the code-word for that character is defined by the\nsequence ofbitsassociated withtheedgesinthepathfromtherootofT tov. (See\nFigure13.12.) Eachleafvhasafrequency, f(v),whichissimplythefrequency in\nX ofthecharacter associated withv. Inaddition, wegiveeachinternalnodevinT\nafrequency, f(v), that isthesum ofthefrequencies ofalltheleaves inthesubtree\nrootedatv.\nwww.it-ebooks.info\n596 Chapter13. TextProcessing\nCharacter a b d e f h i k n o r s t u v\n(a)\nFrequency 9 5 1 3 7 3 1 1 1 4 1 5 1 2 1 1\n46\n19 27\n10 12 15\n9\n(b) a r e 5 7 8\n5 5 7\nd 2 f n 4 4\n3 3 4\nb h 2 2 t 2\n1 1 2\ni k o s u v\n1 1 1 1 1 1\nFigure 13.12: An illustration of an example Huffman code for the input string\nX =\"a fast runner need never be afraid of the dark\": (a)frequency\nofeachcharacter ofX;(b)HuffmantreeT forstringX. Thecodeforacharacter c\nisobtained bytracing thepath fromtherootofT totheleafwherecisstored, and\nassociating a left child with 0 and a right child with 1. For example, the code for\n\"r\"is011,andthecodefor\"h\"is10111.\n13.4.1 The Huffman Coding Algorithm\nTheHuffmancoding algorithm begins witheachofthed distinct characters ofthe\nstring X toencode beingtherootnode ofasingle-node binary tree. Thealgorithm\nproceeds in a series of rounds. In each round, the algorithm takes the two binary\ntrees with the smallest frequencies and merges them into a single binary tree. It\nrepeatsthisprocess untilonlyonetreeisleft. (SeeCodeFragment13.5.)\nEach iteration of the while loop in Huffman\u2019s algorithm can be implemented\nin O(logd) time using a priority queue represented with a heap. In addition, each\niteration takes twonodes out of Qand adds one in, aprocess that willbe repeated\nd 1 times before exactly one node is left in Q. Thus, this algorithm runs in\n\u2212\nO(n+dlogd) time. Although a full justification of this algorithm\u2019s correctness is\nbeyond our scope here, we note that its intuition comes from a simple idea\u2014any\noptimalcodecanbeconvertedintoanoptimalcodeinwhichthecode-wordsforthe\ntwolowest-frequencycharacters, aandb,differonlyintheirlastbit. Repeatingthe\nargumentforastringwithaandbreplacedbyacharacter c,givesthefollowing:\nProposition 13.7: Huffman\u2019salgorithmconstructsanoptimalprefixcodefora\nstringoflengthnwithddistinctcharactersinO(n+dlogd)time.\nwww.it-ebooks.info\n13.4. TextCompressionandtheGreedyMethod 597\nAlgorithmHuffman(X):\nInput: StringX oflengthnwithd distinctcharacters\nOutput: CodingtreeforX\nComputethefrequency f(c)ofeachcharacter cofX.\nInitializeapriorityqueueQ.\nforeachcharactercinX do\nCreateasingle-node binarytreeT storing c.\nInsertT intoQwithkey f(c).\nwhileQ.size()>1do\nEntrye = Q.removeMin()withe having key f andvalueT .\n1 1 1 1\nEntrye = Q.removeMin()withe having key f andvalueT .\n2 2 2 2\nCreateanewbinarytreeT withleftsubtreeT andrightsubtreeT .\n1 2\nInsertT intoQwithkey f + f .\n1 2\nEntrye = Q.removeMin()withehavingtreeT asitsvalue.\nreturntreeT\nCodeFragment13.5: Huffmancodingalgorithm.\n13.4.2 The Greedy Method\nHuffman\u2019s algorithm for building an optimal encoding is an example application\nof an algorithmic design pattern called the greedy method. This design pattern is\napplied tooptimization problems, whereweare trying to construct some structure\nwhileminimizingormaximizingsomeproperty ofthatstructure.\nThe general formula for the greedy-method pattern is almost as simple as that\nfor the brute-force method. In order to solve a given optimization problem using\nthe greedy method, we proceed by a sequence of choices. The sequence starts\nfrom some well-understood starting condition, and computes the cost for that ini-\ntial condition. The pattern then asks that we iteratively make additional choices\nby identifying the decision that achieves the best cost improvement from all of\nthe choices that are currently possible. This approach does not always lead to an\noptimalsolution.\nButthereareseveralproblemsthatitdoesworkfor,andsuchproblemsaresaid\nto possess the greedy-choice property. This is the property that a global optimal\ncondition can be reached by a series of locally optimal choices (that is, choices\nthat are each the current best from among the possibilities available at the time),\nstartingfromawell-definedstartingcondition. Theproblemofcomputinganopti-\nmalvariable-length prefixcodeisjustoneexampleofaproblemthatpossesses the\ngreedy-choice property.\nwww.it-ebooks.info\n598 Chapter13. TextProcessing\n13.5 Dynamic Programming\nInthissection, wewilldiscussthedynamic-programming algorithmic design pat-\ntern. Thistechniqueissimilartothedivide-and-conquertechnique(Section12.1.1),\ninthatitcanbeappliedtoawidevarietyofdifferentproblems. Dynamicprogram-\nming can often be used to produce polynomial-time algorithms to solve problems\nthat seem to require exponential time. In addition, the algorithms that result from\napplicationsofthedynamicprogrammingtechniqueareusuallyquitesimple,often\nneedinglittlemorethanafewlinesofcodetodescribesomenestedloopsforfilling\ninatable.\n13.5.1 Matrix Chain-Product\nRather than starting out with an explanation of the general components of the dy-\nnamic programming technique, we begin by giving a classic, concrete example.\nSuppose we are given a collection of n two-dimensional matrices for which we\nwishtocomputethemathematicalproduct\nA=A A A A ,\n0 1 2 n\u22121\n\u00b7 \u00b7 \u00b7\u00b7\u00b7\nwhere A is a d d matrix, for i = 0,1,2,...,n 1. In the standard matrix\ni i i+1\n\u00d7 \u2212\nmultiplicationalgorithm(whichistheonewewilluse),tomultiplyad e-matrixB\n\u00d7\ntimesane f-matrixC,wecomputetheproduct, A,as\n\u00d7\ne\u22121\nA[i][j]= \u2211B[i][k] C[k][j].\n\u00b7\nk=0\nThis definition implies that matrix multiplication is associative, that is, it implies\nthat B (C D)=(B C) D. Thus, we can parenthesize the expression for A any\n\u00b7 \u00b7 \u00b7 \u00b7\nway we wish and we will end up with the same answer. However, we will not\nnecessarily perform the same number of primitive (that is, scalar) multiplications\nineachparenthesization, asisillustrated inthefollowingexample.\nExample 13.8: LetBbea2 10-matrix,letCbea10 50-matrix,andletDbe\n\u00d7 \u00d7\na50 20-matrix. ComputingB (C D) requires2 10 20+10 50 20 =10400\n\u00d7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nmultiplications,whereascomputing(B C) Drequires2 10 50+2 50 20=3000\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nmultiplications.\nThematrix chain-product problem is todetermine the parenthesization of the\nexpression defining the product A that minimizes the total number of scalar mul-\ntiplications performed. As the example above illustrates, the differences between\nparenthesizations can be dramatic, so finding agood solution can result in signifi-\ncantspeedups.\nwww.it-ebooks.info\n13.5. DynamicProgramming 599\nDefining Subproblems\nOnewayto solve the matrix chain-product problem isto simply enumerate all the\npossible ways of parenthesizing the expression for A and determine the number\nof multiplications performed by each one. Unfortunately, the set of all different\nparenthesizations of the expression for A is equal in number to the set of all dif-\nferent binary trees that have n leaves. This number is exponential in n. Thus, this\nstraightforward (\u201cbrute-force\u201d) algorithm runsinexponential time,fortherearean\nexponential numberofwaystoparenthesize anassociative arithmetic expression.\nWe can significantly improve the performance achieved by the brute-force al-\ngorithm, however, by making a few observations about the nature of the matrix\nchain-product problem. Thefirstisthattheproblemcanbesplitintosubproblems.\nInthis case, wecan defineanumber ofdifferent subproblems, each ofwhich isto\ncomputethebestparenthesizationforsomesubexpressionA A A . Asacon-\ni i+1 j\n\u00b7 \u00b7\u00b7\u00b7\ncisenotation,weuseN todenotetheminimumnumberofmultiplications needed\ni,j\nto compute this subexpression. Thus, the original matrix chain-product problem\ncan be characterized as that of computing the value of N . This observation\n0,n\u22121\nis important, but we need one more in order to apply the dynamic programming\ntechnique.\nCharacterizing Optimal Solutions\nTheotherimportantobservationwecanmakeaboutthematrixchain-productprob-\nlemisthatitispossibletocharacterize anoptimalsolutiontoaparticular subprob-\nlem in terms of optimal solutions to its subproblems. We call this property the\nsubproblem optimality condition.\nIn the case of the matrix chain-product problem, we observe that, no mat-\nter how we parenthesize a subexpression, there has to be some final matrix mul-\ntiplication that we perform. That is, a full parenthesization of a subexpression\nA A A has to be of the form (A A ) (A A ), for some k i,i+\ni i+1 j i k k+1 j\n\u00b7 \u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7 \u00b7 \u00b7\u00b7\u00b7 \u2208{\n1,...,j 1 . Moreover, forwhichever k isthecorrect one, theproducts (A A )\ni k\n\u2212 } \u00b7\u00b7\u00b7\nand(A A )mustalsobesolvedoptimally. Ifthiswerenotso,thentherewould\nk+1 j\n\u00b7\u00b7\u00b7\nbeaglobaloptimalthathadoneofthesesubproblemssolvedsuboptimally. Butthis\nisimpossible,sincewecouldthenreducethetotalnumberofmultiplicationsbyre-\nplacingthecurrentsubproblemsolutionbyanoptimalsolutionforthesubproblem.\nThisobservation implies awayofexplicitly defining theoptimization problem for\nN intermsofother optimal subproblem solutions. Namely, wecancompute N\ni,j i,j\nbyconsidering eachplacekwherewecouldputthefinalmultiplication andtaking\ntheminimumoverallsuchchoices.\nwww.it-ebooks.info\n600 Chapter13. TextProcessing\nDesigning a Dynamic Programming Algorithm\nWecanthereforecharacterize theoptimalsubproblem solution, N ,as\ni,j\nN = min N +N +dd d ,\ni,j i,k k+1,j i k+1 j+1\ni\u2264k<j{ }\nwhere N = 0, since no work is needed for a single matrix. That is, N is the\ni,i i,j\nminimum, taken over allpossible places toperform the final multiplication, ofthe\nnumber ofmultiplications needed tocompute eachsubexpression plusthenumber\nofmultiplications neededtoperform thefinalmatrixmultiplication.\nNotice that there is a sharing of subproblems going on that prevents us from\ndividingtheproblemintocompletelyindependent subproblems (aswewouldneed\nto do to apply the divide-and-conquer technique). We can, nevertheless, use the\nequation for N to derive an efficient algorithm by computing N values in a\ni,j i,j\nbottom-up fashion, and storing intermediate solutions inatable ofN values. We\ni,j\ncan begin simply enough by assigning N =0 for i=0,1,...,n 1. Wecan then\ni,i\n\u2212\napplythegeneralequationforN tocomputeN values,sincetheydependonly\ni,j i,i+1\non N and N values that are available. Given the N values, wecan then\ni,i i+1,i+1 i,i+1\ncompute the N values, and so on. Therefore, wecan build N values up from\ni,i+2 i,j\npreviouslycomputedvaluesuntilwecanfinallycomputethevalueofN ,which\n0,n\u22121\nis the number that we are searching for. A Java implementation of this dynamic\nprogramming solution is given in Code Fragment 13.6; we use techniques from\nSection3.1.5forworkingwithatwo-dimensional arrayinJava.\n1 public static int[ ][ ] matrixChain(int[ ] d)\n{\n2 int n = d.length 1; // number of matrices\n\u2212\n3 int[ ][ ] N = new int[n][n]; // n-by-n matrix; initially zeros\n4 for (int b=1; b < n; b++) // number of products in subchain\n5 for (int i=0; i < n b; i++) // start of subchain\n\u2212 {\n6 int j = i + b; // end of subchain\n7 N[i][j] = Integer.MAX VALUE; // used as \u2019infinity\u2019\n8 for (int k=i; k < j; k++)\n9 N[i][j] = Math.min(N[i][j], N[i][k] + N[k+1][j] + d[i]\u2217d[k+1]\u2217d[j+1]);\n10\n}\n11 return N;\n12\n}\nCode Fragment 13.6: Dynamic programming algorithm for the matrix chain-\nproductproblem.\nThus,wecancomputeN withanalgorithmthatconsistsprimarilyofthree\n0,n\u22121\nnested loops (the third of which computes the min term). Each of these loops\niterates at most n times per execution, with a constant amount of additional work\nwithin. Therefore, thetotalrunning timeofthisalgorithm isO(n3).\nwww.it-ebooks.info\n13.5. DynamicProgramming 601\n13.5.2 DNA and Text Sequence Alignment\nA common text-processing problem, which arises in genetics and software engi-\nneering, istotestthesimilarity betweentwotextstrings. Inagenetics application,\nthetwostringscouldcorrespondtotwostrandsofDNA,forwhichwewanttocom-\npute similarities. Likewise, in a software engineering application, the two strings\ncould comefromtwoversions ofsource code forthesameprogram, forwhichwe\nwanttodeterminechangesmadefromoneversiontothenext. Indeed,determining\nthesimilaritybetweentwostringsissocommonthattheUnixandLinuxoperating\nsystemshaveabuilt-in program,nameddiff,forcomparing textfiles.\nGiven a string X =x x x x , a subsequence of X is any string that is of\n0 1 2 n\u22121\n\u00b7\u00b7\u00b7\ntheform x x x , wherei <i ;that is, itisasequence ofcharacters thatare\ni1 i2\u00b7\u00b7\u00b7 ik j j+1\nnotnecessarilycontiguousbutareneverthelesstakeninorderfromX. Forexample,\nthestringAAAGisasubsequence ofthestringCGATAATTGAGA.\nThe DNA and text similarity problem we address here is the longest common\nsubsequence (LCS)problem. In this problem, weare given twocharacter strings,\nX = x x x x and Y = y y y y , over some alphabet (such as the al-\n0 1 2 n\u22121 0 1 2 m\u22121\n\u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7\nphabet A,C,G,T common in computational genomics) and are asked to find a\n{ }\nlongest string S that is a subsequence of both X and Y. One way to solve the\nlongest common subsequence problem is to enumerate all subsequences of X and\ntake the largest one that is also a subsequence ofY. Since each character of X is\neitherinornotinasubsequence, therearepotentially 2n differentsubsequences of\nX,eachofwhichrequiresO(m)timetodeterminewhetheritisasubsequenceofY.\nThus, this brute-force approach yields an exponential-time algorithm that runs in\nO(2nm)time,whichisveryinefficient. Fortunately, theLCSproblem isefficiently\nsolvableusingdynamicprogramming.\nThe Components of a Dynamic Programming Solution\nAs mentioned above, the dynamic programming technique is used primarily for\noptimization problems, wherewewishtofindthe\u201cbest\u201d wayofdoing something.\nWecanapplythedynamicprogrammingtechniqueinsuchsituationsiftheproblem\nhascertainproperties:\nSimpleSubproblems: Therehastobesomewayofrepeatedlybreakingtheglobal\noptimization problem intosubproblems. Moreover, thereshould beawayto\nparameterize subproblems withjustafewindices, likei, j,k,andsoon.\nSubproblemOptimization: Anoptimal solution totheglobal problem mustbea\ncomposition ofoptimalsubproblem solutions.\nSubproblemOverlap: Optimal solutions to unrelated subproblems can contain\nsubproblems incommon.\nwww.it-ebooks.info\n602 Chapter13. TextProcessing\nApplying Dynamic Programming to the LCS Problem\nRecall that in the LCS problem, we are given two character strings, X and Y, of\nlength n and m, respectively, and are asked to find a longest string S that is a sub-\nsequence of both X andY. Since X andY are character strings, wehave a natural\nsetofindices withwhichtodefinesubproblems\u2014indices intothestrings X andY.\nLet us define a subproblem, therefore, as that of computing the value L , which\nj,k\nwewillusetodenotethelengthofalongeststringthatisasubsequenceofboththe\nfirst j characters of X and the first k characters ofY, that is of prefixes X[0..j 1]\n\u2212\nandY[0..k 1]. Ifeither j=0ork=0,thenL istriviallydefinedas0.\nj,k\n\u2212\nWhenboth j 1andk 1,thisdefinitionallowsustorewriteL recursively\nj,k\n\u2265 \u2265\nintermsofoptimalsubproblem solutions. Thisdefinitiondependsonwhichoftwo\ncaseswearein. (SeeFigure13.13.)\nx = y . In this case, we have a match between the last character of\nj\u22121 k\u22121\n\u2022\nX[0..j 1]andthelastcharacter ofY[0..k 1]. Weclaimthat thischaracter\n\u2212 \u2212\nbelongs to a longest common subsequence of X[0..j 1] and Y[0..k 1].\n\u2212 \u2212\nTo justify this claim, let us suppose it is not true. There has to be some\nlongest common subsequence x x ...x =y y ...y . If x =x or\na1 a2 ac b1 b2 bc ac j\u22121\ny =y , then we get the same sequence by setting a = j 1 and b =\nbc k\u22121 c\n\u2212\nc\nk 1. Alternately, if x = x and y = y , then we can get an even\n\u2212\nac\n6\nj\u22121 bc\n6\nk\u22121\nlonger common subsequence by adding x = y to the end. Thus, a\nj\u22121 k\u22121\nlongest common subsequence of X[0..j 1] andY[0..k 1] ends with x .\nj\u22121\n\u2212 \u2212\nTherefore, weset\nL =1+L ifx =y .\nj,k j\u22121,k\u22121 j\u22121 k\u22121\nx =y . In this case, we cannot have a common subsequence that in-\nj\u22121 k\u22121\n\u2022 6\ncludesbothx andy . Thatis,wecanhaveacommonsubsequence end\nj\u22121 k\u22121\nwith x or one that ends with y (or possibly neither), but certainly not\nj\u22121 k\u22121\nboth. Therefore, weset\nL =max L ,L ifx =y .\nj,k j\u22121,k j,k\u22121 j\u22121 k\u22121\n{ } 6\n0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8\nX=GTTCCTAATA X=GTTCCTAAT\nY=CGATAATTGAGA Y= CGATAATTGAG\n0 1 2 3 4 5 6 7 8 9 1011 0 1 2 3 4 5 6 7 8 9 10\nL =1+L L =max(L , L )\n10,12 9,11 9,11 9,10 8,11\n(a) (b)\nFigure 13.13: The two cases in the longest common subsequence algorithm for\ncomputing L when j,k 1: (a)x =y ;(b)x =y .\nj,k j\u22121 k\u22121 j\u22121 k\u22121\n\u2265 6\nwww.it-ebooks.info\n13.5. DynamicProgramming 603\nThe LCS Algorithm\nThe definition of L satisfies subproblem optimization, for we cannot have a\nj,k\nlongest common subsequence without also having longest common subsequences\nfor the subproblems. Also, it uses subproblem overlap, because a subproblem so-\nlution L can be used in several other problems (namely, the problems L ,\nj,k j+1,k\nL , and L ). Turning this definition of L into an algorithm is actually\nj,k+1 j+1,k+1 j,k\nquitestraightforward. Wecreatean(n+1) (m+1)array,L,definedfor0 j n\n\u00d7 \u2264 \u2264\nand 0 k m. We initialize all entries to 0, in particular so that all entries of the\n\u2264 \u2264\nformL andL arezero. Then,weiteratively build upvaluesinLuntilwehave\nj,0 0,k\nL , the length of a longest common subsequence of X and Y. We give a Java\nn,m\nimplementation ofthisalgorithm inCodeFragment13.7.\n1 /\u2217\u2217 Returns table such that L[j][k] is length of LCS for X[0..j 1] and Y[0..k 1]. \u2217/\n\u2212 \u2212\n2 public static int[ ][ ] LCS(char[ ] X, char[ ] Y)\n{\n3 int n = X.length;\n4 int m = Y.length;\n5 int[ ][ ] L = new int[n+1][m+1];\n6 for (int j=0; j < n; j++)\n7 for (int k=0; k < m; k++)\n8 if (X[j] == Y[k]) // align this match\n9 L[j+1][k+1] = L[j][k] + 1;\n10 else // choose to ignore one character\n11 L[j+1][k+1] = Math.max(L[j][k+1], L[j+1][k]);\n12 return L;\n13\n}\nCodeFragment13.7: Dynamicprogrammingalgorithm fortheLCSproblem.\nThe running time of the algorithm of the LCS algorithm is easy to analyze,\nfor it is dominated by two nested for loops, with the outer one iterating n times\nand the inner one iterating m times. Since the if-statement and assignment inside\nthe loop each requires O(1) primitive operations, this algorithm runs in O(nm)\ntime. Thus, the dynamic programming technique can be applied to the longest\ncommon subsequence problem to improve significantly over the exponential-time\nbrute-force solutiontotheLCSproblem.\nThe LCS method of Code Fragment 13.7 computes the length of the longest\ncommonsubsequence (stored asL ),butnotthesubsequence itself. Fortunately,\nn,m\nitiseasytoextracttheactuallongestcommonsubsequenceifgiventhecompleteta-\nbleofL valuescomputedbytheLCSmethod. Thesolution canbereconstructed\nj,k\nbacktofrontbyreverseengineering thecalculation oflengthL . Atanyposition\nn,m\nL , if x = y , then the length is based on the common subsequence associated\nj,k j k\nwith length L , followed by common character x . Wecan record x as part\nj\u22121,k\u22121 j j\nof the sequence, and then continue the analysis from L . Ifx =y , then we\nj\u22121,k\u22121 j k\n6\ncanmovetothelargerofL andL . Wecontinuethisprocessuntilreaching\nj,k\u22121 j\u22121,k\nwww.it-ebooks.info\n604 Chapter13. TextProcessing\nsome L =0 (for example, if j or k is 0 as a boundary case). A Java implemen-\nj,k\ntation of this strategy is given in Code Fragment 13.8. This method constructs a\nlongest common subsequence in O(n+m) additional time, since each pass of the\nwhile loop decrements either j or k (or both). An illustration of the algorithm for\ncomputing thelongest commonsubsequence isgiveninFigure13.14.\n1 /\u2217\u2217 Returns the longest common substring of X and Y, given LCS table L. \u2217/\n2 public static char[ ] reconstructLCS(char[ ] X, char[ ] Y, int[ ][ ] L)\n{\n3 StringBuilder solution = new StringBuilder();\n4 int j = X.length;\n5 int k = Y.length;\n6 while (L[j][k] > 0) // common characters remain\n7 if (X[j 1] == Y[k 1])\n\u2212 \u2212 {\n8 solution.append(X[j 1]);\n\u2212\n9 j ;\n\u2212\u2212\n10 k ;\n\u2212\u2212\n11 else if (L[j 1][k] >= L[j][k 1])\n} \u2212 \u2212\n12 j ;\n\u2212\u2212\n13 else\n14 k ;\n\u2212\u2212\n15 // return left-to-right version, as char array\n16 return solution.reverse().toString().toCharArray();\n17\n}\nCodeFragment13.8: Reconstructing thelongestcommonsubsequence.\n0 1 2 3 4 5 6 7 8 9 10 11 12\n0 0 0 0 0 0 0 0 0 0 0 0 0 0\n1 0 0 1 1 1 1 1 1 1 1 1 1 1\n2 0 0 1 1 2 2 2 2 2 2 2 2 2\n3 0 0 1 1 2 2 2 3 3 3 3 3 3\n0 1 2 3 4 5 6 7 8 9\n4 0 1 1 1 2 2 2 3 3 3 3 3 3 X=GTTCCTAATA\n5 0 1 1 1 2 2 2 3 3 3 3 3 3\nY= CGATAATTGAGA\n6 0 1 1 1 2 2 2 3 4 4 4 4 4\n0 1 2 3 4 5 6 7 8 9 1011\n7 0 1 1 2 2 3 3 3 4 4 5 5 5\n8 0 1 1 2 2 3 4 4 4 4 5 5 6\n9 0 1 1 2 3 3 4 5 5 5 5 5 6\n10 0 1 1 2 3 4 4 5 5 5 6 6 6\nFigure13.14: Illustration of the algorithm for constructing alongest common sub-\nsequence from the array L. A diagonal step on the highlighted path represents the\nuseofacommoncharacter(withthatcharacter\u2019srespectiveindicesinthesequences\nhighlighted inthemargins).\nwww.it-ebooks.info\n13.6. Exercises 605\n13.6 Exercises\nReinforcement\nR-13.1 ListtheprefixesofthestringP=\"aaabbaaa\"thatarealsosuffixesofP.\nR-13.2 Whatisthelongest(proper)prefixofthestring\"cgtacgttcgtacg\"thatisalso\nasuffixofthisstring?\nR-13.3 Drawafigureillustratingthecomparisonsdonebybrute-forcepatternmatching\nforthetext\"aaabaadaabaaa\"andpattern\"aabaaa\".\nR-13.4 Repeat the previous problem for the Boyer-Moore algorithm, not counting the\ncomparisonsmadetocomputethelast(c)function.\nR-13.5 Repeat Exercise R-13.3 for the Knuth-Morris-Prattalgorithm, not countingthe\ncomparisonsmadetocomputethefailurefunction.\nR-13.6 ComputeamaprepresentingthelastfunctionusedintheBoyer-Moorepattern-\nmatchingalgorithmforcharactersinthepatternstring:\n\"the quick brown fox jumped over a lazy cat\".\nR-13.7 ComputeatablerepresentingtheKnuth-Morris-Prattfailurefunctionforthepat-\nternstring\"cgtacgttcgtac\".\nR-13.8 Drawastandardtrieforthefollowingsetofstrings:\nabab, baba, ccccc, bbaaaa, caa, bbaacc, cbcc, cbca .\n{ }\nR-13.9 Drawacompressedtrieforthestringsgiveninthepreviousproblem.\nR-13.10 Drawthecompactrepresentationofthesuffixtrieforthestring:\n\"minimize minime\".\nR-13.11 DrawthefrequencyarrayandHuffmantreeforthefollowingstring:\n\"dogs do not spot hot pots or cats\".\nR-13.12 What is the best way to multiply a chain of matrices with dimensions that are\n10 5,5 2,2 20,20 12,12 4,and4 60?Showyourwork.\n\u00d7 \u00d7 \u00d7 \u00d7 \u00d7 \u00d7\nR-13.13 InFigure13.14,weillustratethatGTTTAAisalongestcommonsubsequencefor\nthe given strings X andY. However, that answer is not unique. Give another\ncommonsubsequenceofX andY havinglengthsix.\nR-13.14 ShowthelongestcommonsubsequencearrayLforthetwostrings:\nX = \"skullandbones\"\nY = \"lullabybabies\"\nWhatisalongestcommonsubsequencebetweenthesestrings?\nwww.it-ebooks.info\n606 Chapter13. TextProcessing\nCreativity\nC-13.15 Describe an example of a text T of length n and a pattern P of length m such\nthat the brute-forcepattern-matchingalgorithm achieves a running time that is\n\u2126(nm).\nC-13.16 Adaptthe brute-forcepattern-matchingalgorithmso as to implementa method\nfindLastBrute(T,P)thatreturnstheindexatwhichtherightmostoccurrenceof\npatternPwithintextT,ifany.\nC-13.17 Redo the previous problem, adapting the Boyer-Moore pattern-matching algo-\nrithmtoimplementamethodfindLastBoyerMoore(T,P).\nC-13.18 RedoExerciseC-13.16,adaptingtheKnuth-Morris-Prattpattern-matchingalgo-\nrithmappropriatelytoimplementamethodfindLastKMP(T,P).\nC-13.19 GiveajustificationofwhythecomputeFailKMPmethod(CodeFragment13.4)\nrunsinO(m)timeonapatternoflengthm.\nC-13.20 LetT beatextoflengthn,andletPbeapatternoflengthm. DescribeanO(n+\nm)-timemethodforfindingthelongestprefixofPthatisasubstringofT.\nC-13.21 Say that a pattern P of length m is a circular substring of a text T of length\nn>m if P is a (normal) substring of T, or if P is equal to the concatenation\nof a suffix of T and a prefix of T, that is, if there is an index 0 k<m, such\n\u2264\nthatP=T[n m+k..n 1]+T[0..k 1]. GiveanO(n+m)-timealgorithmfor\n\u2212 \u2212 \u2212\ndeterminingwhetherPisacircularsubstringofT.\nC-13.22 TheKnuth-Morris-Prattpattern-matchingalgorithmcanbemodifiedtorunfaster\nonbinarystringsbyredefiningthefailurefunctionas:\nf(k)=thelargest j<ksuchthatP[0..j 1]p isasuffixofP[1..k],\nj\n\u2212\nwherep denotesthecomplementofthe jthbitofP.Describehowtomodifythe\nj\nb\nKMPalgorithmtobeabletotakeadvantageofthisnewfailurefunctionandalso\ngiveamethodforcomputingthisfailurefunction. Showthatthismethodmakes\nb\nat most n comparisons between the text and the pattern (as opposed to the 2n\ncomparisonsneededbythestandardKMPalgorithmgiveninSection13.2.3).\nC-13.23 Modify the simplified Boyer-Moore algorithm presented in this chapter using\nideasfromtheKMPalgorithmsothatitrunsinO(n+m)time.\nC-13.24 LetT beatextstringoflengthn. DescribeanO(n)-timemethodforfindingthe\nlongestprefixofT thatisasubstringofthereversalofT.\nC-13.25 Describeanefficientalgorithmtofindthelongestpalindromethatisa suffixof\na string T of length n. Recall that a palindrome is a string that is equal to its\nreversal.Whatistherunningtimeofyourmethod?\nC-13.26 Giveanefficientalgorithmfordeletingastringfromastandardtrieandanalyze\nitsrunningtime.\nC-13.27 Giveanefficientalgorithmfordeletingastringfromacompressedtrieandana-\nlyzeitsrunningtime.\nwww.it-ebooks.info\n13.6. Exercises 607\nC-13.28 Describeanalgorithmforconstructingthecompactrepresentationofasuffixtrie,\ngivenitsnoncompactrepresentation,andanalyzeitsrunningtime.\nC-13.29 Createaclassthatimplementsastandardtrieforasetofstrings.Theclassshould\nhaveaconstructorthattakesalistofstringsasanargument,andtheclassshould\nhaveamethodthattestswhetheragivenstringisstoredinthetrie.\nC-13.30 Create a class thatimplementsa compressedtrie fora setof strings. The class\nshouldhaveaconstructorthattakesalistofstringsasanargument,andtheclass\nshouldhaveamethodthattestswhetheragivenstringisstoredinthetrie.\nC-13.31 Createaclassthatimplementsaprefixtrieforastring. Theclassshouldhavea\nconstructorthattakesastringasanargument,andamethodforpatternmatching\nonthestring.\nC-13.32 GivenastringXoflengthnandastringY oflengthm,describeanO(n+m)-time\nalgorithmforfindingthelongestprefixofX thatisasuffixofY.\nC-13.33 Describe an efficientgreedyalgorithmfor making changefor a specified value\nusing a minimum number of coins, assuming there are four denominations of\ncoins(calledquarters,dimes,nickels,andpennies),withvalues25,10,5,and1,\nrespectively.Arguewhyyouralgorithmiscorrect.\nC-13.34 Giveanexamplesetofdenominationsofcoinssothatagreedychange-making\nalgorithmwillnotusetheminimumnumberofcoins.\nC-13.35 IntheartgalleryguardingproblemwearegivenalineLthatrepresentsalong\nhallway in anartgallery. We are also givena setX = x 0 ,x 1 ,...,x n\u22121 of real\n{ }\nnumbersthat specify the positions of paintingsin this hallway. Suppose that a\nsingleguardcanprotectallthepaintingswithindistanceatmost1ofhisorher\nposition(onbothsides). Designanalgorithmforfindingaplacementofguards\nthatusestheminimumnumberofguardstoguardallthepaintingswithpositions\ninX.\nC-13.36 Anna has just won a contest that allows her to take n pieces of candy out of a\ncandystoreforfree. Annaisoldenoughtorealizethatsomecandyisexpensive,\nwhile othercandyis relativelycheap, costingmuchless. The jarsof candyare\nnumbered 0, 1, ..., m 1, so that jar j has n pieces in it, with a price of c\nj j\n\u2212\nperpiece. DesignanO(n+m)-timealgorithmthatallowsAnnatomaximizethe\nvalueofthepiecesofcandyshetakesforherwinnings.Showthatyouralgorithm\nproducesthemaximumvalueforAnna.\nC-13.37 ImplementacompressionanddecompressionschemethatisbasedonHuffman\ncoding.\nC-13.38 Design an efficient algorithm for the matrix chain multiplication problem that\noutputsafullyparenthesizedexpressionforhowtomultiplythematricesinthe\nchainusingtheminimumnumberofoperations.\nC-13.39 AnativeAustraliannamedAnatjariwishestocrossadesertcarryingonlyasin-\nglewaterbottle. Hehasamapthatmarksallthewateringholesalongtheway.\nAssuming he can walk k mileson one bottleof water, design an efficientalgo-\nrithmfordeterminingwhereAnatjarishouldrefillhisbottleinordertomakeas\nfewstopsaspossible.Arguewhyyouralgorithmiscorrect.\nwww.it-ebooks.info\n608 Chapter13. TextProcessing\nC-13.40 GivenasequenceS=(x 0 ,x 1 ,...,x n\u22121 )ofnumbers,describeanO(n2)-timealgo-\nrithmforfindingalongestsubsequenceT =(x ,x ,...,x )ofnumbers,such\ni0 i1 ik\u22121\nthati <i andx >x . Thatis,T isalongestdecreasingsubsequenceofS.\nj j+1 ij ij+1\nC-13.41 Let P be a convex polygon, a triangulation of P is an addition of diagonals\nconnectingtheverticesofPsothateachinteriorfaceisatriangle.Theweightof\natriangulationisthesumofthelengthsofthediagonals. Assumingthatwecan\ncompute lengths and add and compare them in constant time, give an efficient\nalgorithmforcomputingaminimum-weighttriangulationofP.\nC-13.42 Givean efficientalgorithmfordeterminingif a patternP is a subsequence(not\nsubstring)ofatextT. Whatistherunningtimeofyouralgorithm?\nC-13.43 DefinetheeditdistancebetweentwostringsX andY oflengthnandm,respec-\ntively,tobethenumberofeditsthatittakestochangeX intoY. Aneditconsists\nofacharacterinsertion,acharacterdeletion,oracharacterreplacement. Forex-\nample,thestrings\"algorithm\"and\"rhythm\"haveeditdistance6. Designan\nO(nm)-timealgorithmforcomputingtheeditdistancebetweenX andY.\nC-13.44 Write a programthattakestwo characterstrings(whichcouldbe, forexample,\nrepresentationsofDNAstrands)andcomputestheireditdistance,basedonyour\nalgorithmfromthepreviousexercise.\nC-13.45 LetX andY bestringsoflengthnandm, respectively. DefineB(j,k) tobethe\nlengthofthelongestcommonsubstringofthesuffixX[n j..n 1]andthesuffix\n\u2212 \u2212\nY[m k..m 1]. DesignanO(nm)-timealgorithmforcomputingallthevalues\n\u2212 \u2212\nofB(j,k)for j=1,...,nandk=1,...,m.\nC-13.46 Let three integer arrays, A, B, andC, be given, each of size n. Given an arbi-\ntrary integer k, design an O(n2logn)-time algorithm to determine if there exist\nnumbers,ainA,binB,andcinC,suchthatk=a+b+c.\nC-13.47 GiveanO(n2)-timealgorithmforthepreviousproblem.\nProjects\nP-13.48 Performanexperimentalanalysisoftheefficiency(numberofcharactercompar-\nisons performed) of the brute-force and KMP pattern-matching algorithms for\nvarying-lengthpatterns.\nP-13.49 Perform an experimental analysis of the efficiency (number of character com-\nparisonsperformed)ofthebrute-forceandBoyer-Moorepattern-matchingalgo-\nrithmsforvarying-lengthpatterns.\nP-13.50 Perform an experimental comparison of the relative speeds of the brute-force,\nKMP, and Boyer-Moore pattern-matching algorithms. Document the relative\nrunning times on large text documents that are then searched using varying-\nlengthpatterns.\nP-13.51 ExperimentwiththeefficiencyoftheindexOfmethodofJava\u2019sStringclassand\ndevelopa hypothesisaboutwhichpattern-matchingalgorithmituses. Describe\nyourexperimentsandyourconclusions.\nwww.it-ebooks.info\n13.6. Exercises 609\nP-13.52 Averyeffectivepattern-matchingalgorithm,developedbyRabinandKarp[54],\nrelies on the use of hashing to produce an algorithm with very good expected\nperformance. Recallthatthebrute-forcealgorithmcomparesthepatterntoeach\npossibleplacementinthe text, spendingO(m) time, in theworstcase, foreach\nsuchcomparison.ThepremiseoftheRabin-Karpalgorithmistocomputeahash\nfunction,h(),onthelength-mpattern,andthentocomputethehashfunctionon\n\u00b7\nall length-m substrings of the text. The pattern P occurs at substring, T[j..j+\nm 1],onlyifh(P)equalsh(T[j..j+m 1]). Ifthehashvaluesareequal, the\n\u2212 \u2212\nauthenticity of the match at that location must then be verified with the brute-\nforceapproach,sincethereisapossibilitythattherewasacoincidentalcollision\nofhashvaluesfordistinctstrings. Butwithagoodhashfunction,therewillbe\nveryfewsuchfalsematches.\nThenextchallenge,however,isthatcomputingagoodhashfunctiononalength-\nm substring would presumably require O(m) time. If we did this for each of\nO(n) possible locations, the algorithm would be no better than the brute-force\napproach.Thetrickistorelyontheuseofapolynomialhashcode,asoriginally\nintroducedinSection10.2.1,suchas\n(x 0\nam\u22121+x\n1\nam\u22122+\n+x n\u22122 a+x m\u22121 )mod p\n\u00b7\u00b7\u00b7\nforasubstring(x 0 ,x 1 ,...,x m\u22121 ),randomlychosena,andlargeprime p. Wecan\ncomputethehashvalueofeachsuccessivesubstringofthetextinO(1)timeeach,\nbyusingthefollowingformula\nh(T[j+1..j+m])=(a h(T[j..j+m 1]) x am+x )mod p.\nj j+m\n\u00b7 \u2212 \u2212\nImplementtheRabin-Karpalgorithmandevaluateitsefficiency.\nP-13.53 ImplementthesimplifiedsearchenginedescribedinSection13.3.4forthepages\nof a small Web site. Use all the words in the pages of the site as index terms,\nexcludingstopwordssuchasarticles,prepositions,andpronouns.\nP-13.54 Implementa searchengineforthepagesofa smallWeb site byaddinga page-\nrankingfeaturetothesimplifiedsearchenginedescribedinSection13.3.4.Your\npage-rankingfeatureshouldreturnthemostrelevantpagesfirst.Useallthewords\nin the pages of the site as index terms, excluding stop words, such as articles,\nprepositions,andpronouns.\nP-13.55 Use the LCS algorithmto compute the best sequence alignmentbetween some\nDNAstrings,whichyoucangetonlinefromGenBank.\nP-13.56 Developa spell-checkerthatuseseditdistance(seeExerciseC-13.43)to deter-\nminewhichcorrectlyspelledwordsareclosesttoamisspelling.\nwww.it-ebooks.info\n610 Chapter13. TextProcessing\nChapter Notes\nTheKMPalgorithmisdescribedbyKnuth,Morris,andPrattintheirjournalarticle[62],\nand Boyer and Moore describe their algorithm in a journal article published the same\nyear [17]. In their article, however, Knuth et al. [62] also prove that the Boyer-Moore\nalgorithmrunsinlineartime. Morerecently,Cole[23]showsthattheBoyer-Moorealgo-\nrithm makesat most 3n charactercomparisonsin the worstcase, and this boundis tight.\nAllof the algorithmsdiscussed aboveare also discussed in the bookchapterbyAho[4],\nalbeitin a moretheoreticalframework,includingthemethodsforregular-expressionpat-\nternmatching.Thereaderinterestedinfurtherstudyofstringpattern-matchingalgorithms\nisreferredtothebookbyStephen[84]andthebookchaptersbyAho[4],andCrochemore\nandLecroq[26].ThetriewasinventedbyMorrison[74]andisdiscussedextensivelyinthe\nclassicSortingandSearchingbookbyKnuth[61]. Thename\u201cPatricia\u201disshortfor\u201cPrac-\ntical Algorithm to Retrieve Information Coded in Alphanumeric\u201d [74]. McCreight [68]\nshowshowtoconstructsuffixtriesinlineartime. Dynamicprogrammingwasdeveloped\nintheoperationsresearchcommunityandformalizedbyBellman[12].\nwww.it-ebooks.info\nChapter\n14\nGraph Algorithms\nContents\n14.1 Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 612\n14.1.1 The Graph ADT . . . . . . . . . . . . . . . . . . . . . . . 618\n14.2 Data Structures for Graphs . . . . . . . . . . . . . . . . . . 619\n14.2.1 Edge List Structure . . . . . . . . . . . . . . . . . . . . . 620\n14.2.2 Adjacency List Structure . . . . . . . . . . . . . . . . . . 622\n14.2.3 Adjacency Map Structure . . . . . . . . . . . . . . . . . . 624\n14.2.4 Adjacency Matrix Structure . . . . . . . . . . . . . . . . . 625\n14.2.5 Java Implementation . . . . . . . . . . . . . . . . . . . . 626\n14.3 Graph Traversals . . . . . . . . . . . . . . . . . . . . . . . . 630\n14.3.1 Depth-First Search . . . . . . . . . . . . . . . . . . . . . 631\n14.3.2 DFS Implementation and Extensions . . . . . . . . . . . . 636\n14.3.3 Breadth-First Search . . . . . . . . . . . . . . . . . . . . 640\n14.4 Transitive Closure . . . . . . . . . . . . . . . . . . . . . . . 643\n14.5 Directed Acyclic Graphs . . . . . . . . . . . . . . . . . . . . 647\n14.5.1 Topological Ordering . . . . . . . . . . . . . . . . . . . . 647\n14.6 Shortest Paths . . . . . . . . . . . . . . . . . . . . . . . . . 651\n14.6.1 Weighted Graphs . . . . . . . . . . . . . . . . . . . . . . 651\n14.6.2 Dijkstra\u2019s Algorithm . . . . . . . . . . . . . . . . . . . . . 653\n14.7 Minimum Spanning Trees . . . . . . . . . . . . . . . . . . . 662\n14.7.1 Prim-Jarn\u00b4\u0131k Algorithm . . . . . . . . . . . . . . . . . . . 664\n14.7.2 Kruskal\u2019s Algorithm . . . . . . . . . . . . . . . . . . . . . 667\n14.7.3 Disjoint Partitions and Union-Find Structures . . . . . . . 672\n14.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 677\nwww.it-ebooks.info\n612 Chapter14. GraphAlgorithms\n14.1 Graphs\nA graph is a way of representing relationships that exist between pairs of objects.\nThat is, a graph is a set of objects, called vertices, together with a collection of\npairwise connections between them, called edges. Graphs have applications in\nmodeling many domains, including mapping, transportation, computer networks,\nand electrical engineering. By the way, this notion of a \u201cgraph\u201d should not be\nconfusedwithbarchartsandfunctionplots,asthesekindsof\u201cgraphs\u201dareunrelated\ntothetopicofthischapter.\nViewed abstractly, a graph G is simply a setV of vertices and a collection E\nof pairs of vertices fromV, called edges. Thus, a graph is a way of representing\nconnectionsorrelationshipsbetweenpairsofobjectsfromsomesetV. Incidentally,\nsomebooksusedifferentterminology forgraphsandrefertowhatwecallvertices\nasnodesandwhatwecalledgesasarcs. Weusetheterms\u201cvertices\u201d and\u201cedges.\u201d\nEdges in a graph are either directed or undirected. An edge (u,v) is said to\nbe directed from u to v if the pair (u,v) is ordered, with u preceding v. An edge\n(u,v)issaidtobeundirectedifthepair(u,v)isnotordered. Undirectededgesare\nsometimes denoted with set notation, as u,v , but for simplicity we use the pair\n{ }\nnotation(u,v),notingthatintheundirectedcase(u,v)isthesameas(v,u). Graphs\naretypicallyvisualizedbydrawingtheverticesasovalsorrectanglesandtheedges\nas segments orcurves connecting pairs of ovals and rectangles. The following are\nsomeexamplesofdirectedandundirected graphs.\nExample 14.1: Wecanvisualizecollaborationsamongtheresearchersofacer-\ntaindisciplinebyconstructingagraphwhoseverticesareassociatedwiththere-\nsearchersthemselves,andwhoseedgesconnectpairsofverticesassociatedwith\nresearcherswhohavecoauthoredapaperorbook. (SeeFigure14.1.)Suchedges\nareundirectedbecausecoauthorshipisasymmetricrelation;thatis,ifAhascoau-\nthoredsomethingwithB,thenBnecessarilyhascoauthoredsomethingwithA.\nSnoeyink Garg\nGoldwasser\nGoodrich Tamassia\nTollis\nVitter Preparata Chiang\nFigure14.1: Graphofcoauthorship amongsomeauthors.\nwww.it-ebooks.info\n14.1. Graphs 613\nExample 14.2: Wecanassociatewithanobject-orientedprogramagraphwhose\nverticesrepresenttheclassesdefinedintheprogram,andwhoseedgesindicate\ninheritancebetweenclasses. Thereisanedgefromavertexv toavertexu if\ntheclassforv inheritsfromtheclassforu. Suchedgesaredirectedbecausethe\ninheritancerelationonlygoesinonedirection(thatis,itisasymmetric).\nIfalltheedgesinagraphareundirected,thenwesaythegraphisanundirected\ngraph. Likewise, a directed graph, also called a digraph, is a graph whose edges\narealldirected. Agraphthathasbothdirectedandundirectededgesisoftencalled\na mixed graph. Note that an undirected or mixed graph can be converted into a\ndirected graph by replacing every undirected edge (u,v) by the pair of directed\nedges (u,v) and (v,u). It is often useful, however, to keep undirected and mixed\ngraphs represented asthey are, forsuch graphs have several applications, asinthe\nfollowingexample.\nExample 14.3: Acitymapcanbemodeledasagraphwhoseverticesareintersec-\ntionsordeadends,andwhoseedgesarestretchesofstreetswithoutintersections.\nThisgraphhasbothundirectededges,whichcorrespondtostretchesoftwo-way\nstreets,anddirectededges,whichcorrespondtostretchesofone-waystreets.Thus,\ninthisway,agraphmodelingacitymapisamixedgraph.\nExample 14.4: Physicalexamplesofgraphsarepresentintheelectricalwiring\nandplumbingnetworksofabuilding. Suchnetworkscanbemodeledasgraphs,\nwhereeachconnector,fixture,oroutletisviewedasavertex,andeachuninter-\nruptedstretchofwireorpipeisviewedasanedge.Suchgraphsareactuallycom-\nponentsofmuchlargergraphs,namelythelocalpowerandwaterdistributionnet-\nworks.Dependingonthespecificaspectsofthesegraphsthatweareinterestedin,\nwemayconsidertheiredgesasundirectedordirected,for,inprinciple,watercan\nflowinapipeandcurrentcanflowinawireineitherdirection.\nThe two vertices joined by an edge are called the end vertices (or endpoints)\noftheedge. Ifanedgeisdirected,itsfirstendpointisitsoriginandtheotheristhe\ndestination of the edge. Twovertices uand vare said tobe adjacent ifthere isan\nedge whose end vertices are u and v. An edge is said to be incident to a vertex if\nthe vertex is one of the edge\u2019s endpoints. The outgoing edges of a vertex are the\ndirected edges whoseorigin isthatvertex. Theincomingedges ofavertexarethe\ndirected edges whose destination is that vertex. The degree of a vertex v, denoted\ndeg(v), is the number of incident edges of v. The in-degree and out-degree of a\nvertex v are the number of the incoming and outgoing edges ofv, and are denoted\nindeg(v)andoutdeg(v),respectively.\nwww.it-ebooks.info\n614 Chapter14. GraphAlgorithms\nExample 14.5: WecanstudyairtransportationbyconstructingagraphG,called\naflight network,whoseverticesareassociatedwithairports,andwhoseedges\nareassociatedwithflights. (SeeFigure14.2.) IngraphG,theedgesaredirected\nbecauseagivenflighthasaspecifictraveldirection.Theendpointsofanedgeein\nGcorrespondrespectivelytotheoriginanddestinationoftheflightcorresponding\ntoe. TwoairportsareadjacentinG ifthereisaflightthatfliesbetweenthem,\nandanedgee isincidenttoavertexv inG iftheflightfore fliestoorfromthe\nairportforv.Theoutgoingedgesofavertexvcorrespondtotheoutboundflights\nfromv\u2019sairport,andtheincomingedgescorrespondtotheinboundflightstov\u2019s\nairport. Finally,thein-degreeofavertexv ofG correspondstothenumberof\ninboundflightstov\u2019sairport,andtheout-degreeofavertexvinGcorrespondsto\nthenumberofoutboundflights.\nSW45 BOS\n5\n3\nW\nORD N\nJFK\n7\n7\nSFO U A 120 U A 8 D L 3 3 5 A A 1387 3 D L 2 4 7\n0\n9\nDFW A\nAA 49 A\nLAX\nAA523\nAA411 MIA\nFigure14.2: Example of a directed graph representing a flight network. The end-\npoints of edge UA 120 are LAX and ORD; hence, LAX and ORD are adjacent.\nThein-degree ofDFWis3,andtheout-degree ofDFWis2.\nThe definition of a graph refers to the group of edges as a collection, not a\nset, thus allowing twoundirected edges tohavethesameend vertices, andfor two\ndirected edges to have the same origin and the same destination. Such edges are\ncalledparalleledgesormultipleedges. Aflightnetworkcancontainparalleledges\n(Example 14.5), such that multiple edges between the same pair of vertices could\nindicate different flights operating on the same route at different times of the day.\nAnotherspecialtypeofedgeisonethatconnectsavertextoitself. Namely,wesay\nthatanedge (undirected ordirected) isaself-loop ifitstwoendpoints coincide. A\nself-loop may occur in a graph associated with a city map (Example 14.3), where\nitwouldcorrespond toa\u201ccircle\u201d(acurving streetthatreturns toitsstartingpoint).\nWith few exceptions, graphs do not have parallel edges or self-loops. Such\ngraphs are said to be simple. Thus, we can usually say that the edges of a simple\ngraph area setof vertex pairs (and notjust acollection). Throughout this chapter,\nwewillassumethatagraphissimpleunlessotherwisespecified.\nwww.it-ebooks.info\n14.1. Graphs 615\nApathisasequenceofalternatingverticesandedgesthatstartsatavertexand\nends at a vertex such that each edge is incident to its predecessor and successor\nvertex. Acycleisapaththatstartsandendsatthesamevertex,andthatincludesat\nleastoneedge. Wesaythatapathissimpleifeachvertexinthepathisdistinct,and\nwe say that a cycle is simple if each vertex in the cycle is distinct, except for the\nfirstandlastone. Adirected pathisapathsuch thatalledges aredirected andare\ntraversed along theirdirection. Adirected cycle issimilarly defined. Forexample,\ninFigure14.2,(BOS,NW35,JFK,AA1387,DFW)isadirectedsimplepath,and\n(LAX, UA 120, ORD, UA 877, DFW, AA 49, LAX) is a directed simple cycle.\nNotethatadirected graph mayhaveacycleconsisting oftwoedgeswithopposite\ndirection between the same pair of vertices, for example (ORD, UA 877, DFW,\nDL 335, ORD) in Figure 14.2. A directed graph is acyclic if it has no directed\ncycles. For example, if we were to remove the edge UA 877 from the graph in\nFigure 14.2, the remaining graph isacyclic. Ifagraph issimple, wemay omitthe\nedges when describing path P or cycleC, as these are well defined, in which case\nPisalistofadjacent verticesandC isacycleofadjacentvertices.\nExample 14.6: GivenagraphGrepresentingacitymap(seeExample14.3),we\ncanmodelacoupledrivingtodinneratarecommendedrestaurantastraversinga\npaththoughG.Iftheyknowtheway,anddonotaccidentallygothroughthesame\nintersectiontwice,thentheytraverseasimplepathinG.Likewise,wecanmodel\ntheentiretripthecoupletakes,fromtheirhometotherestaurantandback,asa\ncycle.Iftheygohomefromtherestaurantinacompletelydifferentwaythanhow\ntheywent,notevengoingthroughthesameintersectiontwice,thentheirentire\nroundtripisasimplecycle. Finally,iftheytravelalongone-waystreetsfortheir\nentiretrip,wecanmodeltheirnightoutasadirectedcycle.\nGiven vertices u and v of a (directed) graph G, we say that u reaches v, and\nthat vis reachable from u, if Ghas a(directed) path from uto v. In anundirected\ngraph, thenotionofreachability issymmetric, thatistosay,ureaches vifanonly\nifvreachesu. However,inadirectedgraph,itispossiblethatureachesvbutvdoes\nnot reach u, because a directed path must be traversed according to the respective\ndirectionsoftheedges. Agraphisconnectedif,foranytwovertices,thereisapath\nbetween them. A directed graph G~ is strongly connected iffor any two vertices u\nandvofG~,ureachesvandvreaches u. (SeeFigure14.3forsomeexamples.)\nAsubgraph ofagraphGisagraphH whoseverticesandedgesaresubsetsof\ntheverticesandedgesofG,respectively. AspanningsubgraphofGisasubgraph\nof G that contains all the vertices of the graph G. If a graph G is not connected,\nits maximal connected subgraphs are called the connected components of G. A\nforest is a graph without cycles. A tree is a connected forest, that is, a connected\ngraph without cycles. A spanning tree of a graph is aspanning subgraph that is a\ntree. (Notethatthisdefinitionofatreeissomewhatdifferentfromtheonegivenin\nChapter8,asthereisnotnecessarily adesignated root.)\nwww.it-ebooks.info\n616 Chapter14. GraphAlgorithms\nBOS BOS\nORD ORD\nJFK JFK\nSFO SFO\nDFW DFW\nLAX LAX\nMIA MIA\n(a) (b)\nBOS BOS\nORD ORD\nJFK JFK\nSFO SFO\nDFW DFW\nLAX LAX\nMIA MIA\n(c) (d)\nFigure14.3: Examples ofreachability inadirected graph: (a)adirected pathfrom\nBOStoLAXishighlighted;(b)adirectedcycle(ORD,MIA,DFW,LAX,ORD)is\nhighlighted; itsvertices induce astrongly connected subgraph; (c)thesubgraph of\nthe vertices and edges reachable from ORD is highlighted; (d) the removal of the\ndashededgesresultsinadirectedacyclicgraph.\nExample 14.7: PerhapsthemosttalkedaboutgraphtodayistheInternet,which\ncanbeviewedasagraphwhoseverticesarecomputersandwhose(undirected)\nedgesarecommunicationconnectionsbetweenpairsofcomputersontheInter-\nnet. Thecomputersandtheconnectionsbetweentheminasingledomain,like\nwiley.com,formasubgraphoftheInternet.Ifthissubgraphisconnected,thentwo\nusersoncomputersinthisdomaincansendemailtooneanotherwithouthaving\ntheirinformationpacketseverleavetheirdomain. Supposetheedgesofthissub-\ngraphformaspanningtree. Thisimpliesthat,ifevenasingleconnectiongoes\ndown(forexample,becausesomeonepullsacommunicationcableoutoftheback\nofacomputerinthisdomain),thenthissubgraphwillnolongerbeconnected.\nwww.it-ebooks.info\n14.1. Graphs 617\nInthepropositionsthatfollow,weexploreafewimportantpropertiesofgraphs.\nProposition 14.8: IfGisagraphwithmedgesandvertexsetV,then\n\u2211 deg(v)=2m.\nvinV\nJustification: Anedge (u,v)iscounted twiceinthesummation above; onceby\nitsendpoint uand once byitsendpoint v. Thus, thetotal contribution ofthe edges\ntothedegreesoftheverticesistwicethenumberofedges.\nProposition 14.9: IfGisadirectedgraphwithmedgesandvertexsetV,then\n\u2211 indeg(v) = \u2211 outdeg(v)=m.\nvinV vinV\nJustification: In a directed graph, an edge (u,v) contributes one unit to the\nout-degree of its origin u and one unit to the in-degree of its destination v. Thus,\nthe total contribution of the edges to the out-degrees of the vertices is equal to the\nnumberofedges,andsimilarlyforthein-degrees.\nWenextshowthatasimplegraphwithnverticeshasO(n2)edges.\nProposition 14.10: LetGbeasimplegraphwithnverticesandmedges.IfGis\nundirected,thenm n(n 1)/2,andifGisdirected,thenm n(n 1).\n\u2264 \u2212 \u2264 \u2212\nJustification: Suppose that G is undirected. Since no two edges can have the\nsame endpoints and there are no self-loops, the maximum degree of a vertex in G\nisn 1 inthis case. Thus, byProposition 14.8, 2m n(n 1). Nowsuppose that\n\u2212 \u2264 \u2212\nG is directed. Since no two edges can have the same origin and destination, and\ntherearenoself-loops,themaximumin-degreeofavertexinGisn 1inthiscase.\n\u2212\nThus,byProposition 14.9,m n(n 1).\n\u2264 \u2212\nThereareanumberofsimplepropertiesoftrees,forests,andconnectedgraphs.\nProposition 14.11: LetGbeanundirectedgraphwithnverticesandmedges.\nIfGisconnected,thenm n 1.\n\u2022 \u2265 \u2212\nIfGisatree,thenm=n 1.\n\u2022 \u2212\nIfGisaforest,thenm n 1.\n\u2022 \u2264 \u2212\nwww.it-ebooks.info\n618 Chapter14. GraphAlgorithms\n14.1.1 The Graph ADT\nA graph is a collection of vertices and edges. Wemodel the abstraction as a com-\nbination of three data types: Vertex, Edge, and Graph. A Vertex is a lightweight\nobject that stores an arbitrary element provided by the user (e.g., an airport code);\nwe assume the element can be retrieved with the getElement() method. An Edge\nalso stores an associated object (e.g., aflight number, travel distance, cost), which\nisreturned byitsgetElement()method.\nTheprimaryabstractionforagraphistheGraphADT.Wepresumethatagraph\ncanbeeither undirected ordirected, withthedesignation declared upon construc-\ntion; recall that a mixed graph can be represented as a directed graph, modeling\nedge u,v as a pair of directed edges (u,v) and (v,u). The Graph ADT includes\n{ }\nthefollowingmethods:\nnumVertices(): Returnsthenumberofverticesofthegraph.\nvertices(): Returnsaniterationofalltheverticesofthegraph.\nnumEdges(): Returnsthenumberofedgesofthegraph.\nedges(): Returnsaniterationofalltheedgesofthegraph.\ngetEdge(u,v): Returns the edge from vertex u to vertex v, if one exists;\notherwise return null. Foranundirected graph, there isno\ndifference betweengetEdge(u,v)andgetEdge(v,u).\nendVertices(e): Returns an array containing the two endpoint vertices of\nedgee. Ifthegraphisdirected,thefirstvertexistheorigin\nandthesecondisthedestination.\nopposite(v,e): Foredge eincident to vertex v, returns the other vertex of\ntheedge;anerroroccursifeisnotincident tov.\noutDegree(v): Returnsthenumberofoutgoing edgesfromvertexv.\ninDegree(v): Returns the number of incoming edges to vertex v. For\nan undirected graph, this returns the same value as does\noutDegree(v).\noutgoingEdges(v): Returnsaniterationofalloutgoing edgesfromvertexv.\nincomingEdges(v): Returns aniteration ofallincoming edges tovertexv. For\nan undirected graph, this returns the same collection as\ndoesoutgoingEdges(v).\ninsertVertex(x): CreatesandreturnsanewVertexstoring elementx.\ninsertEdge(u,v,x): Creates and returns a new Edge from vertex uto vertex v,\nstoringelementx;anerroroccursiftherealreadyexistsan\nedgefromutov.\nremoveVertex(v): Removesvertexvandallitsincidentedgesfromthegraph.\nremoveEdge(e): Removesedgeefromthegraph.\nwww.it-ebooks.info\n14.2. DataStructuresforGraphs 619\n14.2 Data Structures for Graphs\nIn this section, weintroduce four data structures for representing a graph. In each\nrepresentation, wemaintain acollection to store the vertices of agraph. However,\nthefourrepresentations differgreatly inthewaytheyorganize theedges.\nIn an edge list, we maintain an unordered list of all edges. This minimally\n\u2022\nsuffices, butthere isnoefficient waytolocate aparticular edge(u,v), orthe\nsetofalledgesincidenttoavertexv.\nIn an adjacency list, we additionally maintain, for each vertex, a separate\n\u2022\nlist containing those edges that are incident to the vertex. This organization\nallowsustomoreefficientlyfindalledgesincident toagivenvertex.\nAnadjacencymapissimilartoanadjacencylist,butthesecondarycontainer\n\u2022\nof all edges incident to a vertex is organized as a map, rather than as a list,\nwith the adjacent vertex serving as a key. This allows more efficient access\ntoaspecificedge(u,v),forexample, inO(1)expected timewithhashing.\nAn adjacency matrix provides worst-case O(1) access to a specific edge\n\u2022\n(u,v) by maintaining an n n matrix, for a graph with n vertices. Each\n\u00d7\nslot isdedicated tostoring areference to the edge (u,v) for aparticular pair\nofverticesuandv;ifnosuchedgeexists,theslotwillstorenull.\nAsummaryoftheperformance ofthesestructures isgiveninTable14.1.\nMethod EdgeList Adj.List Adj.Map Adj.Matrix\nnumVertices() O(1) O(1) O(1) O(1)\nnumEdges() O(1) O(1) O(1) O(1)\nvertices() O(n) O(n) O(n) O(n)\nedges() O(m) O(m) O(m) O(m)\ngetEdge(u,v) O(m) O(min(d ,d )) O(1)exp. O(1)\nu v\noutDegree(v) O(m) O(1) O(1) O(n)\ninDegree(v)\noutgoingEdges(v) O(m) O(d ) O(d ) O(n)\nv v\nincomingEdges(v)\ninsertVertex(x) O(1) O(1) O(1) O(n2)\nremoveVertex(v) O(m) O(d ) O(d ) O(n2)\nv v\ninsertEdge(u,v,x) O(1) O(1) O(1)exp. O(1)\nremoveEdge(e) O(1) O(1) O(1)exp. O(1)\nTable14.1: AsummaryoftherunningtimesforthemethodsofthegraphADT,us-\ningthegraphrepresentations discussed inthissection. Weletndenotethenumber\nof vertices, m the number of edges, and d the degree of vertex v. Note that the\nv\nadjacency matrixusesO(n2)space,whileallotherstructures useO(n+m)space.\nwww.it-ebooks.info\n620 Chapter14. GraphAlgorithms\n14.2.1 Edge List Structure\nThe edge list structure is possibly the simplest, though not the most efficient, rep-\nresentation of a graph G. All vertex objects are stored in an unordered listV, and\nall edge objects are stored in an unordered list E. We illustrate an example of the\nedgeliststructure foragraphGinFigure14.4.\nV E\nu e\nu v f\ng\ne\nv w z w g\nf h\nz h\n(a) (b)\nFigure14.4: (a) A graph G; (b) schematic representation of the edge list structure\nforG. Noticethatanedgeobjectreferstothetwovertexobjectsthatcorrespondto\nitsendpoints, butthatverticesdonotrefertoincident edges.\nTosupportthemanymethodsoftheGraphADT(Section14.1),weassumethe\nfollowing additional features of an edge list representation. Collections V and E\nare represented with doubly linked lists using our LinkedPositionalList class from\nChapter7.\nVertex Objects\nThevertexobjectforavertexvstoring elementxhasinstance variables for:\nAreferencetoelementx,tosupportthegetElement()method.\n\u2022\nAreferencetothepositionofthevertexinstanceinthelistV,therebyallow-\n\u2022\ningvtobeefficientlyremovedfromV ifitwereremovedfromthegraph.\nEdge Objects\nTheedgeobjectforanedgeestoringelementxhasinstance variablesfor:\nAreferencetoelementx,tosupportthegetElement()method.\n\u2022\nReferences to the vertex objects associated with the endpoint vertices of e.\n\u2022\nThese will allow for constant-time support for methods endVertices(e) and\nopposite(v,e).\nAreference totheposition oftheedge instance inlist E,thereby allowing e\n\u2022\ntobeefficientlyremovedfromE ifitwereremovedfromthegraph.\nwww.it-ebooks.info\n14.2. DataStructuresforGraphs 621\nPerformance of the Edge List Structure\nTheperformanceofanedgeliststructureinfulfillingthegraphADTissummarized\nin Table 14.2. We begin by discussing the space usage, which is O(n+m) for\nrepresenting a graph with n vertices and m edges. Each individual vertex or edge\ninstance uses O(1) space, and the additional listsV and E use space proportional\ntotheirnumberofentries.\nIntermsofrunningtime,theedgeliststructure doesaswellasonecouldhope\nin terms of reporting the number of vertices or edges, or in producing an iteration\nofthoseverticesoredges. Byquerying therespective listV orE,thenumVertices\nandnumEdgesmethods runinO(1)time,andbyiterating through theappropriate\nlist,themethodsverticesandedgesrunrespectively inO(n)andO(m)time.\nThemostsignificantlimitationsofanedgeliststructure, especiallywhencom-\npared to the other graph representations, are the O(m) running times of methods\ngetEdge(u, v), outDegree(v), and outgoingEdges(v) (and corresponding methods\ninDegree and incomingEdges). The problem is that with all edges of the graph in\nanunordered listE,theonlywaytoanswerthose queries isthrough anexhaustive\ninspection ofalledges.\nFinally, weconsider themethodsthatupdate thegraph. Itiseasytoaddanew\nvertex or a new edge to the graph in O(1) time. For example, a new edge can be\nadded tothe graph bycreating anEdge instance storing thegiven element asdata,\nadding that instance to the positional list E, and recording its resulting Position\nwithin E as an attribute of the edge. That stored position can later be used to\nlocate and remove this edge from E inO(1) time, and thus implement the method\nremoveEdge(e).\nIt is worth discussing whythe removeVertex(v) method has arunning time of\nO(m). Asstatedinthegraph ADT,whenavertexvisremovedfromthegraph, all\nedgesincidenttovmustalsoberemoved(otherwise,wewouldhaveacontradiction\nofedges thatrefertovertices that arenotpartofthegraph). Tolocate theincident\nedgestothevertex,wemustexaminealledgesofE.\nMethod Running Time\nnumVertices(), numEdges() O(1)\nvertices() O(n)\nedges() O(m)\ngetEdge(u, v), outDegree(v), outgoingEdges(v) O(m)\ninsertVertex(x), insertEdge(u, v, x), removeEdge(e) O(1)\nremoveVertex(v) O(m)\nTable 14.2: Running times of the methods of a graph implemented with the edge\nliststructure. ThespaceusedisO(n+m),wherenisthenumberofverticesandm\nisthenumberofedges.\nwww.it-ebooks.info\n622 Chapter14. GraphAlgorithms\n14.2.2 Adjacency List Structure\nTheadjacencyliststructureforagraphaddsextrainformationtotheedgeliststruc-\nture that supports direct access to the incident edges (and thus tothe adjacent ver-\ntices) ofeachvertex. Specifically, foreachvertex v,wemaintain acollection I(v),\ncalled the incidence collection of v, whose entries are edges incident to v. In the\ncaseofadirectedgraph,outgoingandincomingedgescanberespectivelystoredin\ntwo separate collections, I (v) and I (v). Traditionally, the incidence collection\nout in\nI(v) for a vertex v is a list, which is why we call this way of representing a graph\ntheadjacencyliststructure.\nWe require that the primary structure for an adjacency list maintain the col-\nlection V of vertices in a way so that we can locate the secondary structure I(v)\nfor a given vertex v in O(1) time. This could be done by using a positional list\ntorepresentV, witheach Vertex instance maintaining adirect reference toitsI(v)\nincidencecollection;weillustratesuchanadjacencyliststructureofagraphinFig-\nure 14.5. If vertices can be uniquely numbered from 0 to n 1, we could instead\n\u2212\nuseaprimaryarray-based structure toaccesstheappropriate secondary lists.\nThe primary benefit of an adjacency list is that the collection I(v) (or more\nspecifically, I (v)) contains exactly those edges that should be reported by the\nout\nmethod outgoingEdges(v). Therefore, wecan implement this method by iterating\nthe edges of I(v) in O(deg(v)) time, where deg(v) is the degree of vertex v. This\nisthebestpossible outcomeforanygraphrepresentation, becausetherearedeg(v)\nedgestobereported.\nV\nu e g\nu\ne g v e f\nv w z\nf h w f g h\nz h\n(a) (b)\nFigure14.5: (a) An undirected graph G; (b) a schematic representation of the ad-\njacency list structure for G. Collection V is the primary list of vertices, and each\nvertex has an associated list ofincident edges. Although not diagrammed as such,\nwepresumethateachedgeofthegraphisrepresented withauniqueEdgeinstance\nthatmaintainsreferences toitsendpoint vertices,andthatE isalistofalledges.\nwww.it-ebooks.info\n14.2. DataStructuresforGraphs 623\nPerformance of the Adjacency List Structure\nTable 14.3 summarizes the performance of the adjacency list structure implemen-\ntation ofagraph, assuming that theprimary collectionV andE,andallsecondary\ncollections I(v)areimplementedwithdoublylinkedlists.\nAsymptotically, the space requirements for an adjacency list are the same as\nan edge list structure, using O(n+m) space for a graph with n vertices and m\nedges. It is clear that the primary lists of vertices and edges use O(n+m) space.\nIn addition, the sum of the lengths of all secondary lists is O(m), for reasons that\nwere formalized in Propositions 14.8 and 14.9. In short, an undirected edge (u,v)\nis referenced in both I(u) and I(v), but its presence in the graph results in only a\nconstant amountofadditional space.\nWe have already noted that the outgoingEdges(v) method can be achieved in\nO(deg(v))timebasedonuseofI(v). Foradirectedgraph,thisismorespecifically\nO(outdeg(v))basedonuseofI (v). TheoutDegree(v)methodofthegraphADT\nout\ncan run in O(1) time, assuming collection I(v) can report its size in similar time.\nTo locate a specific edge for implementing getEdge(u, v), we can search through\neither I(u) and I(v) (or for a directed graph, either I (u) or I (v)). By choosing\nout in\nthesmallerofthetwo,wegetO(min(deg(u),deg(v)))runningtime.\nThe rest of the bounds in Table 14.3 can be achieved with additional care. To\nefficiently support deletions ofedges, anedge (u,v) would need tomaintain aref-\nerence to its positions within both I(u) and I(v), so that it could be deleted from\nthose collections in O(1) time. To remove a vertex v, we must also remove any\nincident edges,butatleastwecanlocatethoseedgesinO(deg(v))time.\nMethod Running Time\nnumVertices(), numEdges() O(1)\nvertices() O(n)\nedges() O(m)\ngetEdge(u, v) O(min(deg(u),deg(v)))\noutDegree(v), inDegree(v) O(1)\noutgoingEdges(v), incomingEdges(v) O(deg(v))\ninsertVertex(x), insertEdge(u, v, x) O(1)\nremoveEdge(e) O(1)\nremoveVertex(v) O(deg(v))\nTable 14.3: Running times of the methods of a graph implemented with the adja-\ncencyliststructure. ThespaceusedisO(n+m),wherenisthenumberofvertices\nandmisthenumberofedges.\nwww.it-ebooks.info\n624 Chapter14. GraphAlgorithms\n14.2.3 Adjacency Map Structure\nIntheadjacency liststructure, weassume thatthe secondary incidence collections\nare implemented as unordered linked lists. Such a collection I(v) uses space pro-\nportional to O(deg(v)), allows an edge to be added or removed in O(1) time, and\nallows an iteration of all edges incident to vertex v in O(deg(v)) time. However,\nthe best implementation of getEdge(u, v) requires O(min(deg(u),deg(v))) time,\nbecausewemustsearchthrougheitherI(u)orI(v).\nWecanimprovetheperformancebyusingahash-basedmaptoimplementI(v)\nfor each vertex v. Specifically, we let the opposite endpoint of each incident edge\nserveasakeyinthemap,withtheedgestructureservingasthevalue. Wecallsuch\na graph representation an adjacency map. (See Figure 14.6.) Thespace usage for\nan adjacency map remains O(n+m), because I(v) uses O(deg(v)) space for each\nvertexv,aswiththeadjacencylist.\nThe advantage of the adjacency map, relative to an adjacency list, is that the\ngetEdge(u,v)methodcanbeimplementedinexpectedO(1)timebysearching for\nvertexuasakeyinI(v),orviceversa. Thisprovidesalikelyimprovementoverthe\nadjacency list,whileretaining theworst-caseboundofO(min(deg(u),deg(v))).\nIn comparing the performance of adjacency map to other representations (see\nTable14.1),wefindthatitessentially achievesoptimalrunningtimesforallmeth-\nods,makingitanexcellent all-purpose choiceasagraphrepresentation.\nV\nv w\nu\ne g\nu w\nu v\ne f\ne g\nu v z\nv w z w\nf h g f h\nw\nz\nh\n(a) (b)\nFigure14.6: (a) An undirected graph G; (b) a schematic representation of the ad-\njacency map structure for G. Each vertex maintains a secondary map in which\nneighboring verticesserveaskeys,withtheconnecting edgesasassociated values.\nAswiththeadjacencylist,wepresumethatthereisalsoanoveralllistE ofallEdge\ninstances.\nwww.it-ebooks.info\n14.2. DataStructuresforGraphs 625\n14.2.4 Adjacency Matrix Structure\nTheadjacencymatrixstructureforagraphGaugmentstheedgeliststructurewith\na matrix A (that is, a two-dimensional array, as in Section 3.1.5), which allows us\nto locate an edge between a given pair of vertices in worst-case constant time. In\nthe adjacency matrix representation, we think of the vertices as being the integers\nintheset 0,1,...,n 1 andtheedgesasbeingpairsofsuchintegers. Thisallows\n{ \u2212 }\nus to store references to edges in the cells of a two-dimensional n n array A.\n\u00d7\nSpecifically, thecellA[i][j]holdsareference totheedge(u,v),ifitexists, whereu\nisthevertex withindex iandvisthe vertexwithindex j. Ifthere isnosuch edge,\nthen A[i][j]=null. We note that array A is symmetric if graph G is undirected, as\nA[i][j]=A[j][i]forallpairsiand j. (SeeFigure14.7.)\nThe most significant advantage of an adjacency matrix is that any edge (u,v)\ncan be accessed in worst-case O(1) time; recall that the adjacency map supports\nthat operation inO(1) expected time. However, several operation areless efficient\nwith an adjacency matrix. For example, to find the edges incident to vertex v, we\nmust presumably examine all n entries in the row associated with v; recall that an\nadjacencylistormapcanlocatethoseedgesinoptimalO(deg(v))time. Addingor\nremovingverticesfromagraphisproblematic, asthematrixmustberesized.\nFurthermore, the O(n2) space usage of an adjacency matrix is typically far\nworse than the O(n+m) space required of the other representations. Although,\nin the worst case, the number of edges in a dense graph will be proportional to\nn2, most real-world graphs are sparse. In such cases, use of an adjacency matrix\nis inefficient. However, if a graph is dense, the constants of proportionality of an\nadjacency matrix can be smaller than that of an adjacency list or map. In fact, if\nedges do not have auxiliary data, a boolean adjacency matrix can use one bit per\nedgeslot,suchthatA[i][j]=trueifandonlyifassociated (u,v)isanedge.\n0 1 2 3\nu u 0 e g\ne g v 1 e f\nw 2 g f h\nv w z\nf h z 3 h\n(a) (b)\nFigure14.7: (a) Anundirected graph G; (b) aschematic representation of theaux-\niliaryadjacencymatrixstructureforG,inwhichnverticesaremappedtoindices0\nton 1. Althoughnotdiagrammedassuch,wepresumethatthereisauniqueEdge\n\u2212\ninstanceforeachedge,andthatitmaintainsreferencestoitsendpointvertices. We\nalso assume that there is asecondary edge list (not pictured), to allow the edges()\nmethodtoruninO(m)time,foragraphwithmedges.\nwww.it-ebooks.info\n626 Chapter14. GraphAlgorithms\n14.2.5 Java Implementation\nIn this section, we provide an implementation of the Graph ADT, based on the\nadjacency map representation, as described in Section 14.2.3. We use positional\nlists to represent each of the primary listsV and E, as originally described in the\nedge list representation. Additionally, for each vertex v, weuse ahash-based map\ntorepresent thesecondary incidence mapI(v).\nTo gracefully support both undirected and directed graphs, each vertex main-\ntains two different map references: outgoing and incoming. In the directed case,\nthese are initialized to two distinct map instances, representing I (v) and I (v),\nout in\nrespectively. In the case of an undirected graph, we assign both outgoing and\nincomingasaliasestoasinglemapinstance.\nOurimplementationisorganizedasfollows. WeassumedefinitionsforVertex,\nEdge, and Graph interfaces, although for the sake of brevity, we do not include\nthosedefinitions inthebook(theyareavailable online). Wethendefineaconcrete\nAdjacencyMapGraphclass, with nested classes InnerVertex and InnerEdge to im-\nplement the vertex and edge abstractions. These classes use generic parameters V\nandEtodesignate theelementtypestoredrespectively atverticesandedges.\nWe begin in Code Fragment 14.1, with the definitions of the InnerVertex and\nInnerEdgeclasses(althoughinreality,thosedefinitionsshouldbenestedwithinthe\nfollowingAdjacencyMapGraphclass). NotewellhowtheInnerVertexconstructor\ninitializes theoutgoingandincominginstance variables depending onwhetherthe\noverallgraphisundirected ordirected.\nCode Fragments 14.2 and 14.3 contain the core implementation of the class\nAdjacencyMapGraph. A graph instance maintains a boolean variable that desig-\nnates whether the graph is directed, and it maintains the vertex list and edge list.\nAlthough not shown in these code fragments, our implementation includes pri-\nvate validate methods that perform type conversions between the public Vertex\nandEdgeinterface typestotheconcrete InnerVertex andInnerEdge classes, while\nalsoperformingsomeerrorchecking. Thisdesignissimilartothevalidatemethod\noftheLinkedPositionalListclass(seeCodeFragment7.10ofSection7.3.3),which\nconverts anoutwardPositiontotheunderlying Nodetypeforthatclass.\nThemostcomplexmethodsarethosethatmodifythegraph. WheninsertVertex\nis called, we must create a new InnerVertex instance, add that vertex to the list of\nvertices, and record its position within that list (so that we can efficiently delete\nit from the list if the vertex is removed from the graph). When inserting an edge\n(u,v), we must also create a new instance, add it to the edge list, and record its\nposition, yet we must also add the new edge to the outgoing adjacency map for\nvertex u, and the incoming map for vertex v. Code Fragment 14.3 contains code\nfor removeVertex as well; the implementation of removeEdge is not included, but\nisavailable intheonlineversionofthecode.\nwww.it-ebooks.info\n14.2. DataStructuresforGraphs 627\n1 /\u2217\u2217 A vertex of an adjacency map graph representation. \u2217/\n2 private class InnerVertex<V> implements Vertex<V>\n{\n3 private V element;\n4 private Position<Vertex<V>> pos;\n5 private Map<Vertex<V>, Edge<E>> outgoing, incoming;\n6 /\u2217\u2217 Constructs a new InnerVertex instance storing the given element. \u2217/\n7 public InnerVertex(V elem, boolean graphIsDirected)\n{\n8 element = elem;\n9 outgoing = new ProbeHashMap<>();\n10 if (graphIsDirected)\n11 incoming = new ProbeHashMap<>();\n12 else\n13 incoming = outgoing; // if undirected, alias outgoing map\n14\n15 } /\u2217\u2217 Returns the element associated with the vertex. \u2217/\n16 public V getElement() return element;\n17 /\u2217\u2217 Stores the position { of this vertex withi } n the graph's vertex list. \u2217/\n18 public void setPosition(Position<Vertex<V>> p) pos = p;\n19 /\u2217\u2217 Returns the position of this vertex within the gr { aph's verte } x list. \u2217/\n20 public Position<Vertex<V>> getPosition() return pos;\n21 /\u2217\u2217 Returns reference to the underlying map { of outgoing ed } ges. \u2217/\n22 public Map<Vertex<V>, Edge<E>> getOutgoing() return outgoing;\n23 /\u2217\u2217 Returns reference to the underlying map of incomi { ng edges. \u2217/ }\n24 public Map<Vertex<V>, Edge<E>> getIncoming() return incoming;\n{ }\n25 //------------end of InnerVertex class ------------\n}\n26\n27 /\u2217\u2217 An edge between two vertices. \u2217/\n28 private class InnerEdge<E> implements Edge<E>\n{\n29 private E element;\n30 private Position<Edge<E>> pos;\n31 private Vertex<V>[ ] endpoints;\n32 /\u2217\u2217 Constructs InnerEdge instance from u to v, storing the given element. \u2217/\n33 public InnerEdge(Vertex<V> u, Vertex<V> v, E elem)\n{\n34 element = elem;\n35 endpoints = (Vertex<V>[ ]) new Vertex[ ] u,v ; // array of length 2\n{ }\n36\n37 } /\u2217\u2217 Returns the element associated with the edge. \u2217/\n38 public E getElement() return element;\n39 /\u2217\u2217 Returns reference to { the endpoint arra } y. \u2217/\n40 public Vertex<V>[ ] getEndpoints() return endpoints;\n41 /\u2217\u2217 Stores the position of this edge w { ithin the graph's vert } ex list. \u2217/\n42 public void setPosition(Position<Edge<E>> p) pos = p;\n43 /\u2217\u2217 Returns the position of this edge within the g { raph's verte } x list. \u2217/\n44 public Position<Edge<E>> getPosition() return pos;\n{ }\n45 //------------end of InnerEdge class ------------\n}\nCode Fragment 14.1: InnerVertex and InnerEdge classes (to be nested within the\nAdjacencyMapGraphclass). InterfacesVertex<V>andEdge<E>arenotshown.\nwww.it-ebooks.info\n628 Chapter14. GraphAlgorithms\n1 public class AdjacencyMapGraph<V,E> implements Graph<V,E>\n{\n2 // nested InnerVertex and InnerEdge classes defined here...\n3 private boolean isDirected;\n4 private PositionalList<Vertex<V>> vertices = new LinkedPositionalList<>();\n5 private PositionalList<Edge<E>> edges = new LinkedPositionalList<>();\n6 /\u2217\u2217 Constructs an empty graph (either undirected or directed). \u2217/\n7 public AdjacencyMapGraph(boolean directed) isDirected = directed;\n8 /\u2217\u2217 Returns the number of vertices of the graph {\u2217/ }\n9 public int numVertices() return vertices.size();\n10 /\u2217\u2217 Returns the vertices o { f the graph as an iterable } collection \u2217/\n11 public Iterable<Vertex<V>> vertices() return vertices;\n12 /\u2217\u2217 Returns the number of edges of the g { raph \u2217/ }\n13 public int numEdges() return edges.size();\n14 /\u2217\u2217 Returns the edges o { f the graph as an iterab } le collection \u2217/\n15 public Iterable<Edge<E>> edges() return edges;\n16 /\u2217\u2217 Returns the number of edges for { which vertex v is } the origin. \u2217/\n17 public int outDegree(Vertex<V> v)\n{\n18 InnerVertex<V> vert = validate(v);\n19 return vert.getOutgoing().size();\n20\n21 } /\u2217\u2217 Returns an iterable collection of edges for which vertex v is the origin. \u2217/\n22 public Iterable<Edge<E>> outgoingEdges(Vertex<V> v)\n{\n23 InnerVertex<V> vert = validate(v);\n24 return vert.getOutgoing().values(); // edges are the values in the adjacency map\n25\n26 } /\u2217\u2217 Returns the number of edges for which vertex v is the destination. \u2217/\n27 public int inDegree(Vertex<V> v)\n{\n28 InnerVertex<V> vert = validate(v);\n29 return vert.getIncoming().size();\n30\n31 } /\u2217\u2217 Returns an iterable collection of edges for which vertex v is the destination. \u2217/\n32 public Iterable<Edge<E>> incomingEdges(Vertex<V> v)\n{\n33 InnerVertex<V> vert = validate(v);\n34 return vert.getIncoming().values(); // edges are the values in the adjacency map\n35\n}\n36 public Edge<E> getEdge(Vertex<V> u, Vertex<V> v)\n37 /\u2217\u2217 Returns the edge from u to v, or null if they are not a { djacent. \u2217/\n38 InnerVertex<V> origin = validate(u);\n39 return origin.getOutgoing().get(v); // will be null if no edge from u to v\n40\n41 } /\u2217\u2217 Returns the vertices of edge e as an array of length two. \u2217/\n42 public Vertex<V>[ ] endVertices(Edge<E> e)\n{\n43 InnerEdge<E> edge = validate(e);\n44 return edge.getEndpoints();\n45\n}\nCode Fragment 14.2: AdjacencyMapGraph class definition. (Continues in Code\nFragment14.3.) Thevalidate(v)andvalidate(e)methodsareavailable online.\nwww.it-ebooks.info\n14.2. DataStructuresforGraphs 629\n46 /\u2217\u2217 Returns the vertex that is opposite vertex v on edge e. \u2217/\n47 public Vertex<V> opposite(Vertex<V> v, Edge<E> e)\n48 throws IllegalArgumentException\n{\n49 InnerEdge<E> edge = validate(e);\n50 Vertex<V>[ ] endpoints = edge.getEndpoints();\n51 if (endpoints[0] == v)\n52 return endpoints[1];\n53 else if (endpoints[1] == v)\n54 return endpoints[0];\n55 else\n56 throw new IllegalArgumentException(\"v is not incident to this edge\");\n57\n58 } /\u2217\u2217 Inserts and returns a new vertex with the given element. \u2217/\n59 public Vertex<V> insertVertex(V element)\n{\n60 InnerVertex<V> v = new InnerVertex<>(element, isDirected);\n61 v.setPosition(vertices.addLast(v));\n62 return v;\n63\n64 } /\u2217\u2217 Inserts and returns a new edge between u and v, storing given element. \u2217/\n65 public Edge<E> insertEdge(Vertex<V> u, Vertex<V> v, E element)\n66 throws IllegalArgumentException\n{\n67 if (getEdge(u,v) == null)\n{\n68 InnerEdge<E> e = new InnerEdge<>(u, v, element);\n69 e.setPosition(edges.addLast(e));\n70 InnerVertex<V> origin = validate(u);\n71 InnerVertex<V> dest = validate(v);\n72 origin.getOutgoing().put(v, e);\n73 dest.getIncoming().put(u, e);\n74 return e;\n75 else\n}\n76 throw new IllegalArgumentException(\"Edge from u to v exists\");\n77\n78 } /\u2217\u2217 Removes a vertex and all its incident edges from the graph. \u2217/\n79 public void removeVertex(Vertex<V> v)\n{\n80 InnerVertex<V> vert = validate(v);\n81 // remove all incident edges from the graph\n82 for (Edge<E> e : vert.getOutgoing().values())\n83 removeEdge(e);\n84 for (Edge<E> e : vert.getIncoming().values())\n85 removeEdge(e);\n86 // remove this vertex from the list of vertices\n87 vertices.remove(vert.getPosition());\n88\n}\n89\n}\nCodeFragment14.3: AdjacencyMapGraph class definition (continued from Code\nFragment14.2). WeomittheremoveEdge method,forbrevity.\nwww.it-ebooks.info\n630 Chapter14. GraphAlgorithms\n14.3 Graph Traversals\nGreek mythology tells of an elaborate labyrinth that was built to house the mon-\nstrousMinotaur, whichwaspartbullandpartman. Thislabyrinth wassocomplex\nthat neither beast nor human could escape it. No human, that is, until the Greek\nhero,Theseus,withthehelpoftheking\u2019sdaughter, Ariadne,decidedtoimplement\na graph traversal algorithm. Theseus fastened a ball of thread to the door of the\nlabyrinth and unwound it as he traversed the twisting passages in search of the\nmonster. Theseus obviously knew about good algorithm design, for, after finding\nanddefeatingthebeast,Theseuseasilyfollowedthestringbackoutofthelabyrinth\ntothelovingarmsofAriadne.\nFormally,atraversal isasystematic procedure forexploring agraphbyexam-\nining allof itsvertices and edges. A traversal is efficient ifitvisits all the vertices\nandedgesintimeproportional totheirnumber,thatis,inlineartime.\nGraph traversal algorithms are key to answering many fundamental questions\nabout graphs involving the notion of reachability, that is, in determining how to\ntravel from one vertex to another while following paths of a graph. Interesting\nproblemsthatdealwithreachabilityinanundirectedgraphGincludethefollowing:\nComputing a path from vertex u to vertex v, or reporting that no such path\n\u2022\nexists.\nGiven a start vertex s of G, computing, for every vertex v of G, a path with\n\u2022\nthe minimum number of edges between s and v, or reporting that no such\npathexists.\nTestingwhetherGisconnected.\n\u2022\nComputingaspanning treeofG,ifGisconnected.\n\u2022\nComputingtheconnected components ofG.\n\u2022\nIdentifying acycleinG,orreporting thatGhasnocycles.\n\u2022\nInteresting problems that deal with reachability in a directed graph G~ include the\nfollowing:\nComputingadirectedpathfromvertexutovertexv,orreportingthatnosuch\n\u2022\npathexists.\nFindingalltheverticesofG~ thatarereachable fromagivenvertexs.\n\u2022\nDeterminewhetherG~ isacyclic.\n\u2022\nDeterminewhetherG~ isstrongly connected.\n\u2022\nIn the remainder of this section, we will present two efficient graph traversal\nalgorithms, calleddepth-firstsearchandbreadth-first search,respectively.\nwww.it-ebooks.info\n14.3. GraphTraversals 631\n14.3.1 Depth-First Search\nThefirsttraversalalgorithmweconsiderinthissectionisdepth-firstsearch(DFS).\nDepth-first search is useful for testing anumber of properties of graphs, including\nwhether there is a path from one vertex to another and whether or not a graph is\nconnected.\nDepth-first search in a graph G is analogous to wandering in a labyrinth with\na string and a can of paint without getting lost. We begin at a specific starting\nvertex sin G, which weinitialize by fixing one end of our string to sand painting\ns as \u201cvisited.\u201d The vertex s is now our \u201ccurrent\u201d vertex. In general, if we call\nourcurrent vertexu,wetraverseGbyconsidering anarbitrary edge(u,v)incident\nto the current vertex u. If the edge (u,v) leads us to a vertex v that is already\nvisited (that is, painted), we ignore that edge. If, on the other hand, (u,v) leads\nto an unvisited vertex v, then we unroll our string, and go to v. We then paint\nv as \u201cvisited,\u201d and make it the current vertex, repeating the computation above.\nEventually, we will get to a \u201cdead end,\u201d that is, acurrent vertex v such that all the\nedges incident to v lead to vertices already visited. To get out of this impasse, we\nrollourstringbackup,backtrackingalongtheedgethatbroughtustov,goingback\nto apreviously visited vertex u. Wethen make u our current vertex and repeat the\ncomputation above for any edges incident to u that we have not yet considered. If\nall of u\u2019s incident edges lead to visited vertices, then we again roll up our string\nand backtrack to the vertex we came from to get to u, and repeat the procedure at\nthat vertex. Thus, we continue to backtrack along the path that we have traced so\nfar until we find a vertex that has yet unexplored edges, take one such edge, and\ncontinuethetraversal. Theprocessterminateswhenourbacktrackingleadsusback\ntothestartvertexs,andtherearenomoreunexplored edgesincident tos.\nThe pseudocode for a depth-first search traversal starting at a vertex u (see\nCode Fragment 14.4) follows our analogy with string and paint. Weuse recursion\nto implement the string analogy, and we assume that we have a mechanism (the\npaintanalogy)todeterminewhetheravertexoredgehasbeenpreviouslyexplored.\nAlgorithmDFS(G, u):\nInput: AgraphGandavertexuofG\nOutput: Acollection ofverticesreachable fromu,withtheirdiscoveryedges\nMarkvertexuasvisited.\nforeachofu\u2019soutgoing edges,e=(u,v)do\nifvertexvhasnotbeenvisited then\nRecordedgeeasthediscovery edgeforvertexv.\nRecursively callDFS(G,v).\nCodeFragment14.4: TheDFSalgorithm.\nwww.it-ebooks.info\n632 Chapter14. GraphAlgorithms\nClassifying Graph Edges with DFS\nAnexecution of depth-first search can be used to analyze the structure of agraph,\nbased upon the way in which edges are explored during the traversal. The DFS\nprocess naturally identifies what is known as the depth-first search tree rooted at\nastarting vertex s. Whenever anedge e=(u,v) isused todiscover anew vertex v\nduringtheDFSalgorithmofCodeFragment14.4,thatedgeisknownasadiscovery\nedgeortreeedge,asorientedfromutov. Allotheredgesthatareconsideredduring\nthe execution of DFS are known as nontree edges, which take us to a previously\nvisitedvertex. Inthecaseofanundirectedgraph,wewillfindthatallnontreeedges\nthat are explored connect the current vertex to one that is an ancestor of it in the\nDFS tree. We will call such an edge a back edge. When performing a DFS on a\ndirected graph,therearethreepossiblekindsofnontreeedges:\nbackedges,whichconnect avertextoanancestor intheDFStree\n\u2022\nforwardedges, whichconnectavertextoadescendant intheDFStree\n\u2022\ncrossedges,whichconnectavertextoavertexthatisneitheritsancestornor\n\u2022\nitsdescendant\nAn example application of the DFSalgorithm on a directed graph is shown in\nFigure 14.8, demonstrating each type of nontree edge. An example application of\ntheDFSalgorithm onanundirected graphisshowninFigure14.9.\n1\nBOS\nBOS\nORD ORD 5\nJFK\nJFK 7 2\nSFO\nSFO\nDFW\nDFW\nLAX\nLAX 3\n4\nMIA\nMIA 6\n(a) (b)\nFigure 14.8: An example of a DFS in a directed graph, starting at vertex (BOS):\n(a)intermediatestep,where,forthefirsttime,aconsiderededgeleadstoanalready\nvisitedvertex(DFW);(b)thecompletedDFS.Thetreeedgesareshownwiththick\nblue lines, the back edges are shown with dashed blue lines, and the forward and\ncross edges areshownwith dotted black lines. Theorder inwhich thevertices are\nvisited isindicated byalabelnexttoeachvertex. Theedge(ORD,DFW)isaback\nedge, but(DFW,ORD)isaforward edge. Edge(BOS,SFO)isaforward edge, and\n(SFO,LAX)isacrossedge.\nwww.it-ebooks.info\n14.3. GraphTraversals 633\nA B C D A B C D\nE F G H E F G H\nI J K L I J K L\nM N O P M N O P\n(a) (b)\nA B C D A B C D\nE F G H E F G H\nI J K L I J K L\nM N O P M N O P\n(c) (d)\nA B C D A B C D\nE F G H E F G H\nI J K L I J K L\nM N O P M N O P\n(e) (f)\nFigure14.9: Exampleofdepth-firstsearchtraversalonanundirectedgraphstarting\nat vertex A. We assume that a vertex\u2019s adjacencies are considered in alphabetical\norder. Visited vertices and explored edges are highlighted, with discovery edges\ndrawn as solid lines and nontree (back) edges as dashed lines: (a) input graph;\n(b)pathoftreeedges, tracedfromAuntilbackedge(G,C)isexamined; (c)reach-\ning F, which is a dead end; (d) after backtracking to I, resuming with edge (I,M),\nandhittinganotherdeadendatO;(e)afterbacktrackingtoG,continuingwithedge\n(G,L),andhittinganotherdeadendatH;(f)finalresult.\nwww.it-ebooks.info\n634 Chapter14. GraphAlgorithms\nProperties of a Depth-First Search\nThere are a number of observations that we can make about the depth-first search\nalgorithm, many of which derive from the way the DFS algorithm partitions the\nedgesofagraphGintogroups. Wewillbeginwiththemostsignificantproperty.\nProposition 14.12: LetGbeanundirectedgraphonwhichaDFStraversalstart-\ningatavertexs hasbeenperformed. Thenthetraversalvisitsallverticesinthe\nconnectedcomponentofs,andthediscoveryedgesformaspanningtreeofthe\nconnectedcomponentofs.\nJustification: Supposethereisatleastonevertexwins\u2019sconnectedcomponent\nnotvisited,andletvbethefirstunvisitedvertexonsomepathfromstow(wemay\nhave v=w). Since v is the first unvisited vertex on this path, it has a neighbor u\nthat was visited. But when wevisited u, we must have considered the edge (u,v);\nhence, it cannot be correct that v is unvisited. Therefore, there are no unvisited\nverticesins\u2019sconnected component.\nSince weonly follow a discovery edge when wego to an unvisited vertex, we\nwill never form a cycle with such edges. Therefore, the discovery edges form a\nconnected subgraph without cycles, hence a tree. Moreover, this is a spanning\ntree because, as we have just seen, the depth-first search visits each vertex in the\nconnected component ofs.\nProposition 14.13: LetG~ beadirectedgraph.Depth-firstsearchonG~ startingat\navertexsvisitsalltheverticesofG~ thatarereachablefroms.Also,theDFStree\ncontainsdirectedpathsfromstoeveryvertexreachablefroms.\nJustification: Let V be the subset of vertices of G~ visited by DFS starting at\ns\nvertex s. We want to show that V contains s and every vertex reachable from s\ns\nbelongstoV . Supposenow,forthesakeofacontradiction, thatthereisavertexw\ns\nreachablefromsthatisnotinV . Consideradirectedpathfromstow,andlet(u,v)\ns\nbe the first edge on such a path taking us out ofV , that is, u is inV but v is not\ns s\ninV . When DFSreaches u, itexplores all the outgoing edges ofu, and thus must\ns\nalsoreachvertexvviaedge (u,v). Hence, vshould beinV ,andwehaveobtained\ns\nacontradiction. Therefore,V mustcontain everyvertexreachable froms.\ns\nWeprovethesecond factbyinduction onthesteps ofthealgorithm. Weclaim\nthateachtimeadiscoveryedge(u,v)isidentified,thereexistsadirectedpathfrom\ns to v in the DFS tree. Since u must have previously been discovered, there exists\napath from stou,sobyappending theedge (u,v)tothat path, wehave adirected\npathfromstov.\nNote that since back edges always connect a vertex v to a previously visited\nvertex u, each back edge implies a cycle in G, consisting of the discovery edges\nfromutovplusthebackedge(u,v).\nwww.it-ebooks.info\n14.3. GraphTraversals 635\nRunning Time of Depth-First Search\nIntermsofitsrunning time,depth-first search isanefficientmethodfortraversing\nagraph. Notethat DFSiscalled atmostonce oneachvertex(since itgetsmarked\nas visited), and therefore every edge is examined at most twice for an undirected\ngraph, once from each of its end vertices, and at most once in a directed graph,\nfrom its origin vertex. If we let n n be the number of vertices reachable from\ns\n\u2264\na vertex s, and m m be the number of incident edges to those vertices, a DFS\ns\n\u2264\nstartingatsrunsinO(n +m )time,providedthefollowingconditionsaresatisfied:\ns s\nThe graph is represented by a data structure such that creating and iterating\n\u2022\nthrough the outgoingEdges(v) takes O(deg(v)) time, and the opposite(v, e)\nmethod takes O(1) time. The adjacency list structure is one such structure,\nbuttheadjacency matrixstructure isnot.\nWehaveawayto\u201cmark\u201davertexoredgeasexplored, andtotestifavertex\n\u2022\nor edge has been explored in O(1) time. We discuss ways of implementing\nDFStoachievethisgoalinthenextsection.\nGiventheassumptions above,wecansolveanumberofinteresting problems.\nProposition 14.14: LetGbeanundirectedgraphwithnverticesandmedges.A\nDFStraversalofGcanbeperformedinO(n+m)time,andcanbeusedtosolve\nthefollowingproblemsinO(n+m)time:\nComputingapathbetweentwogivenverticesofG,ifoneexists.\n\u2022\nTestingwhetherGisconnected.\n\u2022\nComputingaspanningtreeofG,ifGisconnected.\n\u2022\nComputingtheconnectedcomponentsofG.\n\u2022\nComputingacycleinG,orreportingthatGhasnocycles.\n\u2022\nProposition 14.15: LetG~ beadirectedgraphwithn verticesandm edges. A\nDFStraversalofG~ canbeperformedinO(n+m)time,andcanbeusedtosolve\nthefollowingproblemsinO(n+m)time:\nComputingadirectedpathbetweentwogivenverticesofG~,ifoneexists.\n\u2022\nComputingthesetofverticesofG~ thatarereachablefromagivenvertexs.\n\u2022\nTestingwhetherG~ isstronglyconnected.\n\u2022\nComputingadirectedcycleinG~,orreportingthatG~ isacyclic.\n\u2022\nThe justification of Propositions 14.14 and 14.15 is based on algorithms that\nuseslightlymodifiedversionsoftheDFSalgorithmassubroutines. Wewillexplore\nsomeofthoseextensions intheremainderofthissection.\nwww.it-ebooks.info\n636 Chapter14. GraphAlgorithms\n14.3.2 DFS Implementation and Extensions\nWe will begin by providing a Java implementation of the depth-first search al-\ngorithm. We originally described the algorithm with pseudocode in Code Frag-\nment 14.4. In order to implement it, wemust have amechanism for keeping track\nofwhichverticeshavebeenvisited,andforrecordingtheresultingDFStreeedges.\nForthisbookkeeping, weusetwoauxiliarydatastructures. First,wemaintainaset,\nnamedknown,containing verticesthathavealreadybeenvisited. Second,wekeep\namap,namedforest,thatassociates, withavertexv,theedgeeofthegraphthatis\nusedtodiscoverv(ifany). OurDFSmethodispresented inCodeFragment14.5.\n1 /\u2217\u2217 Performs depth-first search of Graph g starting at Vertex u. \u2217/\n2 public static <V,E> void DFS(Graph<V,E> g, Vertex<V> u,\n3 Set<Vertex<V>> known, Map<Vertex<V>,Edge<E>> forest)\n{\n4 known.add(u); // u has been discovered\n5 for (Edge<E> e : g.outgoingEdges(u)) // for every outgoing edge from u\n{\n6 Vertex<V> v = g.opposite(u, e);\n7 if (!known.contains(v))\n{\n8 forest.put(v, e); // e is the tree edge that discovered v\n9 DFS(g, v, known, forest); // recursively explore from v\n10\n}\n11\n}\n12\n}\nCode Fragment 14.5: Recursive implementation of depth-first search on a graph,\nstartingatadesignatedvertexu. Asanoutcomeofacall,visitedverticesareadded\ntotheknownset,anddiscoveryedgesareaddedtotheforest.\nOur DFS method does not make any assumption about how the Set or Map\ninstances are implemented; however, the O(n+m) running-time analysis of the\nprevious section does presume that wecan \u201cmark\u201d a vertex as explored or test the\nstatus of a vertex in O(1) time. If we use hash-based implementations of the set\nand map structure, then all of their operations run in O(1) expected time, and the\noverallalgorithmrunsinO(n+m)timewithveryhighprobability. Inpractice,this\nisacompromise wearewillingtoaccept.\nIfverticescanbenumberedfrom0,...,n 1(acommonassumptionforgraph\n\u2212\nalgorithms), then the set and map can be implemented more directly as a lookup\ntable, with a vertex label used as an index into an array of size n. In that case, the\nnecessary set and map operations run in worst-case O(1) time. Alternatively, we\ncan\u201cdecorate\u201d eachvertexwiththeauxiliary information, eitherbyleveraging the\ngeneric type of the element that is stored with each vertex, or by redesigning the\nVertex type to store additional fields. That would allow marking operations to be\nperformedinO(1)-time,withoutanyassumption aboutverticesbeingnumbered.\nwww.it-ebooks.info\n14.3. GraphTraversals 637\nReconstructing a Path from u to v\nWe can use the basic DFS method as a tool to identify the (directed) path leading\nfrom vertex u to v, if v is reachable from u. This path can easily be reconstructed\nfrom the information that wasrecorded in theforest of discovery edges during the\ntraversal. CodeFragment14.6provides animplementation ofasecondary method\nthatproducesanorderedlistofverticesonthepathfromutov,ifgiventhemapof\ndiscoveryedgesthatwascomputed bytheoriginal DFSmethod.\nTo reconstruct the path, we begin at the end of the path, examining the forest\nof discovery edges to determine what edge was used to reach vertex v. We then\ndeterminetheoppositevertexofthatedgeandrepeattheprocesstodeterminewhat\nedge was used to discover it. By continuing this process until reaching u, we can\nconstruct the entire path. Assuming constant-time lookup in the forest map, the\npathreconstruction takestimeproportional tothelengthofthepath,andtherefore,\nitrunsinO(n)time(inaddition tothetimeoriginally spentcallingDFS).\n1 /\u2217\u2217 Returns an ordered list of edges comprising the directed path from u to v. \u2217/\n2 public static <V,E> PositionalList<Edge<E>>\n3 constructPath(Graph<V,E> g, Vertex<V> u, Vertex<V> v,\n4 Map<Vertex<V>,Edge<E>> forest)\n{\n5 PositionalList<Edge<E>> path = new LinkedPositionalList<>();\n6 if (forest.get(v) != null) // v was discovered during the search\n{\n7 Vertex<V> walk = v; // we construct the path from back to front\n8 while (walk != u)\n{\n9 Edge<E> edge = forest.get(walk);\n10 path.addFirst(edge); // add edge to *front* of path\n11 walk = g.opposite(walk, edge); // repeat with opposite endpoint\n12\n}\n13\n}\n14 return path;\n15\n}\nCodeFragment14.6: Method to reconstruct a directed path from u to v, given the\ntrace of discovery from a DFS started at u. The method returns an ordered list of\nverticesonthepath.\nTesting for Connectivity\nWe can use the basic DFS method to determine whether a graph is connected. In\nthecase ofanundirected graph, wesimply startadepth-first search atanarbitrary\nvertex and then test whether known.size() equals natthe conclusion. Ifthe graph\nis connected, then by Proposition 14.12, all vertices will have been discovered;\nconversely, ifthegraph isnotconnected, there mustbeatleastonevertex vthatis\nnotreachable fromu,andthatwillnotbediscovered.\nwww.it-ebooks.info\n638 Chapter14. GraphAlgorithms\nFordirectedgraph,G~,wemaywishtotestwhetheritisstronglyconnected,that\nis,whetherforeverypairofverticesuandv,bothureachesvandvreachesu. Ifwe\nstartanindependentcalltoDFSfromeachvertex,wecoulddeterminewhetherthis\nwasthecase,butthosencallswhencombinedwouldruninO(n(n+m)). However,\nwe can determine if G~ is strongly connected much faster than this, requiring only\ntwodepth-first searches.\nWebeginbyperforming adepth-first searchofourdirected graphG~ startingat\nanarbitrary vertexs. IfthereisanyvertexofG~ thatisnotvisited bythistraversal,\nand is not reachable from s, then the graph is not strongly connected. If this first\ndepth-firstsearchvisitseachvertexofG~,weneedtothencheckwhethersisreach-\nable from all other vertices. Conceptually, we can accomplish this by making a\ncopyofgraphG~,butwiththeorientationofalledgesreversed. Adepth-firstsearch\nstarting at s in the reversed graph will reach every vertex that could reach s in the\noriginal. Inpractice, abetterapproach thanmaking anewgraphistoreimplement\na version of the DFS method that loops through all incoming edges to the current\nvertex, rather than all outgoing edges. Since this algorithm makes just two DFS\ntraversals ofG~,itrunsinO(n+m)time.\nComputing All Connected Components\nWhen agraph isnot connected, the next goal wemayhave is toidentify allof the\nconnected components of an undirected graph, orthe strongly connected compo-\nnentsofadirected graph. Wewillbeginbydiscussing theundirected case.\nIf an initial call to DFS fails to reach all vertices of a graph, we can restart a\nnew call to DFS at one of those unvisited vertices. An implementation of such a\ncomprehensive DFSCompletemethodisgiveninCodeFragment14.7. Itreturnsa\nmapthatrepresents aDFSforestfortheentiregraph. Wesaythisisaforestrather\nthanatree,because thegraphmaynotbeconnected.\nVerticesthatserveasrootsofDFStreeswithinthisforestwillnothavediscov-\neryedgesandwillnotappearaskeysinthereturnedmap. Therefore,thenumberof\nconnected components ofthegraphgisequaltog.numVertices() forest.size().\n\u2212\n1 /\u2217\u2217 Performs DFS for the entire graph and returns the DFS forest as a map. \u2217/\n2 public static <V,E> Map<Vertex<V>,Edge<E>> DFSComplete(Graph<V,E> g)\n{\n3 Set<Vertex<V>> known = new HashSet<>();\n4 Map<Vertex<V>,Edge<E>> forest = new ProbeHashMap<>();\n5 for (Vertex<V> u : g.vertices())\n6 if (!known.contains(u))\n7 DFS(g, u, known, forest); // (re)start the DFS process at u\n8 return forest;\n9\n}\nCodeFragment14.7:Top-levelmethodthatreturnsaDFSforestforanentiregraph.\nwww.it-ebooks.info\n14.3. GraphTraversals 639\nWe can further determine which vertices are in which component, either by\nexaminingthestructureoftheforestthatisreturned, orbymakingaminormodifi-\ncation tothe core DFSmethod to tag each vertex with acomponent number when\nitisfirstdiscovered. (SeeExerciseC-14.43.)\nAlthough the DFSComplete method makes multiple calls to the original DFS\nmethod, the total time spent by a call to DFSComplete is O(n+m). For an undi-\nrectedgraph,recallfromouroriginalanalysisonpage635thatasinglecalltoDFS\nstartingatvertexsrunsintimeO(n +m )wheren isthenumberofverticesreach-\ns s s\nablefroms,andm isthenumberofincidentedgestothosevertices. Becauseeach\ns\ncalltoDFSexploresadifferent component, thesumofn +m termsisn+m.\ns s\nThe situation is more complex for finding strongly connected components of\na directed graph. The O(n+m) total bound for a call to DFSComplete applies to\nthedirectedcaseaswell,becausewhenrestartingtheprocess,weproceedwiththe\nexisting setofknownvertices. ThisensuresthattheDFSsubroutine iscalledonce\noneachvertex,andtherefore thateachoutgoing edgeisexploredonlyonceduring\ntheentireprocess.\nAs an example, consider again the graph of Figure 14.8. If we were to start\nthe original DFS method at vertex ORD, the known set of vertices would become\nORD, DFW, SFO, LAX, MIA . If restarting the DFS method at vertex BOS,\n{ }\ntheoutgoing edgestovertices SFOandMIAwouldnotresultinfurther recursion,\nbecausethoseverticesaremarkedasknown.\nHowever, the forest returned by a single call to DFSComplete does not rep-\nresent the strongly connected components of the graph. There exists an approach\nfor computing those components in O(n+m) time, making use of two calls to\nDFSComplete,butthedetailsarebeyondthescopeofthisbook.\nDetecting Cycles with DFS\nFor both undirected and directed graphs, a cycle exists if and only if a back edge\nexistsrelativetotheDFStraversalofthatgraph. Itiseasytoseethatifabackedge\nexists, a cycle exists by taking the back edge from the descendant to its ancestor\nand then following the tree edges back to the descendant. Conversely, if a cycle\nexistsinthegraph,theremustbeabackedgerelativetoaDFS(althoughwedonot\nprovethisfacthere).\nAlgorithmically, detecting a back edge in the undirected case is easy, because\nalledges areeither tree edges orback edges. Inthecase ofadirected graph, addi-\ntional modifications to the core DFS implementation are needed to properly cate-\ngorize anontree edge asaback edge. Whenadirected edgeisexplored leading to\napreviouslyvisitedvertex,wemustrecognizewhetherthatvertexisanancestorof\nthecurrentvertex. Thiscanbeaccomplished, forexample,bymaintaining another\nset, with all vertices upon which a recursive call to DFS is currently active. We\nleavedetailsasanexercise(C-14.42).\nwww.it-ebooks.info\n640 Chapter14. GraphAlgorithms\n14.3.3 Breadth-First Search\nThe advancing and backtracking of a depth-first search, as described in the previ-\nous section, defines a traversal that could be physically traced by a single person\nexploring a graph. In this section, we will consider another algorithm for travers-\ningaconnectedcomponentofagraph,knownasabreadth-firstsearch(BFS).The\nBFS algorithm is more akin to sending out, in all directions, many explorers who\ncollectively traverse agraphincoordinated fashion.\nA BFS proceeds in rounds and subdivides the vertices into levels. BFS starts\natvertex s, whichisatlevel0. Inthefirstround, wepaint as\u201cvisited,\u201d all vertices\nadjacent to the start vertex s; these vertices are one step away from the beginning\nand are placed into level 1. In the second round, we allow all explorers to go\ntwo steps (i.e., edges) away from the starting vertex. These new vertices, which\nare adjacent to level 1 vertices and not previously assigned to a level, are placed\ninto level 2 and marked as \u201cvisited.\u201d This process continues in similar fashion,\nterminating whennonewverticesarefoundinalevel.\nA Java implementation of BFS is given in Code Fragment 14.8. We follow a\nconvention similar tothat of DFS(Code Fragment 14.5), maintaining aknown set\nofvertices, and storing the BFStree edges in amap. Weillustrate aBFStraversal\ninFigure14.10.\n1 /\u2217\u2217 Performs breadth-first search of Graph g starting at Vertex u. \u2217/\n2 public static <V,E> void BFS(Graph<V,E> g, Vertex<V> s,\n3 Set<Vertex<V>> known, Map<Vertex<V>,Edge<E>> forest)\n{\n4 PositionalList<Vertex<V>> level = new LinkedPositionalList<>();\n5 known.add(s);\n6 level.addLast(s); // first level includes only s\n7 while (!level.isEmpty())\n{\n8 PositionalList<Vertex<V>> nextLevel = new LinkedPositionalList<>();\n9 for (Vertex<V> u : level)\n10 for (Edge<E> e : g.outgoingEdges(u))\n{\n11 Vertex<V> v = g.opposite(u, e);\n12 if (!known.contains(v))\n{\n13 known.add(v);\n14 forest.put(v, e); // e is the tree edge that discovered v\n15 nextLevel.addLast(v); // v will be further considered in next pass\n16\n}\n17\n}\n18 level = nextLevel; // relabel \u2019next\u2019 level to become the current\n19\n}\n20\n}\nCodeFragment14.8: Implementation ofbreadth-first search onagraph, starting at\nadesignated vertexs.\nwww.it-ebooks.info\n14.3. GraphTraversals 641\n0 0 1\nA B C D A B C D\nE F G H E F G H\nI J K L I J K L\nM N O P M N O P\n(a) (b)\n0 1 2 3\n0 1 2\nA B C D\nA B C D\nE F G H\nE F G H\nI J K L\nI J K L\nM N O P\nM N O P\n(c) (d)\n0 1 2 3 0 1 2 3\nA B C D A B C D\nE F G H E F G H\n4 4\nI J K L I J K L\nM N O P M N O P 5\n(e) (f)\nFigure14.10: Exampleofbreadth-firstsearchtraversal, wheretheedgesincidentto\navertexareconsideredinalphabeticalorderoftheadjacentvertices. Thediscovery\nedges are shown with solid lines and the nontree (cross) edges are shown with\ndashed lines: (a) starting thesearch atA;(b)discovery of level1; (c)discovery of\nlevel2;(d)discoveryoflevel3;(e)discoveryoflevel4;(f)discoveryoflevel5.\nwww.it-ebooks.info\n642 Chapter14. GraphAlgorithms\nWhen discussing DFS, we described a classification of nontree edges being\neither back edges, which connect a vertex to one of its ancestors, forward edges,\nwhich connect a vertex to one of its descendants, or cross edges, which connect a\nvertex to another vertex that is neither its ancestor nor itsdescendant. ForBFSon\nanundirected graph, allnontree edges arecrossedges (seeExercise C-14.46), and\nforBFSonadirected graph,allnontreeedgesareeitherbackedgesorcrossedges\n(seeExerciseC-14.47).\nThe BFS traversal algorithm has a number of interesting properties, some of\nwhichweexploreinthepropositionthatfollows. Mostnotably,apathinabreadth-\nfirst search tree rooted at vertex s to any other vertex v is guaranteed to be the\nshortest suchpathfromstovintermsofthenumberofedges.\nProposition 14.16: LetG beanundirectedordirectedgraphonwhichaBFS\ntraversalstartingatvertexshasbeenperformed.Then\nThetraversalvisitsallverticesofGthatarereachablefroms.\n\u2022\nForeachvertexvatleveli,thepathoftheBFStreeT betweensandvhasi\n\u2022\nedges,andanyotherpathofGfromstovhasatleastiedges.\nIf(u,v)isanedgethatisnotintheBFStree,thenthelevelnumberofvcan\n\u2022\nbeatmost1greaterthanthelevelnumberofu.\nWeleavethejustification ofthisproposition asExerciseC-14.49.\nThe analysis of the running time of BFS is similar to the one of DFS, with\nthe algorithm running in O(n+m) time, or more specifically, in O(n +m ) time\ns s\nif n is the number of vertices reachable from vertex s, and m m is the num-\ns s\n\u2264\nber of incident edges to those vertices. To explore the entire graph, the process\ncanberestartedatanothervertex,akintotheDFSCompletemethodofCodeFrag-\nment14.7. Theactualpathfromvertexstovertexvcanbereconstructed usingthe\nconstructPathmethodofCodeFragment14.6\nProposition 14.17: LetG beagraphwithn verticesandm edgesrepresented\nwiththeadjacencyliststructure.ABFStraversalofGtakesO(n+m)time.\nAlthough our implementation of BFSin Code Fragment 14.8 progresses level\nby level, the BFS algorithm can also be implemented using a single FIFO queue\nto represent the current fringe of the search. Starting with the source vertex in the\nqueue, werepeatedly removethe vertexfrom thefront ofthequeue andinsert any\nofitsunvisited neighbors tothebackofthequeue. (SeeExerciseC-14.50.)\nIn comparing the capabilities of DFSand BFS,both can be used to efficiently\nfindthesetofverticesthatarereachablefromagivensource,andtodeterminepaths\nto those vertices. However, BFS guarantees that those paths use as few edges as\npossible. Foranundirected graph,bothalgorithmscanbeusedtotestconnectivity,\nto identify connected components, or to locate a cycle. For directed graphs, the\nDFSalgorithm isbetter suited for certain tasks, such asfinding adirected cycle in\nthegraph,orinidentifying thestronglyconnected components.\nwww.it-ebooks.info\n14.4. TransitiveClosure 643\n14.4 Transitive Closure\nWehaveseenthatgraph traversals canbeusedtoanswerbasicquestions ofreach-\nability in a directed graph. In particular, if we are interested in knowing whether\nthere is apath from vertex uto vertex vinagraph, wecan perform aDFSorBFS\ntraversal starting atuand observe whether visdiscovered. Ifrepresenting agraph\nwithanadjacencylistoradjacencymap,wecananswerthequestionofreachability\nforuandvinO(n+m)time(seePropositions 14.15and14.17).\nIncertainapplications, wemaywishtoanswermanyreachability queriesmore\nefficiently, in which case it may be worthwhile to precompute a more convenient\nrepresentation of a graph. For example, the first step for a service that computes\ndriving directions from an origin to a destination might be to assess whether the\ndestination is reachable. Similarly, in an electricity network, we may wish to be\nable to quickly determine whether current flows from one particular vertex to an-\nother. Motivated by such applications, we introduce the following definition. The\ntransitive closure of a directed graph G~ is itself a directed graph G~\u2217 such that the\nvertices of G~\u2217 are the same as the vertices of G~, and G~\u2217 has an edge (u,v), when-\neverG~ hasadirectedpathfromutov(including thecasewhere(u,v)isanedgeof\ntheoriginalG~).\nIfagraphisrepresentedasanadjacencylistoradjacencymap,wecancompute\nitstransitive closure inO(n(n+m))timebymaking useofngraph traversals, one\nfrom each starting vertex. For example, a DFS starting at vertex u can be used to\ndetermine all vertices reachable from u, and thus a collection of edges originating\nwithuinthetransitiveclosure.\nIntheremainderofthissection,weexploreanalternativetechniqueforcomput-\ningthetransitiveclosureofadirectedgraphthatisparticularlywellsuitedforwhen\na directed graph is represented by a data structure that supports O(1)-time lookup\nforthegetEdge(u,v)method(forexample, theadjacency-matrix structure). LetG~\nbeadirectedgraphwithnverticesandmedges. Wecomputethetransitiveclosure\nof G~ in a series of rounds. We initialize G~ =G~. We also arbitrarily number the\n0\nverticesofG~ asv ,v ,...,v . Wethenbeginthecomputationoftherounds,begin-\n1 2 n\nning with round 1. In a generic round k, we construct directed graph G~ starting\nk\nwith G~ =G~ and adding to G~ the directed edge (v,v ) ifdirected graph G~\nk k\u22121 k i j k\u22121\ncontains both the edges (v,v ) and (v ,v ). In this way, we will enforce a simple\ni k k j\nruleembodiedintheproposition thatfollows.\nProposition 14.18: Fori=1,...,n,directedgraphG~ hasanedge(v,v )ifand\nk i j\nonlyifdirectedgraph G~ hasadirectedpathfrom v tov , whoseintermediate\ni j\nvertices(ifany)areintheset v ,...,v . Inparticular, G~ isequaltoG~\u2217,the\n1 k n\n{ }\ntransitiveclosureofG~.\nwww.it-ebooks.info\n644 Chapter14. GraphAlgorithms\nProposition14.18suggestsasimplealgorithmforcomputingthetransitiveclo-\nsureofG~ thatisbased ontheseriesofrounds tocompute eachG~ . Thisalgorithm\nk\nis known as the Floyd-Warshall algorithm, and its pseudocode is given in Code\nFragment 14.9. We illustrate an example run of the Floyd-Warshall algorithm in\nFigure14.11.\nAlgorithmFloydWarshall(G~):\nInput: Adirected graphG~ withnvertices\nOutput: ThetransitiveclosureG~\u2217 ofG~\nletv ,v ,...,v beanarbitrary numberingoftheverticesofG~\n1 2 n\nG~ = G~\n0\nfork = 1tondo\nG~ = G~\nk k\u22121\nforalli,jin 1,...,n withi= jandi,j=kdo\n{ } 6 6\nifbothedges(v,v )and(v ,v )areinG~ then\ni k k j k\u22121\naddedge(v,v )toG~ (ifitisnotalready present)\ni j k\nreturnG~\nn\nCodeFragment14.9:PseudocodefortheFloyd-Warshallalgorithm. Thisalgorithm\ncomputes the transitive closure G~\u2217 of G by incrementally computing a series of\ndirected graphsG~ ,G~ ,...,G~ ,fork=1,...,n.\n0 1 n\nFrom this pseudocode, we can easily analyze the running time of the Floyd-\nWarshallalgorithm assuming thatthedatastructure representing Gsupports meth-\nods getEdge and insertEdge in O(1) time. The main loop is executed ntimes and\ntheinnerloopconsiderseachofO(n2)pairsofvertices,performingaconstant-time\ncomputation for each one. Thus, the total running time of the Floyd-Warshall al-\ngorithm is O(n3). From the description and analysis above we may immediately\nderivethefollowingproposition.\nProposition 14.19: LetG~ beadirectedgraphwithnvertices,andletG~ berepre-\nsentedbyadatastructurethatsupportslookupandupdateofadjacencyinformation\ninO(1) time. ThentheFloyd-Warshallalgorithmcomputesthetransitiveclosure\nG~\u2217ofG~ inO(n3)time.\nPerformance of the Floyd-Warshall Algorithm\nAsymptotically, theO(n3)running timeoftheFloyd-Warshall algorithm isnobet-\nter than that achieved by repeatedly running DFS,once from each vertex, to com-\npute the reachability. However, the Floyd-Warshall algorithm matches the asymp-\ntoticbounds oftherepeated DFSwhenagraphisdense, orwhenagraphissparse\nbutrepresented asanadjacency matrix. (SeeExerciseR-14.13.)\nwww.it-ebooks.info\n14.4. TransitiveClosure 645\nv7 v7\nBOS BOS\nv4 v4\nORD ORD\nJFK JFK\nv2\nv6\nv2\nv6\nSFO SFO\nDFW DFW\nLAX LAX\nv3 v3\nv1 v1\nMIA MIA\n(a)\nv5\n(b)\nv5\nv7 v7\nBOS BOS\nv4 v4\nORD ORD\nJFK JFK\nv2\nv6\nv2\nv6\nSFO SFO\nDFW DFW\nLAX LAX\nv3 v3\nv1 v1\nMIA MIA\n(c)\nv5\n(d)\nv5\nv7\nBOS\nv7\nv4\nBOS\nv4\nORD\nORD\nJFK\nv2\nJFK\nv6\nv2\nSFO\nv6\nSFO\nDFW\nDFW LAX\nLAX\nv3\nv3 v1\nv1 MIA\nMIA\nv5\nv5\n(e) (f)\nFigure14.11: Sequence of directed graphs computed by the Floyd-Warshall algo-\nrithm: (a)initialdirectedgraphG~ =G~ andnumberingofthevertices;(b)directed\n0\ngraph G~ ; (c) G~ ; (d) G~ ; (e) G~ ; (f) G~ . Note that G~ = G~ = G~ . If directed\n1 2 3 4 5 5 6 7\ngraphG~ hastheedges(v,v )and(v ,v ),butnottheedge(v,v ),inthedraw-\nk\u22121 i k k j i j\ningofdirected graphG~ ,weshowedges(v,v )and(v ,v )withdashedlines,and\nk i k k j\nedge (v,v ) witha thick line. Forexample, in (b) existing edges (MIA,LAX)and\ni j\n(LAX,ORD)resultinnewedge(MIA,ORD).\nwww.it-ebooks.info\n646 Chapter14. GraphAlgorithms\nTheimportanceoftheFloyd-Warshall algorithm isthatitismucheasiertoim-\nplementthanrepeatedDFS,andmuchfasterinpracticebecausetherearerelatively\nfew low-level operations hidden within the asymptotic notation. The algorithm is\nparticularly well suited for the use of an adjacency matrix, as a single bit can be\nusedtodesignatethereachabilitymodeledasanedge(u,v)inthetransitiveclosure.\nHowever, note that repeated calls to DFS results in better asymptotic perfor-\nmance when the graph is sparse and represented using an adjacency list or adja-\ncency map. Inthat case, asingle DFSruns inO(n+m) time, and so thetransitive\nclosurecanbecomputedinO(n2+nm)time,whichispreferable toO(n3).\nJava Implementation\nWe will conclude with a Java implementation of the Floyd-Warshall algorithm,\nas presented inCode Fragment 14.10. Although the pseudocode for thealgorithm\ndescribesaseriesofdirectedgraphsG~ ,G~ ,...,G~ ,wedirectlymodifytheoriginal\n0 1 n\ngraph, repeatedly adding new edges to the closure as we progress through rounds\noftheFloyd-Warshall algorithm.\nAlso, the pseudocode for the algorithm describes the loops based on vertices\nbeing indexed from 0 to n 1. With our graph ADT, we prefer to use Java\u2019s for-\n\u2212\neach loop syntax directly on the vertices of the graph. Therefore, in Code Frag-\nment 14.10, variables i, j, and k are references tovertices, not integer indices into\nthesequence ofvertices.\nFinally, we make one additional optimization in the Java implementation, rel-\native to the pseudocode, by not bothering to iterate through values of j unless we\nhaveverifiedthatedge(i,k)existsinthecurrentversionoftheclosure.\n1 /\u2217\u2217 Converts graph g into its transitive closure. \u2217/\n2 public static <V,E> void transitiveClosure(Graph<V,E> g)\n{\n3 for (Vertex<V> k : g.vertices())\n4 for (Vertex<V> i : g.vertices())\n5 // verify that edge (i,k) exists in the partial closure\n6 if (i != k && g.getEdge(i,k) != null)\n7 for (Vertex<V> j : g.vertices())\n8 // verify that edge (k,j) exists in the partial closure\n9 if (i != j && j != k && g.getEdge(k,j) != null)\n10 // if (i,j) not yet included, add it to the closure\n11 if (g.getEdge(i,j) == null)\n12 g.insertEdge(i, j, null);\n13\n}\nCodeFragment14.10: Javaimplementation oftheFloyd-Warshall algorithm.\nwww.it-ebooks.info\n14.5. DirectedAcyclicGraphs 647\n14.5 Directed Acyclic Graphs\nDirected graphs without directed cycles are encountered in many applications.\nSuch a directed graph is often referred to as a directed acyclic graph, or DAG,\nforshort. Applications ofsuchgraphsincludethefollowing:\nPrerequisites betweencourses ofanacademicprogram.\n\u2022\nInheritance betweenclassesofanobject-oriented program.\n\u2022\nScheduling constraints betweenthetasksofaproject.\n\u2022\nWewillexplorethislatterapplication furtherinthefollowingexample:\nExample 14.20: Inordertomanagealargeproject,itisconvenienttobreakitup\nintoacollectionofsmallertasks. Thetasks,however,arerarelyindependent,be-\ncauseschedulingconstraintsexistbetweenthem.(Forexample,inahousebuilding\nproject,thetaskoforderingnailsobviouslyprecedesthetaskofnailingshingles\ntotheroofdeck.)Clearly,schedulingconstraintscannothavecircularities,because\ntheywouldmaketheprojectimpossible. (Forexample,inordertogetajobyou\nneedtohaveworkexperience,butinordertogetworkexperienceyouneedtohave\najob.) Theschedulingconstraintsimposerestrictionsontheorderinwhichthe\ntaskscanbeexecuted. Namely,ifaconstraintsaysthattaskamustbecompleted\nbeforetaskbisstarted,thenamustprecedebintheorderofexecutionofthetasks.\nThus,ifwemodelafeasiblesetoftasksasverticesofadirectedgraph,andwe\nplaceadirectededgefromutovwheneverthetaskforumustbeexecutedbefore\nthetaskforv,thenwedefineadirectedacyclicgraph.\n14.5.1 Topological Ordering\nThe example above motivates the following definition. Let G~ be a directed graph\nwithnvertices. AtopologicalorderingofG~ isanorderingv ,...,v ofthevertices\n1 n\nofG~ such that forevery edge (v,v )ofG~, itisthecase that i< j. Thatis, atopo-\ni j\nlogicalorderingisanorderingsuchthatanydirectedpathinG~ traversesverticesin\nincreasing order. Note that a directed graph may have more than one topological\nordering. (SeeFigure14.12.)\nProposition 14.21: G~ hasatopologicalorderingifandonlyifitisacyclic.\nJustification: The necessity (the \u201conly if\u201d part of the statement) is easy to\ndemonstrate. Suppose G~ is topologically ordered. Assume, for the sake of a con-\ntradiction, that G~ has a cycle consisting of edges (v ,v ),(v ,v ),...,(v ,v ).\ni0 i1 i1 i2 ik\u22121 i0\nBecauseofthetopological ordering, wemusthavei <i < <i <i ,which\n0 1 k\u22121 0\n\u00b7\u00b7\u00b7\nisclearlyimpossible. Thus,G~ mustbeacyclic.\nwww.it-ebooks.info\n648 Chapter14. GraphAlgorithms\n1 4 2 1\nA B A B\n2 3\nC C\nD D\nE 5 F E 4 F\n3 6 6 5\nG G\n7 7\nH H\n8 8\n(a) (b)\nFigure14.12: Twotopological orderings ofthesameacyclicdirectedgraph.\nWe now argue the sufficiency of the condition (the \u201cif\u201d part). Suppose G~ is\nacyclic. We will give an algorithmic description of how to build a topological\nordering for G~. Since G~ is acyclic, G~ must have a vertex with no incoming edges\n(that is, with in-degree 0). Let v be such a vertex. Indeed, if v did not exist,\n1 1\nthen in tracing a directed path from an arbitrary start vertex, we would eventually\nencounter apreviously visited vertex, thus contradicting the acyclicity of G~. Ifwe\nremovev fromG~,together withitsoutgoing edges, theresulting directedgraphis\n1\nstillacyclic. Hence,theresultingdirectedgraphalsohasavertexwithnoincoming\nedges, and we let v be such a vertex. By repeating this process until the directed\n2\ngraphbecomesempty,weobtainanorderingv ,...,v oftheverticesofG~. Because\n1 n\noftheconstruction above, if(v,v )isanedgeofG~,thenv mustbedeleted before\ni j i\nv canbedeleted, andthus,i< j. Therefore, v ,...,v isatopological ordering.\nj 1 n\nProposition 14.21\u2019s justification suggests an algorithm for computing a topo-\nlogicalorderingofadirectedgraph,whichwecalltopological sorting. Wepresent\na Java implementation of the technique in Code Fragment 14.11, and an example\nexecutionofthealgorithminFigure14.13. Ourimplementationusesamap,named\ninCount, to map each vertex v to a counter that represents the current number of\nincoming edges to v, excluding those coming from vertices that have previously\nbeen added to the topological order. As was the case with our graph traversals, a\nhash-based maponlyprovides O(1)expectedtimeaccess toitsentries, ratherthan\nworst-casetime. Thiscouldeasilybeconvertedtoworst-casetimeifverticescould\nbeindexedfrom0ton 1,orifwestorethecountasafieldofthevertexinstance.\n\u2212\nAs a side effect, the topological sorting algorithm of Code Fragment 14.11\nalso tests whether the given directed graph G~ is acyclic. Indeed, if the algorithm\nterminates without ordering all the vertices, then the subgraph of the vertices that\nhavenotbeenordered mustcontain adirectedcycle.\nwww.it-ebooks.info\n14.5. DirectedAcyclicGraphs 649\n1 /\u2217\u2217 Returns a list of verticies of directed acyclic graph g in topological order. \u2217/\n2 public static <V,E> PositionalList<Vertex<V>> topologicalSort(Graph<V,E> g)\n{\n3 // list of vertices placed in topological order\n4 PositionalList<Vertex<V>> topo = new LinkedPositionalList<>();\n5 // container of vertices that have no remaining constraints\n6 Stack<Vertex<V>> ready = new LinkedStack<>();\n7 // map keeping track of remaining in-degree for each vertex\n8 Map<Vertex<V>, Integer> inCount = new ProbeHashMap<>();\n9 for (Vertex<V> u : g.vertices())\n{\n10 inCount.put(u, g.inDegree(u)); // initialize with actual in-degree\n11 if (inCount.get(u) == 0) // if u has no incoming edges,\n12 ready.push(u); // it is free of constraints\n13\n}\n14 while (!ready.isEmpty())\n{\n15 Vertex<V> u = ready.pop();\n16 topo.addLast(u);\n17 for (Edge<E> e : g.outgoingEdges(u)) // consider all outgoing neighbors of u\n{\n18 Vertex<V> v = g.opposite(u, e);\n19 inCount.put(v, inCount.get(v) 1); // v has one less constraint without u\n\u2212\n20 if (inCount.get(v) == 0)\n21 ready.push(v);\n22\n}\n23\n}\n24 return topo;\n25\n}\nCode Fragment 14.11: Java implementation for the topological sorting algorithm.\n(Weshowanexampleexecution ofthisalgorithm inFigure14.13.)\nProposition 14.22: LetG~ beadirectedgraphwithnverticesandmedges,using\nanadjacencylistrepresentation.ThetopologicalsortingalgorithmrunsinO(n+m)\ntimeusingO(n)auxiliaryspace,andeithercomputesatopologicalorderingofG~\norfailstoincludesomevertices,whichindicatesthatG~ hasadirectedcycle.\nJustification: The initial recording of the n in-degrees uses O(n) time based\non the inDegree method. Say that a vertex u is visited by the topological sorting\nalgorithm when u is removed from the ready list. A vertex u can be visited only\nwhen inCount.get(u) is 0, which implies that all its predecessors (vertices with\noutgoing edges into u)were previously visited. Asa consequence, any vertex that\nis on a directed cycle will never be visited, and any other vertex will be visited\nexactly once. Thealgorithm traverses alltheoutgoing edgesofeachvisited vertex\nonce, so its running time is proportional to the number of outgoing edges of the\nvisited vertices. In accordance with Proposition 14.9, the running time is (n+m).\nRegarding thespace usage, observe that containers topo,ready,andinCount have\natmostoneentrypervertex,andtherefore useO(n)space.\nwww.it-ebooks.info\n650 Chapter14. GraphAlgorithms\n0 0 1 0 1 0\nA B A B A B\n1 0 2\nC C C\nD D D\nE 3 F E 2 F E 1 F\n1 2 1 2 0 2\nG G G\n2 2 2\nH 3 H 3 H 2\n(a) (b) (c)\n1 0 1 4 1 4\nA B A B A B\n2 2 2\nC C C\nD D D\nE 1 F E 0 F E 5 F\n3 2 3 1 3 0\nG G G\n1 1 1\nH 2 H 2 H 2\n(d) (e) (f)\n1 4 1 4 1 4\nA B A B A B\n2 2 2\nC C C\nD D D\nE 5 F E 5 F E 5 F\n3 6 3 6 3 6\nG G G\n0 7 7\nH 1 H 0 H 8\n(g) (h) (i)\nFigure 14.13: Example of a run of algorithm topologicalSort (Code Frag-\nment 14.11). The label near a vertex shows its current inCount value, and its\neventualrankintheresulting topological order. Thehighlighted vertexisonewith\ninCount equal to zero that will become the next vertex in the topological order.\nDashed lines denote edges that have already been examined, which are no longer\nreflectedintheinCountvalues.\nwww.it-ebooks.info\n14.6. ShortestPaths 651\n14.6 Shortest Paths\nAswesawinSection14.3.3, thebreadth-first search strategy canbeusedtofinda\npathwithasfewedgesaspossiblefromsomestartingvertextoeveryothervertexin\naconnectedgraph. Thisapproachmakessenseincaseswhereeachedgeisasgood\nasanyother, buttherearemanysituations wherethisapproachisnotappropriate.\nFor example, we might want to use a graph to represent the roads between\ncities,andwemightbeinterested infindingthefastestwaytotravelcross-country.\nInthiscase,itisprobablynotappropriateforalltheedgestobeequaltoeachother,\nfor some inter-city distances will likely be much larger than others. Likewise, we\nmightbeusingagraphtorepresent acomputernetwork(suchastheInternet), and\nwe might be interested in finding the fastest way to route a data packet between\ntwo computers. In this case, it again may not be appropriate for all the edges to\nbe equal to each other, for some connections in a computer network are typically\nmuch faster than others (for example, some edges might represent low-bandwidth\nconnections, while others might represent high-speed, fiber-optic connections). It\nisnatural, therefore, toconsider graphswhoseedgesarenotweightedequally.\n14.6.1 Weighted Graphs\nA weighted graph is a graph that has a numeric (for example, integer) label w(e)\nassociated with each edge e, called the weight of edge e. For e = (u,v), we let\nnotationw(u,v)=w(e). WeshowanexampleofaweightedgraphinFigure14.14.\n2704\n1846 867\nORD BOS\n187\n740 JFK\nSFO 1464\n802\n337\nLAX 1090\n1235\n1258\nDFW 1121\n2342\nMIA\nFigure14.14: A weighted graph whose vertices represent major U.S. airports and\nwhoseedgeweightsrepresentdistancesinmiles. ThisgraphhasapathfromJFKto\nLAXoftotalweight2,777 (going through ORDandDFW).Thisistheminimum-\nweightpathinthegraphfromJFKtoLAX.\nwww.it-ebooks.info\n652 Chapter14. GraphAlgorithms\nDefining Shortest Paths in a Weighted Graph\nLet G be a weighted graph. The length (or weight) of a path is the sum of the\nweightsoftheedgesofP. Thatis,ifP=((v ,v ),(v ,v ),...,(v ,v )),thenthe\n0 1 1 2 k\u22121 k\nlengthofP,denoted w(P),isdefinedas\nk\u22121\nw(P)= \u2211w(v,v ).\ni i+1\ni=0\nThe distance from a vertex u to a vertex v in G, denoted d(u,v), is the length of a\nminimum-length path(alsocalledshortestpath)fromutov,ifsuchapathexists.\nPeopleoften usetheconvention thatd(u,v)= ifthere isnopathatallfrom\n\u221e\nu to v in G. Even if there is a path from u to v in G, however, if there is a cycle\nin G whose total weight is negative, the distance from u to v may not be defined.\nFor example, suppose vertices in G represent cities, and the weights of edges in\nG represent how much money it costs to go from one city to another. If someone\nwerewilling to actually pay ustogo from say JFKtoORD,then the \u201ccost\u201d ofthe\nedge (JFK,ORD)would be negative. If someone else were willing to pay us to go\nfromORDtoJFK,thentherewouldbeanegative-weight cycleinGanddistances\nwould no longer be defined. That is, anyone could now build a path (with cycles)\nin G from any city A to another city B that first goes to JFK and then cycles as\nmany times as he or she likes from JFK to ORD and back, before going on to B.\nThe existence of such paths would allow us to build arbitrarily low negative-cost\npaths (and, in this case, make a fortune in the process). But distances cannot be\narbitrarily lownegativenumbers. Thus,anytimeweuseedgeweightstorepresent\ndistances, wemustbecarefulnottointroduce anynegative-weight cycles.\nSuppose weare given aweighted graph G, and weare asked to find ashortest\npathfromsomevertexstoeachothervertexinG,viewingtheweightsontheedges\nas distances. In this section, we explore efficient ways of finding all such shortest\npaths, if they exist. The first algorithm we discuss is for the simple, yet common,\ncasewhenalltheedgeweightsinGarenonnegative(thatis,w(e) 0foreachedge\n\u2265\neofG); hence, weknow inadvance that there areno negative-weight cycles in G.\nRecallthatthespecialcaseofcomputingashortestpathwhenallweightsareequal\ntoonewassolvedwiththeBFStraversal algorithm presented inSection14.3.3.\nThere is an interesting approach for solving this single-source problem based\nonthegreedy-methoddesignpattern(Section13.4.2). Recallthatinthispatternwe\nsolvetheproblemathandbyrepeatedlyselectingthebestchoicefromamongthose\navailableineachiteration. Thisparadigmcanoftenbeusedinsituations wherewe\naretrying tooptimize somecost function overacollection ofobjects. Wecan add\nobjects toourcollection, oneatatime, always picking the nextonethatoptimizes\nthefunction fromamongthoseyettobechosen.\nwww.it-ebooks.info\n14.6. ShortestPaths 653\n14.6.2 Dijkstra\u2019s Algorithm\nThemainideainapplyingthegreedy-method patterntothesingle-source shortest-\npath problem is toperform a\u201cweighted\u201d breadth-first search starting at the source\nvertex s. In particular, wecan use the greedy method todevelop an algorithm that\niteratively growsa\u201ccloud\u201dofverticesoutofs,withtheverticesentering thecloud\nin order of their distances from s. Thus, in each iteration, the next vertex chosen\nis the vertex outside the cloud that is closest to s. The algorithm terminates when\nno more vertices are outside the cloud (or when those outside the cloud are not\nconnected to those within the cloud), at which point we have a shortest path from\ns to every vertex of G that is reachable from s. This approach is a simple, but\nneverthelesspowerful,exampleofthegreedy-method designpattern. Applyingthe\ngreedy method to the single-source, shortest-path problem, results inanalgorithm\nknownasDijkstra\u2019s algorithm.\nEdge Relaxation\nLetus define alabel D[v]for each vertex v inV, which weuse to approximate the\ndistanceinGfromstov. ThemeaningoftheselabelsisthatD[v]willalwaysstore\nthelength ofthebestpathwehavefoundsofarfromstov. Initially, D[s]=0and\nD[v]= foreachv=s,andwedefinethesetC,whichisour\u201ccloud\u201dofvertices,\n\u221e 6\nto initially be the empty set. Ateach iteration of the algorithm, we select a vertex\nu not inC with smallest D[u] label, and we pull u intoC. (In general, we will use\na priority queue to select among the vertices outside the cloud.) In the very first\niteration we will, of course, pull s into C. Once a new vertex u is pulled into C,\nwe update the label D[v] of each vertex v that is adjacent to u and is outside ofC,\nto reflect the fact that there may be a new and better way to get to v via u. This\nupdate operation is known as a relaxation procedure, for it takes an old estimate\nand checks if it can be improved to get closer to its true value. The specific edge\nrelaxation operation isasfollows:\nEdgeRelaxation:\nifD[u]+w(u,v)<D[v]then\nD[v] = D[u]+w(u,v)\nAlgorithm Description and Example\nWe give the pseudocode for Dijkstra\u2019s algorithm in Code Fragment 14.12, and il-\nlustrateseveraliterations ofDijkstra\u2019s algorithm inFigures14.15through 14.17.\nwww.it-ebooks.info\n654 Chapter14. GraphAlgorithms\nAlgorithmShortestPath(G,s):\nInput: Adirected orundirected graph Gwithnonnegative edgeweights, anda\ndistinguished vertexsofG.\nOutput: Thelengthofashortest pathfromstovforeachvertexvofG.\nInitializeD[s] = 0andD[v] = foreachvertexv=s.\n\u221e 6\nLetapriorityqueueQcontain alltheverticesofGusingtheDlabelsaskeys.\nwhileQisnotemptydo\npullanewvertexuintothecloud\n{ }\nu = valuereturned byQ.removeMin()\nforeachedge(u,v)suchthatvisinQ do\nperformtherelaxation procedure onedge(u,v)\n{ }\nifD[u]+w(u,v)<D[v]then\nD[v] = D[u]+w(u,v)\nChangethekeyofvertexvinQtoD[v].\nreturnthelabelD[v]ofeachvertexv\nCode Fragment 14.12: Pseudocode for Dijkstra\u2019s algorithm, solving the single-\nsourceshortest-path problem foranundirected ordirected graph.\n\u221e \u221e\n2704 2704\nBOS BOS\n867 \u221e 867 \u221e\n\u221e 621\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n\u221e 1846 621 JFK \u221e \u221e 1846 621 JFK 184\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 0 BWI 1090 1464 1391 0 BWI 1090\n337 337\nDFW \u221e DFW \u221e\nLAX 1235 946 LAX 1235 946\n1121 1121\n\u221e \u221e\n2342 MIA 2342 MIA\n\u221e 946\n(a) (b)\nFigure 14.15: An example execution of Dijkstra\u2019s shortest-path algorithm on a\nweighted graph. The start vertex is BWI. A box next to each vertex v stores the\nlabel D[v]. The edges of the shortest-path tree are drawn as thick arrows, and for\neach vertex u outside the \u201ccloud\u201d we show the current best edge for pulling in u\nwithathickline. (Continues inFigure14.16.)\nwww.it-ebooks.info\n14.6. ShortestPaths 655\n371 371\n2704 2704\nBOS BOS\n867 328 867 328\n621 621\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n\u221e 1846 621 JFK 184 \u221e 1846 621 JFK 184\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 0 BWI 1090 1464 1391 0 BWI 1090\n337 337\nDFW 1575 DFW 1575\nLAX 1235 946 LAX 1235 946\n1121 1121\n\u221e \u221e\n2342 MIA 2342 MIA\n946 946\n(c) (d)\n371 371\n2704 2704\nBOS BOS\n867 328 867 328\n621 621\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n3075 1846 621 JFK 184 2467 1846 621 JFK 184\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 0 BWI 1090 1464 1391 0 BWI 1090\n337 337\nDFW 1575 DFW 1423\nLAX 1235 946 LAX 1235 946\n1121 1121\n\u221e \u221e\n2342 MIA 2342 MIA\n946 946\n(e) (f)\n371 371\n2704 2704\nBOS BOS\n867 328 867 328\n621 621\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n2467 1846 621 JFK 184 2467 1846 621 JFK 184\n1258 1258\nSFO 802 184 SFO 802 184\n1464 1391 0 BWI 1090 1464 1391 0 BWI 1090\n337 337\nDFW 1423 DFW 1423\nLAX 1235 946 LAX 1235 946\n1121 1121\n3288 2658\n2342 MIA 2342 MIA\n946 946\n(g) (h)\nFigure 14.16: An example execution of Dijkstra\u2019s shortest-path algorithm on a\nweightedgraph. (Continued fromFigure14.15;continues inFigure14.17.)\nwww.it-ebooks.info\n656 Chapter14. GraphAlgorithms\n371 371\n2704 2704\nBOS BOS\n867 328 867 328\n621 621\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n2 S 46 F 7 O 1846 802 621 18 JF 4 K 184 1258 2 S 46 F 7 O 1846 802 621 1 J 8 F 4 K 184 1258\n337 1464 1391 0 BWI 1090 337 1464 1391 0 BWI 1090\nLAX 1235 DFW 1423 946 LAX 1235 DFW 1423 946\n1121 1121\n2658 2658\n2342 MIA 2342 MIA\n946 946\n(i) (j)\nFigure 14.17: An example execution of Dijkstra\u2019s shortest-path algorithm on a\nweightedgraph. (Continued fromFigure14.16.)\nWhy It Works\nThe interesting aspect of the Dijkstra algorithm is that, at the moment a vertex u\nis pulled into C, its label D[u] stores the correct length of a shortest path from v\ntou. Thus, whenthealgorithm terminates, itwillhavecomputed theshortest-path\ndistance from s to every vertex of G. That is, it will have solved the single-source\nshortest-path problem.\nItisprobablynotimmediatelyclearwhyDijkstra\u2019salgorithmcorrectlyfindsthe\nshortest path from the start vertex s to each other vertex u in the graph. Why is it\nthatthedistancefromstouisequaltothevalueofthelabelD[u]atthetimevertex\nu is removed from the priority queue Q and added to the cloud C? The answer\ntothis question depends onthere being nonegative-weight edges inthe graph, for\nit allows the greedy method to work correctly, as we show in the proposition that\nfollows.\nProposition 14.23: InDijkstra\u2019salgorithm,wheneveravertexvispulledintothe\ncloud,thelabelD[v]isequaltod(s,v),thelengthofashortestpathfromstov.\nJustification: Suppose that D[v] > d(s,v) for some vertex v in V, and let z\nbe the first vertex the algorithm pulled into the cloud C (that is, removed from\nQ) such that D[z]>d(s,z). There is a shortest path P from s to z (for otherwise\nd(s,z)= =D[z]). Let us therefore consider the moment when z is pulled into\n\u221e\nC, and letybethe firstvertex ofP (whengoing from stoz) that isnotinC at this\nmoment. Let x be the predecessor of y in path P (note that we could have x=s).\n(SeeFigure14.18.) Weknow,byourchoiceofy,thatxisalreadyinCatthispoint.\nwww.it-ebooks.info\n14.6. ShortestPaths 657\nthefirst\u201cwrong\u201dvertexpicked\nzpickedimplies\nC\nthatD[z] D[y]\n\u2264\nz\nD[z]>d(s,z)\ns\nD[x]=d(s,x)\nP\ny\nx D[y]=d(s,y)\nFigure14.18: Aschematicillustration forthejustification ofProposition 14.23.\nMoreover, D[x]=d(s,x), since z is the first incorrect vertex. When x was pulled\nintoC,wetested(andpossiblyupdated) D[y]sothatwehadatthatpoint\nD[y] D[x]+w(x,y)=d(s,x)+w(x,y).\n\u2264\nButsinceyisthenextvertexontheshortest pathfromstoz,thisimpliesthat\nD[y]=d(s,y).\nButwearenowatthemomentwhenwearepickingz,noty,tojoinC;hence,\nD[z] D[y].\n\u2264\nIt should be clear that a subpath of a shortest path is itself a shortest path. Hence,\nsinceyisontheshortest pathfromstoz,\nd(s,y)+d(y,z)=d(s,z).\nMoreover, d(y,z) 0becausetherearenonegative-weight edges. Therefore,\n\u2265\nD[z] D[y]=d(s,y) d(s,y)+d(y,z)=d(s,z).\n\u2264 \u2264\nButthiscontradicts thedefinitionofz;hence,therecanbenosuchvertexz.\nThe Running Time of Dijkstra\u2019s Algorithm\nInthissection, weanalyze thetimecomplexityofDijkstra\u2019s algorithm. Wedenote\nwith n and m the number of vertices and edges of the input graph G, respectively.\nWe assume that the edge weights can be added and compared in constant time.\nBecause of the high level of the description we gave for Dijkstra\u2019s algorithm in\nCodeFragment14.12,analyzingitsrunningtimerequiresthatwegivemoredetails\nonitsimplementation. Specifically,weshouldindicatethedatastructuresusedand\nhowtheyareimplemented.\nwww.it-ebooks.info\n658 Chapter14. GraphAlgorithms\nLet us first assume that we are representing the graph G using an adjacency\nlist or adjacency map structure. This data structure allows us to step through the\nverticesadjacenttouduringtherelaxationstepintimeproportionaltotheirnumber.\nTherefore,thetimespentinthemanagementofthenestedforloop,andthenumber\nofiterations ofthatloop,is\n\u2211 outdeg(u),\nuinV\nG\nwhich is O(m) by Proposition 14.9. The outer while loop executes O(n) times,\nsince a new vertex is added to the cloud during each iteration. This still does not\nsettleallthedetailsforthealgorithmanalysis,however,forwemustsaymoreabout\nhow to implement the other principal data structure in the algorithm\u2014the priority\nqueueQ.\nReferring backtoCodeFragment14.12insearchofpriorityqueue operations,\nwefindthatnverticesareoriginallyinsertedintothepriorityqueue;sincetheseare\nthe only insertions, the maximum size of the queue is n. In each of n iterations of\nthe while loop, a call to removeMin is made to extract the vertex u with smallest\nD label from Q. Then, for each neighbor v of u, we perform an edge relaxation,\nand may potentially update the key of v in the queue. Thus, we actually need an\nimplementation of an adaptable priority queue (Section 9.5), in which case the\nkey of a vertex v is changed using the method replaceKey(e, k), where e is the\npriority queueentryassociated withvertexv. Intheworstcase,therecould beone\nsuch update for each edge of the graph. Overall, the running time of Dijkstra\u2019s\nalgorithm isboundedbythesumofthefollowing:\nninsertions intoQ.\n\u2022\nncallstotheremoveMinmethodonQ.\n\u2022\nmcallstothereplaceKeymethodonQ.\n\u2022\nIf Q is an adaptable priority queue implemented as a heap, then each of the\nabove operations run in O(logn), and so the overall running time for Dijkstra\u2019s\nalgorithmisO((n+m)logn). Notethatifwewishtoexpresstherunningtimeasa\nfunction ofnonly, thenitisO(n2logn)intheworstcase.\nLet us now consider an alternative implementation for the adaptable priority\nqueue Q using an unsorted sequence. (See Exercise P-9.52.) This, of course, re-\nquires that we spend O(n) time to extract the minimum element, but it affords\nvery fast key updates, provided Q supports location-aware entries (Section 9.5.1).\nSpecifically, we can implement each key update done in a relaxation step in O(1)\ntime\u2014we simply change the key value once we locate the entry in Q to update.\nHence, this implementation results in arunning time that isO(n2+m), which can\nbesimplifiedtoO(n2)sinceGissimple.\nwww.it-ebooks.info\n14.6. ShortestPaths 659\nComparing the Two Implementations\nWehave twochoices forimplementing theadaptable priority queue withlocation-\naware entries in Dijkstra\u2019s algorithm: a heap implementation, which yields a run-\nning time of O((n+m)logn), and an unsorted sequence implementation, which\nyieldsarunningtimeofO(n2). Sincebothimplementationswouldbefairlysimple\nto code, they are about equal in terms of the programming sophistication needed.\nThesetwoimplementations arealsoaboutequalintermsoftheconstant factors in\ntheir worst-case running times. Looking only at these worst-case times, weprefer\nthe heap implementation when the number of edges in the graph is small (that is,\nwhenm<n2/logn),andwepreferthesequenceimplementationwhenthenumber\nofedgesislarge(thatis,whenm>n2/logn).\nProposition 14.24: GivenaweightedgraphGwithnverticesandmedges,such\nthattheweightofeachedgeisnonnegative,andavertexsofG,Dijkstra\u2019salgorithm\ncancomputethedistancefromstoallotherverticesofGinthebetterofO(n2)or\nO((n+m)logn)time.\nWenotethatanadvancedpriorityqueueimplementation,knownasaFibonacci\nheap,canbeusedtoimplementDijkstra\u2019salgorithm inO(m+nlogn)time.\nProgramming Dijkstra\u2019s Algorithm in Java\nHaving given apseudocode description of Dijkstra\u2019s algorithm, let usnowpresent\nJava code for performing Dijkstra\u2019s algorithm, assuming we are given a graph\nwhose edge elements are nonnegative integer weights. Our implementation of the\nalgorithm isinthe form of amethod, shortestPathLengths, that takes agraph and\na designated source vertex as parameters. (See Code Fragment 14.13.) It returns\na map, named cloud, storing the shortest-path distance d(s,v) for each vertex v\nthat is reachable from the source. We rely on our HeapAdaptablePriorityQueue\ndeveloped inSection9.5.2asanadaptable priority queue.\nAs we have done with other algorithms in this chapter, we rely on hash-based\nmapstostoreauxiliary data(inthiscase,mapping vtoitsdistance boundD[v]and\nits adaptable priority queue entry). The expected O(1)-time access to elements of\nthese dictionaries could be converted to worst-case bounds, either by numbering\nverticesfrom0ton 1touseasindicesintoanarray,orbystoringtheinformation\n\u2212\nwithineachvertex\u2019selement.\nThepseudocodeforDijkstra\u2019salgorithmbeginsbyassigningD[v]= foreach\n\u221e\nvotherthanthesource;werelyonthespecialvalueInteger.MAX VALUEinJavato\nprovide asufficient numeric value to model infinity. However, weavoid including\nvertices with this \u201cinfinite\u201d distance in the resulting cloud that is returned by the\nmethod. The use of this numeric limit could be avoided altogether by waiting to\naddavertextothepriority queueuntilafteranedgethatreachesitisrelaxed. (See\nExerciseC-14.62.)\nwww.it-ebooks.info\n660 Chapter14. GraphAlgorithms\n1 /\u2217\u2217 Computes shortest-path distances from src vertex to all reachable vertices of g. \u2217/\n2 public static <V> Map<Vertex<V>, Integer>\n3 shortestPathLengths(Graph<V,Integer> g, Vertex<V> src)\n{\n4 // d.get(v) is upper bound on distance from src to v\n5 Map<Vertex<V>, Integer> d = new ProbeHashMap<>();\n6 // map reachable v to its d value\n7 Map<Vertex<V>, Integer> cloud = new ProbeHashMap<>();\n8 // pq will have vertices as elements, with d.get(v) as key\n9 AdaptablePriorityQueue<Integer, Vertex<V>> pq;\n10 pq = new HeapAdaptablePriorityQueue<>();\n11 // maps from vertex to its pq locator\n12 Map<Vertex<V>, Entry<Integer,Vertex<V>>> pqTokens;\n13 pqTokens = new ProbeHashMap<>();\n14\n15 // for each vertex v of the graph, add an entry to the priority queue, with\n16 // the source having distance 0 and all others having infinite distance\n17 for (Vertex<V> v : g.vertices())\n{\n18 if (v == src)\n19 d.put(v,0);\n20 else\n21 d.put(v, Integer.MAX VALUE);\n22 pqTokens.put(v, pq.insert(d.get(v), v)); // save entry for future updates\n23\n}\n24 // now begin adding reachable vertices to the cloud\n25 while (!pq.isEmpty())\n{\n26 Entry<Integer, Vertex<V>> entry = pq.removeMin();\n27 int key = entry.getKey();\n28 Vertex<V> u = entry.getValue();\n29 cloud.put(u, key); // this is actual distance to u\n30 pqTokens.remove(u); // u is no longer in pq\n31 for (Edge<Integer> e : g.outgoingEdges(u))\n{\n32 Vertex<V> v = g.opposite(u,e);\n33 if (cloud.get(v) == null)\n{\n34 // perform relaxation step on edge (u,v)\n35 int wgt = e.getElement();\n36 if (d.get(u) + wgt < d.get(v)) // better path to v?\n{\n37 d.put(v, d.get(u) + wgt); // update the distance\n38 pq.replaceKey(pqTokens.get(v), d.get(v)); // update the pq entry\n39\n}\n40\n}\n41\n}\n42\n}\n43 return cloud; // this only includes reachable vertices\n44\n}\nCodeFragment14.13: Java implementation of Dijkstra\u2019s algorithm for computing\nthe shortest-path distances from a single source. We assume that e.getElement()\nforedgeerepresents theweightofthatedge.\nwww.it-ebooks.info\n14.6. ShortestPaths 661\nReconstructing a Shortest-Path Tree\nOur pseudocode description of Dijkstra\u2019s algorithm in Code Fragment 14.12 and\nourimplementation inCodeFragment14.13computethevalueD[v],foreachver-\ntex v, that is the length of a shortest path from the source vertex s to v. However,\nthoseformsofthealgorithmdonotexplicitlycomputetheactualpathsthatachieve\nthose distances. Fortunately, it is possible to represent shortest paths from source\ns to every reachable vertex in a graph using a compact data structure known as a\nshortest-path tree. This is possible because if a shortest path from s to v passes\nthrough anintermediate vertexu,itmustbeginwithashortest pathfromstou.\nWe next demonstrate that a shortest-path tree rooted at source s can be recon-\nstructed in O(n+m)time, given the D[v] values produced by Dijkstra\u2019s algorithm\nusing s as the source. As we did when representing the DFS and BFS trees, we\nwillmapeach vertex v=s toaparent u(possibly, u=s), such that uis the vertex\n6\nimmediately before vonashortest path from sto v. Ifuisthe vertex just before v\nonashortestpathfromstov,itmustbethat\nD[u]+w(u,v)=D[v].\nConversely, if the above equation is satisfied, then a shortest path from s to u fol-\nlowedbytheedge(u,v)isashortest pathtov.\nOur implementation in Code Fragment 14.14 reconstructs a tree based on this\nlogic, testing all incoming edges to each vertex v, looking for a(u,v) that satisfies\nthekeyequation. TherunningtimeisO(n+m),asweconsidereachvertexandall\nincomingedgestothosevertices. (SeeProposition 14.9.)\n1 /\u2217\u2217\n2 \u2217 Reconstructs a shortest-path tree rooted at vertex s, given distance map d.\n3 \u2217 The tree is represented as a map from each reachable vertex v (other than s)\n4 \u2217 to the edge e = (u,v) that is used to reach v from its parent u in the tree.\n5 \u2217/\n6 public static <V> Map<Vertex<V>,Edge<Integer>>\n7 spTree(Graph<V,Integer> g, Vertex<V> s, Map<Vertex<V>,Integer> d)\n{\n8 Map<Vertex<V>, Edge<Integer>> tree = new ProbeHashMap<>();\n9 for (Vertex<V> v : d.keySet())\n10 if (v != s)\n11 for (Edge<Integer> e : g.incomingEdges(v)) // consider INCOMING edges\n{\n12 Vertex<V> u = g.opposite(v, e);\n13 int wgt = e.getElement();\n14 if (d.get(v) == d.get(u) + wgt)\n15 tree.put(v, e); // edge is is used to reach v\n16\n}\n17 return tree;\n18\n}\nCodeFragment14.14: Java method that reconstructs a single-source shortest-path\ntree,basedonknowledgeoftheshortest-path distances.\nwww.it-ebooks.info\n662 Chapter14. GraphAlgorithms\n14.7 Minimum Spanning Trees\nSuppose we wish to connect all the computers in a new office building using the\nleast amount of cable. We can model this problem using an undirected, weighted\ngraph G whose vertices represent the computers, and whose edges represent all\nthe possible pairs (u,v) of computers, where the weight w(u,v) of edge (u,v) is\nequal to the amount of cable needed to connect computer u to computer v. Rather\nthancomputingashortest-pathtreefromsomeparticularvertexv,weareinterested\ninstead in finding atree T that contains all thevertices of Gand has theminimum\ntotalweight overallsuchtrees. Algorithms forfindingsuch atreearethefocusof\nthissection.\nProblem Definition\nGiven an undirected, weighted graph G, we are interested in finding a tree T that\ncontains alltheverticesinGandminimizesthesum\nw(T)= \u2211 w(u,v).\n(u,v)inT\nAtree,suchasthis,thatcontainseveryvertexofaconnectedgraphGissaidto\nbeaspanningtree, andtheproblem ofcomputing aspanning treeT withsmallest\ntotalweightisknownastheminimumspanningtree(orMST)problem.\nThe development of efficient algorithms for the minimum spanning tree prob-\nlem predates the modern notion of computer science itself. In this section, we\ndiscuss two classic algorithms for solving the MST problem. These algorithms\nare both applications ofthe greedy method, which, aswas discussed briefly in the\nprevious section, is based on choosing objects to join a growing collection by it-\neratively picking an object that minimizes some cost function. The firstalgorithm\nwe discuss is the Prim-Jarn\u00b4\u0131k algorithm, which grows the MST from a single root\nvertex, much in the same way as Dijkstra\u2019s shortest-path algorithm. The second\nalgorithm we discuss is Kruskal\u2019s algorithm, which \u201cgrows\u201d the MST in clusters\nbyconsidering edgesinnondecreasing orderoftheirweights.\nInordertosimplifythedescriptionofthealgorithms,weassume,inthefollow-\ning, that the input graph G is undirected (that is, all its edges are undirected) and\nsimple (that is, it has no self-loops and no parallel edges). Hence, we denote the\nedgesofGasunordered vertexpairs(u,v).\nBeforewediscussthedetailsofthesealgorithms,however,letusgiveacrucial\nfactaboutminimumspanning treesthatformsthebasisofthealgorithms.\nwww.it-ebooks.info\n14.7. MinimumSpanningTrees 663\nA Crucial Fact about Minimum Spanning Trees\nThetwoMSTalgorithmswediscussarebasedonthegreedymethod,whichinthis\ncasedepends crucially onthefollowingfact. (SeeFigure14.19.)\neBelongs to a Minimum Spanning Tree\ne\nV V\n1 min-weight 2\n\u201cbridge\u201d edge\nFigure14.19: Anillustration ofthecrucialfactaboutminimumspanning trees.\nProposition 14.25: LetGbeaweightedconnectedgraph,andletV andV bea\n1 2\npartitionoftheverticesofGintotwodisjointnonemptysets.Furthermore,letebe\nanedgeinGwithminimumweightfromamongthosewithoneendpointinV and\n1\ntheotherinV .ThereisaminimumspanningtreeT thathaseasoneofitsedges.\n2\nJustification: Let T be a minimum spanning tree of G. If T does not contain\nedge e, the addition of e to T must create a cycle. Therefore, there is some edge\nf =e of this cycle that has one endpoint inV and the other inV . Moreover, by\n1 2\n6\nthe choice ofe, w(e) w(f). Ifweremove f from T e , weobtain aspanning\n\u2264 \u222a{ }\ntreewhose total weightisnomorethanbefore. SinceT wasaminimum spanning\ntree,thisnewtreemustalsobeaminimumspanning tree.\nIn fact, if the weights in G are distinct, then the minimum spanning tree is\nunique; we leave the justification of this less crucial fact as an exercise (C-14.64).\nIn addition, note that Proposition 14.25 remains valid even if the graph G con-\ntains negative-weight edges or negative-weight cycles, unlike the algorithms we\npresented forshortestpaths.\nwww.it-ebooks.info\n664 Chapter14. GraphAlgorithms\n\u00b4\u0131\n14.7.1 Prim-Jarn k Algorithm\nIn the Prim-Jarn\u00b4\u0131k algorithm, we grow a minimum spanning tree from a single\ncluster starting from some \u201croot\u201d vertex s. The main idea is similar to that of\nDijkstra\u2019salgorithm. Wewillbeginwithsomevertexs,definingtheinitial\u201ccloud\u201d\nofverticesC. Then,ineachiteration,wechooseaminimum-weightedgee=(u,v),\nconnecting a vertex u in the cloud C to a vertex v outside of C. The vertex v is\nthen brought into the cloud C and the process is repeated until a spanning tree is\nformed. Again, the crucial fact about minimum spanning trees comes into play,\nfor by always choosing the smallest-weight edge joining a vertex inside C to one\noutsideC,weareassured ofalwaysaddingavalidedgetotheMST.\nToefficientlyimplementthisapproach,wecantakeanothercuefromDijkstra\u2019s\nalgorithm. We maintain a label D[v] for each vertex v outside the cloudC, so that\nD[v] stores the weight of the minimum observed edge for joining v to the cloud\nC. (In Dijkstra\u2019s algorithm, this label measured the full path length from starting\nvertex s to v, including an edge (u,v).) These labels serve as keys in a priority\nqueue used to decide which vertex is next in line to join the cloud. We give the\npseudocode inCodeFragment14.15.\nAlgorithmPrimJarnik(G):\nInput: Anundirected,weighted,connectedgraphGwithnverticesandmedges\nOutput: Aminimumspanning treeT forG\nPickanyvertexsofG\nD[s] = 0\nforeachvertexv=sdo\n6\nD[v] =\n\u221e\nInitialize T = .\n\u2205\nInitialize apriorityqueueQwithanentry(D[v],v)foreachvertexv.\nForeachvertexv,maintainconnect(v)astheedgeachieving D[v](ifany).\nwhileQisnotemptydo\nLetubethevalueoftheentryreturned byQ.removeMin().\nConnectvertexutoT usingedgeconnect(e).\nforeachedgee\u2032=(u,v)suchthatvisinQ do\ncheckifedge(u,v)betterconnectsvtoT\n{ }\nifw(u,v)<D[v]then\nD[v] = w(u,v)\nconnect(v) = e\u2032.\nChangethekeyofvertexvinQtoD[v].\nreturnthetreeT\nCodeFragment14.15: ThePrim-Jarn\u00b4\u0131kalgorithm fortheMSTproblem.\nwww.it-ebooks.info\n14.7. MinimumSpanningTrees 665\n\u00b4\u0131\nAnalyzing the Prim-Jarn k Algorithm\nThe implementation issues for the Prim-Jarn\u00b4\u0131k algorithm are similar to those for\nDijkstra\u2019s algorithm, relying on an adaptable priority queue Q (Section 9.5.1).\nWe initially perform n insertions into Q, later perform n extract-min operations,\nand may update a total of m priorities as part of the algorithm. Those steps are\nthe primary contributions to the overall running time. With a heap-based priority\nqueue, eachoperation runsinO(logn)time,andtheoveralltimeforthealgorithm\nis O((n+m)logn), which is O(mlogn) for a connected graph. Alternatively, we\ncanachieveO(n2)running timebyusinganunsorted listasapriority queue.\n\u00b4\u0131\nIllustrating the Prim-Jarn k Algorithm\nWeillustrate thePrim-Jarn\u00b4\u0131kalgorithm inFigures14.20and14.21.\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(a) (b)\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(c) (d)\nFigure14.20:AnillustrationofthePrim-Jarn\u00b4\u0131kMSTalgorithm,startingwithvertex\nPVD.(Continues inFigure14.21.)\nwww.it-ebooks.info\n666 Chapter14. GraphAlgorithms\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(e) (f)\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(g) (h)\n2704\n2704 BOS\nBOS 867\n867\n849 PVD\nORD 740 849 144 PVD 187 1846 ORD 621 740 JF 14 K 4 187\n1846 621 JFK\n1258\nSFO 1464 802 1391 1 B 84 WI 1090 1258 SF 3 O 37 1464 802 1391 1 B 84 WI 1090\n337 DFW\nLAX 1235 DFW 946 LAX 1235 1121 946\n1121\n2342 MIA\n2342 MIA\n(i) (j)\nFigure14.21: An illustration of the Prim-Jarn\u00b4\u0131k MST algorithm. (Continued from\nFigure14.20.)\nwww.it-ebooks.info\n14.7. MinimumSpanningTrees 667\n14.7.2 Kruskal\u2019s Algorithm\nInthissection, wewillintroduce Kruskal\u2019salgorithmforconstructing aminimum\nspanningtree. WhilethePrim-Jarn\u00b4\u0131kalgorithmbuildstheMSTbygrowingasingle\ntreeuntilitspansthegraph, Kruskal\u2019salgorithm maintains manysmallertreesina\nforest, repeatedly mergingpairsoftreesuntilasingletreespansthegraph.\nInitially, each vertex is in its own cluster. The algorithm then considers each\nedge in turn, ordered by increasing weight. If an edge e connects vertices in two\ndifferent clusters, then e is added to the set of edges of the minimum spanning\ntree, and the two trees are merged with the addition of e. If, on the other hand, e\nconnects two vertices in the same cluster, then e is discarded. Once the algorithm\nhasaddedenough edgestoformaspanning tree,itterminates andoutputs thistree\nastheminimumspanning tree.\nWegivepseudocodeforKruskal\u2019sMSTalgorithminCodeFragment14.16and\nweshowanexampleofthisalgorithm inFigures14.22,14.23,and14.24.\nAlgorithmKruskal(G):\nInput: Asimpleconnected weightedgraphGwithnvertices andmedges\nOutput: Aminimumspanning treeT forG\nforeachvertexvinGdo\nDefineanelementary clusterC(v) = v .\n{ }\nInitialize apriorityqueueQtocontainalledgesinG,usingtheweightsaskeys.\nT = T willultimately containtheedgesofanMST\n\u2205 { }\nwhileT hasfewerthann 1edgesdo\n\u2212\n(u,v) = valuereturned byQ.removeMin()\nLetC(u)betheclustercontaining u,andletC(v)betheclustercontaining v.\nifC(u)=C(v)then\n6\nAddedge(u,v)toT.\nMergeC(u)andC(v)intoonecluster.\nreturntreeT\nCodeFragment14.16: Kruskal\u2019salgorithm fortheMSTproblem.\nAswasthecasewiththePrim-Jarn\u00b4\u0131kalgorithm,thecorrectnessofKruskal\u2019sal-\ngorithm isbased upon thecrucial fact about minimum spanning trees from Propo-\nsition 14.25. Each time Kruskal\u2019s algorithm adds an edge (u,v) to the minimum\nspanning tree T, we can define a partitioning of the set of vertices V (as in the\nproposition) bylettingV bethecluster containing vandlettingV contain therest\n1 2\nof the vertices inV. This clearly defines a disjoint partitioning of the vertices of\nV and, more importantly, since we are extracting edges from Q in order by their\nweights, e mustbe a minimum-weight edge withone vertex inV and the other in\n1\nV . Thus,Kruskal\u2019salgorithm alwaysaddsavalidminimumspanning treeedge.\n2\nwww.it-ebooks.info\n668 Chapter14. GraphAlgorithms\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(a) (b)\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\n1258 1258\nSFO 802 184 SFO 802 184\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(c) (d)\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\n1258 1258\nSFO 802 184 SFO 802 184\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(e) (f)\nFigure14.22:ExampleofanexecutionofKruskal\u2019sMSTalgorithmonagraphwith\nintegerweights. Weshowtheclusters asshadedregionsandwehighlight theedge\nbeingconsidered ineachiteration. (Continues inFigure14.23.)\nwww.it-ebooks.info\n14.7. MinimumSpanningTrees 669\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(g) (h)\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\nSFO 802 184 1258 SFO 802 184 1258\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(i) (j)\n2704 2704\nBOS BOS\n867 867\n849 PVD 849 PVD\nORD 740 144 187 ORD 740 144 187\n1846 621 JFK 1846 621 JFK\n1258 1258\nSFO 802 184 SFO 802 184\n1464 1391 BWI 1090 1464 1391 BWI 1090\n337 337\nDFW DFW\nLAX 1235 946 LAX 1235 946\n1121 1121\n2342 MIA 2342 MIA\n(k) (l)\nFigure14.23: An example of an execution of Kruskal\u2019s MST algorithm. Rejected\nedgesareshowndashed. (ContinuesinFigure14.24.)\nwww.it-ebooks.info\n670 Chapter14. GraphAlgorithms\n2704\n2704 BOS\nBOS 867\n867\n849 PVD\n849 PVD ORD 740 144 187\nORD 740 144 187 1846 621 JFK\n1846 621 JFK 1258\n1258 SFO 802 184\nSFO 802 184 1464 1391 BWI 1090\n1464 1391 BWI 1090 337\n337 DFW\nDFW LAX 1235 946\nLAX 1235 946 1121\n1121\n2342 MIA\n2342 MIA\n(m) (n)\nFigure 14.24: Example of an execution of Kruskal\u2019s MST algorithm (continued).\nTheedge considered in(n)merges thelasttwoclusters, whichconcludes thisexe-\ncutionofKruskal\u2019s algorithm. (Continued fromFigure14.23.)\nThe Running Time of Kruskal\u2019s Algorithm\nThere are two primary contributions to the running time of Kruskal\u2019s algorithm.\nThefirstistheneed toconsider theedges innondecreasing order oftheir weights,\nand the second is the management of the cluster partition. Analyzing its running\ntimerequires thatwegivemoredetailsonitsimplementation.\nThe ordering of edges by weight can be implemented in O(mlogm), either by\nuseofasortingalgorithmorapriorityqueueQ. Ifthatqueueisimplementedwitha\nheap,wecaninitializeQinO(mlogm)timebyrepeatedinsertions,orinO(m)time\nusing bottom-up heap construction (see Section 9.3.4), andthesubsequent callsto\nremoveMineachruninO(logm)time,sincethequeuehassizeO(m). Wenotethat\nsince m is O(n2) for a simple graph, O(logm) is the same as O(logn). Therefore,\ntherunningtimeduetotheordering ofedgesisO(mlogn).\nThe remaining task is the management of clusters. To implement Kruskal\u2019s\nalgorithm,wemustbeabletofindtheclustersforverticesuandvthatareendpoints\nof an edge e, to test whether those two clusters are distinct, and if so, to merge\nthose two clusters into one. None of the data structures we have studied thus far\narewellsuitedforthistask. However,weconclude thischapterbyformalizing the\nproblem ofmanagingdisjointpartitions, andintroducing efficientunion-finddata\nstructures. In the context of Kruskal\u2019s algorithm, we perform at most 2m \u201cfind\u201d\noperations and n 1 \u201cunion\u201d operations. We will see that a simple union-find\n\u2212\nstructure can perform that combination of operations in O(m+nlogn) time (see\nProposition 14.26),andamoreadvancedstructurecansupportanevenfastertime.\nFor a connected graph, m n 1; therefore, the bound of O(mlogn) time for\n\u2265 \u2212\norderingtheedgesdominatesthetimeformanagingtheclusters. Weconcludethat\ntherunningtimeofKruskal\u2019salgorithm isO(mlogn).\nwww.it-ebooks.info\n14.7. MinimumSpanningTrees 671\nJava Implementation\nCodeFragment14.17 presents aJavaimplementation ofKruskal\u2019s algorithm. The\nminimumspanningtreeisreturnedintheformofalistofedges. Asaconsequence\nofKruskal\u2019salgorithm,thoseedgeswillbereportedinnondecreasingorderoftheir\nweights.\nOur implementation assumes use of a Partition class for managing the cluster\npartition. Animplementation ofthePartitionclassispresented inSection14.7.3.\n1 /\u2217\u2217 Computes a minimum spanning tree of graph g using Kruskal's algorithm. \u2217/\n2 public static <V> PositionalList<Edge<Integer>> MST(Graph<V,Integer> g)\n{\n3 // tree is where we will store result as it is computed\n4 PositionalList<Edge<Integer>> tree = new LinkedPositionalList<>();\n5 // pq entries are edges of graph, with weights as keys\n6 PriorityQueue<Integer, Edge<Integer>> pq = new HeapPriorityQueue<>();\n7 // union-find forest of components of the graph\n8 Partition<Vertex<V>> forest = new Partition<>();\n9 // map each vertex to the forest position\n10 Map<Vertex<V>,Position<Vertex<V>>> positions = new ProbeHashMap<>();\n11\n12 for (Vertex<V> v : g.vertices())\n13 positions.put(v, forest.makeGroup(v));\n14\n15 for (Edge<Integer> e : g.edges())\n16 pq.insert(e.getElement(), e);\n17\n18 int size = g.numVertices();\n19 // while tree not spanning and unprocessed edges remain...\n20 while (tree.size() != size 1 && !pq.isEmpty())\n\u2212 {\n21 Entry<Integer, Edge<Integer>> entry = pq.removeMin();\n22 Edge<Integer> edge = entry.getValue();\n23 Vertex<V>[ ] endpoints = g.endVertices(edge);\n24 Position<Vertex<V>> a = forest.find(positions.get(endpoints[0]));\n25 Position<Vertex<V>> b = forest.find(positions.get(endpoints[1]));\n26 if (a != b)\n{\n27 tree.addLast(edge);\n28 forest.union(a,b);\n29\n}\n30\n}\n31\n32 return tree;\n33\n}\nCode Fragment 14.17: Java implementation of Kruskal\u2019s algorithm for the mini-\nmumspanning treeproblem. ThePartitionclassisdiscussed inSection14.7.3.\nwww.it-ebooks.info\n672 Chapter14. GraphAlgorithms\n14.7.3 Disjoint Partitions and Union-Find Structures\nIn this section, we consider a data structure for managing a partition of elements\ninto a collection of disjoint sets. Our initial motivation is in support of Kruskal\u2019s\nminimumspanningtreealgorithm,inwhichaforestofdisjointtreesismaintained,\nwithoccasionalmergingofneighboringtrees. Moregenerally,thedisjointpartition\nproblem canbeapplied tovariousmodelsofdiscretegrowth.\nWeformalize theproblem withthefollowingmodel. Apartition datastructure\nmanages a universe of elements that are organized into disjoint sets (that is, an\nelement belongs to one and only one of these sets). Unlike with the Set ADT, we\ndonotexpecttobeabletoiteratethroughthecontentsofaset,nortoefficientlytest\nwhetheragivensetincludesagivenelement. Toavoidconfusionwithsuchnotions\nofaset, wewillrefer tothesets ofourpartition asclusters. However, wewillnot\nrequire an explicit structure for each cluster, instead allowing the organization of\nclusterstobeimplicit. Todifferentiatebetweenoneclusterandanother,weassume\nthat at any point in time, each cluster has a designated element that we refer to as\ntheleaderofthecluster.\nFormally, we define the methods of a partition ADT using positions, each of\nwhichstoresanelementx. Thepartition ADTsupports thefollowingmethods.\nmakeCluster(x): Createsasingletonclustercontainingnewelementxand\nreturns itsposition.\nunion(p,q): Mergestheclusterscontaining positions pandq.\nfind(p): Returns the position of the leader of the cluster contain-\ningposition p.\nSequence Implementation\nAsimple implementation ofapartition withatotalofnelements usesacollection\nofsequences,oneforeachcluster,wherethesequenceforaclusterAstoreselement\npositions. Eachposition objectstores areference toitsassociated elementx,anda\nreference to the sequence storing p, since this sequence is representing the cluster\ncontaining p\u2019selement. (SeeFigure14.25.)\nWiththisrepresentation,wecaneasilyperformthemakeCluster(x)andfind(p)\noperations in O(1) time, allowing the first position in a sequence to serve as the\n\u201cleader.\u201d Operation union(p, q) requires that we join two sequences into one and\nupdate the cluster references of the positions in one of the two. We choose to\nimplement this operation by removing all the positions from the sequence with\nsmaller size, and inserting them in the sequence with larger size. Each time we\ntake aposition from thesmaller cluster Aandinsert itintothe larger cluster B,we\nupdatetheclusterreferenceforthatpositiontonowpointtoB. Hence,theoperation\nunion(p,q)takestimeO(min(n ,n )),wheren (resp. n )isthecardinality ofthe\np q p q\nwww.it-ebooks.info\n14.7. MinimumSpanningTrees 673\nA B\n4 1 7 9 3 6 2\nC\n5 11 12 10 8\nFigure 14.25: Sequence-based implementation of a partition consisting of three\nclusters: A= 1,4,7 , B= 2,3,6,9 , andC= 5,8,10,11,12 .\n{ } { } { }\ncluster containing position p (resp. q). Clearly, this time is O(n) if there are n\nelementsinthepartitionuniverse. However,wenextpresentanamortizedanalysis\nthatshowsthisimplementationtobemuchbetterthanappearsfromthisworst-case\nanalysis.\nProposition 14.26: Whenusing thesequence-based partition implementation,\nperformingaseriesofk makeCluster,union,andfind operationsonaninitially\nemptypartitioninvolvingatmostnelementstakesO(k+nlogn)time.\nJustification: Weuse the accounting method and assume that one cyber-dollar\ncan pay for the time to perform a find operation, a makeCluster operation, or the\nmovement ofaposition object from one sequence toanother in aunion operation.\nIn the case of a find or makeCluster operation, we charge the operation itself 1\ncyber-dollar. In the case of aunion operation, weassume that 1 cyber-dollar pays\nfortheconstant-timeworkincomparingthesizesofthetwosequences,andthatwe\ncharge 1cyber-dollar toeachposition thatwemovefromthesmallerclustertothe\nlarger cluster. Clearly, the 1 cyber-dollar charged for each find and makeCluster\noperation, together with the first cyber-dollar collected for each union operation,\naccounts foratotalofkcyber-dollars.\nConsider, then, the number of charges made to positions on behalf of union\noperations. The important observation is that each time we move a position from\none cluster to another, the size of that position\u2019s cluster at least doubles. Thus,\neachpositionismovedfromoneclustertoanotheratmostlogntimes;hence,each\nposition canbecharged atmostO(logn)times. Sinceweassumethatthepartition\nisinitiallyempty,thereareO(n)differentelementsreferencedinthegivenseriesof\noperations, whichimpliesthatthetotaltimeformovingelements duringtheunion\noperations isO(nlogn).\nwww.it-ebooks.info\n674 Chapter14. GraphAlgorithms\n\u22c6\nA Tree-Based Partition Implementation\nAn alternative data structure for representing a partition uses a collection of\ntrees to store the nelements, where each tree is associated withadifferent cluster.\nIn particular, we implement each tree with a linked data structure whose nodes\nserve as the position objects. (See Figure 14.26.) We view each position p as\nbeing a node having an instance variable, element, referring to its element x, and\naninstance variable, parent,referring toitsparentnode. Byconvention, if pisthe\nrootofitstree,weset p\u2019sparentreference toitself.\n1 2 5\n4 7 3 6 8 10\n9 11\n12\nFigure14.26: Tree-basedimplementation ofapartition consisting ofthreeclusters:\nA= 1,4,7 , B= 2,3,6,9 , andC= 5,8,10,11,12 .\n{ } { } { }\nWith this partition data structure, operation find(p) is performed by walking\nup from position p tothe root of itstree, which takes O(n)time in the worst case.\nOperation union(p, q) can be implemented by making one of the trees a subtree\nof the other. This can be done by first locating the two roots, and then in O(1)\nadditionaltimebysettingtheparentreferenceofoneroottopointtotheotherroot.\nSeeFigure14.27foranexampleofbothoperations.\n2 2\n3 6 5 3 6 5\n9 8 10 9 8 10\n11 11\n12 12\n(a) (b)\nFigure14.27: Tree-based implementation ofapartition: (a)operation union(p,q);\n(b)operation find(p),where pdenotestheposition objectforelement12.\nwww.it-ebooks.info\n14.7. MinimumSpanningTrees 675\nAtfirst,thisimplementation mayseemtobenobetterthanthesequence-based\ndatastructure, butweaddthefollowingtwosimpleheuristicstomakeitrunfaster.\nUnion-by-Size: Witheachposition p,storethenumberofelementsinthesubtree\nrootedat p. Inaunionoperation,maketherootofthesmallerclusterbecome\nachildoftheotherroot,andupdatethesizefieldofthelargerroot.\nPathCompression: In a find operation, for each position q that the find visits,\nresettheparentofqtotheroot. (SeeFigure14.28.)\n2 2\n3 6 5 3 6 5\n9 8 10 9 8 10\n11 11\n12 12\n(a) (b)\nFigure 14.28: Path-compression heuristic: (a) path traversed by operation find on\nelement12;(b)restructured tree.\nAsurprisingpropertyofthisdatastructure,whenimplementedusingtheunion-\nby-sizeandpath-compression heuristics, isthatperformingaseriesofkoperations\ninvolving n elements takes O(klog\u2217n) time, where log\u2217n is the log-star function,\nwhichistheinverseofthetower-of-twos function. Intuitively, log\u2217nisthenumber\nof times that one can iteratively take the logarithm (base 2) of a number before\ngettinganumbersmallerthan2. Table14.4showsafewsamplevalues.\nminimumn 2 22 =4 222 =16 2222 =65,536 22222 =265,536\n\u2217\nlog n 1 2 3 4 5\nTable14.4: Somevaluesoflog\u2217nandcriticalvaluesforitsinverse.\nProposition 14.27: Whenusingthetree-basedpartitionrepresentationwithboth\nunion-by-sizeandpathcompression,performingaseriesofkmakeCluster,union,\nandfind operationsonaninitiallyemptypartitioninvolvingatmostn elements\ntakesO(klog\u2217n)time.\nAlthough the analysis for this data structure is rather complex, its implemen-\ntation is quite straightforward. We conclude with a Java implementation of the\nstructure, giveninCodeFragment14.18.\nwww.it-ebooks.info\n676 Chapter14. GraphAlgorithms\n1 /\u2217\u2217 A Union-Find structure for maintaining disjoint sets. \u2217/\n2 public class Partition<E>\n{\n3 //---------------nested Locator class -------------\n4 private class Locator<E> implements Position<E>\n{\n5 public E element;\n6 public int size;\n7 public Locator<E> parent;\n8 public Locator(E elem)\n{\n9 element = elem;\n10 size = 1;\n11 parent = this; // convention for a cluster leader\n12\n}\n13 public E getElement() return element;\n{ }\n14 //--------- end of nested Locator class ---------\n15 / }\u2217\u2217 Makes a new cluster containing element e and returns its position. \u2217/\n16 public Position<E> makeCluster(E e)\n{\n17 return new Locator<E>(e);\n18\n19 } /\u2217\u2217\n20 \u2217 Finds the cluster containing the element identified by Position p\n21 \u2217 and returns the Position of the cluster's leader.\n22 \u2217/\n23 public Position<E> find(Position<E> p)\n{\n24 Locator<E> loc = validate(p);\n25 if (loc.parent != loc)\n26 loc.parent = (Locator<E>) find(loc.parent); // overwrite parent after recursion\n27 return loc.parent;\n28\n29 } /\u2217\u2217 Merges the clusters containing elements with positions p and q (if distinct). \u2217/\n30 public void union(Position<E> p, Position<E> q)\n{\n31 Locator<E> a = (Locator<E>) find(p);\n32 Locator<E> b = (Locator<E>) find(q);\n33 if (a != b)\n34 if (a.size > b.size)\n{\n35 b.parent = a;\n36 a.size += b.size;\n37 else\n} {\n38 a.parent = b;\n39 b.size += a.size;\n40\n}\n41\n}\n42\n}\nCodeFragment14.18: JavaimplementationofaPartitionclassusingunion-by-size\nandpathcompression. Weomitthevalidatemethodduetospacelimitation.\nwww.it-ebooks.info\n14.8. Exercises 677\n14.8 Exercises\nReinforcement\nR-14.1 DrawasimpleundirectedgraphGthathas12vertices,18edges,and3connected\ncomponents.\nR-14.2 IfGisasimpleundirectedgraphwith12verticesand3connectedcomponents,\nwhatisthelargestnumberofedgesitmighthave?\nR-14.3 DrawanadjacencymatrixrepresentationoftheundirectedgraphshowninFig-\nure14.1.\nR-14.4 Draw an adjacency list representation of the undirected graph shown in Fig-\nure14.1.\nR-14.5 Drawasimple,connected,directedgraphwith8verticesand16edgessuchthat\nthe in-degree and out-degree of each vertex is 2. Show that there is a single\n(nonsimple)cyclethatincludesalltheedgesofyourgraph,thatis,youcantrace\nalltheedgesintheirrespectivedirectionswithouteverliftingyourpencil.(Such\nacycleiscalledanEulertour.)\nR-14.6 SupposewerepresentagraphGhavingnverticesandmedgeswiththeedgelist\nstructure.Why,inthiscase,doestheinsertVertexmethodruninO(1)timewhile\ntheremoveVertexmethodrunsinO(m)time?\nR-14.7 GivepseudocodeforperformingtheoperationinsertEdge(u,v,x)inO(1)time\nusingtheadjacencymatrixrepresentation.\nR-14.8 RepeatExerciseR-14.7fortheadjacencylistrepresentation,asdescribedinthe\nchapter.\nR-14.9 Can edgelistE beomittedfromtheadjacencymatrixrepresentationwhilestill\nachievingthetimeboundsgiveninTable14.1?Whyorwhynot?\nR-14.10 Can edge list E be omitted from the adjacency list representation while still\nachievingthetimeboundsgiveninTable14.3?Whyorwhynot?\nR-14.11 Would you use the adjacencymatrix structureor the adjacencylist structurein\neachofthefollowingcases? Justifyyourchoice.\na. Thegraphhas10,000verticesand20,000edges,anditisimportanttouse\naslittlespaceaspossible.\nb. Thegraphhas10,000verticesand20,000,000edges,anditisimportantto\nuseaslittlespaceaspossible.\nc. YouneedtoanswerthequerygetEdge(u,v)asfastaspossible,nomatter\nhowmuchspaceyouuse.\nR-14.12 In orderto verifythatall ofits nontreeedgesarebackedges, redrawthe graph\nfrom Figure 14.8b so that the DFS tree edges are drawn with solid lines and\noriented downward, as in a standard portrayal of a tree, and with all nontree\nedgesdrawnusingdashedlines.\nwww.it-ebooks.info\n678 Chapter14. GraphAlgorithms\nR-14.13 Explainwhythe DFS traversalrunsin O(n2)time onan n-vertexsimple graph\nthatisrepresentedwiththeadjacencymatrixstructure.\nR-14.14 Asimpleundirectedgraphiscompleteifitcontainsanedgebetweeneverypair\nofdistinctvertices. Whatdoesadepth-firstsearchtreeofacompletegraphlook\nlike?\nR-14.15 RecallingthedefinitionofacompletegraphfromExerciseR-14.14,whatdoesa\nbreadth-firstsearchtreeofacompletegraphlooklike?\nR-14.16 LetGbeanundirectedgraphwhoseverticesaretheintegers1through8,andlet\ntheadjacentverticesofeachvertexbegivenbythetablebelow:\nvertex adjacentvertices\n1 (2,3,4)\n2 (1,3,4)\n3 (1,2,4)\n4 (1,2,3,6)\n5 (6,7,8)\n6 (4,5,7)\n7 (5,6,8)\n8 (5,7)\nAssume that, in a traversalof G, the adjacentvertices of a given vertexare re-\nturnedinthesameorderastheyarelistedinthetableabove.\na. DrawG.\nb. GivethesequenceofverticesofGvisitedusingaDFStraversalstartingat\nvertex1.\nc. GivethesequenceofverticesvisitedusingaBFStraversalstartingatver-\ntex1.\nR-14.17 Bob lovesforeignlanguagesand wants to plan his course schedule for the fol-\nlowing years. He is interested in the following nine language courses: LA15,\nLA16, LA22, LA31, LA32, LA126, LA127, LA141, and LA169. The course\nprerequisitesare:\nLA15:(none)\n\u2022\nLA16:LA15\n\u2022\nLA22:(none)\n\u2022\nLA31:LA15\n\u2022\nLA32:LA16,LA31\n\u2022\nLA126:LA22,LA32\n\u2022\nLA127:LA16\n\u2022\nLA141:LA22,LA16\n\u2022\nLA169:LA32\n\u2022\nInwhatordercanBobtakethesecourses,respectingtheprerequisites?\nR-14.18 Computeatopologicalorderingforthedirectedgraphdrawnwithsolidedgesin\nFigure14.3d.\nR-14.19 DrawthetransitiveclosureofthedirectedgraphshowninFigure14.2.\nwww.it-ebooks.info\n14.8. Exercises 679\nR-14.20 If theverticesofthe graphfromFigure14.11are orderedas(JFK, LAZ, MIA,\nBOS, ORD, SFO, DFW), in whatorder wouldedgesbe addedto the transitive\nclosureduringtheFloyd-Warshallalgorithm?\nR-14.21 Howmanyedgesareinthetransitiveclosureofagraphthatconsistsofasimple\ndirectedpathofnvertices?\nR-14.22 Given an n-nodecomplete binarytree T, rooted at a given position, considera\ndirected graph G~ having the nodes of T as its vertices. For each parent-child\npairinT,createadirectededgeinG~ fromtheparenttothechild. Showthatthe\ntransitiveclosureofG~ hasO(nlogn)edges.\nR-14.23 Draw a simple, connected, weighted graph with 8 vertices and 16 edges, each\nwithuniqueedgeweights. Identifyonevertexasa\u201cstart\u201dvertexandillustratea\nrunningofDijkstra\u2019salgorithmonthisgraph.\nR-14.24 ShowhowtomodifythepseudocodeforDijkstra\u2019salgorithmforthecasewhen\nthe graph is directed and we want to compute shortest directed paths from the\nsourcevertextoalltheothervertices.\nR-14.25 Draw a simple, connected, undirected, weighted graph with 8 vertices and 16\nedges,eachwithuniqueedgeweights. IllustratetheexecutionofthePrim-Jarn\u00b4\u0131k\nalgorithmforcomputingtheminimumspanningtreeofthisgraph.\nR-14.26 RepeatthepreviousproblemforKruskal\u2019salgorithm.\nR-14.27 Thereareeightsmallislandsinalake,andthestatewantstobuildsevenbridges\ntoconnectthemsothateachislandcanbereachedfromanyotheroneviaoneor\nmorebridges.Thecostofconstructingabridgeisproportionaltoitslength.The\ndistancesbetweenpairsofislandsaregiveninthefollowingtable.\n1 2 3 4 5 6 7 8\n1 - 240 210 340 280 200 345 120\n2 - - 265 175 215 180 185 155\n3 - - - 260 115 350 435 195\n4 - - - - 160 330 295 230\n5 - - - - - 360 400 170\n6 - - - - - - 175 205\n7 - - - - - - - 305\n8 - - - - - - - -\nFindwhichbridgestobuildtominimizethetotalconstructioncost.\nR-14.28 DescribethemeaningofthegraphicalconventionsusedinFigure14.9illustrat-\ningaDFStraversal. Whatdothelinethicknessessignify? Whatdothearrows\nsignify?Howaboutdashedlines?\nR-14.29 Repeat Exercise R-14.28 for Figure 14.8 that illustrates a directed DFS traver-\nsal.\nR-14.30 RepeatExerciseR-14.28forFigure14.10thatillustratesaBFStraversal.\nR-14.31 Repeat Exercise R-14.28for Figure 14.11illustrating the Floyd-Warshallalgo-\nrithm.\nwww.it-ebooks.info\n680 Chapter14. GraphAlgorithms\nR-14.32 RepeatExerciseR-14.28forFigure14.13thatillustratesthetopologicalsorting\nalgorithm.\nR-14.33 RepeatExerciseR-14.28forFigures14.15and14.16illustratingDijkstra\u2019salgo-\nrithm.\nR-14.34 Repeat Exercise R-14.28 for Figures 14.20 and 14.21 that illustrate the Prim-\nJarn\u00b4\u0131kalgorithm.\nR-14.35 RepeatExerciseR-14.28forFigures14.22through14.24thatillustrateKruskal\u2019s\nalgorithm.\nR-14.36 George claims he has a fast way to do path compression in a partition struc-\nture,startingataposition p. Heputs pintoalistL, andstartsfollowingparent\npointers. Eachtimeheencountersanewposition,q,headdsqtoLandupdates\nthe parentpointerof eachnodein L to pointto q\u2019sparent. Show thatGeorge\u2019s\nalgorithmrunsin\u2126(h2)timeonapathoflengthh.\nCreativity\nC-14.37 GiveaJavaimplementationoftheremoveEdge(e)methodforouradjacencymap\nimplementationof Section 14.2.5, makingsure your implementationworksfor\nbothdirectedandundirectedgraphs.YourmethodshouldruninO(1)time.\nC-14.38 Supposewewishtorepresentann-vertexgraphGusingtheedgeliststructure,\nassumingthatweidentifytheverticeswiththeintegersintheset 0,1,...,n 1 .\n{ \u2212 }\nDescribe how to implement the collection E to support O(logn)-time perfor-\nmanceforthegetEdge(u,v)method. Howareyouimplementingthemethodin\nthiscase?\nC-14.39 LetT bethespanningtreerootedatthestartvertexproducedbythedepth-first\nsearchofaconnected,undirectedgraphG. ArguewhyeveryedgeofGnotinT\ngoesfromavertexinT tooneofitsancestors,thatis,itisabackedge.\nC-14.40 OursolutiontoreportingapathfromutovinCodeFragment14.6couldbemade\nmore efficient in practice if the DFS process ended as soon as v is discovered.\nDescribehowtomodifyourcodebasetoimplementthisoptimization.\nC-14.41 LetGbeanundirectedgraphwithnverticesandmedges.DescribeanO(n+m)-\ntimealgorithmfortraversingeachedgeofGexactlyonceineachdirection.\nC-14.42 ImplementanalgorithmthatreturnsacycleinadirectedgraphG~,ifoneexists.\nC-14.43 Write a method, components(G), forundirectedgraphG, that returnsa dictio-\nnary mapping each vertex to an integer that serves as an identifier for its con-\nnectedcomponent.Thatis,twoverticesshouldbemappedtothesameidentifier\nifandonlyiftheyareinthesameconnectedcomponent.\nC-14.44 Say that a maze is constructed correctly if there is one path from the start to\nthe finish, the entire maze is reachable from the start, and there are no loops\naround any portions of the maze. Given a maze drawn in an n n grid, how\n\u00d7\ncanwedetermineifitisconstructedcorrectly? Whatistherunningtimeofthis\nalgorithm?\nwww.it-ebooks.info\n14.8. Exercises 681\nC-14.45 Computernetworksshouldavoidsinglepointsoffailure,thatis,networkvertices\nthat can disconnect the network if they fail. We say an undirected, connected\ngraphG is biconnectedif it containsno vertexwhose removalwould divideG\nintotwo ormoreconnectedcomponents. Giveanalgorithmforaddingatmost\nn edges to a connected graph G, with n 3 vertices and m n 1 edges, to\n\u2265 \u2265 \u2212\nguaranteethatGisbiconnected.YouralgorithmshouldruninO(n+m)time.\nC-14.46 Explainwhyall nontreeedgesare cross edges, with respectto a BFS tree con-\nstructedforanundirectedgraph.\nC-14.47 ExplainwhytherearenoforwardnontreeedgeswithrespecttoaBFStreecon-\nstructedforadirectedgraph.\nC-14.48 Show that if T is a BFS tree producedfor a connectedgraphG, then, for each\nvertexvatleveli,thepathofT betweensandvhasiedges,andanyotherpath\nofGbetweensandvhasatleastiedges.\nC-14.49 JustifyProposition14.16.\nC-14.50 ProvideanimplementationoftheBFSalgorithmthatusesaFIFOqueue,rather\nthanalevel-by-levelformulation,to manageverticesthathavebeendiscovered\nuntilthetimewhentheirneighborsareconsidered.\nC-14.51 A graph G is bipartite if its vertices can be partitioned into two sets X andY\nsuch that every edge in G has one end vertex in X and the other inY. Design\nand analyze an efficient algorithm for determining if an undirected graph G is\nbipartite(withoutknowingthesetsX andY inadvance).\nC-14.52 AnEulertourofadirectedgraphG~ withnverticesandmedgesisacyclethat\ntraverses each edge of G~ exactly once according to its direction. Such a tour\nalwaysexistsif G~ isconnectedandthe in-degreeequalsthe out-degreeofeach\nvertex in G~. Describe an O(n+m)-time algorithmfor finding an Euler tour of\nsuchadirectedgraphG~.\nC-14.53 AcompanynamedRT&Thasanetworkofnswitchingstationsconnectedbym\nhigh-speedcommunicationlinks.Eachcustomer\u2019sphoneisdirectlyconnectedto\nonestationinhisorherarea.TheengineersofRT&Thavedevelopedaprototype\nvideo-phonesystemthatallowstwocustomerstoseeeachotherduringaphone\ncall. In order to have acceptable image quality, however, the number of links\nusedtotransmitvideosignalsbetweenthetwopartiescannotexceed4. Suppose\nthat RT&T\u2019s network is represented by a graph. Design an efficient algorithm\nthatcomputes,foreachstation,thesetofstationsitcanreachusingnomorethan\n4links.\nC-14.54 Thetimedelayofalong-distancecallcanbedeterminedbymultiplyingasmall\nfixedconstantbythenumberofcommunicationlinksonthetelephonenetwork\nbetween the caller and callee. Suppose the telephone network of a company\nnamedRT&Tisatree. TheengineersofRT&Twanttocomputethemaximum\npossibletimedelaythatmaybeexperiencedinalong-distancecall. Givenatree\nT,thediameterofT isthelengthofalongestpathbetweentwonodesofT. Give\nanefficientalgorithmforcomputingthediameterofT.\nwww.it-ebooks.info\n682 Chapter14. GraphAlgorithms\nC-14.55 TamarindoUniversityandmanyotherschoolsworldwidearedoingajointproject\nonmultimedia.Acomputernetworkisbuilttoconnecttheseschoolsusingcom-\nmunication links that form a tree. The schools decide to install a file server at\none of the schools to share data amongall the schools. Since the transmission\ntimeonalinkisdominatedbythelinksetupandsynchronization,thecostofa\ndatatransferisproportionaltothenumberoflinksused.Hence,itisdesirableto\nchoosea\u201ccentral\u201dlocationforthefileserver. GivenatreeT andanodevofT,\ntheeccentricityofvisthelengthofalongestpathfromvtoanyothernodeofT.\nAnodeofT withminimumeccentricityiscalledacenterofT.\na. Design an efficient algorithm that, given an n-node tree T, computes a\ncenterofT.\nb. Isthecenterunique?Ifnot,howmanydistinctcenterscanatreehave?\nC-14.56 Saythatann-vertexdirectedacyclicgraphG~ iscompactifthereissomewayof\nnumberingtheverticesofG~ withtheintegersfrom0ton 1suchthatG~ contains\nthe edge (i,j) if and only if i< j, for all i,j in [0,n \u2212 1]. Give an O(n2)-time\n\u2212\nalgorithmfordetectingifG~ iscompact.\nC-14.57 LetG~ beaweighteddirectedgraphwithnvertices. DesignavariationofFloyd-\nWarshall\u2019s algorithmfor computingthe lengthsof the shortestpaths fromeach\nvertextoeveryothervertexinO(n3)time.\nC-14.58 Design an efficient algorithm for finding a longest directed path from a vertex\ns to a vertext of an acyclicweighteddirectedgraphG~. Specifythe graphrep-\nresentationused and anyauxiliary data structuresused. Also, analyze the time\ncomplexityofyouralgorithm.\nC-14.59 AnindependentsetofanundirectedgraphG=(V,E)isasubsetIofV suchthat\nnotwoverticesinIareadjacent.Thatis,ifuandvareinI,then(u,v)isnotinE.\nAmaximalindependentsetMisanindependentsetsuchthat,ifweweretoadd\nany additionalvertexto M, then it would not be independentany more. Every\ngraph has a maximalindependentset. (Can you see this? This question is not\npartofthe exercise,butitisworththinkingabout.) Giveanefficientalgorithm\nthatcomputesamaximalindependentset fora graphG. Whatis thismethod\u2019s\nrunningtime?\nC-14.60 Giveanexampleofann-vertexsimplegraphGthatcausesDijkstra\u2019salgorithm\ntorunin\u2126(n2logn)timewhenitsimplementedwithaheap.\nC-14.61 GiveanexampleofaweighteddirectedgraphG~ withnegative-weightedges,but\nnonegative-weightcycle,suchthatDijkstra\u2019salgorithmincorrectlycomputesthe\nshortest-pathdistancesfromsomestartvertexs.\nC-14.62 Our implementationof shortestPathLengthsin Code Fragment14.13relies on\nuseof\u201cinfinity\u201dasanumericvalue,torepresentthedistanceboundforvertices\nthat are not (yet) known to be reachable from the source. Reimplement that\nmethod without such a sentinel, so that vertices, other than the source, are not\naddedtothepriorityqueueuntilitisevidentthattheyarereachable.\nwww.it-ebooks.info\n14.8. Exercises 683\nC-14.63 Consider the following greedy strategy for finding a shortest path from vertex\nstarttovertexgoalinagivenconnectedgraph.\n1: Initializepathtostart.\n2: Initializesetvisitedto start .\n{ }\n3: Ifstart=goal,returnpathandexit.Otherwise,continue.\n4: Findtheedge(start,v)ofminimumweightsuchthatvisadjacenttostart\nandvisnotinvisited.\n5: Addvtopath.\n6: Addvtovisited.\n7: Setstartequaltovandgotostep3.\nDoesthisgreedystrategyalwaysfindashortestpathfromstarttogoal? Either\nexplainintuitivelywhyitworks,orgiveacounterexample.\nC-14.64 Show thatif allthe weightsin a connectedweightedgraphG are distinct, then\nthereisexactlyoneminimumspanningtreeforG.\nC-14.65 AnoldMSTmethod,calledBaru\u02davka\u2019salgorithm,worksasfollowsonagraph\nGhavingnverticesandmedgeswithdistinctweights:\nLetT beasubgraphofGinitiallycontainingjusttheverticesinV.\nwhileT hasfewerthann 1edgesdo\n\u2212\nforeachconnectedcomponentC ofT do\ni\nFindthelowest-weightedge(u,v)inE withuinC andvnotinC.\ni i\nAdd(u,v)toT (unlessitisalreadyinT).\nreturnT\nProvethatthisalgorithmiscorrectandthatitrunsinO(mlogn)time.\nC-14.66 Let G be a graph with n vertices and m edges such that all the edge weights\nin G are integers in the range [1,n]. Give an algorithm for finding a minimum\n\u2217\nspanningtreeforGinO(mlog n)time.\nC-14.67 Considera diagramofatelephonenetwork,whichisa graphG whosevertices\nrepresent switching centers, and whose edges represent communication lines\njoining pairs of centers. Edges are marked by their bandwidth, and the band-\nwidthofapathisequaltothelowestbandwidthamongthepath\u2019sedges.Givean\nalgorithmthat, givena networkand two switchingcentersa and b, outputsthe\nmaximumbandwidthofapathbetweenaandb.\nC-14.68 NASA wants to link n stations spread over the country using communication\nchannels. Each pair of stations has a different bandwidth available, which is\nknownapriori. NASAwantstoselectn 1channels(theminimumpossible)in\n\u2212\nsuchawaythatallthestationsarelinkedbythechannelsandthetotalbandwidth\n(definedasthesumoftheindividualbandwidthsofthechannels)is maximum.\nGive an efficient algorithm for this problem and determine its worst-case time\ncomplexity. ConsidertheweightedgraphG=(V,E),whereV isthesetofsta-\ntionsandE isthesetofchannelsbetweenthestations. Definetheweightw(e)of\nanedgeeinE asthebandwidthofthecorrespondingchannel.\nwww.it-ebooks.info\n684 Chapter14. GraphAlgorithms\nC-14.69 InsidetheCastleofAsymptopiathereisamaze,andalongeachcorridorofthe\nmazethereisabagofgoldcoins.Theamountofgoldineachbagvaries.Anoble\nknight,namedSirPaul,willbegiventheopportunitytowalkthroughthemaze,\npicking up bags of gold. He may enter the maze only through a door marked\n\u201cENTER\u201dandexitthroughanotherdoormarked\u201cEXIT.\u201dWhileinthemazehe\nmaynotretracehissteps. Eachcorridorofthemazehasanarrowpaintedonthe\nwall. SirPaulmayonlygodownthecorridorinthedirectionofthearrow.There\nisnowaytotraversea\u201cloop\u201dinthemaze. Givenamapofthemaze,including\ntheamountofgoldineachcorridor,describeanalgorithmtohelpSirPaulpick\nupthemostgold.\nC-14.70 Supposeyouaregivenatimetable,whichconsistsof:\nAset ofnairports,andforeachairportain ,aminimumconnecting\n\u2022 A A\ntimec(a).\nAset ofmflights,andthefollowing,foreachflight f in :\n\u2022 F F\nOriginairporta (f)in\n1\n\u25e6 A\nDestinationairporta (f)in\n2\n\u25e6 A\nDeparturetimet (f)\n1\n\u25e6\nArrivaltimet (f)\n2\n\u25e6\nDescribeanefficientalgorithmfortheflightschedulingproblem.Inthisproblem,\nwearegivenairportsaandb,andatimet,andwewishtocomputeasequenceof\nflightsthatallowsonetoarriveattheearliestpossibletimeinbwhendeparting\nfrom a at or after time t. Minimum connecting times at intermediate airports\nmustbeobserved. Whatistherunningtimeofyouralgorithmasafunctionofn\nandm?\nC-14.71 SupposewearegivenadirectedgraphG~ withnvertices,andletM bethen n\nadjacencymatrixcorrespondingtoG~. \u00d7\na. LettheproductofMwithitself(M2)bedefined,for1 i,j n,asfollows:\n\u2264 \u2264\nM2(i,j)=M(i,1) M(1,j) M(i,n) M(n,j),\n\u2299 \u2295\u00b7\u00b7\u00b7\u2295 \u2299\nwhere\u201c \u201disthebooleanoroperatorand\u201c \u201disbooleanand. Giventhis\ndefinitio \u2295 n,whatdoesM2(i,j)=1implyab \u2299 outtheverticesiand j? What\nifM2(i,j)=0?\nb. Suppose M4 is the productof M2 with itself. What do the entries of M4\nsignify? HowabouttheentriesofM5=(M4)(M)? Ingeneral,whatinfor-\nmationiscontainedinthematrixMp?\nc. NowsupposethatG~ isweightedandassumethefollowing:\n1: for1 i n,M(i,i)=0.\n\u2264 \u2264\n2: for1 i,j n,M(i,j)=weight(i,j)if(i,j)isinE.\n\u2264 \u2264\n3: for1 i,j n,M(i,j)= if(i,j)isnotinE.\n\u2264 \u2264 \u221e\nAlso,letM2 bedefined,for1 i,j n,asfollows:\n\u2264 \u2264\nM2(i,j)=min M(i,1)+M(1,j),...,M(i,n)+M(n,j) .\n{ }\nIfM2(i,j)=k,whatmayweconcludeabouttherelationshipbetweenver-\nticesiand j?\nwww.it-ebooks.info\n14.8. Exercises 685\nC-14.72 Karenhasanewwaytodopathcompressioninatree-basedunion/findpartition\ndata structurestarting ata position p. She putsall the positionsthatare on the\npathfrom ptotherootinasetS. ThenshescansthroughSandsetstheparent\npointerofeachpositioninStoitsparent\u2019sparentpointer(recallthattheparent\npointeroftherootpointstoitself).Ifthispasschangedthevalueofanyposition\u2019s\nparentpointer,thensherepeatsthisprocess,andgoesonrepeatingthisprocess\nuntilshemakesascanthroughSthatdoesnotchangeanyposition\u2019sparentvalue.\nShowthatKaren\u2019salgorithmiscorrectandanalyzeitsrunningtimeforapathof\nlengthh.\nProjects\nP-14.73 UseanadjacencymatrixtoimplementaclasssupportingasimplifiedgraphADT\nthat does not include update methods. Your class should include a constructor\nmethodthattakestwocollections\u2014acollectionV ofvertexelementsandacol-\nlectionE ofpairsofvertexelements\u2014andproducesthegraphGthatthesetwo\ncollectionsrepresent.\nP-14.74 Implement the simplified graph ADT described in Exercise P-14.73, using the\nedgeliststructure.\nP-14.75 Implement the simplified graph ADT described in Exercise P-14.73, using the\nadjacencyliststructure.\nP-14.76 ExtendtheclassofExerciseP-14.75tosupporttheupdatemethodsofthegraph\nADT.\nP-14.77 DesignanexperimentalcomparisonofrepeatedDFStraversalsversustheFloyd-\nWarshallalgorithmforcomputingthetransitiveclosureofadirectedgraph.\nP-14.78 Developa JavaimplementationofthePrim-Jarn\u00b4\u0131kalgorithmforcomputingthe\nminimumspanningtreeofagraph.\nP-14.79 Performanexperimentalcomparisonoftwooftheminimumspanningtreealgo-\nrithmsdiscussedinthischapter(KruskalandPrim-Jarn\u00b4\u0131k).Developanextensive\nsetofexperimentstotesttherunningtimesofthesealgorithmsusingrandomly\ngeneratedgraphs.\nP-14.80 One way to construct a maze starts with an n n grid such that each grid cell\n\u00d7\nisboundedbyfourunit-lengthwalls. Wethenremovetwoboundaryunit-length\nwalls, to representthe startandfinish. Foreach remainingunit-lengthwall not\nontheboundary,weassignarandomvalueandcreateagraphG,calledthedual,\nsuchthateachgridcellisavertexinGandthereisanedgejoiningthevertices\nfor two cells if and only if the cells share a commonwall. The weightof each\nedgeistheweightofthecorrespondingwall. Weconstructthemazebyfinding\na minimumspanningtree T forG and removingall the walls correspondingto\nedgesinT. Writeaprogramthatusesthisalgorithmtogeneratemazesandthen\nsolves them. Minimally, your program should draw the maze and, ideally, it\nshouldvisualizethesolutionaswell.\nwww.it-ebooks.info\n686 Chapter14. GraphAlgorithms\nP-14.81 Write a programthat buildsthe routingtables for the nodesin a computernet-\nwork, based on shortest-path routing, where path distance is measured by hop\ncount, thatis, the numberof edgesin a path. The inputfor this problemis the\nconnectivity information for all the nodes in the network, as in the following\nexample:\n241.12.31.14: 241.12.31.15 241.12.31.18 241.12.31.19\nwhichindicatesthreenetworknodesthatareconnectedto241.12.31.14,thatis,\nthree nodesthatare one hopaway. The routingtable for the nodeat addressA\nisasetofpairs(B,C),whichindicatesthat,torouteamessagefromAtoB,the\nnextnodetosendto(ontheshortestpathfromAtoB)isC. Yourprogramshould\noutputtheroutingtableforeachnodeinthenetwork,givenaninputlistofnode\nconnectivitylists, eachofwhichisinputinthesyntaxasshownabove,oneper\nline.\nChapter Notes\nThedepth-firstsearchmethodisapartofthe\u201cfolklore\u201dofcomputerscience,butHopcroft\nand Tarjan [46, 87] are the ones who showed how useful this algorithm is for solving\nseveral different graph problems. Knuth [60] discusses the topological sorting problem.\nThe simple linear-time algorithm that we describe for determining if a directed graph is\nstronglyconnectedis due to Kosaraju. The Floyd-Warshallalgorithmappearsin a paper\nbyFloyd[34]andisbaseduponatheoremofWarshall[94].\nThe first known minimum spanning tree algorithm is due to Baru\u02davka [9], and was\npublishedin1926. ThePrim-Jarn\u00b4\u0131kalgorithmwasfirstpublishedinCzechbyJarn\u00b4\u0131k[51]\nin 1930 and in English in 1957 by Prim [79]. Kruskalpublished his minimum spanning\ntree algorithm in 1956 [63]. The reader interested in further study of the history of the\nminimum spanning tree problem is referred to the paper by Graham and Hell [41]. The\ncurrentasymptoticallyfastest minimumspanningtree algorithmis a randomizedmethod\nofKarger,Klein,andTarjan[53]thatrunsinO(m)expectedtime. Dijkstra[30]published\nhis single-source, shortest-path algorithmin 1959. The runningtime for the Prim-Jarn\u00b4\u0131k\nalgorithm,andalsothatofDijkstra\u2019salgorithm,canactuallybeimprovedtobeO(nlogn+\nm)byimplementingthequeueQwitheitheroftwomoresophisticateddatastructures,the\n\u201cFibonacciHeap\u201d[36]orthe\u201cRelaxedHeap\u201d[32].\nTolearnaboutdifferentalgorithmsfordrawinggraphs,pleaseseethebookchapterby\nTamassiaandLiotta[85]andthebookbyDiBattista,Eades,TamassiaandTollis[29]. The\nreader interested in further study of graph algorithms is referred to the books by Ahuja,\nMagnanti, and Orlin [7], Cormen, Leiserson, Rivest and Stein [25], Mehlhorn [72], and\nTarjan[88],andthebookchapterbyvanLeeuwen[90].\nwww.it-ebooks.info\nChapter\n15\nMemory Management and B-Trees\nContents\n15.1 Memory Management . . . . . . . . . . . . . . . . . . . . . 688\n15.1.1 Stacks in the Java Virtual Machine . . . . . . . . . . . . . 688\n15.1.2 Allocating Space in the Memory Heap . . . . . . . . . . . 691\n15.1.3 Garbage Collection . . . . . . . . . . . . . . . . . . . . . 693\n15.2 Memory Hierarchies and Caching . . . . . . . . . . . . . . 695\n15.2.1 Memory Systems . . . . . . . . . . . . . . . . . . . . . . 695\n15.2.2 Caching Strategies . . . . . . . . . . . . . . . . . . . . . 696\n15.3 External Searching and B-Trees . . . . . . . . . . . . . . . 701\n15.3.1 (a,b) Trees . . . . . . . . . . . . . . . . . . . . . . . . . 702\n15.3.2 B-Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . 704\n15.4 External-Memory Sorting . . . . . . . . . . . . . . . . . . . 705\n15.4.1 Multiway Merging . . . . . . . . . . . . . . . . . . . . . . 706\n15.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 707\nwww.it-ebooks.info\n688 Chapter15. MemoryManagementandB-Trees\n15.1 Memory Management\nComputer memoryis organized into asequence of words, each of which typically\nconsists of 4, 8, or 16 bytes (depending on the computer). These memory words\narenumbered from 0toN 1, whereN isthenumber ofmemorywords available\n\u2212\nto the computer. The number associated with each memory word is known as its\nmemoryaddress. Thus, thememoryinacomputer canbeviewedasbasically one\ngiantarrayofmemorywords,asportrayed inFigure15.1.\n4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0\n4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6\n1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\nFigure15.1: Memoryaddresses.\nIn order to run programs and store information, the computer\u2019s memory must\nbe managed so as to determine what data is stored in what memory cells. In this\nsection,wediscussthebasicsofmemorymanagement,mostnotablydescribingthe\nwayinwhichmemoryisallocated forvarious purposes inaJavaprogram, andthe\nway in which portions of memory are deallocated and reclaimed, when no longer\nneeded.\n15.1.1 Stacks in the Java Virtual Machine\nA Java program is typically compiled into a sequence of byte codes that serve\nas \u201cmachine\u201d instructions for a well-defined model\u2014the Java Virtual Machine\n(JVM). The definition of the JVM is at the heart of the definition of the Java lan-\nguage itself. By compiling Java code into the JVM byte codes, rather than the\nmachine language of a specific CPU, a Java program can be run on any computer\nthathasaprogram thatcanemulatetheJVM.\nStacks have an important application to the runtime environment of Java pro-\ngrams. A running Java program (more precisely, a running Java thread) has a pri-\nvatestack,calledtheJavamethodstackorjustJavastackforshort,whichisused\ntokeeptrackoflocalvariablesandotherimportantinformationonmethodsasthey\nareinvoked duringexecution. (SeeFigure15.2.)\nMore specifically, during the execution of a Java program, the Java Virtual\nMachine (JVM) maintains a stack whose elements are descriptors of the currently\nactive(thatis,nonterminated)invocations ofmethods. Thesedescriptorsarecalled\nframes. Aframeforsomeinvocation ofmethod\u201cfool\u201dstoresthecurrentvaluesof\nthelocalvariablesandparametersofmethodfool,aswellasinformationonmethod\n\u201ccool\u201dthatcalledfoolandonwhatneedstobereturned tomethod\u201ccool\u201d.\nwww.it-ebooks.info\n15.1. MemoryManagement 689\nmain() {\nint i=5;\n14 cool(i);\nfool:\nPC = 320\nm = 7 }\ncool: cool(int j) {\nPC =216\nint k=7;\nj = 5\nk = 7\n216 fool(k);\nmain:\nPC = 14\ni = 5 }\n320 fool(int m) {\nJavaStack\n}\nJavaProgram\nFigure15.2: Anexample of aJava method stack: method foolhas just been called\nby method cool, which itself was previously called by method main. Note the\nvalues of the program counter, parameters, and local variables stored in the stack\nframes. When the invocation of method fool terminates, the invocation of method\ncoolwillresumeitsexecutionatinstruction217,whichisobtainedbyincrementing\nthevalueoftheprogram counter storedinthestackframe.\nKeeping Track of the Program Counter\nThe JVM keeps a special variable, called the program counter, to maintain the\naddress of the statement the JVM is currently executing in the program. When a\nmethod \u201ccool\u201d invokes another method \u201cfool\u201d, the current value of the program\ncounter is recorded in the frame of the current invocation of cool (so the JVM\nwill know where to return to when method fool is done). At the top of the Java\nstack is the frame of the running method, that is, the method that currently has\ncontrol of the execution. The remaining elements of the stack are frames of the\nsuspended methods, that is, methods that have invoked another method and are\ncurrently waitingforittoreturncontroltothemuponitstermination. Theorderof\nthe elements in the stack corresponds to the chain of invocations of the currently\nactivemethods. Whenanewmethodisinvoked, aframeforthismethodispushed\nontothestack. Whenitterminates,itsframeispoppedfromthestackandtheJVM\nresumestheprocessing ofthepreviously suspended method.\nwww.it-ebooks.info\n690 Chapter15. MemoryManagementandB-Trees\nImplementing Recursion\nOneofthebenefitsofusingastacktoimplementmethodinvocationisthatitallows\nprograms to use recursion. That is, it allows a method to call itself, as discussed\nin Chapter 5. We implicitly described the concept of the call stack and the use\nof frames within our portrayal of recursion traces in that chapter. Interestingly,\nearly programming languages, such as Cobol and Fortran, did not originally use\ncallstackstoimplementfunction andprocedure calls. Butbecause oftheelegance\nandefficiencythatrecursionallows,allmodernprogramminglanguages, including\nthe modern versions of classic languages like Cobol and Fortran, utilize aruntime\nstackformethodandprocedure calls.\nEachboxofarecursion tracecorresponds toaframeoftheJavamethodstack.\nAtanypointintime,thecontentsoftheJavamethodstackcorrespondstothechain\nofboxesfromtheinitialmethodinvocation tothecurrentone.\nTo better illustrate how a runtime stack allows recursive methods, we refer\nback to the Java implementation of the classic recursive definition of the factorial\nfunction,\nn!=n(n 1)(n 2) 1,\n\u2212 \u2212 \u00b7\u00b7\u00b7\nwiththecodeoriginallygiveninCodeFragment5.1,andtherecursiontraceinFig-\nure5.1. Thefirsttimewecallmethodfactorial(n),itsstack frameincludes alocal\nvariablestoringthevaluen. Themethodrecursivelycallsitselftocompute(n 1)!,\n\u2212\nwhich pushes a new frame on the Java runtime stack. In turn, this recursive invo-\ncation callsitself tocompute (n 2)!, etc. Thechain ofrecursive invocations, and\n\u2212\nthus the runtime stack, only grows up to size n+1, with the most deeply nested\ncallbeing factorial(0),whichreturns 1withoutanyfurther recursion. Theruntime\nstack allows several invocations of the factorial method to exist simultaneously.\nEach has a frame that stores the value of its parameter n as well as the value to\nbereturned. Whenthefirstrecursive calleventually terminates, itreturns (n 1)!,\n\u2212\nwhich is then multiplied by n to compute n! for the original call of the factorial\nmethod.\nThe Operand Stack\nInterestingly, there is actually another place where the JVM uses a stack. Arith-\nmeticexpressions, suchas((a+b) (c+d))/e, areevaluatedbytheJVMusingan\n\u2217\noperandstack. Asimplebinaryoperation,suchasa+b,iscomputedbypushinga\nonthestack,pushingbonthestack,andthencallinganinstructionthatpopsthetop\ntwoitemsfromthestack,performsthebinaryoperationonthem,andpushesthere-\nsultbackontothestack. Likewise,instructions forwritingandreadingelementsto\nandfrom memory involve theuseofpopand pushmethods fortheoperand stack.\nThus,theJVMusesastacktoevaluatearithmeticexpressions inJava.\nwww.it-ebooks.info\n15.1. MemoryManagement 691\n15.1.2 Allocating Space in the Memory Heap\nWehave already discussed (in Section 15.1.1) how the Java Virtual Machine allo-\ncates a method\u2019s local variables in that method\u2019s frame on the Java runtime stack.\nThe Java stack is not the only kind of memory available for program data in Java,\nhowever.\nDynamic Memory Allocation\nMemoryforanobject can alsobeallocated dynamically during amethod\u2019s execu-\ntion, by having that method utilize the special new operator built into Java. For\nexample, the following Java statement creates an array of integers whose size is\ngivenbythevalueofvariable k:\nint[ ] items = new int[k];\nThe size of the array above is known only at runtime. Moreover, the array may\ncontinuetoexistevenafterthemethodthatcreateditterminates. Thus,thememory\nforthisarraycannotbeallocated ontheJavastack.\nThe Memory Heap\nInstead of using the Java stack for this object\u2019s memory, Java uses memory from\nanother area of storage\u2014the memory heap (which should not be confused with\nthe \u201cheap\u201d data structure presented in Chapter 9). Weillustrate this memory area,\ntogetherwiththeothermemoryareas,inaJavaVirtualMachineinFigure15.3. The\nstorage available in thememoryheap isdivided into blocks, which arecontiguous\narray-like \u201cchunks\u201d ofmemorythatmaybeofvariableorfixedsizes.\nTo simplify the discussion, let us assume that blocks in the memory heap are\nof a fixed size, say, 1,024 bytes, and that one block is big enough for any object\nwemightwanttocreate. (Efficiently handling themoregeneralcaseisactually an\ninteresting researchproblem.)\nProgram Code Java Stack Free Memory Memory Heap\nfixed size\u2212 doesn\u2019t grow grows into higher memory grows into lower memory\nFigure15.3:AschematicviewofthelayoutofmemoryaddressesintheJavaVirtual\nMachine.\nwww.it-ebooks.info\n692 Chapter15. MemoryManagementandB-Trees\nMemory Allocation Algorithms\nThe Java Virtual Machine definition requires that the memory heap be able to\nquickly allocate memory for new objects, but it does not specify the algorithm\nthat should be used to do this. One popular method is to keep contiguous \u201choles\u201d\nofavailablefreememoryinalinkedlist,calledthefreelist. Thelinksjoiningthese\nholesarestoredinside theholesthemselves, sincetheirmemoryisnotbeing used.\nAs memory is allocated and deallocated, the collection of holes in the free lists\nchanges, with the unused memory being separated into disjoint holes divided by\nblocks of used memory. This separation of unused memory into separate holes is\nknownasfragmentation. Theproblemisthatitbecomesmoredifficulttofindlarge\ncontinuous chunksofmemory,whenneeded,eventhoughanequivalent amountof\nmemorymaybeunused(yetfragmented).\nTwokinds offragmentation can occur. Internal fragmentation occurs when a\nportion of an allocated memory block is unused. For example, a program may re-\nquestanarrayofsize1000, butonlyusethefirst100cellsofthisarray. Aruntime\nenvironment can not do much to reduce internal fragmentation. External frag-\nmentation, ontheotherhand, occurs whenthere isasignificant amountofunused\nmemory between several contiguous blocks of allocated memory. Since the run-\ntime environment has control over where to allocate memory when it is requested\n(for example, when the new keyword is used in Java), the runtime environment\nshouldallocate memoryinawaytotrytoreduceexternalfragmentation.\nSeveral heuristics have been suggested for allocating memory from the heap\nso as to minimize external fragmentation. The best-fit algorithm searches the en-\ntire free list to find the hole whose size is closest to the amount of memory being\nrequested. The first-fit algorithm searches from the beginning of the free list for\nthe first hole that is large enough. The next-fit algorithm is similar, in that it also\nsearches the free list for the first hole that is large enough, but it begins its search\nfrom where it left off previously, viewing the free list as a circularly linked list\n(Section 3.3). Theworst-fitalgorithm searches thefree listtofindthe largest hole\nofavailablememory,whichmightbedonefasterthanasearchoftheentirefreelist\nif this list were maintained as a priority queue (Chapter 9). In each algorithm, the\nrequested amount of memory is subtracted from the chosen memory hole and the\nleftoverpartofthatholeisreturned tothefreelist.\nAlthough it might sound good at first, the best-fit algorithm tends to produce\nthe worst external fragmentation, since the leftover parts of the chosen holes tend\nto be small. The first-fit algorithm is fast, but it tends to produce a lot of external\nfragmentation at the front of the free list, which slows down future searches. The\nnext-fitalgorithmspreadsfragmentationmoreevenlythroughoutthememoryheap,\nthus keeping search times low. This spreading also makesit moredifficult toallo-\ncate large blocks, however. Theworst-fitalgorithm attempts toavoid this problem\nbykeepingcontiguous sections offreememoryaslargeaspossible.\nwww.it-ebooks.info\n15.1. MemoryManagement 693\n15.1.3 Garbage Collection\nInsomelanguages, like Cand C++,the memoryspace forobjects mustbeexplic-\nitlydeallocated bytheprogrammer, whichisadutyoftenoverlooked bybeginning\nprogrammers and is the source of frustrating programming errors even for experi-\nenced programmers. The designers of Java instead placed the burden of memory\nmanagemententirely ontheruntimeenvironment.\nAs mentioned above, memory for objects is allocated from the memory heap\nandthespacefortheinstancevariables ofarunningJavaprogram areplacedinits\nmethod stacks, one for each running thread (for the simple programs discussed in\nthis book there is typically just one running thread). Since instance variables in a\nmethodstackcanrefertoobjectsinthememoryheap,allthevariablesandobjects\nin the method stacks of running threads are called root objects. All those objects\nthat can be reached by following object references that start from a root object\nare called live objects. The live objects are the active objects currently being used\nby the running program; these objects should not be deallocated. For example, a\nrunning Java program may store, in a variable, a reference to a sequence S that is\nimplementedusingadoublylinkedlist. ThereferencevariabletoSisarootobject,\nwhiletheobjectforSisaliveobject,asareallthenodeobjectsthatarereferenced\nfromthisobjectandalltheelementsthatarereferenced fromthesenodeobjects.\nFrom time to time, the Java virtual machine (JVM) may notice that available\nspaceinthememoryheapisbecomingscarce. Atsuchtimes,theJVMcanelectto\nreclaimthespacethatisbeingusedforobjectsthatarenolongerlive,andreturnthe\nreclaimed memory to the free list. This reclamation process is known as garbage\ncollection. Thereareseveraldifferentalgorithmsforgarbagecollection, butoneof\nthemostusedisthemark-sweepalgorithm.\nThe Mark-Sweep Algorithm\nIn the mark-sweep garbage collection algorithm, we associate a \u201cmark\u201d bit with\neach object that identifies whether that object is live. When wedetermine atsome\npoint that garbage collection isneeded, wesuspend all other activity and clear the\nmark bits of all the objects currently allocated in the memory heap. Wethen trace\nthrough the Java stacks of the currently running threads and we mark all the root\nobjectsinthesestacksas\u201clive.\u201d Wemustthendeterminealltheotherliveobjects\u2014\ntheonesthatarereachable fromtherootobjects.\nTo do this efficiently, we can perform a depth-first search (see Section 14.3.1)\non the directed graph that is defined by objects referencing other objects. In this\ncase, each object in the memory heap is viewed as a vertex in a directed graph,\nand the reference from one object to another is viewed as a directed edge. By\nperforming a directed DFS from each root object, we can correctly identify and\nmarkeachliveobject. Thisprocessisknownasthe\u201cmark\u201dphase.\nwww.it-ebooks.info\n694 Chapter15. MemoryManagementandB-Trees\nOnce this process has completed, we then scan through the memory heap and\nreclaimanyspacethatisbeingusedforanobjectthathasnotbeenmarked. Atthis\ntime, we can also optionally coalesce all the allocated space in the memory heap\ninto a single block, thereby eliminating external fragmentation for the time being.\nThis scanning and reclamation process is known as the \u201csweep\u201d phase, and when\nit completes, we resume running the suspended program. Thus, the mark-sweep\ngarbage collection algorithm willreclaim unused space intimeproportional tothe\nnumberofliveobjects andtheirreferences plusthesizeofthememoryheap.\nPerforming DFS In-Place\nThe mark-sweep algorithm correctly reclaims unused space in the memory heap,\nbut there is an important issue we must face during the mark phase. Since we are\nreclaimingmemoryspaceatatimewhenavailablememoryisscarce,wemusttake\ncare not to use extra space during the garbage collection itself. The trouble is that\ntheDFSalgorithm,intherecursivewaywehavedescribeditinSection14.3.1,can\nusespaceproportionaltothenumberofverticesinthegraph. Inthecaseofgarbage\ncollection, theverticesinourgrapharetheobjects inthememoryheap;hence, we\nprobably don\u2019t have this much memory to use. Soour only alternative is to find a\nwaytoperformDFSin-placeratherthanrecursively.\nThe main idea for performing DFS in-place is to simulate the recursion stack\nusing the edges of the graph (which in the case of garbage collection correspond\nto object references). When we traverse an edge from a visited vertex v to a new\nvertexw,wechange theedge(v,w)stored inv\u2019sadjacency listtopointback tov\u2019s\nparent in the DFS tree. When we return back to v (simulating the return from the\n\u201crecursive\u201d callatw),wecannowswitchtheedgewemodifiedtopointbacktow.\nOfcourse,weneedtohavesomewayofidentifyingwhichedgeweneedtochange\nback. Onepossibility istonumberthereferences going outofvas1,2,andsoon,\nand store, in addition to the mark bit (which we are using for the \u201cvisited\u201d tag in\nourDFS),acountidentifierthattellsuswhichedgeswehavemodified.\nUsing a count identifier requires an extra word of storage per object. This\nextrawordcanbeavoided insomeimplementations, however. Forexample, many\nimplementations of the Java virtual machine represent an object as a composition\nof a reference with a type identifier (which indicates if this object is an Integer\nor some other type) and as a reference to the other objects or data fields for this\nobject. Since the type reference is always supposed to be the first element of the\ncompositioninsuchimplementations,wecanusethisreferenceto\u201cmark\u201dtheedge\nwechangedwhenleavinganobjectvandgoingtosomeobjectw. Wesimplyswap\nthereference atvthatreferstothetypeofvwiththereference atvthatreferstow.\nWhenwereturntov,wecanquicklyidentifytheedge(v,w)wechanged,becauseit\nwillbethefirstreferenceinthecompositionforv,andthepositionofthereference\ntov\u2019stypewilltellustheplacewherethisedgebelongsinv\u2019sadjacency list.\nwww.it-ebooks.info\n15.2. MemoryHierarchiesandCaching 695\n15.2 Memory Hierarchies and Caching\nWith the increased use of computing in society, software applications must man-\nage extremely large data sets. Such applications include the processing of online\nfinancial transactions, the organization and maintenance of databases, and analy-\nsesofcustomers\u2019 purchasing histories andpreferences. Theamountofdatacanbe\nso large that the overall performance of algorithms and data structures sometimes\ndepends moreonthetimetoaccessthedatathanonthespeedoftheCPU.\n15.2.1 Memory Systems\nIn order to accommodate large data sets, computers have a hierarchy of differ-\nent kinds of memories, which vary in terms of their size and distance from the\nCPU. Closest to the CPU are the internal registers that the CPU itself uses. Ac-\ncess to such locations is very fast, but there are relatively few such locations. At\nthe second level in the hierarchy are one or more memory caches. This memory\nis considerably larger than the register set of a CPU,but accessing it takes longer.\nAtthe third level in the hierarchy is the internal memory, which is also known as\nmain memory or core memory. The internal memory is considerably larger than\nthe cache memory, but also requires more time to access. Another level in the hi-\nerarchy is the external memory, which usually consists of disks, CD drives, DVD\ndrives,and/ortapes. Thismemoryisverylarge,butitisalsoveryslow. Datastored\nthrough an external network can be viewed as yet another level in this hierarchy,\nwith even greater storage capacity, but even slower access. Thus, the memory hi-\nerarchy for computers can be viewed as consisting of five or more levels, each of\nwhich is larger and slower than the previous level. (See Figure 15.4.) During the\nexecution ofaprogram, data isroutinely copied from onelevelofthehierarchy to\naneighboring level,andthesetransfers canbecomeacomputational bottleneck.\nNetworkStorage Faster\nExternal Memory\nInternal Memory\nCaches\nBigger Registers\nCPU\nFigure15.4: Thememoryhierarchy.\nwww.it-ebooks.info\n696 Chapter15. MemoryManagementandB-Trees\n15.2.2 Caching Strategies\nThe significance of the memory hierarchy on the performance of a program de-\npends greatly upon thesize of the problem weare trying tosolve and thephysical\ncharacteristics of the computer system. Often, the bottleneck occurs between two\nlevels of the memoryhierarchy\u2014the one that can hold all data items and the level\njust below that one. For a problem that can fit entirely in main memory, the two\nmostimportantlevelsarethecachememoryandtheinternalmemory. Accesstimes\nforinternal memorycanbeasmuchas10to100timeslongerthanthoseforcache\nmemory. It is desirable, therefore, to be able to perform most memory accesses\nin cache memory. For a problem that does not fit entirely in main memory, on\nthe other hand, the two most important levels are the internal memory and the ex-\nternal memory. Here the differences are even more dramatic, for access times for\ndisks, theusual general-purpose external-memory device, aretypically asmuchas\n100,000 to1,000,000 timeslongerthanthoseforinternalmemory.\nToputthislatterfigureintoperspective,imaginethereisastudentinBaltimore\nwho wants to send a request-for-money message to his parents in Chicago. If the\nstudent sends his parents an email message, it can arrive at their home computer\nin about five seconds. Think of this mode of communication as corresponding to\naninternal-memory accessbyaCPU.Amodeofcommunicationcorresponding to\nan external-memory access that is 500,000 times slower would be for the student\nto walk to Chicago and deliver his message in person, which would take about a\nmonth if he can average 20 miles per day. Thus, we should make as few accesses\ntoexternal memoryaspossible.\nMostalgorithms are notdesigned withthe memoryhierarchy inmind, inspite\nofthegreatvariancebetweenaccesstimesforthedifferentlevels. Indeed,allofthe\nalgorithm analyses thus far described in this book have assumed that all memory\naccesses are equal. Thisassumption might seem, at first, tobeagreat oversight\u2014\nandoneweareonlyaddressingnowinthefinalchapter\u2014buttherearegoodreasons\nwhyitisactually areasonable assumptiontomake.\nOnejustification forthisassumption isthatitisoftennecessary toassumethat\nallmemoryaccessestakethesameamountoftime,sincespecificdevice-dependent\ninformationaboutmemorysizesisoftenhardtocomeby. Infact,informationabout\nmemorysizemaybedifficult toget. Forexample, aJavaprogram thatisdesigned\nto run on many different computer platforms cannot easily be defined in terms of\na specific computer architecture configuration. We can certainly use architecture-\nspecificinformation, ifwehaveit(andwewillshowhowtoexploit suchinforma-\ntion later in this chapter). But once we have optimized our software for a certain\narchitectureconfiguration, oursoftwarewillnolongerbedevice-independent. For-\ntunately, such optimizations are not always necessary, primarily because of the\nsecondjustification fortheequal-timememory-access assumption.\nwww.it-ebooks.info\n15.2. MemoryHierarchiesandCaching 697\nCaching and Blocking\nAnother justification for the memory-access equality assumption is that operating\nsystem designers have developed general mechanisms that allow most memory\naccesses to be fast. These mechanisms are based on two important locality-of-\nreferenceproperties thatmostsoftwarepossesses:\nTemporal locality: If a program accesses a certain memory location, then\n\u2022\nthere is increased likelihood that it accesses that same location again in the\nnear future. For example, it is common to use the value of a counter vari-\nableinseveraldifferentexpressions,includingonetoincrementthecounter\u2019s\nvalue. Infact,acommonadageamongcomputerarchitectsisthataprogram\nspends90%ofitstimein10%ofitscode.\nSpatiallocality: Ifaprogramaccessesacertainmemorylocation,thenthere\n\u2022\nisincreased likelihood thatitsoon accesses other locations thatarenearthis\none. For example, a program using an array may be likely to access the\nlocations ofthisarrayinasequential ornear-sequential manner.\nComputerscientistsandengineers haveperformedextensivesoftwareprofilingex-\nperiments to justify the claim that most software possesses both of these kinds of\nlocalityofreference. Forexample,anestedforloopusedtorepeatedlyscanthrough\nanarraywillexhibitbothkindsoflocality.\nTemporal and spatial localities have, in turn, given rise to two fundamental\ndesign choices for multilevel computer memory systems (which are present in the\ninterface between cache memory and internal memory, and also in the interface\nbetweeninternalmemoryandexternalmemory).\nThefirstdesign choice iscalled virtualmemory. Thisconcept consists ofpro-\nvidinganaddressspaceaslargeasthecapacityofthesecondary-levelmemory,and\noftransferringdatalocatedinthesecondarylevelintotheprimarylevel,whenthey\nare addressed. Virtual memory does not limit the programmer to the constraint of\nthe internal memory size. The concept of bringing data into primary memory is\ncalled caching, anditismotivated bytemporal locality. Bybringing datainto pri-\nmary memory, we are hoping that it will be accessed again soon, and we will be\nabletorespondquicklytoalltherequestsforthisdatathatcomeinthenearfuture.\nThe second design choice is motivated by spatial locality. Specifically, if data\nstored at a secondary-level memory location \u2113 is accessed, then we bring into\nprimary-level memory a large block of contiguous locations that include the lo-\ncation\u2113. (SeeFigure15.5.) Thisconcept isknownasblocking, anditismotivated\nbytheexpectationthatothersecondary-level memorylocationscloseto\u2113willsoon\nbe accessed. In the interface between cache memory and internal memory, such\nblocks are often called cache lines, and in the interface between internal memory\nandexternalmemory,suchblocksareoftencalledpages.\nwww.it-ebooks.info\n698 Chapter15. MemoryManagementandB-Trees\nA block on disk\nA block in the external memory address space\n0 1 2 3 ... 1024 ... 2048 ...\nFigure15.5: Blocksinexternalmemory.\nWhen implemented with caching and blocking, virtual memory often allows\nus to perceive secondary-level memory as being faster than it really is. There is\nstill a problem, however. Primary-level memory is much smaller than secondary-\nlevel memory. Moreover, because memory systems use blocking, any program\nof substance will likely reach a point where it requests data from secondary-level\nmemory, but the primary memory is already full of blocks. In order to fulfill the\nrequestandmaintainouruseofcachingandblocking,wemustremovesomeblock\nfrom primary memory to make room for a new block from secondary memory in\nthis case. Deciding which block to evict brings up a number of interesting data\nstructure andalgorithm designissues.\nCaching in Web Browsers\nFor motivation, we will consider a related problem that arises when revisiting in-\nformation presented in Web pages. To exploit temporal locality of reference, it is\noftenadvantageoustostorecopiesofWebpagesinacachememory,sothesepages\ncanbequickly retrievedwhenrequested again. Thiseffectively createsatwo-level\nmemoryhierarchy, withthecacheservingasthesmaller,quickerinternalmemory,\nandthenetworkbeingtheexternalmemory. Inparticular, supposewehaveacache\nmemorythathasm\u201cslots\u201dthatcancontainWebpages. WeassumethataWebpage\ncanbeplacedinanyslotofthecache. Thisisknownasafullyassociative cache.\nAsabrowser executes, itrequests different Webpages. Eachtimethebrowser\nrequests such a Web page p, the browser determines (using a quick test) if p is\nunchanged and currently contained in the cache. If p is contained in the cache,\nthen the browser satisfies the request using the cached copy. If p is not in the\ncache, however, the page for p is requested over the Internet and transferred into\nthe cache. If one of the m slots in the cache is available, then the browser assigns\np to one of the empty slots. But if all the m cells of the cache are occupied, then\nthe computer must determine which previously viewed Web page to evict before\nbringingin ptotakeitsplace. Thereare,ofcourse,manydifferentpoliciesthatcan\nbeusedtodetermine thepagetoevict.\nwww.it-ebooks.info\n15.2. MemoryHierarchiesandCaching 699\nPage Replacement Algorithms\nSome of the better-known page replacement policies include the following (see\nFigure15.6):\nFirst-in, first-out (FIFO): Evict the page that has been in the cache the\n\u2022\nlongest,thatis,thepagethatwastransferredtothecachefurthestinthepast.\nLeastrecentlyused(LRU):Evictthepagewhoselastrequestoccurred fur-\n\u2022\nthestinthepast.\nInaddition, wecanconsiderasimpleandpurelyrandomstrategy:\nRandom: Chooseapageatrandom toevictfromthecache.\n\u2022\nFigure15.6: TheRandom,FIFO,andLRUpagereplacement policies.\nThe Random strategy is one of the easiest policies to implement, for it only\nrequires a random or pseudorandom number generator. The overhead involved in\nimplementing this policy is an O(1) additional amount of work per page replace-\nment. Moreover,thereisnoadditionaloverheadforeachpagerequest,otherthanto\ndetermine whetherapagerequest isinthecacheornot. Still,thispolicymakesno\nattempttotakeadvantage ofanytemporallocality exhibitedbyauser\u2019sbrowsing.\nwww.it-ebooks.info\n700 Chapter15. MemoryManagementandB-Trees\nThe FIFO strategy is quite simple to implement, as it only requires a queue\nQ to store references to the pages in the cache. Pages are enqueued in Q when\nthey are referenced by a browser, and then are brought into the cache. When a\npageneeds tobeevicted, thecomputer simplyperforms adequeue operation onQ\nto determine which page to evict. Thus, this policy also requires O(1) additional\nwork per page replacement. Also, the FIFO policy incurs no additional overhead\nforpagerequests. Moreover,ittriestotakesomeadvantage oftemporallocality.\nTheLRUstrategygoesastepfurtherthantheFIFOstrategy,fortheLRUstrat-\negyexplicitly takes advantage oftemporal locality asmuchaspossible, byalways\nevicting the page that wasleast-recently used. From apolicy point of view, this is\nan excellent approach, but it iscostly from an implementation point ofview. That\nis, its way of optimizing temporal and spatial locality is fairly costly. Implement-\ningtheLRUstrategyrequirestheuseofanadaptablepriorityqueueQthatsupports\nupdatingthepriorityofexistingpages. IfQisimplementedwithasortedsequence\nbased on a linked list, then the overhead for each page request and page replace-\nment is O(1). When we insert a page in Q or update its key, the page is assigned\nthe highest key in Q and is placed at the end of the list, which can also be done\nin O(1) time. Even though the LRU strategy has constant-time overhead, using\ntheimplementation above, theconstant factors involved, intermsoftheadditional\ntime overhead and the extra space for the priority queue Q, make this policy less\nattractivefromapractical pointofview.\nSince these different page replacement policies have different trade-offs be-\ntween implementation difficulty and the degree to which they seem to take advan-\ntage of localities, it is natural for us to ask for some kind of comparative analysis\nofthesemethodstoseewhichone,ifany,isthebest.\nFrom a worst-case point of view, the FIFO and LRU strategies have fairly\nunattractive competitive behavior. For example, suppose we have a cache con-\ntaining m pages, and consider the FIFO and LRU methods for performing page\nreplacement for a program that has a loop that repeatedly requests m+1 pages in\nacyclicorder. BoththeFIFOandLRUpolicies perform badlyonsuchasequence\nofpage requests, because they perform apage replacement onevery page request.\nThus, from a worst-case point of view, these policies are almost the worst we can\nimagine\u2014they requireapagereplacement oneverypagerequest.\nThis worst-case analysis is a little too pessimistic, however, for it focuses on\neach protocol\u2019s behavior for one bad sequence of page requests. An ideal analy-\nsis would be to compare these methods over all possible page-request sequences.\nOf course, this is impossible to do exhaustively, but there have been a great num-\nberofexperimental simulations doneonpage-request sequences derived fromreal\nprograms. Based on these experimental comparisons, the LRU strategy has been\nshown tobe usually superior to the FIFOstrategy, whichis usually better than the\nRandomstrategy.\nwww.it-ebooks.info\n15.3. ExternalSearchingandB-Trees 701\n15.3 External Searching and B-Trees\nConsider theproblem ofmaintaining alarge collection ofitemsthatdoesnotfitin\nmainmemory,suchasatypicaldatabase. Inthiscontext,werefertothesecondary-\nmemoryblocksasdiskblocks. Likewise,werefertothetransferofablockbetween\nsecondary memory and primary memory as a disk transfer. Recalling the great\ntime difference that exists between main memory accesses and disk accesses, the\nmain goal of maintaining such a collection in external memory is to minimize the\nnumber of disk transfers needed to perform a query or update. We refer to this\ncountastheI/Ocomplexity ofthealgorithm involved.\nSome Inefficient External-Memory Representations\nAtypicaloperationwewouldliketosupportisthesearchforakeyinamap. Ifwe\nwere to store n items unordered in a doubly linked list, searching for a particular\nkey within the list requires n transfers in the worst case, since each link hop we\nperform onthelinkedlistmightaccessadifferentblockofmemory.\nWe can reduce the number of block transfers by storing the sequence in an\narray. A sequential search of an array can be performed using only O(n/B) block\ntransfers because of spatial locality of reference, where B denotes the number of\nelements that fit into a block. This is because the block transfer when accessing\nthe firstelement of thearray actually retrieves the firstBelements, and so onwith\neachsuccessiveblock. ItisworthnotingthattheboundofO(n/B)transfersisonly\nachieved when using an array of primitives in Java. For an array of objects, the\narray stores the sequence of references; the actual objects that are referenced are\nnot necessarily stored near each other in memory, and so there may be n distinct\nblocktransfersintheworstcase.\nIfasequenceisstoredinsortedorderwithinanarray,abinarysearchperforms\nO(log n) transfers, which is a nice improvement. But we do not get significant\n2\nbenefit from block transfers because each query during abinary search islikely in\na different block of the sequence. As usual, update operations are expensive for a\nsortedarray.\nSincethesesimpleimplementations areI/Oinefficient, weshould consider the\nlogarithmic-time internal-memory strategies thatusebalancedbinarytrees(forex-\nample, AVL trees or red-black trees) or other search structures with logarithmic\naverage-case query and update times (for example, skip lists orsplay trees). Typi-\ncally,eachnodeaccessedforaqueryorupdateinoneofthesestructures willbein\na different block. Thus, these methods all require O(log n) transfers in the worst\n2\ncasetoperformaqueryorupdateoperation. Butwecandobetter! Wecanperform\nmapqueries andupdatesusingonlyO(log n)=O(logn/logB)transfers.\nB\nwww.it-ebooks.info\n702 Chapter15. MemoryManagementandB-Trees\n15.3.1 (a,b) Trees\nToreducethenumberofexternal-memory accesses whensearching, wecanrepre-\nsent our map using a multiway search tree (Section 11.5.1). This approach gives\nrisetoageneralization ofthe(2,4)treedatastructure knownasthe(a,b)tree.\nAn(a,b)treeisamultiwaysearch treesuchthateach nodehasbetween aand\nbchildrenandstoresbetweena 1andb 1entries. Thealgorithmsforsearching,\n\u2212 \u2212\ninserting, andremovingentriesinan(a,b)treearestraightforward generalizations\nof the corresponding ones for (2,4) trees. The advantage of generalizing (2,4)\ntrees to (a,b) trees is that a parameterized class of trees provides a flexible search\nstructure, where the size of the nodes and the running time of the various map\noperations depends on the parameters a and b. By setting the parameters a and b\nappropriately withrespecttothesizeofdiskblocks, wecanderiveadatastructure\nthatachievesgoodexternal-memory performance.\nDefinition of an (a,b) Tree\nAn(a,b) tree, where parameters aand bareintegers such that2 a (b+1)/2,\n\u2264 \u2264\nisamultiwaysearchtreeT withthefollowingadditional restrictions:\nSizeProperty: Each internal node has atleast achildren, unless itis theroot, and\nhasatmostbchildren.\nDepthProperty: Alltheexternalnodeshavethesamedepth.\nProposition 15.1: Theheightofan(a,b)treestoringnentriesis\u2126(logn/logb)\nandO(logn/loga).\nJustification: LetT bean(a,b)treestoring nentries, andlethbetheheightof\nT. Wejustifytheproposition byestablishing thefollowingboundsonh:\n1 1 n+1\nlog(n+1) h log +1.\nlogb \u2264 \u2264 loga 2\nBy the size and depth properties, the number n\u2032\u2032 of external nodes of T is at least\n2ah\u22121 andatmostbh. ByProposition 11.6,n\u2032\u2032=n+1. Thus,\n2ah\u22121 n+1 bh.\n\u2264 \u2264\nTakingthelogarithm inbase2ofeachterm,weget\n(h 1)loga+1 log(n+1) hlogb.\n\u2212 \u2264 \u2264\nAnalgebraic manipulation oftheseinequalities completes thejustification.\nwww.it-ebooks.info\n15.3. ExternalSearchingandB-Trees 703\nSearch and Update Operations\nWe recall that in a multiway search tree T, each node w of T holds a secondary\nstructure M(w), which is itself a map (Section 11.5.1). If T is an (a,b) tree, then\nM(w) stores at most b entries. Let f(b) denote the time for performing a search\nin a map, M(w). The search algorithm in an (a,b) tree is exactly like the one for\nmultiwaysearchtreesgiveninSection11.5.1. Hence,searching inan(a,b)treeT\nwithnentries takes O(\nf(b)logn)time.\nNotethatifbisconsidered aconstant (and\nloga\nthusaisalso),thenthesearchtimeisO(logn).\nThe main application of (a,b) trees is for maps stored in external memory.\nNamely, to minimize disk accesses, we select the parameters a and b so that each\ntreenodeoccupies asinglediskblock(sothat f(b)=1ifwewishtosimplycount\nblock transfers). Providing the right a and b values in this context gives rise to\na data structure known as the B-tree, which we will describe shortly. Before we\ndescribe this structure, however, let us discuss how insertions and removals are\nhandled in(a,b)trees.\nThe insertion algorithm for an (a,b) tree is similar to that for a (2,4) tree.\nAn overflow occurs when an entry is inserted into a b-node v, which becomes an\nillegal (b+1)-node. (Recall that a node in a multiway tree is a d-node if it has d\nchildren.) Toremedyanoverflow,wesplitnodewbymovingthemedianentryofw\nintotheparentofwandreplacingwwitha (b+1)/2 -node w\u2032anda (b+1)/2 -\n\u2308 \u2309 \u230a \u230b\nnode w\u2032\u2032. We can now see the reason for requiring a (b+1)/2 in the definition\n\u2264\nof an (a,b) tree. Note that as a consequence of the split, we need to build the\nsecondary structures M(w\u2032)andM(w\u2032\u2032).\nRemoving an entry from an (a,b) tree is similar to what was done for (2,4)\ntrees. Anunderflowoccurswhenakeyisremovedfromana-nodew,distinctfrom\ntheroot,whichcauseswtobecomeanillegal(a 1)-node. Toremedyanunderflow,\n\u2212\nwe perform a transfer with a sibling of w that is not an a-node or we perform a\nfusion of w with a sibling that is an a-node. The new node w\u2032 resulting from the\nfusionisa(2a 1)-node, whichisanotherreasonforrequiring a (b+1)/2.\n\u2212 \u2264\nTable15.1showstheperformance ofamaprealizedwithan(a,b)tree.\nMethod RunningTime\nget O f(b) logn\nloga\nput O(cid:16)g(b) logn(cid:17)\nloga\nremove O(cid:16)g(b) logn(cid:17)\nloga\nTable15.1:Timeboundsforann-entryma(cid:16)prealized(cid:17)byan(a,b)treeT. Weassume\nthesecondarystructureofthenodesofT supportsearchin f(b)time,andsplitand\nfusion operations in g(b) time, for some functions f(b) and g(b), which can be\nmadetobeO(1)whenweareonlycounting disktransfers.\nwww.it-ebooks.info\n704 Chapter15. MemoryManagementandB-Trees\n15.3.2 B-Trees\nA version of the (a,b) tree data structure, which is the best-known method for\nmaintainingamapinexternalmemory,iscalledthe\u201cB-tree.\u201d (SeeFigure15.7.) A\nB-tree of order d is an (a,b) tree with a= d/2 and b=d. Since we discussed\n\u2308 \u2309\nthe standard map query and update methods for (a,b) trees above, we restrict our\ndiscussion heretotheI/OcomplexityofB-trees.\n42 65\n22 37 46 58 72 80 93\n11 12 24 29 38 40 41 43 45 48 50 51 53 56 59 63 66 70 74 75 83 85 86 95 98\nFigure15.7: AB-treeoforder6.\nAnimportantproperty ofB-treesisthatwecanchoosed sothatthed children\nreferences and the d 1 keys stored at a node can fit compactly into a single disk\n\u2212\nblock, implying thatd isproportional toB. Thischoice allowsustoassumethat a\nandbarealsoproportional toBintheanalysis ofthesearchandupdateoperations\non(a,b)trees. Thus, f(b)andg(b) arebothO(1), foreach timeweaccess anode\nto perform a search or an update operation, we need only perform a single disk\ntransfer.\nAs we have already observed above, each search or update requires that we\nexamine at most O(1) nodes for each level of the tree. Therefore, any map search\norupdateoperationonaB-treerequiresonlyO(log n),thatis,O(logn/logB),\n\u2308d/2\u2309\ndisktransfers. Forexample,aninsertoperation proceeds downtheB-treetolocate\nthenodeinwhichtoinsertthenewentry. Ifthenodewouldoverflow(tohaved+1\nchildren) because of this addition, then this node is split into two nodes that have\n(d+1)/2 and (d+1)/2 children, respectively. This process is then repeated\n\u230a \u230b \u2308 \u2309\natthenextlevelup,andwillcontinue foratmostO(log n)levels.\nB\nLikewise,ifaremoveoperationresultsinanodeunderflow(tohave d/2 1\n\u2308 \u2309\u2212\nchildren), then we move references from a sibling node with at least d/2 +1\n\u2308 \u2309\nchildren or weperform afusion operation ofthis node withits sibling (and repeat\nthis computation at the parent). Aswith the insert operation, this will continue up\nthe B-tree for at most O(log n) levels. The requirement that each internal node\nB\nhaveatleast d/2 childrenimpliesthateachdiskblockusedtosupportaB-treeis\n\u2308 \u2309\natleasthalffull. Thus,wehavethefollowing:\nProposition 15.2: AB-treewithnentrieshasI/OcomplexityO(log n)forsearch\nB\norupdateoperation,andusesO(n/B)blocks,whereBisthesizeofablock.\nwww.it-ebooks.info\n15.4. External-MemorySorting 705\n15.4 External-Memory Sorting\nInadditiontodatastructures,suchasmaps,thatneedtobeimplementedinexternal\nmemory,therearemanyalgorithmsthatmustalsooperateoninputsetsthataretoo\nlarge to fit entirely into internal memory. In this case, the objective is to solve the\nalgorithmic problem using as few block transfers as possible. The most classic\ndomainforsuchexternal-memory algorithms isthesortingproblem.\nMultiway Merge-Sort\nAnefficient wayto sort aset S of nobjects inexternal memoryamounts to asim-\npleexternal-memoryvariationonthefamiliarmerge-sortalgorithm. Themainidea\nbehind this variation is to merge many recursively sorted lists at a time, thereby\nreducing the number of levels of recursion. Specifically, a high-level description\nof this multiway merge-sort method is to divide S into d subsets S , S , ..., S of\n1 2 d\nroughly equal size, recursively sort each subset S,and then simultaneously merge\ni\nalld sortedlistsintoasortedrepresentation ofS. Ifwecanperformthemergepro-\ncess using only O(n/B)disktransfers, then, forlarge enough values ofn, thetotal\nnumber of transfers performed by this algorithm satisfies the following recurrence\nequation:\nt(n)=d t(n/d)+cn/B,\n\u00b7\nfor some constant c 1. We can stop the recursion when n B, since we can\n\u2265 \u2264\nperform a single block transfer at this point, getting all of the objects into internal\nmemory, and then sort the set with an efficient internal-memory algorithm. Thus,\nthestopping criterionfort(n)is\nt(n)=1 ifn/B 1.\n\u2264\nThisimpliesaclosed-form solution thatt(n)isO((n/B)log (n/B)),whichis\nd\nO((n/B)log(n/B)/logd).\nThus,ifwecanchoosedtobe\u0398(M/B),whereMisthesizeoftheinternalmemory,\nthen the worst-case number of block transfers performed by this multiway merge-\nsortalgorithm willbequitelow. Forreasons giveninthenextsection, wechoose\nd=(M/B) 1.\n\u2212\nTheonlyaspectofthisalgorithm lefttospecify, then,ishowtoperformthed-way\nmergeusingonlyO(n/B)blocktransfers.\nwww.it-ebooks.info\n706 Chapter15. MemoryManagementandB-Trees\n15.4.1 Multiway Merging\nIn a standard merge-sort (Section 12.1), the merge process combines two sorted\nsequences into onebyrepeatedly taking thesmalleroftheitemsatthefrontofthe\ntwo respective lists. In ad-way merge, werepeatedly find the smallest among the\nitemsatthefrontofthed sequences andplaceitasthenextelementofthemerged\nsequence. Wecontinue untilallelementsareincluded.\nIn the context of an external-memory sorting algorithm, if main memory has\nsize M and each block has size B, we can store up to M/B blocks within main\nmemory at any given time. We specifically choose d =(M/B) 1 so that we can\n\u2212\nafford to keep one block from each input sequence in main memory at any given\ntime, and to have one additional block touse as abuffer for the merged sequence.\n(SeeFigure15.8.)\n12 24 26 34 41 49 50 57 60\n25 27 40 43 44 53 56\n7 8 10 11 Q 30 39 42 45 54 65\n13 16 19 33 37 46 52 58 66 75\n17 18 29 35 48 51 59 72 78 88\nFigure15.8: Ad-waymerge withd =5and B=4. Blocks that currently reside in\nmainmemoryareshaded.\nWe maintain the smallest unprocessed element from each input sequence in\nmainmemory,requestingthenextblockfromasequencewhentheprecedingblock\nhas been exhausted. Similarly, we use one block of internal memory to buffer the\nmerged sequence, flushing that block to external memory when full. In this way,\nthe total number of transfers performed during a single d-way merge is O(n/B),\nsincewescaneachblockoflistS once,andwewriteouteachblockofthemerged\ni\nlist S\u2032 once. In terms of computation time, choosing the smallest of d values can\ntrivially be performed using O(d) operations. If we are willing to devote O(d)\ninternalmemory,wecanmaintainapriorityqueueidentifyingthesmallestelement\nfrom each sequence, thereby performing each step of the merge in O(logd) time\nbyremovingtheminimumelementandreplacingitwiththenextelementfromthe\nsamesequence. Hence,theinternal timeforthed-waymergeisO(nlogd).\nProposition 15.3: Givenanarray-basedsequenceS ofn elementsstoredinex-\nternalmemory,wecansortS withO((n/B)log(n/B)/log(M/B)) blocktransfers\nandO(nlogn)internalcomputations,whereM isthesizeoftheinternalmemory\nandBisthesizeofablock.\nwww.it-ebooks.info\n15.5. Exercises 707\n15.5 Exercises\nReinforcement\nR-15.1 Julia just bought a new computer that uses 64-bit integers to address memory\ncells. ArguewhyJuliawillneverinherlifebeabletoupgradethemainmemory\nofhercomputersothatitisthemaximum-sizepossible,assumingthatyouhave\ntohavedistinctatomstorepresentdifferentbits.\nR-15.2 Consideraninitiallyemptymemorycacheconsistingoffourpages. Howmany\npage misses does the LRU algorithm incur on the following page request se-\nquence:(2,3,4,1,2,5,1,3,5,4,1,2,3)?\nR-15.3 Consideraninitiallyemptymemorycacheconsistingoffourpages. Howmany\npage misses does the FIFO algorithm incur on the following page request se-\nquence:(2,3,4,1,2,5,1,3,5,4,1,2,3)?\nR-15.4 Consider an initially empty memory cache consisting of four pages. What is\nthe maximum number of page misses that the random algorithm incurs on the\nfollowing page request sequence: (2,3,4,1,2,5,1,3,5,4,1,2,3)? Show all of\ntherandomchoicesthealgorithmmadeinthiscase.\nR-15.5 Describe,indetail,algorithmsforaddinganitemto,ordeletinganitemfrom,an\n(a,b)tree.\nR-15.6 SupposeT isamultiwaytreeinwhicheachinternalnodehasatleastfiveandat\nmosteightchildren.ForwhatvaluesofaandbisT avalid(a,b)tree?\nR-15.7 ForwhatvaluesofdisthetreeT ofthepreviousexerciseanorder-dB-tree?\nR-15.8 Drawthe resultofinserting, intoan initially emptyorder-7B-tree, entrieswith\nkeys(4,40,23,50,11,34,62,78,66,22,90,59,25,72,64,77,39,12),inthisorder.\nCreativity\nC-15.9 Describe anefficientexternal-memoryalgorithmforremovingall the duplicate\nentriesinanarraylistofsizen.\nC-15.10 Describeanexternal-memorydatastructuretoimplementthestackADTsothat\nthe total number of disk transfers needed to process a sequence of k push and\npopoperationsisO(k/B).\nC-15.11 Describeanexternal-memorydatastructuretoimplementthequeueADTsothat\nthetotalnumberofdisktransfersneededtoprocessasequenceofkenqueueand\ndequeueoperationsisO(k/B).\nC-15.12 Describe an external-memoryversion of the PositionalList ADT (Section 7.3),\nwithblocksizeB, suchthataniterationofa listoflengthnis completedusing\nO(n/B) transfers in the worst case, and all other methods of the ADT require\nonlyO(1)transfers.\nwww.it-ebooks.info\n708 Chapter15. MemoryManagementandB-Trees\nC-15.13 Change the rulesthatdefine red-blacktrees so that each red-blacktreeT hasa\ncorresponding(4,8)tree,andviceversa.\nC-15.14 Describe a modifiedversionof the B-tree insertionalgorithmso that eachtime\nwecreateanoverflowbecauseofasplitofanodew,weredistributekeysamong\nall of w\u2019s siblings, so thateach sibling holdsroughlythe same numberof keys\n(possiblycascadingthesplituptotheparentofw). Whatistheminimumfraction\nofeachblockthatwillalwaysbefilledusingthisscheme?\nC-15.15 Anotherpossibleexternal-memorymapimplementationistouseaskiplist,butto\ncollectconsecutivegroupsofO(B)nodes,inindividualblocks,onanylevelinthe\nskiplist. Inparticular,wedefineanorder-dB-skiplisttobesucharepresentation\nofaskipliststructure,whereeachblockcontainsatleast d/2 listnodesandat\n\u2308 \u2309\nmostd listnodes. Letusalsochoosed inthiscasetobethemaximumnumber\noflistnodesfromalevelofaskiplistthatcanfitintooneblock. Describehow\nweshouldmodifytheskip-listinsertionandremovalalgorithmsforaB-skiplist\nsothattheexpectedheightofthestructureisO(logn/logB).\nC-15.16 DescribehowtouseaB-treetoimplementthePartitionADT(Section14.7.3)so\nthattheunionandfindoperationseachuseatmostO(logn/logB)disktransfers.\nC-15.17 Suppose we are given a sequence S of n elements with integer keys such that\nsomeelementsinSarecolored\u201cblue\u201dandsomeelementsinSarecolored\u201cred.\u201d\nInaddition,saythataredelementepairswithablueelement f iftheyhavethe\nsamekeyvalue. Describeanefficientexternal-memoryalgorithmforfindingall\nthered-bluepairsinS.Howmanydisktransfersdoesyouralgorithmperform?\nC-15.18 Considerthepagecachingproblemwherethememorycachecanholdmpages,\nandwearegivenasequencePofnrequeststakenfromapoolofm+1possible\npages. Describe the optimal strategy for the offline algorithm and show that it\ncausesatmostm+n/mpagemissesintotal,startingfromanemptycache.\nC-15.19 Describeanefficientexternal-memoryalgorithmthatdetermineswhetheranar-\nrayofnintegerscontainsavalueoccurringmorethann/2times.\nC-15.20 Consider the page caching strategy based on the least frequently used (LFU)\nrule,wherethepageinthecachethathasbeenaccessedtheleastoftenistheone\nthat is evicted when a new page is requested. If there are ties, LFU evicts the\nleastfrequentlyusedpagethathasbeeninthecachethelongest.Showthatthere\nisasequencePofnrequeststhatcausesLFUtomiss\u2126(n)timesforacacheof\nmpages,whereastheoptimalalgorithmwillmissonlyO(m)times.\nC-15.21 Suppose that instead of having the node-searchfunction f(d)=1 in an order-\nd B-tree T, we have f(d)=logd. What does the asymptotic running time of\nperformingasearchinT nowbecome?\nProjects\nP-15.22 WriteaJavaclassthatsimulatesthebest-fit,worst-fit,first-fit,andnext-fitalgo-\nrithmsformemorymanagement.Determineexperimentallywhichmethodisthe\nbestundervarioussequencesofmemoryrequests.\nwww.it-ebooks.info\nChapterNotes 709\nP-15.23 Write a Java class that implements all the methods of the sorted map ADT by\nmeansofan(a,b)tree,whereaandbareintegerconstantspassedasparameters\ntoaconstructor.\nP-15.24 ImplementtheB-tree datastructure,assuminga blocksize of1024andinteger\nkeys. Testthenumberof\u201cdisktransfers\u201dneededtoprocessa sequenceofmap\noperations.\nChapter Notes\nThe reader interested in the study of the architecture of hierarchical memory systems is\nreferred to the book chapter by Burger et al. [20] or the book by Hennessy and Patter-\nson[44]. Themark-sweepgarbagecollectionmethodwedescribeisoneofmanydifferent\nalgorithmsforperforminggarbagecollection. We encouragethe readerinterestedin fur-\ntherstudyofgarbagecollectionto examinethebookbyJonesandLins[52]. Knuth[61]\nhas very nice discussions about external-memory sorting and searching. The handbook\nbyGonnetandBaeza-Yates[38]comparestheperformanceofanumberofdifferentsort-\ningalgorithms,manyofwhichareexternal-memoryalgorithms. B-treeswereinventedby\nBayerandMcCreight[11]andComer[24]providesaveryniceoverviewofthisdatastruc-\nture.ThebooksbyMehlhorn[71]andSamet[81]alsohavenicediscussionsaboutB-trees\nandtheirvariants. AggarwalandVitter[3]studytheI/Ocomplexityofsortingandrelated\nproblems, establishing upperand lower bounds. Goodrichet al. [40] study the I/O com-\nplexityofseveralcomputationalgeometryproblems.Thereaderinterestedinfurtherstudy\nofI/O-efficientalgorithmsisencouragedtoexaminethesurveypaperofVitter[91].\nwww.it-ebooks.info\nBibliography\n[1] H. Abelson, G. J. Sussman, and J. Sussman, Structure and Interpretation of Computer Pro-\ngrams. Cambridge,MA:MITPress,2nded.,1996.\n[2] G.M.Adel\u2019son-Vel\u2019skiiandY.M.Landis,\u201cAnalgorithmfortheorganizationofinformation,\u201d\nDokladyAkademiiNaukSSSR,vol.146,pp.263\u2013266,1962.EnglishtranslationinSovietMath.\nDoklady,vol.3,pp.1259\u20131262.\n[3] A.AggarwalandJ.S.Vitter,\u201cTheinput/output complexityofsortingandrelatedproblems,\u201d\nCommun.ACM,vol.31,pp.1116\u20131127,1988.\n[4] A.V.Aho,\u201cAlgorithmsforfindingpatternsinstrings,\u201dinHandbookofTheoreticalComputer\nScience(J.vanLeeuwen,ed.),vol.A.AlgorithmsandComplexity,pp.255\u2013300,Amsterdam:\nElsevier,1990.\n[5] A.V.Aho,J.E.Hopcroft,andJ.D.Ullman,TheDesignandAnalysisofComputerAlgorithms.\nReading,MA:Addison-Wesley,1974.\n[6] A.V.Aho,J.E.Hopcroft,andJ.D.Ullman,DataStructuresandAlgorithms. Reading,MA:\nAddison-Wesley,1983.\n[7] R.K.Ahuja,T.L.Magnanti,andJ.B.Orlin,NetworkFlows: Theory,Algorithms,andAppli-\ncations. EnglewoodCliffs,NJ:PrenticeHall,1993.\n[8] K. Arnold, J. Gosling, and D. Holmes, The Java Programming Language. The Java Series,\nUpperSaddleRiver,NJ:PrenticeHall,4thed.,2006.\n[9] O.Baru\u02davka, \u201cOjistemproblemuminimalnim,\u201dPracaMoravske PrirodovedeckeSpolecnosti,\nvol.3,pp.37\u201358,1926. (inCzech).\n[10] R. Bayer, \u201cSymmetric binary B-trees: Data structure and maintenance,\u201d Acta Informatica,\nvol.1,no.4,pp.290\u2013306,1972.\n[11] R.BayerandMcCreight,\u201cOrganizationoflargeorderedindexes,\u201dActaInform.,vol.1,pp.173\u2013\n189,1972.\n[12] R.E.Bellman,DynamicProgramming. Princeton,NJ:PrincetonUniversityPress,1957.\n[13] J.L.Bentley,\u201cProgrammingpearls: Writingcorrectprograms,\u201dCommunicationsoftheACM,\nvol.26,pp.1040\u20131045,1983.\n[14] J. L. Bentley, \u201cProgramming pearls: Thanks, heaps,\u201d Communications of the ACM, vol. 28,\npp.245\u2013250,1985.\n[15] J.L.BentleyandM.D.McIlroy,\u201cEngineeringasortfunction,\u201dSoftware\u2014PracticeandExpe-\nrience,vol.23,no.11,pp.1249\u20131265,1993.\n[16] G.Booch,Object-OrientedAnalysisandDesignwithApplications. RedwoodCity,CA:Ben-\njamin/Cummings,1994.\n[17] R.S.BoyerandJ.S.Moore,\u201cAfaststringsearchingalgorithm,\u201dCommunicationsoftheACM,\nvol.20,no.10,pp.762\u2013772,1977.\n[18] G.Brassard,\u201cCrusadeforabetternotation,\u201dSIGACTNews,vol.17,no.1,pp.60\u201364,1985.\n[19] T.Budd, AnIntroductiontoObject-OrientedProgramming. Reading, MA:Addison-Wesley,\n1991.\n[20] D.Burger,J.R.Goodman,andG.S.Sohi,\u201cMemorysystems,\u201dinTheComputerScienceand\nEngineeringHandbook(A.B.Tucker,Jr.,ed.),ch.18,pp.447\u2013461,CRCPress,1997.\nwww.it-ebooks.info\nBibliography 711\n[21] S.Carlsson,\u201cAveragecaseresultsonheapsort,\u201dBIT,vol.27,pp.2\u201317,1987.\n[22]\nK.L.Clarkson,\u201cLinearprogramminginO(n3d2\n)time,\u201dInform.Process.Lett.,vol.22,pp.21\u2013\n24,1986.\n[23] R. Cole, \u201cTight bounds on the complexity of the Boyer-Moore pattern matching algorithm,\u201d\nSIAMJ.Comput.,vol.23,no.5,pp.1075\u20131091,1994.\n[24] D.Comer,\u201cTheubiquitousB-tree,\u201dACMComput.Surv.,vol.11,pp.121\u2013137,1979.\n[25] T.H.Cormen,C.E.Leiserson,R.L.Rivest,andC.Stein,IntroductiontoAlgorithms. Cam-\nbridge,MA:MITPress,3rded.,2009.\n[26] M. Crochemore and T. Lecroq, \u201cPattern matching and text compression algorithms,\u201d in The\nComputerScienceandEngineeringHandbook(A.B.Tucker,Jr.,ed.),ch.8,pp.162\u2013202,CRC\nPress,1997.\n[27] S.CrosbyandD.Wallach,\u201cDenialofserviceviaalgorithmiccomplexityattacks,\u201dinProc.12th\nUsenixSecuritySymp.,pp.29\u201344,2003.\n[28] S.A.Demurjian,Sr.,\u201cSoftwaredesign,\u201dinTheComputerScienceandEngineeringHandbook\n(A.B.Tucker,Jr.,ed.),ch.108,pp.2323\u20132351,CRCPress,1997.\n[29] G.DiBattista,P.Eades,R.Tamassia,andI.G.Tollis,GraphDrawing. UpperSaddleRiver,\nNJ:PrenticeHall,1999.\n[30] E.W.Dijkstra,\u201cAnoteontwoproblemsinconnexionwithgraphs,\u201dNumerischeMathematik,\nvol.1,pp.269\u2013271,1959.\n[31] E.W.Dijkstra,\u201cRecursiveprogramming,\u201dNumerischeMathematik,vol.2,no.1,pp.312\u2013318,\n1960.\n[32] J.R.Driscoll,H.N.Gabow,R.Shrairaman,andR.E.Tarjan,\u201cRelaxedheaps:Analternativeto\nFibonacciheapswithapplicationstoparallelcomputation,\u201dCommun.ACM,vol.31,pp.1343\u2013\n1354,1988.\n[33] D.Flanagan,JavainaNutshell. O\u2019Reilly,5thed.,2005.\n[34] R.W.Floyd,\u201cAlgorithm97:Shortestpath,\u201dCommunicationsoftheACM,vol.5,no.6,p.345,\n1962.\n[35] R.W.Floyd,\u201cAlgorithm245: Treesort3,\u201dCommunicationsoftheACM,vol.7,no.12,p.701,\n1964.\n[36] M.L.Fredmanand R.E.Tarjan, \u201cFibonacci heaps andtheirusesinimprovednetwork opti-\nmizationalgorithms,\u201dJ.ACM,vol.34,pp.596\u2013615,1987.\n[37] E. Gamma, R. Helm, R. Johnson, and J. Vlissides, Design Patterns: Elements of Reusable\nObject-OrientedSoftware. Reading,MA:Addison-Wesley,1995.\n[38] G. H. Gonnet and R. Baeza-Yates, Handbook of Algorithms and Data Structures. Addison-\nWesley,1991.\n[39] G.H.GonnetandJ.I.Munro,\u201cHeapsonheaps,\u201dSIAMJ.Comput.,vol.15,no.4,pp.964\u2013971,\n1986.\n[40] M.T.Goodrich,J.-J.Tsay,D.E.Vengroff,andJ.S.Vitter,\u201cExternal-memorycomputational\ngeometry,\u201dinProc.34thAnnu.IEEESympos.Found.Comput.Sci.,pp.714\u2013723,1993.\n[41] R.L.GrahamandP.Hell,\u201cOnthehistoryoftheminimumspanningtreeproblem,\u201dAnnalsof\ntheHistoryofComputing,vol.7,no.1,pp.43\u201357,1985.\n[42] L.J.GuibasandR.Sedgewick, \u201cAdichromaticframeworkforbalancedtrees,\u201dinProc.19th\nAnnu. IEEE Sympos. Found. Comput. Sci., Lecture Notes Comput. Sci., pp. 8\u201321, Springer-\nVerlag,1978.\n[43] Y.Gurevich,\u201cWhatdoesO(n)mean?,\u201dSIGACTNews,vol.17,no.4,pp.61\u201363,1986.\n[44] J.HennessyandD.Patterson,ComputerArchitecture:AQuantitativeApproach.SanFrancisco:\nMorganKaufmann,2nded.,1996.\n[45] C.A.R.Hoare,\u201cQuicksort,\u201dTheComputerJournal,vol.5,pp.10\u201315,1962.\n[46] J.E.HopcroftandR.E.Tarjan,\u201cEfficientalgorithmsforgraphmanipulation,\u201dCommunications\noftheACM,vol.16,no.6,pp.372\u2013378,1973.\nwww.it-ebooks.info\n712 Bibliography\n[47] C. S.Horstmann and G. Cornell, Core Java, vol. I\u2013Fundamentals. Upper Saddle River, NJ:\nPrenticeHall,8thed.,2008.\n[48] C.S.HorstmannandG.Cornell,CoreJava,vol.II\u2013AdvancedFeatures. UpperSaddleRiver,\nNJ:PrenticeHall,8thed.,2008.\n[49] B.-C. Huang and M. Langston, \u201cPractical in-place merging,\u201d Communications of the ACM,\nvol.31,no.3,pp.348\u2013352,1988.\n[50] J.Ja\u00b4Ja\u00b4,AnIntroductiontoParallelAlgorithms. Reading,MA:Addison-Wesley,1992.\n[51] V. Jarn\u00b4\u0131k, \u201cO jistem problemu minimalnim,\u201d Praca Moravske Prirodovedecke Spolecnosti,\nvol.6,pp.57\u201363,1930. (inCzech).\n[52] R.JonesandR.Lins,GarbageCollection: AlgorithmsforAutomaticDynamicMemoryMan-\nagement. JohnWileyandSons,1996.\n[53] D.R.Karger,P.Klein,andR.E.Tarjan,\u201cArandomizedlinear-timealgorithmtofindminimum\nspanningtrees,\u201dJournaloftheACM,vol.42,pp.321\u2013328,1995.\n[54] R.M.KarpandM.O.Rabin,\u201cEfficientrandomizedpattern-matchingalgorithms,\u201dIBMJ.Res.\nDevelop.,vol.31,no.2,pp.249\u2013260,1987.\n[55] R.M.KarpandV.Ramachandran,\u201cParallelalgorithmsforsharedmemorymachines,\u201dinHand-\nbookofTheoreticalComputerScience(J.vanLeeuwen,ed.),pp.869\u2013941,Amsterdam: Else-\nvier/TheMITPress,1990.\n[56] P.Kirschenhofer andH.Prodinger, \u201cThepathlengthofrandomskiplists,\u201dActaInformatica,\nvol.31,pp.775\u2013792,1994.\n[57] J.KleinbergandE\u00b4.Tardos,AlgorithmDesign. Reading,MA:Addison-Wesley,2006.\n[58] A.KlinkandJ.Wa\u00a8lde,\u201cEfficientdenialofserviceattacksonwebapplicationplatforms.\u201d2011.\n[59] D.E.Knuth,\u201cBigomicronandbigomegaandbigtheta,\u201dinSIGACTNews,vol.8,pp.18\u201324,\n1976.\n[60] D.E.Knuth,FundamentalAlgorithms,vol.1ofTheArtofComputerProgramming. Reading,\nMA:Addison-Wesley,3rded.,1997.\n[61] D.E.Knuth, SortingandSearching, vol.3ofTheArtofComputerProgramming. Reading,\nMA:Addison-Wesley,2nded.,1998.\n[62] D. E. Knuth, J. H. Morris, Jr., and V. R. Pratt, \u201cFast pattern matching in strings,\u201d SIAM J.\nComput.,vol.6,no.1,pp.323\u2013350,1977.\n[63] J. B. Kruskal, Jr., \u201cOn the shortest spanning subtree of a graph and the traveling salesman\nproblem,\u201dProc.Amer.Math.Soc.,vol.7,pp.48\u201350,1956.\n[64] R.Lesuisse,\u201cSomelessonsdrawnfromthehistoryofthebinarysearchalgorithm,\u201dTheCom-\nputerJournal,vol.26,pp.154\u2013163,1983.\n[65] N.G.LevesonandC.S.Turner,\u201cAninvestigationoftheTherac-25accidents,\u201dIEEEComputer,\nvol.26,no.7,pp.18\u201341,1993.\n[66] A.Levitin,\u201cDoweteachtherightalgorithmdesigntechniques?,\u201din30thACMSIGCSESymp.\nonComputerScienceEducation,pp.179\u2013183,1999.\n[67] B.LiskovandJ.Guttag,AbstractionandSpecificationinProgramDevelopment. Cambridge,\nMA/NewYork:TheMITPress/McGraw-Hill,1986.\n[68] E.M. McCreight, \u201cA space-economical suffixtreeconstruction algorithm,\u201d Journal of Algo-\nrithms,vol.23,no.2,pp.262\u2013272,1976.\n[69] C. J. H. McDiarmid and B. A. Reed, \u201cBuilding heaps fast,\u201d Journal of Algorithms, vol. 10,\nno.3,pp.352\u2013365,1989.\n[70] N.Megiddo,\u201cLinearprogramminginlineartimewhenthedimensionisfixed,\u201dJ.ACM,vol.31,\npp.114\u2013127,1984.\n[71] K. Mehlhorn, Data Structures and Algorithms 1: Sorting and Searching, vol. 1 of EATCS\nMonographsonTheoreticalComputerScience. Heidelberg,Germany:Springer-Verlag,1984.\n[72] K. Mehlhorn, Data Structures and Algorithms 2: Graph Algorithms and NP-Completeness,\nvol. 2 of EATCS Monographs on Theoretical Computer Science. Heidelberg, Germany:\nSpringer-Verlag,1984.\nwww.it-ebooks.info\nBibliography 713\n[73] K. Mehlhorn and A. Tsakalidis, \u201cData structures,\u201d in Algorithms and Complexity (J. van\nLeeuwen, ed.), vol.A ofHandbook of Theoretical ComputerScience, pp. 303\u2013334, Amster-\ndam:Elsevier,1990.\n[74] D. R. Morrison, \u201cPATRICIA\u2014practical algorithm to retrieve information coded in alphanu-\nmeric,\u201dJournaloftheACM,vol.15,no.4,pp.514\u2013534,1968.\n[75] R.MotwaniandP.Raghavan,RandomizedAlgorithms. NewYork,NY:CambridgeUniversity\nPress,1995.\n[76] Oracle Corporation, \u201cCollections framework enhancements in Java SE 7.\u201d http://docs.\noracle.com/javase/7/docs/technotes/guides/collections/changes7.html. Ac-\ncessedonline,December2013.\n[77] T. Papadakis, J. I.Munro, andP.V. Poblete, \u201cAverage search and updatecosts inskiplists,\u201d\nBIT,vol.32,pp.316\u2013332,1992.\n[78] P. V. Poblete, J. I. Munro, and T. Papadakis, \u201cThe binomial transform and its application to\nthe analysis of skip lists,\u201d in Proceedings of the European Symposium on Algorithms (ESA),\npp.554\u2013569,1995.\n[79] R. C. Prim, \u201cShortest connection networks and some generalizations,\u201d Bell Syst. Tech. J.,\nvol.36,pp.1389\u20131401,1957.\n[80] W. Pugh, \u201cSkip lists: a probabilistic alternative to balanced trees,\u201d Commun. ACM, vol. 33,\nno.6,pp.668\u2013676,1990.\n[81] H.Samet,TheDesignandAnalysisofSpatialDataStructures.Reading,MA:Addison-Wesley,\n1990.\n[82] R.SchafferandR.Sedgewick,\u201cTheanalysisofheapsort,\u201dJournalofAlgorithms,vol.15,no.1,\npp.76\u2013100,1993.\n[83] D. D. Sleator and R. E. Tarjan, \u201cSelf-adjusting binary search trees,\u201d J. ACM, vol. 32, no. 3,\npp.652\u2013686,1985.\n[84] G.A.Stephen,StringSearchingAlgorithms. WorldScientificPress,1994.\n[85] R. Tamassia and G. Liotta, \u201cGraph drawing,\u201d in Handbook of Discrete and Computational\nGeometry (J. E. Goodman and J. O\u2019Rourke, eds.), ch. 52, pp. 1163\u20131186, CRC Press LLC,\n2nded.,2004.\n[86] R.TarjanandU. Vishkin, \u201cAnefficientparallel biconnectivity algorithm,\u201d SIAMJ. Comput.,\nvol.14,pp.862\u2013874,1985.\n[87] R.E.Tarjan,\u201cDepthfirstsearchandlineargraphalgorithms,\u201dSIAMJ.Comput.,vol.1,no.2,\npp.146\u2013160,1972.\n[88] R.E.Tarjan,DataStructuresandNetworkAlgorithms,vol.44ofCBMS-NSFRegionalCon-\nferenceSeriesinAppliedMathematics. Philadelphia, PA:Societyfor IndustrialandApplied\nMathematics,1983.\n[89] A.B.Tucker,Jr.,TheComputerScienceandEngineeringHandbook. CRCPress,1997.\n[90] J. van Leeuwen, \u201cGraph algorithms,\u201d in Handbook of Theoretical Computer Science (J. van\nLeeuwen,ed.),vol.A.AlgorithmsandComplexity,pp.525\u2013632,Amsterdam:Elsevier,1990.\n[91] J.S.Vitter,\u201cEfficientmemoryaccessinlarge-scalecomputation,\u201dinProc.8thSympos.Theoret.\nAspectsComput.Sci.,LectureNotesComput.Sci.,Springer-Verlag,1991.\n[92] J.S.VitterandW.C.Chen, DesignandAnalysisofCoalescedHashing. NewYork: Oxford\nUniversityPress,1987.\n[93] J.S.VitterandP.Flajolet,\u201cAverage-caseanalysisofalgorithmsanddatastructures,\u201dinAlgo-\nrithms and Complexity (J. van Leeuwen, ed.), vol. A of Handbook of Theoretical Computer\nScience,pp.431\u2013524,Amsterdam:Elsevier,1990.\n[94] S.Warshall,\u201cAtheoremonbooleanmatrices,\u201dJournal oftheACM,vol.9,no.1, pp.11\u201312,\n1962.\n[95] J. W. J. Williams, \u201cAlgorithm 232: Heapsort,\u201d Communications of the ACM, vol. 7, no. 6,\npp.347\u2013348,1964.\n[96] D.Wood,DataStructures,Algorithms,andPerformance. Addison-Wesley,1993.\nwww.it-ebooks.info\nIndex\n%operator,24,242 adaptablepriorityqueue, big-Oh,164\u2013167\n==operator,25,138 390\u2013392,658,659 big-Omega,167,265\n\u02c6operator,412 adapterdesignpattern,233, big-Theta,167\n245 autoboxing,19,92\nAbelson,Hal,223 Adel\u2019son-Vel\u2019skii,Georgii, AVLtree,479\u2013486\nabstractclass,80\u201381, 479,530\n313\u2013314,323 backedge,639,680\nadjacencylist,619,622\u2013623\nabstractdatatype,62 Baeza-Yates,Ricardo,530,\nadjacencymap,619,624,626\ndeque,248\u2013249 572,709\nadjacencymatrix,619,625\ngraph,612\u2013618 BalanceableBinaryTreeclass,\nAggarwal,Alok,709\nmap,402\u2013404 476\u2013478\nAho,Alfred,256,305,530,\npartition,672\u2013675 Baru\u02davka,Otakar,683,686\n610\npositionallist,272\u2013275 baseclass,64\nAhuja,Ravindra,686\npriorityqueue,361 basetype,4\nalgorithmanalysis,164\u2013181\nqueue,239\u2013240 Bayer,Rudolf,530,709\nalphabet,17,575\nsortedmap,428 Bellman,Richard,610\namortization,205,266\u2013269,\nstack,227\u2013228 Bentley,Jon,223,400,572\n376,672\u2013675\nstring,17\u201318 best-fitalgorithm,692\nancestor,310\ntree,312\u2013314 BFS,seebreadth-firstsearch\nantisymmetricproperty,363\nabstractmethods,80 biconnectedgraph,681\nApacheCommons,448\nabstractmodifier,11,81 big-Ohnotation,164\u2013167\nAPI,76,228\nAbstractBinaryTreeclass, big-Omeganotation,167,265\narithmeticoperators,24\n319\u2013320,323,325,330, big-Thetanotation,167\narithmeticprogression,71,268\n339,341,342 binaryheap,370\u2013384\nArnold,Ken,57\nAbstractHashMapclass,406, binarysearch,196\u2013197,\n422\u2013424 array,20\u201321,104\u2013119 203\u2013204,429\u2013432,563\nabstraction,62 dynamic,263\u2013269 binarysearchtree,338,\nAbstractMapclass,384, arraylist,260\u2013265 460\u2013478\n406\u2013407,408,422 ArrayDequeclass,251 rotation,472\nAbstractPriorityQueueclass, ArrayIndexOutOfBounds trinoderestructuring,473\n364\u2013365,366 exception,20,33,84,87 binarytree,317\u2013330,533\nAbstractSortedMapclass, ArrayListclass,260\u2013261, array-basedrepresentation,\n406,430,466 263\u2013265,283\u2013285,290 331\u2013332\nAbstractTreeclass,313\u2013316, ArrayQueueclass,242\u2013244, complete,370\n323,330,339\u2013342 302 improper,317\n(a,b)tree,702\u2013704 Arraysclass,112,114,139, level,321\naccessfrequency,294 175 linkedstructure,323\u2013330\naccessormethod,5 ArrayStackclass,230\u2013232, proper,317\nactivationrecord,seeframe 300 BinaryTreeinterface,319\nacyclicgraph,615 associativearray,402 bipartitegraph,681\nadaptability,60,61 asymptoticnotation,164\u2013177 bitvector,456\nwww.it-ebooks.info\nIndex 715\nBooch,Grady,101,305 clonemethod,141\u2013144 directed,615\nbootstrapping,424,502 Cloneableinterface,79,141, cyclic-shifthashcode,\nBoyer,Robert,610 144,302,303,353 413\u2013414\nBoyer-Moorealgorithm, cloning,141\u2013144\n578\u2013581 clustering,419\nDAG,seedirectedacyclic\nBrassard,Gilles,188 coding,46\ngraph\nbreadth-firstsearch,640\u2013642 Cole,Richard,610\ndatapackets,304\nbreadth-firsttreetraversal, Collectioninterface,288\ndeMorgan\u2019slaw,178\n336,341\u2013342 collections,seeJava\ndebugging,46\nbreakstatement,32,37 collectionsframework\ndecisiontree,317,461,556\nbruteforce,576 collisionresolution,411,\ndecrease-and-conquer,\nB-tree,704 417\u2013419\n563\u2013565\nbubble-sort,304 Comer,Douglas,709\ndecryption,115\nbucket-sort,558\u2013559,562 comparabilityproperty,363\ndefaultconstructor,6,14\nBudd,Timothy,101,305 Comparableinterface,79,363\ndegreeofavertex,613\nbufferoverflowattack,20 Comparatorinterface,363,\ndelimiter,40,235\nBurger,Doug,709 538\nDemurjian,Steven,101,256\ncompletebinarytree,370\ndenial-of-serviceattack,421\ncaching,695\u2013700 completegraph,678\ndepthofatree,314\u2013316\nCaesarcipher,115\u2013117 compositiondesignpattern,\ndepth-firstsearch(DFS),\nCarlsonn,Svante,400 91,295\n631\u2013639\ncasting,28\u201329,88\u201390 compressionfunction,411,\ndeque,248\u2013251\nimplicit,29 416\nabstractdatatype,248\u2013249\ncatch,82 concatenation,17,24\nlinked-listimplementation,\ncatchinganexception,82\u201384 concretemethods,80\n250\nceilingfunction,163 ConcurrentSkipListMap\nDequeinterface,288\ncentralprocessingunit(CPU), class,436\ndescendant,310\n151 connectedcomponents,615,\ndesignpatterns,49,63\nChainHashMapclass,406, 635,638\n424\u2013425 constructor,14 adapter,233,245\ncharacter,17 continuestatement,37 amortization,266\u2013269\ncheckedexception,86 contradiction,178 bruteforce,576\nChen,Wen-Chin,458 contrapositive,178 composition,91,295,362\nChernoffbound,570 controlflow,30\u201337 divide-and-conquer,\nchildclass,seesubclass corememory,695 532\u2013536,544\u2013545\ncircularqueue,246\u2013247 Cormen,Thomas,530,686 dynamicprogramming,\ncircularlylinkedlist,128\u2013131, Cornell,Gary,57 598\u2013604\n246 CPU,151 factorymethod,325,477\nClarkson,Kenneth,572 CRCcards,47 greedymethod,597\nclass,2,5\u201322,60,62 CreditCardclass,41\u201343,47, iterator,282\u2013286\nabstract,80\u201381,313\u2013314 50\u201351,65\u201368,88\u201389 position,272\u2013275\nbase,64 Crochemore,Maxime,610 prune-and-search,563\u2013565\nchild,64 Crosby,Scott,458 templatemethod,81,446,\ninner,96,284 cryptography,115\u2013117 475\nnested,96 cubicfunction,160 DFS,seedepth-firstsearch\nouter,96 cuckoohashing,456 DiBattista,Giuseppe,358,\nparent,64 currentTimeMillismethod, 686\nsub,64 113,151 diameter,355\nsuper,64 cyber-dollar,266\u2013267, dictionary,seemap\nclassdiagram,47 495\u2013498,673 Dijkstra\u2019salgorithm,653\u2013661\nClassCastException,87,89 cycle,615 Dijkstra,Edsger,223,686\nwww.it-ebooks.info\n716 Index\ndirectedacyclicgraph, evolvability,61 freelist,692\n647\u2013649 exception,82\u201387\ndiskusage,198\u2013201,204\u2013205, catching,82\u201384 gametree,336,358\n345 checked,86 Gamma,Erich,101\ndivide-and-conquer,532\u2013536, throwing,85\u201386 garbagecollection,232,\n544\u2013545 unchecked,86 693\u2013694\ndivisionmethodforhash Exceptionclass,86,87 mark-sweep,693\ncodes,416 exponentialfunction,161\u2013162, Gauss,Carl,159\ndotoperator,7 209\u2013210 generics,91\u201395,126,228\ndoublehashing,419 expression,23\u201329 geometricprogression,72,267\ndouble-endedqueue,seedeque expressiontree,318 geometricsum,162\ndoublylinkedlist,125, externalmemory,695\u2013707, Gonnet,Gaston,400,530,572,\n132\u2013137 709 709\nDoublyLinkedListclass, external-memoryalgorithm, Goodrich,Michael,709\n135\u2013137,250,271,276 695\u2013707 Gosling,James,57\ndown-heapbubbling,374 external-memorysorting, Graham,Ronald,686\ndynamicarray,263\u2013269 705\u2013707 graph,612\u2013686\nshrinking,269 abstractdatatype,612\u2013618\ndynamicdispatch,68 factorialfunction,191\u2013192, acyclic,615,647\u2013649\ndynamicprogramming, 202,690 breadth-firstsearch,\n598\u2013604 factorymethodpattern,325, 640\u2013642\n477 connected,615,630\nEades,Peter,358,686 fail-fastiterator,284,304 datastructures,619\u2013629\nedge,310 favoriteslist,294\u2013299 adjacencylist,619,\ndestination,613 FavoritesListclass,295\u2013296 622\u2013623\nendpoint,613 FavoritesListMTFclass,298, adjacencymap,619,624,\nincident,613 399 626\nmultiple,614 Fibonacciheap,659 adjacencymatrix,619,625\norigin,613 Fibonacciseries,73,180,186, edgelist,619\u2013621\noutgoing,613 216\u2013217,480 depth-firstsearch,631\u2013639\nparallel,614 field,5 directed,612,613,647\u2013649\nself-loop,614 FIFO,seefirst-in,first-out mixed,613\nedgelist,619\u2013621 Fileclass,200 reachability,643\u2013646\nedgeofagraph,612 filesystem,198\u2013201,310,345 shortestpaths,651\u2013661\nedgerelaxation,653 finalmodifier,11 simple,614\neditdistance,608 first-fitalgorithm,692 stronglyconnected,615\nelementuniquenessproblem, first-in,first-out(FIFO) traversal,630\u2013642\n174\u2013175,215 protocol,238,255,336, undirected,612,613\nencapsulation,62 360,699\u2013700 weighted,651\u2013686\nencryption,115 Flajolet,Philippe,188 greedymethod,597,652,653\nendpoints,613 Flanagan,David,57 Guavalibrary,448\nenum,22 floorfunction,163,209 Guibas,Leonidas,530\nequalsmethod,25,138\u2013140 flowchart,31 Guttag,John,101,256,305\nequivalencerelation,138 Floyd,Robert,400,686\nequivalencetesting,138\u2013140 Floyd-Warshallalgorithm, Harmonicnumber,171,221\nerasure,140 644\u2013646,686 hashcode,411\u2013415\nErrorclass,86,87 for-eachloop,36,283 cyclic-shift,413\u2013414\nEuclideannorm,56 forest,615 polynomial,413,609\nEulertourofagraph,677,681 fractal,193 hashtable,410\u2013427\nEulertourtreetraversal, fragmentationofmemory,692 clustering,419\n348\u2013349,358 frame,192,688 collision,411\nwww.it-ebooks.info\nIndex 717\ncollisionresolution, multiple,79 Knuth-Morris-Prattalgorithm,\n417\u2013419 single,66 582\u2013585\ndoublehashing,419 innerclass,96,284 Kosaraju,S.Rao,686\nlinearprobing,418 inordertreetraversal,337, Kruskal\u2019salgorithm,667\u2013675\nquadraticprobing,419 341,473 Kruskal,Joseph,686\nhashing insertion-sort,110\u2013111,\ncuckoo,456 293\u2013294,387,561 Landis,Evgenii,479,530\npower-of-two-choices,457 instance,5,60 Langston,Michael,572\nheadersentinel,132 instancevariable,5,60 last-in,first-out(LIFO)\nheap,370\u2013384 instanceofoperator,68,89 protocol,226,228\nbottom-upconstruction, integrateddevelopment lazyiterator,284\n380\u2013384 environment(IDE),16,49 LCS,seelongestcommon\nheap-sort,388\u2013389,561 interface,62,76\u201379,90,228 subsequence\nHeapAdaptablePriorityQueue internalmemory,695 leafofatree,310\nclass,392\u2013394 Internet,304 leastrecentlyused(LRU)\nHeapAdaptablePriorityQueue inversion,387,561,569 protocol,699\u2013700\nclass,659 invertedfile,456 Lecroq,Thierry,610\nHeapPriorityQueueclass, isomorphism,352 Leiserson,Charles,530,686\n377\u2013378,382 Iterableinterface,36,283 Lesuisse,R.,223\nheightofatree,315\u2013316,471 iterator,282\u2013286 levelinatree,321\nHell,Pavol,686 fail-fast,284,304 levelnumbering,331,371\nHennessy,John,709 Leveson,Nancy,101\nJa\u00b4Ja\u00b4,Joseph,358\nheuristic,297 lexicographicorder,363,559\nJarn\u00b4\u0131k,Vojte\u02c7ch,686\nhierarchy,64 LIFO,seelast-in,first-out\nJava,2\u201357,60\u201396\nHoare,C.A.R.,572 linearfunction,158\narrays,20\u201321,104\u2013119\nHolmes,David,57 linearprobing,418\ncasting,88\u201390\nhook,466,475 linearityofexpectation,565\ncontrolflow,30\u201337\nHopcroft,John,256,305,530, linkedlist,122\u2013137,233,245\nexceptions,82\u201387\n686 circularlylinked,128\u2013131,\nexpressions,23\u201329\nHorner\u2019smethod,187 246\ninput,38\u201340\nHorstman,Cay,57 doublylinked,125,\nmethodstack,688\u2013690\nHTML,235\u2013237,253,574 132\u2013137,250,276\u2013280\nmethods,12\u201313\nHuang,Bing-Chao,572 singlylinked,122\u2013127,\noutput,38\u201340\nHuffmancoding,595\u2013596 233,245\npackages,44\u201345\nLinkedBinaryTreeclass,\nJavacollectionsframework,\nI/Ocomplexity,701 325\u2013330,466,476\u2013477\n251,288\u2013292,384,\nidentifier,2 LinkedHashMapclass,454\n445\u2013448\nIllegalArgumentException, LinkedListclass,251,288,\nJavaVirtualMachine(JVM),\n85,87 289,290\n688\u2013693\nimmutable,18 LinkedPositionalListclass,\njavadoc,50\nimplicitcast,29 276\u2013280,286\u2013287,620\nJones,Richard,709\nimportstatement,45 LinkedQueueclass,245,341,\nJosephusproblem,246\nin-degree,613 541,549\nin-placealgorithm,389,553 Karger,David,686 Lins,Rafael,709\nincomingedges,613 Karp,Richard,358,609 Liotta,Giuseppe,358,686\nindex,17,20 Klein,Philip,686 Liskovsubstitutionprinciple,\nIndexOutOfBoundsException, Kleinberg,Jon,572 68\n259 Klink,Alexander,458 Liskov,Barbara,68,101,256,\ninduction,179\u2013180,203 Knuth,Donald,148,188,305, 305\ninfixnotation,356 358,400,458,530,572, list\ninheritance,64\u201374 610,686,709 offavorites,294\u2013299\nwww.it-ebooks.info\n718 Index\npositional,270\u2013281 minimumspanningtree, object,5\u201322,60\nListinterface,258\u2013259,284, 662\u2013675 Objectclass,66,91,138,141\n288 Kruskal\u2019salgorithm, object-orienteddesign,60\u2013101\nliteral,23 667\u2013675 openaddressing,418\nLittman,Michael,572 Prim-Jarnikalgorithm, operandstack,690\nliveobjects,693 664\u2013666 orderstatistic,563\nloadfactor,417,420\u2013421 mixin,79 Orlin,James,686\nlocalityofreference,297,697 modularity,62 out-degree,613\nlog-starfunction,675 modulooperator,24,116,242 outerclass,96\nlogarithmfunction,156\u2013157 Moore,J.Strother,610 outgoingedge,613\nlongestcommonsubsequence, Morris,James,610 override,64\n601\u2013604 Morrison,Donald,610\nlooking-glassheuristic,578 Motwani,Rajeev,458,572 p-norm,56\nlookuptable,410 move-to-frontheuristic, package,10,44\u201345\nloopinvariant,181 297\u2013299 palindrome,222,606\nlowestcommonancestor,355 MST,seeminimumspanning parameterpassing,13\ntree parentclass,64\nmultimap,445,448\u2013450 parentnode,309\nMagnanti,Thomas,686\nmultipleinheritance,79 parentheticstring\nmainmemory,695\nMultiply-Add-and-Divide representation,346\nmap,402\u2013444\n(MAD),416 partition,670,672\u2013675\nabstractdatatype,402\u2013404\nmultiset,445,447\u2013448 path,310,615\nbinarysearchtree,460\u2013478\nmultiwaymerge-sort,705\u2013707 compression,675\nhashtable,410\u2013427\nmultiwaysearchtree,500\u2013502 directed,615\nskiplist,436\u2013444\nMunro,J.Ian,400 length,352,652\nsorted,428\u2013435,460\nsimple,615\nMapinterface,406\nn-log-nfunction,158 patternmatching,576\u2013585\nmark-sweepalgorithm,693\nnarrowingconversion,88 Boyer-Moorealgorithm,\nmatrix,118\nnaturaljoin,304 578\u2013581\nmatrixchain-product,598\u2013600\nnaturalordering,363 bruteforce,576\u2013577\nmaximalindependentset,682\nnestedclass,96 Knuth-Morris-Pratt\nMcCreight,Edward,610,709\nnestedloops,159 algorithm,582\u2013585\nMcDiarmid,Colin,400 next-fitalgorithm,692 Rabin-Karpalgorithm,609\nMcIlroy,Douglas,572 node,309 Patterson,David,709\nmedian,196,555,563,571 ancestor,310 permutation,191\nMegiddo,Nimrod,572 child,309 Peters,Tim,562\nMehlhorn,Kurt,530,686,709 descendant,310 polymorphism,68\nmemberofaclass,5 external,310 polynomialfunction,160,187\nmemoryaddress,688 internal,310 polynomialhashcode,413,\nmemoryallocation,692 leaf,310 609\nmemoryheap,691 parent,309 portability,61\nmemoryhierarchy,695 root,309 position,272\u2013275,312,437\nmemorymanagement, sibling,310 Positioninterface,274,313,\n688\u2013694 nodeofagraph,612 325\nmerge-sort,532\u2013544,562 NoSuchElementException, positionallist,270\u2013281\nmultiway,705\u2013707 86,87,240,251,282 abstractdatatype,272\u2013280\nmergeableheap,530 nullvalue,6,7,21,23 PositionalListinterface,275,\nmethod,2,12\u201313,60 NullPointerException,7,87 293,295\nabstract,80 Numberclass,89 postfixnotation,253,356\nconcrete,80 NumberFormatException,28, postordertreetraversal,335\nsignature,12 84,85,87 powerfunction,209\nwww.it-ebooks.info\nIndex 719\npower-of-two-choiceshashing, java.util.Queueinterface,384 seed,113,437\n457 quick-sort,544\u2013555,562 selectionproblem,563\u2013565\nPratt,Vaughan,610 selection-sort,386\nPredatoryCreditCard,65\u201368, Rabin,Michael,609 self-loop,614\n88\u201389 Rabin-Karpalgorithm,609 sentinel,132\u2013133\nprefixaverage,175\u2013177 radix-sort,559\u2013560,562 separatechaining,417\nprefixcode,595 Raghavan,Prabhakar,458,572 sequentialsearch,196\nprefixofastring,575 Ramachandran,Vijaya,358 setADT,445\u2013447\npreordertreetraversal,334 Randomclass,53,113,437 Sharir,Micha,358\nPrim,Robert,686 randomization,421,437, short-circuitevaluation,33\nPrim-Jarnikalgorithm, 442\u2013444,551\u2013552, shortestpath,651\u2013661\n664\u2013666 564\u2013565 Dijkstra\u2019salgorithm,\nprimitiveoperations,154 randomizedquick-select,564 653\u2013661\nprimitivetype,4 randomizedquick-sort,551 tree,661\npriorityqueue,360\u2013400 reachability,615,630 sievealgorithm,453\nadaptable,390\u2013392,658 recurrenceequation,203,540, signature,7,12,14\nADT,361 565,705 singleinheritance,66\nheapimplementation, recursion,190\u2013220,314\u2013316, singlylinkedlist,122\u2013127,\n372\u2013379 334\u2013335,344\u2013349, 233,245\nsortedlistimplementation, 461\u2013462,532,540,563, SinglyLinkedListclass,\n368\u2013369 690 126\u2013127,140,144\nunsortedlist binary,211 skiplist,436\u2013444\nimplementation,366\u2013367 depthlimit,218,525 Sleator,Daniel,530\nprioritysearchtree,400 linear,206\u2013210 snapshotiterator,284,320,\nprivatemodifier,10 multiple,212\u2013213 340\nProbeHashMapclass,406, tail,219\u2013220 sortmethod,175\n426\u2013427 trace,192,202,690 sortedmap,428\u2013435,460\nprogramcounter,689 red-blacktree,510\u2013524 abstractdatatype,428\nprogression Reed,Bruce,400 searchtable,429\u2013432\narithmetic,71,268 referencetype,6 SortedMapinterface,406\nFibonacci,73 referencevariable,6 SortedPriorityQueueclass,\ngeometric,72,267 reflexiveproperty,363 368\u2013369\nprotectedmodifier,10,67 rehashing,420 SortedTableMapclass,406,\nprune-and-search,563\u2013565 reusability,60,61 429\u2013432\npseudocode,48 Rivest,Ronald,530,686 sorting,110,385\u2013389,\npseudorandomnumber robustness,60 532\u2013560\ngenerator,113\u2013114,437 rootobjects,693 bucket-sort,558\u2013559\npublicmodifier,9 rootofatree,309 external-memory,705\u2013707\nPugh,William,458 round-robinscheduling,128 heap-sort,388\u2013389\npuzzlesolver,212\u2013213 runningtime,150 in-place,389,553\nRuntimeException,87 insertion-sort,110\u2013111,\nquadraticfunction,158 293,387\nquadraticprobing,419 Samet,Hanan,709 lowerbound,556\u2013557\nqueue,238\u2013247 Scannerclass,39\u201340,45,86 merge-sort,532\u2013544\nabstractdatatype,239\u2013240 Schaffer,Russel,400 priority-queue,385\u2013389\narrayimplementation, scheduling,399 quick-sort,544\u2013555\n241\u2013244 Scoreboardclass,105\u2013109 radix-sort,559\u2013560\ncircular,246\u2013247 searchengine,594 selection-sort,386\nlinked-listimplementation, searchtable,429\u2013432 stable,559\n245 searchtree,460\u2013530 Tim-sort,562\nQueueinterface,239,240,288 Sedgewick,Robert,400,530 spaceusage,150\nwww.it-ebooks.info\n720 Index\nspanningtree,615,630,634, three-waysetdisjointness, preorder,334,340\n635,662 173\u2013174 (2,4),see(2,4)tree\nsparsearray,303 throwstatement,85 TreeMapclass,406\nsplaytree,475,488\u2013499 Throwableclass,86,87 triangulation,608\nstablesorting,559 throwinganexception,85\u201386 trie,586\u2013594\nstack,226\u2013237 Tic-Tac-Toe,119,336,358 compressed,590\nabstractdatatype,227\u2013228 Tim-sort,562 trinoderestructuring,473,482,\narrayimplementation, Tollis,Ioannis,358,686 513\n230\u2013232 topologicalordering,647\u2013649 try-catchstatement,82\nlinked-listimplementation, totalorder,363 Tsakalidis,Athanasios,530\n233 tower-of-twos,675 Turner,Clark,101\nStackinterface,228\u2013229 TowersofHanoi,222 two-dimensionalarray,118\nstaticmodifier,10 trailersentinel,132 (2,4)tree,500\u2013509\nStein,Clifford,530,686 transitiveclosure,643\u2013646 type,5\nStephen,Graham,610 transitiveproperty,363 typeconversion,28\u201329\nstopwords,588,609 tree,205,307\u2013358,615 typeinference,93\nstring abstractdatatype,312\u2013314\nmutable,18 binary,seebinarytree Ullman,Jeffrey,256,305,530\nprefix,575 binarysearch,seebinary unboxing,19,93\nsuffix,575 searchtree uncheckedexception,86\nStringclass,17\u201318 binarytreerepresentation, Unicode,115,575\nStringBuilderclass,18,152, 354 union-find,670,672\u2013675\n269 childnode,309 unittesting,54\nstrongtyping,76 decision,317 UnsortedPriorityQueueclass,\nstronglyconnected depth,314\u2013316 366\u2013367\ncomponents,638 edge,310 UnsortedTableMapclass,\nstronglyconnectedgraph,615 expression,318 406,408\u2013409,424\nsubclass,10,64 externalnode,310 up-heapbubbling,372\nsubgraph,615 height,315\u2013316 updatemethod,5\nsubsequence,601 internalnode,310\nsubtree,310 leaf,310 vanLeeuwen,Jan,686\nsuffixofastring,575 level,321 vertexofagraph,612\nsummation,161 linkedstructure,333 virtualmemory,697\ngeometric,162 multiway,500\u2013502 Vishkin,Uzi,358\nsuperkeyword,67,81 node,309 visibility,9\nsuperclass,64 ordered,311 Vitter,Jeffrey,188,458,709\nSussman,Gerald,223 parentnode,309\nSussman,Julie,223 path,310 Wa\u00a8lde,Julian,458\nred-black,seered-blacktree Wallach,Dan,458\nTamassia,Roberto,358,686 rootnode,309 Warshall,Stephen,686\nTardos,E\u00b4va,572 splay,seesplaytree wideningconversion,88\nTarjan,Robert,358,530,686 traversal,205,334\u2013349 Williams,J.W.J.,400\ntemplatemethodpattern,81, breadth-first,336, Wood,Derick,305\n446,475 341\u2013342 worst-fitalgorithm,692\ntesting,46 Eulertour,348\u2013349 wrappertype,19,91,93,232\ntextcompression,595\u2013596 inorder,337,341,473\nthiskeyword,15,67,96 postorder,335,341 XML,236,574\nwww.it-ebooks.info\n",
  "context": "Drive, Danvers, MA 01923, website www.copyright.com. Requests to the Publisher for\npermissionshouldbeaddressedtothePermissionsDepartment,JohnWiley&Sons,Inc.,\n111RiverStreet,Hoboken,NJ07030-5774,(201)748-6011,fax(201)748-6008,website",
  "source_file": "resources\\Year 2\\Java DSA\\Data Structures and Algorithms in Java, 6th Edition.pdf",
  "line_numbers": [
    49,
    31457
  ]
}