{
  "title": "Data Structures and Algorithms in C++, 2nd edition",
  "language": "cpp",
  "topics": [
    "machine_learning",
    "web_dev",
    "fundamentals",
    "algorithms",
    "data_structures",
    "networking",
    "database"
  ],
  "purpose": "This page intentionally left blank www.allitebooks.com i i",
  "code": "\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page i \u2014 #1\ni i\nData Structures and\nAlgorithms in C++\nSecond Edition\nwww.allitebooks.com\ni i\ni i\nThis page intentionally left blank\nwww.allitebooks.com\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page iii \u2014 #3\ni i\nData Structures and\nAlgorithms in C++\nSecond Edition\nMichael T. Goodrich\nDepartmentofComputerScience\nUniversityofCalifornia, Irvine\nRoberto Tamassia\nDepartmentofComputerScience\nBrownUniversity\nDavid M. Mount\nDepartmentofComputerScience\nUniversityofMaryland\nJohn Wiley & Sons, Inc.\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page iv \u2014 #4\ni i\nACQUISITIONSEDITOR BethLangGolub\nMARKETINGMANAGER ChrisRuel\nEDITORIALASSISTANT ElizabethMills\nMEDIAEDITOR ThomasKulesa\nSENIORDESIGNER JimO\u2019Shea\nCONTENTMANAGER MichelineFrederick\nPRODUCTIONEDITOR AmyWeintraub\nPHOTOEDITOR SheenaGoldstein\nThisbookwassetinLATEXbytheauthorsandprintedandboundbyMalloyLithographers.\nThecoverwasprintedbyMalloyLithographers.ThecoverimageisfromWutaWutaTjan-\ngala,\u201cEmudreaming\u201d c estateoftheartist2009licensedbyAboriginalArtistsAgency.\n(cid:13)\nJenniferSteele/ArtResource,NY.\nThisbookisprintedonacidfreepaper.\n\u221e\nTrademarkAcknowledgments: JavaisatrademarkofSunMicrosystems, Inc. UNIX(cid:13)R is\naregisteredtrademarkintheUnitedStatesandothercountries,licensedthroughX/Open\nCompany,Ltd. PowerPoint(cid:13)R isatrademarkofMicrosoftCorporation. Allotherproduct\nnamesmentionedhereinarethetrademarksoftheirrespectiveowners.\nCopyright c 2011,JohnWiley&Sons,Inc. Allrightsreserved.\n(cid:13)\nNopartofthispublicationmaybereproduced,storedinaretrievalsystemortransmitted\nin anyform or by any means, electronic, mechanical, photocopying,recording, scanning\nor otherwise, except as permitted under Sections 107 or 108 of the 1976 United States\nCopyrightAct,withouteitherthepriorwrittenpermissionofthePublisher,orauthorization\nthroughpaymentof the appropriateper-copyfee to the CopyrightClearance Center, Inc.\n222RosewoodDrive,Danvers,MA01923,(978)750-8400,fax(978)646-8600.\nRequests to the Publisherfor permissionshould be addressedto the PermissionsDepart-\nment,JohnWiley&Sons,Inc.,111RiverStreet,Hoboken,NJ07030,(201)748-6011,fax\n(201)748-6008,E-Mail:PERMREQ@WILEY.COM.\nToorderbooksorforcustomerservicepleasecall1-800-CALLWILEY(225-5945).\nFounded in 1807, John Wiley & Sons, Inc. has been a valued source of knowledge and\nunderstandingformorethan200years,helpingpeoplearoundtheworldmeettheirneeds\nandfulfilltheiraspirations.Ourcompanyisbuiltonafoundationofprinciplesthatinclude\nresponsibility to the communities we serve and where we live and work. In 2008, we\nlaunched a Corporate Citizenship Initiative, a globaleffortto address the environmental,\nsocial, economic, and ethical challenges we face in our business. Among the issues we\nare addressing are carbon impact, paper specifications and procurement, ethical conduct\nwithin our business and amongourvendors, and communityand charitable support. For\nmoreinformation,pleasevisitourwebsite: www.wiley.com/go/citizenship.\nLibraryofCongressCataloginginPublicationData\nISBN-13978-0-470-38327-8\nPrintedintheUnitedStatesofAmerica\n10987654321\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page v \u2014 #5\ni i\nTo Karen, Paul,Anna, and Jack\n\u2013 MichaelT.Goodrich\nTo Isabel\n\u2013 RobertoTamassia\nToJeanine\n\u2013 DavidM. Mount\nwww.allitebooks.com\ni i\ni i\nThis page intentionally left blank\nwww.allitebooks.com\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page vii \u2014 #7\ni i\nPreface\nThis second edition of Data Structures and Algorithms in C++ is designed to pro-\nvideanintroductiontodatastructuresandalgorithms,includingtheirdesign,analy-\nsis,andimplementation. IntermsofcurriculabasedontheIEEE/ACM2001Com-\nputing Curriculum, this book is appropriate for use in the courses CS102 (I/O/B\nversions),CS103(I/O/Bversions),CS111(Aversion),andCS112(A/I/O/F/Hver-\nsions). Wediscussitsuseforsuchcoursesinmoredetaillaterinthispreface.\nThemajorchanges inthesecondeditionarethefollowing:\nWeaddedmoreexamplesofdatastructureandalgorithm analysis.\n\u2022\nWeenhanced consistency withtheC++StandardTemplateLibrary(STL).\n\u2022\nWeincorporated STLdatastructures intomanyofourdatastructures.\n\u2022\nWeaddedachapteronarrays,linkedlists,anditerators (Chapter3).\n\u2022\nWeaddedachapteronmemorymanagement andB-trees(Chapter14).\n\u2022\nWeenhanced the discussion of algorithmic design techniques, like dynamic\n\u2022\nprogramming andthegreedymethod.\nWesimplifiedandreorganized thepresentation ofcodefragments.\n\u2022\nWe have introduced STL-style iterators into our container classes, and have\n\u2022\npresented C++ implementations for these iterators, even for complex struc-\nturessuchashashtablesandbinarysearchtrees.\nWe have modified our priority-queue interface to use STL-style comparator\n\u2022\nobjects.\nWe expanded and revised exercises, continuing our approach of dividing\n\u2022\nthemintoreinforcement, creativity, andprojectexercises.\nThisbookisrelatedtothefollowingbooks:\nM.T. Goodrich and R. Tamassia, Data Structures and Algorithms in Java,\n\u2022\nJohn Wiley & Sons, Inc. This book has a similar overall structure to the\npresent book, but uses Java as the underlying language (with some modest,\nbutnecessary pedagogical differences requiredbythisapproach).\nM.T. Goodrich and R. Tamassia, Algorithm Design: Foundations, Analysis,\n\u2022\nandInternetExamples,JohnWiley&Sons,Inc. Thisisatextbookforamore\nadvanced algorithms and data structures course, such as CS210 (T/W/C/S\nversions) intheIEEE/ACM2001curriculum.\nWhile this book retains the same pedagogical approach and general structure\nas Data Structures and Algorithms in Java, the code fragments have been com-\npletelyredesigned. WehavebeencarefultomakefulluseofC++\u2019scapabilitiesand\ndesign code in a manner that is consistent with modern C++ usage. In particular,\nwhenever appropriate, wemakeextensive useofC++elements thatarenot partof\nJava,includingtheC++StandardTemplateLibrary(STL),C++memoryallocation\nvii\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page viii \u2014 #8\ni i\nviii Preface\nanddeallocation(andtheassociatedissuesofdestructors),virtualfunctions,stream\ninputandoutput,operator overloading, andC++\u2019ssaferun-timecasting.\nUse as a Textbook\nThe design and analysis of efficient data structures has long been recognized as a\nvital subject in computing, because the study of data structures is part of the core\nofeverycollegiate computer science andcomputer engineering majorprogram we\nare familiar with. Typically, the introductory courses are presented as a two- or\nthree-course sequence. Elementary data structures are often briefly introduced in\nthefirstprogramming course orinanintroduction tocomputer science course and\nthisisfollowedbyamorein-depthintroductiontodatastructuresinthecoursesthat\nfollow after this. Furthermore, thiscourse sequence istypically followed atalater\npointinthecurriculum byamorein-depth studyofdatastructures andalgorithms.\nWefeelthatthecentral roleofdatastructure designandanalysisinthecurriculum\nisfully justified, given the importance ofefficient data structures inmost software\nsystems,includingtheWeb,operatingsystems,databases,compilers,andscientific\nsimulation systems.\nWiththeemergenceoftheobject-orientedparadigmastheframeworkofchoice\nforbuildingrobustandreusablesoftware,wehavetriedtotakeaconsistent object-\noriented viewpoint throughout this text. One of the main ideas behind the object-\noriented approach is that data should be presented as being encapsulated with the\nmethods that access and modify them. That is, rather than simply viewing data\nas a collection of bytes and addresses, we think of data objects as instances of an\nabstract data type (ADT), which includes a repertoire of methods for performing\noperationsondataobjectsofthistype. Likewise,object-orientedsolutionsareoften\norganized utilizing common design patterns, which facilitate software reuse and\nrobustness. Thus, we present each data structure using ADTsand their respective\nimplementations and we introduce important design patterns as a way to organize\nthoseimplementations intoclasses, methods,andobjects.\nFor most of the ADTs presented in this book, we provide a description of the\npublic interface in C++. Also, concrete data structures realizing the ADTs are\ndiscussed and we often give concrete C++ classes implementing these interfaces.\nWealsogiveC++implementations offundamental algorithms, suchassortingand\ngraphsearching. Moreover,inadditiontoprovidingtechniquesforusingdatastruc-\nturestoimplementADTs,wealsogivesampleapplicationsofdatastructures,such\nas HTML tag matching and a simple system to maintain a play list for a digital\naudio system. Duetospacelimitations, however, weonlyshow codefragments of\nsome of the implementations in this book and make additional source code avail-\nableonthecompanionwebsite.\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page ix \u2014 #9\ni i\nPreface ix\nOnline Resources\nThis book is accompanied by an extensive set of online resources, which can be\nfoundatthefollowingwebsite:\nwww.wiley.com/college/goodrich\nIncluded on this Web site is a collection of educational aids that augment the\ntopics of this book, for both students and instructors. Students are encouraged to\nuse this site along with the book, to help with exercises and increase understand-\ning of the subject. Instructors are likewise welcome to use the site to help plan,\norganize,andpresenttheircoursematerials. Becauseoftheiraddedvalue,someof\ntheseonlineresources arepasswordprotected.\nFor the Student\nForallreaders, andespecially forstudents, weinclude thefollowingresources:\nAlltheC++sourcecodepresented inthisbook.\n\u2022\nPDFhandouts ofPowerpointslides(four-per-page) provided toinstructors.\n\u2022\nAdatabaseofhintstoallexercises,indexedbyproblem number.\n\u2022\nAnonlinestudyguide,whichincludes solutions toselected exercises.\n\u2022\nThe hints should be of considerable use to anyone needing a little help getting\nstarted on certain exercises, and the solutions should help anyone wishing to see\ncompleted exercises. Students who have purchased a new copy of this book will\nget password access to the hints and other password-protected online resources at\nnoextracharge. Otherreaderscanpurchase passwordaccessforanominalfee.\nFor the Instructor\nForinstructors usingthisbook,weincludethefollowingadditional teachingaids:\nSolutions toover200ofthebook\u2019sexercises.\n\u2022\nAdatabaseofadditional exercises, suitable forquizesandexams.\n\u2022\nAdditional C++sourcecode.\n\u2022\nSlidesinPowerpointandPDF(one-per-page) format.\n\u2022\nSelf-contained, special-topic supplements, including discussions on convex\n\u2022\nhulls, rangetrees,andorthogonal segmentintersection.\nThe slides are fully editable, so as to allow an instructor using this book full free-\ndomincustomizing hisorherpresentations. Alltheonline resources areprovided\natnoextrachargetoanyinstructor adopting thisbookforhisorhercourse.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page x \u2014 #10\ni i\nx Preface\nA Resource for Teaching Data Structures and Algorithms\nThis book contains many C++-code and pseudo-code fragments, and hundreds of\nexercises, which are divided into roughly 40% reinforcement exercises, 40% cre-\nativityexercises, and20%programming projects.\nThisbookcanbeusedfortheCS2course,asdescribedinthe1978ACMCom-\nputerScienceCurriculum,orincoursesCS102(I/O/Bversions),CS103(I/O/Bver-\nsions),CS111(Aversion), and/orCS112(A/I/O/F/Hversions), asdescribed inthe\nIEEE/ACM 2001 Computing Curriculum, with instructional units as outlined in\nTable0.1.\nInstructionalUnit RelevantMaterial\nPL1. OverviewofProgrammingLanguages Chapters1and2\nPL2. VirtualMachines Sections14.1.1and14.1.2\nPL3. IntroductiontoLanguageTranslation Section1.7\nPL4. DeclarationsandTypes Sections1.1.2,1.1.3,and2.2.5\nPL5. AbstractionMechanisms Sections2.2.5,5.1\u20135.3,6.1.1,6.2.1,6.3,\n7.1,7.3.1,8.1,9.1,9.5,11.4,and13.1.1\nPL6. Object-OrientedProgramming Chapters 1 and 2 and Sections 6.2.1,\n7.3.7,8.1.2,and13.3.1\nPF1. FundamentalProgrammingConstructs Chapters1and2\nPF2. AlgorithmsandProblem-Solving Sections1.7and4.2\nPF3. FundamentalDataStructures Sections 3.1, 3.2, 5.1\u20135.3, 6.1\u20136.3, 7.1,\n7.3,8.1,8.3,9.1\u20139.4,10.1,and13.1.1\nPF4. Recursion Section3.5\nSE1. SoftwareDesign Chapter 2 and Sections 6.2.1, 7.3.7,\n8.1.2,and13.3.1\nSE2. UsingAPIs Sections2.2.5,5.1\u20135.3,6.1.1,6.2.1,6.3,\n7.1,7.3.1,8.1,9.1,9.5,11.4,and13.1.1\nAL1. BasicAlgorithmicAnalysis Chapter4\nAL2. AlgorithmicStrategies Sections11.1.1,11.5.1,12.2,12.3.1,and\n12.4.2\nAL3. FundamentalComputingAlgorithms Sections 8.1.5, 8.2.2, 8.3.5, 9.2, and\n9.3.1,andChapters11,12,and13\nDS1. Functions,Relations,andSets Sections4.1,8.1,and11.4\nDS3. ProofTechniques Sections4.3,6.1.3,7.3.3,8.3,10.2\u201310.5,\n11.2.1, 11.3.1, 11.4.3, 13.1.1, 13.3.1,\n13.4,and13.5\nDS4. BasicsofCounting Sections2.2.3and11.1.5\nDS5. GraphsandTrees Chapters7,8,10,and13\nDS6. DiscreteProbability Appendix A and Sections 9.2, 9.4.2,\n11.2.1,and11.5\nTable0.1: MaterialforunitsintheIEEE/ACM2001ComputingCurriculum.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xi \u2014 #11\ni i\nPreface xi\nContents and Organization\nThechapters forthiscourseareorganized toprovide apedagogical paththatstarts\nwith the basics of C++ programming and object-oriented design. We provide an\nearly discussion ofconcrete structures, likearrays andlinked lists, inorder topro-\nvide a concrete footing to build upon when constructing other data structures. We\nthenaddfoundational techniques likerecursion andalgorithm analysis, and,inthe\nmain portion of the book, we present fundamental data structures and algorithms,\nconcluding with a discussion of memory management (that is, the architectural\nunderpinnings ofdatastructures). Specifically, thechapters forthisbook areorga-\nnizedasfollows:\n1. A C++ Primer\n2. Object-Oriented Design\n3. Arrays, Linked Lists, and Recursion\n4. Analysis Tools\n5. Stacks, Queues, and Deques\n6. List and Iterator ADTs\n7. Trees\n8. Heaps and Priority Queues\n9. Hash Tables, Maps, and Skip Lists\n10. Search Trees\n11. Sorting, Sets, and Selection\n12. Strings and Dynamic Programming\n13. Graph Algorithms\n14. Memory Management and B-Trees\nA. Useful Mathematical Facts\nAmoredetailedlistingofthecontents ofthisbookcanbefoundinthetableof\ncontents.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xii \u2014 #12\ni i\nxii Preface\nPrerequisites\nWehavewrittenthisbookassumingthatthereadercomestoitwithcertainknowl-\nedge. Weassume that the reader is atleast vaguely familiar with a high-level pro-\ngramminglanguage,suchasC,C++,Python,orJava,andthatheorsheunderstands\nthemainconstructs fromsuchahigh-levellanguage, including:\nVariablesandexpressions.\n\u2022\nFunctions (alsoknownasmethodsorprocedures).\n\u2022\nDecisionstructures (suchasif-statements andswitch-statements).\n\u2022\nIteration structures (for-loops andwhile-loops).\n\u2022\nFor readers who are familiar with these concepts, but not with how they are ex-\npressed in C++, weprovide a primer on the C++ language in Chapter 1. Still, this\nbookisprimarilyadatastructuresbook,notaC++book;hence,itdoesnotprovide\nacomprehensive treatmentofC++. Nevertheless, wedonotassumethatthereader\nis necessarily familiar with object-oriented design or with linked structures, such\naslinked lists,sincethesetopicsarecoveredinthecorechapters ofthisbook.\nIntermsofmathematicalbackground,weassumethereaderissomewhatfamil-\niar with topics from high-school mathematics. Even so, in Chapter 4, we discuss\nthesevenmost-importantfunctionsforalgorithmanalysis. Infact,sectionsthatuse\nsomething otherthanoneofthesesevenfunctions areconsidered optional, andare\n\u22c6\nindicated with a star ( ). We give a summary of other useful mathematical facts,\nincluding elementary probability, inAppendixA.\nAbout the Authors\nProfessors Goodrich, Tamassia, and Mount are well-recognized researchers in al-\ngorithms and data structures, having published many papers in this field, with ap-\nplications toInternetcomputing, information visualization, computer security, and\ngeometric computing. They have served as principal investigators in several joint\nprojects sponsored by the National Science Foundation, the Army Research Of-\nfice, the Office of Naval Research, and the Defense Advanced Research Projects\nAgency. Theyarealsoactiveineducational technology research.\nMichael Goodrich received his Ph.D. in Computer Science from Purdue Uni-\nversityin1987. HeiscurrentlyaChancellor\u2019sProfessorintheDepartmentofCom-\nputer Science atUniversity of California, Irvine. Previously, he wasaprofessor at\nJohns Hopkins University. He is an editor for a number of journals in computer\nsciencetheory,computational geometry,andgraphalgorithms. HeisanACMDis-\ntinguishedScientist,aFellowoftheAmericanAssociationfortheAdvancementof\nScience(AAAS),aFulbrightScholar,andaFellowoftheIEEE.Heisarecipientof\ntheIEEEComputerSocietyTechnicalAchievementAward,theACMRecognition\nofServiceAward,andthePondAwardforExcellence inUndergraduate Teaching.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xiii \u2014 #13\ni i\nPreface xiii\nRoberto Tamassia received his Ph.D. in Electrical and Computer Engineering\nfrom the University of Illinois at Urbana-Champaign in 1988. He is the Plastech\nProfessor ofComputer Science andtheChairoftheDepartment ofComputer Sci-\nenceatBrownUniversity. HeisalsotheDirectorofBrown\u2019sCenterforGeometric\nComputing. Hisresearchinterestsincludeinformationsecurity,cryptography,anal-\nysis,design, andimplementation ofalgorithms, graphdrawing,andcomputational\ngeometry. He is an IEEE Fellow and a recipient of the Technical Achievement\nAwardfromtheIEEEComputerSocietyforpioneering thefieldofgraphdrawing.\nHeisaneditorofseveraljournalsingeometricandgraphalgorithms. Hepreviously\nservedontheeditorial boardofIEEETransactions onComputers.\nDavid Mount received his Ph.D.inComputer Science from Purdue University\nin 1983. He is currently a professor in the Department of Computer Science at\nthe University of Maryland with a joint appointment in the University of Mary-\nland\u2019sInstituteforAdvancedComputerStudies. Heisanassociate editorforACM\nTransactions on Mathematical Software and the International Journal of Compu-\ntational Geometry and Applications. Heis the recipient of twoACM Recognition\nofServiceAwards.\nIn addition to their research accomplishments, the authors also have extensive\nexperience intheclassroom. Forexample, Dr.Goodrich hastaught data structures\nand algorithms courses, including Data Structures as a freshman-sophomore level\ncourseandIntroductiontoAlgorithmsasanupper-levelcourse. Hehasearnedsev-\neralteachingawardsinthiscapacity. Histeachingstyleistoinvolvethestudentsin\nlivelyinteractiveclassroomsessionsthatbringouttheintuitionandinsightsbehind\ndata structuring and algorithmic techniques. Dr. Tamassia has taught Data Struc-\ntures and Algorithms as an introductory freshman-level course since 1988. One\nthing that has set his teaching style apart is his effective use of interactive hyper-\nmedia presentations integrated with the Web. Dr. Mount has taught both the Data\nStructures and the Algorithms courses at the University of Maryland since 1985.\nHehaswonanumberofteachingawardsfromPurdueUniversity,theUniversityof\nMaryland, and the Hong Kong University of Science and Technology. His lecture\nnotesandhomeworkexercisesforthecoursesthathehastaughtarewidelyusedas\nsupplementary learning materialbystudents andinstructors atotheruniversities.\nAcknowledgments\nThereareanumberofindividuals whohavemadecontributions tothisbook.\nWe are grateful to all our research collaborators and teaching assistants, who\nprovided feedback on early drafts of chapters and have helped us in developing\nexercises,software,andalgorithmanimationsystems. Therehavebeenanumberof\nfriendsandcolleagueswhosecommentshaveleadtoimprovementsinthetext. We\nareparticularlythankfultoMichaelGoldwasserforhismanyvaluablesuggestions.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xiv \u2014 #14\ni i\nxiv Preface\nWeare also grateful toKaren Goodrich, Art Moorshead, Scott Smith, and Ioannis\nTollisfortheirinsightful comments.\nWe are also truly indebted to the outside reviewers and readers for their co-\npious comments, emails, and constructive criticism, which were extremely use-\nful in writing this edition. We specifically thank the following reviewers for their\ncomments and suggestions: Divy Agarwal, University of California, Santa Bar-\nbara; TerryAndres, UniversityofManitoba; BobbyBlumofe, University ofTexas,\nAustin; Michael Clancy, University of California, Berkeley; Larry Davis, Univer-\nsity of Maryland; Scott Drysdale, Dartmouth College; Arup Guha, University of\nCentral Florida; Chris Ingram, University of Waterloo; Stan Kwasny, Washington\nUniversity; Calvin Lin, University of Texas at Austin; John Mark Mercer, McGill\nUniversity; LaurentMichel, UniversityofConnecticut; LeonardMyers,California\nPolytechnic State University, San Luis Obispo; David Naumann, Stevens Institute\nof Technology; Robert Pastel, Michigan Technological University; Bina Rama-\nmurthy, SUNY Buffalo; Ken Slonneger, University of Iowa; C.V. Ravishankar,\nUniversity of Michigan; Val Tannen, University of Pennsylvania; Paul Van Ar-\nragon,MessiahCollege;andChristopher Wilson,UniversityofOregon.\nWe are grateful to our editor, Beth Golub, for her enthusiastic support of this\nproject. The team at Wiley has been great. Many thanks go to Mike Berlin, Lil-\nian Brady, Regina Brooks, Paul Crockett, Richard DeLorenzo, Jen Devine, Simon\nDurkin,MichelineFrederick,LisaGee,KatherineHepburn,RachaelLeblond,An-\ndreLegaspi,Madelyn Lesure,FrankLyman,HopeMiller, BridgetMorrisey, Chris\nRuel, Ken Santor, Lauren Sapira, Dan Sayre, Diana Smith, Bruce Spatz, Dawn\nStanley,JeriWarner,andBillZobrist.\nThecomputingsystemsandexcellenttechnicalsupportstaffinthedepartments\nofcomputerscienceatBrownUniversity,UniversityofCalifornia,Irvine,andUni-\nversity of Maryland gave us reliable working environments. This manuscript was\nprepared primarilywiththeLATEXtypesetting package.\nFinally, we would like to warmly thank Isabel Cruz, Karen Goodrich, Jeanine\nMount, Giuseppe DiBattista, FrancoPreparata, Ioannis Tollis, andourparents for\nproviding advice, encouragement, and support atvarious stages of the preparation\nof this book. We also thank them for reminding us that there are things in life\nbeyondwritingbooks.\nMichaelT.Goodrich\nRobertoTamassia\nDavidM.Mount\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xv \u2014 #15\ni i\nContents\n1 A C++ Primer 1\n1.1 Basic C++ Programming Elements . . . . . . . . . . . . . . . 2\n1.1.1 A Simple C++ Program . . . . . . . . . . . . . . . . . . 2\n1.1.2 Fundamental Types . . . . . . . . . . . . . . . . . . . . 4\n1.1.3 Pointers, Arrays, and Structures . . . . . . . . . . . . . 7\n1.1.4 Named Constants, Scope, and Namespaces . . . . . . . 13\n1.2 Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n1.2.1 Changing Types through Casting . . . . . . . . . . . . . 20\n1.3 Control Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n1.4 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n1.4.1 Argument Passing . . . . . . . . . . . . . . . . . . . . . 28\n1.4.2 Overloading and Inlining . . . . . . . . . . . . . . . . . 30\n1.5 Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n1.5.1 Class Structure . . . . . . . . . . . . . . . . . . . . . . 33\n1.5.2 Constructors and Destructors . . . . . . . . . . . . . . . 37\n1.5.3 Classes and Memory Allocation . . . . . . . . . . . . . . 40\n1.5.4 Class Friends and Class Members . . . . . . . . . . . . . 43\n1.5.5 The Standard Template Library . . . . . . . . . . . . . . 45\n1.6 C++ Program and File Organization . . . . . . . . . . . . . . 47\n1.6.1 An Example Program . . . . . . . . . . . . . . . . . . . 48\n1.7 Writing a C++ Program . . . . . . . . . . . . . . . . . . . . . 53\n1.7.1 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n1.7.2 Pseudo-Code . . . . . . . . . . . . . . . . . . . . . . . 54\n1.7.3 Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n1.7.4 Testing and Debugging . . . . . . . . . . . . . . . . . . 57\n1.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n2 Object-Oriented Design 65\n2.1 Goals, Principles, and Patterns . . . . . . . . . . . . . . . . 66\n2.1.1 Object-Oriented Design Goals . . . . . . . . . . . . . . 66\n2.1.2 Object-Oriented Design Principles . . . . . . . . . . . . 67\n2.1.3 Design Patterns . . . . . . . . . . . . . . . . . . . . . . 70\nxv\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xvi \u2014 #16\ni i\nxvi Contents\n2.2 Inheritance and Polymorphism . . . . . . . . . . . . . . . . . 71\n2.2.1 Inheritance in C++ . . . . . . . . . . . . . . . . . . . . . 71\n2.2.2 Polymorphism . . . . . . . . . . . . . . . . . . . . . . . 78\n2.2.3 Examples of Inheritance in C++ . . . . . . . . . . . . . . 79\n2.2.4 Multiple Inheritance and Class Casting . . . . . . . . . . 84\n2.2.5 Interfaces and Abstract Classes . . . . . . . . . . . . . . 87\n2.3 Templates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n2.3.1 Function Templates . . . . . . . . . . . . . . . . . . . . 90\n2.3.2 Class Templates . . . . . . . . . . . . . . . . . . . . . . 91\n2.4 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n2.4.1 Exception Objects . . . . . . . . . . . . . . . . . . . . . 93\n2.4.2 Throwing and Catching Exceptions . . . . . . . . . . . . 94\n2.4.3 Exception Specification . . . . . . . . . . . . . . . . . . 96\n2.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\n3 Arrays, Linked Lists, and Recursion 103\n3.1 Using Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n3.1.1 Storing Game Entries in an Array . . . . . . . . . . . . . 104\n3.1.2 Sorting an Array . . . . . . . . . . . . . . . . . . . . . . 109\n3.1.3 Two-Dimensional Arrays and Positional Games . . . . . 111\n3.2 Singly Linked Lists . . . . . . . . . . . . . . . . . . . . . . . . 117\n3.2.1 Implementing a Singly Linked List . . . . . . . . . . . . 117\n3.2.2 Insertion to the Front of a Singly Linked List . . . . . . 119\n3.2.3 Removal from the Front of a Singly Linked List . . . . . 119\n3.2.4 Implementing a Generic Singly Linked List . . . . . . . . 121\n3.3 Doubly Linked Lists . . . . . . . . . . . . . . . . . . . . . . . 123\n3.3.1 Insertion into a Doubly Linked List . . . . . . . . . . . . 123\n3.3.2 Removal from a Doubly Linked List . . . . . . . . . . . 124\n3.3.3 A C++ Implementation . . . . . . . . . . . . . . . . . . 125\n3.4 Circularly Linked Lists and List Reversal . . . . . . . . . . . 129\n3.4.1 Circularly Linked Lists . . . . . . . . . . . . . . . . . . . 129\n3.4.2 Reversing a Linked List . . . . . . . . . . . . . . . . . . 133\n3.5 Recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\n3.5.1 Linear Recursion . . . . . . . . . . . . . . . . . . . . . . 140\n3.5.2 Binary Recursion . . . . . . . . . . . . . . . . . . . . . 144\n3.5.3 Multiple Recursion . . . . . . . . . . . . . . . . . . . . 147\n3.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n4 Analysis Tools 153\n4.1 The Seven Functions Used in This Book . . . . . . . . . . . 154\n4.1.1 The Constant Function . . . . . . . . . . . . . . . . . . 154\n4.1.2 The Logarithm Function . . . . . . . . . . . . . . . . . 154\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xvii \u2014 #17\ni i\nContents xvii\n4.1.3 The Linear Function . . . . . . . . . . . . . . . . . . . . 156\n4.1.4 The N-Log-N Function . . . . . . . . . . . . . . . . . . 156\n4.1.5 The Quadratic Function . . . . . . . . . . . . . . . . . . 156\n4.1.6 The Cubic Function and Other Polynomials . . . . . . . 158\n4.1.7 The Exponential Function . . . . . . . . . . . . . . . . . 159\n4.1.8 Comparing Growth Rates . . . . . . . . . . . . . . . . . 161\n4.2 Analysis of Algorithms . . . . . . . . . . . . . . . . . . . . . 162\n4.2.1 Experimental Studies . . . . . . . . . . . . . . . . . . . 163\n4.2.2 Primitive Operations . . . . . . . . . . . . . . . . . . . 164\n4.2.3 Asymptotic Notation . . . . . . . . . . . . . . . . . . . 166\n4.2.4 Asymptotic Analysis . . . . . . . . . . . . . . . . . . . . 170\n4.2.5 Using the Big-Oh Notation . . . . . . . . . . . . . . . . 172\n4.2.6 A Recursive Algorithm for Computing Powers . . . . . . 176\n4.2.7 Some More Examples of Algorithm Analysis . . . . . . . 177\n4.3 Simple Justification Techniques . . . . . . . . . . . . . . . . 181\n4.3.1 By Example . . . . . . . . . . . . . . . . . . . . . . . . 181\n4.3.2 The \u201cContra\u201d Attack . . . . . . . . . . . . . . . . . . . 181\n4.3.3 Induction and Loop Invariants . . . . . . . . . . . . . . 182\n4.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n5 Stacks, Queues, and Deques 193\n5.1 Stacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n5.1.1 The Stack Abstract Data Type . . . . . . . . . . . . . . 195\n5.1.2 The STL Stack . . . . . . . . . . . . . . . . . . . . . . 196\n5.1.3 A C++ Stack Interface . . . . . . . . . . . . . . . . . . 196\n5.1.4 A Simple Array-Based Stack Implementation . . . . . . 198\n5.1.5 Implementing a Stack with a Generic Linked List . . . . 202\n5.1.6 Reversing a Vector Using a Stack . . . . . . . . . . . . . 203\n5.1.7 Matching Parentheses and HTML Tags . . . . . . . . . 204\n5.2 Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208\n5.2.1 The Queue Abstract Data Type . . . . . . . . . . . . . 208\n5.2.2 The STL Queue . . . . . . . . . . . . . . . . . . . . . . 209\n5.2.3 A C++ Queue Interface . . . . . . . . . . . . . . . . . . 210\n5.2.4 A Simple Array-Based Implementation . . . . . . . . . . 211\n5.2.5 Implementing a Queue with a Circularly Linked List . . . 213\n5.3 Double-Ended Queues . . . . . . . . . . . . . . . . . . . . . . 217\n5.3.1 The Deque Abstract Data Type . . . . . . . . . . . . . 217\n5.3.2 The STL Deque . . . . . . . . . . . . . . . . . . . . . . 218\n5.3.3 Implementing a Deque with a Doubly Linked List . . . . 218\n5.3.4 Adapters and the Adapter Design Pattern . . . . . . . . 220\n5.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xviii \u2014 #18\ni i\nxviii Contents\n6 List and Iterator ADTs 227\n6.1 Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n6.1.1 The Vector Abstract Data Type . . . . . . . . . . . . . 228\n6.1.2 A Simple Array-Based Implementation . . . . . . . . . . 229\n6.1.3 An Extendable Array Implementation . . . . . . . . . . . 231\n6.1.4 STL Vectors . . . . . . . . . . . . . . . . . . . . . . . . 236\n6.2 Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n6.2.1 Node-Based Operations and Iterators. . . . . . . . . . . 238\n6.2.2 The List Abstract Data Type . . . . . . . . . . . . . . . 240\n6.2.3 Doubly Linked List Implementation . . . . . . . . . . . . 242\n6.2.4 STL Lists . . . . . . . . . . . . . . . . . . . . . . . . . 247\n6.2.5 STL Containers and Iterators . . . . . . . . . . . . . . . 248\n6.3 Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\n6.3.1 The Sequence Abstract Data Type . . . . . . . . . . . . 255\n6.3.2 Implementing a Sequence with a Doubly Linked List . . 255\n6.3.3 Implementing a Sequence with an Array . . . . . . . . . 257\n6.4 Case Study: Bubble-Sort on a Sequence . . . . . . . . . . . 259\n6.4.1 The Bubble-Sort Algorithm . . . . . . . . . . . . . . . . 259\n6.4.2 A Sequence-Based Analysis of Bubble-Sort . . . . . . . . 260\n6.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n7 Trees 267\n7.1 General Trees. . . . . . . . . . . . . . . . . . . . . . . . . . . 268\n7.1.1 Tree Definitions and Properties . . . . . . . . . . . . . . 269\n7.1.2 Tree Functions . . . . . . . . . . . . . . . . . . . . . . . 272\n7.1.3 A C++ Tree Interface . . . . . . . . . . . . . . . . . . . 273\n7.1.4 A Linked Structure for General Trees . . . . . . . . . . . 274\n7.2 Tree Traversal Algorithms . . . . . . . . . . . . . . . . . . . 275\n7.2.1 Depth and Height . . . . . . . . . . . . . . . . . . . . . 275\n7.2.2 Preorder Traversal . . . . . . . . . . . . . . . . . . . . . 278\n7.2.3 Postorder Traversal . . . . . . . . . . . . . . . . . . . . 281\n7.3 Binary Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\n7.3.1 The Binary Tree ADT . . . . . . . . . . . . . . . . . . . 285\n7.3.2 A C++ Binary Tree Interface . . . . . . . . . . . . . . . 286\n7.3.3 Properties of Binary Trees . . . . . . . . . . . . . . . . 287\n7.3.4 A Linked Structure for Binary Trees . . . . . . . . . . . 289\n7.3.5 A Vector-Based Structure for Binary Trees . . . . . . . . 295\n7.3.6 Traversals of a Binary Tree . . . . . . . . . . . . . . . . 297\n7.3.7 The Template Function Pattern . . . . . . . . . . . . . 303\n7.3.8 Representing General Trees with Binary Trees . . . . . . 309\n7.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xix \u2014 #19\ni i\nContents xix\n8 Heaps and Priority Queues 321\n8.1 The Priority Queue Abstract Data Type . . . . . . . . . . . 322\n8.1.1 Keys, Priorities, and Total Order Relations . . . . . . . . 322\n8.1.2 Comparators . . . . . . . . . . . . . . . . . . . . . . . . 324\n8.1.3 The Priority Queue ADT . . . . . . . . . . . . . . . . . 327\n8.1.4 A C++ Priority Queue Interface . . . . . . . . . . . . . . 328\n8.1.5 Sorting with a Priority Queue . . . . . . . . . . . . . . . 329\n8.1.6 The STL priority queue Class . . . . . . . . . . . . . . . 330\n8.2 Implementing a Priority Queue with a List . . . . . . . . . . 331\n8.2.1 A C++ Priority Queue Implementation using a List . . . 333\n8.2.2 Selection-Sort and Insertion-Sort . . . . . . . . . . . . . 335\n8.3 Heaps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337\n8.3.1 The Heap Data Structure . . . . . . . . . . . . . . . . . 337\n8.3.2 Complete Binary Trees and Their Representation . . . . 340\n8.3.3 Implementing a Priority Queue with a Heap . . . . . . . 344\n8.3.4 C++ Implementation . . . . . . . . . . . . . . . . . . . 349\n8.3.5 Heap-Sort . . . . . . . . . . . . . . . . . . . . . . . . . 351\n\u22c6\n8.3.6 Bottom-Up Heap Construction . . . . . . . . . . . . . 353\n8.4 Adaptable Priority Queues . . . . . . . . . . . . . . . . . . . 357\n8.4.1 A List-Based Implementation . . . . . . . . . . . . . . . 358\n8.4.2 Location-Aware Entries . . . . . . . . . . . . . . . . . . 360\n8.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\n9 Hash Tables, Maps, and Skip Lists 367\n9.1 Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368\n9.1.1 The Map ADT . . . . . . . . . . . . . . . . . . . . . . 369\n9.1.2 A C++ Map Interface . . . . . . . . . . . . . . . . . . . 371\n9.1.3 The STL map Class . . . . . . . . . . . . . . . . . . . . 372\n9.1.4 A Simple List-Based Map Implementation . . . . . . . . 374\n9.2 Hash Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . 375\n9.2.1 Bucket Arrays . . . . . . . . . . . . . . . . . . . . . . . 375\n9.2.2 Hash Functions . . . . . . . . . . . . . . . . . . . . . . 376\n9.2.3 Hash Codes . . . . . . . . . . . . . . . . . . . . . . . . 376\n9.2.4 Compression Functions . . . . . . . . . . . . . . . . . . 380\n9.2.5 Collision-Handling Schemes . . . . . . . . . . . . . . . . 382\n9.2.6 Load Factors and Rehashing . . . . . . . . . . . . . . . 386\n9.2.7 A C++ Hash Table Implementation . . . . . . . . . . . . 387\n9.3 Ordered Maps . . . . . . . . . . . . . . . . . . . . . . . . . . 394\n9.3.1 Ordered Search Tables and Binary Search . . . . . . . . 395\n9.3.2 Two Applications of Ordered Maps . . . . . . . . . . . . 399\n9.4 Skip Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 402\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xx \u2014 #20\ni i\nxx Contents\n9.4.1 Search and Update Operations in a Skip List . . . . . . 404\n\u22c6\n9.4.2 A Probabilistic Analysis of Skip Lists . . . . . . . . . 408\n9.5 Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411\n9.5.1 The Dictionary ADT . . . . . . . . . . . . . . . . . . . 411\n9.5.2 A C++ Dictionary Implementation . . . . . . . . . . . . 413\n9.5.3 Implementations with Location-Aware Entries . . . . . . 415\n9.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417\n10 Search Trees 423\n10.1 Binary Search Trees . . . . . . . . . . . . . . . . . . . . . . . 424\n10.1.1 Searching . . . . . . . . . . . . . . . . . . . . . . . . . 426\n10.1.2 Update Operations . . . . . . . . . . . . . . . . . . . . 428\n10.1.3 C++ Implementation of a Binary Search Tree . . . . . . 432\n10.2 AVL Trees. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 438\n10.2.1 Update Operations . . . . . . . . . . . . . . . . . . . . 440\n10.2.2 C++ Implementation of an AVL Tree . . . . . . . . . . . 446\n10.3 Splay Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . 450\n10.3.1 Splaying . . . . . . . . . . . . . . . . . . . . . . . . . . 450\n10.3.2 When to Splay . . . . . . . . . . . . . . . . . . . . . . . 454\n\u22c6\n10.3.3 Amortized Analysis of Splaying . . . . . . . . . . . . 456\n10.4 (2,4) Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . 461\n10.4.1 Multi-Way Search Trees . . . . . . . . . . . . . . . . . . 461\n10.4.2 Update Operations for (2,4) Trees . . . . . . . . . . . . 467\n10.5 Red-Black Trees . . . . . . . . . . . . . . . . . . . . . . . . . 473\n10.5.1 Update Operations . . . . . . . . . . . . . . . . . . . . 475\n10.5.2 C++ Implementation of a Red-Black Tree . . . . . . . . 488\n10.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492\n11 Sorting, Sets, and Selection 499\n11.1 Merge-Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . 500\n11.1.1 Divide-and-Conquer . . . . . . . . . . . . . . . . . . . . 500\n11.1.2 Merging Arrays and Lists . . . . . . . . . . . . . . . . . 505\n11.1.3 The Running Time of Merge-Sort . . . . . . . . . . . . 508\n11.1.4 C++ Implementations of Merge-Sort . . . . . . . . . . . 509\n\u22c6\n11.1.5 Merge-Sort and Recurrence Equations . . . . . . . . . 511\n11.2 Quick-Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . 513\n11.2.1 Randomized Quick-Sort . . . . . . . . . . . . . . . . . . 521\n11.2.2 C++ Implementations and Optimizations . . . . . . . . . 523\n11.3 Studying Sorting through an Algorithmic Lens . . . . . . . 526\n11.3.1 A Lower Bound for Sorting . . . . . . . . . . . . . . . . 526\n11.3.2 Linear-Time Sorting: Bucket-Sort and Radix-Sort . . . . 528\n11.3.3 Comparing Sorting Algorithms . . . . . . . . . . . . . . 531\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xxi \u2014 #21\ni i\nContents xxi\n11.4 Sets and Union/Find Structures . . . . . . . . . . . . . . . . 533\n11.4.1 The Set ADT . . . . . . . . . . . . . . . . . . . . . . . 533\n11.4.2 Mergable Sets and the Template Method Pattern . . . . 534\n11.4.3 Partitions with Union-Find Operations . . . . . . . . . . 538\n11.5 Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542\n11.5.1 Prune-and-Search . . . . . . . . . . . . . . . . . . . . . 542\n11.5.2 Randomized Quick-Select . . . . . . . . . . . . . . . . . 543\n11.5.3 Analyzing Randomized Quick-Select . . . . . . . . . . . 544\n11.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 545\n12 Strings and Dynamic Programming 553\n12.1 String Operations . . . . . . . . . . . . . . . . . . . . . . . . 554\n12.1.1 The STL String Class . . . . . . . . . . . . . . . . . . . 555\n12.2 Dynamic Programming . . . . . . . . . . . . . . . . . . . . . 557\n12.2.1 Matrix Chain-Product . . . . . . . . . . . . . . . . . . . 557\n12.2.2 DNA and Text Sequence Alignment . . . . . . . . . . . 560\n12.3 Pattern Matching Algorithms . . . . . . . . . . . . . . . . . 564\n12.3.1 Brute Force . . . . . . . . . . . . . . . . . . . . . . . . 564\n12.3.2 The Boyer-Moore Algorithm . . . . . . . . . . . . . . . 566\n12.3.3 The Knuth-Morris-Pratt Algorithm . . . . . . . . . . . . 570\n12.4 Text Compression and the Greedy Method . . . . . . . . . 575\n12.4.1 The Huffman-Coding Algorithm . . . . . . . . . . . . . 576\n12.4.2 The Greedy Method . . . . . . . . . . . . . . . . . . . . 577\n12.5 Tries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 578\n12.5.1 Standard Tries . . . . . . . . . . . . . . . . . . . . . . . 578\n12.5.2 Compressed Tries . . . . . . . . . . . . . . . . . . . . . 582\n12.5.3 Suffix Tries . . . . . . . . . . . . . . . . . . . . . . . . 584\n12.5.4 Search Engines . . . . . . . . . . . . . . . . . . . . . . 586\n12.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587\n13 Graph Algorithms 593\n13.1 Graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 594\n13.1.1 The Graph ADT . . . . . . . . . . . . . . . . . . . . . . 599\n13.2 Data Structures for Graphs . . . . . . . . . . . . . . . . . . . 600\n13.2.1 The Edge List Structure. . . . . . . . . . . . . . . . . . 600\n13.2.2 The Adjacency List Structure . . . . . . . . . . . . . . . 603\n13.2.3 The Adjacency Matrix Structure . . . . . . . . . . . . . 605\n13.3 Graph Traversals . . . . . . . . . . . . . . . . . . . . . . . . . 607\n13.3.1 Depth-First Search . . . . . . . . . . . . . . . . . . . . 607\n13.3.2 Implementing Depth-First Search . . . . . . . . . . . . . 611\n13.3.3 A Generic DFS Implementation in C++ . . . . . . . . . . 613\n\u22c6\n13.3.4 Polymorphic Objects and Decorator Values . . . . . . 621\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page xxii \u2014 #22\ni i\nxxii Contents\n13.3.5 Breadth-First Search . . . . . . . . . . . . . . . . . . . 623\n13.4 Directed Graphs . . . . . . . . . . . . . . . . . . . . . . . . . 626\n13.4.1 Traversing a Digraph . . . . . . . . . . . . . . . . . . . 628\n13.4.2 Transitive Closure . . . . . . . . . . . . . . . . . . . . . 630\n13.4.3 Directed Acyclic Graphs . . . . . . . . . . . . . . . . . . 633\n13.5 Shortest Paths . . . . . . . . . . . . . . . . . . . . . . . . . . 637\n13.5.1 Weighted Graphs . . . . . . . . . . . . . . . . . . . . . 637\n13.5.2 Dijkstra\u2019s Algorithm . . . . . . . . . . . . . . . . . . . . 639\n13.6 Minimum Spanning Trees . . . . . . . . . . . . . . . . . . . . 645\n13.6.1 Kruskal\u2019s Algorithm . . . . . . . . . . . . . . . . . . . . 647\n13.6.2 The Prim-Jarn\u00b4\u0131k Algorithm . . . . . . . . . . . . . . . . 651\n13.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 654\n14 Memory Management and B-Trees 665\n14.1 Memory Management . . . . . . . . . . . . . . . . . . . . . . 666\n14.1.1 Memory Allocation in C++ . . . . . . . . . . . . . . . . 669\n14.1.2 Garbage Collection . . . . . . . . . . . . . . . . . . . . 671\n14.2 External Memory and Caching . . . . . . . . . . . . . . . . . 673\n14.2.1 The Memory Hierarchy . . . . . . . . . . . . . . . . . . 673\n14.2.2 Caching Strategies . . . . . . . . . . . . . . . . . . . . 674\n14.3 External Searching and B-Trees . . . . . . . . . . . . . . . . 679\n14.3.1 (a,b) Trees . . . . . . . . . . . . . . . . . . . . . . . . 680\n14.3.2 B-Trees . . . . . . . . . . . . . . . . . . . . . . . . . . 682\n14.4 External-Memory Sorting . . . . . . . . . . . . . . . . . . . . 683\n14.4.1 Multi-Way Merging . . . . . . . . . . . . . . . . . . . . 684\n14.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 685\nA Useful Mathematical Facts 689\nBibliography 697\nIndex 702\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 1 \u2014 #23\ni i\nChapter\n1\nA C++ Primer\nContents\n1.1 Basic C++ Programming Elements . . . . . . . . . . . 2\n1.1.1 A Simple C++ Program . . . . . . . . . . . . . . . . 2\n1.1.2 Fundamental Types . . . . . . . . . . . . . . . . . . 4\n1.1.3 Pointers, Arrays, and Structures . . . . . . . . . . . 7\n1.1.4 Named Constants, Scope, and Namespaces . . . . . 13\n1.2 Expressions . . . . . . . . . . . . . . . . . . . . . . . . 16\n1.2.1 Changing Types through Casting . . . . . . . . . . . 20\n1.3 Control Flow . . . . . . . . . . . . . . . . . . . . . . . 23\n1.4 Functions . . . . . . . . . . . . . . . . . . . . . . . . . 26\n1.4.1 Argument Passing . . . . . . . . . . . . . . . . . . . 28\n1.4.2 Overloading and Inlining . . . . . . . . . . . . . . . 30\n1.5 Classes . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n1.5.1 Class Structure . . . . . . . . . . . . . . . . . . . . 33\n1.5.2 Constructors and Destructors . . . . . . . . . . . . . 37\n1.5.3 Classes and Memory Allocation . . . . . . . . . . . . 40\n1.5.4 Class Friends and Class Members . . . . . . . . . . . 43\n1.5.5 The Standard Template Library . . . . . . . . . . . . 45\n1.6 C++ Program and File Organization . . . . . . . . . . 47\n1.6.1 An Example Program . . . . . . . . . . . . . . . . . 48\n1.7 Writing a C++ Program . . . . . . . . . . . . . . . . . 53\n1.7.1 Design . . . . . . . . . . . . . . . . . . . . . . . . . 54\n1.7.2 Pseudo-Code . . . . . . . . . . . . . . . . . . . . . 54\n1.7.3 Coding . . . . . . . . . . . . . . . . . . . . . . . . . 55\n1.7.4 Testing and Debugging . . . . . . . . . . . . . . . . 57\n1.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 60\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 2 \u2014 #24\ni i\n2 Chapter1. AC++Primer\n1.1 Basic C++ Programming Elements\nBuilding data structures and algorithms requires communicating instructions to a\ncomputer, and an excellent way to perform such communication is using a high-\nlevel computer language, such as C++. C++ evolved from the programming lan-\nguage C, and has, over time, undergone further evolution and development from\nits original definition. It has incorporated many features that were not part of C,\nsuchassymbolicconstants, in-linefunctionsubstitution, referencetypes,paramet-\nric polymorphism through templates, and exceptions (which are discussed later).\nAs a result, C++ has grown to be a complex programming language. Fortunately,\nwedo not need to know every detail of this sophisticated language in order to use\niteffectively.\nIn this chapter and the next, we present a quick tour of the C++ programming\nlanguageanditsfeatures. Itwouldbeimpossibletopresentacompletepresentation\nof the language in this short space, however. Since we assume that the reader is\nalready familiar with programming with some other language, such as C or Java,\nourdescriptions areshort. Thischapter presents thelanguage\u2019s basicfeatures, and\nin the following chapter, we concentrate on those features that are important for\nobject-oriented programming.\nC++isapowerful and flexibleprogramming language, which wasdesigned to\nbuild upon the constructs of the C programming language. Thus, with minor ex-\nceptions,C++isasupersetoftheCprogramminglanguage. C++sharesC\u2019sability\nto deal efficiently with hardware at the level of bits, bytes, words, addresses, etc.\nIn addition, C++ adds several enhancements over C (which motivates the name\n\u201cC++\u201d), with the principal enhancement being the object-oriented concept of a\nclass.\nA class is a user-defined type that encapsulates many important mechanisms\nsuchasguaranteedinitialization, implicittypeconversion,controlofmemoryman-\nagement, operator overloading, and polymorphism (which are allimportant topics\nthat are discussed later in this book). A class also has the ability to hide its un-\nderlying data. Thisallows aclass toconceal its implementation details and allows\nuserstoconceptualize theclassintermsofawell-definedinterface. Classesenable\nprogrammers tobreakanapplication upintosmall, manageable pieces, orobjects.\nTheresulting programsareeasiertounderstand andeasiertomaintain.\n1.1.1 A Simple C++ Program\nLikemanyprogramming languages, creating and running aC++ program requires\nseveralsteps. First,wecreateaC++sourcefileintowhichweenterthelinesofour\nprogram. After wesave this file, wethen run aprogram, called a compiler, which\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 3 \u2014 #25\ni i\n1.1. BasicC++ProgrammingElements 3\ncreates a machine-code interpretation of this program. Another program, called\na linker (which is typically invoked automatically by the compiler), includes any\nrequired library code functions needed and produces the final machine-executable\nfile. Inordertorunourprogram,theuserrequeststhatthesystemexecutethisfile.\nLetusconsideraverysimpleprogramtoillustratesomeofthelanguage\u2019sbasic\nelements. Don\u2019tworryifsomeelementsinthisexamplearenotfullyexplained. We\ndiscussthemingreaterdepthlaterinthischapter. Thisprograminputstwointegers,\nwhicharestoredinthevariablesxandy. Itthencomputestheirsumandstoresthe\nresult in avariable sum, and finally itoutputs this sum. (The line numbers are not\npartoftheprogram;theyarejustforourreference.)\n1 #include <cstdlib>\n2 #include <iostream>\n3 /* This program inputs two numbers x and y and outputs their sum */\n4 int main( )\n{\n5 int x, y;\n6 std::cout << \"Please enter two numbers: \";\n7 std::cin >> x >> y; // input x and y\n8 int sum = x + y; // compute their sum\n9 std::cout << \"Their sum is \" << sum << std::endl;\n10 return EXIT SUCCESS; // terminate successfully\n11\n}\nAfewthingsaboutthisC++programshouldbefairlyobvious. First,comments\nare indicated with twoslashes (//). Each such comment extends to the end of the\nline. Longer block comments are enclosed between /* and */. Block comments\nmay extend over multiple lines. The quantities manipulated by this program are\nstored in three integer variables, x, y, and sum. The operators \u201c>>\u201d and \u201c<<\u201d are\nusedforinputandoutput, respectively.\nProgram Elements\nLet us consider the elements of the above program in greater detail. Lines 1 and\n2 input the two header files, \u201ccstdlib\u201d and \u201ciostream.\u201d Header files are used to\nprovide special declarations and definitions, which are of use to the program. The\nfirstprovidessomestandardsystemdefinitions,andthesecondprovidesdefinitions\nneededforinputandoutput.\nThe initial entry point for C++ programs is the function main. The statement\n\u201cint main( )\u201donline4declaresmaintobeafunction thattakesnoarguments and\nreturns an integer result. (In general, the main function may be called with the\ncommand-line arguments, but we don\u2019t discuss this.) The function body is given\nwithin curly braces ( ... ), which start on line 4 and end on line 11. The program\n{ }\nterminateswhenthereturnstatementonline10isexecuted.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 4 \u2014 #26\ni i\n4 Chapter1. AC++Primer\nBy convention, the function main returns the value zero to indicate success\nand returns anonzero value to indicate failure. Theinclude filecstdlib defines the\nconstant EXIT SUCCESStobe 0. Thus, the return statement on line 10 returns 0,\nindicating asuccessful termination.\nThe statement on line 6 prints a string using the output operator (\u201c<<\u201d). The\nstatementonline7inputsthevaluesofthevariablesxandyusingtheinputoperator\n(\u201c>>\u201d). Thesevariablevaluescouldbesupplied,forexample,bythepersonrunning\nourprogram. Thenamestd::coutindicatesthatoutputistobesenttothestandard\noutputstream. Therearetwoother important I/Ostreams inC++: standard input\niswhereinputistypicallyread,andstandarderroriswhereerroroutputiswritten.\nThesearedenotedstd::cinandstd::cerr,respectively.\nThe prefix \u201cstd::\u201d indicates that these objects are from the system\u2019s standard\nlibrary. Weshould include this prefix when referring to objects from the standard\nlibrary. Nonetheless, it is possible to inform the compiler that we wish to use\nobjectsfromthestandardlibrary\u2014andsoomitthisprefix\u2014byutilizingthe\u201cusing\u201d\nstatementasshownbelow.\n#include <iostream>\nusing namespace std; // makes std:: available\n// ...\ncout << \"Please enter two numbers: \"; // (std:: is not needed)\ncin >> x >> y;\nWe discuss the using statement later in Section 1.1.4. In order to keep our\nexamples short, we often omit the include and using statements when displaying\nC++code. Wealsouse\u201c//...\u201dtoindicate thatsomecodehasbeenomitted.\nReturning to our simple example C++ program, we note that the statement on\nline9outputsthevalueofthevariablesum,whichinthiscasestoresthecomputed\nsum of x and y. By default, the output statement does not produce an end of line.\nThespecialobjectstd::endlgeneratesaspecialend-of-line character. Anotherway\ntogenerate anendoflineistooutputthenewlinecharacter, \u2019\\n\u2019.\nIf run interactively, that is, with the user inputing values when requested to\ndo so, this program\u2019s output would appear as shown below. The user\u2019s input is\nindicated belowinblue.\nPlease enter two numbers: 7 35\nTheir sum is 42\n1.1.2 Fundamental Types\nWecontinue our exploration of C++by discussing the language\u2019s basic data types\nand how these types are represented as constants and variables. The fundamental\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 5 \u2014 #27\ni i\n1.1. BasicC++ProgrammingElements 5\ntypesarethebasicbuildingblocksfromwhichmorecomplextypesareconstructed.\nTheyinclude thefollowing.\nbool Booleanvalue,eithertrueorfalse\nchar character\nshort shortinteger\nint integer\nlong longinteger\nfloat single-precision floating-point number\ndouble double-precision floating-point number\nThere is also an enumeration, or enum, type to represent aset of discrete val-\nues. Together, enumerations and the types bool, char, and int are called integral\ntypes. Finally, there is a special type void, which explicitly indicates the absence\nofanytypeinformation. Wenowdiscuss eachofthesetypesingreaterdetail.\nCharacters\nAchar variable holdsasingle character. Achar inC++istypically 8-bits, butthe\nexactnumberofbitsusedforachar variableisdependent ontheparticular imple-\nmentation. By allowing different implementations to define the meaning of basic\ntypes,suchaschar,C++cantailoritsgeneratedcodetoeachmachinearchitecture\nand so achieve maximum efficiency. This flexibility can be asource of frustration\nforprogrammerswhowanttowritemachine-independent programs, however.\nA literal is a constant value appearing in a program. Character literals are\nenclosed in single quotes, as in \u2019a\u2019, \u2019Q\u2019, and \u2019+\u2019. A backslash ( ) is used to\n\\\nspecifyanumberofspecialcharacter literalsasshownbelow.\n\u2019\\n\u2019 newline \u2019\\t\u2019 tab\n\u2019\\b\u2019 backspace \u2019\\0\u2019 null\n\u2019\\\u2019\u2019 singlequote \u2019\\\"\u2019 doublequote\n\u2019\\\\\u2019 backslash\nThe null character, \u2019\\0\u2019, is sometimes used to indicate the end of a string of\ncharacters. Everycharacterisassociatedwithanintegercode. Thefunctionint(ch)\nreturnstheintegervalueassociated withacharacter variablech.\nIntegers\nAn int variable holds an integer. Integers come in three sizes: short int, (plain)\nint,andlong int. Theterms\u201cshort\u201dand\u201clong\u201daresynonymsfor\u201cshort int\u201dand\n\u201clong int,\u201drespectively. Decimalnumberssuchas0,25,98765,and-3areoftype\nint. Thesuffix\u201cl\u201dor\u201cL\u201dcanbeaddedtoindicatealonginteger,asin123456789L.\nOctal (base 8) constants are specified by prefixing the number with the zero digit,\nandhexadecimal(base16)constantscanbespecifiedbyprefixingthenumberwith\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 6 \u2014 #28\ni i\n6 Chapter1. AC++Primer\n\u201c0x.\u201d Forexample,theliterals256,0400, and0x100allrepresent theintegervalue\n256(indecimal).\nWhen declaring a variable, we have the option of providing a definition, or\ninitial value. If no definition is given, the initial value is unpredictable, so it is\nimportantthateachvariablebeassignedavaluebeforebeingused. Variablenames\nmay consist of any combination of letters, digits, or the underscore ( ) character,\nbutthefirstcharacter cannot beadigit. Herearesomeexamplesofdeclarations of\nintegralvariables.\nshort n; // n\u2019s value is undefined\nint octalNumber = 0400; // 400 (base 8) = 256 (base 10)\nchar newline character = \u2019\\n\u2019;\nlong BIGnumber = 314159265L;\nshort aSTRANGE 1234 variABlE NaMe;\nAlthough it is legal to start a variable name with an underscore, it is best to avoid\nthispractice, sincesomeC++compilers usethisconvention fordefining their own\ninternalidentifiers.\nC++doesnotspecifytheexactnumberofbitsineachtype,butashortisatleast\n16 bits, and along is at least 32 bits. In fact, there is no requirement that long be\nstrictlylongerthanshort(butitcannotbeshorter!). GivenatypeT,theexpression\nsizeof(T)returnsthesizeoftypeT,expressedassomenumberofmultiplesofthe\nsize of char. For example, on typical systems, a char is 8 bits long, and an int is\n32bitslong,andhencesizeof(int)is4.\nEnumerations\nAnenumeration isauser-defined typethatcanholdanyofasetofdiscrete values.\nOnce defined, enumerations behave much like an integer type. A common use\nof enumerations is to provide meaningful names to a set of related values. Each\nelement of an enumeration is associated with an integer value. By default, these\nvalues count up from 0, but it is also possible to define explicit constant values as\nshownbelow.\nenum Day SUN, MON, TUE, WED, THU, FRI, SAT ;\n{ }\nenum Mood HAPPY = 3, SAD = 1, ANXIOUS = 4, SLEEPY = 2 ;\n{ }\nDay today = THU; // today may be any of MON ... SAT\nMood myMood = SLEEPY; // myMood may be HAPPY, ..., SLEEPY\nSincewedidnotspecifyvalues,SUNwouldbeassociatedwith0,MONwith1,\nandsoon. Asahinttothereader,wewriteenumerationnamesandotherconstants\nwithallcapitalletters.\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 7 \u2014 #29\ni i\n1.1. BasicC++ProgrammingElements 7\nFloating Point\nAvariable oftypefloatholdsasingle-precision floating-point number, andavari-\nable of type double holds a double-precision floating-point number. As it does\nwithintegers,C++leavesundefinedtheexactnumberofbitsineachofthefloating\npoint types. By default, floating point literals, such as 3.14159 and -1234.567 are\nof type double. Scientific or exponential notation may by specified using either\n\u201ce\u201d or\u201cE\u201dtoseparate themantissa from theexponent, asin3.14E5, which means\n3.14 105. To force a literal to be a float, add the suffix \u201cf\u201d or \u201cF,\u201d as in 2.0f or\n\u00d7\n1.234e-3F.\n1.1.3 Pointers, Arrays, and Structures\nWenextdiscusshowtocombinefundamental typestoformmorecomplexones.\nPointers\nEach program variable is stored in the computer\u2019s memory at some location, or\naddress. A pointer is a variable that holds the value of such an address. Given a\ntype T, the type T* denotes a pointer to a variable of type T. For example, int*\ndenotesapointertoaninteger.\nTwo essential operators are used to manipulate pointers. The first returns the\naddress of an object in memory, and the second returns the contents of a given\naddress. In C++ the first task is performed by the address-of operator, &. For\nexampleifxisanintegervariableinyourprogram&xistheaddressofxinmemory.\nAccessing anobject\u2019s value from its address iscalled dereferencing. This isdone\nusing the * operator. For example, if we were to declare q to be a pointer to an\ninteger (that is, int*) and then set q = &x, we could access x\u2019s value with *q.\nAssigninganintegervalueto*qeffectivelychanges thevalueofx.\nConsider, for example, the code fragment below. Thevariable p isdeclared to\nbe a pointer to a char, and is initialized to point to the variable ch. Thus, *p is\nanother way of referring to ch. Observe that when the value of ch is changed, the\nvalueof*pchanges aswell.\nchar ch = \u2019Q\u2019;\nchar* p = &ch; // p holds the address of ch\ncout << *p; // outputs the character \u2019Q\u2019\nch = \u2019Z\u2019; // ch now holds \u2019Z\u2019\ncout << *p; // outputs the character \u2019Z\u2019\n*p = \u2019X\u2019; // ch now holds \u2019X\u2019\ncout << ch; // outputs the character \u2019X\u2019\nWeshall see that pointers are very useful when building data structures where ob-\njects arelinked tooneanother through theuseofpointers. Pointers neednotpoint\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 8 \u2014 #30\ni i\n8 Chapter1. AC++Primer\nonly to fundamental types, such as char and int\u2014theymayalso point tocomplex\ntypes and even to functions. Indeed, the popularity of C++ stems in part from its\nabilitytohandlelow-levelentitieslikepointers.\nItisusefultohaveapointervaluethatpointstonothing, thatis,anullpointer.\nByconvention, suchapointerisassignedthevaluezero. Anattempttodereference\nanullpointer results inarun-time error. AllC++implementations defineaspecial\nsymbol NULL, which is equal to zero. This definition is activated by inserting the\nstatement\u201c#include <cstdlib>\u201dinthebeginning ofaprogramfile.\nWe mentioned earlier that the special type void is used to indicate no type\ninformation at all. Although we cannot declare a variable to be of type void, we\ncandeclare apointer tobeoftype void*. Suchapointer can point toavariable of\nanytype. Sincethecompilerisunabletocheckthecorrectness ofsuchreferences,\nthe use of void* pointers is strongly discouraged, except in unusual cases where\ndirectaccesstothecomputer\u2019s memoryisneeded.\nBewarewhendeclaring twoormorepointers onthesameline. The*operator\nCaution binds with the variable name, not with the type name. Consider the following\nmisleading declaration.\nint* x, y, z; // same as: int* x; int y; int z;\nThisdeclares one pointer variable x, but the other twovariables areplain integers.\nThesimplestwaytoavoidthisconfusion istodeclareonevariableperstatement.\nArrays\nAn array is a collection of elements of the same type. Given any type T and a\nconstant N, a variable of type T[N] holds an array of N elements, each of type T.\nEach element of the array is referenced by its index, that is, a number from 0 to\nN 1. The following statements declare two arrays; one holds three doubles and\n\u2212\ntheotherholds10doublepointers.\ndouble f[5]; // array of 5 doubles: f[0], ..., f[4]\nint m[10]; // array of 10 ints: m[0], ..., m[9]\nf[4] = 2.5;\nm[2] = 4;\ncout << f[m[2]]; // outputs f[4], which is 2.5\nOnce declared, it is not possible to increase the number of elements in an array.\nAlso, C++ provides no built-in run-time checking for array subscripting out of\nbounds. This decision is consistent with C++\u2019s general philosophy of not intro-\nducing any feature that would slow the execution of aprogram. Indexing an array\noutside of its declared bounds is a common programming error. Such an error of-\nten occurs \u201csilently,\u201d and only much later are its effects noticed. In Section 1.5.5,\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 9 \u2014 #31\ni i\n1.1. BasicC++ProgrammingElements 9\nwe see that the vector type of the C++ Standard Template Library (STL)provides\nmany of the capabilities of a more complete array type, including run-time index\nchecking andtheabilitytodynamically change thearray\u2019s size.\nA two-dimensional array is implemented asan \u201carray of arrays.\u201d Forexample\n\u201cint A[15][30]\u201d declares A to be an array of 30 objects, each of which is an array\nof 15 integers. An element in such an array is indexed as A[i][j], where i is in the\nrange0to14andjisintherange0to29.\nWhendeclaring anarray,wecaninitialize itsvaluesbyenclosing theelements\nin curly braces ( ... ). When doing so, we do not have to specify the size of the\n{ }\narray,sincethecompilercanfigurethisout.\nint a[] = 10, 11, 12, 13 ; // declares and initializes a[4]\n{ }\nbool b[] = false, true ; // declares and initializes b[2]\n{ }\nchar c[] = \u2019c\u2019, \u2019a\u2019, \u2019t\u2019 ; // declares and initializes c[3]\n{ }\nJust as it is possible to declare an array of integers, it is possible to declare an\narray of pointers to integers. For example, int* r[17] declares an array r consist-\ning of 17 pointers to objects of type int. Once initialized, we can dereference an\nelement of this array using the * operator, for example, *r[16] is the value of the\nintegerpointedtobythelastelementofthisarray.\nPointers and Arrays\nThere is an interesting connection between arrays and pointers, which C++ inher-\nited from the C programming language\u2014the name of an array is equivalent to a\npointer to the array\u2019s initial element and vice versa. In the example below, c is\nan array of characters, and p and q are pointers to the first element of c. They all\nbehaveessentially thesame,however.\nchar c[] = \u2019c\u2019, \u2019a\u2019, \u2019t\u2019 ;\n{ }\nchar* p = c; // p points to c[0]\nchar* q = &c[0]; // q also points to c[0]\ncout << c[2] << p[2] << q[2]; // outputs \u201cttt\u201d\nThisequivalence between array namesand pointers can beconfusing, but ithelps\nCaution toexplain manyofC++\u2019sapparent mysteries. Forexample,giventwoarrayscand\nd,thecomparison(c ==d)doesnottestwhetherthecontentsofthetwoarraysare\nequal. Ratheritcomparestheaddresses oftheirinitialelements,whichisprobably\nnot what the programmer had in mind. If there is a need to perform operations\non entire arrays (such as copying one array to another) it is a good idea to use the\nvector class, which is part of C++\u2019s Standard Template Library. We discuss these\nconcepts inSection1.5.5.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 10 \u2014 #32\ni i\n10 Chapter1. AC++Primer\nStrings\nA string literal, such as \"Hello World\",is represented as a fixed-length array of\ncharacters that ends with the null character. Character strings represented in this\nway are called C-style strings, since they were inherited from C. Unfortunately,\nthisrepresentation alonedoesnotprovidemanystringoperations, suchasconcate-\nnation and comparison. It also possesses all the peculiarities of C++ arrays, as\nmentioned earlier.\nFor this reason, C++ provides a string type as part of its Standard Template\nLibrary (STL). When we need to distinguish, we call these STL strings. In order\nto use STL strings it is necessary to include the header file <string>. Since STL\nstrings are part of the standard namespace (see Section 1.1.4), their full name is\nstd::string. By adding the statement \u201cusing std::string,\u201d we inform the compiler\nthat we want to access this definition directly, so we can omit the \u201cstd::\u201d prefix.\nSTLstringsmaybeconcatenatedusingthe+operator,theymaybecomparedwith\neach other using lexicographic (or dictionary) order, and they may be input and\noutputusingthe>>and<<operators, respectively. Forexample:\n#include <string>\nusing std::string;\n// ...\nstring s = \"to be\";\nstring t = \"not \" + s; // t = \u201cnot to be\u201d\nstring u = s + \" or \" + t; // u = \u201cto be or not to be\u201d\nif (s > t) // true: \u201cto be\u201d > \u201cnot to be\u201d\ncout << u; // outputs \u201cto be or not to be\u201d\nThereareotherSTLstringoperations,aswell. Forexample,wecanappendone\nstring to another using the += operator. Also, strings may be indexed like arrays\nand the number of characters in a string s is given by s.size(). Since some library\nfunctions require the old C-style strings, there is a conversion function s.c str(),\nwhichreturnsapointertoaC-stylestring. Herearesomeexamples:\nstring s = \"John\"; // s = \u201cJohn\u201d\nint i = s.size(); // i = 4\nchar c = s[3]; // c = \u2019n\u2019\ns += \" Smith\"; // now s = \u201cJohn Smith\u201d\nTheC++STLprovidesmanyotherstringoperators including operators forex-\ntracting, searching for, andreplacing substrings. Wediscuss someofthese inSec-\ntion1.5.5.\nC-Style Structures\nA structure is useful for storing an aggregation of elements. Unlike an array, the\nelements of a structure may be of different types. Each member, or field, of a\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 11 \u2014 #33\ni i\n1.1. BasicC++ProgrammingElements 11\nstructureisreferredtobyagivenname. Forexample,considerthefollowingstruc-\nture for storing information about an airline passenger. The structure includes the\npassenger\u2019s name, meal preference, and information as to whether this passenger\nis in the frequent flyer program. We create an enumerated type to handle meal\npreferences.\nenum MealType NO PREF, REGULAR, LOW FAT, VEGETARIAN ;\n{ }\nstruct Passenger\n{\nstring name; // passenger name\nMealType mealPref; // meal preference\nbool isFreqFlyer; // in the frequent flyer program?\nstring freqFlyerNo; // the passenger\u2019s freq. flyer number\n;\n}\nThis defines a new type called Passenger. Let us declare and initialize a variable\nnamed\u201cpass\u201dofthistype.\nPassenger pass = \"John Smith\", VEGETARIAN, true, \"293145\" ;\n{ }\nThe individual members of the structure are accessed using the member selection\noperator,whichhastheformstruct name.member. Forexample,wecouldchange\nsomeoftheabovefieldsasfollows.\npass.name = \"Pocahontas\"; // change name\npass.mealPref = REGULAR; // change meal preference\nStructuresofthesametypemaybeassignedtooneanother. Forexample,ifp1and\np2areoftypePassenger,thenp2 = p1copiestheelementsofp1top2.\nWhat we have discussed so far might be called a C-style structure. C++ pro-\nvides a much more powerful and flexible construct called a class, in which both\ndataandfunctions canbecombined. WediscussclassesinSection1.5.\nPointers, Dynamic Memory, and the \u201cnew\u201d Operator\nWeoften findit useful in data structures to create objects dynamically as the need\narises. TheC++ run-time system reserves a large block of memory called the free\nstore, for this reason. (This memory is also sometimes called heap memory, but\nthis should not be confused with the heap data structure, which is discussed in\nChapter8.) Theoperator new dynamically allocates thecorrect amountofstorage\nforanobjectofagiventypefromthefreestoreandreturnsapointertothisobject.\nThatis,thevalueofthispointeristheaddresswherethisobjectresidesinmemory.\nIndeed, C++allowsforpointervariables toanydatatype,eventootherpointers or\ntoindividual cellsinanarray.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 12 \u2014 #34\ni i\n12 Chapter1. AC++Primer\nForexample,supposethatinourairlinesystemweencounter anewpassenger.\nWe would like to dynamically create a new instance using the new operator. Let\np be a pointer to a Passenger structure. This implies that *p refers to the actual\nstructure;hence,wecouldaccessoneofitsmembers,saythemealPreffield,using\nthe expression (*p).mealPref. Because complex objects like structures are often\nallocated dynamically, C++ provides a shorter way to access members using the\n\u201c->\u201doperator.\npointer name->member isequivalent to (*pointer name).member\nFor example, we could allocate a new passenger object and initialize its members\nasfollows.\nPassenger *p;\n// ...\np = new Passenger; // p points to the new Passenger\np >name = \"Pocahontas\"; // set the structure members\n\u2212\np >mealPref = REGULAR;\n\u2212\np >isFreqFlyer = false;\n\u2212\np >freqFlyerNo = \"NONE\";\n\u2212\nItwouldbenaturaltowonderwhetherwecaninitializethemembersusingthecurly\nbrace ( ... ) notation used above. The answer is no, but wewill see another more\n{ }\nconvenient way of initializing members when we discuss classes and constructors\ninSection1.5.2.\nThisnewpassengerobjectcontinuestoexistinthefreestoreuntilitisexplicitly\ndeleted\u2014aprocessthatisdoneusingthedeleteoperator,whichdestroystheobject\nandreturnsitsspacetothefreestore.\ndelete p; // destroy the object p points to\nThedeleteoperatorshouldonlybeappliedtoobjectsthathavebeenallocated\nthroughnew. Sincetheobjectatp\u2019saddresswasallocatedusingthenewoperator,\nthe C++ run-time system knows how much memory to deallocate for this delete\nstatement. Unlike some programming languages such as Java, C++ does not pro-\nvide automatic garbage collection. This means that C++ programmers have the\nresponsibility ofexplicitly deleting alldynamically allocated objects.\nArrayscanalsobeallocatedwithnew. Whenthisisdone,thesystemallocator\nreturns a pointer to the first element of the array. Thus, a dynamically allocated\narraywithelementsoftypeTwouldbedeclaredbeingoftype*T.Arraysallocated\nin this manner cannot be deallocated using the standard delete operator. Instead,\nthe operator delete[ ] is used. Here is an example that allocates a character buffer\nof500elements,andthenlaterdeallocates it.\nchar* buffer = new char[500]; // allocate a buffer of 500 chars\nbuffer[3] = \u2019a\u2019; // elements are still accessed using []\ndelete [] buffer; // delete the buffer\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 13 \u2014 #35\ni i\n1.1. BasicC++ProgrammingElements 13\nMemory Leaks\nFailure to delete dynamically allocated objects can cause problems. If we were\nto change the (address) value of p without first deleting the structure to which it\npoints, there would be no way for us to access this object. It would continue to\nexist for the lifetime of the program, using up space that could otherwise be used\nfor other allocated objects. Having such inaccessible objects in dynamic memory\nis called a memory leak. We should strongly avoid memory leaks, especially in\nprograms that do a great deal of memory allocation and deallocation. A program\nwith memory leaks can run out of usable memory even when there is a sufficient\namount of memory present. An important rule for a disciplined C++ programmer\nisthefollowing:\nRemember\nIfanobjectisallocatedwithnew,itshouldeventuallybedeallocatedwith\ndelete.\nReferences\nPointers provide one way to refer indirectly to an object. Another way is through\nreferences. A reference is simply an alternative name for an object. Given a type\nT, the notation T& indicates a reference to an object of type T. Unlike pointers,\nwhich can be NULL, a reference in C++ must refer to an actual variable. When a\nreference is declared, its value must be initialized. Afterwards, any access to the\nreference istreatedexactlyasifitisanaccesstotheunderlying object.\nstring author = \"Samuel Clemens\";\nstring& penName = author; // penName is an alias for author\npenName = \"Mark Twain\"; // now author = \u201cMark Twain\u201d\ncout << author; // outputs \u201cMark Twain\u201d\nReferences are most often used for passing function arguments and are also often\nusedforreturning resultsfromfunctions. Theseusesarediscussed later.\n1.1.4 Named Constants, Scope, and Namespaces\nWecan easily name variables without concern for naming conflicts in small prob-\nlems. It is much harder for us to avoid conflicts in large software systems, which\nmayconsist ofhundreds of fileswritten bymany different programmers. C++ has\nanumberofmechanismsthataidinprovidingnamesandlimitingtheirscope.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 14 \u2014 #36\ni i\n14 Chapter1. AC++Primer\nConstants and Typedef\nGood programmers commonly like to associate names with constant quantities.\nBy adding the keyword const to a declaration, we indicate that the value of the\nassociated object cannot be changed. Constants may be used virtually anywhere\nthat literals can be used, for example, in an array declaration. As a hint to the\nreader, wewilluseallcapitalletterswhennamingconstants.\nconst double PI = 3.14159265;\nconst int CUT OFF[] = 90, 80, 70, 60 ;\n{ }\nconst int N DAYS = 7;\nconst int N HOURS = 24*N DAYS; // using a constant expression\nint counter[N HOURS]; // an array of 168 ints\nNote that enumerations (see Section 1.1.2) provide another convenient way to de-\nfineinteger-valued constants, especially withinstructures andclasses.\nInadditiontoassociating nameswithconstants, itisoftenusefultoassociate a\nnamewithatype. Thisassociationcanbedonewithatypedef declaration. Rather\nthandeclaring avariable, atypedef definesanewtypename.\ntypedef char* BufferPtr; // type BufferPtr is a pointer to char\ntypedef double Coordinate; // type Coordinate is a double\nBufferPtr p; // p is a pointer to char\nCoordinate x, y; // x and y are of type double\nBy using typedef we can provide shorter or more meaningful synonyms for\nvarious types. The type name Coordinate provides more of a hint to the reader\nof the meaning of variables x and y than does double. Also, if later we decide\nto change our coordinate representation to int, we need only change the typedef\nstatement. Wewillfollow theconvention ofindicating user-defined types bycapi-\ntalizingthefirstcharacter oftheirnames.\nLocal and Global Scopes\nWhen a group of C++ statements are enclosed in curly braces ( ... ), they define\n{ }\na block. Variables and types that are declared within a block are only accessible\nfromwithintheblock. Theyaresaidtobelocaltotheblock. Blockscanbenested\nwithin other blocks. In C++, a variable may be declared outside of any block.\nSuch a variable is global, in the sense that it is accessible from everywhere in the\nprogram. The portions of a program from which a given name is accessible are\ncalleditsscope.\nTwo variables of the same name may be defined within nested blocks. When\nthishappens,thevariableoftheinnerblockbecomesactiveuntilleavingtheblock.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 15 \u2014 #37\ni i\n1.1. BasicC++ProgrammingElements 15\nThus a local variable \u201chides\u201d any global variables of the same name as shown in\nthefollowingexample.\nconst int Cat = 1; // global Cat\nint main()\n{\nconst int Cat = 2; // this Cat is local to main\ncout << Cat; // outputs 2 (local Cat)\nreturn EXIT SUCCESS;\n}\nint dog = Cat; // dog = 1 (from the global Cat)\nNamespaces\nGlobal variables present many problems in large software systems because they\ncan be accessed and possibly modified anywhere in the program. They also can\nleadtoprogrammingerrors,sinceanimportantglobalvariablemaybehiddenbya\nlocalvariableofthesamename. Asaresult,itisbesttoavoidglobalvariables. We\nmaynotbeabletoavoidglobalsentirely,however. Forexample,whenweperform\noutput, weactually use thesystem\u2019s global standard output stream object, cout. If\nwe were to define a variable with the same name, then the system\u2019s cout stream\nwouldbeinaccessible.\nAnamespaceisamechanismthatallowsagroupofrelatednamestobedefined\ninoneplace. Thishelpsorganize global objectsintonaturalgroups andminimizes\ntheproblemsofglobals. Forexample,thefollowingdeclaresanamespacemyglob-\nalscontaining twovariables, catanddog.\nnamespace myglobals\n{\nint cat;\nstring dog = \"bow wow\";\n}\nNamespacesmaygenerallycontaindefinitions ofmorecomplexobjects, including\ntypes, classes, and functions. We can access an object x in namespace group, us-\ning the notation group::x, which is called its fully qualified name. For example,\nmyglobals::catreferstothecopyofvariablecatinthemyglobalsnamespace.\nWe have already seen an example of a namespace. Many standard system ob-\njects, such as the standard input and output streams cin and cout, are defined in a\nsystemnamespacecalledstd. Theirfullyqualifiednamesarestd::cinandstd::cout,\nrespectively.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 16 \u2014 #38\ni i\n16 Chapter1. AC++Primer\nThe Using Statement\nIf we are repeatedly using variables from the same namespace, it is possible to\navoid entering namespace specifiers by telling the system that we want to \u201cuse\u201d a\nparticular specifier. We communicate this desire by utilizing the using statement,\nwhich makes some or all of the names from the namespace accessible, without\nexplicitly providing the specifier. This statement has two forms that allow us to\nlistindividual namesortomakeeverynameinthenamespace accessible asshown\nbelow.\nusing std::string; // makes just std::string accessible\nusing std::cout; // makes just std::cout accessible\nusing namespace myglobals; // makes all of myglobals accessible\n1.2 Expressions\nAnexpression combinesvariablesandliteralswithoperators tocreatenewvalues.\nIn the following discussion, we group operators according to the types of objects\nthey may be applied to. Throughout, we use var to denote a variable or anything\ntowhichavaluemaybeassigned. (InofficialC++jargon, thisiscalledanlvalue.)\nWeuseexptodenoteanexpression andtypetodenoteatype.\nMember Selection and Indexing\nSomeoperators access amemberofastructure, class, orarray. Weletclass name\ndenote the name of a structure or class; pointerdenotes a pointer to a structure or\nclassandarraydenotesanarrayorapointertothefirstelementofanarray.\nclass name . member class/structure memberselection\npointer > member class/structure memberselection\n\u2212\narray [ exp ] arraysubscripting\nArithmetic Operators\nThefollowingarethebinaryarithmeticoperators:\nexp + exp addition\nexp exp subtraction\n\u2212\nexp * exp multiplication\nexp / exp division\nexp % exp modulo(remainder)\nThere are also unary minus (\u2013x) and unary plus (+x)operations. Division be-\ntween two integer operands results in an integer result by truncation, even if the\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 17 \u2014 #39\ni i\n1.2. Expressions 17\nresult is being assigned to a floating point variable. The modulo operator n%m\nyieldstheremainderthatwouldresultfromtheintegerdivisionn/m.\nIncrement and Decrement Operators\nThe post-increment operator returns a variable\u2019s value and then increments it by\n1. The post-decrement operator is analogous but decreases the value by 1. The\npre-incrementoperator firstincrementsthevariables andthenreturnsthevalue.\nvar ++ postincrement\nvar postdecrement\n\u2212\u2212\n++ var preincrement\nvar predecrement\n\u2212\u2212\nThefollowingcodefragmentillustrates theincrement anddecrementoperators.\nint a[] = 0, 1, 2, 3 ;\n{ }\nint i = 2;\nint j = i++; // j = 2 and now i = 3\nint k = i; // now i = 2 and k = 2\n\u2212\u2212\ncout << a[k++]; // a[2] (= 2) is output; now k = 3\nRelational and Logical Operators\nC++provides theusualcomparison operators.\nexp < exp lessthan\nexp > exp greaterthan\nexp <= exp lessthanorequal\nexp >= exp greaterthanorequal\nexp == exp equalto\nexp != exp notequalto\nThesereturnaBooleanresult\u2014eithertrueorfalse. Comparisonscanbemade\nbetween numbers, characters, and STL strings (but not C-style strings). Pointers\ncanbecompared aswell,butitisusually onlymeaningful totestwhetherpointers\nareequalornotequal(sincetheirvaluesarememoryaddresses).\nThefollowinglogicaloperators arealsoprovided.\n! exp logicalnot\nexp && exp logicaland\nexp exp logicalor\n||\nThe operators && and evaluate sequentially from left to right. If the left\n||\noperand of &&isfalse, theentireresult isfalse, andtheright operand isnoteval-\nuated. The operatorisanalogous, butevaluationstopsiftheleftoperandistrue.\n||\nThis \u201cshort circuiting\u201d is quite useful in evaluating a chain of conditional ex-\npressions where the left condition guards against an error committed by the right\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 18 \u2014 #40\ni i\n18 Chapter1. AC++Primer\ncondition. Forexample, the following code firsttests thataPassenger pointer pis\nnon-null before accessing it. It would result in an error if the execution were not\nstopped ifthefirstcondition isnotsatisfied.\nif ((p != NULL) && p >isFreqFlyer) ...\n\u2212\nBitwise Operators\nThefollowingoperatorsactontherepresentations ofnumbersasbinarybitstrings.\nTheycanbeappliedtoanyintegertype,andtheresultisanintegertype.\n\u02dc exp bitwisecomplement\nexp & exp bitwiseand\nexp ^ exp bitwiseexclusive-or\nexp exp bitwiseor\n|\nexp1 << exp2 shiftexp1leftbyexp2bits\nexp1 >> exp2 shiftexp1rightbyexp2bits\nTheleftshiftoperator alwaysfillswithzeros. Howtheright shiftfillsdepends\non a variable\u2019s type. In C++ integer variables are \u201csigned\u201d quantities by default,\nbut they may be declared as being \u201cunsigned,\u201d as in \u201cunsigned int x.\u201d If the left\noperandofarightshiftisunsigned, theshiftfillswithzerosandotherwisetheright\nshift fills with the number\u2019s sign bit (0 for positive numbers and 1 for negative\nnumbers). Notethatthe input (>>)andoutput (<<)operators arenotinthisgroup.\nTheyarediscussed later.\nAssignment Operators\nIn addition to the familiar assignment operator (=), C++ includes a special form\nfor each of the arithmetic binary operators (+, , *, /, %) and each of the bit-\n\u2212\nwisebinary operators (&, , ^, <<, >>), thatcombines abinary operation with\n|\nassignment. For example, the statement \u201cn += 2\u201d means \u201cn = n + 2.\u201d Some\nexamplesareshownbelow.\nint i = 10;\nint j = 5;\nstring s = \"yes\";\ni = 4; // i = i - 4 = 6\n\u2212\nj *= 2; // j = j * (-2) = -10\n\u2212\ns += \" or no\"; // s = s + \u201c or no\u201d = \u201cyes or no\u201d\nThese assignment operators not only provide notational convenience, but they\ncan be more efficient to execute as well. For example, in the string concatenation\nexampleabove,thenewtextcanjustbeappendedtoswithouttheneedtogenerate\natemporarystringtoholdtheintermediate result.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 19 \u2014 #41\ni i\n1.2. Expressions 19\nTake care when performing assignments between aggregate objects (arrays,\nstrings, and structures). Typically the programmer intends such an assignment to\ncopy the contents of one object to the other. This works for STL strings and C-\nstyle structures (provided theyhavethesametype). However, asdiscussed earlier,\nC-style strings and arrays cannot be copied merely through a single assignment\nstatement.\nOther Operators\nHerearesomeotherusefuloperators.\nclass name :: member classscoperesolution\nnamespace name :: member namespace resolution\nbool exp ? true exp : false exp conditional expression\nWe have seen the namespace resolution operator in Section 1.1.4. The condi-\ntionalexpressionisavariantof\u201cif-then-else\u201dforexpressions. Ifbool expevaluates\ntotrue,thevalueoftrue expisreturned, andotherwisethevalueoffalse expisre-\nturned.\nThe following example shows how to use this to return the minimum of two\nnumbers, xandy.\nsmaller = (x < y ? x : y); // smaller = min(x,y)\nWealsohavethefollowingoperations oninput/output streams.\nstream >> var streaminput\nstream << exp streamoutput\nAlthough they look like the bitwise shift operators, the input (>>) and output\n(<<)streamoperatorsarequitedifferent. TheyareexamplesofC++\u2019spowerfulca-\npability, called operator overloading, which are discussed inSection 1.4.2. These\noperators are not an intrinsic part of C++, but are provided by including the file\n<iostream>. We refer the reader to the references given in the chapter notes for\nmoreinformation oninputandoutputinC++.\nTheabovediscussion providesasomewhatincompletelistofalltheC++oper-\nators,butitnevertheless coversthemostcommonones. Laterweintroduce others,\nincluding castingoperators.\nOperator Precedence\nOperators in C++ are assigned a precedence that determines the order in which\noperations areperformed intheabsence ofparentheses. InTable1.1, weshow the\nprecedence of some of the more common C++ operators, with the highest listed\nfirst. Unless parentheses are used, operators are evaluated in order from highest\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 20 \u2014 #42\ni i\n20 Chapter1. AC++Primer\nto lowest. Forexample, the expression 0 < 4 + x * 3 would be evaluated as ifit\nwereparenthesized as 0 < (4 + (x * 3)). Ifpisanarrayofpointers,then*p[2]is\nequivalentto*(p[2]). Exceptfor &&and ,whichguaranteeleft-to-right evalua-\n||\ntion,theorderofevaluationofsubexpressionsisdependentontheimplementation.\nSince these rules are complex, it is a good idea to add parentheses to complex\nexpressions tomakeyourintentcleartosomeonereadingyourprogram.\nOperatorPrecedences\nType Operators\nscoperesolution namespace name :: member\nselection/subscripting class name.member pointer >member array[exp]\n\u2212\nfunctioncall function(args)\npostfixoperators var++ var\n\u2212\u2212\nprefixoperators ++var var +exp exp \u02dcexp !exp\n\u2212\u2212 \u2212\ndereference/address *pointer &var\nmultiplication/division * / %\naddition/subtraction +\n\u2212\nshift << >>\ncomparison < <= > >=\nequality == !=\nbitwiseand &\nbitwiseexclusive-or ^\nbitwiseor\n|\nlogicaland &&\nlogicalor\n||\nconditional bool exp ? true exp : false exp\nassignment = += = *= /= %= >>= <<= &= ^= =\n\u2212 |\nTable1.1: TheC++precedence rules. Thenotation \u201cexp\u201ddenotes anyexpression.\n1.2.1 Changing Types through Casting\nCasting is anoperation that allows usto change the type ofavariable. In essence,\nwecantakeavariableofonetypeandcastitintoanequivalentvariableofanother\ntype. Casting is useful in many situations. There are two fundamental types of\ncastingthatcanbedoneinC++. Wecaneithercastwithrespecttothefundamental\ntypes orwecancast withrespect toclass objects and pointers. Wediscuss casting\nwithfundamentaltypeshere,andweconsidercastingwithobjectsinSection2.2.4.\nWebeginbyintroducingthetraditionalwayofcastinginC++,andlaterwepresent\nC++\u2019snewercastingoperators.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 21 \u2014 #43\ni i\n1.2. Expressions 21\nTraditional C-Style Casting\nLetexpbesomeexpression, andletTbeatype. Tocastthevalueoftheexpression\nto type T we can use the notation \u201c(T)exp.\u201d We call this a C-style cast. If the\ndesired type isatype name (asopposed toatype expression), there isanalternate\nfunctional-style cast. This has the form \u201cT(exp).\u201d Some examples are shown\nbelow. Inbothcases,theintegervalue14iscasttoadoublevalue14.0.\nint cat = 14;\ndouble dog = (double) cat; // traditional C-style cast\ndouble pig = double(cat); // C++ functional cast\nBothformsofcastingarelegal,butsomeauthorspreferthefunctional-style cast.\nCastingtoatypeofhigherprecision orsizeisoftenneededinformingexpres-\nsions. Theresultsofcertainbinaryoperatorsdependonthevariabletypesinvolved.\nForexample, division between integers always produces an integer result by trun-\ncating the fractional part. If a floating-point result is desired, we must cast the\noperands beforeperforming theoperation asshownbelow.\nint i1 = 18;\nint i2 = 16;\ndouble dv1 = i1 / i2; // dv1 has value 1.0\ndouble dv2 = double(i1) / double(i2); // dv2 has value 1.125\ndouble dv3 = double( i1 / i2 ); // dv3 has value 1.0\nWhen i1 and i2 are cast to doubles, double-precision division is performed.\nWheni1andi2arenotcast, truncated integer division isperformed. Inthecaseof\ndv3,thecastisperformedaftertheintegerdivision, soprecision isstilllost.\nExplicit Cast Operators\nCastingoperationscanvaryfromharmlesstodangerous,dependingonhowsimilar\nthe twotypes areand whether information islost. Forexample, casting ashortto\nanintisharmless, sincenoinformation islost. Castingfromadoubletoanintis\nmore dangerous because the fractional part of the number is lost. Casting from a\ndouble* to char* is dangerous because the meaning of converting such a pointer\nwilllikelyvaryfrommachinetomachine. Oneimportantelementofgoodsoftware\ndesignisthatprogramsbeportable,meaningthattheybehavethesameondifferent\nmachines.\nFor this reason, C++ provides a number of casting operators that make the\nsafetyofthecastmuchmoreexplicit. Thesearecalledthestatic cast,dynamic cast,\nconst cast,andreinterpret cast. Wediscussonlythestatic casthereandcon-\nsidertheothersastheneedarises.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 22 \u2014 #44\ni i\n22 Chapter1. AC++Primer\nStatic Casting\nStatic casting is used when a conversion is made between two related types, for\nexamplenumberstonumbersorpointers topointers. Itssyntax isgivenbelow.\nstatic cast<desired type>(expression )\nThe most common use is for conversions between numeric types. Some of these\nconversions may involve the loss of information, for example a conversion from\na double to an int. This conversion is done by truncating the fractional part (not\nrounding). Forexample,consider thefollowing:\ndouble d1 = 3.2;\ndouble d2 = 3.9999;\nint i1 = static cast<int>(d1); // i1 has value 3\nint i2 = static cast<int>(d2); // i2 has value 3\nThis type of casting is more verbose than the C-style and functional-style casts\nshownearlier. Butthisformisappropriate, becauseitservesasavisiblewarningto\ntheprogrammerthatapotentiallyunsafeoperationistakingplace. Inourexamples\nin this book, we use the functional style for safe casts (such as integer to double)\nand these newercast operators for all other casts. Someolder C++compilers may\nnotsupportthenewercastoperators,butthenthetraditionalC-styleandfunctional-\nstylecastscanbeusedinstead.\nImplicit Casting\nTherearemanyinstanceswheretheprogrammerhasnotrequestedanexplicitcast,\nbutachangeoftypesisrequired. Inmanyofthesecases,C++performsanimplicit\ncast. That is, the compiler automatically inserts a cast into the machine-generated\ncode. Forexample, when numbers of different types are involved in an operation,\nthe compiler automatically casts to the stronger type. C++ allows an assignment\nthat implicitly loses information, but the compiler usually issues a warning mes-\nsage.\nint i = 3;\ndouble d = 4.8;\ndouble d3 = i / d; // d3 = 0.625 = double(i)/d\nint i3 = d3; // i3 = 0 = int(d3)\n// Warning! Assignment may lose information\nA general rule with casting is to \u201cplay it safe.\u201d If a compiler\u2019s behavior regarding\nthe implicit casting of a value is uncertain, then we are safest in using an explicit\ncast. Doingsomakesourintentions clear.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 23 \u2014 #45\ni i\n1.3. ControlFlow 23\n1.3 Control Flow\nControlflowinC++issimilartothatofotherhigh-level languages. Wereviewthe\nbasicstructure andsyntax ofcontrol flowinC++inthissection, including method\nreturns, if statements, switch statements, loops, and restricted forms of \u201cjumps\u201d\n(thebreakandcontinuestatements).\nIf Statement\nEvery programming language includes a way of making choices, and C++ is no\nexception. The most common method of making choices in a C++ program is\nthrough the use ofan ifstatement. Thesyntax of an ifstatement in C++is shown\nbelow,together withasmallexample.\nif (condition )\ntrue statement\nelse if (condition )\nelse if statement\nelse\nelse statement\nEach of the conditions should return a Boolean result. Each statement can either\nbeasinglestatement orablockofstatements enclosed inbraces( ... ). The\u201celse\n{ }\nif\u201d and \u201celse\u201d parts are optional, and any number of else-if parts may be given.\nThe conditions are tested one by one, and the statement associated with the first\ntrue condition is executed. All the other statements are skipped. Here is a simple\nexample.\nif ( snowLevel < 2 )\n{\ngoToClass(); // do this if snow level is less than 2\ncomeHome();\n}\nelse if ( snowLevel < 5 )\nhaveSnowballFight(); // if level is at least 2 but less than 5\nelse if ( snowLevel < 10 )\ngoSkiing(); // if level is at least 5 but less than 10\nelse\nstayAtHome(); // if snow level is 10 or more\nSwitch Statement\nAswitchstatementprovidesanefficientwaytodistinguishbetweenmanydifferent\noptions according to the value of an integral type. In the following example, a\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 24 \u2014 #46\ni i\n24 Chapter1. AC++Primer\nsinglecharacter isinput,andbasedonthecharacter\u2019s value, anappropriate editing\nfunction is called. Thecomments explain the equivalent if-then-else structure, but\nthecompilerisfreetoselectthemostefficientwaytoexecutethestatement.\nchar command;\ncin >> command; // input command character\nswitch (command) // switch based on command value\n{\ncase \u2019I\u2019 : // if (command == \u2019I\u2019)\neditInsert();\nbreak;\ncase \u2019D\u2019 : // else if (command == \u2019D\u2019)\neditDelete();\nbreak;\ncase \u2019R\u2019 : // else if (command == \u2019R\u2019)\neditReplace();\nbreak;\ndefault : // else\ncout << \"Unrecognized command\\n\";\nbreak;\n}\nThe argument of the switch can be any integral type or enumeration. The\n\u201cdefault\u201dcaseisexecutedifnoneofthecasesequalstheswitchargument.\nEach case in a switch statement should be terminated with a break statement,\nwhich, when executed, exits the switch statement. Otherwise, the flow of control\n\u201cfallsthrough\u201d tothenextcase.\nWhile and Do-While Loops\nC++ has two kinds of conditional loops for iterating over a set of statements as\nlong as some specified condition holds. These two loops are the standard while\nloopandthedo-whileloop. OnelooptestsaBooleancondition beforeperforming\nan iteration of the loop body and the other tests a condition after. Let us consider\nthewhileloopfirst.\nwhile(condition )\nloop body statement\nAt the beginning of each iteration, the loop tests the Boolean expression and then\nexecutes the loop body only if this expression evaluates to true. The loop body\nstatementcanalsobeablockofstatements.\nConsider the following example. It computes the sum of the elements of an\narray,untilencounteringthefirstnegativevalue. Notetheuseofthe+=operatorto\nincrementthevalueofsumandthe++operatorwhichincrementsiafteraccessing\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 25 \u2014 #47\ni i\n1.3. ControlFlow 25\nthecurrentarrayelement.\nint a[100];\n// ...\nint i = 0;\nint sum = 0;\nwhile (i < 100 && a[i] >= 0)\n{\nsum += a[i++];\n}\nThedo-while loop is similar to the while loop in that the condition istested at\ntheendoftheloopexecution ratherthanbefore. Ithasthefollowingsyntax.\ndo\nloop body statement\nwhile(condition )\nFor Loop\nMany loops involve three common elements: an initialization, a condition under\nwhichtocontinueexecution,andanincrementtobeperformedaftereachexecution\noftheloop\u2019sbody. Aforloopconveniently encapsulates thesethreeelements.\nfor(initialization ;condition ;increment )\nloop body statement\nThe initialization indicates what is to be done before starting the loop. Typ-\nically, this involves declaring and initializing a loop-control variable or counter.\nNext,thecondition givesaBooleanexpression tobetestedinorderfortheloopto\ncontinue execution. Itisevaluated before executing theloop body. Whenthecon-\ndition evaluates to false, execution jumps to the next statement after the for loop.\nFinally, the increment specifies what changes are to be made at the end of each\nexecution of the loop body. Typically, this involves incrementing or decrementing\nthevalueoftheloop-control variable.\nHere is a simple example, which prints the positive elements of an array, one\nperline. Recallthat \u2019\\n\u2019generates anewlinecharacter.\nconst int NUM ELEMENTS = 100;\ndouble b[NUM ELEMENTS];\n// ...\nfor (int i = 0; i < NUM ELEMENTS; i++)\n{\nif (b[i] > 0)\ncout << b[i] << \u2019\\n\u2019;\n}\nInthisexample,theloopvariableiwasdeclaredasint i = 0. Beforeeachiteration,\nthe loop tests the condition \u201ci < NUM ELEMENTS\u201d and executes the loop body\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 26 \u2014 #48\ni i\n26 Chapter1. AC++Primer\nonly ifthis is true. Finally, at the end of each iteration the loop uses the statement\ni++ to increment the loop variable i before testing the condition again. Although\nthe loop variable is declared outside the curly braces of the for loop, the compiler\ntreats it as if it were a local variable within the loop. This implies that its value is\nnotaccessible outside theloop.\nBreak and Continue Statements\nC++ provides statements to change control flow, including the break, continue,\nand return statements. We discuss the first two here, and leave the return state-\nment for later. A break statement is used to \u201cbreak\u201d out of a loop or switch state-\nment. When it is executed, it causes the flow of control to immediately exit the\ninnermost switch statement or loop (for loop, while loop, or do-while loop). The\nbreakstatementisusefulwhentheconditionforterminatingtheloopisdetermined\ninside the loop. For example, in an input loop, termination often depends on a\nspecific value that has been input. The following example provides a different\nimplementation of an earlier example, which sums the elements of an array until\nfindingthefirstnegativevalue.\nint a[100];\n// ...\nint sum = 0;\nfor (int i = 0; i < 100; i++)\n{\nif (a[i] < 0) break;\nsum += a[i];\n}\nThe other statement that is often useful for altering loop behavior is the con-\ntinuestatement. Thecontinuestatementcanonlybeusedinsideloops(for,while,\nand do-while). The continue statement causes the execution to skip to the end of\ntheloop,readytostartanewiteration.\n1.4 Functions\nAfunctionisachunkofcodethatcanbecalledtoperformsomewell-definedtask,\nsuch as calculating the area of a rectangle, computing the weekly withholding tax\nforacompany employee, orsorting alist ofnames inascending order. Inorder to\ndefineafunction, weneedtoprovidethefollowinginformation tothecompiler:\nReturntype. Thisspecifiesthetypeofvalueorobjectthatisreturnedbythefunc-\ntion. Forexample,afunctionthatcomputes theareaofarectangle mightre-\nturnavalueoftypedouble. Afunction isnotrequiredtoreturnavalue. For\nexample,itmaysimplyproducesomeoutputormodifysomedatastructure.\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 27 \u2014 #49\ni i\n1.4. Functions 27\nIf so, the return type is void. A function that returns no value is sometimes\ncalledaprocedure.\nFunctionname. Thisindicates thenamethat isgiven tothe function. Ideally, the\nfunction\u2019s name should provide a hint to the reader as to what the function\ndoes.\nArgumentlist. This serves as a list of placeholders for the values that will be\npassed into the function. The actual values will be provided when the func-\ntionisinvoked. Forexample, afunction thatcomputestheareaofapolygon\nmight take four double arguments; the x- and y-coordinates of the rectan-\ngle\u2019s lower left corner and the x- and y-coordinates of the rectangle\u2019s upper\nright corner. The argument list is given as a comma-separated list enclosed\ninparentheses, whereeachentryconsistsofthenameoftheargumentandits\ntype. A function may have any number of arguments, and the argument list\nmayevenbeempty.\nFunctionbody. Thisisacollection ofC++statements thatdefinetheactual com-\nputations to be performed by the function. This is enclosed within curly\nbraces. If the function returns a value, the body will typically end with a\nreturnstatement, whichspecifiesthefinalfunctionvalue.\nFunctionspecificationsinC++typicallyinvolvetwosteps,declarationanddef-\ninition. A function is declared, by specifying three things: the function\u2019s return\ntype, its name, and its argument list. The declaration makes the compiler aware\nof the function\u2019s existence, and allows the compiler to verify that the function is\nbeing used correctly. This three-part combination of return type, function name,\nandargumenttypesiscalledthefunction\u2019s signatureorprototype.\nForexample,supposethatwewantedtocreateafunction,calledevenSum,that\nis given two arguments, an integer array a and its length n. It determines whether\nthe sum of array values is even, and if so it returns the value true. Otherwise,\nit returns false. Thus, it has a return value of type bool. The function could be\ndeclared asfollows:\nbool evenSum(int a[], int n); // function declaration\nSecond, the function is defined. The definition consists both of the function\u2019s\nsignature and the function body. The reason for distinguishing between the decla-\nrationanddefinitioninvolvesthemannerinwhichlargeC++programsarewritten.\nTheyaretypically spread overmanydifferent files. Thefunction declaration must\nappear in every file that invokes the function, but the definition must appear only\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 28 \u2014 #50\ni i\n28 Chapter1. AC++Primer\nonce. HereishowourevenSumfunction mightbedefined.\nbool evenSum(int a[], int n) // function definition\n{\nint sum = 0;\nfor (int i = 0; i < n; i++) // sum the array elements\nsum += a[i];\nreturn (sum % 2) == 0; // returns true if sum is even\n}\nThe expression in the return statement may take a minute to understand. We use\nthe mod operator (%) to compute the remainder when sum is divided by 2. If the\nsum is even, the remainder is 0, and hence the expression \u201c(sum % 2) == 0\u201d\nevaluatestotrue. Otherwise,itevaluates tofalse,whichisexactlywhatwewant.\nTo complete the example, let us provide a simple main program, which first\ndeclares thefunction, andtheninvokes itonanactualarray.\nbool evenSum(int a[], int n); // function declaration\nint main()\n{\nint list[] = 4, 2, 7, 8, 5, 1 ;\n{ }\nbool result = evenSum(list, 6); // invoke the function\nif (result) cout << \"the sum is even\\n\";\nelse cout << \"the sum is odd\\n\";\nreturn EXIT SUCCESS;\n}\nLet us consider this example in greater detail. The names \u201ca\u201d and \u201cn\u201d in the\nfunction definition are called formal arguments since they serve merely as place-\nholders. Thevariable\u201clist\u201dandliteral\u201c6\u201dinthefunction callinthemainprogram\naretheactualarguments. Thus,eachreferenceto\u201ca\u201dinthefunctionbodyistrans-\nlatedintoareference totheactualarray\u201clist.\u201d Similarly, eachreference to\u201cn\u201dcan\nbethoughtofastakingontheactualvalue6inthefunction body. Thetypesofthe\nactualarguments mustagreewiththecorresponding formalarguments. Exacttype\nagreementisnotalwaysnecessary,however,forthecompilermayperformimplicit\ntype conversions in some cases, such as casting a short actual argument to match\nanintformalargument.\nWhenwerefertofunctionnamesthroughout thisbook,weoftenincludeapair\nof parentheses following the name. This makes it easier to distinguish function\nnamesfromvariable names. Forexample, wewouldrefertotheabovefunction as\nevenSum.\n1.4.1 Argument Passing\nBy default, arguments in C++ programs are passed by value. When arguments\nare passed by value, the system makes a copy of the variable to be passed to the\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 29 \u2014 #51\ni i\n1.4. Functions 29\nfunction. Intheaboveexample,theformalargument\u201cn\u201disinitialized totheactual\nvalue 6 when the function is called. This implies that modifications made to a\nformalargument inthefunction donotaltertheactualargument.\nSometimes it is useful for the function to modify one of its arguments. To do\nso,wecanexplicitlydefineaformalargumenttobeareferencetype(asintroduced\ninSection 1.1.3). Whenwedothis, anymodifications madetoan argument inthe\nfunction modifies the corresponding actual argument. This is called passing the\nargumentbyreference. Anexampleisshownbelow,whereoneargumentispassed\nbyvalueandtheotherispassedbyreference.\nvoid f(int value, int& ref) // one value and one reference\n{\nvalue++; // no effect on the actual argument\nref++; // modifies the actual argument\ncout << value << endl; // outputs 2\ncout << ref << endl; // outputs 6\n}\nint main()\n{\nint cat = 1;\nint dog = 5;\nf(cat, dog); // pass cat by value, dog by ref\ncout << cat << endl; // outputs 1\ncout << dog << endl; // outputs 6\nreturn EXIT SUCCESS;\n}\nObserve that altering the value argument had no effect on the actual argument,\nwhereasmodifyingthereference argumentdid.\nModifying function arguments is felt to be a rather sneaky way of passing in-\nformation back from afunction, especially ifthefunction returns anonvoid value.\nAnother way to modify an argument is to pass the address of the argument, rather\nthantheargument itself. Eventhough apointer ispassedbyvalue(and, hence, the\naddress of where it is pointing cannot be changed), we can access the pointer and\nmodify the variables to which it points. Reference arguments achieve essentially\nthesameresultwithlessnotational burden.\nConstant References as Arguments\nThere is a good reason for choosing to pass structure and class arguments by ref-\nerence. In particular, passing a large structure or class by value results in a copy\nbeing made of the entire structure. All this copying may be quite inefficient for\nlarge structures and classes. Passing such anargument by reference is much more\nefficient,sinceonlytheaddressofthestructure needbepassed.\nSince most function arguments are not modified, an even better practice is to\npassanargumentasa\u201cconstantreference.\u201d Suchadeclarationinformsthecompiler\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 30 \u2014 #52\ni i\n30 Chapter1. AC++Primer\nthat, even though the argument is being passed by reference, the function cannot\nalter its value. Furthermore, the function is not allowed to pass the argument to\nanotherfunctionthatmightmodifyitsvalue. HereisanexampleusingthePassen-\ngerstructure, whichwedefinedearlierinSection1.1.3. Theattempttomodifythe\nargumentwouldresultinacompilererrormessage.\nvoid someFunction(const Passenger& pass)\n{\npass.name = \"new name\"; // ILLEGAL! pass is declared const\n}\nWhen writing small programs, we can easily avoid modifying the arguments\nthatarepassedbyreferenceforthesakeofefficiency. Butinlargeprograms,which\nmaybedistributed overmanyfiles,enforcingthisruleismuchharder. Fortunately,\npassing class and structure arguments as a constant reference allows the compiler\nto do the checking for us. Henceforth, when we pass a class or structure as an\nargument, wetypically passitasareference, usually aconstant reference.\nArray Arguments\nWehavediscussedpassinglargestructuresandclassesbyreference,butwhatabout\nlargearrays? Wouldpassinganarraybyvalueresultinmakingacopyoftheentire\narray? Theanswerisno. Whenanarrayispassedtoafunction, itisconverted toa\npointertoitsinitialelement. Thatis,anobjectoftypeT[ ]isconverted totypeT*.\nThus, an assignment to an element of an array within a function does modify the\nactualarraycontents. Inshort,arraysarenotpassedbyvalue.\nBy the same token, it is not meaningful to pass an array back as the result of\na function call. Essentially, an attempt to do so will only pass a pointer to the\narray\u2019s initial element. If returning an array is our goal, then we should either\nexplicitly return a pointer or consider returning an object of type vector from the\nC++StandardTemplateLibrary.\n1.4.2 Overloading and Inlining\nOverloadingmeansdefiningtwoormorefunctionsoroperatorsthathavethesame\nname,butwhoseeffectdependsonthetypesoftheiractualarguments.\nFunction Overloading\nFunction overloading occurs when two or more functions are defined with the\nsame name but with different argument lists. Such definitions are useful in situa-\ntions wherewedesire twofunctions that achieveessentially thesamepurpose, but\ndoitwithdifferent typesofarguments.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 31 \u2014 #53\ni i\n1.4. Functions 31\nOne convenient application of function overloading is in writing procedures\nthat print their arguments. In particular, a function that prints an integer would be\ndifferent from a function that prints a Passenger structure from Section 1.1.3, but\nbothcouldusethesamename,print,asshowninthefollowingexample.\nvoid print(int x) // print an integer\ncout << x;\n{ }\nvoid print(const Passenger& pass) // print a Passenger\n{\ncout << pass.name << \" \" << pass.mealPref;\nif (pass.isFreqFlyer)\ncout << \" \" << pass.freqFlyerNo;\n}\nWhen the print function is used, the compiler considers the types of the actual ar-\ngumentandinvokestheappropriate function,thatis,theonewithsignature closest\ntotheactualarguments.\nOperator Overloading\nC++ also allows overloading of operators, such as +, *, +=, and <<. Not\nsurprisingly, such a definition is called operator overloading. Suppose we would\nlike to write an equality test for two Passenger objects. We can denote this in a\nnaturalwaybyoverloading the ==operator asshownbelow.\nbool operator==(const Passenger& x, const Passenger& y)\n{\nreturn x.name == y.name\n&& x.mealPref == y.mealPref\n&& x.isFreqFlyer == y.isFreqFlyer\n&& x.freqFlyerNo == y.freqFlyerNo;\n}\nThisdefinitionissimilartoafunctiondefinition,butinplaceofafunctionnamewe\nuse \u201coperator==.\u201d In general, the == is replaced by whatever operator is being\ndefined. For binary operators wehave two arguments, and for unary operators we\nhavejustone.\nThereareseveralusefulapplications offunctionandoperatoroverloading. For\nexample,overloadingthe ==operatorallowsustonaturallytestfortheequalityof\ntwoobjects,p1andp2,withtheexpression\u201cp1==p2.\u201d Anotherusefulapplication\nof operator overloading is for defining input and output operators for classes and\nstructures. Here is how to define an output operator for our Passenger structure.\nThetype ostream isthe system\u2019s output stream type. Thestandard output, cout is\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 32 \u2014 #54\ni i\n32 Chapter1. AC++Primer\nofthistype.\nostream& operator<<(ostream& out, const Passenger& pass)\n{\nout << pass.name << \" \" << pass.mealPref;\nif (pass.isFreqFlyer)\n{\nout << \" \" << pass.freqFlyerNo;\n}\nreturn out;\n}\nTheoutputinthiscaseisnotverypretty,butwecouldeasilymodifyouroutput\noperator toproduce nicerformatting.\nThere is much more that could be said about function and operator overload-\ning, and indeed C++ functions in general. We refer the reader to a more complete\nreference onC++forthisinformation.\nOperatoroverloadingisapowerfulmechanism,butitiseasilyabused. Itcanbe\nvery confusing for someone reading your program to find that familiar operations\nsuch as \u201c+\u201d and \u201c/\u201d have been assigned new and possibly confusing meanings.\nGoodprogrammersusuallyrestrictoperatoroverloadingtocertaingeneralpurpose\noperatorssuchas\u201c<<\u201d(output),\u201c=\u201d(assignment),\u201c==\u201d(equality),\u201c[ ]\u201d(index-\ning,forsequences).\nIn-line Functions\nVery short functions may be defined to be \u201cinline.\u201d This is a hint to the compiler\nit should simply expand the function code in place, rather than using the system\u2019s\ncall-return mechanism. As a rule of thumb, in-line functions should be very short\n(at most a few lines) and should not involve any loops or conditionals. Here is an\nexample,whichreturnstheminimumoftwointegers.\ninline int min(int x, int y) return (x < y ? x : y);\n{ }\n1.5 Classes\nTheconceptofaclassisfundamentaltoC++,sinceitprovidesawaytodefinenew\nuser-defined types, complete with associated functions and operators. By restrict-\ningaccesstocertainclassmembers,itispossibletoseparateoutthepropertiesthat\nareessentialtoaclass\u2019scorrectusefromthedetailsneededforitsimplementation.\nClasses are fundamental to programming that uses an object-oriented approach,\nwhichisaprogramming paradigm wediscussinthenextchapter.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 33 \u2014 #55\ni i\n1.5. Classes 33\n1.5.1 Class Structure\nA class consists of members. Members that are variables or constants are data\nmembers(alsocalledmembervariables)andmembersthatarefunctionsarecalled\nmember functions (also called methods). Data members may be of any type, and\nmayevenbeclassesthemselves,orpointersorreferencestoclasses. Memberfunc-\ntionstypicallyactonthemembervariables, andsodefinethebehavioroftheclass.\nWe begin with a simple example, called Counter. It implements a simple\ncounter stored in the member variable count. It provides three member functions.\nThe first member function, called Counter, initializes the counter. The second,\ncalled getCount, returns the counter\u2019s current value. Thethird, called increaseBy,\nincreases thecounter\u2019s value.\nclass Counter // a simple counter\n{\npublic:\nCounter(); // initialization\nint getCount(); // get the current count\nvoid increaseBy(int x); // add x to the count\nprivate:\nint count; // the counter\u2019s value\n;\n}\nLet\u2019s explore this class definition in a bit more detail. Observe that the class\ndefinition is separated into two parts by the keywords public and private. The\npublic section definestheclass\u2019s publicinterface. Thesearetheentities thatusers\nof the class are allowed to access. In this case, the public interface has the three\nmember functions (Counter, getCount, and increaseBy). In contrast, the private\nsectiondeclaresentitiesthatcannotbeaccessedbyusersoftheclass. Wesaymore\naboutthesetwopartsbelow.\nSo far, we have only declared the member functions of class Counter. Next,\nwe present the definitions of these member functions. In order to make clear to\nthe compiler that we are defining member functions of Counter (as opposed to\nmember functions of some other class), we precede each function name with the\nscoping specifier\u201cCounter::\u201d.\nCounter::Counter() // constructor\ncount = 0;\n{ }\nint Counter::getCount() // get current count\nreturn count;\n{ }\nvoid Counter::increaseBy(int x) // add x to the count\ncount += x;\n{ }\nThe first of these functions has the same name as the class itself. This is a special\nmemberfunctioncalledaconstructor. Aconstructor\u2019sjobistoinitializethevalues\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 34 \u2014 #56\ni i\n34 Chapter1. AC++Primer\nof the class\u2019s member variables. The function getCount is commonly referred to\nasa\u201cgetter\u201dfunction. Suchfunctions provideaccesstotheprivatemembersofthe\nclass.\nHereisanexamplehowwemightuseoursimpleclass. Wedeclareanewobject\noftypeCounter,calledctr. Thisimplicitlyinvokestheclass\u2019sconstructor,andthus\ninitializes thecounter\u2019s valueto0. Toinvoke oneofthememberfunctions, weuse\nthenotation ctr.function name().\nCounter ctr; // an instance of Counter\ncout << ctr.getCount() << endl; // prints the initial value (0)\nctr.increaseBy(3); // increase by 3\ncout << ctr.getCount() << endl; // prints 3\nctr.increaseBy(5); // increase by 5\ncout << ctr.getCount() << endl; // prints 8\nAccess Control\nOne important feature of classes is the notion of access control. Members may\nbe declared to be public, which means that they are accessible from outside the\nclass, or private, which means that they are accessible only from within the class.\n(Wediscuss twoexceptions tothislater: protected access andfriendfunctions.) In\ntheprevious example,wecouldnotdirectlyaccesstheprivatemembercountfrom\noutsidetheclassdefinition.\nCounter ctr; // ctr is an instance of Counter\n// ...\ncout << ctr.count << endl; // ILLEGAL - count is private\nWhybother declaring memberstobeprivate? Wediscuss thereasons indetail\nin Chapter2whenwediscuss object-oriented programming. Fornow,sufficeitto\nsaythatitstemsfromthedesiretopresentuserswithaclean(public)interfacefrom\nwhichtousetheclass,withoutbothering themwiththeinternal(private)detailsof\nits implementation. All external access to class objects takes place through the\npublic members, or thepublic interface as itis called. Thesyntax foraclass isas\nfollows.\nclass class name\nh i{\npublic:\npublic members\nprivate:\nprivate members\n;\n}\nNote that if no access specifier is given, the default is private for classes and\npublic for structures. (There is a third specifier, called protected, which is dis-\ncussedlaterinthebook.) Thereisnorequiredorderbetweentheprivateandpublic\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 35 \u2014 #57\ni i\n1.5. Classes 35\nsections, and in fact, it is possible to switch back and forth between them. Most\nC++style manuals recommend that public members bepresented first, since these\nare the elements of the class that are relevant to a programmer who wishes to use\ntheclass. Wesometimesviolatethisconvention inthisbook,particularly whenwe\nwanttoemphasizetheprivatemembers.\nMember Functions\nLet us return to the Passenger structure, which was introduced earlier in Sec-\ntion 1.1.3, but this time we define it using a class structure. We provide the same\nmember variables as earlier, but they are now private members. To this we add\na few member functions. For this short example, we provide just a few of many\npossible member functions. The first member function is a constructor. Its job is\nto guarantee that each instance of the class is properly initialized. Notice that the\nconstructordoesnothaveareturntype. ThememberfunctionisFrequentFlyertests\nwhetherthepassengerisafrequentflyer,andthememberfunctionmakeFrequent-\nFlyermakesapassenger afrequent flyerandassigns afrequent flyernumber. This\nis only a partial definition, and a number of member functions have been omitted.\nAsusualweuse\u201c//...\u201dtoindicateomittedcode.\nclass Passenger // Passenger (as a class)\n{\npublic:\nPassenger(); // constructor\nbool isFrequentFlyer() const; // is this a frequent flyer?\n// make this a frequent flyer\nvoid makeFrequentFlyer(const string& newFreqFlyerNo);\n// ... other member functions\nprivate:\nstring name; // passenger name\nMealType mealPref; // meal preference\nbool isFreqFlyer; // is a frequent flyer?\nstring freqFlyerNo; // frequent flyer number\n;\n}\nClass member functions can be placed in two major categories: accessor func-\ntions, which only read class data, and update functions, which may alter class\ndata. The keyword \u201cconst\u201d indicates that the member function isFrequentFlyeris\nan accessor. This informs the user of the class that this function will not change\ntheobjectcontents. Italsoallowsthecompilertocatchapotentialerrorshouldwe\ninadvertently attempttomodifyanyclassmembervariables.\nWe have declared two member functions, but we still need to define them.\nMember functions may either be defined inside or outside the class body. Most\nC++style manuals recommend defining all memberfunctions outside theclass, in\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 36 \u2014 #58\ni i\n36 Chapter1. AC++Primer\norder topresent aclean public interface intheclass\u2019s definition. Aswesaw above\nintheCounterexample,whenamemberfunctionisdefinedoutsidetheclassbody,\nitisnecessary tospecify whichclass itbelongs to,whichisdonebypreceding the\nfunction namewiththescopingspecifierclass name::member name.\nbool Passenger::isFrequentFlyer() const\n{\nreturn isFreqFlyer;\n}\nvoid Passenger::makeFrequentFlyer(const string& newFreqFlyerNo)\n{\nisFreqFlyer = true;\nfreqFlyerNo = newFreqFlyerNo;\n}\nNotice that when we are within the body of a member function, the member vari-\nables (such as isFreqFlyer and freqFlyerNo) are given without reference to a par-\nticular object. These functions will be invoked on a particular Passenger object.\nForexample,letpassbeavariableoftypePassenger. Wemayinvoke thesepublic\nmemberfunctionsonpassusingthesamememberselectionoperatorweintroduced\nwithstructuresasshownbelow. Onlypublicmembersmaybeaccessedinthisway.\nPassenger pass; // pass is a Passenger\n// ...\nif ( !pass.isFrequentFlyer() ) // not already a frequent flyer?\n{\npass.makeFrequentFlyer(\"392953\"); // set pass\u2019s freq flyer number\n}\npass.name = \"Joe Blow\"; // ILLEGAL! name is private\nIn-Class Function Definitions\nIntheaboveexamples, wehaveshownmemberfunctions beingdefinedoutside of\ntheclassbody. Wecanalsodefinememberswithintheclassbody. Whenamember\nfunction is defined within a class it is compiled in line (recall Section 1.4.2). As\nwith in-line functions, in-class function definitions should be reserved for short\nfunctions thatdonotinvolve loops orconditionals. Hereisanexampleofhowthe\nisFrequentFlyermemberfunction wouldbedefinedfromwithintheclass.\nclass Passenger\n{\npublic:\n// ...\nbool isFrequentFlyer() const return isFreqFlyer;\n{ }\n// ...\n;\n}\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 37 \u2014 #59\ni i\n1.5. Classes 37\n1.5.2 Constructors and Destructors\nThe above declaration of the class variable passsuffers from the shortcoming that\nwehave not initialized anyofitsclasses members. Animportant aspect of classes\nis the capability to initialize a class\u2019s member data. A constructor is a special\nmember function whose task is to perform such an initialization. It is invoked\nwhen a new class object comes into existence. There is an analogous destructor\nmemberfunctionthatiscalledwhenaclassobjectgoesoutofexistence.\nConstructors\nAconstructormemberfunction\u2019snameisthesameastheclass,andithasnoreturn\ntype. Because objects may be initialized in different ways, it is natural to define\ndifferent constructors and rely on function overloading to determine which one is\ntobecalled.\nReturningtoourPassengerclass,letusdefinethreeconstructors. Thefirstcon-\nstructorhasnoarguments. Suchaconstructoriscalledadefaultconstructor,since\nit is used in the absence of any initialization information. The second constructor\nis given the values of the member variables to initialize. The third constructor is\ngivenaPassengerreference fromwhichtocopyinformation. Thisiscalledacopy\nconstructor.\nclass Passenger\n{\nprivate:\n// ...\npublic:\nPassenger(); // default constructor\nPassenger(const string& nm, MealType mp, const string& ffn = \"NONE\");\nPassenger(const Passenger& pass); // copy constructor\n// ...\n;\n}\nLook carefully at the second constructor. The notation ffn=\"NONE\"indicates that\nthe argument for ffn is a default argument. That is, an actual argument need not\nbegiven, andifso, thevalue \"NONE\"isusedinstead. Ifanewlycreated passenger\nisnotafrequent flyer,wesimplyomitthisargument. Theconstructor testsforthis\nspecial value and sets things up accordingly. Default arguments can be assigned\nany legal value and can be used for more than one argument. It is often useful\nto define default values for all the arguments of a constructor. Such a constructor\nis the default constructor because it is called if no arguments are given. Default\narguments can be used with any function (not just constructors). The associated\nconstructor definitionsareshownbelow. Notethatthedefault argumentisgivenin\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 38 \u2014 #60\ni i\n38 Chapter1. AC++Primer\nthedeclaration, butnotinthedefinition.\nPassenger::Passenger() // default constructor\n{\nname = \"--NO NAME--\";\nmealPref = NO PREF;\nisFreqFlyer = false;\nfreqFlyerNo = \"NONE\";\n}\n// constructor given member values\nPassenger::Passenger(const string& nm, MealType mp, const string& ffn)\n{\nname = nm;\nmealPref = mp;\nisFreqFlyer = (ffn != \"NONE\"); // true only if ffn given\nfreqFlyerNo = ffn;\n}\n// copy constructor\nPassenger::Passenger(const Passenger& pass)\n{\nname = pass.name;\nmealPref = pass.mealPref;\nisFreqFlyer = pass.isFreqFlyer;\nfreqFlyerNo = pass.freqFlyerNo;\n}\nHere are some examples of how the constructors above can be invoked to de-\nfine Passenger objects. Note that in the cases of p3 and pp2 we have omitted the\nfrequent flyernumber.\nPassenger p1; // default constructor\nPassenger p2(\"John Smith\", VEGETARIAN, 293145); // 2nd constructor\nPassenger p3(\"Pocahontas\", REGULAR); // not a frequent flyer\nPassenger p4(p3); // copied from p3\nPassenger p5 = p2; // copied from p2\nPassenger* pp1 = new Passenger; // default constructor\nPassenger* pp2 = new Passenger(\"Joe Blow\", NO PREF); // 2nd constr.\nPassenger pa[20]; // uses the default constructor\nAlthough theylook different, thedeclarations forp4and p5both callthecopy\nconstructor. These declarations take advantage ofabit ofnotational magic, which\nC++ provides to make copy constructors look more like the type definitions we\nhave seen so far. The declarations for pp1 and pp2 create new passenger objects\nfrom the free store, and return a pointer to each. The declaration of pa declares\nan array of Passenger. The individual members of the array are always initialized\nfromthedefault constructor.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 39 \u2014 #61\ni i\n1.5. Classes 39\nInitializing Class Members with Initializer Lists\nThere is a subtlety that we glossed over in our presentations of the constructors.\nRecall that a string is a class in the standard template library. Our initialization\nusing \u201cname=nm\u201d above relied onthe fact that the string class has an assignment\noperator defined forit. Ifthetypeofnameisaclasswithout anassignment opera-\ntor, this type ofinitialization might not bepossible. Inorder todeal with theissue\nofinitializingmembervariablesthatarethemselvesclasses,C++providesanalter-\nnate method of initialization called an initializer list. This list is placed between\nthe constructor\u2019s argument list and its body. It consists of a colon (:) followed by\na comma-separated list of the form member name(initial value). To illustrate the\nfeature, letusrewritethesecond Passengerconstructor sothatitsfirstthree mem-\nbers are initialized by an initializer list. The initializer list is executed before the\nbodyoftheconstructor.\n// constructor using an initializer list\nPassenger::Passenger(const string& nm, MealType mp, string ffn)\n: name(nm), mealPref(mp), isFreqFlyer(ffn != \"NONE\")\nfreqFlyerNo = ffn;\n{ }\nDestructors\nA constructor is called when a class object comes into existence. A destructor is\namemberfunction thatisautomatically called when aclass object ceases toexist.\nIf a class object comes into existence dynamically using the new operator, the\ndestructor will be called when this object is destroyed using the delete operator.\nIf a class object comes into existence because it is a local variable in a function\nthat has been called, the destructor will be called when the function returns. The\ndestructorforaclassTisdenoted~T.Ittakesnoargumentsandhasnoreturntype.\nDestructors areneeded whenclasses allocate resources, suchasmemory, from the\nsystem. Whentheobject ceases toexist, itistheresponsibility ofthedestructor to\nreturntheseresources tothesystem.\nLet us consider a class Vect, shown in the following code fragment, which\nstores a vector by dynamically allocating an array of integers. The dynamic array\nis referenced by the member variable data. (Recall from Section 1.1.3 that a dy-\nnamically allocated array is represented by a pointer to its initial element.) The\nmembervariable sizestores thenumber ofelements inthevector. Theconstructor\nfor this class allocates an array of the desired size. In order to return this space to\nthesystemwhenaVectobjectisremoved,weneedtoprovideadestructortodeal-\nlocate this space. (Recall that when an array is deleted we use \u201cdelete[ ],\u201d rather\nthan\u201cdelete.\u201d)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 40 \u2014 #62\ni i\n40 Chapter1. AC++Primer\nclass Vect // a vector class\n{\npublic:\nVect(int n); // constructor, given size\n\u02dcVect(); // destructor\n// ... other public members omitted\nprivate:\nint* data; // an array holding the vector\nint size; // number of array entries\n;\n}\nVect::Vect(int n) // constructor\n{\nsize = n;\ndata = new int[n]; // allocate array\n}\nVect::\u02dcVect() // destructor\n{\ndelete [] data; // free the allocated array\n}\nWearenotstrictlyrequiredbyC++toprovideourowndestructor. Nonetheless,\nifourclass allocates memory, weshould writeadestructor tofreethismemory. If\nwe did not provide the destructor in the example above, the deletion of an object\nof type Vect would cause a memory leak. (Recall from Section 1.1.3 that this is\nan inaccessible block of memory that cannot be removed). The job of explicitly\ndeallocating objectsthatwereallocatedisoneofthechoresthatC++programmers\nmustendure.\n1.5.3 Classes and Memory Allocation\nWhenaclass performs memoryallocation using new, caremustbetaken toavoid\na number of common programming errors. We have shown above that failure to\ndeallocate storage in aclass\u2019s destructor can result in memory leaks. A somewhat\nmoreinsidiousproblem occurswhenclassesthatallocatememoryfailtoprovidea\ncopyconstructororanassignmentoperator. Considerthefollowingexample,using\nourVectclass.\nVect a(100); // a is a vector of size 100\nVect b = a; // initialize b from a (DANGER!)\nVect c; // c is a vector (default size 10)\nc = a; // assign a to c (DANGER!)\nIt would seem that we have just created three separate vectors, all of size 100,\nbuthavewe? Inrealityallthreeofthesevectorssharethesame100-elementarray.\nLetusseewhythishasoccurred.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 41 \u2014 #63\ni i\n1.5. Classes 41\nThe declaration of object a invokes the vector constructor, which allocates an\narray of 100 integers and a.data points to this array. The declaration \u201cVect b=a\u201d\ninitializes b from a. Since we provided no copy constructor in Vect, the system\nuses its default, which simply copies each member of a to b. In particular it sets\n\u201cb.data=a.data.\u201d Noticethatthisdoesnotcopythecontents ofthearray; ratherit\ncopies the pointer to the array\u2019s initial element. This default action is sometimes\ncalledashallowcopy.\nThe declaration of c invokes the constructor with a default argument value of\n10, andhenceallocates anarray of10elements inthefreestore. Because wehave\nnotprovidedanassignmentoperator,thestatement\u201cc=a,\u201dalsodoesashallowcopy\nofatoc. Onlypointers arecopied, notarraycontents. Worseyet,wehavelostthe\npointertoc\u2019soriginal 10-element array,thuscreating amemoryleak.\nNow,a,b,andcallhavemembersthatpointtothesamearrayinthefreestore.\nIfthecontentsofthearraysofoneofthethreeweretochange,theothertwowould\nmysteriously change as well. Worse yet, if one of the three were to be deleted\nbefore theothers (forexample, ifthisvariable wasdeclared inanested block), the\ndestructor would delete the shared array. Wheneither ofthe other twoattempts to\naccess the now deleted array, the results would be disastrous. In short, there are\nmanyproblemshere.\nFortunately, thereisasimplefixforalloftheseproblems. Theproblems arose\nbecause we allocated memory and we used the system\u2019s default copy constructor\nand assignment operator. If a class allocates memory, you should provide a copy\nconstructorandassignmentoperatortoallocatenewmemoryformakingcopies. A\ncopyconstructorforaclassTistypicallydeclaredtotakeasingleargument,which\nis a constant reference to an object of the same class, that is, T(const T& t). As\nshown in the code fragment below, it copies each of the data members from one\nclasstotheotherwhileallocating memoryforanydynamicmembers.\nVect::Vect(const Vect& a) // copy constructor from a\n{\nsize = a.size; // copy sizes\ndata = new int[size]; // allocate new array\nfor (int i = 0; i < size; i++) // copy the vector contents\n{\ndata[i] = a.data[i];\n}\n}\nThe assignment operator is handled by overloading the = operator as shown\nin the next code fragment. The argument \u201ca\u201d plays the role of the object on the\nrightsideoftheassignment operator. Theassignment operator deletes theexisting\narray storage, allocates a new array of the proper size, and copies elements into\nthis new array. The if statement checks against the possibility of self assignment.\n(This can sometimes happen when different variables reference the same object.)\nWeperform this check using the keyword this. Forany instance of aclass object,\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 42 \u2014 #64\ni i\n42 Chapter1. AC++Primer\n\u201cthis\u201d isdefined tobe the address ofthis instance. If thisequals the address of a,\nthen this is acase of self assignment, and weignore the operation. Otherwise, we\ndeallocate theexistingarray, allocateanewarray,andcopythecontentsover.\nVect& Vect::operator=(const Vect& a) // assignment operator from a\n{\nif (this != &a) // avoid self-assignment\n{\ndelete [] data; // delete old array\nsize = a.size; // set new size\ndata = new int[size]; // allocate new array\nfor (int i=0; i < size; i++) // copy the vector contents\n{\ndata[i] = a.data[i];\n}\n}\nreturn *this;\n}\nNotice that in the last line of the assignment operator we return a reference to\nthe current object with the statement \u201creturn *this.\u201d Such an approach is useful\nfor assignment operators, since it allows us to chain together assignments, as in\n\u201ca=b=c.\u201d The assignment \u201cb=c\u201d invokes the assignment operator, copying vari-\nablectobandthenreturnsareferencetob. Thisresultisthenassignedtovariable\na.\nTheonlyotherchanges neededtocomplete thejobwouldbetoaddtheappro-\npriate function declarations to the Vect class. By using the copy constructor and\nassignment operator, we avoid the above memory leak and the dangerous shared\narray. Thelessonsofthelasttwosectionscanbesummarizedinthefollowingrule.\nRemember\nEveryclassthatallocates itsownobjects usingnew should:\nDefineadestructor tofreeanyallocated objects.\n\u2022\nDefineacopyconstructor,whichallocatesitsownnewmemberstor-\n\u2022\nageandcopiesthecontents ofmembervariables.\nDefineanassignmentoperator, whichdeallocates oldstorage, allo-\n\u2022\ncatesnewstorage, andcopiesallmembervariables.\nSomeprogrammersrecommendthatthesefunctionsbeincludedforeveryclass,\nevenifmemoryisnotallocated, butwearenotsofastidious. Inrareinstances, we\nmaywanttoforbidusersfromusingoneormoreoftheseoperations. Forexample,\nwe may not want a huge data structure to be copied inadvertently. In this case,\nwe can define empty copy constructors and assignment functions and make them\nprivatemembersoftheclass.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 43 \u2014 #65\ni i\n1.5. Classes 43\n1.5.4 Class Friends and Class Members\nComplexdatastructurestypicallyinvolvetheinteraction ofmanydifferentclasses.\nIn such cases, there are often issues coordinating the actions of these classes to\nallowsharing ofinformation. Wediscusssomeoftheseissuesinthissection.\nWesaidprivatemembersofaclassmayonlybeaccessedfromwithintheclass,\nbutthereisanexceptiontothis. Specifically,wecandeclareafunctionasafriend,\nwhich means that this function may access the class\u2019s private data. There are a\nnumber of reasons for defining friend functions. One is that syntax requirements\nmay forbid us from defining a member function. For example, consider a class\nSomeClass. Suppose thatwewanttodefineanoverloaded output operator forthis\nclass,andthisoutputoperatorneedsaccesstoprivatememberdata. Tohandlethis,\ntheclassdeclares thattheoutputoperatorisafriendoftheclassasshownbelow.\nclass SomeClass\n{\nprivate:\nint secret;\npublic:\n// ... // give << operator access to secret\nfriend ostream& operator<<(ostream& out, const SomeClass& x);\n;\n}\nostream& operator<<(ostream& out, const SomeClass& x)\ncout << x.secret;\n{ }\nAnothertimewhenitisappropriatetousefriendsiswhentwodifferentclasses\narecloselyrelated. Forexample,CodeFragment1.1showstwocooperatingclasses\nVector and Matrix. The former stores a three-dimensional vector and the latter\nstores a 3 3 matrix. In this code fragment, we show just one example of the\n\u00d7\nusefulness of class friendship. The class Vector stores is coordinates in a private\narray, called coord. The Matrix class defines a function that multiplies a matrix\ntimesavector. BecausecoordisaprivatememberofVector,membersoftheclass\nMatrix would not have access to coord. However, because Vector has declared\nMatrix to be a friend, class Matrix can access all the private members of class\nVector.\nTheabilitytodeclarefriendshiprelationships betweenclassesisuseful,butthe\nextensiveuseoffriendsoftenindicatesapoorclassstructuredesign. Forexample,a\nbettersolutionwouldbetohaveclassVectordefineapublicsubscripting operator.\nThenthemultiplyfunctioncouldusethispublicmembertoaccessthevectorclass,\nratherthanaccessprivatememberdata.\nNote that \u201cfriendship\u201d is not transitive. For example, if a new class Tensor\nwasmade afriend ofMatrix,Tensor would not beafriend of Vector, unless class\nVectorweretoexplicitly declareittobeso.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 44 \u2014 #66\ni i\n44 Chapter1. AC++Primer\nclass Vector // a 3-element vector\n{\npublic: // ... public members omitted\nprivate:\ndouble coord[3]; // storage for coordinates\nfriend class Matrix; // give Matrix access to coord\n;\n}\nclass Matrix // a 3x3 matrix\n{\npublic:\nVector multiply(const Vector& v); // multiply by vector v\n// ... other public members omitted\nprivate:\ndouble a[3][3]; // matrix entries\n;\n}\nVector Matrix::multiply(const Vector& v) // multiply by vector v\n{\nVector w;\nfor (int i = 0; i < 3; i++)\nfor (int j = 0; j < 3; j++)\nw.coord[i] += a[i][j] * v.coord[j]; // access to coord allowed\nreturn w;\n}\nCodeFragment1.1: Anexampleofclassfriendship.\nNesting Classes and Types within Classes\nWeknowthatclassesmaydefinemembervariablesandmemberfunctions. Classes\nmayalsodefinetheirowntypesaswell. Inparticular, wecannestaclassdefinition\nwithin another class. Such anested class is often convenient in the design of data\nstructures. For example, suppose that we want to design a data structure, called\nBook,andwewanttoprovideamechanismforplacingbookmarks toidentifypar-\nticularlocationswithinourbook. Wecoulddefineanestedclass,calledBookmark,\nwhichisdefinedwithinclassBook.\nclass Book\n{\npublic:\nclass Bookmark\n{\n// ... (Bookmark definition here)\n;\n}\n// ... (Remainder of Book definition)\n}\nWemightdefine amember function that returns abookmark within the book, say,\nto the start of some chapter. Outside the class Book, we use the scope-resolution\noperator,Book::Bookmark,inordertorefertothisnestedclass. Weshallseemany\notherexamplesofnestedclasseslaterinthebook.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 45 \u2014 #67\ni i\n1.5. Classes 45\n1.5.5 The Standard Template Library\nTheStandardTemplateLibrary(STL)isacollectionofusefulclassesforcommon\ndata structures. In addition to the string class, which we have seen many times, it\nalso provides data structures for the following standard containers. We discuss\nmanyofthesedatastructures laterinthisbook,sodon\u2019tworryiftheirnamesseem\nunfamiliar.\nstack Container withlast-in, first-outaccess\nqueue Container withfirst-in,first-outaccess\ndeque Double-ended queue\nvector Resizeable array\nlist Doublylinkedlist\npriority queue Queueordered byvalue\nset Set\nmap Associative array(dictionary)\nTemplates and the STL Vector Class\nOneoftheimportant features oftheSTListhateach such object canstoreobjects\nof any one type. Contrast this with the Vect class of Section 1.5.2, which can\nonly hold integers. Suchaclass whose definition depends on auser-specified type\nis called a template. We discuss templates in greater detail in Chapter 2, but we\nbrieflymentionhowtheyareusedwithcontainer objectshere.\nWespecifythetypeoftheobjectbeingstoredinthecontainerinanglebrackets\n(<...>). Forexample, wecould definevectors tohold100integers, 500characters,\nand20passengers asfollows:\n#include <vector>\nusing namespace std; // make std accessible\nvector<int> scores(100); // 100 integer scores\nvector<char> buffer(500); // buffer of 500 characters\nvector<Passenger> passenList(20); // list of 20 Passengers\nAs usual, the include statement provides the necessary declarations for using\nthevectorclass. EachinstanceofanSTLvectorcanonlyholdobjectsofonetype.\nSTL vectors are superior to standard C++ arrays in many respects. First, as\nwitharrays,individualelementscanbeindexedusingtheusualindexoperator([ ]).\nTheycan also be accessed by the atmemberfunction. Theadvantage ofthe latter\nis that it performs range checking and generates an error exception if the index is\nout ofbounds. (Wediscuss exceptions inSection 2.4.) Recall that standard arrays\ninC++donotevenknowtheirsize,andhencerangecheckingisnotevenpossible.\nIn contrast, a vector object\u2019s size is given by its size member function. Unlike\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 46 \u2014 #68\ni i\n46 Chapter1. AC++Primer\nstandard arrays, one vector object can be assigned to another, which results in the\ncontents of one vector object being copied to the other. A vector can be resized\ndynamically by calling the resize member function. Weshow several examples of\nusesoftheSTLvectorclassbelow.\nint i = // ...\ncout << scores[i]; // index (range unchecked)\nbuffer.at(i) = buffer.at(2 * i); // index (range checked)\nvector<int> newScores = scores; // copy scores to newScores\nscores.resize(scores.size() + 10); // add room for 10 more elements\nWediscusstheSTLfurtherinChapter3.\nMore on STL Strings\nInSection1.1.3,weintroduced theSTLstring class. Thisclassprovides anumber\nof useful utilities for manipulating character strings. Earlier, wediscussed the use\nof the addition operator (\u201c+\u201d) for concatenating strings, the operator \u201c+=\u201d for\nappendingastringtotheendofanexistingstring,thefunctionsizefordetermining\nthe length of a string, and the indexing operator (\u201c[]\u201d) for accessing individual\ncharacters ofastring.\nLetus present afew morestring functions. Inthe table below, letsbe anSTL\nstring, and let p be either an STL string or a standard C++ string. Let i and m be\nnonnegative integers. Throughout, we use i to denote the index of a position in a\nstring and we use m to denote the number of characters involved in the operation.\n(Astring\u2019sfirstcharacter isatindexi=0.)\ns.find(p) Returntheindexoffirstoccurrence ofstring pins\ns.find(p, i) Returntheindexoffirstoccurrence ofstring pins\nonorafterposition i\ns.substr(i,m) Returnthesubstring starting atposition iofs\nandconsisting ofmcharacters\ns.insert(i, p) Insertstring pjustpriortoindexiins\ns.erase(i, m) Removethesubstring oflengthmstartingatindexi\ns.replace(i, m, p) Replacethesubstring oflengthmstarting atindexi\nwith p\ngetline(is, s) Readasinglelinefromtheinputstreamisandstore\ntheresultins\nInordertoindicatethatapatternstring pisnotfound,thefindfunctionreturns\nthe special value string::npos. Strings can also be compared lexicographically,\nusingtheC++comparison operators: <, <=, >, >=, ==,and !=.\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 47 \u2014 #69\ni i\n1.6. C++ProgramandFileOrganization 47\nHerearesomeexamplesoftheuseofthesefunctions.\nstring s = \"a dog\"; // \u201ca dog\u201d\ns += \" is a dog\"; // \u201ca dog is a dog\u201d\ncout << s.find(\"dog\"); // 2\ncout << s.find(\"dog\", 3); // 11\nif (s.find(\"doug\") == string::npos) // true\n{ }\ncout << s.substr(7, 5); // \u201cs a d\u201d\ns.replace(2, 3, \"frog\"); // \u201ca frog is a dog\u201d\ns.erase(6, 3); // \u201ca frog a dog\u201d\ns.insert(0, \"is \"); // \u201cis a frog a dog\u201d\nif (s == \"is a frog a dog\") // true\n{ }\nif (s < \"is a frog a toad\") // true\n{ }\nif (s < \"is a frog a cat\") // false\n{ }\n1.6 C++ Program and File Organization\nLet us now consider the broader issue of how to organize an entire C++ program.\nA typical large C++ program consists of many files, with related pieces of code\nresiding within each file. For example, C++ programmers commonly place each\nmajorclassinitsownfile.\nSource Files\nThere are two common file types, source files and header files. Source files typi-\ncallycontain mostoftheexecutable statements anddatadefinitions. Thisincludes\nthebodiesoffunctions anddefinitions ofanyglobalvariables.\nDifferent compilers use different file naming conventions. Source file names\ntypicallyhavedistinctivesuffixes,suchas\u201c.cc\u201d,\u201c.cpp\u201d,and\u201c.C\u201d.Sourcefilesmay\nbecompiledseparately bythecompiler, andthenthesefilesarecombined intoone\nprogram byasystem programcalledalinker.\nEachnonconstantglobalvariableandfunctionmaybedefinedonlyonce. Other\nsource files may share such a global variable or function provided they have a\nmatching declaration. To indicate that a global variable is defined in another file,\nthe type specifier \u201cextern\u201d is added. This keyword is not needed for functions.\nFor example, consider the declarations extracted from two files below. The file\nSource1.cpp defines a global variable cat and function foo. The file Source2.cpp\ncan access these objects by including the appropriate matching declarations and\nadding\u201cextern\u201dforvariables.\nFile: Source1.cpp\nint cat = 1; // definition of cat\nint foo(int x) return x+1; // definition of foo\n{ }\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 48 \u2014 #70\ni i\n48 Chapter1. AC++Primer\nFile: Source2.cpp\nextern int cat; // cat is defined elsewhere\nint foo(int x); // foo is defined elsewhere\nHeader Files\nSincesourcefilesusingsharedobjectsmustprovideidenticaldeclarations,wecom-\nmonlystoretheseshareddeclarations inaheaderfile,whichisthenreadintoeach\nsuch source file using an #include statement. Statements beginning with # are\nhandledbyaspecialprogram, calledthepreprocessor, whichisinvoked automati-\ncallybythecompiler. Aheaderfiletypicallycontainsmanydeclarations, including\nclasses, structures, constants, enumerations, and typedefs. Header files generally\ndo not contain the definition (body) of a function. In-line functions are an excep-\ntion,however,astheirbodiesaregiveninaheaderfile.\nExcept for some standard library headers, the convention is that header file\nnamesendwitha\u201c.h\u201dsuffix. Standardlibraryheaderfilesareindicatedwithangle\nbrackets,asin<iostream>,whileotherlocalheaderfilesareindicatedusingquotes,\nasin\u201dmyIncludes.h\u201d.\n#include <iostream> // system include file\n#include \"myIncludes.h\" // user-defined include file\nAs a general rule, we should avoid including namespace using directives in\nheader files, because anysource filethatincludes such aheader filehasitsnames-\npaceexpandedasaresult. Wemakeoneexceptiontothisinourexamples,however.\nSomeofourheaderfilesincludeausingdirectivefortheSTLstringclassbecause\nitissouseful.\n1.6.1 An Example Program\nTo make this description more concrete, let us consider an example of a simple\nyetcomplete C++program. Ourexample consists ofoneclass, called CreditCard,\nwhichdefinesacreditcardobjectandaprocedure thatusesthisclass.\nThe CreditCard Class\nThecreditcardobjectdefinedbyCreditCardisasimplifiedversionofatraditional\ncredit card. Ithasanidentifying number, identifying information about theowner,\nand information about the credit limit and the current balance. It does not charge\ninterest or late payments, but it does restrict charges that would cause a card\u2019s\nbalancetogooveritsspending limit.\nThe main class structure is presented in the header file CreditCard.h and is\nshowninCodeFragment1.2.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 49 \u2014 #71\ni i\n1.6. C++ProgramandFileOrganization 49\n#ifndef CREDIT CARD H // avoid repeated expansion\n#define CREDIT CARD H\n#include <string> // provides string\n#include <iostream> // provides ostream\nclass CreditCard\n{\npublic:\nCreditCard(const std::string& no, // constructor\nconst std::string& nm, int lim, double bal=0);\n// accessor functions\nstd::string getNumber() const return number;\n{ }\nstd::string getName() const return name;\n{ }\ndouble getBalance() const return balance;\n{ }\nint getLimit() const return limit;\n{ }\nbool chargeIt(double price); // make a charge\nvoid makePayment(double payment); // make a payment\nprivate: // private member data\nstd::string number; // credit card number\nstd::string name; // card owner\u2019s name\nint limit; // credit limit\ndouble balance; // credit card balance\n;\n}\n// print card information\nstd::ostream& operator<<(std::ostream& out, const CreditCard& c);\n#endif\nCodeFragment1.2: Theheader fileCreditCard.h, which contains thedefinition of\nclassCreditCard.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 50 \u2014 #72\ni i\n50 Chapter1. AC++Primer\nBefore discussing the class, let us say a bit about the general file structure.\nThe first two lines (containing #ifndef and #define) and the last line (containing\n#endif) are used to keep the same header file from being expanded twice. We\ndiscuss this later. The next lines include the header files for strings and standard\ninputandoutput.\nThis class has four private data members. We provide a simple constructor to\ninitialize these members. Therearefouraccessor functions,whichprovide access\nto read the current values of these member variables. Of course, we could have\nalternately defined the member variables as being public and saved the work of\nprovidingtheseaccessorfunctions. However,thiswouldallowuserstomodifyany\nofthesemembervariablesdirectly. Weusuallyprefertorestrictthemodificationof\nmember variables to special update functions. We include two such update func-\ntions, chargeIt and makePayment. We have also defined a stream output operator\nfortheclass.\nTheaccessor functions and makePayment areshort, so wedefine them within\nthe class body. The other member functions and the output operator are defined\noutside the class in the file CreditCard.cpp, shown in Code Fragment 1.3. This\napproachofdefiningaheaderfilewiththeclassdefinitionandanassociatedsource\nfilewiththelongermemberfunctiondefinitions iscommoninC++.\nThe Main Test Program\nOurmainprogramisinthefileTestCard.cpp. Itconsistsofamainfunction,butthis\nfunction does little more than call the function testCard, which does all the work.\nWeincludeCreditCard.htoprovidetheCreditCarddeclaration. Wedonotneedto\ninclude iostream and string, since CreditCard.h does this for us, but it would not\nhavehurttodoso.\nThetestCardfunctiondeclares anarrayofpointerstoCreditCard. Weallocate\nthreesuchobjectsandinitialize them. Wethenperformanumberofpaymentsand\nprint the associated information. We show the complete code for the Test class in\nCodeFragment1.4.\nTheoutputoftheTestclassissenttothestandardoutputstream. Weshowthis\noutputinCodeFragment1.5.\nAvoiding Multiple Header Expansions\nA typical C++ program includes many different header files, which often include\nother header files. Asaresult, the same header filemay be expanded many times.\nSuch repeated header expansion is wasteful and can result in compilation errors\nbecause of repeated definitions. To avoid this repeated expansion, most header\nfiles use a combination of preprocessor commands. Let us explain the process,\nillustrated inCodeFragment1.2.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 51 \u2014 #73\ni i\n1.6. C++ProgramandFileOrganization 51\n#include \"CreditCard.h\" // provides CreditCard\nusing namespace std; // make std:: accessible\n// standard constructor\nCreditCard::CreditCard(const string& no, const string& nm, int lim, double bal)\n{\nnumber = no;\nname = nm;\nbalance = bal;\nlimit = lim;\n}\n// make a charge\nbool CreditCard::chargeIt(double price)\n{\nif (price + balance > double(limit))\nreturn false; // over limit\nbalance += price;\nreturn true; // the charge goes through\n}\nvoid CreditCard::makePayment(double payment) // make a payment\n{\nbalance = payment;\n\u2212\n}\n// print card information\nostream& operator<<(ostream& out, const CreditCard& c)\n{\nout << \"Number = \" << c.getNumber() << \"\\n\"\n<< \"Name = \" << c.getName() << \"\\n\"\n<< \"Balance = \" << c.getBalance() << \"\\n\"\n<< \"Limit = \" << c.getLimit() << \"\\n\";\nreturn out;\n}\nCode Fragment1.3: The file CreditCard.cpp, which contains the definition of the\nout-of-class memberfunctions forclassCreditCard.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 52 \u2014 #74\ni i\n52 Chapter1. AC++Primer\n#include <vector> // provides STL vector\n#include \"CreditCard.h\" // provides CreditCard, cout, string\nusing namespace std; // make std accessible\nvoid testCard() // CreditCard test function\n{\nvector<CreditCard*> wallet(10); // vector of 10 CreditCard pointers\n// allocate 3 new cards\nwallet[0] = new CreditCard(\"5391 0375 9387 5309\", \"John Bowman\", 2500);\nwallet[1] = new CreditCard(\"3485 0399 3395 1954\", \"John Bowman\", 3500);\nwallet[2] = new CreditCard(\"6011 4902 3294 2994\", \"John Bowman\", 5000);\nfor (int j=1; j <= 16; j++) // make some charges\n{\nwallet[0] >chargeIt(double(j)); // explicitly cast to double\n\u2212\nwallet[1] >chargeIt(2 * j); // implicitly cast to double\n\u2212\nwallet[2] >chargeIt(double(3 * j));\n\u2212\n}\ncout << \"Card payments:\\n\";\nfor (int i=0; i < 3; i++) // make more charges\n{\ncout << *wallet[i];\nwhile (wallet[i] >getBalance() > 100.0)\n\u2212 {\nwallet[i] >makePayment(100.0);\n\u2212\ncout << \"New balance = \" << wallet[i] >getBalance() << \"\\n\";\n\u2212\n}\ncout << \"\\n\";\ndelete wallet[i]; // deallocate storage\n}\n}\nint main() // main function\n{\ntestCard();\nreturn EXIT SUCCESS; // successful execution\n}\nCodeFragment1.4: ThefileTestCard.cpp.\nLetusstartwiththesecondline. The#definestatementdefinesapreprocessor\nvariable CREDIT CARD H. This variable\u2019s name istypically based on the header\nfile name, and by convention, it is written in all capitals. The name itself is not\nimportant as long as different header files use different names. The entire file is\nenclosed inapreprocessor \u201cif\u201dblockstartingwith#ifndefontopandendingwith\n#endifatthebottom. The\u201cifndef\u201disread\u201cifnotdefined,\u201dmeaningthattheheader\nfilecontentswillbeexpanded onlyifthepreprocessor variableCREDIT CARD H\nisnotdefined.\nHereishowitworks. Thefirsttimetheheaderfileisencountered, thevariable\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 53 \u2014 #75\ni i\n1.7. WritingaC++Program 53\nCard payments:\nNumber = 5391 0375 9387 5309\nName = John Bowman\nBalance = 136\nLimit = 2500\nNew balance = 36\nNumber = 3485 0399 3395 1954\nName = John Bowman\nBalance = 272\nLimit = 3500\nNew balance = 172\nNew balance = 72\nNumber = 6011 4902 3294 2994\nName = John Bowman\nBalance = 408\nLimit = 5000\nNew balance = 308\nNew balance = 208\nNew balance = 108\nNew balance = 8\nCodeFragment1.5: Sampleprogram output.\nCREDIT CARD H has not yet been seen, so the header file is expanded by the\npreprocessor. In the process of doing this expansion, the second line defines the\nvariableCREDIT CARD H.Hence,anyattempttoincludetheheaderfilewillfind\nthatCREDIT CARD Hisdefined,sothefilewillnotbeexpanded.\nThroughout this book we omit these preprocessor commands from our exam-\nples,buttheyshouldbeincludedineachheaderfilewewrite.\n1.7 Writing a C++ Program\nAswithanyprogramming language, writing aprogram inC++involves three fun-\ndamentalsteps:\n1. Design\n2. Coding\n3. TestingandDebugging.\nWebrieflydiscusseachofthesestepsinthissection.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 54 \u2014 #76\ni i\n54 Chapter1. AC++Primer\n1.7.1 Design\nThedesignstepisperhaps themostimportantintheprocess ofwritingaprogram.\nInthisstep, wedecide howtodivide theworkings ofourprogram intoclasses, we\ndecide how these classes will interact, what data each will store, and what actions\neach will perform. Indeed, one of the main challenges that beginning C++ pro-\ngrammers face is deciding what classes to define to do the work of their program.\nWhile general prescriptions are hard to come by, there are some general rules of\nthumbthatwecanapplywhendetermining howtodefineourclasses.\nResponsibilities: Dividetheworkintodifferent actors, eachwithadifferent\n\u2022\nresponsibility. Try to describe responsibilities using action verbs. These\nactorsformtheclasses fortheprogram.\nIndependence: Define the work for each class to be as independent from\n\u2022\nother classes as possible. Subdivide responsibilities between classes so that\neach class has autonomy over some aspect of the program. Give data (as\nmember variables) to the class that has jurisdiction over the actions that re-\nquireaccesstothisdata.\nBehaviors: Define the behaviors for each class carefully and precisely, so\n\u2022\nthat the consequences of each action performed by a class are well under-\nstood by other classes with which it interacts. These behaviors define the\nmemberfunctionsthatthisclassperforms. Thesetofbehaviorsforaclassis\nsometimesreferredtoasaprotocol,sinceweexpectthebehaviorsforaclass\ntoholdtogether asacohesiveunit.\nDefining the classes, together with their member variables and member func-\ntions, determines thedesignofaC++program. Agoodprogrammer willnaturally\ndevelopgreaterskillinperformingthesetasksovertime,asexperienceteacheshim\nor her to notice patterns in the requirements of a program that match patterns that\nheorshehasseenbefore.\n1.7.2 Pseudo-Code\nProgrammers are often asked to describe algorithms in a way that is intended for\nhumaneyesonly,priortowritingactualcode. Suchdescriptionsarecalledpseudo-\ncode. Pseudo-code is not a computer program, but is more structured than usual\nprose. Pseudo-code is a mixture of natural language and high-level programming\nconstructs that describe the main ideas behind a generic implementation of a data\nstructureoralgorithm. Therereallyisnoprecisedefinitionofthepseudo-codelan-\nguage, however, because of its reliance on natural language. At the same time, to\nhelp achieve clarity, pseudo-code mixes natural language with standard program-\nming language constructs. The programming language constructs we choose are\nthoseconsistent withmodernhigh-level languages suchasC,C++,andJava.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 55 \u2014 #77\ni i\n1.7. WritingaC++Program 55\nTheseconstructs include thefollowing:\nExpressions: We use standard mathematical symbols to express numeric\n\u2022\nand Boolean expressions. Weuse the left arrow sign ( ) as the assignment\n\u2190\noperator inassignment statements (equivalent tothe=operator inC++)and\nwe use the equal sign (=) as the equality relation in Boolean expressions\n(equivalent tothe\u201c==\u201drelation inC++).\nFunction declarations: Algorithm name(arg1,arg2, ...) declares a new\n\u2022\nfunction \u201cname\u201danditsarguments.\nDecision structures: ifcondition then true-actions [else false-actions]. We\n\u2022\nuseindentationtoindicatewhatactionsshouldbeincludedinthetrue-actions\nandfalse-actions.\nWhile-loops: while condition do actions. We use indentation to indicate\n\u2022\nwhatactionsshouldbeincluded intheloopactions.\nRepeat-loops: repeatactionsuntilcondition. Weuseindentationtoindicate\n\u2022\nwhatactionsshouldbeincluded intheloopactions.\nFor-loops: forvariable-increment-definition doactions. Weuseindentation\n\u2022\ntoindicatewhatactionsshouldbeincluded amongtheloopactions.\nArray indexing: A[i] represents the ith cell in the array A. The cells of an\n\u2022\nn-celled arrayAareindexedfromA[0]toA[n 1](consistent withC++).\n\u2212\nMember function calls: object.method(args) (object is optional if it is un-\n\u2022\nderstood).\nFunction returns: return value. This operation returns the value specified\n\u2022\ntothemethodthatcalledthisone.\nComments: Commentgoeshere. . Weenclose commentsinbraces.\n\u2022 { }\nWhen we write pseudo-code, we must keep in mind that we are writing for a\nhuman reader, not a computer. Thus, we should strive to communicate high-level\nideas, notlow-levelimplementation details. Atthesametime,weshouldnotgloss\noverimportantsteps. Likemanyformsofhumancommunication, findingtheright\nbalanceisanimportant skillthatisrefinedthroughpractice.\n1.7.3 Coding\nAs mentioned above, one of the key steps in coding up an object-oriented pro-\ngramiscodingupthedescriptions ofclassesandtheirrespectivedataandmember\nfunctions. In order to accelerate the development of this skill, we discuss vari-\nous design patterns for designing object-oriented programs (see Section 2.1.3) at\nvarious points throughout this text. These patterns provide templates for defining\nclassesandtheinteractions betweentheseclasses.\nManyprogrammersdotheirinitialcodingnotonacomputer,butbyusingCRC\ncards. Class-Responsibility-Collaborator (CRC)cards are simple index cards that\nsubdivide the work required of a program. The main idea behind this tool is to\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 56 \u2014 #78\ni i\n56 Chapter1. AC++Primer\nhaveeachcardrepresentacomponent, whichwillultimatelybecomeaclassinour\nprogram. We write the name of each component on the top of an index card. On\nthe left-hand side of the card, we begin writing the responsibilities for this com-\nponent. On the right-hand side, we list the collaborators for this component, that\nis, the other components that this component will have to interact with to perform\nitsduties. Thedesign processiteratesthrough anaction/actor cycle,wherewefirst\nidentify an action (that is, a responsibility), and we then determine an actor (that\nis, a component) that is best suited to perform that action. Thedesign is complete\nwhenwehaveassignedallactionstoactors.\nBy the way, in using index cards to begin our coding, we are assuming that\neach component will have a small set of responsibilities and collaborators. This\nassumption isnoaccident, sinceithelpskeepourprogramsmanageable.\nAn alternative to CRCcards is the use of UML (Unified Modeling Language)\ndiagrams to express the organization of a program, and the use of pseudo-code to\ndescribe the algorithms. UML diagrams are a standard visual notation to express\nobject-oriented software designs. Several computer-aided tools are available to\nbuild UMLdiagrams. Describing algorithms inpseudo-code, ontheotherhand, is\natechnique thatweutilizethroughout thisbook.\nOnce we have decided on the classes and their respective responsibilities for\nour programs, we are ready to begin coding. We create the actual code for the\nclasses in our program by using either an independent text editor (such as emacs,\nnotepad, orvi),ortheeditorembeddedinanintegrateddevelopmentenvironment\n(IDE),suchasMicrosoft\u2019s VisualStudioandEclipse.\nOnce we have completed coding for a program (or file), we then compile this\nfile into working code by invoking a compiler. If our program contains syntax\nerrors,theywillbeidentified, andwewillhavetogobackintooureditortofixthe\noffending linesofcode. Oncewehaveeliminated allsyntax errorsandcreated the\nappropriate compiledcode,wethenrunourprogram.\nReadability and Style\nProgramsshouldbemadeeasytoreadandunderstand. Goodprogrammers should\ntherefore be mindful of their coding style and develop a style that communicates\ntheimportantaspectsofaprogram\u2019sdesignforbothhumansandcomputers. Much\nhasbeenwrittenaboutgoodcodingstyle. Herearesomeofthemainprinciples.\nUsemeaningful names foridentifiers. Tryto choose namesthat can be read\n\u2022\naloud and reflect the action, responsibility, or data each identifier is nam-\ning. The tradition in most C++ circles is to capitalize the first letter of each\nword in an identifier, except for the first word in an identifier for a variable\nor method. So, in this tradition, \u201cDate,\u201d \u201cVector,\u201d and \u201cDeviceManager\u201d\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 57 \u2014 #79\ni i\n1.7. WritingaC++Program 57\nwouldidentifyclasses,and\u201cisFull,\u201d\u201cinsertItem,\u201d\u201cstudentName,\u201dand\u201cstu-\ndentHeight\u201dwouldrespectively identifymemberfunctions andvariables.\nUse named constants and enumerations instead of embedded values. Read-\n\u2022\nability, robustness, and modifiability are enhanced if we include a series of\ndefinitions ofnamed constant values inaclassdefinition. Thesecanthenbe\nused withinthisclassandothers torefertospecial values forthisclass. Our\nconvention istofullycapitalize suchconstants asshownbelow.\nconst int MIN CREDITS = 12; // min. credits in a term\nconst int MAX CREDITS = 24; // max. credits in a term\n// enumeration for year\nenum Year FRESHMAN, SOPHOMORE, JUNIOR, SENIOR ;\n{ }\nIndentstatementblocks. Typicallyprogrammersindenteachstatementblock\n\u2022\nby four spaces. (In this book, we typically use two spaces to avoid having\nourcodeoverrunthebook\u2019smargins.)\nOrganize each class in a consistent order. In the examples in this book, we\n\u2022\nusually usethefollowingorder:\n1. Publictypesandnestedclasses\n2. Publicmemberfunctions\n3. Protectedmemberfunctions (internal utilities)\n4. Privatememberdata\nOur class organizations do not always follow this convention. In particular,\nwhenwewishtoemphasizetheimplementationdetailsofaclass,wepresent\ntheprivatemembersfirstandthepublicfunctions afterwards.\nUse comments that add meaning to a program and explain ambiguous or\n\u2022\nconfusing constructs. In-line commentsaregood forquickexplanations and\ndo not need to be sentences. Block comments are good for explaining the\npurpose ofamethodandcomplexcodesections.\n1.7.4 Testing and Debugging\nTesting is the process of verifying the correctness of a program, while debugging\nis the process of tracking the execution of a program and discovering the errors\nin it. Testing and debugging are often the most time-consuming activity in the\ndevelopment ofaprogram.\nTesting\nA careful testing plan is an essential part of writing a program. While verifying\nthe correctness of a program over all possible inputs is usually not feasible, we\nshould aim at executing the program on a representative subset of inputs. At the\nvery minimum, we should make sure that every method in the program is tested\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 58 \u2014 #80\ni i\n58 Chapter1. AC++Primer\nat least once (method coverage). Even better, each code statement in the program\nshouldbeexecutedatleastonce(statementcoverage).\nPrograms often tend to fail on special cases of the input. Such cases need to\nbe carefully identified and tested. For example, when testing a method that sorts\nanarrayofintegers(thatis,arrangestheminascending order),weshouldconsider\nthefollowinginputs:\nThearrayhaszerolength(noelements)\n\u2022\nThearrayhasoneelement\n\u2022\nAlltheelementsofthearrayarethesame\n\u2022\nThearrayisalreadysorted\n\u2022\nThearrayisreversesorted\n\u2022\nIn addition to special inputs to the program, we should also consider special\nconditions forthestructures usedbytheprogram. Forexample, ifweuseanarray\ntostoredata,weshouldmakesurethatboundarycases,suchasinserting/removing\natthebeginningorendofthesubarrayholdingdata,areproperlyhandled. Whileit\nisessentialtousehand-craftedtestsuites,itisalsoadvantageoustoruntheprogram\nonalargecollection ofrandomlygenerated inputs.\nThere isahierarchy among the classes and functions ofaprogram induced by\nthe \u201ccaller-callee\u201d relationship. Namely, a function A is above a function B in the\nhierarchyifAcallsB. Therearetwomaintestingstrategies,top-downandbottom-\nup,whichdifferintheorderinwhichfunctions aretested.\nBottom-up testing proceeds from lower-level functions to higher-level func-\ntions. Namely, bottom-level functions, which do not invoke other functions, are\ntested first, followed byfunctions that call only bottom-level functions, and soon.\nThis strategy ensures that errors found in a method are not likely to be caused by\nlower-levelfunctions nestedwithinit.\nTop-downtestingproceedsfromthetoptothebottomofthemethodhierarchy.\nIt is typically used in conjunction with stubbing, a boot-strapping technique that\nreplacesalower-levelmethodwithastub,areplacement forthemethodthatsimu-\nlatestheoutput oftheoriginal method. Forexample, iffunction Acallsfunction B\ntogetthefirstlineofafile,wecanreplace Bwithastub thatreturns afixedstring\nwhentestingA.\nDebugging\nThesimplestdebugging technique consistsofusingprintstatements(typically us-\ning the stream output operator, \u201c<<\u201d) to track the values of variables during the\nexecution of the program. The problem with this approach is that the print state-\nments need to be removed or commented out before the program can be executed\naspartofa\u201cproduction\u201d softwaresystem.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 59 \u2014 #81\ni i\n1.7. WritingaC++Program 59\nAbetterapproach istoruntheprogram within adebugger, whichisaspecial-\nized environment for controlling and monitoring the execution of a program. The\nbasic functionality provided by a debugger is the insertion of breakpoints within\nthe code. When the program is executed within the debugger, it stops at each\nbreakpoint. While the program is stopped, the current value of variables can be\ninspected. In addition to fixed breakpoints, advanced debuggers allow for specifi-\ncationofconditionalbreakpoints,whicharetriggeredonlyifagivenexpressionis\nsatisfied.\nMany IDEs, such as Microsoft Visual Studio and Eclipse provide built-in de-\nbuggers.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 60 \u2014 #82\ni i\n60 Chapter1. AC++Primer\n1.8 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-1.1 Whichofthefollowing isnotavalidC++variable name? (Theremaybe\nmorethanone.)\na. i think i am valid\nb. i may have 2 many digits 2 be valid\nc. I start and end with underscores\nd. I Have A Dollar $ign\ne. I AM LONG AND HAVE NO LOWER CASE LETTERS\nR-1.2 Writeapseudo-code description ofamethod forfinding thesmallest and\nlargestnumbersinanarrayofintegersandcomparethattoaC++function\nthatwoulddothesamething.\nR-1.3 Give a C++ definition of a struct called Pair that consists of two mem-\nbers. The first is an integer called first, and the second isa double called\nsecond.\nR-1.4 Whatarethecontentsofstringsafterexecutingthefollowingstatements.\nstring s = \"abc\";\nstring t = \"cde\";\ns += s + t[1] + s;\nR-1.5 Consider the expression y + 2 * z ++ < 3 - w / 5. Add parentheses\nto show the precise order of evaluation given the C++ rules for operator\nprecedence.\nR-1.6 Consider the following attempt toallocate a10-element array ofpointers\nto doubles and initialize the associated double values to 0.0. Rewrite the\nfollowing (incorrect) code to do this correctly. (Hint: Storage for the\ndoubles needstobeallocated.)\ndouble* dp[10]\nfor (int i = 0; i < 10; i++) dp[i] = 0.0;\nR-1.7 Write a short C++ function that takes an integer n and returns the sum of\nalltheintegerssmallerthann.\nR-1.8 WriteashortC++function,isMultiple,thattakestwopositivelongvalues,\nnandm,andreturnstrueifandonlyifnisamultipleofm,thatis,n=mi\nforsomeintegeri.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 61 \u2014 #83\ni i\n1.8. Exercises 61\nR-1.9 Write a C++ function printArray(A, m, n) that prints an m n two-\n\u00d7\ndimensional array Aofintegers, declared tobe\u201cint** A,\u201dtothestandard\noutput. Eachofthemrowsshouldappearonaseparateline.\nR-1.10 What (if anything) is different about the behavior of the following two\nfunctions fandgthatincrementavariable andprintitsvalue?\nvoid f(int x)\nstd::cout << ++x;\n{ }\nvoid g(int& x)\nstd::cout << ++x;\n{ }\nR-1.11 WriteaC++class,Flower,thathasthreemembervariablesoftypestring,\nint, and float, which respectively represent the name of the flower, its\nnumberofpedals,andprice. Yourclassmustincludeaconstructormethod\nthatinitializeseachvariabletoanappropriatevalue,andyourclassshould\ninclude functions for setting the value of each type, and getting thevalue\nofeachtype.\nR-1.12 Modify the CreditCard class from Code Fragment 1.3 to check that the\nprice argument passed to function chargeIt and the payment argument\npassedtofunctionmakePayment arepositive.\nR-1.13 Modify the CreditCard class from Code Fragment 1.2 to charge interest\noneachpayment.\nR-1.14 ModifytheCreditCardclassfromCodeFragment1.2tocharge alatefee\nforanypaymentthatispastitsduedate.\nR-1.15 ModifytheCreditCardclassfromCodeFragment1.2toincludemodifier\nfunctions that allow a user to modify internal variables in a CreditCard\nclassinacontrolled manner.\nR-1.16 ModifythedeclarationofthefirstforloopintheTestclassinCodeFrag-\nment1.4sothatitscharges willeventually cause exactly oneofthethree\ncreditcardstogooveritscreditlimit. Whichcreditcardisit?\nR-1.17 WriteaC++class, AllKinds,that has three membervariables oftype int,\nlong,andfloat,respectively. Eachclassmustinclude aconstructor func-\ntionthatinitializeseachvariabletoanonzerovalue,andeachclassshould\ninclude functions for setting the value of each type, getting the value of\neach type, and computing and returning the sum of each possible combi-\nnationoftypes.\nR-1.18 Write ashort C++function, isMultiple,that takes two long values, n and\nm,andreturnstrueifandonlyifnisamultipleofm,thatis,n=m ifor\n\u00b7\nsomeintegeri.\nR-1.19 Write a short C++ function, isTwoPower, that takes an int i and returns\ntrueifandonlyifiisapowerof2. Donotusemultiplication ordivision,\nhowever.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 62 \u2014 #84\ni i\n62 Chapter1. AC++Primer\nR-1.20 Write a short C++ function that takes an integer n and returns the sum of\nalltheintegerssmallerthann.\nR-1.21 Write a short C++ function that takes an integer n and returns the sum of\nalltheoddintegerssmallerthann.\nR-1.22 WriteashortC++functionthattakesapositivedoublevaluexandreturns\nthe number of times we can divide x by 2 before we get a number less\nthan2.\nCreativity\nC-1.1 Write a pseudo-code description of a method that reverses an array of n\nintegers,sothatthenumbersarelistedintheoppositeorderthantheywere\nbefore, and compare this method to an equivalent C++ method for doing\nthesamething.\nC-1.2 WriteashortC++functionthattakesanarrayofintvaluesanddetermines\nifthereisapairofnumbersinthearraywhoseproduct iseven.\nC-1.3 Write a C++ function that takes an STL vector of int values and deter-\nmines if all the numbers are different from each other (that is, they are\ndistinct).\nC-1.4 WriteaC++function thattakesanSTLvectorofintvaluesandprintsall\ntheoddvaluesinthevector.\nC-1.5 WriteaC++function that takes anarray containing thesetofall integers\nintherange1to52andshufflesitintorandomorder. Usethebuilt-infunc-\ntion rand, which returns a pseudo-random integer each time it is called.\nYourfunctionshould outputeachpossible orderwithequalprobability.\nC-1.6 Write a short C++ program that outputs all possible strings formed by\nusing each of the characters \u2019a\u2019, \u2019b\u2019, \u2019c\u2019, \u2019d\u2019, \u2019e\u2019, and \u2019f\u2019 exactly\nonce.\nC-1.7 Write ashort C++program that takes all the lines input tostandard input\nand writes them to standard output in reverse order. That is, each line is\noutputinthecorrect order,buttheordering ofthelinesisreversed.\nC-1.8 Write a short C++ program that takes two arguments of type STL vec-\ntor<double>, a and b, and returns the element-by-element product of a\nand b. That is, it returns a vector c of the same length such that c[i] =\na[i] b[i].\n\u00b7\nC-1.9 Write a C++ class Vector2, that stores the (x,y) coordinates of a two-\ndimensional vector, where x and y are of type double. Show how to\noverride various C++operators inorder toimplement theaddition oftwo\nvectors (producing a vector result), the multiplication of a scalar times\na vector (producing a vector result), and the dot product of two vectors\n(producing adoubleresult).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 63 \u2014 #85\ni i\n1.8. Exercises 63\nC-1.10 Write an efficient C++ function that takes any integer value i and returns\n2i, asalong value. Yourfunction should notmultiply 2byitself itimes;\ntherearemuchfasterwaysofcomputing2i.\nC-1.11 Thegreatestcommondivisor,orGCD,oftwopositiveintegersnandmis\nthelargestnumber j,suchthatnandmarebothmultiplesof j. Euclidpro-\nposedasimplealgorithm forcomputingGCD(n,m),wheren>m,which\nis based on a concept known as the Chinese Remainder Theorem. The\nmainideaofthealgorithm istorepeatedly performmodulocomputations\nof consecutive pairs of the sequence that starts (n,m,...), until reaching\nzero. The last nonzero number in this sequence is the GCD of n and m.\nForexample,forn=80,844andm=25,320,thesequence isasfollows:\n80,844 mod 25,320 = 4,884\n25,320 mod 4,884 = 900\n4,884 mod900 = 384\n900 mod384 = 132\n384 mod132 = 120\n132 mod120 = 12\n120 mod 12 = 0\nSo, GCD of 80,844 and 25,320 is 12. Write a short C++ function to\ncomputeGCD(n,m)fortwointegers nandm.\nProjects\nP-1.1 A common punishment for school children is to write out the same sen-\ntence multiple times. Write a C++ stand-alone program that will write\nout the following sentence one hundred times: \u201cI will always use object-\noriented design.\u201d Yourprogram shouldnumbereachofthesentences and\nitshould\u201caccidentally\u201dmakeeightdifferentrandom-lookingtyposatvar-\niouspointsinthelisting,sothatitlookslikeahumantypeditallbyhand.\nP-1.2 Write a C++ program that, when given a starting day (Sunday through\nSaturday) asastring, andafour-digit year, printsacalendar forthatyear.\nEachmonthshouldcontainthenameofthemonth,centeredoverthedates\nfor that month and a line containing the names of the days of the week,\nrunning fromSundaytoSaturday. Eachweekshould beprintedonasep-\narateline. Becareful tocheckforaleapyear.\nP-1.3 Thebirthday paradox says thattheprobability thattwopeople inaroom\nwill have the same birthday is more than half as long as the number of\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 64 \u2014 #86\ni i\n64 Chapter1. AC++Primer\npeopleintheroom(n),ismorethan23. Thispropertyisnotreallyapara-\ndox, but many people find it surprising. Design a C++ program that can\ntest thisparadox byaseries ofexperiments onrandomly generated birth-\ndays,whichtestthisparadoxforn=5,10,15,20,...,100. Youshouldrun\nat least 10 experiments for each value of n and it should output, for each\nn, the number of experiments for that n, such that two people in that test\nhavethesamebirthday.\nChapter Notes\nFor more detailed information about the C++ programming language and the Standard\nTemplate Library, we refer the reader to books by Stroustrup [91], Lippmann and La-\njoie [67], Musser and Saini [81], and Horstmann [47]. Lippmann also wrote a short in-\ntroductionto C++ [66]. For more advancedinformationof how to use C++\u2019s featuresin\nthe most effective manner, consultthe booksby Meyers[77, 76]. For an introductionto\nC++ assuming a backgroundof C see the book by Pohl [84]. For an explanation of the\ndifferencesbetweenC++andJavaseethebookbyBudd[17].\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 65 \u2014 #87\ni i\nChapter\n2\nObject-Oriented Design\nContents\n2.1 Goals, Principles, and Patterns . . . . . . . . . . . . . 66\n2.1.1 Object-Oriented Design Goals . . . . . . . . . . . . 66\n2.1.2 Object-Oriented Design Principles . . . . . . . . . . 67\n2.1.3 Design Patterns . . . . . . . . . . . . . . . . . . . . 70\n2.2 Inheritance and Polymorphism . . . . . . . . . . . . . 71\n2.2.1 Inheritance in C++. . . . . . . . . . . . . . . . . . . 71\n2.2.2 Polymorphism . . . . . . . . . . . . . . . . . . . . . 78\n2.2.3 Examples of Inheritance in C++ . . . . . . . . . . . . 79\n2.2.4 Multiple Inheritance and Class Casting . . . . . . . . 84\n2.2.5 Interfaces and Abstract Classes . . . . . . . . . . . . 87\n2.3 Templates . . . . . . . . . . . . . . . . . . . . . . . . 90\n2.3.1 Function Templates . . . . . . . . . . . . . . . . . . 90\n2.3.2 Class Templates . . . . . . . . . . . . . . . . . . . . 91\n2.4 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . 93\n2.4.1 Exception Objects . . . . . . . . . . . . . . . . . . . 93\n2.4.2 Throwing and Catching Exceptions . . . . . . . . . . 94\n2.4.3 Exception Specification . . . . . . . . . . . . . . . . 96\n2.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 98\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 66 \u2014 #88\ni i\n66 Chapter2. Object-OrientedDesign\n2.1 Goals, Principles, and Patterns\nAsthenameimplies, themain\u201cactors\u201d intheobject-oriented design paradigm are\ncalled objects. An object comes from a class, which is a specification of the data\nmembers that the object contains, as well as the member functions (also called\nmethodsoroperations) thatthe object can execute. Eachclass presents tothe out-\nside world a concise and consistent view of the objects that are instances of this\nclass,withoutgoingintotoomuchunnecessarydetailorgivingothersaccesstothe\ninnerworkings oftheobjects. Thisviewofcomputing isintended tofulfillseveral\ngoalsandincorporate severaldesignprinciples, whichwediscussinthischapter.\n2.1.1 Object-Oriented Design Goals\nSoftware implementations should achieve robustness, adaptability, and reusabil-\nity. (SeeFigure2.1.)\nRobustness Adaptability Reusability\nFigure2.1: Goalsofobject-oriented design.\nRobustness\nEvery good programmer wants to develop software that is correct, which means\nthat a program produces the right output for all the anticipated inputs in the pro-\ngram\u2019s application. In addition, we want software to be robust, that is, capable of\nhandling unexpected inputs that are not explicitly defined for its application. For\nexample,ifaprogramisexpectingapositiveinteger(forexample,representingthe\npriceofanitem)andinsteadisgivenanegativeinteger,thentheprogramshouldbe\nable to recover gracefully from this error. More importantly, in life-critical appli-\ncations,whereasoftwareerrorcanleadtoinjuryorlossoflife,softwarethatisnot\nrobust could be deadly. This point was driven home in the late 1980s in accidents\ninvolving Therac-25, a radiation-therapy machine, which severely overdosed six\npatientsbetween1985and1987,someofwhomdiedfromcomplications resulting\nfromtheirradiation overdose. Allsixaccidents weretracedtosoftwareerrors.\nwww.allitebooks.com\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 67 \u2014 #89\ni i\n2.1. Goals,Principles,andPatterns 67\nAdaptability\nModern software applications, such as Web browsers and Internet search engines,\ntypically involve large programs that are used for many years. Software therefore\nneedstobeabletoevolveovertimeinresponse tochanging conditions initsenvi-\nronment. Thus,anotherimportantgoalofqualitysoftwareisthatitachievesadapt-\nability(alsocalledevolvability). Relatedtothisconceptisportability, whichisthe\nability of software to run with minimal change on different hardware and operat-\ning system platforms. An advantage of writing software in C++ is the portability\nprovided bythelanguage itself.\nReusability\nGoing hand in hand with adaptability is the desire that software be reusable, that\nis, the same code should be usable as a component of different systems in various\napplications. Developing quality software can be an expensive enterprise, and its\ncostcanbeoffsetsomewhatifthesoftwareisdesignedinawaythatmakesiteasily\nreusable infuture applications. Such reuse should bedone withcare, however, for\noneofthemajorsourcesofsoftwareerrorsintheTherac-25camefrominappropri-\nate reuse of Therac-20 software (which was not object-oriented and not designed\nforthehardwareplatformusedwiththeTherac-25).\n2.1.2 Object-Oriented Design Principles\nChief among theprinciples of theobject-oriented approach, which are intended to\nfacilitate thegoalsoutlined above,arethefollowing(seeFigure2.2):\nAbstraction\n\u2022\nEncapsulation\n\u2022\nModularity.\n\u2022\nAbstraction Encapsulation Modularity\nFigure2.2: Principlesofobject-oriented design.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 68 \u2014 #90\ni i\n68 Chapter2. Object-OrientedDesign\nAbstraction\nThe notion of abstraction is to distill a complicated system down to its most fun-\ndamental parts and describe these parts in a simple, precise language. Typically,\ndescribing the parts of a system involves naming them and explaining their func-\ntionality. Applying the abstraction paradigm to the design of data structures gives\nrise to abstract data types (ADTs). An ADT is a mathematical model of a data\nstructurethatspecifiesthetypeofthedatastored,theoperationssupportedonthem,\nandthetypesoftheparametersoftheoperations. AnADTspecifieswhateachop-\neration does, but not how it does it. In C++, the functionality of a data structure\nis expressed through the public interface ofthe associated class or classes that de-\nfinethedatastructure. Bypublicinterface, wemeanthesignatures (names,return\ntypes, and argument types) of a class\u2019s public member functions. This is the only\npartoftheclassthatcanbeaccessed byauseroftheclass.\nAn ADT is realized by a concrete data structure, which is modeled in C++\nby a class. A class defines the data being stored and the operations supported by\nthe objects that are instances of the class. Also, unlike interfaces, classes specify\nhow the operations are performed in the body of each function. A C++ class is\nsaid to implement an interface if its functions include all the functions declared\nin the interface, thus providing a body for them. However, a class can have more\nfunctions thanthoseoftheinterface.\nEncapsulation\nAnotherimportantprincipleofobject-oriented designistheconceptofencapsula-\ntion,whichstatesthatdifferentcomponentsofasoftwaresystemshouldnotreveal\ntheinternaldetailsoftheirrespectiveimplementations. Oneofthemainadvantages\nof encapsulation is that it gives the programmer freedom in implementing the de-\ntailsofasystem. Theonlyconstraintontheprogrammeristomaintaintheabstract\ninterface thatoutsiders see.\nModularity\nIn addition to abstraction and encapsulation, a fundamental principle of object-\noriented design is modularity. Modern software systems typically consist of sev-\neraldifferentcomponents thatmustinteractcorrectlyinorderfortheentiresystem\nto work properly. Keeping these interactions straight requires that these different\ncomponents be well organized. In object-oriented design, this code structuring\napproach centers around the concept of modularity. Modularity refers to an orga-\nnizing principle for code in which different components of a software system are\ndividedintoseparate functional units.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 69 \u2014 #91\ni i\n2.1. Goals,Principles,andPatterns 69\nHierarchical Organization\nThe structure imposed by modularity helps to enable software reusability. If soft-\nwaremodules arewritten inanabstract wayto solve general problems, then mod-\nules can be reused when instances of these same general problems arise in other\ncontexts.\nForexample,thestructuraldefinitionofawallisthesamefromhousetohouse,\ntypicallybeingdefinedintermsofverticalstuds,spacedatfixed-distanceintervals,\netc. Thus, an organized architect can reuse his or her wall definitions from one\nhousetoanother. Inreusing suchadefinition, somepartsmayrequireredefinition,\nforexample,awallinacommercialbuilding maybesimilartothatofahouse, but\ntheelectrical systemandstudmaterialmightbedifferent.\nAnaturalwaytoorganizevariousstructuralcomponentsofasoftwarepackage\nis in a hierarchical fashion, which groups similar abstract definitions together in\na level-by-level manner that goes from specific to more general as one traverses\nup the hierarchy. A common use of such hierarchies is in an organizational chart\nwhere each link going up can be read as \u201cis a,\u201d as in \u201ca ranch is a house is a\nbuilding.\u201d Thiskindofhierarchyisusefulinsoftwaredesign,foritgroupstogether\ncommonfunctionality atthemostgeneral level, and viewsspecialized behavior as\nanextensionofthegeneralone.\nBuilding\nCommercial\nApartment House\nBuilding\nLow-rise High-rise Two-story\nRanch Skyscraper\nApartment Apartment House\nFigure2.3: Anexampleofan\u201cisa\u201dhierarchyinvolving architectural buildings.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 70 \u2014 #92\ni i\n70 Chapter2. Object-OrientedDesign\n2.1.3 Design Patterns\nOne of the advantages of object-oriented design is that it facilitates reusable, ro-\nbust, andadaptable software. Designing good codetakes morethan simply under-\nstanding object-oriented methodologies, however. It requires the effective use of\nobject-oriented designtechniques.\nComputing researchers andpractitioners havedeveloped avariety oforganiza-\ntional concepts and methodologies for designing quality object-oriented software\nthat is concise, correct, and reusable. Ofspecial relevance to this book is the con-\ncept ofadesign pattern, whichdescribes asolution toa\u201ctypical\u201d software design\nproblem. Apatternprovidesageneraltemplateforasolutionthatcanbeappliedin\nmanydifferentsituations. Itdescribesthemainelementsofasolutioninanabstract\nway that can be specialized for a specific problem at hand. It consists of a name,\nwhichidentifiesthepattern,acontext,whichdescribesthescenariosforwhichthis\npattern canbeapplied, atemplate, whichdescribes howthepattern isapplied, and\naresult, whichdescribes andanalyzes whatthepattern produces.\nWepresent several design patterns inthis book, andweshow how they canbe\nconsistently applied to implementations of data structures and algorithms. These\ndesign patterns fall into two groups\u2014patterns for solving algorithm design prob-\nlems and patterns for solving software engineering problems. Some of the algo-\nrithmdesignpatternswediscussinclude thefollowing:\nRecursion (Section3.5)\n\u2022\nAmortization (Section6.1.3)\n\u2022\nDivide-and-conquer (Section11.1.1)\n\u2022\nPrune-and-search, alsoknownasdecrease-and-conquer (Section11.5.1)\n\u2022\nBruteforce(Section12.3.1)\n\u2022\nThegreedymethod(Section12.4.2)\n\u2022\nDynamicprogramming (Section12.2)\n\u2022\nLikewise,someofthesoftwareengineeringdesignpatternswediscussinclude:\nPosition(Section6.2.1)\n\u2022\nAdapter(Section5.3.4)\n\u2022\nIterator (Section6.2.1)\n\u2022\nTemplatemethod(Sections 7.3.7,11.4,and13.3.3)\n\u2022\nComposition (Section8.1.2)\n\u2022\nComparator(Section8.1.2)\n\u2022\nDecorator(Section13.3.1)\n\u2022\nRather than explain each of these concepts here, however, we introduce them\nthroughoutthetextasnotedabove. Foreachpattern,beitforalgorithmengineering\norsoftwareengineering, weexplainitsgeneraluseandweillustrateitwithatleast\noneconcrete example.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 71 \u2014 #93\ni i\n2.2. InheritanceandPolymorphism 71\n2.2 Inheritance and Polymorphism\nTo take advantage of hierarchical relationships, which are common in software\nprojects, theobject-oriented designapproach provides waysofreusingcode.\n2.2.1 Inheritance in C++\nTheobject-orientedparadigmprovidesamodularandhierarchicalorganizingstruc-\ntureforreusingcodethroughatechniquecalledinheritance. Thistechniqueallows\nthedesignofgenericclassesthatcanbespecializedtomoreparticularclasses,with\nthe specialized classes reusing the code from the generic class. Forexample, sup-\npose that we are designing a set of classes to represent people at a university. We\nmight have a generic class Person, which defines elements common to all people.\nWe could then define specialized classes such as Student, Administrator, and In-\nstructor, each of which provides specific information about a particular type of\nperson.\nA generic class is also known as a base class, parent class, or superclass.\nIt defines \u201cgeneric\u201d members that apply in a multitude of situations. Any class\nthat specializes or extends abase class need notgive new implementations for the\ngeneral functions, for it inherits them. It should only define those functions that\narespecialized forthisparticular class. Suchaclassiscalledaderivedclass,child\nclass,orsubclass.\nLet us consider an example to illustrate these concepts. Suppose that we are\nwriting a program to deal with people at a university. Below we show a partial\nimplementation of a generic class for a person. We use \u201c// ...\u201d to indicate code\nthatisirrelevant totheexampleandsohasbeenomitted.\nclass Person // Person (base class)\n{\nprivate:\nstring name; // name\nstring idNum; // university ID number\npublic:\n// ...\nvoid print(); // print information\nstring getName(); // retrieve name\n;\n}\nSuppose wenext wishtodefineastudent object. Wecan derive ourclass Stu-\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 72 \u2014 #94\ni i\n72 Chapter2. Object-OrientedDesign\ndentfromclassPersonasshownbelow.\nclass Student : public Person // Student (derived from Person)\n{\nprivate:\nstring major; // major subject\nint gradYear; // graduation year\npublic:\n// ...\nvoid print(); // print information\nvoid changeMajor(const string& newMajor); // change major\n;\n}\nThe\u201cpublic Person\u201dphraseindicates thattheStudentisderivedfromthePer-\nson class. (The keyword \u201cpublic\u201d specifies public inheritance. We discuss other\ntypes ofinheritance later.) Whenwederive classes inthisway, there isanimplied\n\u201cis a\u201d relationship between them. In this case, a Student \u201cis a\u201d Person. In partic-\nular, a Student object inherits all the member data and member functions of class\nPerson in addition to providing its own members. The relationship between these\ntwoclassesisshowngraphically inaclassinheritancediagram inFigure2.4.\nPerson(cid:13)\n-name : string(cid:13)\n-ssn : string(cid:13)\n+print() : void(cid:13)\n+getName() : string(cid:13)\nStudent(cid:13)\n-major : string(cid:13)\n-gradYear : int(cid:13)\n+print() : void(cid:13)\n+changeMajor(in newMajor : string) : void(cid:13)\nFigure2.4: A class inheritance diagram, showing a base class Person and derived\nclass Student. Entries tagged with \u201c\u2013\u201d are private and entries tagged with \u201c+\u201d are\npublic. Eachblockofthediagram consists ofthreeparts: theclassname,theclass\nmember variables, and the class member functions. The type (or return type) of\neachmemberisindicated afterthecolon(\u201c:\u201d). Thearrowindicates thatStudentis\nderivedfromPerson.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 73 \u2014 #95\ni i\n2.2. InheritanceandPolymorphism 73\nMember Functions\nAn object of type Person can access the public members of Person. An object of\ntype Student can access the public members of both classes. If a Student object\ninvokes the shared print function, it will use its own version by default. We use\nthe class scope operator (::) to specify which class\u2019s function is used, as in Per-\nson::print and Student::print. Note that an object of type Person cannot access\nmembers ofthe base type, and thus it isnot possible fora Person object to invoke\nthechangeMajorfunction ofclassStudent.\nPerson person(\"Mary\", \"12-345\"); // declare a Person\nStudent student(\"Bob\", \"98-764\", \"Math\", 2012); // declare a Student\ncout << student.getName() << endl; // invokes Person::getName()\nperson.print(); // invokes Person::print()\nstudent.print(); // invokes Student::print()\nperson.changeMajor(\"Physics\"); // ERROR!\nstudent.changeMajor(\"English\"); // okay\nC++ programmers often find it useful for a derived class to explicitly invoke a\nmember function of abase class. Forexample, in theprocess ofprinting informa-\ntionforastudent,itisnaturaltofirstprinttheinformationofthePersonbaseclass,\nand then print information particular to the student. Performing this task is done\nusingtheclassscopeoperator.\nvoid Person::print() // definition of Person print\n{\ncout << \"Name \" << name << endl;\ncout << \"IDnum \" << idNum << endl;\n}\nvoid Student::print() // definition of Student print\n{\nPerson::print(); // first print Person information\ncout << \"Major \" << major << endl;\ncout << \"Year \" << gradYear << endl;\n}\nWithoutthe\u201cPerson::\u201d specifierusedabove,theStudent::printfunctionwould\ncallitselfrecursively, whichisnotwhatwewant.\nProtected Members\nEven though class Student is inherited from class Person, member functions of\nStudent do not have access to private members of Person. For example, the fol-\nlowingisillegal.\nvoid Student::printName()\n{\ncout << name << \u2019\\n\u2019; // ERROR! name is private to Person\n}\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 74 \u2014 #96\ni i\n74 Chapter2. Object-OrientedDesign\nSpecialaccessprivilegesforderivedclassescanbeprovidedbydeclaringmem-\nberstobe\u201cprotected.\u201d Aprotectedmemberis\u201cpublic\u201dtoallclassesderivedfrom\nthisone,but\u201cprivate\u201dtoallotherfunctions. Fromasyntactic perspective, thekey-\nword protected behaves in the same way as the keyword private and public. In\ntheclassexampleabove,hadwedeclarednametobeprotected ratherthanprivate,\ntheabovefunction printNamewouldworkfine.\nAlthough C++ makes no requirements on the order in which the various sec-\ntions of a class appear, there are two common ways of doing it. The first is to\ndeclare public members first and private members last. This emphasizes the ele-\nments that are important to auser ofthe class. Theother way is topresent private\nmembers first and public members last. This tends to be easier to read for an im-\nplementor. Of course, clarity is a more important consideration than adherence to\nanystandard.\nIllustrating Class Protection\nConsiderforexample,threeclasses: abaseclassBase,aderivedclassDerived,and\nanunrelated classUnrelated. Thebaseclassdefinesthreeintegermembers,oneof\neachaccesstype.\nclass Base\n{\nprivate: int priv;\nprotected: int prot;\npublic: int publ;\n;\n}\nclass Derived: public Base\n{\nvoid someMemberFunction()\n{\ncout << priv; // ERROR: private member\ncout << prot; // okay\ncout << publ; // okay\n}\n;\n}\nclass Unrelated\n{\nBase X;\nvoid anotherMemberFunction()\n{\ncout << X.priv; // ERROR: private member\ncout << X.prot; // ERROR: protected member\ncout << X.publ; // okay\n}\n;\n}\nWhen designing a class, we should give careful thought to the access privi-\nleges we give each member variable or function. Member variables are almost\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 75 \u2014 #97\ni i\n2.2. InheritanceandPolymorphism 75\nalways declared tobeprivate oratleast protected, since they determine the details\nof the class\u2019s implementation. A user of the class can access only the public class\nmembers, which consist of the principal member functions for accessing and ma-\nnipulating classobjects. Finally,protected membersarecommonlyusedforutility\nfunctions, which may be useful to derived classes. Wewill see many examples of\nthesethreeaccesstypesintheexamplesappearing inlaterchapters.\nConstructors and Destructors\nWesawinSection1.5.2,thatwhenaclassobjectiscreated, theclass\u2019sconstructor\niscalled. Whenaderived classisconstructed, itistheresponsibility ofthisclass\u2019s\nconstructor to takecare that the appropriate constructor iscalled forits base class.\nClasshierarchies inC++areconstructed bottom-up: baseclassfirst,thenitsmem-\nbers, then the derived class itself. For this reason, the constructor for a base class\nneedstobecalledintheinitializer list(seeSection1.5.2)ofthederivedclass. The\nexample below shows how constructors might be implemented for the Person and\nStudentclasses.\nPerson::Person(const string& nm, const string& id)\n: name(nm), // initialize name\nidNum(id) // initialize ID number\n{ }\nStudent::Student(const string& nm, const string& id,\nconst string& maj, int year)\n: Person(nm, id), // initialize Person members\nmajor(maj), // initialize major\ngradYear(year) // initialize graduation year\n{ }\nOnlythePerson(nm,id)callhastobeintheinitializerlist. Theotherinitializations\ncouldbeplacedintheconstructorfunctionbody( ... ),butputtingclassinitializa-\n{ }\ntions in the initialization list is generally more efficient. Suppose that we create a\nnewstudentobject.\nStudent* s = new Student(\"Carol\", \"34-927\", \"Physics\", 2014);\nNote that the constructor for the Student class first makes a function call to Per-\nson(\u201dCarol\u201d, \u201d34-927\u201d) to initialize the Person base class, and then it initializes\nthemajorto\u201dPhysics\u201dandtheyearto2014.\nClassesaredestroyed inthereverseorderfromtheirconstruction, withderived\nclasses destroyed before base classes. For example, suppose that we declared de-\nstructors for these two classes. (Note that destructors are not really needed in this\ncase,becauseneither classallocates storageorotherresources.)\nPerson::\u02dcPerson() ... // Person destructor\n{ }\nStudent::\u02dcStudent() ... // Student destructor\n{ }\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 76 \u2014 #98\ni i\n76 Chapter2. Object-OrientedDesign\nIf we were to destroy our student object, the Student destructor would be called\nfirst,followedbythePersondestructor. Unlikeconstructors,theStudentdestructor\ndoes not need to (and is not allowed to) call the Person destructor. This happens\nautomatically.\ndelete s; // calls \u02dcStudent() then \u02dcPerson()\nStatic Binding\nWhenaclassisderivedfromabaseclass,aswithStudentandPerson,thederived\nclassbecomesasubtypeofthebaseclass,whichmeansthatwecanusethederived\nclasswhereverthebaseclassisacceptable. Forexample,supposethatwecreatean\narrayofpointers touniversity people.\nPerson* pp[100]; // array of 100 Person pointers\npp[0] = new Person(...); // add a Person (details omitted)\npp[1] = new Student(...); // add a Student (details omitted)\nSince getName is common to both classes, it can be invoked on either elements\nof the array. A more interesting issue arises if we attempt to invoke print. Since\npp[1] holds the address of a Student object, wemight think that the function Stu-\ndent::print would be called. Surprisingly, the function Person::print is called in\nbothcases,inspiteoftheapparentdifferenceinthetwoobjects. Furthermore,pp[i]\nisnotevenallowedtoaccessStudentmemberfunctions.\ncout << pp[1] >getName() << \u2019\\n\u2019; // okay\n\u2212\npp[0] >print(); // calls Person::print()\n\u2212\npp[1] >print(); // also calls Person::print() (!)\n\u2212\npp[1] >changeMajor(\"English\"); // ERROR!\n\u2212\nThereason forthisapparently anomalous behavior iscalled static binding\u2014when\ndetermining which memberfunction tocall, C++\u2019s default action isto consider an\nobject\u2019sdeclared type,notitsactualtype. Sincepp[1]isdeclared tobeapointerto\naPerson,themembersforthatclassareused. Nonetheless, C++provides awayto\nachievethedesireddynamiceffectusingthetechnique wedescribe next.\nDynamic Binding and Virtual Functions\nAswesawabove, C++uses static binding bydefault todetermine which member\nfunction to call for a derived class. Alternatively, in dynamic binding, an object\u2019s\ncontents determine which member function is called. To specify that a member\nfunction should use dynamic binding, the keyword \u201cvirtual\u201d isadded to the func-\ntion\u2019s declaration. Let us redefine our Person and Student, but this time we will\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 77 \u2014 #99\ni i\n2.2. InheritanceandPolymorphism 77\ndeclaretheprintfunctiontobevirtual.\nclass Person // Person (base class)\n{\nvirtual void print() ... // print (details omitted)\n{ }\n// ...\n;\n}\nclass Student : public Person // Student (derived from Person)\n{\nvirtual void print() ... // print (details omitted)\n{ }\n// ...\n;\n}\nLet us consider the effect of this change on our array example, thereby illus-\ntratingtheusefulness ofdynamicbinding.\nPerson* pp[100]; // array of 100 Person pointers\npp[0] = new Person(...); // add a Person (details omitted)\npp[1] = new Student(...); // add a Student (details omitted)\npp[0] >print(); // calls Person::print()\n\u2212\npp[1] >print(); // calls Student::print()\n\u2212\nIn this case, pp[1] contains a pointer to an object of type Student, and by the\npower of dynamic binding with virtual functions, the function Student::print will\nbecalled. Thedecision astowhich function tocall ismadeatrun-time, hence the\nnamedynamicbinding.\nVirtual Destructors\nThere is no such thing as a virtual constructor. Such a concept does not make any\nsense. Virtualdestructors,however,areveryimportant. Inourarrayexample,since\nwestore objects ofboth types Person andStudentinthearray, itisimportant that\nthe appropriate destructor be called for each object. However, if the destructor is\nnonvirtual, then only the Person destructor will be called in each case. In our ex-\nample,thischoiceisnotaproblem. ButiftheStudentclasshadallocatedmemory\ndynamically, the fact that the wrong destructor iscalled would result in amemory\nleak(seeSection1.5.3).\nWhenwritingabaseclass,wecannotknow,ingeneral,whetheraderivedclass\nmay need to implement a destructor. So, to be safe, when defining any virtual\nfunctions, it is recommended that a virtual destructor be defined as well. This\ndestructor may do nothing at all, and that is fine. It is provided just in case a\nderived class needs to define its own destructor. This principle is encapsulated in\nthefollowingruleofthumb.\nRemember If a base class defines any virtual functions, it should define a virtual de-\nstructor,evenifitisempty.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 78 \u2014 #100\ni i\n78 Chapter2. Object-OrientedDesign\nDynamicbindingisapowerfultechnique,sinceitallowsustocreateanobject,\nsuch asthearray ppabove, whosebehavior varies depending onits contents. This\ntechnique isfundamental totheconceptofpolymorphism, whichwediscussinthe\nnextsection.\n2.2.2 Polymorphism\nLiterally, \u201cpolymorphism\u201d means \u201cmany forms.\u201d In the context of object-oriented\ndesign, itreferstotheabilityofavariabletotakedifferenttypes. Polymorphismis\ntypicallyappliedinC++usingpointervariables. Inparticular,avariable pdeclared\nto be a pointer to some class S implies that pcan point to any object belonging to\nanyderivedclassTofS.\nNow consider what happens if both of these classes define a virtual member\nfunction a, and let us consider which of these functions is called when we invoke\np->a(). Since dynamic binding is used, if p points to an object of type T, then\nit invokes the function T::a. In this case, T is said to override function a from S.\nAlternatively, if ppointstoanobjectoftypeS,itwillinvoke S::a.\nPolymorphismsuchasthisisusefulbecausethecallerof p->a()doesnothave\nto know whether the pointer p refers to an instance of T or S in order to get the a\nfunction toexecute correctly. Apointer variable pthatpoints toaclass object that\nhasatleastonevirtualfunctionissaidtobepolymorphic. Thatis, pcantakemany\nforms, depending on the specific class of the object it is referring to. This kind of\nfunctionality allows aspecialized class T toextend aclass S,inherit the \u201cgeneric\u201d\nfunctions from class S, and redefine other functions from class S to account for\nspecificproperties ofobjectsofclassT.\nInheritance, polymorphism, and function overloading support reusable soft-\nware. We can define classes that inherit generic member variables and functions\nand can then define new, more specific variables and functions that deal with spe-\ncial aspects of objects of the new class. For example, suppose that we defined a\ngeneric class Person and then derived three classes Student, Administrator, and\nInstructor. We could store pointers to all these objects in a list of type Person*.\nWhen we invoke a virtual member function, such as print, to any element of the\nlist,itwillcallthefunction appropriate totheindividual element\u2019stype.\nSpecialization\nThere are two primary ways of using inheritance, one of which is specialization.\nIn using specialization, we are specializing a general class to a particular derived\nclass. Such derived classes typically possess an \u201cis a\u201d relationship to their base\nclass. The derived classes inherit all the members of the base class. For each\ninherited function, if that function operates correctly, independent of whether it\nis operating for a specialization, no additional work is needed. If, on the other\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 79 \u2014 #101\ni i\n2.2. InheritanceandPolymorphism 79\nhand, ageneral function of thebase class would notwork correctly on thederived\nclass,thenweshouldoverridethefunction tohavethecorrect functionality forthe\nderivedclass.\nFor example, we could have a general class, Dog, which has a function drink\nandafunction sniff. Specializing thisclasstoaBloodhoundclass wouldprobably\nnot require that we override the drink function, as all dogs drink pretty much the\nsameway. Butitcouldrequirethatweoverridethesnifffunction,asaBloodhound\nhas a much more sensitive sense of smell than a \u201cgeneric\u201d dog. In this way, the\nBloodhoundclassspecializes thefunctions ofitsbaseclass,Dog.\nExtension\nAnother way of using inheritance is extension. In using extension, we reuse the\ncodewrittenforfunctions ofthebaseclass,butwethenaddnewfunctionsthatare\nnotpresentinthebaseclass,soastoextenditsfunctionality. Forexample,returning\nto our Dog class, we might wish to create a derived class, BorderCollie, which\ninherits all the generic functions of the Dog class, but then adds a new function,\nherd, since Border Collies have a herding instinct that is not present in generic\ndogs,thereby extendingthefunctionality ofagenericdog.\n2.2.3 Examples of Inheritance in C++\nTomaketheconcepts ofinheritance andpolymorphism moreconcrete, letuscon-\nsiderasimpleexampleinC++. Weconsideranexampleofseveralclassesthatprint\nnumericprogressions. Anumericprogressionisasequenceofnumbers,wherethe\nvalueofeachnumberdependsononeormoreofthepreviousvalues. Forexample,\nan arithmetic progression determines a next number by addition of a fixed incre-\nment. A geometric progression determines a next number by multiplication by a\nfixedbasevalue. Inanycase,aprogressionrequiresawayofdefiningitsfirstvalue\nanditneedsawayofidentifying thecurrent valueaswell.\nArithmeticprogression (increment 1) 0,1,2,3,4,5,...\nArithmeticprogression (increment 3) 0,3,6,9,12,...\nGeometricprogression (base2) 1,2,4,8,16,32,...\nGeometricprogression (base3) 1,3,9,27,81,...\nWebegin by defining a class, Progression, which is declared in the code frag-\nmentbelow. Itdefinesthe\u201cgeneric\u201d membersandfunctions ofanumericprogres-\nsion. Specifically, itdefinesthefollowingtwolong-integer variablemembers:\nfirst: firstvalueoftheprogression\n\u2022\ncur: currentvalueoftheprogression\n\u2022\nBecause wewantthesevariables tobeaccessible from derived classes, wedeclare\nthemtobeprotected.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 80 \u2014 #102\ni i\n80 Chapter2. Object-OrientedDesign\nWe define a constructor, Progression, a destructor, ~Progression, and the fol-\nlowingthreememberfunctions.\nfirstValue(): Resettheprogression tothefirstvalueandreturnit.\nnextValue(): Steptheprogression tothenextvalueandreturnit.\nprintProgression(n): Resettheprogression andprintitsfirstnvalues.\nclass Progression // a generic progression\n{\npublic:\nProgression(long f = 0) // constructor\n: first(f), cur(f)\n{ }\nvirtual \u02dcProgression() ; // destructor\n{ }\nvoid printProgression(int n); // print the first n values\nprotected:\nvirtual long firstValue(); // reset\nvirtual long nextValue(); // advance\nprotected:\nlong first; // first value\nlong cur; // current value\n;\n}\nThememberfunctionprintProgressionispublicandisdefinedbelow.\nvoid Progression::printProgression(int n) // print n values\n{\ncout << firstValue(); // print the first\nfor (int i = 2; i <= n; i++) // print 2 through n\ncout << \u2019 \u2019 << nextValue();\ncout << endl;\n}\nIn contrast, the member functions firstValue and nextValue are intended as\nutilities that will only be invoked from within this class or its derived classes. For\nthisreason, wedeclarethemtobeprotected. Theyaredefinedbelow.\nlong Progression::firstValue() // reset\n{\ncur = first;\nreturn cur;\n}\nlong Progression::nextValue() // advance\n{\nreturn ++cur;\n}\nIt is our intention that, in order to generate different progressions, derived\nclasses will override one or both of these functions. For this reason, we have de-\nclared both to be virtual. Because there are virtual functions in our class, we have\nalsoprovided avirtual destructor inordertobesafe. (Recall thediscussion ofvir-\ntual destructors from Section 2.2.1.) Atthis point the destructor does nothing, but\nthismightbeoverriddenbyderivedclasses.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 81 \u2014 #103\ni i\n2.2. InheritanceandPolymorphism 81\nArithmetic Progression Class\nLet us consider a class ArithProgression, shown below. We add a new member\nvariable inc,whichprovides thevaluetobeadded toeachnewelementofthepro-\ngression. Wealso override the member function nextValueto produce the desired\nnewbehavior.\nclass ArithProgression : public Progression // arithmetic progression\n{\npublic:\nArithProgression(long i = 1); // constructor\nprotected:\nvirtual long nextValue(); // advance\nprotected:\nlong inc; // increment\n;\n}\nThe constructor and the new member function nextValue are defined below.\nObserve that the constructor invokes the base class constructor Progression to ini-\ntializethebaseobjectinaddition toinitializing thevalueofinc.\nArithProgression::ArithProgression(long i) // constructor\n: Progression(), inc(i)\n{ }\nlong ArithProgression::nextValue() // advance by adding\n{\ncur += inc;\nreturn cur;\n}\nPolymorphism is at work here. When a Progression pointer is pointing to an\nArithProgression object, it will use the ArithProgression functions firstValue and\nnextValue. EventhoughthefunctionprintProgressionisnotvirtual,itmakesuseof\nthispolymorphism. ItscallstothefirstValueandnextValuefunctionsareimplicitly\nforthe\u201ccurrent\u201dobject, whichwillbeoftheArithProgressionclass.\nA Geometric Progression Class\nLetusnext defineGeomProgression that implements ageometric progression. As\nwith the ArithProgression class, this new class inherits the member variables first\nand cur, and themember functions firstValueand printProgression from Progres-\nsion. Weaddanewmembervariablebase,whichholdsthebasevaluetobemulti-\nplied to form each new element of the progression. The constructor initializes the\nbase class with astarting value of 1 rather than 0. The function nextValueapplies\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 82 \u2014 #104\ni i\n82 Chapter2. Object-OrientedDesign\nmultiplication toobtainthenextvalue.\nclass GeomProgression : public Progression // geometric progression\n{\npublic:\nGeomProgression(long b = 2); // constructor\nprotected:\nvirtual long nextValue(); // advance\nprotected:\nlong base; // base value\n;\n}\nGeomProgression::GeomProgression(long b) // constructor\n: Progression(1), base(b)\n{ }\nlong GeomProgression::nextValue() // advance by multiplying\n{\ncur *= base;\nreturn cur;\n}\nA Fibonacci Progression Class\nAs a further example, we define a FibonacciProgression class that represents an-\nother kind of progression, the Fibonacci progression, where the next value is de-\nfined as the sum of the current and previous values. We show the FibonacciPro-\ngression class below. Recall that each element of a Fibonacci series is the sum of\ntheprevioustwoelements.\nFibonacciprogression (first=0,second=1): 0,1,1,2,3,5,8,...\nInaddition tothecurrent valuecur intheProgressionbaseclass,wealsostore\nhere the value of the previous element, denoted prev. The constructor is given the\nfirsttwoelements ofthesequence. Themembervariable first isinherited fromthe\nbase class. We add a new member variable second, to store this second element.\nThedefaultvaluesforthefirstandsecondelementsare0and1,respectively.\nclass FibonacciProgression : public Progression // Fibonacci progression\n{\npublic:\nFibonacciProgression(long f = 0, long s = 1); // constructor\nprotected:\nvirtual long firstValue(); // reset\nvirtual long nextValue(); // advance\nprotected:\nlong second; // second value\nlong prev; // previous value\n;\n}\nTheinitialization processisabittrickybecauseweneedtocreatea\u201cfictitious\u201d\nelement that precedes the first element. Note that setting this element to the value\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 83 \u2014 #105\ni i\n2.2. InheritanceandPolymorphism 83\nsecond first achieves the desired result. Thischange is reflected both in thecon-\n\u2212\nstructor and the overridden member function firstValue. The overridden member\nfunctionnextValuecopiesthecurrentvaluetothepreviousvalue. Weneedtostore\ntheoldpreviousvalueinatemporary variable.\nFibonacciProgression::FibonacciProgression(long f, long s)\n: Progression(f), second(s), prev(second first)\n\u2212 { }\nlong FibonacciProgression::firstValue() // reset\n{\ncur = first;\nprev = second first; // create fictitious prev\n\u2212\nreturn cur;\n}\nlong FibonacciProgression::nextValue() // advance\n{\nlong temp = prev;\nprev = cur;\ncur += temp;\nreturn cur;\n}\nCombining the Progression Classes\nIn order to visualize how the three different progression classes are derived from\nthegenericProgressionclass,wegivetheirinheritance diagraminFigure2.5.\nFigure2.5: Inheritance diagram forclassProgressionanditssubclasses.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 84 \u2014 #106\ni i\n84 Chapter2. Object-OrientedDesign\nTo complete our example, we define the main function shown in Code Frag-\nment 2.1, which performs a simple test of each of the three classes. In this class,\nvariableprogisapolymorphicarrayofpointerstoclassProgression. Sinceeachof\nitsmemberspointstoanobjectofclassArithProgression,GeomProgression,orFi-\nbonacciProgression,thefunctionsappropriatetothegivenprogression areinvoked\nineachcase. Theoutput isshowninCodeFragment 2.2. Notice thatthisprogram\nhasa(unimportant) memoryleakbecauseweneverdeletedtheallocated object.\nThe example presented in this section provides a simple illustration of inheri-\ntanceandpolymorphisminC++. TheProgressionclass,itsderivedclasses,andthe\ntester program have a number of shortcomings, however, which might not be im-\nmediatelyapparent. OneproblemisthatthegeometricandFibonacciprogressions\ngrow quickly, and there isno provision for handling the inevitable overflow of the\nlongintegersinvolved. Forexample,since340>263,ageometricprogressionwith\nbase b = 3 will overflow a 64-bit long integer after 40 iterations. Likewise, the\n94th Fibonacci number is greater than 263; hence, the Fibonacci progression will\noverflow a64-bit long integer after 94 iterations. Another problem isthat wemay\nnotallowarbitrarystartingvaluesforaFibonacciprogression. Forexample,dowe\nallowaFibonacciprogression startingwith0and 1? Dealingwithinputerrorsor\n\u2212\nerror conditions that occur during the running of a C++ program requires that we\nhavesomemechanismforhandlingthem. WediscussthistopiclaterinSection2.4.\n2.2.4 Multiple Inheritance and Class Casting\nIn the examples we have shown so far, a subclass has been derived from a single\nbase class and we didn\u2019t have to deal with the problem of viewing an object of a\nspecificdeclared classasalsobeingofaninherited type. Wediscuss somerelated,\nmore-advanced C++programming issuesinthissection.\nMultiple and Restricted Inheritance\nInC++,weareallowedtoderiveaclassfromanumberofbaseclasses,thatis,C++\nallows multiple inheritance. Although multiple inheritance can be useful, espe-\ncially in defining interfaces, it introduces a number of complexities. For example,\nif both base classes provide a member variable with the same name or a member\nfunctionwiththesamedeclaration, thederivedclassmustspecifyfromwhichbase\nclass the member should be used (which is complicated). For this reason, we use\nsingleinheritance almostexclusively.\nWehave been using public inheritance in our previous examples, indicated by\nthekeyword publicinspecifying thebaseclass. Rememberthatprivatebaseclass\nmembersarenotaccessibleinaderivedclass. Protectedandpublicmembersofthe\nbaseclassbecomeprotectedandpublicmembersofthederivedclass,respectively.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 85 \u2014 #107\ni i\n2.2. InheritanceandPolymorphism 85\n/** Test program for the progression classes */\nint main()\n{\nProgression* prog;\n// test ArithProgression\ncout << \"Arithmetic progression with default increment:\\n\";\nprog = new ArithProgression();\nprog >printProgression(10);\n\u2212\ncout << \"Arithmetic progression with increment 5:\\n\";\nprog = new ArithProgression(5);\nprog >printProgression(10);\n\u2212\n// test GeomProgression\ncout << \"Geometric progression with default base:\\n\";\nprog = new GeomProgression();\nprog >printProgression(10);\n\u2212\ncout << \"Geometric progression with base 3:\\n\";\nprog = new GeomProgression(3);\nprog >printProgression(10);\n\u2212\n// test FibonacciProgression\ncout << \"Fibonacci progression with default start values:\\n\";\nprog = new FibonacciProgression();\nprog >printProgression(10);\n\u2212\ncout << \"Fibonacci progression with start values 4 and 6:\\n\";\nprog = new FibonacciProgression(4, 6);\nprog >printProgression(10);\n\u2212\nreturn EXIT SUCCESS; // successful execution\n}\nCodeFragment2.1: Programfortestingtheprogression classes.\nArithmetic progression with default increment:\n0 1 2 3 4 5 6 7 8 9\nArithmetic progression with increment 5:\n0 5 10 15 20 25 30 35 40 45\nGeometric progression with default base:\n1 2 4 8 16 32 64 128 256 512\nGeometric progression with base 3:\n1 3 9 27 81 243 729 2187 6561 19683\nFibonacci progression with default start values:\n0 1 1 2 3 5 8 13 21 34\nFibonacci progression with start values 4 and 6:\n4 6 10 16 26 42 68 110 178 288\nCodeFragment2.2: OutputofTestProgression program fromCodeFragment2.1.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 86 \u2014 #108\ni i\n86 Chapter2. Object-OrientedDesign\nC++ supports two other types of inheritance. These different types of inheritance\ndiminish theaccessrights forbaseclassmembers. Inprotected inheritance, fields\ndeclared to be public in the base class become protected in the child class. In\nprivate inheritance, fields declared to be public and protected in the base class\nbecomeprivateinthederivedclass. Anexampleisshownbelow.\nclass Base // base class\n{\nprotected: int foo;\npublic: int bar;\n;\n}\nclass Derive1 : public Base // public inheritance\n{\n// foo is protected and bar is public\n;\n}\nclass Derive2 : protected Base // protected inheritance\n{\n// both foo and bar are protected\n;\n}\nclass Derive3 : private Base // public inheritance\n{\n// both foo and bar are private\n;\n}\nProtected and private inheritance are not used as often as public inheritance. We\nonlyusepublicinheritance inthisbook.\nCasting in an Inheritance Hierarchy\nAn object variable can be viewed as being of various types, but it can be declared\nas only one type. Thus, a variable\u2019s declared type determines how it is used, and\neven determines how certain functions will act on it. Enforcing that all variables\nbe typed and that operations declare the types they expect is called strong typing,\nwhichhelpspreventbugs. Nonetheless,wesometimesneedtoexplicitlychange,or\ncast, avariable fromonetypetoanother. Wehavealready introduced typecasting\ninSection1.2.1. Wenowdiscuss howitworksforclasses.\nToillustrate anexamplewherewemaywanttoperform acast, recallourclass\nhierarchy consisting of a base class Person and derived class Student. Suppose\nthat weare storing pointers to objects of both types in an array pp. The following\nattempttochangeastudent\u2019s majorwouldbeflaggedasanerrorbythecompiler.\nPerson* pp[100]; // array of 100 Person pointers\npp[0] = new Person(...); // add a Person (details omitted)\npp[1] = new Student(...); // add a Student (details omitted)\n// ...\npp[1] >changeMajor(\"English\"); // ERROR!\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 87 \u2014 #109\ni i\n2.2. InheritanceandPolymorphism 87\nThe problem is that the base class Person does not have a function changeMajor.\nNotice that this is different from the case of the function print because the print\nfunctionwasprovidedinbothclasses. Nonetheless,we\u201cknow\u201dthatpp[1]pointsto\nanobjectofclassStudent,sothisoperation shouldbelegal.\nTo access the changeMajor function, we need to cast the pp[1] pointer from\ntypePerson*totypeStudent*. Becausethecontentsofavariablearedynamic,we\nneedtousetheC++run-timesystemtodeterminewhetherthiscastislegal,which\niswhatadynamiccastdoes. Thesyntaxofadynamiccastisshownbelow.\ndynamic cast<desired type>(expression )\nDynamic casting can only be applied to polymorphic objects, that is, objects\nthat come from a class with at least one virtual function. Below we show how to\nusedynamiccastingtochange themajorofpp[1].\nStudent* sp = dynamic cast<Student*>(pp[1]); // cast pp[1] to Student*\nsp >changeMajor(\"Chemistry\"); // now changeMajor is legal\n\u2212\nDynamic casting is most often applied for casting pointers within the class\nhierarchy. If an illegal pointer cast is attempted, then the result is a null pointer.\nForexample,wewouldgetaNULLpointerfromanattempttocastpp[0]asabove,\nsinceitpointstoaPersonobject.\nToillustrate theuseofdynamiccast,weaccessalltheelementsofthepparray\nand,forobjects of(actual) typeStudent,changethemajorto\u201cUndecided\u201d\nfor (int i = 0; i < 100; i++)\n{\nStudent *sp = dynamic cast<Student*>(pp[i]);\nif (sp != NULL) // cast succeeded?\nsp >changeMajor(\"Undecided\"); // change major\n\u2212\n}\nThecasting wehavediscussed here could alsohavebeen doneusing thetradi-\ntional C-style cast orthrough astatic cast (recall Section 1.2.1). Unfortunately, no\nerrorcheckingwouldbeperformedinthatcase. AnattempttocastaPersonobject\npointer to aStudent pointer would succeed \u201csilently,\u201d but any attempt to use such\napointerwouldhavedisastrous consequences.\n2.2.5 Interfaces and Abstract Classes\nFor two objects to interact, they must \u201cknow\u201d about each other\u2019s member func-\ntions. To enforce this \u201cknowledge,\u201d the object-oriented design paradigm asks that\nclassesspecifytheapplication programminginterface(API),orsimplyinterface,\nthat their objects present to other objects. In the ADT-based approach (see Sec-\ntion 2.1.2) to data structures followed in this book, an interface defining an ADT\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 88 \u2014 #110\ni i\n88 Chapter2. Object-OrientedDesign\nisspecified asatype definition andacollection ofmemberfunctions forthis type,\nwiththearguments foreachfunction beingofspecifiedtypes.\nSome programming languages provide a mechanism for defining ADTs. One\nexample is Java\u2019s interface. An interface is a collection of function declarations\nwith no data and no bodies. That is, the member functions of an interface are\nalways empty. Whenaclass implements aninterface, itmustimplement all ofthe\nmemberfunctions declaredintheinterface.\nC++ does not provide a direct mechanism for specifying interfaces. Nonethe-\nless, throughout this book weoften provide informalinterfaces, eventhough they\nare not legal C++ structures. For example, a stack data structure (see Chapter 5)\nis a container that supports various operations such as inserting (or pushing) an\nelement onto the top of the stack, removing (or popping) an element from the top\nofthestack, andtestingwhetherthestackisempty. Belowweprovideanexample\nofaminimalinterface forastackofintegers.\nclass Stack // informal interface \u2013 not a class\n{\npublic:\nbool isEmpty() const; // is the stack empty?\nvoid push(int x); // push x onto the stack\nint pop(); // pop the stack and return result\n;\n}\nAbstract Classes\nTheabove informal interface is not avalid construct in C++; it isjust adocumen-\ntation aid. In particular, it does not contain any data members or definitions of\nmember functions. Nonetheless, it is useful, since it provides important informa-\ntionaboutastack\u2019spublicmemberfunctions andhowtheyarecalled.\nAn abstract class in C++ is a class that is used only as a base class for inheri-\ntance; it cannot be used to create instances directly. At first the idea of creating a\nclassthatcannotbeinstantiatedseemstobenonsense,butitisoftenveryimportant.\nForexample, suppose that wewant todefineasetofgeometric shape classes, say,\nCircle, Rectangle, and Triangle. It is natural to derive these related classes from a\nsinglegenericbaseclass,say,Shape. Eachofthederivedclasseswillhaveavirtual\nmemberfunctiondraw,whichdrawstheassociatedobject. Therulesofinheritance\nrequirethatwedefinesuchafunction forthebaseclass,butitisunclearwhatsuch\nafunction meansforagenericshape.\nOnewaytohandlethiswouldbetodefineShape::drawwithanemptyfunction\nbody ( ), which would be a rather unnatural solution. What is really desired\n{ }\nhere is some way to inform the compiler that the class Shapeis abstract; it is not\npossible to create objects of type Shape, only its subclasses. In C++, we define\na class as being abstract by specifying that one or more members of its functions\nareabstract, orpurevirtual. Afunction isdeclared purevirtualbygiving\u201c=0\u201din\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 89 \u2014 #111\ni i\n2.2. InheritanceandPolymorphism 89\nplaceofitsbody. C++doesnotallowthecreationofanobjectthathasoneormore\npure virtual functions. Thus, any derived class must provide concrete definitions\nforallpurevirtualfunctions ofthebaseclass.\nAs an example, recall our Progression class and consider the member func-\ntion nextValue, which computes the next value in the progression. The meaning\nof this function is clear for each of the derived classes: ArithProgression, Geom-\nProgression, and FibonacciProgression. However, in the base class Progression\nwe invented a rather arbitrary default for the nextValue function. (Go back and\ncheck it. What progression does it compute?) It would be more natural to leave\nthis function undefined. We show below how to make it a pure virtual member\nfunction.\nclass Progression // abstract base class\n{\n// ...\nvirtual long nextValue() = 0; // pure virtual function\n// ...\n;\n}\nAsaresult, thecompilerwillnotallowthecreation ofobjectsoftypeProgres-\nsion, since the function nextValue is \u201cpure virtual.\u201d However, its derived classes,\nArithProgressionforexample,canbedefinedbecausetheyprovideadefinitionfor\nthismemberfunction.\nInterfaces and Abstract Base Classes\nWesaidabovethatC++doesnotprovideadirectmechanismfordefininginterfaces\nfor abstract data types. Nevertheless, we can use abstract base classes to achieve\nmuchofthesamepurpose.\nInparticular,wemayconstructaclassforaninterfaceinwhichallthefunctions\narepurevirtualasshownbelowfortheexampleofasimplestackADT.\nclass Stack // stack interface as an abstract class\n{\npublic:\nvirtual bool isEmpty() const = 0; // is the stack empty?\nvirtual void push(int x) = 0; // push x onto the stack\nvirtual int pop() = 0; // pop the stack and return result\n;\n}\nA class that implements this stack interface can be derived from this abstract\nbaseclass,andthenprovideconcretedefinitionsforallofthesevirtualfunctionsas\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 90 \u2014 #112\ni i\n90 Chapter2. Object-OrientedDesign\nshownbelow.\nclass ConcreteStack : public Stack // implements Stack\n{\npublic:\nvirtual bool isEmpty() ... // implementation of members\n{ }\nvirtual void push(int x) ... // ... (details omitted)\n{ }\nvirtual int pop() ...\n{ }\nprivate:\n// ... // member data for the implementation\n;\n}\nTherearepracticallimitationstothismethodofdefininginterfaces, soweonly\nuseinformalinterfaces forthepurpose ofillustrating ADTs.\n2.3 Templates\nInheritance isonlyonemechanism thatC++providesinsupportofpolymorphism.\nInthissection, weconsider anotherway\u2014using templates.\n2.3.1 Function Templates\nLetusconsiderthefollowingfunction,whichreturnstheminimumoftwointegers.\nint integerMin(int a, int b) // returns the minimum of a and b\nreturn (a < b ? a : b);\n{ }\nSuch a function is very handy, so we might like to define a similar function for\ncomputing theminimumoftwovariables ofothertypes, suchaslong,short,float,\nanddouble. Eachsuchfunctionwouldrequireadifferentdeclarationanddefinition,\nhowever, andmaking manycopies ofthesamefunction isanerror-prone solution,\nespecially forlongerfunctions.\nC++ provides an automatic mechanism, called the function template, to pro-\nduce a generic function for an arbitrary type T. A function template provides a\nwell-defined pattern fromwhichaconcrete function maylaterbeformallydefined\norinstantiated. TheexamplebelowdefinesagenericMinfunctiontemplate.\ntemplate <typename T>\nT genericMin(T a, T b) // returns the minimum of a and b\n{\nreturn (a < b ? a : b);\n}\nThedeclarationtakestheformofthekeyword\u201ctemplate\u201dfollowedbythenotation\n<typename T>, which is the parameter list for the template. In this case, there is\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 91 \u2014 #113\ni i\n2.3. Templates 91\njust one parameter T. The keyword \u201ctypename\u201d indicates that T is the name of\nsome type. (Older versions of C++ do not support this keyword and instead the\nkeyword \u201cclass\u201d must be used.) We can have other types of template parameters,\nintegers for example, but type names are themost common. Observe that thetype\nparameter T takes the place of \u201cint\u201d in the original definition of the genericMin\nfunction.\nWecannowinvokeourtemplatedfunctiontocomputetheminimumofobjects\nofmanydifferent types. Thecompiler looks attheargument types anddetermines\nwhichformofthefunctiontoinstantiate.\ncout << genericMin(3, 4) << \u2019 \u2019 // = genericMin<int>(3,4)\n<< genericMin(1.1, 3.1) << \u2019 \u2019 // = genericMin<double>(1.1, 3.1)\n<< genericMin(\u2019t\u2019, \u2019g\u2019) << endl; // = genericMin<char>(\u2019t\u2019,\u2019g\u2019)\nThe template type does not need to be a fundamental type. We could use any\ntypeinthisexample,providedthatthelessthanoperator(<)isdefinedforthistype.\n2.3.2 Class Templates\nIn addition to function templates, C++ allows classes to be templated, which is a\npowerfulmechanism because itallowsustoprovideonedatastructure declaration\nthatcanbeapplied tomanydifferent types. Infact,theStandardTemplateLibrary\nusesclasstemplatesextensively.\nLetusconsideranexampleofatemplateforarestrictedclassBasicVectorthat\nstoresavectorofelements,whichisasimplifiedversionofastructurediscussedin\ngreaterdetail inChapter6. Thisclasshasaconstructor thatisgiventhesizeofthe\narraytoallocate. Inordertoaccesselementsofthearray,weoverloadtheindexing\noperator \u201c[ ].\u201d\nWe present a partial implementation of a class template for class BasicVector\nbelow. We have omitted many of the other member functions, such as the copy\nconstructor, assignment operator, and destructor. The template parameter T takes\ntheplaceoftheactualtypethatwillbestoredinthearray.\ntemplate <typename T>\nclass BasicVector // a simple vector class\n{\npublic:\nBasicVector(int capac = 10); // constructor\nT& operator[](int i) // access element at index i\nreturn a[i];\n{ }\n// ... other public members omitted\nprivate:\nT* a; // array storing the elements\nint capacity; // length of array a\n;\n}\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 92 \u2014 #114\ni i\n92 Chapter2. Object-OrientedDesign\nWe have defined one member function (the indexing operator) within the class\nbody, and below we show how the other member function (the constructor) can\nbedefinedoutsidetheclassbody. Theconstructorinitializesthecapacityvalueand\nallocates thearraystorage.\ntemplate <typename T> // constructor\nBasicVector<T>::BasicVector(int capac)\n{\ncapacity = capac;\na = new T[capacity]; // allocate array storage\n}\nToinstantiateaconcreteinstanceoftheclassBasicVector,weprovidetheclass\nnamefollowedbytheactualtypeparameterenclosedinangledbrackets(<...>). The\ncode fragment below shows how we would define three vectors, one of type int,\noneoftypedouble,andoneoftypestring.\nBasicVector<int> iv(5); // vector of 5 integers\nBasicVector<double> dv(20); // vector of 20 doubles\nBasicVector<string> sv(10); // vector of 10 strings\nSince we have overloaded the indexing operator, we can access elements of each\narrayinthesamemanneraswewouldforanyC++array.\niv[3] = 8;\ndv[14] = 2.5;\nsv[7] = \"hello\";\nTemplated Arguments\nTheactualargumentintheinstantiationofaclasstemplatecanitselfbeatemplated\ntype. For example, we could create a BasicVector whose individual elements are\nthemselvesoftypeBasicVector<int>.\nBasicVector<BasicVector<int> > xv(5); // a vector of vectors\n// ...\nxv[2][8] = 15;\nIn this case, because no capacity argument could be provided to the constructor,\neachelementofthevectorisconstructed usingthedefaultcapacityof10. Thusthe\nabovedefinition declares aBasicVectorconsisting offiveelements, eachofwhich\nisaBasicVectorconsistingof10integers. Suchastructurethereforebehavesmuch\nlikeatwo-dimensional arrayofintegers.\nNote that in the declaration of xv above, we intentionally left a space after\n\u201c<int>.\u201d The reason is that without the space, the character combination \u201c>>\u201d\nwould be interpreted as a bitwise right-shift operator by the compiler (see Sec-\ntion1.2).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 93 \u2014 #115\ni i\n2.4. Exceptions 93\n2.4 Exceptions\nExceptionsareunexpectedeventsthatoccurduringtheexecutionofaprogram. An\nexception can be the result of an error condition or simply an unanticipated input.\nInC++,exceptions canbethought ofasbeingobjects themselves.\n2.4.1 Exception Objects\nInC++,anexception is\u201cthrown\u201dbycodethatencounters someunexpected condi-\ntion. ExceptionscanalsobethrownbytheC++run-timeenvironmentshoulditen-\ncounter an unexpected condition like running out ofmemory. A thrown exception\nis\u201ccaught\u201dbyothercodethat\u201chandles\u201dtheexceptionsomehow,ortheprogramis\nterminated unexpectedly. (Wesaymoreaboutcatching exceptions shortly.)\nExceptions are arelatively recent addition to C++. Prior tohaving exceptions,\nerrors were typically handled by having the program abort at the source of the\nerror or by having the involved function return some special value. Exceptions\nprovideamuchcleanermechanismforhandlingerrors. Nevertheless,forhistorical\nreasons,manyofthefunctionsintheC++standardlibrarydonotthrowexceptions.\nTypically they return some sort of special error status, or set an error flag, which\ncanbetested.\nExceptions are thrown when a piece of code finds some sort of problem dur-\ningexecution. Sincethere aremanytypes ofpossible errors, whenanexception is\nthrown,itisidentifiedbyatype. Typicallythistypeisaclasswhosememberspro-\nvideinformationastotheexactnatureoftheerror,forexampleastringcontaining\nadescriptive errormessage.\nExceptiontypesoftenformhierarchies. Forexample,let\u2019simagineahypothet-\nical mathematics library, which may generate many different types of errors. The\nlibrary might begin bydefining one generic exception, MathException, represent-\ning all types of mathematical errors, and then derive more specific exceptions for\nparticular error conditions. The errMsg member holds a message string with an\ninformativemessage. Hereisapossible definitionofthisgenericclass.\nclass MathException // generic math exception\n{\npublic:\nMathException(const string& err) // constructor\n: errMsg(err)\n{ }\nstring getError() return errMsg; // access error message\n{ }\nprivate:\nstring errMsg; // error message\n;\n}\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 94 \u2014 #116\ni i\n94 Chapter2. Object-OrientedDesign\nUsing Inheritance to Define New Exception Types\nThe above MathException class would likely have other member functions, for\nexample, for accessing the error message. We may then add more specific excep-\ntions,suchasZeroDivide,tohandledivisionbyzero,andNegativeRoot,tohandle\nattempts to compute the square root of a negative number. We could use class\ninheritance torepresent thishierarchical relationship, asfollows.\nclass ZeroDivide : public MathException\n{\npublic:\nZeroDivide(const string& err) // divide by zero\n: MathException(err)\n{ }\n;\n}\nclass NegativeRoot : public MathException\n{\npublic:\nNegativeRoot(const string& err) // negative square root\n: MathException(err)\n{ }\n;\n}\n2.4.2 Throwing and Catching Exceptions\nExceptions are typically processed in the context of \u201ctry\u201d and \u201ccatch\u201d blocks. A\ntryblockisablockofstatements proceeded bythekeywordtry. Afteratryblock,\nthereareoneormorecatchblocks. Eachcatchblockspecifiesthetypeofexception\nthat it catches. Execution begins with the statements of the try block. If all goes\nsmoothly, then execution leaves the try block and skips over its associated catch\nblocks. If an exception is thrown, then the control immediately jumps into the\nappropriate catchblockforthisexception.\nFor example, suppose that we were to use our mathematical library as part of\ntheimplementationofanumericalapplication. Wewouldenclosethecomputations\nofthe application within atryblock. Afterthe tryblock, wewould catch and deal\nwithanyexceptions thataroseinthecomputation.\ntry\n{\n// ... application computations\nif (divisor == 0) // attempt to divide by 0?\nthrow ZeroDivide(\"Divide by zero in Module X\");\n}\ncatch (ZeroDivide& zde)\n{\n// handle division by zero\n}\ncatch (MathException& me)\n{\n// handle any math exception other than division by zero\n}\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 95 \u2014 #117\ni i\n2.4. Exceptions 95\nProcessing theabovetryblock isdoneasfollows. Thecomputations ofthetry\nblockareexecuted. Whenanattemptisdiscoveredtodividebyzero,ZeroDivideis\nthrown,andexecutionjumpsimmediatelytotheassociatedcatchstatementwhere\ncorrective recoveryandcleanupshouldbeperformed.\nLetusstudytheentireprocessinsomewhatgreaterdetail. Thethrowstatement\nistypically writtenasfollows:\nthrowexception name(arg1,arg2,...)\nwheretheargumentsarepassedtotheexception\u2019s constructor.\nExceptionsmayalsobethrownbytheC++run-timesystemitself. Forexample,\nifan attempt to allocate space inthe free store using the new operator fails due to\nlackofspace,thenabad allocexception isthrownbythesystem.\nWhen an exception is thrown, it must be caught or the program will abort. In\nany particular function, an exception in that function can be passed through to the\ncalling function orit canbe caught in that function. When an exception iscaught,\nitcan beanalyzed anddealt with. Thegeneral syntax foratry-catch block inC++\nisasfollows:\ntry\ntry statements\ncatch(exception type 1identifier 1)\ncatch statements 1\n...\ncatch(exception type nidentifier n)\ncatch statements n\nExecution beginsinthe\u201ctry statements.\u201d Ifthisexecution generates noexcep-\ntions,thentheflowofcontrolcontinueswiththefirststatementafterthelastlineof\nthe entire try-catch block. If, on the other hand, an exception is generated, execu-\ntion in the try block terminates at that point and execution jumps to the first catch\nblock matching the exception thrown. Thus, an exception thrown for a derived\nclasswillbecaughtbyitsbaseclass. Forexample,ifwehadthrownNegativeRoot\nintheexampleabove, itwouldbecaught bycatchblockforMathException. Note\nthatbecause thesystem executes thefirstmatching catch block, exceptions should\nbe listed in order of most specific to least specific. The special form \u201ccatch(...)\u201d\ncatchesallexceptions.\nThe \u201cidentifier\u201d for the catch statement identifies the exception object itself.\nAs we said before, this object usually contains additional information about the\nexception,andthisinformationmaybeaccessedfromwithinthecatchblock. Asis\ncommoninpassingclassarguments,theexceptionistypicallypassedasareference\noraconstant reference. Onceexecution ofthecatchblock completes, control flow\ncontinues withthefirststatementafterthelastcatchblock.\nTherecoveryactiontakeninacatchblockdependsverymuchontheparticular\napplication. It may be as simple as printing an error message and terminating the\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 96 \u2014 #118\ni i\n96 Chapter2. Object-OrientedDesign\nprogram. Itmayrequirecomplexclean-upoperations,suchasdeallocatingdynam-\nically allocated storage and restoring the program\u2019s internal state. There are also\nsomeinteresting cases inwhich thebest waytohandle anexception istoignore it\n(which can be specified by having an empty catch block). Ignoring an exception\nis usually done, for example, when the programmer does not care whether there\nwasanexceptionornot. Anotherlegitimatewayofhandlingexceptionsistothrow\nanother exception, possibly one that specifies the exceptional condition more pre-\ncisely.\n2.4.3 Exception Specification\nWhenwedeclareafunction, weshouldalsospecify theexceptions itmightthrow.\nThisconvention hasbothafunctional andcourteous purpose. Forone, itletsusers\nknow what to expect. It also lets the compiler know which exceptions to prepare\nfor. Thefollowingisanexampleofsuchafunction definition.\nvoid calculator() throw(ZeroDivide, NegativeRoot)\n{\n// function body ...\n}\nThis definition indicates that the function calculator (and any other functions it\ncalls) can throw these two exceptions or exceptions derived from these types, but\nnoothers.\nByspecifyingalltheexceptionsthatmightbethrownbyafunction,weprepare\nothers to be able to handle all of the exceptional cases that might arise from using\nthis function. Another benefit of declaring exceptions is that we do not need to\ncatch those exceptions in our function, which is appropriate, for example, in the\ncase where other code is responsible for causing the circumstances leading up to\ntheexception.\nThefollowingillustrates anexception thatis\u201cpassed through.\u201d\nvoid getReadyForClass() throw(ShoppingListTooSmallException,\nOutOfMoneyException)\n{\ngoShopping(); // I don\u2019t have to try or catch the exceptions\n// which goShopping() might throw because\n// getReadyForClass() will just pass these along.\nmakeCookiesForTA();\n}\nA function can declare that it throws as many exceptions as it likes. Such a\nlisting can besimplifiedsomewhat ifallexceptions thatcan bethrownarederived\nclasses ofthesameexception. Inthiscase, weonlyhavetodeclare thatafunction\nthrowstheappropriate baseclass.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 97 \u2014 #119\ni i\n2.4. Exceptions 97\nSuppose that a function does not contain a throw specification. It would be\nnaturaltoassumethatsuchafunctiondoesnotthrowanyexceptions. Infact,ithas\nquiteadifferentmeaning. Ifafunctiondoesnotprovideathrowspecification,then\nitmaythrowanyexception. Althoughthisisconfusing, itisnecessary tomaintain\ncompatibility with older versions of C++. To indicate that a function throws no\nexceptions, providethethrowspecifierwithanemptylistofexceptions.\nvoid func1(); // can throw any exception\nvoid func2() throw(); // can throw no exceptions\nGeneric Exception Class\nWe declare many different exceptions in this book. In order to structure these ex-\nceptions hierarchically, weneed tohave one generic exception class that serves as\nthe \u201cmother ofall exceptions.\u201d C++ does not provide such ageneric exception, so\nwecreated one ofour own. Thisclass, called RuntimeException, isshownbelow.\nIt has an error message as its only member. It provides a constructor that is given\nan informative error message as its argument. It also provides a member function\ngetMessagethatallowsustoaccessthismessage.\nclass RuntimeException // generic run-time exception\n{\nprivate:\nstring errorMsg;\npublic:\nRuntimeException(const string& err) errorMsg = err;\n{ }\nstring getMessage() const return errorMsg;\n{ }\n;\n}\nByderiving all ofour exceptions from this base class, for any exception e, we\ncanoutpute\u2019serrormessagebyinvoking theinherited getMessagefunction.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 98 \u2014 #120\ni i\n98 Chapter2. Object-OrientedDesign\n2.5 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-2.1 Whataresomepotential efficiencydisadvantages ofhaving verydeepin-\nheritance trees, thatis,alargesetofclasses, A,B,C,andsoon,suchthat\nBextends A,CextendsB,DextendsC,etc.?\nR-2.2 What are some potential efficiency disadvantages of having very shallow\ninheritance trees, that is, a large set of classes, A, B, C, and so on, such\nthatalloftheseclassesextendasingleclass,Z?\nR-2.3 Givethreeexamplesoflife-critical softwareapplications.\nR-2.4 Give an example of a software application where adaptability can mean\nthedifference betweenaprolonged saleslifetimeandbankruptcy.\nR-2.5 Describeacomponentfromatext-editorGUI(otherthanan\u201cedit\u201dmenu)\nandthememberfunctions thatitencapsulates.\nR-2.6 Drawaclassinheritance diagramforthefollowingsetofclasses.\nClass Goat extends Object and adds a member variable tail and\n\u2022\nfunctions milkandjump.\nClassPigextendsObjectandaddsamembervariablenoseandfunc-\n\u2022\ntionseatandwallow.\nClass Horse extends Object and adds member variables height and\n\u2022\ncolor,andfunctions runandjump.\nClassRacerextendsHorseandaddsafunctionrace.\n\u2022\nClassEquestrianextendsHorseandaddsamembervariable weight\n\u2022\nandfunctions trotandisTrained.\nR-2.7 Aderivedclass\u2019sconstructorexplicitlyinvokesitsbaseclass\u2019sconstructor,\nbut a derived class\u2019s destructor cannot invoke its base class\u2019s destructor.\nWhydoesthisapparentasymmetrymakesense?\nR-2.8 Giveashort fragmentofC++code thatusestheprogression classes from\nSection 2.2.3 to find the 7th value of a Fibonacci progression that starts\nwith3and4asitsfirsttwovalues.\nR-2.9 If we choose inc=128, how many calls to the nextValue function from\ntheArithProgressionclassofSection2.2.3canwemakebeforewecause\nalong-integer overflow,assuminga64-bitlonginteger?\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 99 \u2014 #121\ni i\n2.5. Exercises 99\nR-2.10 Suppose wehaveavariable pthat isdeclared tobeapointer toanobject\nof type Progression using the classes of Section 2.2.3. Suppose further\nthat p actually points to an instance of the class GeomProgression that\nwascreated withthe default constructor. If wecast ptoapointer oftype\nProgressionandcall p->firstValue(),whatwillbereturned? Why?\nR-2.11 Consider the inheritance of classes from Exercise R-2.6, and let d be an\nobjectvariableoftypeHorse. IfdreferstoanactualobjectoftypeEques-\ntrian,canitbecasttotheclassRacer? Whyorwhynot?\nR-2.12 GeneralizethePerson-StudentclasshierarchytoincludeclassesFaculty,\nUndergraduateStudent,GraduateStudent,Professor,Instructor. Explain\nthe inheritance structure of these classes, and derive some appropriate\nmembervariablesforeachclass.\nR-2.13 GiveanexampleofaC++codefragmentthatperformsanarrayreference\nthat is possibly out of bounds, and if it is out of bounds, the program\ncatchesthatexception andprintsanappropriate errormessage.\nR-2.14 Considerthefollowingcodefragment:\nclass Object\npublic: virtual void printMe() = 0; ;\n{ }\nclass Place : public Object\npublic: virtual void printMe() cout << \"Buy it.\\n\"; ;\n{ { } }\nclass Region : public Place\npublic: virtual void printMe() cout << \"Box it.\\n\"; ;\n{ { } }\nclass State : public Region\npublic: virtual void printMe() cout << \"Ship it.\\n\"; ;\n{ { } }\nclass Maryland : public State\npublic: virtual void printMe() cout << \"Read it.\\n\"; ;\n{ { } }\nint main()\n{\nRegion* mid = new State;\nState* md = new Maryland;\nObject* obj = new Place;\nPlace* usa = new Region;\nmd >printMe();\n\u2212\nmid >printMe();\n\u2212\n(dynamic cast<Place*>(obj)) >printMe();\n\u2212\nobj = md;\n(dynamic cast<Maryland*>(obj)) >printMe();\n\u2212\nobj = usa;\n(dynamic cast<Place*>(obj)) >printMe();\n\u2212\nusa = md;\n(dynamic cast<Place*>(usa)) >printMe();\n\u2212\nreturn EXIT SUCCESS;\n}\nWhatistheoutputfromcalling themainfunctionoftheMarylandclass?\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 100 \u2014 #122\ni i\n100 Chapter2. Object-OrientedDesign\nR-2.15 Write a short C++ function that counts the number of vowels in a given\ncharacter string.\nR-2.16 WriteashortC++functionthatremovesallthepunctuationfromastrings\nstoringasentence. Forexample,thisoperationwouldtransformthestring\n\"Let\u2019s try, Mike.\"to\"Lets try Mike\".\nR-2.17 Write a short program that takes as input three integers, a, b, and c, and\ndeterminesiftheycanbeusedinacorrectarithmeticformula(inthegiven\norder), like\u201ca+b=c,\u201d\u201ca=b c,\u201dor\u201ca b=c.\u201d\n\u2212 \u2217\nR-2.18 Write a short C++ program that creates a Pair class that can store two\nobjects declared as generic types. Demonstrate this program by creating\nandprinting Pairobjectsthatcontain fivedifferentkindsofpairs, suchas\n<int,string>and<float,long>.\nCreativity\nC-2.1 GiveanexampleofaC++program thatoutputsitssourcecodewhenitis\nrun. Suchaprogram iscalledaquine.\nC-2.2 Supposeyouareonthedesignteamforanewe-bookreader. Whatarethe\nprimary classes and functions that the C++ software for your reader will\nneed? You should include an inheritance diagram for this code, but you\ndon\u2019t need to write any actual code. Your software architecture should\nat least include ways for customers to buy new books, view their list of\npurchased book, andreadtheirpurchased books.\nC-2.3 MostmodernC++compilershaveoptimizersthatcandetectsimplecases\nwhenitislogically impossibleforcertainstatementsinaprogramtoever\nbeexecuted. Insuchcases,thecompiler warnstheprogrammeraboutthe\nuseless code. Write a short C++ function that contains code for which it\nisprovablyimpossibleforthatcodetoeverbeexecuted,butyourfavorite\nC++compilerdoesnotdetectthisfact.\nC-2.4 DesignaclassLinethatimplementsaline,whichisrepresentedbythefor-\nmulay=ax+b. Yourclassshouldstoreaandbasdoublemembervari-\nables. Writeamember function intersect(\u2113)that returns the xcoordinate\nat which this line intersects line \u2113. Ifthe twolines are parallel, then your\nfunction should throw an exception Parallel. Write a C++ program that\ncreatesanumberofLineobjectsandtestseachpairforintersection. Your\nprogram shouldprintanappropriate errormessageforparallellines.\nC-2.5 WriteaC++class thatisderived from theProgression class toproduce a\nprogression where each value is the absolute value of the difference be-\ntween the previous two values. You should include a default constructor\nthatstartswith2and200asthefirsttwovaluesandaparametricconstruc-\ntorthatstartswithaspecifiedpairofnumbersasthefirsttwovalues.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 101 \u2014 #123\ni i\n2.5. Exercises 101\nC-2.6 Write a C++ class that is derived from the Progression class to produce\na progression where each value is the square root of the previous value.\n(Note that you can no longer represent each value with an integer.) You\nshould include a default constructor that starts with 65,536 as the first\nvalue and a parametric constructor that starts with a specified (double)\nnumberasthefirstvalue.\nC-2.7 Writeaprogramthatconsistsofthreeclasses,A,B,andC,suchthatBisa\nsubclassofAandCisasubclassofB. Eachclassshoulddefineamember\nvariable named\u201cx\u201d(thatis,eachhasitsownvariable namedx). Describe\na way for a member function inC to access and set A\u2019s version of x to a\ngivenvalue,withoutchanging BorC\u2019sversion.\nC-2.8 WriteasetofC++classesthatcansimulateanInternetapplication, where\noneparty, Alice,isperiodically creating asetofpackets thatshewantsto\nsendtoBob. TheInternetprocessiscontinuallycheckingifAlicehasany\npackets tosend, andifso, itdelivers them toBob\u2019scomputer, and Bobis\nperiodically checking ifhis computer has apacket from Alice, and, ifso,\nhereadsanddeletesit.\nC-2.9 WriteaC++programthatcaninputanypolynomial instandard algebraic\nnotation andoutputsthefirstderivativeofthatpolynomial.\nProjects\nP-2.1 Write a C++ program that can take a positive integer greater than 2 as\ninput and write out the number of times one must repeatedly divide this\nnumberby2beforegetting avaluelessthan2.\nP-2.2 Write a C++ program that \u201cmakes change.\u201d Your program should input\ntwonumbers, onethatisamonetary amountcharged andtheotherthatis\namonetaryamountgiven. Itshouldreturnthenumberofeachkindofbill\nand coin to give back as change for the difference between the amounts\ngivenandcharged. Thevaluesassignedtothebillsandcoinscanbebased\non the monetary system of any government. Try to design your program\nsothatitreturnsthefewestnumberofbillsandcoinsaspossible.\nP-2.3 ImplementatemplatedC++classVectorthatmanipulates anumericvec-\ntor. Your class should be templated with any numerical scalar type T,\nwhich supports the operations + (addition), (subtraction), and * (mul-\n\u2212\ntiplication). In addition, type T should have constructors T(0), which\nproduces theadditive identity element (typically 0)andT(1), which pro-\nducesthemultiplicativeidentity(typically1). Yourclassshouldprovidea\nconstructor, whichisgiventhesizeofthevectorasanargument. Itshould\nprovide member functions (or operators) for vector addition, vector sub-\ntraction, multiplication of a scalar and a vector, and vector dot product.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 102 \u2014 #124\ni i\n102 Chapter2. Object-OrientedDesign\nWrite a class Complex that implements a complex number by overload-\ningtheoperators foraddition, subtraction, andmultiplication. Implement\nthree concrete instances of your class Vector with the scalar types int,\ndouble,andComplex,respectively.\nP-2.4 Write a simulator as in the previous project, but add a Boolean gender\nfield and a floating-point strength field to each Animal object. Now, if\ntwo animals of the same type try to collide, then they only create a new\ninstanceofthattypeofanimaliftheyareofdifferentgenders. Otherwise,\nif two animals of the same type and gender try to collide, then only the\noneoflargerstrengthsurvives.\nP-2.5 Write a C++ program that has a Polygon interface that has abstract func-\ntions, area(), and perimeter(). Implement classes for Triangle, Quadri-\nlateral, Pentagon, Hexagon, and Octagon, which implement this inter-\nface, withtheobvious meanings forthearea()and perimeter()functions.\nAlso implement classes, IsoscelesTriangle, EquilateralTriangle, Rectan-\ngle,andSquare,whichhavetheappropriate inheritance relationships. Fi-\nnally, writeasimpleuserinterface thatallowsuserstocreatepolygons of\nthevarious types, input theirgeometric dimensions, andthenoutput their\nareaandperimeter. Forextraeffort,allowuserstoinputpolygonsbyspec-\nifyingtheirvertexcoordinatesandbeabletotestiftwosuchpolygonsare\nsimilar.\nP-2.6 WriteaC++programthatinputsadocumentandthenoutputs abar-chart\nplotofthefrequenciesofeachalphabetcharacterthatappearsinthatdoc-\nument.\nP-2.7 WriteaC++program that inputs alistofwords separated bywhitespace,\nand outputs how manytimes each word appears in the list. You need not\nworry about efficiency at this point, however, as this topic is something\nthatwillbeaddressed laterinthisbook.\nChapter Notes\nForabroadoverviewofdevelopmentsincomputerscienceandengineering,wereferthe\nreaderto The ComputerScience andEngineeringHandbook[96]. Formore information\nabouttheTherac-25incident,pleaseseethepaperbyLevesonandTurner[63].\nThe reader interested in studyingobject-orientedprogrammingfurther, is referredto\nthebooksbyBooch[13],Budd[16],andLiskovandGuttag[68]. LiskovandGuttag[68]\nalsoprovideanicediscussionofabstractdatatypes,asdoesthesurveypaperbyCardelli\nand Wegner [19] and the book chapter by Demurjian [27] in the The Computer Science\nandEngineeringHandbook[96]. DesignpatternsaredescribedinthebookbyGammaet\nal.[35]. TheclassinheritancediagramnotationweuseisderivedfromtheGammaetal.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 103 \u2014 #125\ni i\nChapter\n3\nArrays, Linked Lists, and Recursion\nContents\n3.1 Using Arrays . . . . . . . . . . . . . . . . . . . . . . . 104\n3.1.1 Storing Game Entries in an Array . . . . . . . . . . . 104\n3.1.2 Sorting an Array . . . . . . . . . . . . . . . . . . . . 109\n3.1.3 Two-Dimensional Arrays and Positional Games . . . 111\n3.2 Singly Linked Lists . . . . . . . . . . . . . . . . . . . . 117\n3.2.1 Implementing a Singly Linked List . . . . . . . . . . 117\n3.2.2 Insertion to the Front of a Singly Linked List . . . . 119\n3.2.3 Removal from the Front of a Singly Linked List . . . 119\n3.2.4 Implementing a Generic Singly Linked List . . . . . . 121\n3.3 Doubly Linked Lists . . . . . . . . . . . . . . . . . . . 123\n3.3.1 Insertion into a Doubly Linked List . . . . . . . . . . 123\n3.3.2 Removal from a Doubly Linked List . . . . . . . . . 124\n3.3.3 A C++ Implementation . . . . . . . . . . . . . . . . 125\n3.4 Circularly Linked Lists and List Reversal . . . . . . . . 129\n3.4.1 Circularly Linked Lists . . . . . . . . . . . . . . . . . 129\n3.4.2 Reversing a Linked List . . . . . . . . . . . . . . . . 133\n3.5 Recursion . . . . . . . . . . . . . . . . . . . . . . . . . 134\n3.5.1 Linear Recursion . . . . . . . . . . . . . . . . . . . . 140\n3.5.2 Binary Recursion . . . . . . . . . . . . . . . . . . . 144\n3.5.3 Multiple Recursion . . . . . . . . . . . . . . . . . . 147\n3.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 149\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 104 \u2014 #126\ni i\n104 Chapter3. Arrays,LinkedLists,andRecursion\n3.1 Using Arrays\nInthissection,weexploreafewapplicationsofarrays\u2014theconcretedatastructures\nintroduced inSection1.1.3thataccesstheirentriesusingintegerindices.\n3.1.1 Storing Game Entries in an Array\nThe first application we study is for storing entries in an array; in particular, high\nscoreentriesforavideogame. Storingobjectsinarraysisacommonuseforarrays,\nandwecouldjustaseasilyhavechosentostorerecordsforpatientsinahospitalor\nthenamesofplayers onafootball team. Nevertheless, letusfocus onstoring high\nscore entries, which is a simple application that is already rich enough to present\nsomeimportantdatastructuring concepts.\nLetusbeginbythinking aboutwhatwewanttoinclude inanobject represent-\ning a high score entry. Obviously, one component to include is an integer repre-\nsenting thescoreitself, whichwecallscore. Anotheruseful thingtoinclude isthe\nnameofthepersonearningthisscore,whichwesimplycallname. Wecouldgoon\nfrom here, adding fieldsrepresenting thedate thescore wasearned orgamestatis-\ntics that led tothat score. Letus keep our example simple, however, and just have\ntwofields,scoreandname. Theclassstructure isshowninCodeFragment3.1.\nclass GameEntry // a game score entry\n{\npublic:\nGameEntry(const string& n=\"\", int s=0); // constructor\nstring getName() const; // get player name\nint getScore() const; // get score\nprivate:\nstring name; // player\u2019s name\nint score; // player\u2019s score\n;\n}\nCodeFragment3.1: AC++classrepresenting agameentry.\nIn Code Fragment 3.2, we provide the definitions of the class constructor and\ntwoaccessor memberfunctions.\nGameEntry::GameEntry(const string& n, int s) // constructor\n: name(n), score(s)\n{ }\n// accessors\nstring GameEntry::getName() const return name;\n{ }\nint GameEntry::getScore() const return score;\n{ }\nCodeFragment3.2: GameEntryconstructor andaccessors.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 105 \u2014 #127\ni i\n3.1. UsingArrays 105\nA Class for High Scores\nLet\u2019s now design a class, called Scores, to store our game-score information. We\nstore the highest scores in an array entries. The maximum number of scores may\nvary from instance to instance, so we create a member variable, maxEntries, stor-\ning the desired maximum. Its value is specified when a Scores object is first con-\nstructed. Inordertokeeptrackoftheactualnumberofentries,wedefineamember\nvariable numEntries. Itis initialized tozero, and itis updated asentries are added\norremoved. Weprovide aconstructor, adestructor, amemberfunction for adding\nanewscore, andoneforremovingascoreatagivenindex. Thedefinitionisgiven\ninCodeFragment3.3.\nclass Scores // stores game high scores\n{\npublic:\nScores(int maxEnt = 10); // constructor\n\u02dcScores(); // destructor\nvoid add(const GameEntry& e); // add a game entry\nGameEntry remove(int i) // remove the ith entry\nthrow(IndexOutOfBounds);\nprivate:\nint maxEntries; // maximum number of entries\nint numEntries; // actual number of entries\nGameEntry* entries; // array of game entries\n;\n}\nCodeFragment3.3: AC++classforstoringhighgamescores.\nIn Code Fragment 3.4, we present the class constructor, which allocates the\ndesired amount of storage for the array using the \u201cnew\u201d operator. Recall from\nSection 1.1.3 that C++ represents a dynamic array as a pointer to its first element,\nandthiscommandreturnssuchapointer. Theclassdestructor,~Scores,deletesthis\narray.\nScores::Scores(int maxEnt) // constructor\n{\nmaxEntries = maxEnt; // save the max size\nentries = new GameEntry[maxEntries]; // allocate array storage\nnumEntries = 0; // initially no elements\n}\nScores::\u02dcScores() // destructor\n{\ndelete[] entries;\n}\nCodeFragment3.4: AC++classGameEntryrepresenting agameentry.\nThe entries that have been added to the array are stored in indices 0 through\nnumEntries 1. Asmoreusersplayourvideogame,additionalGameEntryobjects\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 106 \u2014 #128\ni i\n106 Chapter3. Arrays,LinkedLists,andRecursion\narecopiedintothearray. Thisisdoneusingtheclass\u2019saddmemberfunction,which\nwe describe below. Only the highest maxEntries scores are retained. We also\nprovide a member function, remove(i), which removes the entry at index i from\nthe array. We assume that 0 i numEntries 1. If not, the remove function,\n\u2264 \u2264 \u2212\nthrowsanIndexOutOfBounds exception. Wedonotdefinethisexception here, but\nitisderivedfromtheclassRuntimeExceptionfromSection2.4.\nIn our design, we have chosen to order the GameEntry objects by their score\nvalues,fromhighesttolowest. (InExerciseC-3.2,weexploreanalternativedesign\ninwhich entries are notordered.) Weillustrate anexample ofthe data structure in\nFigure3.1.\nMike Rob Paul Anna Rose Jack\n1105 750 720 660 590 510\n0 1 2 3 4 5 6 7 8 9\nFigure3.1: The entries array of length eight storing six GameEntry objects in the\ncellsfromindex0to5. HeremaxEntriesis10andnumEntriesis6.\nInsertion\nNext,letusconsiderhowtoaddanewGameEntryetothearrayofhighscores. In\nparticular, letusconsiderhowwemightperformthefollowingupdateoperationon\naninstanceoftheScoresclass.\nadd(e): Insert game entry e into the collection of high scores. If\nthis causes the number of entries to exceed maxEntries,\nthesmallestisremoved.\nTheapproachistoshiftalltheentriesofthearraywhosescoresaresmallerthan\ne\u2019sscoretotheright,inordertomakespaceforthenewentry. (SeeFigure3.2.)\nJill\n740\nMike Rob Paul Anna Rose Jack\n1105 750 720 660 590 510\n0 1 2 3 4 5 6 7 8 9\nFigure 3.2: Preparing to add a new GameEntry object (\u201cJill\u201d,740) to the entries\narray. Inordertomakeroomforthenewentry,weshiftalltheentrieswithsmaller\nscorestotherightbyoneposition.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 107 \u2014 #129\ni i\n3.1. UsingArrays 107\nOnce we have identified the position in the entries array where the new game\nentry,e,belongs, wecopyeintothisposition. (SeeFigure3.3.)\nMike Rob Jill Paul Anna Rose Jack\n1105 750 740 720 660 590 510\n0 1 2 3 4 5 6 7 8 9\nFigure3.3: Afteraddingthenewentryatindex2.\nThedetailsofouralgorithmforaddingthenewgameentryetotheentriesarray\nare similar to this informal description and are given in Code Fragment 3.5. First,\nweconsider whetherthearray isalready full. Ifso, wecheck whether thescoreof\nthe last entry in the array (which is at entries[maxEntries 1]) is at least as large\n\u2212\nase\u2019sscore. Ifso,wecanreturnimmediatelysinceeisnothighenough toreplace\nanyoftheexistinghighestscores. Ifthearrayisnotyetfull,weknowthatonenew\nentrywillbeadded,soweincrementthevalueofnumEntries. Next,weidentifyall\nthe entries whose scores are smaller than e\u2019s and shift them one entry to the right.\nToavoidoverwritingexisting arrayentries, westartfromtherightendofthearray\nand work to the left. The loop continues until we encounter an entry whose score\nis not smaller than e\u2019s, or we fall off the front end of the array. In either case, the\nnewentryisaddedatindexi+1.\nvoid Scores::add(const GameEntry& e) // add a game entry\n{\nint newScore = e.getScore(); // score to add\nif (numEntries == maxEntries) // the array is full\n{\nif (newScore <= entries[maxEntries 1].getScore())\n\u2212\nreturn; // not high enough - ignore\n}\nelse numEntries++; // if not full, one more entry\nint i = numEntries 2; // start with the next to last\n\u2212\nwhile ( i >= 0 && newScore > entries[i].getScore() )\n{\nentries[i+1] = entries[i]; // shift right if smaller\ni ;\n\u2212\u2212\n}\nentries[i+1] = e; // put e in the empty spot\n}\nCodeFragment3.5: C++codeforinserting aGameEntryobject.\nCheck the code carefully to see that all the limiting cases have been handled\ncorrectly by the add function (for example, largest score, smallest score, empty\narray,fullarray). Thenumberoftimesweperformtheloopinthisfunctiondepends\non the number of entries that we need to shift. This is pretty fast if the number of\nentriesissmall. Butiftherearealottomove,thenthismethodcouldbefairlyslow.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 108 \u2014 #130\ni i\n108 Chapter3. Arrays,LinkedLists,andRecursion\nObject Removal\nSupposesomehotshotplays ourvideo gameandgetshisorhernameonourhigh\nscorelist. Inthiscase,wemightwanttohaveafunctionthatletsusremoveagame\nentryfromthelistofhighscores. Therefore, letusconsiderhowwemightremove\na GameEntry object from the entries array. That is, let us consider how we might\nimplementthefollowingoperation:\nremove(i): Remove and return the game entry e at index i in the\nentries array. If index i is outside the bounds of the\nentriesarray,thenthisfunctionthrowsanexception;oth-\nerwise, the entries array is updated to remove the ob-\njectatindexiandallobjectspreviously storedatindices\nhigher than i are \u201cshifted left\u201d to fill in for the removed\nobject.\nOur implementation of remove is similar to that of add, but in reverse. To\nremove the entry at index i, we start at index i and move all the entries at indices\nhigherthanioneposition totheleft. (SeeFigure3.4.)\nReturn: Paul\n720\nMike Rob Jill Anna Rose Jack\n1105 750 740 660 590 510\n0 1 2 3 4 5 6 7 8 9\nFigure3.4: Removaloftheentry(\u201cPaul\u201d,720)atindex3.\nThecodeforperforming theremovalispresented inCodeFragment3.6.\nGameEntry Scores::remove(int i) throw(IndexOutOfBounds)\n{\nif ((i < 0) (i >= numEntries)) // invalid index\n||\nthrow IndexOutOfBounds(\"Invalid index\");\nGameEntry e = entries[i]; // save the removed object\nfor (int j = i+1; j < numEntries; j++)\nentries[j 1] = entries[j]; // shift entries left\n\u2212\nnumEntries ; // one fewer entry\n\u2212\u2212\nreturn e; // return the removed object\n}\nCodeFragment3.6: C++codeforperforming theremoveoperation.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 109 \u2014 #131\ni i\n3.1. UsingArrays 109\nTheremovaloperationinvolvesafewsubtlepoints. Inordertoreturnthevalue\noftheremovedgameentry(let\u2019scallite),wemustfirstsaveeinatemporaryvari-\nable. When we are done, the function will return this value. The shifting process\nstarts attheposition just following the removal, j=i+1. Werepeatedly copy the\nentry at index j to index j 1, and then increment j, until coming to the last ele-\n\u2212\nment of the set. Similar tothe case of insertion, this left-to-right order is essential\ntoavoidoverwritingexistingentries. Tocompletethefunction,wereturnacopyof\ntheremovedentrythatwassavedine.\nThesefunctions foraddingandremovingobjectsinanarrayofhighscoresare\nsimple. Nevertheless, they form the basis of techniques that are used repeatedly\nto build more sophisticated data structures. These other structures may be more\ngeneral than our simple array-based solution, and they may support many more\noperations. Butstudying the concrete array datastructure, aswearedoing now,is\na great starting point for understanding these more sophisticated structures, since\neverydatastructure hastobeimplementedusingconcrete means.\n3.1.2 Sorting an Array\nIn the previous subsection, we worked hard to show how we can add or remove\nobjects at a certain index i in an array while keeping the previous order of the\nobjectsintact. Inthissection,weconsiderhowtorearrangeobjectsofanarraythat\nareorderedarbitrarily inascending order. Thisisknownassorting.\nWestudyseveralsortingalgorithmsinthisbook,mostofwhichappearinChap-\nter11. Asawarmup,wedescribe asimplesorting algorithm calledinsertion-sort.\nInthiscase,wedescribeaspecificversionofthealgorithmwheretheinputisanar-\nrayofcomparableelements. Weconsidermoregeneralkindsofsortingalgorithms\nlaterinthisbook.\nWe begin with a high-level outline of the insertion-sort algorithm. We start\nwiththefirstelementinthearray. Oneelementbyitselfisalreadysorted. Thenwe\nconsider thenextelementinthearray. Ifitissmaller thanthefirst,weswapthem.\nNext we consider the third element in the array. We swap it leftward until it is in\nits proper order withthe firsttwoelements. Wecontinue in this manner witheach\nelementofthearray,swappingitleftwarduntilitisinitsproperposition.\nIt is easy to see why this algorithm is called \u201cinsertion-sort\u201d\u2014each iteration\nof the algorithm inserts the next element into the current sorted part of the array,\nwhich was previously the subarray in front of that element. We may implement\nthe above outline using two nested loops. The outer loop considers each element\nin the array in turn, and the inner loop moves that element to its proper location\nwiththe(sorted)subarray ofelementsthataretoitsleft. Weillustratetheresulting\nalgorithm inCodeFragment3.7.\nThis description is already quite close to actual C++ code. It indicates which\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 110 \u2014 #132\ni i\n110 Chapter3. Arrays,LinkedLists,andRecursion\nAlgorithmInsertionSort(A):\nInput: AnarrayAofncomparable elements\nOutput: ThearrayAwithelementsrearranged innondecreasing order\nfori 1ton 1do\n\u2190 \u2212\nInsertA[i]atitsproperlocationinA[0],A[1],...,A[i 1]\n{ \u2212 }\ncur A[i]\n\u2190\nj i 1\n\u2190 \u2212\nwhile j 0andA[j]>cur do\n\u2265\nA[j+1] A[j]\n\u2190\nj j 1\n\u2190 \u2212\nA[j+1] cur cur isnowintherightplace\n\u2190 { }\nCodeFragment3.7: Algorithmicdescription oftheinsertion-sort algorithm.\ntemporary variables are needed, how the loops are structured, and what decisions\nneedtobemade. Weillustrate anexampleruninFigure3.5.\nWe present C++ code for our insertion-sort algorithm in Code Fragment 3.8.\nWeassumethatthearraytobesortedconsistsofelementsoftypechar,butitiseasy\ntogeneralize thistoother data types. Thearray Ainthealgorithm isimplemented\nasachar array. RecallthateacharrayinC++isrepresented asapointertoitsfirst\nelement, sothe parameter Aisdeclared tobeof type char*. Wealso pass the size\nof the array in an integer parameter n. The rest is a straightforward translation of\nthedescription giveninCodeFragment3.7intoC++syntax.\nvoid insertionSort(char* A, int n) // sort an array of n characters\n{\nfor (int i = 1; i < n; i++) // insertion loop\n{\nchar cur = A[i]; // current character to insert\nint j = i 1; // start at previous character\n\u2212\nwhile ((j >= 0) && (A[j] > cur)) // while A[j] is out of order\n{\nA[j + 1] = A[j]; // move A[j] right\nj ; // decrement j\n\u2212\u2212\n}\nA[j + 1] = cur; // this is the proper place for cur\n}\n}\nCodeFragment3.8: C++codeimplementing theinsertion-sort algorithm.\nAn interesting thing happens in the insertion-sort algorithm if the array is al-\nreadysorted. Inthiscase,theinnerloopdoesonlyonecomparison,determinesthat\nthere is no swap needed, and returns back to the outer loop. Of course, we might\nhave to do a lot more work than this if the input array is extremely out of order.\nIndeed, theworstcasearisesiftheinitialarrayisgivenindescending order.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 111 \u2014 #133\ni i\n3.1. UsingArrays 111\nFigure3.5:Executionoftheinsertion-sortalgorithmonanarrayofeightcharacters.\nWe show the completed (sorted) part of the array in white, and we color the next\nelement that is being inserted into the sorted part of the array with light blue. We\nalso highlight the character on the left, since it is stored in the cur variable. Each\nrow corresponds to an iteration of the outer loop, and each copy of the array in a\nrow corresponds to an iteration of the inner loop. Each comparison is shown with\nanarc. Inaddition, weindicate whetherthatcomparison resulted inamoveornot.\n3.1.3 Two-Dimensional Arrays and Positional Games\nMany computer games, be they strategy games, simulation games, or first-person\nconflict games, use a two-dimensional \u201cboard.\u201d Programs that deal with such po-\nsitional games need a way of representing objects in a two-dimensional space. A\nnatural waytodothisiswithatwo-dimensional array, whereweusetwoindices,\nsay iand j, torefer tothe cells in thearray. Thefirstindex usually refers to arow\nnumberandthesecondtoacolumnnumber. Givensuchanarraywecanthenmain-\ntaintwo-dimensional gameboards,aswellasperformotherkindsofcomputations\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 112 \u2014 #134\ni i\n112 Chapter3. Arrays,LinkedLists,andRecursion\ninvolving datathatisstoredinrowsandcolumns.\nArrays in C++ are one-dimensional; we use a single index to access each cell\nof an array. Nevertheless, there is a way we can define two-dimensional arrays in\nC++\u2014wecancreateatwo-dimensional arrayasanarrayofarrays. Thatis,wecan\ndefine a two-dimensional array to be an array with each of its cells being another\narray. Suchatwo-dimensional arrayissometimesalsocalledamatrix. InC++,we\ndeclareatwo-dimensional arrayasfollows:\nint M[8][10]; // matrix with 8 rows and 10 columns\nThis statement creates a two-dimensional \u201carray of arrays,\u201d M, which is 8 10,\n\u00d7\nhaving 8 rows and 10 columns. That is, M is an array of length 8 such that each\nelementofM isanarrayoflength10ofintegers. (SeeFigure3.6.)\nFigure3.6: A two-dimensional integer array that has 8 rows and 10 columns. The\nvalueofM[3][5]is100andthevalueofM[6][2]is632.\nGiven integer variables i and j, we could output the element of row i and col-\numn j(orequivalently, the jthelementoftheitharray)asfollows:\ncout << M[i][j]; // output element in row i column j\nIt is often a good idea to use symbolic constants to define the dimensions in\nordertomakeyourintentions clearertosomeonereadingyourprogram.\nconst int N DAYS = 7;\nconst int N HOURS = 24;\nint schedule[N DAYS][N HOURS];\nDynamic Allocation of Matrices\nIf the dimensions of a two-dimensional array are not known in advance, it is nec-\nessary toallocate thearraydynamically. Thiscanbedone byapplying themethod\nthatwediscussedearlierforallocatingarraysinSection1.1.3,butinstead,weneed\ntoapplyittoeachindividual rowofthematrix.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 113 \u2014 #135\ni i\n3.1. UsingArrays 113\nForexample,supposethatwewishtoallocateanintegermatrixwithnrowsand\nmcolumns. Eachrowofthematrix isanarray ofintegers oflength m. Recall that\na dynamic array is represented as a pointer to its first element, so each row would\nbe declared to be of type int*. How do we group the individual rows together to\nformthematrix? Thematrixisanarrayofrowpointers. Sinceeachrowpointer is\noftypeint*,thematrixisoftypeint**,thatis,apointertoapointerofintegers.\nTo generate our matrix, we first declare M to be of this type and allocate the\nn row pointers with the command \u201cM = new int*[n].\u201d The ith row of the matrix\nis allocated with the statement \u201cM[i] = new int[m].\u201d In Code Fragment 3.9, we\nshowhowtodothisgiventwointegervariablesnandm.\nint** M = new int*[n]; // allocate an array of row pointers\nfor (int i = 0; i < n; i++)\nM[i] = new int[m]; // allocate the i-th row\nCodeFragment3.9: Allocating storageforamatrixasanarrayofarrays.\nOnce allocated, we can access its elements just as before, for example, as\n\u201cM[i][j].\u201d As shown in Code Fragment 3.10, deallocating the matrix involves re-\nversing these steps. First, we deallocate each of the rows, one by one. We then\ndeallocate the array of row pointers. Since we are deleting an array, we use the\ncommand\u201cdelete[].\u201d\nfor (int i = 0; i < n; i++)\ndelete[] M[i]; // delete the i-th row\ndelete[] M; // delete the array of row pointers\nCodeFragment3.10: Deallocating storageforamatrixasanarrayofarrays.\nUsing STL Vectors to Implement Matrices\nAs we can see from the previous section, dynamic allocation of matrices is rather\ncumbersome. The STL vector class (recall Section 1.5.5) provides a much more\nelegant way to process matrices. We adapt the same approach as above by imple-\nmenting a matrix as a vector of vectors. Each row of our matrix is declared as\n\u201cvector<int>.\u201d Thus, the entire matrix is declared to be a vector of rows, that is,\n\u201cvector<vector<int>>.\u201d LetusdeclareM tobeofthistype.\nLetting ndenote thedesired number ofrowsinthematrix, the constructor call\nM(n) allocates storage for the rows. However, this does not allocate the desired\nnumber of columns. The reason is that the default constructor is called for each\nrow,andthedefault istoconstruct anemptyarray.\nTofixthis,wemakeuseofanicefeatureofthevectorclassconstructor. There\nis an optional second argument, which indicates the value to use when initializing\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 114 \u2014 #136\ni i\n114 Chapter3. Arrays,LinkedLists,andRecursion\neachelementofthevector. Inourcase,eachelementofMisavectorofmintegers,\nthatis,\u201cvector<int>(m).\u201d Thus,givenintegervariablesnandm,thefollowingcode\nfragmentgenerates ann mmatrixasavectorofvectors.\n\u00d7\nvector< vector<int> > M(n, vector<int>(m));\ncout << M[i][j] << endl;\nThe space between vector<int> and the following \u201c>\u201d has been added to prevent\nambiguity with the C++ input operator \u201c>>.\u201d Because the STL vector class au-\ntomatically takes care of deleting its members, we do not need to write a loop to\nexplicitly deletetherows,asweneededwithdynamicarrays.\nTwo-dimensional arrays have many applications. Next, we explore a simple\napplication oftwo-dimensional arraysforimplementingapositional game.\nTic-Tac-Toe\nAs most school children know, Tic-Tac-Toe is a game played on a three-by-three\nboard. Twoplayers,XandO,alternateinplacingtheirrespectivemarksinthecells\nofthisboard,startingwithplayerX.Ifeitherplayersucceedsingettingthreeofhis\norhermarksinarow,column, ordiagonal, thenthatplayerwins.\nThis is admittedly not a sophisticated positional game, and it\u2019s not even that\nmuchfuntoplay,sinceagoodplayerOcanalwaysforceatie. Tic-Tac-Toe\u2019ssaving\ngrace isthatitisanice, simple exampleshowing howtwo-dimensional arrays can\nbe used for positional games. Software for more sophisticated positional games,\nsuchascheckers,chess,orthepopularsimulationgames,areallbasedonthesame\napproachweillustratehereforusingatwo-dimensionalarrayforTic-Tac-Toe. (See\nExerciseP-7.11.)\nThe basic idea is to use a two-dimensional array, board, to maintain the game\nboard. CellsinthisarraystorevaluesthatindicateifthatcellisemptyorstoresanX\norO.Thatis,boardisathree-by-threematrix. Forexample,itsmiddlerowconsists\nof the cells board[1][0], board[1][1], and board[1][2]. In our case, we choose to\nmakethecellsintheboard arraybeintegers, witha0indicating anemptycell,a1\nindicating an X, and a 1 indicating O. This encoding allows us to have a simple\n\u2212\nwayof testing whether agiven board configuration is awinforXor O,namely, if\nthevaluesofarow,column,ordiagonal addupto 3or3,respectively.\n\u2212\nWegiveacomplete C++program formaintaining aTic-Tac-Toeboardfortwo\nplayers in Code Fragments 3.11 and 3.12. We show the resulting output in Fig-\nure3.8. NotethatthiscodeisjustformaintainingtheTic-Tac-Toeboardandregis-\nteringmoves;itdoesn\u2019tperformanystrategyorallowsomeonetoplayTic-Tac-Toe\nagainst the computer. The details of such a program are beyond the scope of this\nchapter, butitmightnonetheless makeagoodproject(seeExerciseP-7.11).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 115 \u2014 #137\ni i\n3.1. UsingArrays 115\nFigure3.7: ATic-Tac-Toeboardandthearrayrepresenting it.\n#include <cstdlib> // system definitions\n#include <iostream> // I/O definitions\nusing namespace std; // make std:: accessible\nconst int X = 1, O = 1, EMPTY = 0; // possible marks\n\u2212\nint board[3][3]; // playing board\nint currentPlayer; // current player (X or O)\nvoid clearBoard() // clear the board\n{\nfor (int i = 0; i < 3; i++)\nfor (int j = 0; j < 3; j++)\nboard[i][j] = EMPTY; // every cell is empty\ncurrentPlayer = X; // player X starts\n}\nvoid putMark(int i, int j) // mark row i column j\n{\nboard[i][j] = currentPlayer; // mark with current player\ncurrentPlayer = currentPlayer; // switch players\n\u2212\n}\nbool isWin(int mark) // is mark the winner?\n{\nint win = 3*mark; // +3 for X and -3 for O\nreturn ((board[0][0] + board[0][1] + board[0][2] == win) // row 0\n(board[1][0] + board[1][1] + board[1][2] == win) // row 1\n||\n(board[2][0] + board[2][1] + board[2][2] == win) // row 2\n||\n(board[0][0] + board[1][0] + board[2][0] == win) // column 0\n||\n(board[0][1] + board[1][1] + board[2][1] == win) // column 1\n||\n(board[0][2] + board[1][2] + board[2][2] == win) // column 2\n||\n(board[0][0] + board[1][1] + board[2][2] == win) // diagonal\n||\n(board[2][0] + board[1][1] + board[0][2] == win)); // diagonal\n||\n}\nCodeFragment3.11: AC++programforplayingTic-Tac-Toebetweentwoplayers.\n(Continues inCodeFragment3.12.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 116 \u2014 #138\ni i\n116 Chapter3. Arrays,LinkedLists,andRecursion\nint getWinner() // who wins? (EMPTY means tie)\n{\nif (isWin(X)) return X;\nelse if (isWin(O)) return O;\nelse return EMPTY;\n}\nvoid printBoard() // print the board\n{\nfor (int i = 0; i < 3; i++)\n{\nfor (int j = 0; j < 3; j++)\n{\nswitch (board[i][j])\n{\ncase X: cout << \"X\"; break;\ncase O: cout << \"O\"; break;\ncase EMPTY: cout << \" \"; break;\n}\nif (j < 2) cout << \"|\"; // column boundary\n}\nif (i < 2) cout << \"\\n-+-+-\\n\"; // row boundary\n}\n}\nint main() // main program\n{\nclearBoard(); // clear the board\nputMark(0,0); putMark(1,1); // add the marks\nputMark(0,1); putMark(0,2);\nputMark(2,0); putMark(1,2);\nputMark(2,2); putMark(2,1);\nputMark(1,0);\nprintBoard(); // print the final board\nint winner = getWinner();\nif (winner != EMPTY) // print the winner\ncout << \" \" << (winner == X ? \u2019X\u2019 : \u20190\u2019) << \" wins\" << endl;\nelse\ncout << \" Tie\" << endl;\nreturn EXIT SUCCESS;\n}\nCodeFragment3.12: AC++programforplayingTic-Tac-Toebetweentwoplayers.\n(Continued fromCodeFragment3.11.)\nX|X|O\n-+-+-\nX|O|O\n-+-+-\nX|O|X X wins\nFigure3.8: OutputoftheTic-Tac-Toeprogram.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 117 \u2014 #139\ni i\n3.2. SinglyLinkedLists 117\n3.2 Singly Linked Lists\nIn the previous section, we presented the array data structure and discussed some\nofitsapplications. Arrays arenice andsimpleforstoring things inacertain order,\nbut they have drawbacks. They are not very adaptable. For instance, we have\nto fix the size n of an array in advance, which makes resizing an array difficult.\n(This drawback is remedied in STLvectors.) Insertions and deletions are difficult\nbecause elements need to be shifted around to make space for insertion or to fill\nempty positions after deletion. In this section, we explore an important alternate\nimplementation ofsequence, knownasthesinglylinkedlist.\nAlinked list, initssimplest form, isacollection ofnodesthat together form a\nlinear ordering. As in the children\u2019s game \u201cFollow the Leader,\u201d each node stores\na pointer, called next, to the next node of the list. In addition, each node stores its\nassociated element. (SeeFigure3.9.)\nFigure3.9: Example of a singly linked list of airport codes. The next pointers are\nshownasarrows. Thenullpointerisdenoted by .\n\u2205\nThe next pointer inside a node is a link or pointer to the next node of the list.\nMoving from one node to another by following a next reference is known as link\nhopping or pointer hopping. The first and last nodes of a linked list are called\nthe head and tail of the list, respectively. Thus, we can link-hop through the list,\nstartingattheheadandendingatthetail. Wecanidentifythetailasthenodehaving\nanullnext reference. Thestructure iscalledasinglylinkedlistbecause eachnode\nstoresasinglelink.\nLike an array, a singly linked list maintains its elements in a certain order, as\ndetermined bythechainofnext links. Unlikeanarray,asinglylinked listdoesnot\nhaveapredetermined fixedsize. Itcanberesizedbyaddingorremovingnodes.\n3.2.1 Implementing a Singly Linked List\nLetusimplementasingly linked listofstrings. Wefirstdefineaclass StringNode\nshowninCodeFragment3.13. Thenodestorestwovalues,thememberelemstores\nthe element stored in this node, which in this case is a character string. (Later, in\nSection 3.2.4, we describe how to define nodes that can store arbitrary types of\nelements.) Themembernext stores apointer tothenextnode ofthelist. Wemake\nthelinkedlistclassafriend, sothatitcanaccessthenode\u2019s privatemembers.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 118 \u2014 #140\ni i\n118 Chapter3. Arrays,LinkedLists,andRecursion\nclass StringNode // a node in a list of strings\n{\nprivate:\nstring elem; // element value\nStringNode* next; // next item in the list\nfriend class StringLinkedList; // provide StringLinkedList access\n;\n}\nCodeFragment3.13: Anodeinasinglylinkedlistofstrings.\nInCodeFragment3.14,wedefineaclassStringLinkedListfortheactuallinked\nlist. Itsupportsanumberofmemberfunctions,includingaconstructoranddestruc-\ntor and functions for insertion and deletion. Their implementations are presented\nlater. Itsprivatedataconsists ofapointertotheheadnodeofthelist.\nclass StringLinkedList // a linked list of strings\n{\npublic:\nStringLinkedList(); // empty list constructor\n\u02dcStringLinkedList(); // destructor\nbool empty() const; // is list empty?\nconst string& front() const; // get front element\nvoid addFront(const string& e); // add to front of list\nvoid removeFront(); // remove front item list\nprivate:\nStringNode* head; // pointer to the head of list\n;\n}\nCodeFragment3.14: Aclassdefinition forasinglylinkedlistofstrings.\nAnumberofsimplememberfunctions areshowninCodeFragment3.15. The\nlist constructor creates an empty list by setting the head pointer to NULL. The de-\nstructorrepeatedlyremoveselementsfromthelist. Itexploitsthefactthatthefunc-\ntion remove (presented below) destroys the node that it removes. To test whether\nthelistisempty,wesimplytestwhethertheheadpointerisNULL.\nStringLinkedList::StringLinkedList() // constructor\n: head(NULL)\n{ }\nStringLinkedList::\u02dcStringLinkedList() // destructor\nwhile (!empty()) removeFront();\n{ }\nbool StringLinkedList::empty() const // is list empty?\nreturn head == NULL;\n{ }\nconst string& StringLinkedList::front() const // get front element\nreturn head >elem;\n{ \u2212 }\nCodeFragment3.15: Somesimplememberfunctions ofclassStringLinkedList.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 119 \u2014 #141\ni i\n3.2. SinglyLinkedLists 119\n3.2.2 Insertion to the Front of a Singly Linked List\nWecaneasilyinsertanelement attheheadofasingly linked list. Wefirstcreate a\nnewnode,andsetitselemvaluetothedesiredstringandsetitsnextlinktopointto\nthecurrentheadofthelist. Wethensethead topointtothenewnode. Theprocess\nisillustrated inFigure3.10.\n(a)\n(b)\n(c)\nFigure3.10: Insertion of an element at the head of a singly linked list: (a) before\ntheinsertion; (b)creationofanewnode;(c)aftertheinsertion.\nAn implementation is shown in Code Fragment 3.16. Note that access to the\nprivatememberselemandnext oftheStringNodeclasswouldnormallybeprohib-\nited, butitisallowedhere because StringLinkedListwasdeclared tobeafriend of\nStringNode.\nvoid StringLinkedList::addFront(const string& e) // add to front of list\n{\nStringNode* v = new StringNode; // create new node\nv >elem = e; // store data\n\u2212\nv >next = head; // head now follows v\n\u2212\nhead = v; // v is now the head\n}\nCodeFragment3.16: Insertion tothefrontofasinglylinkedlist.\n3.2.3 Removal from the Front of a Singly Linked List\nNext,weconsider howtoremoveanelement fromthefrontofasingly linked list.\nWeessentially undotheoperations performed forinsertion. Wefirstsaveapointer\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 120 \u2014 #142\ni i\n120 Chapter3. Arrays,LinkedLists,andRecursion\nto the old head node and advance the head pointer to the next node inthe list. We\nthendeletetheoldheadnode. Thisoperation isillustrated inFigure3.11.\n(a)\n(b)\n(c)\nFigure3.11: Removal of an element at the head of a singly linked list: (a) before\ntheremoval;(b)\u201clinking out\u201dtheoldnewnode;(c)aftertheremoval.\nAn implementation of this operation is provided in Code Fragment 3.17. We\nassume that the user has checked that the list is nonempty before applying this\noperation. (A more careful implementation would throw an exception if the list\nwere empty.) The function deletes the node in order to avoid any memory leaks.\nWe do not return the value of the deleted node. If its value is desired, we can call\nthefrontfunctionpriortotheremoval.\nvoid StringLinkedList::removeFront() // remove front item\n{\nStringNode* old = head; // save current head\nhead = old >next; // skip over old head\n\u2212\ndelete old; // delete the old head\n}\nCodeFragment3.17: Removalfromthefrontofasinglylinkedlist.\nItisnoteworthy thatwecannot aseasily delete thelast node ofasingly linked\nlist, evenifwehadapointer toit. Inorder todelete anode, weneed toupdate the\nnext link of the node immediately preceding the deleted node. Locating this node\ninvolves traversing the entire list and could take a long time. (We remedy this in\nSection3.3whenwediscuss doublylinkedlists.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 121 \u2014 #143\ni i\n3.2. SinglyLinkedLists 121\n3.2.4 Implementing a Generic Singly Linked List\nTheimplementationofthesinglylinkedlistgiveninSection3.2.1assumesthatthe\nelementtypeisacharacterstring. Itiseasytoconverttheimplementationsothatit\nworksforanarbitrary elementtypethrough theuseofC++\u2019stemplatemechanism.\nTheresulting genericsinglylinkedlistclassiscalledSLinkedList.\nWebegin by presenting the node class, called SNode, inCode Fragment 3.18.\nThe element type associated with each node is parameterized by the type vari-\nable E. In contrast to our earlier version in Code Fragment 3.13, references to the\ndata type \u201cstring\u201d have been replaced by \u201cE.\u201d When referring to our templated\nnode and list class, weneed to include the suffix \u201c<E>.\u201d For example, the class is\nSLinkedList<E>andtheassociated nodeisSNode<E>.\ntemplate <typename E>\nclass SNode // singly linked list node\n{\nprivate:\nE elem; // linked list element value\nSNode<E>* next; // next item in the list\nfriend class SLinkedList<E>; // provide SLinkedList access\n;\n}\nCodeFragment3.18: Anodeinagenericsinglylinkedlist.\nThe generic list class is presented in Code Fragment 3.19. As above, refer-\nencestothespecific elementtype\u201cstring\u201dhavebeen replaced byreferences tothe\ngeneric typeparameter \u201cE.\u201dTokeepthings simple,wehaveomittedhousekeeping\nfunctions suchasacopyconstructor.\ntemplate <typename E>\nclass SLinkedList // a singly linked list\n{\npublic:\nSLinkedList(); // empty list constructor\n\u02dcSLinkedList(); // destructor\nbool empty() const; // is list empty?\nconst E& front() const; // return front element\nvoid addFront(const E& e); // add to front of list\nvoid removeFront(); // remove front item list\nprivate:\nSNode<E>* head; // head of the list\n;\n}\nCodeFragment3.19: Aclassdefinitionforagenericsinglylinkedlist.\nInCodeFragment3.20, wepresent theclass memberfunctions. Notethesim-\nilarity with Code Fragments 3.15 through 3.17. Observe that each definition is\nprefaced bythetemplatespecifiertemplate <typename E>.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 122 \u2014 #144\ni i\n122 Chapter3. Arrays,LinkedLists,andRecursion\ntemplate <typename E>\nSLinkedList<E>::SLinkedList() // constructor\n: head(NULL)\n{ }\ntemplate <typename E>\nbool SLinkedList<E>::empty() const // is list empty?\nreturn head == NULL;\n{ }\ntemplate <typename E>\nconst E& SLinkedList<E>::front() const // return front element\nreturn head >elem;\n{ \u2212 }\ntemplate <typename E>\nSLinkedList<E>::\u02dcSLinkedList() // destructor\nwhile (!empty()) removeFront();\n{ }\ntemplate <typename E>\nvoid SLinkedList<E>::addFront(const E& e) // add to front of list\n{\nSNode<E>* v = new SNode<E>; // create new node\nv >elem = e; // store data\n\u2212\nv >next = head; // head now follows v\n\u2212\nhead = v; // v is now the head\n}\ntemplate <typename E>\nvoid SLinkedList<E>::removeFront() // remove front item\n{\nSNode<E>* old = head; // save current head\nhead = old >next; // skip over old head\n\u2212\ndelete old; // delete the old head\n}\nCodeFragment3.20: Othermemberfunctions forageneric singlylinkedlist.\nWecangenerate singly linked lists ofvarious types by simply setting thetem-\nplateparameter asdesiredasshowninthefollowingcodefragment.\nSLinkedList<string> a; // list of strings\na.addFront(\"MSP\");\n// ...\nSLinkedList<int> b; // list of integers\nb.addFront(13);\nCodeFragment3.21: Examplesusingthegeneric singlylinkedlistclass.\nBecause templated classes carry a relatively high notational burden, we often\nsacrifice generality for simplicity, and avoid the use of templated classes in some\nofourexamples.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 123 \u2014 #145\ni i\n3.3. DoublyLinkedLists 123\n3.3 Doubly Linked Lists\nAs we saw in the previous section, removing an element at the tail of a singly\nlinked listisnot easy. Indeed, itistimeconsuming toremoveanynode other than\nthe head in asingly linked list, since wedo not have a quick way ofaccessing the\nnode immediately preceding the one we want to remove. There are many appli-\ncations where we do not have quick access to such a predecessor node. For such\napplications, itwouldbenicetohaveawayofgoingbothdirectionsinalinkedlist.\nThere is a type of linked list that allows us to go in both directions\u2014forward\nand reverse\u2014in alinked list. Itisthe doubly linked list. Inaddition to itselement\nmember, a node in a doubly linked list stores two pointers, a next link and a prev\nlink, which point to the next node in the list and the previous node in the list, re-\nspectively. Suchlistsallowforagreatvarietyofquickupdateoperations,including\nefficientinsertion andremovalatanygivenposition.\nHeader and Trailer Sentinels\nTo simplify programming, it is convenient to add special nodes at both ends of\na doubly linked list: a header node just before the head of the list, and a trailer\nnode just after the tail of the list. These \u201cdummy\u201d or sentinel nodes do not store\nany elements. They provide quick access to the first and last nodes of the list. In\nparticular, the header\u2019s next pointer points tothefirstnode of thelist, and theprev\npointer of the trailer node points to the last node of the list. Anexample is shown\ninFigure3.12.\nFigure 3.12: A doubly linked list with sentinels, header and trailer, marking the\nends of the list. An empty list would have these sentinels pointing to each other.\nWedo not show the null prev pointer for the header nor do we show the null next\npointerforthetrailer.\n3.3.1 Insertion into a Doubly Linked List\nBecause of its double link structure, it is possible to insert a node at any position\nwithin a doubly linked list. Given a node v of a doubly linked list (which could\npossiblybetheheader,butnotthetrailer),letzbeanewnodethatwewishtoinsert\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 124 \u2014 #146\ni i\n124 Chapter3. Arrays,LinkedLists,andRecursion\nimmediatelyafterv. Letwthebenodefollowingv,thatis,wisthenodepointedto\nbyv\u2019snextlink. (Thisnode exists, sincewehavesentinels.) Toinsert zafterv,we\nlinkitintothecurrent list,byperforming thefollowingoperations:\nMakez\u2019sprevlinkpointtov\n\u2022\nMakez\u2019snext linkpointtow\n\u2022\nMakew\u2019sprevlinkpointtoz\n\u2022\nMakev\u2019snext linkpointtoz\n\u2022\nThisprocessisillustrated inFigure3.13,wherevpointstothenodeJFK,wpoints\ntoPVD,and zpoints tothenewnode BWI.Observe thatthis process worksifvis\nanynoderanging fromtheheadertothenodejustpriortothetrailer.\n(a)\n(b)\nFigure3.13: AddinganewnodeafterthenodestoringJFK:(a)creatinganewnode\nwithelementBWIandlinking itin;(b)aftertheinsertion.\n3.3.2 Removal from a Doubly Linked List\nLikewise,itiseasytoremoveanodevfromadoublylinkedlist. Letubethenode\njust prior to v, and w be the node just following v. (These nodes exist, since we\nhave sentinels.) To remove node v, we simply have u and w point to each other\ninstead of to v. We refer to this operation as the linking out of v. Weperform the\nfollowingoperations.\nMakew\u2019sprevlinkpointtou\n\u2022\nMakeu\u2019snext linkpointtow\n\u2022\nDeletenodev\n\u2022\nThis process is illustrated in Figure 3.14, where v is the node PVD, u is the node\nJFK,andwisthenodeSFO.Observethatthisprocessworksifvisanynodefrom\ntheheadertothetailnode(thenodejustpriortothetrailer).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 125 \u2014 #147\ni i\n3.3. DoublyLinkedLists 125\n(a)\n(b)\n(c)\nFigure3.14: Removing the node storing PVD: (a) before the removal; (b) linking\nouttheoldnode;(c)afternodedeletion.\n3.3.3 A C++ Implementation\nLet us consider how to implement a doubly linked list in C++. First, we present a\nC++ class for a node of the list in Code Fragment 3.22. To keep the code simple,\nwehavechosennottoderiveatemplatedclassaswedidinSection3.2.1forsingly\nlinkedlists. Instead,weprovideatypedef statementthatdefinestheelementtype,\ncalled Elem. We define it to be a string, but any other type could be used instead.\nEachnodestoresanelement. Italsocontainspointerstoboththepreviousandnext\nnodesofthelist. WedeclareDLinkedListtobeafriend,soitcanaccessthenode\u2019s\nprivatemembers.\ntypedef string Elem; // list element type\nclass DNode // doubly linked list node\n{\nprivate:\nElem elem; // node element value\nDNode* prev; // previous node in list\nDNode* next; // next node in list\nfriend class DLinkedList; // allow DLinkedList access\n;\n}\nCodeFragment3.22: C++implementation ofadoublylinkedlistnode.\nNext, we present the definition of the doubly linked list class, DLinkedList,\nin Code Fragment 3.23. In addition to a constructor and destructor, the public\nmembers consist of a function that indicates whether the list is currently empty\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 126 \u2014 #148\ni i\n126 Chapter3. Arrays,LinkedLists,andRecursion\n(meaning that it has no nodes other than the sentinels) and accessors to retrieve\nthe front and back elements. Wealso provide methods for inserting and removing\nelements from the front and back of the list. There are two private data members,\nheader andtrailer,whichpoint tothe sentinels. Finally, weprovide twoprotected\nutility member functions, add and remove. They are used internally by the class\nandbyitssubclasses, buttheycannot beinvoked fromoutsidetheclass.\nclass DLinkedList // doubly linked list\n{\npublic:\nDLinkedList(); // constructor\n\u02dcDLinkedList(); // destructor\nbool empty() const; // is list empty?\nconst Elem& front() const; // get front element\nconst Elem& back() const; // get back element\nvoid addFront(const Elem& e); // add to front of list\nvoid addBack(const Elem& e); // add to back of list\nvoid removeFront(); // remove from front\nvoid removeBack(); // remove from back\nprivate: // local type definitions\nDNode* header; // list sentinels\nDNode* trailer;\nprotected: // local utilities\nvoid add(DNode* v, const Elem& e); // insert new node before v\nvoid remove(DNode* v); // remove node v\n;\n}\nCodeFragment3.23: Implementation ofadoublylinkedlistclass.\nLet us begin by presenting the class constructor and destructor as shown in\nCode Fragment 3.24. The constructor creates the sentinel nodes and sets each to\npointtotheother, andthedestructor removesallbutthesentinel nodes.\nDLinkedList::DLinkedList() // constructor\n{\nheader = new DNode; // create sentinels\ntrailer = new DNode;\nheader >next = trailer; // have them point to each other\n\u2212\ntrailer >prev = header;\n\u2212\n}\nDLinkedList::\u02dcDLinkedList() // destructor\n{\nwhile (!empty()) removeFront(); // remove all but sentinels\ndelete header; // remove the sentinels\ndelete trailer;\n}\nCodeFragment3.24: Classconstructor anddestructor.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 127 \u2014 #149\ni i\n3.3. DoublyLinkedLists 127\nNext, inCodeFragment 3.25weshow thebasic class accessors. Todetermine\nwhetherthelistisempty,wecheckthatthereisnonodebetweenthetwosentinels.\nWe do this by testing whether the trailer follows immediately after the header. To\naccessthefrontelementofthelist, wereturntheelementassociated withthenode\nthat follows the list header. To access the back element, we return the element\nassociated with node that precedes the trailer. Bothoperations assume that the list\nisnonempty. Wecould haveenhanced thesefunctions bythrowinganexception if\nan attempt is made to access the front or back of an empty list, just as we did in\nCodeFragment3.6.\nbool DLinkedList::empty() const // is list empty?\nreturn (header >next == trailer);\n{ \u2212 }\nconst Elem& DLinkedList::front() const // get front element\nreturn header >next >elem;\n{ \u2212 \u2212 }\nconst Elem& DLinkedList::back() const // get back element\nreturn trailer >prev >elem;\n{ \u2212 \u2212 }\nCodeFragment3.25: Accessorfunctions forthedoublylinkedlistclass.\nIn Section 3.3.1, we discussed how to insert a node into a doubly linked list.\nThelocalutilityfunctionadd,whichisshowninCodeFragment3.26,implements\nthisoperation. Inordertoaddanodetothefrontofthelist,wecreate anewnode,\nand insert it immediately after the header, or equivalently, immediately before the\nnodethatfollowstheheader. Inordertoaddanewnodetothebackofthelist, we\ncreateanewnode,andinsertitimmediatelybeforethetrailer.\n// insert new node before v\nvoid DLinkedList::add(DNode* v, const Elem& e)\n{\nDNode* u = new DNode; u >elem = e; // create a new node for e\n\u2212\nu >next = v; // link u in between v\n\u2212\nu >prev = v >prev; // ...and v->prev\n\u2212 \u2212\nv >prev >next = v >prev = u;\n\u2212 \u2212 \u2212\n}\nvoid DLinkedList::addFront(const Elem& e) // add to front of list\nadd(header >next, e);\n{ \u2212 }\nvoid DLinkedList::addBack(const Elem& e) // add to back of list\nadd(trailer, e);\n{ }\nCodeFragment3.26: Inserting anew node into adoubly linked list. Theprotected\nutilityfunctionaddinsertsanodezbeforeanarbitrarynodev. Thepublicmember\nfunctions addFrontandaddBackbothinvoke thisutilityfunction.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 128 \u2014 #150\ni i\n128 Chapter3. Arrays,LinkedLists,andRecursion\nObserve that the above code works even if the list is empty (meaning that the\nonly nodes are the header and trailer). For example, if addBack is invoked on an\nempty list, then the value of trailer->prev is a pointer to the list header. Thus,\nthe node is added between the header and trailer as desired. One of the major\nadvantages ofprovidingsentinelnodesistoavoidhandlingofspecialcases,which\nwouldotherwisebeneeded.\nFinally, let us discuss deletion. In Section 3.3.2, we showed how to remove\nan arbitrary node from a doubly linked list. In Code Fragment 3.27, we present\nlocal utility function remove, whichperforms the operation. In addition tolinking\nout the node, it also deletes the node. The public member functions removeFront\nandremoveBackareimplementedbydeletingthenodesimmediatelyfollowingthe\nheaderandimmediatelypreceding thetrailer, respectively.\nvoid DLinkedList::remove(DNode* v) // remove node v\n{\nDNode* u = v >prev; // predecessor\n\u2212\nDNode* w = v >next; // successor\n\u2212\nu >next = w; // unlink v from list\n\u2212\nw >prev = u;\n\u2212\ndelete v;\n}\nvoid DLinkedList::removeFront() // remove from font\nremove(header >next);\n{ \u2212 }\nvoid DLinkedList::removeBack() // remove from back\nremove(trailer >prev);\n{ \u2212 }\nCodeFragment3.27: Removing anode from adoubly linked list. Thelocal utility\nfunction remove removes the node v. The public member functions removeFront\nandremoveBackinvoke thisutilityfunction.\nThere are many more features that we could have added to our simple imple-\nmentationofadoublylinkedlist. Althoughwehaveprovidedaccesstotheendsof\nthelist,wehavenotprovidedanymechanismforaccessing ormodifyingelements\nin the middle of the list. Later, in Chapter 6, we discuss the concept of iterators,\nwhichprovidesamechanism foraccessing arbitrary elementsofalist.\nWe have also performed no error checking in our implementation. It is the\nuser\u2019s responsibility not to attempt to access or remove elements from an empty\nlist. In amore robust implementation of adoubly linked list, wewould design the\nmember functions front, back, removeFront, and removeBack to throw an excep-\ntion when an attempt is made to perform one of these functions on an empty list.\nNonetheless, this simple implementation illustrates how easy it is to manipulate\nthisusefuldatastructure.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 129 \u2014 #151\ni i\n3.4. CircularlyLinkedListsandListReversal 129\n3.4 Circularly Linked Lists and List Reversal\nInthissection, westudysomeapplications andextensions oflinkedlists.\n3.4.1 Circularly Linked Lists\nA circularly linked list has the same kind of nodes as a singly linked list. That is,\neach node in a circularly linked list has a next pointer and an element value. But,\nrather than having a head or tail, the nodes of a circularly linked list are linked\ninto a cycle. If we traverse the nodes of a circularly linked list from any node by\nfollowing next pointers, we eventually visit all the nodes and cycle back to the\nnodefromwhichwestarted.\nEven though a circularly linked list has no beginning or end, we nevertheless\nneed some node to be marked as a special node, which we call the cursor. The\ncursor node allows us to have a place to start from if we ever need to traverse a\ncircularly linkedlist.\nThere are two positions of particular interest in a circular list. The first is the\nelement that isreferenced by thecursor, which iscalled theback, and theelement\nimmediatelyfollowingthisinthecircularorder,whichiscalledthefront. Although\nitmayseemoddtothinkofacircularlistashavingafrontandaback,observethat,\nifweweretocutthelinkbetweenthenodereferencedbythecursorandthisnode\u2019s\nimmediatesuccessor, theresultwouldbeasinglylinkedlistfromthefrontnodeto\nthebacknode.\ncursor\n(front) (back)\nLAX MSP ATL BOS\nFigure3.15: Acircularlylinkedlist. Thenodereferencedbythecursoriscalledthe\nback,andthenodeimmediately followingiscalledthefront.\nWedefinethefollowingfunctions foracircularly linked list:\nfront(): Returntheelementreferenced bythecursor; anerrorre-\nsultsifthelistisempty.\nback(): Returntheelementimmediatelyafterthecursor;anerror\nresults ifthelistisempty.\nadvance(): Advancethecursortothenextnodeinthelist.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 130 \u2014 #152\ni i\n130 Chapter3. Arrays,LinkedLists,andRecursion\nadd(e): Insert a new node with element e immediately after the\ncursor; if the list is empty, then this node becomes the\ncursoranditsnext pointerpointstoitself.\nremove(): Remove the node immediately after the cursor (not the\ncursor itself, unless it is the only node); if the list be-\ncomesempty,thecursorissettonull.\nIn Code Fragment 3.28, we show a C++ implementation of a node of a cir-\ncularly linked list, assuming that each node contains a single string. The node\nstructure is essentially identical to that of a singly linked list (recall Code Frag-\nment3.13). Tokeep the code simple, wehave not implemented atemplated class.\nInstead, weprovide a typedef statement that defines the element type Elem to be\nthebasetypeofthelist,whichinthiscaseisastring.\ntypedef string Elem; // element type\nclass CNode // circularly linked list node\n{\nprivate:\nElem elem; // linked list element value\nCNode* next; // next item in the list\nfriend class CircleList; // provide CircleList access\n;\n}\nCodeFragment3.28: Anodeofacircularly linked list.\nNext, in Code Fragment 3.29, we present the class definition for a circularly\nlinked list called CircleList. In addition to the above functions, the class provides\na constructor, a destructor, and a function to detect whether the list is empty. The\nprivatememberconsists ofthecursor, whichpointstosomenodeofthelist.\nclass CircleList // a circularly linked list\n{\npublic:\nCircleList(); // constructor\n\u02dcCircleList(); // destructor\nbool empty() const; // is list empty?\nconst Elem& front() const; // element at cursor\nconst Elem& back() const; // element following cursor\nvoid advance(); // advance cursor\nvoid add(const Elem& e); // add after cursor\nvoid remove(); // remove node after cursor\nprivate:\nCNode* cursor; // the cursor\n;\n}\nCodeFragment3.29: Implementation ofacircularly linkedlistclass.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 131 \u2014 #153\ni i\n3.4. CircularlyLinkedListsandListReversal 131\nCode Fragment 3.30 presents the class\u2019s constructor and destructor. The con-\nstructor generates anemptylistbysetting thecursor toNULL.Thedestructor iter-\natively removes nodes until the list is empty. We exploit the fact that the member\nfunction remove(givenbelow)deletesthenodethatitremoves.\nCircleList::CircleList() // constructor\n: cursor(NULL)\n{ }\nCircleList::\u02dcCircleList() // destructor\nwhile (!empty()) remove();\n{ }\nCodeFragment3.30: Theconstructor anddestructor.\nWe present a number of simple member functions in Code Fragment 3.31. To\ndetermine whether the list is empty, we test whether the cursor is NULL. The ad-\nvancefunction advancesthecursortothenextelement.\nbool CircleList::empty() const // is list empty?\nreturn cursor == NULL;\n{ }\nconst Elem& CircleList::back() const // element at cursor\nreturn cursor >elem;\n{ \u2212 }\nconst Elem& CircleList::front() const // element following cursor\nreturn cursor >next >elem;\n{ \u2212 \u2212 }\nvoid CircleList::advance() // advance cursor\ncursor = cursor >next;\n{ \u2212 }\nCodeFragment3.31: Simplememberfunctions.\nNext,letusconsiderinsertion. Recallthatinsertionstothecircularlylinkedlist\noccur after the cursor. We begin by creating a new node and initializing its data\nmember. If the list is empty, we create a new node that points to itself. We then\ndirectthecursortopointtothiselement. Otherwise,welinkthenewnodejustafter\nthecursor. Thecodeispresented inCodeFragment3.32.\nvoid CircleList::add(const Elem& e) // add after cursor\n{\nCNode* v = new CNode; // create a new node\nv >elem = e;\n\u2212\nif (cursor == NULL) // list is empty?\n{\nv >next = v; // v points to itself\n\u2212\ncursor = v; // cursor points to v\n}\nelse // list is nonempty?\n{\nv >next = cursor >next; // link in v after cursor\n\u2212 \u2212\ncursor >next = v;\n\u2212\n}\n}\nCodeFragment3.32: Insertinganodejustafterthecursorofacircularlylinkedlist.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 132 \u2014 #154\ni i\n132 Chapter3. Arrays,LinkedLists,andRecursion\nFinally,weconsiderremoval. Weassumethattheuserhascheckedthatthelist\nisnonemptybefore invoking thisfunction. (Amorecareful implementation would\nthrowanexception ifthelistisempty.) Therearetwocases. Ifthisisthelastnode\nof the list (which can be tested by checking that the node to be removed points to\nitself) we set the cursor to NULL. Otherwise, we link the cursor\u2019s next pointer to\nskip over the removed node. We then delete the node. The code is presented in\nCodeFragment3.33.\nvoid CircleList::remove() // remove node after cursor\n{\nCNode* old = cursor >next; // the node being removed\n\u2212\nif (old == cursor) // removing the only node?\ncursor = NULL; // list is now empty\nelse\ncursor >next = old >next; // link out the old node\n\u2212 \u2212\ndelete old; // delete the old node\n}\nCodeFragment3.33: Removingthenodefollowingthecursor.\nTo keep the code simple, we have omitted error checking. In front, back, and\nadvance, we should first test whether the list is empty, since otherwise the cursor\npointer will be NULL. In the first two cases, we should throw some sort of excep-\ntion. Inthecaseofadvance,ifthelistisempty,wecansimplyreturn.\nMaintaining a Playlist for a Digital Audio Player\nTo help illustrate the use of our CircleList implementation of the circularly linked\nlist, let us consider how to build a simple interface for maintaining a playlist for\na digital audio player, also known as an MP3 player. The songs of the player are\nstored in a circular list. The cursor points to the current song. By advancing the\ncursor, we can move from one song to the next. We can also add new songs and\nremove songs by invoking the member functions insert and remove, respectively.\nOfcourse,acompleteimplementation wouldneedtoprovideamethodforplaying\nthe current song, but our purpose is to illustrate how the circularly linked list can\nbeappliedtothistask.\nTo make this more concrete, suppose that you have a friend who loves retro\nmusic, and you want tocreate aplaylist of songs from the bygone Disco Era. The\nmain program is presented Code Fragment 3.34. We declare an object playList\nto be a CircleList. The constructor creates an empty playlist. We proceed to add\nthree songs, \u201cStayin Alive,\u201d \u201cLe Freak,\u201d and \u201cJive Talkin.\u201d The comments on the\nright show the current contents of the list insquare brackets. Thefirstentry of the\nlist is the element immediately following the cursor (which iswhere insertion and\nremoval occur), and the last entry in the list is cursor (which is indicated with an\nasterisk).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 133 \u2014 #155\ni i\n3.4. CircularlyLinkedListsandListReversal 133\nSuppose that we decide to replace \u201cStayin Alive\u201d with \u201cDisco Inferno.\u201d We\nadvancethecursortwicesothat\u201cStayinAlive\u201dcomesimmediatelyafterthecursor.\nWethenremovethisentryandinsertitsreplacement.\nint main()\n{\nCircleList playList; // []\nplayList.add(\"Stayin Alive\"); // [Stayin Alive*]\nplayList.add(\"Le Freak\"); // [Le Freak, Stayin Alive*]\nplayList.add(\"Jive Talkin\"); // [Jive Talkin, Le Freak, Stayin Alive*]\nplayList.advance(); // [Le Freak, Stayin Alive, Jive Talkin*]\nplayList.advance(); // [Stayin Alive, Jive Talkin, Le Freak*]\nplayList.remove(); // [Jive Talkin, Le Freak*]\nplayList.add(\"Disco Inferno\"); // [Disco Inferno, Jive Talkin, Le Freak*]\nreturn EXIT SUCCESS;\n}\nCodeFragment3.34: UsingtheCircleListclasstoimplementaplaylistforadigital\naudioplayer.\n3.4.2 Reversing a Linked List\nAsanotherexampleofthemanipulationoflinkedlists,wepresentasimplefunction\nfor reversing the elements of a doubly linked list. Given a list L, our approach\ninvolvesfirstcopyingthecontentsofLinreverseorderintoatemporarylistT,and\nthencopying thecontents ofT backintoL(butwithoutreversing).\nTo achieve the initial reversed copy, we repeatedly extract the first element of\nL and copy it to the front of T. (To see why this works, observe that the later an\nelement appears in L, the earlier it will appear in T.) To copy the contents of T\nback to L, we repeatedly extract elements from the front of T, but this time we\ncopy each onetotheback oflistL. OurC++implementation ispresented inCode\nFragment3.35.\nvoid listReverse(DLinkedList& L) // reverse a list\n{\nDLinkedList T; // temporary list\nwhile (!L.empty()) // reverse L into T\n{\nstring s = L.front(); L.removeFront();\nT.addFront(s);\n}\nwhile (!T.empty()) // copy T back to L\n{\nstring s = T.front(); T.removeFront();\nL.addBack(s);\n}\n}\nCodeFragment3.35: AfunctionthatreversesthecontentsofadoublylinkedlistL.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 134 \u2014 #156\ni i\n134 Chapter3. Arrays,LinkedLists,andRecursion\n3.5 Recursion\nWe have seen that repetition can be achieved by writing loops, such as for loops\nand while loops. Another way to achieve repetition is through recursion, which\noccurswhenafunctionreferstoitselfinitsowndefinition. Wehaveseenexamples\nof functions calling other functions, so it should come as no surprise that most\nmodern programming languages, including C++, allow a function to call itself. In\nthissection,weseewhythiscapabilityprovidesanelegantandpowerfulalternative\nforperformingrepetitive tasks.\nThe Factorial Function\nToillustraterecursion,letusbeginwithasimpleexampleofcomputingthevalueof\nthe factorial function. The factorial of a positive integer n, denoted n!, is defined\nas the product of the integers from 1 to n. If n = 0, then n! is defined as 1 by\nconvention. Moreformally,foranyintegern 0,\n\u2265\n1 ifn=0\nn!=\nn (n 1) (n 2) 3 2 1 ifn 1.\n(cid:26) \u00b7 \u2212 \u00b7 \u2212 \u00b7\u00b7\u00b7 \u00b7 \u00b7 \u2265\nFor example, 5! = 5 4 3 2 1 = 120. To make the connection with functions\n\u00b7 \u00b7 \u00b7 \u00b7\nclearer, weusethenotationfactorial(n)todenoten!.\nThe factorial function can be defined in a manner that suggests a recursive\nformulation. Toseethis,observethat\nfactorial(5)=5 (4 3 2 1)=5 factorial(4).\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nThus, wecan define factorial(5)interms offactorial(4). Ingeneral, for apositive\ninteger n, we can define factorial(n) to be n factorial(n 1). This leads to the\n\u00b7 \u2212\nfollowingrecursivedefinition\n1 ifn=0\nfactorial(n)=\nn factorial(n 1) ifn 1.\n(cid:26) \u00b7 \u2212 \u2265\nThis definition is typical of many recursive definitions. First, it contains one\nor more base cases, which are defined nonrecursively in terms of fixed quantities.\nIn this case, n=0 is the base case. It also contains one or more recursive cases,\nwhicharedefinedbyappealing tothedefinitionofthefunctionbeingdefined. Ob-\nservethatthereisnocircularity inthisdefinitionbecause eachtimethefunction is\ninvoked, itsargumentissmallerbyone.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 135 \u2014 #157\ni i\n3.5. Recursion 135\nA Recursive Implementation of the Factorial Function\nLetusconsideraC++implementationofthefactorialfunctionshowninCodeFrag-\nment 3.36 under the name recursiveFactorial. Notice that no looping was needed\nhere. Therepeated recursiveinvocations ofthefunction taketheplaceoflooping.\nint recursiveFactorial(int n) // recursive factorial function\n{\nif (n == 0) return 1; // basis case\nelse return n * recursiveFactorial(n 1); // recursive case\n\u2212\n}\nCodeFragment3.36: Arecursiveimplementation ofthefactorialfunction.\nWecanillustrate theexecution ofarecursive function definitionbymeansofa\nrecursion trace. Eachentry ofthe trace corresponds toarecursive call. Eachnew\nrecursivefunctioncallisindicated byanarrowtothenewlycalledfunction. When\nthe function returns, an arrow showing this return is drawn, and the return value\nmaybeindicated withthisarrow. AnexampleofatraceisshowninFigure3.16.\nWhatistheadvantageofusingrecursion? Althoughtherecursiveimplementa-\ntion ofthe factorial function issomewhatsimpler than theiterative version, inthis\ncasethereisnocompellingreasonforpreferringrecursionoveriteration. Forsome\nproblems, however, a recursive implementation can be significantly simpler and\neasiertounderstand thananiterativeimplementation. Suchanexamplefollows.\nFigure3.16: Arecursion traceforthecallrecursiveFactorial(4).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 136 \u2014 #158\ni i\n136 Chapter3. Arrays,LinkedLists,andRecursion\nDrawing an English Ruler\nAs a more complex example of the use of recursion, consider how to draw the\nmarkings ofatypical English ruler. Sucharuler isbroken into intervals, andeach\ninterval consists of a set of ticks, placed at intervals of 1/2 inch, 1/4 inch, and so\non. As the size of the interval decreases by half, the tick length decreases by one.\n(SeeFigure3.17.)\n---- 0 ----- 0 --- 0\n- - -\n-- -- --\n- - -\n--- --- --- 1\n- - -\n-- -- --\n- - -\n---- 1 ---- --- 2\n- - -\n-- -- --\n- - -\n--- --- --- 3\n- -\n-- --\n- -\n---- 2 ----- 1\n(a) (b) (c)\nFigure3.17: Three sample outputs of an English ruler drawing: (a) a 2-inch ruler\nwith major tick length 4; (b) a 1-inch ruler with major tick length 5; (c) a 3-inch\nrulerwithmajorticklength3.\nEach fraction of an inch also has a numeric label. The longest tick length is\ncalledthemajorticklength. Wewon\u2019tworryaboutactualdistances, however,and\njustprintonetickperline.\nA Recursive Approach to Ruler Drawing\nOurapproachtodrawingsucharulerconsistsofthreefunctions. Themainfunction\ndrawRuler draws the entire ruler. Its arguments are the total number of inches in\ntheruler,nInches,andthemajorticklength,majorLength. Theutilityfunctiondra-\nwOneTickdrawsasingle tickofthe given length. Itcanalso begiven anoptional\nintegerlabel,whichisprinted ifitisnonnegative.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 137 \u2014 #159\ni i\n3.5. Recursion 137\nTheinterestingworkisdonebytherecursivefunctiondrawTicks,whichdraws\nthe sequence of ticks within some interval. Its only argument is the tick length\nassociated with the interval\u2019s central tick. Consider the English ruler with major\nticklength 5showninFigure3.17(b). Ignoring thelines containing 0and1, letus\nconsider how to draw the sequence ofticks lying between these lines. The central\ntick (at 1/2 inch) has length 4. Observe that the two patterns of ticks above and\nbelow this central tick are identical, and each has a central tick of length 3. In\ngeneral, anintervalwithacentralticklengthL 1iscomposedofthefollowing:\n\u2265\nAnintervalwithacentralticklengthL 1\n\u2022 \u2212\nAsingletickoflengthL\n\u2022\nAnintervalwithacentralticklengthL 1\n\u2022 \u2212\nWith each recursive call, the length decreases by one. When the length drops to\nzero, wesimply return. Asaresult, this recursive process always terminates. This\nsuggests arecursiveprocess inwhichthefirstandlaststepsareperformed bycall-\ning the drawTicks(L 1) recursively. The middle step is performed by calling\n\u2212\nthe function drawOneTick(L). This recursive formulation is shown in Code Frag-\nment 3.37. Asin the factorial example, the code has a base case (when L=0). In\nthisinstance wemaketworecursive callstothefunction.\n// one tick with optional label\nvoid drawOneTick(int tickLength, int tickLabel = 1)\n\u2212 {\nfor (int i = 0; i < tickLength; i++)\ncout << \"-\";\nif (tickLabel >= 0) cout << \" \" << tickLabel;\ncout << \"\\n\";\n}\nvoid drawTicks(int tickLength) // draw ticks of given length\n{\nif (tickLength > 0) // stop when length drops to 0\n{\ndrawTicks(tickLength 1); // recursively draw left ticks\n\u2212\ndrawOneTick(tickLength); // draw center tick\ndrawTicks(tickLength 1); // recursively draw right ticks\n\u2212\n}\n}\nvoid drawRuler(int nInches, int majorLength) // draw the entire ruler\n{\ndrawOneTick(majorLength, 0); // draw tick 0 and its label\nfor (int i = 1; i <= nInches; i++)\n{\ndrawTicks(majorLength 1); // draw ticks for this inch\n\u2212\ndrawOneTick(majorLength, i); // draw tick i and its label\n}\n}\nCodeFragment3.37: Arecursive implementation ofafunctionthatdrawsaruler.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 138 \u2014 #160\ni i\n138 Chapter3. Arrays,LinkedLists,andRecursion\nIllustrating Ruler Drawing using a Recursion Trace\nTherecursiveexecutionoftherecursivedrawTicksfunction,definedabove,canbe\nvisualized usingarecursion trace.\nThe trace for drawTicks is more complicated than in the factorial example,\nhowever, because each instance makes two recursive calls. To illustrate this, we\nshowtherecursion traceinaformthatisreminiscentofanoutlineforadocument.\nSeeFigure3.18.\nFigure3.18: ApartialrecursiontraceforthecalldrawTicks(3). Thesecondpattern\nofcallsfordrawTicks(2)isnotshown,butitisidentical tothefirst.\nThroughout this book, we see many other examples of how recursion can be\nusedinthedesignofdatastructures andalgorithms.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 139 \u2014 #161\ni i\n3.5. Recursion 139\nFurther Illustrations of Recursion\nAswediscussed above, recursion istheconcept ofdefining afunction that makes\nacalltoitself. Whenafunction callsitself, werefertothisasarecursivecall. We\nalsoconsiderafunctionMtoberecursiveifitcallsanotherfunctionthatultimately\nleadstoacallbacktoM.\nThemainbenefitofarecursiveapproachtoalgorithmdesignisthatitallowsus\ntotakeadvantage oftherepetitive structure present inmanyproblems. Bymaking\nouralgorithmdescriptionexploitthisrepetitivestructureinarecursiveway,wecan\noften avoid complex case analyses and nested loops. This approach can lead to\nmorereadablealgorithm descriptions, whilestillbeingquiteefficient.\nIn addition, recursion is a useful way for defining objects that have a repeated\nsimilarstructural form,suchasinthefollowingexamples.\nExample 3.1: Modernoperatingsystemsdefinefile-systemdirectories(whichare\nalsosometimescalled\u201cfolders\u201d)inarecursiveway.Namely,afilesystemconsists\nofatop-leveldirectory,andthecontentsofthisdirectoryconsistsoffilesandother\ndirectories,whichinturncancontainfilesandotherdirectories,andsoon. The\nbasedirectoriesinthefilesystemcontainonlyfiles,butbyusingthisrecursive\ndefinition,theoperatingsystemallowsfordirectoriestobenestedarbitrarilydeep\n(aslongasthereisenoughspaceinmemory).\nExample 3.2: Muchofthesyntaxinmodernprogramminglanguagesisdefined\ninarecursiveway. Forexample,wecandefineanargumentlistinC++usingthe\nfollowingnotation:\nargument-list:\nargument\nargument-list,argument\nInotherwords,anargumentlistconsistsofeither(i)anargumentor(ii)anargu-\nmentlistfollowedbyacommaandanargument.Thatis,anargumentlistconsists\nofacomma-separatedlistofarguments. Similarly,arithmeticexpressionscanbe\ndefinedrecursivelyintermsofprimitives(likevariablesandconstants)andarith-\nmeticexpressions.\nExample 3.3: Therearemanyexamplesofrecursioninartandnature.Oneofthe\nmostclassicexamplesofrecursionusedinartisintheRussianMatryoshkadolls.\nEachdollismadeofsolidwoodorishollowandcontainsanotherMatryoshkadoll\ninsideit.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 140 \u2014 #162\ni i\n140 Chapter3. Arrays,LinkedLists,andRecursion\n3.5.1 Linear Recursion\nThe simplest form of recursion is linear recursion, where a function is defined\nso that it makes at most one recursive call each time it is invoked. This type of\nrecursion isuseful whenweview analgorithmic problem intermsofafirstorlast\nelementplusaremainingsetthathasthesamestructure astheoriginal set.\nSumming the Elements of an Array Recursively\nSuppose, for example, weare given an array, A, ofn integers that wewant tosum\ntogether. Wecansolvethissummationproblemusinglinearrecursionbyobserving\nthatthesumofallnintegersinAisequaltoA[0],ifn=1,orthesumofthefirstn\n\u2212\n1integersinAplusthelastelementinA. Inparticular,wecansolvethissummation\nproblem usingtherecursive algorithm described inCodeFragment3.38.\nAlgorithmLinearSum(A,n):\nInput: AintegerarrayAandanintegern 1,suchthatAhasatleastnelements\n\u2265\nOutput: ThesumofthefirstnintegersinA\nifn=1then\nreturnA[0]\nelse\nreturnLinearSum(A,n 1)+A[n 1]\n\u2212 \u2212\nCodeFragment3.38: Summingtheelementsinanarrayusinglinearrecursion.\nThis example also illustrates an important property that a recursive function\nshould always possess\u2014the function terminates. Weensure this bywriting anon-\nrecursivestatementforthecasen=1. Inaddition,wealwaysperformtherecursive\ncallonasmallervalueoftheparameter(n 1)thanthatwhichwearegiven(n),so\n\u2212\nthat, at some point (at the \u201cbottom\u201d of the recursion), we will perform the nonre-\ncursive partofthecomputation (returning A[0]). Ingeneral, analgorithm thatuses\nlinearrecursion typically hasthefollowingform:\nTestforbasecases. Webeginbytestingforasetofbasecases(thereshould\n\u2022\nbe at least one). These base cases should be defined so that every possible\nchain of recursive calls eventually reaches a base case, and the handling of\neachbasecaseshouldnotuserecursion.\nRecur. After testing for base cases, we then perform a single recursive call.\n\u2022\nThisrecursive step mayinvolve atest thatdecides which ofseveral possible\nrecursive calls to make, but it should ultimately choose to make just one of\nthesecallseachtimeweperform thisstep. Moreover,weshoulddefineeach\npossible recursivecallsothatitmakesprogress towardsabasecase.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 141 \u2014 #163\ni i\n3.5. Recursion 141\nAnalyzing Recursive Algorithms using Recursion Traces\nWecan analyze arecursive algorithm by using a visual tool known asarecursion\ntrace. We used recursion traces, for example, to analyze and visualize the recur-\nsivefactorial function ofSection 3.5, andwesimilarly userecursion traces for the\nrecursivesorting algorithmsofSections11.1and11.2.\nTo draw a recursion trace, we create a box for each instance of the function\nandlabelitwiththeparameters ofthefunction. Also,wevisualize arecursive call\nby drawing an arrow from the box of the calling function to the box of the called\nfunction. Forexample,weillustratetherecursiontraceoftheLinearSumalgorithm\nof Code Fragment 3.38 in Figure 3.19. We label each box in this trace with the\nparameters used to make this call. Each time we make a recursive call, we draw\na line to the box representing the recursive call. We can also use this diagram to\nvisualize stepping through the algorithm, since it proceeds by going from the call\nforntothecallforn 1,tothecallforn 2,andsoon,allthewaydowntothecall\n\u2212 \u2212\nfor 1. When the final call finishes, it returns its value back to the call for 2, which\nadds in its value, and returns this partial sum to the call for 3, and so on, until the\ncallforn 1returnsitspartialsumtothecallforn.\n\u2212\nFigure3.19: RecursiontraceforanexecutionofLinearSum(A,n)withinputparam-\netersA= 4,3,6,2,5 andn=5.\n{ }\nFromFigure3.19,itshouldbeclearthatforaninputarrayofsizen,Algorithm\nLinearSummakesncalls. Hence,ittakesanamountoftimethatisroughlypropor-\ntional to n, since it spends a constant amount of time performing the nonrecursive\npart of each call. Moreover, we can also see that the memory space used by the\nalgorithm (in addition to the array A) is also roughly proportional to n, since we\nneedaconstantamountofmemoryspaceforeachofthenboxesinthetraceatthe\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 142 \u2014 #164\ni i\n142 Chapter3. Arrays,LinkedLists,andRecursion\ntimewemakethefinalrecursivecall(forn=1).\nReversing an Array by Recursion\nNext,letusconsidertheproblemofreversingthenelementsofanarray,A,sothat\nthe first element becomes the last, the second element becomes second to the last,\nandsoon. Wecansolvethis problem usinglinear recursion, byobserving thatthe\nreversal of an array can be achieved by swapping the first and last elements and\nthen recursively reversing the remaining elements in the array. We describe the\ndetails ofthis algorithm inCodeFragment3.39, using theconvention thatthe first\ntimewecallthisalgorithm wedosoasReverseArray(A,0,n 1).\n\u2212\nAlgorithmReverseArray(A,i,j):\nInput: AnarrayAandnonnegativeintegerindicesiand j\nOutput: ThereversaloftheelementsinAstarting atindexiandendingat j\nifi< jthen\nSwapA[i]andA[j]\nReverseArray(A,i+1,j 1)\n\u2212\nreturn\nCodeFragment3.39: Reversingtheelementsofanarrayusinglinearrecursion.\nNote that, in this algorithm, we actually have two base cases, namely, when\ni= jandwheni> j. Moreover, ineithercase,wesimplyterminatethealgorithm,\nsinceasequencewithzeroelementsoroneelementistriviallyequaltoitsreversal.\nFurthermore, note that in the recursive step we are guaranteed to make progress\ntowardsoneofthesetwobasecases. Ifnisodd,weeventuallyreachthei= jcase,\nand if n iseven, weeventually reach the i> j case. The above argument immedi-\nately implies that the recursive algorithm of Code Fragment 3.39 is guaranteed to\nterminate.\nDefining Problems in Ways that Facilitate Recursion\nTodesignarecursivealgorithm foragivenproblem, itisusefultothinkofthedif-\nferent ways we can subdivide this problem to define problems that have the same\ngeneral structure as the original problem. Thisprocess sometimes means weneed\nto redefine the original problem to facilitate similar-looking subproblems. Forex-\nample,withtheReverseArrayalgorithm, weaddedtheparameters iand jsothata\nrecursivecalltoreversetheinnerpartofthearrayAwouldhavethesamestructure\n(and same syntax) asthe call to reverse all of A. Then, rather than initially calling\nthe algorithm as ReverseArray(A), wecall itinitially asReverseArray(A,0,n 1).\n\u2212\nIngeneral,ifonehasdifficultyfindingtherepetitivestructureneededtodesignare-\ncursivealgorithm,itissometimesusefultoworkouttheproblemonafewconcrete\nexamplestoseehowthesubproblems shouldbedefined.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 143 \u2014 #165\ni i\n3.5. Recursion 143\nTail Recursion\nUsing recursion can often be a useful tool for designing algorithms that have ele-\ngant, short definitions. But this usefulness does come at a modest cost. When we\nuse a recursive algorithm to solve aproblem, wehave to use some of the memory\nlocations in our computer to keep track of the state of each active recursive call.\nWhencomputermemoryisatapremium,thenitisusefulinsomecasestobeable\ntoderivenonrecursive algorithms fromrecursive ones.\nWecanusethestackdatastructure,discussedinSection5.1,toconvertarecur-\nsivealgorithmintoanonrecursivealgorithm,buttherearesomeinstanceswhenwe\ncandothisconversion moreeasily andefficiently. Specifically, wecaneasilycon-\nvert algorithms that use tail recursion. An algorithm uses tail recursion if it uses\nlinear recursion and thealgorithm makes arecursive callasitsvery lastoperation.\nFor example, the algorithm of Code Fragment 3.39 uses tail recursion to reverse\ntheelementsofanarray.\nIt is not enough that the last statement in the function definition includes a\nrecursive call, however. In order for a function to use tail recursion, the recursive\ncallmustbeabsolutelythelastthingthefunctiondoes(unlessweareinabasecase,\nof course). For example, the algorithm of Code Fragment 3.38 does not use tail\nrecursion, even though its last statement includes a recursive call. This recursive\ncall is not actually the last thing the function does. After it receives the value\nreturned from therecursive call, itaddsthisvaluetoA[n 1]andreturns thissum.\n\u2212\nThatis,thelastthingthisalgorithm doesisanadd,notarecursive call.\nWhen an algorithm uses tail recursion, wecan convert the recursive algorithm\ninto a nonrecursive one, by iterating through the recursive calls rather than call-\ning them explicitly. We illustrate this type of conversion by revisiting the prob-\nlem of reversing the elements of an array. In Code Fragment 3.40, we give a\nnonrecursive algorithm that performs this task by iterating through the recursive\ncalls of the algorithm of Code Fragment 3.39. We initially call this algorithm as\nIterativeReverseArray(A,0,n 1).\n\u2212\nAlgorithmIterativeReverseArray(A,i,j):\nInput: AnarrayAandnonnegativeintegerindicesiand j\nOutput: ThereversaloftheelementsinAstarting atindexiandendingat j\nwhilei< jdo\nSwapA[i]andA[j]\ni i+1\n\u2190\nj j 1\n\u2190 \u2212\nreturn\nCodeFragment3.40: Reversingtheelementsofanarrayusingiteration.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 144 \u2014 #166\ni i\n144 Chapter3. Arrays,LinkedLists,andRecursion\n3.5.2 Binary Recursion\nWhenanalgorithmmakestworecursivecalls,wesaythatitusesbinaryrecursion.\nThesecallscan,forexample,beusedtosolvetwosimilarhalvesofsomeproblem,\nas we did in Section 3.5 for drawing an English ruler. As another application of\nbinaryrecursion,letusrevisittheproblemofsummingthenelementsofaninteger\narrayA. Inthiscase,wecansumtheelementsinAby: (i)recursivelysummingthe\nelements inthefirsthalfofA;(ii)recursively summingtheelements inthe second\nhalf of A; and (iii) adding these two values together. We give the details in the\nalgorithm ofCodeFragment3.41,whichweinitiallycallasBinarySum(A,0,n).\nAlgorithmBinarySum(A,i,n):\nInput: AnarrayAandintegersiandn\nOutput: Thesumofthenintegers inAstarting atindexi\nifn=1then\nreturnA[i]\nreturnBinarySum(A,i, n/2 )+BinarySum(A,i+ n/2 , n/2 )\n\u2308 \u2309 \u2308 \u2309 \u230a \u230b\nCodeFragment3.41: Summingtheelementsinanarrayusingbinaryrecursion.\nTo analyze Algorithm BinarySum, we consider, for simplicity, the case where\nnisapoweroftwo. ThegeneralcaseofarbitrarynisconsideredinExerciseR-4.5.\nFigure3.20showstherecursiontraceofanexecutionoffunctionBinarySum(0,8).\nWelabeleachboxwiththevaluesofparametersiandn,whichrepresent thestart-\ningindex and length ofthe sequence ofelements tobesummed, respectively. No-\ntice that thearrows inthe trace gofrom abox labeled (i,n) toanother boxlabeled\n(i,n/2) or(i+n/2,n/2). Thatis, thevalueofparameter nishalved ateach recur-\nsivecall. Thus,thedepthoftherecursion,thatis,themaximumnumberoffunction\ninstances that are active at the same time, is 1+log n. Thus, Algorithm Binary-\n2\nSumusesanamountofadditional spaceroughlyproportional tothisvalue. Thisis\nabigimprovementoverthespaceneededbytheLinearSumfunctionofCodeFrag-\nment3.38. Therunning timeofAlgorithmBinarySumisstillroughly proportional\nton,however,sinceeachboxisvisitedinconstanttimewhensteppingthroughour\nalgorithm andthereare2n 1boxes.\n\u2212\nFigure3.20: Recursiontracefortheexecution ofBinarySum(0,8).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 145 \u2014 #167\ni i\n3.5. Recursion 145\nComputing Fibonacci Numbers via Binary Recursion\nLet us consider the problem of computing the kth Fibonacci number. Recall from\nSection2.2.3,thattheFibonaccinumbersarerecursively definedasfollows:\nF = 0\n0\nF = 1\n1\nF = F +F fori>1\ni i\u22121 i\u22122\nBy directly applying this definition, Algorithm BinaryFib, shown in Code Frag-\nment3.42,computesthesequence ofFibonacci numbersusingbinaryrecursion.\nAlgorithmBinaryFib(k):\nInput: Nonnegativeintegerk\nOutput: ThekthFibonaccinumberF\nk\nifk 1then\n\u2264\nreturnk\nelse\nreturnBinaryFib(k 1)+BinaryFib(k 2)\n\u2212 \u2212\nCodeFragment3.42: ComputingthekthFibonaccinumberusingbinaryrecursion.\nUnfortunately, in spite of the Fibonacci definition looking like a binary recur-\nsion, using this technique isinefficient inthis case. Infact, ittakes anexponential\nnumber of calls tocompute the kthFibonacci number in this way. Specifically, let\nn denote the number of calls performed in the execution of BinaryFib(k). Then,\nk\nwehavethefollowingvaluesforthen \u2019s:\nk\nn = 1\n0\nn = 1\n1\nn = n +n +1=1+1+1=3\n2 1 0\nn = n +n +1=3+1+1=5\n3 2 1\nn = n +n +1=5+3+1=9\n4 3 2\nn = n +n +1=9+5+1=15\n5 4 3\nn = n +n +1=15+9+1=25\n6 5 4\nn = n +n +1=25+15+1=41\n7 6 5\nn = n +n +1=41+25+1=67\n8 7 6\nIfwefollowthepatternforward,weseethatthenumberofcallsmorethandoubles\nforeachtwoconsecutive indices. Thatis,n ismorethantwicen ,n ismorethan\n4 2 5\ntwice n , n is more than twice n , and so on. Thus, n >2k/2, which means that\n3 6 4 k\nBinaryFib(k) makes a number of calls that are exponential in k. In other words,\nusingbinaryrecursion tocomputeFibonaccinumbersisveryinefficient.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 146 \u2014 #168\ni i\n146 Chapter3. Arrays,LinkedLists,andRecursion\nComputing Fibonacci Numbers via Linear Recursion\nThe main problem with the approach above, based on binary recursion, is that the\ncomputation of Fibonacci numbers is really a linearly recursive problem. It is not\na good candidate for using binary recursion. We simply got tempted into using\nbinary recursion because of theway thekth Fibonacci number, F , depends on the\nk\ntwopreviousvalues,F andF . ButwecancomputeF muchmoreefficiently\nk\u22121 k\u22122 k\nusinglinearrecursion.\nInordertouselinearrecursion, however,weneedtoslightlyredefinetheprob-\nlem. One way to accomplish this conversion is to define a recursive function that\ncomputes apairofconsecutive Fibonacci numbers (F ,F )using theconvention\nk k\u22121\nF =0. Then we can use the linearly recursive algorithm shown in Code Frag-\n\u22121\nment3.43.\nAlgorithmLinearFibonacci(k):\nInput: Anonnegative integerk\nOutput: PairofFibonaccinumbers(F ,F )\nk k\u22121\nifk 1then\n\u2264\nreturn(k,0)\nelse\n(i,j) LinearFibonacci(k 1)\n\u2190 \u2212\nreturn(i+ j,i)\nCodeFragment3.43: ComputingthekthFibonaccinumberusinglinearrecursion.\nThe algorithm given in Code Fragment 3.43 shows that using linear recursion\ntocomputeFibonaccinumbersismuchmoreefficientthanusingbinaryrecursion.\nSince each recursive call to LinearFibonacci decreases the argument k by 1, the\noriginal call LinearFibonacci(k) results in a series of k 1 additional calls. That\n\u2212\nis, computing the kth Fibonacci number via linear recursion requires k function\ncalls. Thisperformance issignificantly faster than the exponential timeneeded by\nthealgorithm based onbinary recursion, whichwasgiven inCodeFragment3.42.\nTherefore, when using binary recursion, we should first try to fully partition the\nproblem intwo(as wedid forsumming theelements of anarray) orweshould be\nsurethatoverlapping recursivecallsarereallynecessary.\nUsually,wecaneliminateoverlappingrecursivecallsbyusingmorememoryto\nkeeptrackofprevious values. Infact,thisapproach isacentralpartofatechnique\ncalled dynamic programming, which is related to recursion and is discussed in\nSection12.2.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 147 \u2014 #169\ni i\n3.5. Recursion 147\n3.5.3 Multiple Recursion\nGeneralizing from binary recursion, we use multiple recursion when a function\nmay make multiple recursive calls, with that number potentially being more than\ntwo. Oneof the most common applications of this type of recursion is used when\nwewanttoenumeratevariousconfigurationsinordertosolveacombinatorialpuz-\nzle. Forexample,thefollowingareallinstances ofsummationpuzzles.\npot + pan = bib\ndog+cat = pig\nboy+girl = baby\nTosolvesuchapuzzle, weneedtoassignauniquedigit(thatis,0,1,...,9)toeach\nletter inthe equation, inorder tomake the equation true. Typically, wesolve such\na puzzle by using our human observations of the particular puzzle we are trying\nto solve to eliminate configurations (that is, possible partial assignments of digits\ntoletters) until wecan workthough thefeasible configurations left, testing for the\ncorrectness ofeachone.\nIf the number of possible configurations is not too large, however, we can use\na computer to simply enumerate all the possibilities and test each one, without\nemployinganyhumanobservations. Inaddition,suchanalgorithmcanusemultiple\nrecursiontoworkthroughtheconfigurationsinasystematicway. Weshowpseudo-\ncodeforsuchanalgorithminCodeFragment3.44. Tokeepthedescriptiongeneral\nenough to be used with other puzzles, the algorithm enumerates and tests all k-\nlengthsequenceswithoutrepetitionsoftheelementsofagivensetU. Webuildthe\nsequences ofkelementsbythefollowingsteps:\n1. Recursively generating thesequences ofk 1elements\n\u2212\n2. Appending toeachsuchsequence anelementnotalreadycontained init.\nThroughout the execution of the algorithm, we use the setU to keep track of the\nelements not contained in the current sequence, so that an element e has not been\nusedyetifandonlyifeisinU.\nAnotherwaytolookatthealgorithm ofCodeFragment3.44isthatitenumer-\nates every possible size-k ordered subset of U, and tests each subset for being a\npossible solutiontoourpuzzle.\nFor summation puzzles, U = 0,1,2,3,4,5,6,7,8,9 and each position in the\n{ }\nsequence corresponds to a given letter. Forexample, the first position could stand\nforb,thesecond foro,thethirdfory,andsoon.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 148 \u2014 #170\ni i\n148 Chapter3. Arrays,LinkedLists,andRecursion\nAlgorithmPuzzleSolve(k,S,U):\nInput: Anintegerk,sequence S,andsetU\nOutput: An enumeration of all k-length extensions to S using elements in U\nwithoutrepetitions\nforeacheinU do\nRemoveefromU eisnowbeingused\n{ }\nAddetotheendofS\nifk=1then\nTestwhetherSisaconfiguration thatsolvesthepuzzle\nifSsolvesthepuzzlethen\nreturn\u201cSolution found: \u201d S\nelse\nPuzzleSolve(k 1,S,U)\n\u2212\nAddebacktoU eisnowunused\n{ }\nRemoveefromtheendofS\nCode Fragment 3.44: Solving a combinatorial puzzle by enumerating and testing\nallpossibleconfigurations.\nIn Figure 3.21, we show a recursion trace of a call to PuzzleSolve(3,S,U),\nwhere S is empty and U = a,b,c . During the execution, all the permutations\n{ }\nof the three characters are generated and tested. Note that the initial call makes\nthree recursive calls, each of which in turn makes two more. If we had executed\nPuzzleSolve(3,S,U) on a setU consisting of four elements, the initial call would\nhave made four recursive calls, each of which would have a trace looking like the\noneinFigure3.21.\nFigure 3.21: Recursion trace for an execution of PuzzleSolve(3,S,U), where S is\nemptyandU= a,b,c . Thisexecutiongeneratesandtestsallpermutationsofa,b,\n{ }\nandc. Weshowthepermutations generated directlybelowtheirrespective boxes.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 149 \u2014 #171\ni i\n3.6. Exercises 149\n3.6 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-3.1 ModifytheimplementationofclassScoressothatatmost maxEnt/2 of\n\u2308 \u2309\nthescorescancomefromanyonesingleplayer.\nR-3.2 Suppose that twoentries ofanarray Aareequal toeach other. After run-\nning the insertion-sort algorithm of Code Fragment 3.7, will they appear\nin the same relative order in the final sorted order or in reverse order?\nExplainyouranswer.\nR-3.3 Give a C++ code fragment that, given a n n matrix M of type float,\n\u00d7\nreplacesMwithitstranspose. Trytodothiswithouttheuseofatemporary\nmatrix.\nR-3.4 Describeawaytouserecursiontocomputethesumofalltheelementsin\nan n(two-dimensional) arrayofintegers.\n\u00d7\nR-3.5 Givearecursivedefinition ofasinglylinkedlist.\nR-3.6 Addafunctionsize()toourC++implementationofasinglylinklist. Can\nyoudesignthisfunction sothatitrunsinO(1)time?\nR-3.7 Give an algorithm for finding the penultimate (second to last) node in a\nsinglylinkedlistwherethelastelementisindicated byanullnextlink.\nR-3.8 Giveafullygenericimplementationofthedoublylinkedlistdatastructure\nofSection3.3.3byusingatemplatedclass.\nR-3.9 Give a more robust implementation of the doubly linked list data struc-\nture of Section 3.3.3, which throws an appropriate exception if an illegal\noperation isattempted.\nR-3.10 Describeanonrecursive function forfinding,bylinkhopping, themiddle\nnodeofadoubly linked listwithheader andtrailer sentinels. (Note: This\nfunctionmustonlyuselinkhopping; itcannotuseacounter.) Whatisthe\nrunning timeofthisfunction?\nR-3.11 Describe a recursive algorithm for finding the maximum element in an\narrayAofnelements. Whatisyourrunningtimeandspaceusage?\nR-3.12 DrawtherecursiontracefortheexecutionoffunctionReverseArray(A,0,4)\n(CodeFragment3.39)onarrayA= 4,3,6,2,5 .\n{ }\nR-3.13 DrawtherecursiontracefortheexecutionoffunctionPuzzleSolve(3,S,U)\n(CodeFragment3.44),whereSisemptyandU = a,b,c,d .\n{ }\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 150 \u2014 #172\ni i\n150 Chapter3. Arrays,LinkedLists,andRecursion\nR-3.14 Write a short C++ function that repeatedly selects and removes a ran-\ndom entry from an n-element array until the array holds no more entries.\nAssume that you have access to a function random(k), which returns a\nrandom integerintherangefrom0tok.\nR-3.15 Giveafullygenericimplementationofthecircularlylinkedlistdatastruc-\ntureofSection3.4.1byusingatemplatedclass.\nR-3.16 Giveamorerobustimplementation ofthecircularlylinkedlistdatastruc-\nture of Section 3.4.1, which throws an appropriate exception if an illegal\noperation isattempted.\nR-3.17 Write a short C++ function to count the number of nodes in a circularly\nlinkedlist.\nCreativity\nC-3.1 IntheTic-Tac-Toeexample, weused1forplayer Xand 1forplayer O.\n\u2212\nExplain howtomodify theprogram\u2019s counting tricktodecide thewinner\nif we had used 1 for player X and 4 for player O instead. Could we use\nanycombination ofvaluesaandbforthetwoplayers? Explain.\nC-3.2 Give C++ code for performing add(e) and remove(i) functions for game\nentriesstoredinanarraya,asinclassScoresinSection3.1.1,exceptthis\ntime, don\u2019t maintain the gameentries in order. Assumethat westillneed\nto keep n entries stored in indices 0 to n 1. Try to implement the add\n\u2212\nandremovefunctionswithoutusinganyloops,sothatthenumberofsteps\ntheyperform doesnotdependonn.\nC-3.3 LetAbeanarrayofsizen 2containing integers from1ton 1,inclu-\n\u2265 \u2212\nsive, with exactly one repeated. Describe a fast algorithm for finding the\nintegerinAthatisrepeated.\nC-3.4 LetBbeanarrayofsizen 6containing integers from1ton 5,inclu-\n\u2265 \u2212\nsive,withexactlyfiverepeated. Describeagoodalgorithmforfindingthe\nfiveintegersinBthatarerepeated.\nC-3.5 Supposeyouaredesigningamulti-playergamethathasn 1000players,\n\u2265\nnumbered 1 to n, interacting in an enchanted forest. The winner of this\ngame is the first player who can meet all the other players at least once\n(ties are allowed). Assuming that there is a function meet(i,j), which is\ncalledeachtimeaplayerimeetsaplayer j(withi= j),describeawayto\n6\nkeeptrackofthepairsofmeetingplayersandwhoisthewinner.\nC-3.6 Givearecursivealgorithmtocomputetheproductoftwopositiveintegers,\nmandn,usingonlyaddition andsubtraction.\nC-3.7 Describe afast recursive algorithm for reversing asingly linked list L,so\nthattheordering ofthenodesbecomesoppositeofwhatitwasbefore.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 151 \u2014 #173\ni i\n3.6. Exercises 151\nC-3.8 Describeagoodalgorithm forconcatenating twosinglylinkedlistsLand\nM,withheadersentinels, intoasinglelistL\u2032 thatcontainsallthenodesof\nLfollowedbyallthenodesofM.\nC-3.9 Give a fast algorithm for concatenating two doubly linked lists L and M,\nwithheaderandtrailersentinel nodes,intoasinglelistL\u2032.\nC-3.10 Describe indetail howtoswaptwonodes xand y(andnot just theircon-\ntents) in a singly linked list L given references only to x and y. Repeat\nthisexerciseforthecasewhenLisadoubly linked list. Whichalgorithm\ntakesmoretime?\nC-3.11 Describe in detail an algorithm for reversing a singly linked list L using\nonlyaconstantamountofadditional spaceandnotusinganyrecursion.\nC-3.12 IntheTowersofHanoipuzzle,wearegivenaplatformwiththreepegs,a,\nb,andc,stickingoutofit. Onpegaisastackofndisks,eachlargerthan\nthenext,sothatthesmallestisonthetopandthelargestisonthebottom.\nThepuzzle isto moveallthe disks from pegato pegc, moving onedisk\nat a time, so that we never place a larger disk on top of a smaller one.\nDescribearecursivealgorithmforsolvingtheTowersofHanoipuzzlefor\narbitrary n.\n(Hint: Consider first the subproblem of moving all but the nth disk from\npegatoanother pegusingthethirdas\u201ctemporary storage.\u201d)\nC-3.13 Describe a recursive function for converting astring of digits into the in-\ntegeritrepresents. Forexample,\"13531\"representstheinteger13,531.\nC-3.14 Describearecursivealgorithmthatcountsthenumberofnodesinasingly\nlinkedlist.\nC-3.15 Write arecursive C++ program that will output all the subsets of a set of\nnelements(withoutrepeating anysubsets).\nC-3.16 Write a short recursive C++ function that finds the minimum and maxi-\nmumvaluesinanarrayofintvalueswithoutusinganyloops.\nC-3.17 Describe a recursive algorithm that will check if an array A of integers\ncontains an integer A[i]that is the sum of two integers that appear earlier\ninA,thatis,suchthatA[i]=A[j]+A[k]for j,k<i.\nC-3.18 Write a short recursive C++ function that will rearrange an array of int\nvaluessothatalltheevenvaluesappearbeforealltheoddvalues.\nC-3.19 Write a short recursive C++ function that takes a character string s and\noutputs its reverse. So for example, the reverse of \"pots&pans\" would\nbe\"snap&stop\".\nC-3.20 Write a short recursive C++ function that determines if a string s is a\npalindrome, that is, it is equal to its reverse. For example, \"racecar\"\nand\"gohangasalamiimalasagnahog\"arepalindromes.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 152 \u2014 #174\ni i\n152 Chapter3. Arrays,LinkedLists,andRecursion\nC-3.21 Use recursion to write a C++ function for determining if a string s has\nmorevowelsthanconsonants.\nC-3.22 Suppose you are given two circularly linked lists, L and M, that is, two\nlistsofnodessuchthateachnodehasanonnullnextnode. Describeafast\nalgorithm for telling ifLand M arereally thesame list ofnodes but with\ndifferent (cursor)startingpoints.\nC-3.23 Given a circularly linked list L containing an even number of nodes, de-\nscribehowtosplitLintotwocircularly linkedlistsofhalfthesize.\nProjects\nP-3.1 WriteaC++function that takes twothree-dimensional integer arrays and\naddsthemcomponentwise.\nP-3.2 WriteaC++programforamatrixclassthatcanaddandmultiplyarbitrary\ntwo-dimensional arrays of integers. Do this by overloading the addition\n(\u201c+\u201d)andmultiplication (\u201c*\u201d)operators.\nP-3.3 Writeaclassthat maintains thetop 10scores foragameapplication, im-\nplementingtheaddandremovefunctionsofSection3.1.1,butuseasingly\nlinkedlistinsteadofanarray.\nP-3.4 Performtheprevious project butuseadoubly linked list. Moreover, your\nimplementation of remove(i) should make the fewest number of pointer\nhopstogettothegameentryatindexi.\nP-3.5 Perform the previous project but use a linked list that is both circularly\nlinkedanddoublylinked.\nP-3.6 Writeaprogram forsolving summationpuzzlesbyenumerating andtest-\ning all possible configurations. Using your program, solve the three puz-\nzlesgiveninSection3.5.3.\nP-3.7 Writeaprogram that canperform encryption and decryption using anar-\nbitrary substitution cipher. In this case, the encryption array is a random\nshuffling of the letters in the alphabet. Your program should generate\na random encryption array, its corresponding decryption array, and use\nthesetoencodeanddecodeamessage.\nP-3.8 Write a program that can solve instances of the Towerof Hanoi problem\n(fromExerciseC-3.12).\nChapter Notes\nThefundamentaldatastructuresofarraysandlinkedlists, aswellasrecursion,discussed\ninthischapter,belongtothefolkloreofcomputerscience.Theywerefirstchronicledinthe\ncomputerscienceliteraturebyKnuthinhisseminalbookonFundamentalAlgorithms[59].\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 153 \u2014 #175\ni i\nChapter\n4\nAnalysis Tools\nContents\n4.1 The Seven Functions Used in This Book . . . . . . . 154\n4.1.1 The Constant Function . . . . . . . . . . . . . . . . 154\n4.1.2 The Logarithm Function . . . . . . . . . . . . . . . 154\n4.1.3 The Linear Function . . . . . . . . . . . . . . . . . . 156\n4.1.4 The N-Log-N Function . . . . . . . . . . . . . . . . 156\n4.1.5 The Quadratic Function. . . . . . . . . . . . . . . . 156\n4.1.6 The Cubic Function and Other Polynomials . . . . . 158\n4.1.7 The Exponential Function. . . . . . . . . . . . . . . 159\n4.1.8 Comparing Growth Rates . . . . . . . . . . . . . . . 161\n4.2 Analysis of Algorithms . . . . . . . . . . . . . . . . . . 162\n4.2.1 Experimental Studies . . . . . . . . . . . . . . . . . 163\n4.2.2 Primitive Operations . . . . . . . . . . . . . . . . . 164\n4.2.3 Asymptotic Notation . . . . . . . . . . . . . . . . . 166\n4.2.4 Asymptotic Analysis . . . . . . . . . . . . . . . . . . 170\n4.2.5 Using the Big-Oh Notation . . . . . . . . . . . . . . 172\n4.2.6 A Recursive Algorithm for Computing Powers . . . . 176\n4.2.7 Some More Examples of Algorithm Analysis . . . . . 177\n4.3 Simple Justification Techniques . . . . . . . . . . . . 181\n4.3.1 By Example . . . . . . . . . . . . . . . . . . . . . . 181\n4.3.2 The \u201cContra\u201d Attack . . . . . . . . . . . . . . . . . 181\n4.3.3 Induction and Loop Invariants . . . . . . . . . . . . 182\n4.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 185\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 154 \u2014 #176\ni i\n154 Chapter4. AnalysisTools\n4.1 The Seven Functions Used in This Book\nIn this section, we briefly discuss the seven most important functions used in the\nanalysis of algorithms. We use only these seven simple functions for almost all\nthe analysis we do in this book. In fact, sections that use a function other than\none of these seven are marked with a star (\u22c6) to indicate that they are optional. In\naddition tothese sevenfundamental functions, Appendix Acontains alistofother\nuseful mathematical facts that apply in the context ofdata structure and algorithm\nanalysis.\n4.1.1 The Constant Function\nThesimplestfunctionwecanthinkofistheconstantfunction. Thisisthefunction,\nf(n)=c,\nfor somefixedconstant c, such as c=5, c=27, orc=210. Thatis, forany argu-\nment n, the constant function f(n) assigns the value c. In other words, it doesn\u2019t\nmatterwhatthevalueofnis, f(n)isalwaysbeequaltotheconstant valuec.\nSince we are most interested in integer functions, the most fundamental con-\nstant function is g(n)=1, and this is the typical constant function we use in this\nbook. Notethatanyotherconstant function, f(n)=c,canbewrittenasaconstant\nctimesg(n). Thatis, f(n)=cg(n)inthiscase.\nAssimpleasitis,theconstant function isuseful inalgorithm analysis because\nitcharacterizes the number of steps needed to doabasic operation on acomputer,\nlike adding two numbers, assigning a value to some variable, or comparing two\nnumbers.\n4.1.2 The Logarithm Function\nOne of the interesting and sometimes even surprising aspects of the analysis of\ndatastructuresandalgorithmsistheubiquitouspresenceofthelogarithmfunction,\nf(n)=log n,forsomeconstant b>1. Thisfunction isdefinedasfollows:\nb\nx=log n ifandonlyif bx =n.\nb\nBydefinition, log 1=0. Thevaluebisknownasthebaseofthelogarithm.\nb\nComputing the logarithm function exactly for any integer n involves the use\nof calculus, but we can use an approximation that is good enough for our pur-\nposes without calculus. In particular, we can easily compute the smallest integer\ngreater than or equal to log n, since this number is equal to the number of times\na\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 155 \u2014 #177\ni i\n4.1. TheSevenFunctionsUsedinThisBook 155\nwe can divide n by a until we get a number less than or equal to 1. For exam-\nple, this evaluation of log 27 is 3, since 27/3/3/3 =1. Likewise, this evaluation\n3\nof log 64 is 3, since 64/4/4/4 =1, and this approximation to log 12 is 4, since\n4 2\n12/2/2/2/2 =0.75 1. This base-2 approximation arises in algorithm analysis,\n\u2264\nsince a common operation in many algorithms is to repeatedly divide an input in\nhalf.\nIndeed,sincecomputersstoreintegersinbinary,themostcommonbaseforthe\nlogarithm function in computer science is 2. In fact, this base is so common that\nwetypically leaveitoffwhenitis2. Thatis,forus,\nlogn=log n.\n2\nWe note that most handheld calculators have a button marked LOG, but this is\ntypically forcalculating thelogarithm base10,notbase2.\nTherearesomeimportantrulesforlogarithms, similartotheexponent rules.\nProposition 4.1 (Logarithm Rules): Givenrealnumbersa> 0,b >1,c> 0\nandd>1,wehave:\n1. log ac=log a+log c\nb b b\n2. log a/c=log a log c\nb b \u2212 b\n3. log ac=clog a\nb b\n4. log a=(log a)/log b\nb d d\n5. blog d a=alog d b\nAlso, as a notational shorthand, we use logcn to denote the function (logn)c.\nRatherthanshowhowwecouldderiveeachoftheidentitiesabovewhichallfollow\nfrom the definition of logarithms and exponents, let us illustrate these identities\nwithafewexamplesinstead.\nExample 4.2: Wedemonstratebelowsomeinterestingapplicationsoftheloga-\nrithmrulesfromProposition4.1(usingtheusualconventionthatthebaseofa\nlogarithmis2ifitisomitted).\nlog(2n)=log2+logn=1+logn,byrule1\n\u2022\nlog(n/2)=logn log2=logn 1,byrule2\n\u2022 \u2212 \u2212\nlogn3=3logn,byrule3\n\u2022\nlog2n=nlog2=n 1=n,byrule3\n\u2022 \u00b7\nlog n=(logn)/log4=(logn)/2,byrule4\n4\n\u2022\n2logn=nlog2=n1=n,byrule5\n\u2022\nAsapracticalmatter,wenotethatrule4givesusawaytocomputethebase-2\nlogarithmonacalculatorthathasabase-10logarithmbutton,LOG,for\nlog n=LOGn/LOG2.\n2\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 156 \u2014 #178\ni i\n156 Chapter4. AnalysisTools\n4.1.3 The Linear Function\nAnothersimpleyetimportantfunction isthelinearfunction,\nf(n)=n.\nThatis,givenaninputvaluen,thelinearfunction f assigns thevaluenitself.\nThisfunctionarisesinalgorithmanalysisanytimewehavetodoasinglebasic\noperation for each of n elements. For example, comparing a number x to each\nelement of an array of size n requires n comparisons. The linear function also\nrepresents the best running time we can hope to achieve for any algorithm that\nprocesses a collection of n objects that are not already in the computer\u2019s memory,\nsincereadinginthenobjects itselfrequires noperations.\n4.1.4 The N-Log-N Function\nThenextfunction wediscuss inthissection isthen-log-nfunction,\nf(n)=nlogn.\nThat is, the function that assigns to an input n the value of n times the logarithm\nbase 2 of n. This function grows a little faster than the linear function and a lot\nslower than the quadratic function. Thus, as we show on several occasions, if we\ncan improve the running timeof solving some problem from quadratic to n-log-n,\nwehaveanalgorithm thatrunsmuchfasteringeneral.\n4.1.5 The Quadratic Function\nAnother function that appears quite often in algorithm analysis is the quadratic\nfunction,\nf(n)=n2.\nThat is, given an input value n, the function f assigns the product of n with itself\n(inotherwords,\u201cnsquared\u201d).\nThe main reason why the quadratic function appears in the analysis of algo-\nrithms is that there are many algorithms that have nested loops, where the inner\nloop performs a linear number of operations and the outer loop is performed a\nlinear number of times. Thus, in such cases, the algorithm performs n n = n2\n\u00b7\noperations.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 157 \u2014 #179\ni i\n4.1. TheSevenFunctionsUsedinThisBook 157\nNested Loops and the Quadratic Function\nThequadratic function canalso arise inthe context ofnested loops where the first\niterationofaloopusesoneoperation,thesecondusestwooperations,thethirduses\nthreeoperations, andsoon. Thatis,thenumberofoperations is\n1+2+3+ +(n 2)+(n 1)+n.\n\u00b7\u00b7\u00b7 \u2212 \u2212\nIn other words, this is the total number of operations that are performed by the\nnestedloopifthenumberofoperationsperformedinsidetheloopincreasesbyone\nwitheachiterationoftheouterloop. Thisquantity alsohasaninteresting history.\nIn1787,aGermanschoolteacher decidedtokeephis9-and10-year-old pupils\noccupied by adding up the integers from 1 to 100. But almost immediately one\nof the children claimed to have the answer! The teacher was suspicious, for the\nstudenthadonlytheansweronhisslate. Buttheanswerwascorrect\u20145,050\u2014and\nthe student, Carl Gauss, grew up to be one of the greatest mathematicians of his\ntime. Itiswidelysuspected thatyoungGaussusedthefollowingidentity.\nProposition 4.3: Foranyintegern 1,wehave:\n\u2265\nn(n+1)\n1+2+3+ +(n 2)+(n 1)+n= .\n\u00b7\u00b7\u00b7 \u2212 \u2212 2\nWegivetwo\u201cvisual\u201djustifications ofProposition 4.3inFigure4.1.\n(a) (b)\nFigure4.1: Visual justifications ofProposition 4.3. Both illustrations visualize the\nidentity in terms of the total area covered by n unit-width rectangles with heights\n1,2,...,n. In(a),therectanglesareshowntocoverabigtriangleofarean2/2(base\nn and height n) plus n small triangles of area 1/2 each (base 1 and height 1). In\n(b), which applies only when n is even, the rectangles are shown to cover a big\nrectangle ofbasen/2andheightn+1.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 158 \u2014 #180\ni i\n158 Chapter4. AnalysisTools\nThelessontobelearnedfromProposition4.3isthatifweperformanalgorithm\nwith nested loops such that the operations in the inner loop increase by one each\ntime,thenthetotalnumberofoperations isquadraticinthenumberoftimes,n,we\nperformtheouterloop. Inparticular,thenumberofoperationsisn2/2+n/2,inthis\ncase,whichisalittlemorethanaconstantfactor(1/2)timesthequadraticfunction\nn2. Inother words, suchan algorithm isonly slightly better than analgorithm that\nusesnoperations eachtimetheinnerloopisperformed. Thisobservation mightat\nfirstseemnonintuitive, butitisnevertheless trueasshowninFigure4.1.\n4.1.6 The Cubic Function and Other Polynomials\nContinuing our discussion of functions that are powers of the input, we consider\nthecubicfunction,\nf(n)=n3,\nwhichassignstoaninputvaluentheproductofnwithitselfthreetimes. Thisfunc-\ntion appears less frequently in the context of algorithm analysis than the constant,\nlinear, andquadratic functions previously mentioned, but itdoes appear fromtime\ntotime.\nPolynomials\nInterestingly, thefunctions wehave listed sofarcan beviewedasallbeing partof\nalargerclassoffunctions, thepolynomials.\nApolynomialfunction isafunctionoftheform,\nf(n)=a +a n+a n2+a n3+ +a nd,\n0 1 2 3 d\n\u00b7\u00b7\u00b7\nwhere a ,a ,...,a are constants, called the coefficients of the polynomial, and\n0 1 d\na =0. Integer d, which indicates the highest power in the polynomial, is called\nd\n6\nthedegreeofthepolynomial.\nForexample,thefollowingfunctions areallpolynomials:\nf(n)=2+5n+n2\n\u2022\nf(n)=1+n3\n\u2022\nf(n)=1\n\u2022\nf(n)=n\n\u2022\nf(n)=n2\n\u2022\nTherefore,wecouldarguethatthisbookpresentsjustfourimportantfunctionsused\ninalgorithmanalysis,butwesticktosayingthatthereareseven,sincetheconstant,\nlinear, and quadratic functions are too important to be lumped in with other poly-\nnomials. Running times that are polynomials with degree, d, are generally better\nthanpolynomial running timesoflargerdegree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 159 \u2014 #181\ni i\n4.1. TheSevenFunctionsUsedinThisBook 159\nSummations\nAnotation thatappearsagainandagainintheanalysis ofdatastructures andalgo-\nrithmsisthesummation,whichisdefinedas\nb\n\u2211\nf(i)= f(a)+ f(a+1)+ f(a+2)+ + f(b),\n\u00b7\u00b7\u00b7\ni=a\nwhereaandbareintegersanda b. Summationsariseindatastructure andalgo-\n\u2264\nrithmanalysisbecausetherunningtimesofloopsnaturallygiverisetosummations.\nUsingasummation, wecanrewritetheformulaofProposition 4.3as\n\u2211 n n(n+1)\ni= .\n2\ni=1\nLikewise,wecanwriteapolynomial f(n)ofdegreedwithcoefficientsa ,...,a as\n0 d\nd\nf(n)= \u2211 ani.\ni\ni=0\nThus, the summation notation gives us a shorthand way of expressing sums of in-\ncreasing termsthathavearegularstructure.\n4.1.7 The Exponential Function\nAnotherfunctionusedintheanalysis ofalgorithms istheexponentialfunction,\nf(n)=bn,\nwherebisapositiveconstant, calledthebase,andtheargumentnistheexponent.\nThatis,function f(n)assigns totheinputargument nthevalueobtained bymulti-\nplyingthebasebbyitselfntimes. Inalgorithmanalysis,themostcommonbasefor\ntheexponential functionisb=2. Forinstance,ifwehavealoopthatstartsbyper-\nforming one operation and then doubles the number of operations performed with\neach iteration, then the number of operations performed in the nth iteration is 2n.\nInaddition, aninteger wordcontaining nbits can represent allthe nonnegative in-\ntegers less than 2n. Thus, the exponential function with base 2 is quite common.\nTheexponential functionisalsoreferredtoasexponentfunction.\nWe sometimes have other exponents besides n, however; hence, it is useful\nfor us to know a few handy rules for working with exponents. In particular, the\nfollowingexponentrulesarequitehelpful.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 160 \u2014 #182\ni i\n160 Chapter4. AnalysisTools\nProposition 4.4 (Exponent Rules): Givenpositiveintegersa,b,andc,wehave:\n1. (ba)c=bac\n2. babc=ba+c\n3. ba/bc =ba\u2212c\nForexample,wehavethefollowing:\n256=162=(24)2=24\u00b72=28=256(Exponent Rule1)\n\u2022\n243=35=32+3=3233=9 27=243(ExponentRule2)\n\u2022 \u00b7\n16=1024/64=210/26 =210\u22126=24=16(Exponent Rule3)\n\u2022\nWe can extend the exponential function to exponents that are fractions or real\nnumbers and to negative exponents, as follows. Given a positive integer k, wede-\nfine b1/k to be kth root of b, that is, the number r such that rk =b. For example,\n251/2 =5, since 52 =25. Likewise, 271/3 =3 and 161/4 =2. This approach al-\nlows us to define any power whose exponent can be expressed as a fraction, since\nba/c =(ba)1/c, by Exponent Rule 1. For example, 93/2 =(93)1/2 =7291/2 =27.\nThus,ba/c isreallyjustthecthrootoftheintegralexponentba.\nWe can further extend the exponential function to define bx for any real num-\nber x, bycomputing aseries ofnumbers ofthe form ba/c for fractions a/c that get\nprogressively closer and closer tox. Anyreal number xcan beapproximated arbi-\ntrarily close by a fraction a/c; hence, we can use the fraction a/c as the exponent\nof b to get arbitrarily close to bx. So, for example, the number 2 \u03c0 is well defined.\nFinally, givenanegativeexponent d,wedefinebd =1/b\u2212d,whichcorresponds to\napplying ExponentRule3witha=0andc= d.\n\u2212\nGeometric Sums\nSuppose we have a loop where each iteration takes a multiplicative factor longer\nthantheprevious one. Thisloopcanbeanalyzed usingthefollowingproposition.\nProposition 4.5: Foranyintegern 0andanyrealnumberasuchthata>0and\n\u2265\na=1,considerthesummation\n6\nn\n\u2211 ai=1+a+a2+ +an\n\u00b7\u00b7\u00b7\ni=0\n(rememberingthata0=1ifa>0).Thissummationisequalto\nan+1 1\n\u2212 .\na 1\n\u2212\nSummationsasshowninProposition4.5arecalledgeometricsummations,be-\ncauseeachtermisgeometricallylargerthanthepreviousoneifa>1. Forexample,\neveryoneworkingincomputingshouldknowthat\n1+2+4+8+ +2n\u22121=2n 1,\n\u00b7\u00b7\u00b7 \u2212\nsince this is the largest integer that can be represented in binary notation using n\nbits.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 161 \u2014 #183\ni i\n4.1. TheSevenFunctionsUsedinThisBook 161\n4.1.8 Comparing Growth Rates\nTosumup,Table4.1showseachofthesevencommonfunctionsusedinalgorithm\nanalysis inorder.\nconstant logarithm linear n-log-n quadratic cubic exponential\n1 logn n nlogn n2 n3 an\nTable4.1: Classesoffunctions. Hereweassumethata>1isaconstant.\nIdeally, we would like data structure operations to run in times proportional\nto the constant or logarithm function, and we would like our algorithms to run in\nlinear or n-log-n time. Algorithms with quadratic or cubic running times are less\npractical, but algorithms with exponential running times are infeasible for all but\nthesmallestsizedinputs. Plotsofthesevenfunctions areshowninFigure4.2.\n1.E+44\n1.E+40 Exponential\n1.E+36\nCubic\n1.E+32\nQuadratic\n1.E+28\n1.E+24 N-Log-N\n1.E+20 Linear\n1.E+16 Logarithmic\n1.E+12 Constant\n1.E+08\n1.E+04\n1.E+00\n1.E+00 1.E+01 1.E+02 1.E+03 1.E+04 1.E+05 1.E+06 1.E+07 1.E+08 1.E+09 1.E+10 1.E+11 1.E+12 1.E+13 1.E+14 1.E+15\nFigure 4.2: Growth rates for the seven fundamental functions used in algorithm\nanalysis. Weusebasea=2fortheexponential function. Thefunctionsareplotted\nin a log-log chart, to compare the growth rates primarily as slopes. Even so, the\nexponential function grows too fast to display all itsvalues on the chart. Also, we\nusethescientificnotationfornumbers, whereaE+bdenotesa10b.\nThe Ceiling and Floor Functions\nOne additional comment concerning the functions above is in order. The value\nof a logarithm is typically not an integer, yet the running time of an algorithm is\nusuallyexpressedbymeansofanintegerquantity,suchasthenumberofoperations\nperformed. Thus, the analysis of an algorithm may sometimes involve the use of\nthefloorfunctionandceilingfunction,whicharedefinedrespectively asfollows:\nx =thelargestintegerlessthanorequaltox\n\u2022 \u230a \u230b\nx =thesmallestintegergreaterthanorequaltox\n\u2022 \u2308 \u2309\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 162 \u2014 #184\ni i\n162 Chapter4. AnalysisTools\n4.2 Analysis of Algorithms\nInaclassicstory,thefamousmathematicianArchimedeswasaskedtodetermineif\nagoldencrowncommissionedbythekingwasindeedpuregold,andnotpartsilver,\nasaninformanthadclaimed. Archimedesdiscoveredawaytoperformthisanalysis\nwhile stepping into a (Greek) bath. He noted that water spilled out of the bath in\nproportion to the amount of him that went in. Realizing the implications of this\nfact, he immediately got out of the bath and ran naked through the city shouting,\n\u201cEureka, eureka!,\u201d for he had discovered an analysis tool (displacement), which,\nwhen combined witha simple scale, could determine if the king\u2019s new crown was\ngoodornot. Thatis,Archimedescoulddipthecrownandanequal-weight amount\nof gold into a bowl of water to see if they both displaced the same amount. This\ndiscovery was unfortunate for the goldsmith, however, for when Archimedes did\nhis analysis, the crown displaced more water than an equal-weight lump of pure\ngold,indicating thatthecrownwasnot,infact,puregold.\nInthisbook,weareinterestedinthedesignof\u201cgood\u201ddatastructuresandalgo-\nrithms. Simplyput, adatastructureisasystematic wayoforganizing andaccess-\ningdata,andanalgorithmisastep-by-step procedureforperformingsometaskin\nafiniteamountoftime. Theseconcepts arecentral tocomputing, but tobeableto\nclassifysomedatastructuresandalgorithmsas\u201cgood,\u201dwemusthavepreciseways\nofanalyzing them.\nThe primary analysis tool weuse in this book involves characterizing the run-\nningtimesofalgorithmsanddatastructureoperations, withspaceusagealsobeing\nof interest. Running time is a natural measure of \u201cgoodness,\u201d since time is a pre-\nciousresource\u2014computer solutions shouldrunasfastaspossible.\nIngeneral, therunningtimeofanalgorithm ordatastructure methodincreases\nwiththe input size, although itmayalso vary for different inputs ofthe samesize.\nAlso,therunning timeisaffected bythehardwareenvironment (asreflectedinthe\nprocessor,clockrate,memory,disk,etc.) andsoftwareenvironment(asreflectedin\nthe operating system, programming language, compiler, interpreter, etc.) in which\nthe algorithm is implemented, compiled, and executed. All other factors being\nequal, the running time of the same algorithm on the same input data is smaller if\nthecomputerhas,say,amuchfasterprocessororiftheimplementationisdoneina\nprogram compiled intonative machine code instead ofaninterpreted implementa-\ntion run onavirtual machine. Nevertheless, inspite ofthe possible variations that\ncomefromdifferent environmental factors, wewouldliketofocusontherelation-\nshipbetweentherunningtimeofanalgorithm andthesizeofitsinput.\nWeareinterestedincharacterizing analgorithm\u2019srunningtimeasafunctionof\ntheinputsize. Butwhatistheproperwayofmeasuring it?\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 163 \u2014 #185\ni i\n4.2. AnalysisofAlgorithms 163\n4.2.1 Experimental Studies\nIfanalgorithm hasbeenimplemented, wecanstudy itsrunning timebyexecuting\nitonvarioustestinputsandrecording theactualtimespentineachexecution. For-\ntunately, such measurements can be taken in an accurate manner by using system\ncallsthatarebuiltintothelanguageoroperatingsystem(forexample,byusingthe\nclock()function orcalling therun-time environment withprofiling enabled). Such\ntestsassign aspecificrunning timetoaspecificinput size,butweareinterested in\ndeterminingthegeneraldependence ofrunningtimeonthesizeoftheinput. Inor-\ndertodeterminethisdependence, weshouldperformseveralexperimentsonmany\ndifferent test inputs of various sizes. Then we can visualize the results of such\nexperiments by plotting the performance of each run of the algorithm as a point\nwith x-coordinate equal to the input size, n, and y-coordinate equal to the running\ntime, t. (See Figure 4.3.) From this visualization and the data that supports it, we\ncanperform astatistical analysis thatseekstofitthebestfunction oftheinput size\nto the experimental data. To be meaningful, this analysis requires that we choose\ngood sample inputs and test enough of them to be able to make sound statistical\nclaimsaboutthealgorithm\u2019s runningtime.\nt (ms)\n60\n50\n40\n30\n20\n10\nn\n0 50 100\nFigure4.3: Results of an experimental study on the running time of an algorithm.\nA dot with coordinates (n,t) indicates that on an input of size n, the running time\nofthealgorithm ist milliseconds (ms).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 164 \u2014 #186\ni i\n164 Chapter4. AnalysisTools\nWhile experimental studies of running times are useful, they have three major\nlimitations:\nExperiments can be done only on a limited set of test inputs; hence, they\n\u2022\nleave out the running times of inputs not included in the experiment (and\ntheseinputsmaybeimportant).\nWe have difficulty comparing the experimental running times of two algo-\n\u2022\nrithms unless the experiments were performed in the same hardware and\nsoftwareenvironments.\nWe have to fully implement and execute an algorithm in order to study its\n\u2022\nrunning timeexperimentally.\nThislastrequirementisobvious,butitisprobablythemosttimeconsumingaspect\nofperforming an experimental analysis ofan algorithm. Theother limitations im-\nposeserioushurdlestoo,ofcourse. Thus,wewouldideallyliketohaveananalysis\ntoolthatallowsustoavoidperforming experiments.\nIn the rest of this chapter, we develop a general way of analyzing the running\ntimesofalgorithms that:\nTakesintoaccount allpossible inputs.\n\u2022\nAllows us to evaluate the relative efficiency of any two algorithms in a way\n\u2022\nthatisindependent fromthehardwareandsoftwareenvironment.\nCanbeperformedbystudyingahigh-leveldescriptionofthealgorithmwith-\n\u2022\noutactually implementing itorrunning experiments onit.\nThis methodology aims at associating, with each algorithm, a function f(n) that\ncharacterizes the running time of the algorithm as a function of the input size n.\nTypical functions that are encountered include the seven functions mentioned ear-\nlierinthischapter.\n4.2.2 Primitive Operations\nAs noted above, experimental analysis is valuable, but it has its limitations. If\nwe wish to analyze a particular algorithm without performing experiments on its\nrunning time, we can perform an analysis directly on the high-level pseudo-code\ninstead. Wedefineasetofprimitiveoperations suchasthefollowing:\nAssigning avaluetoavariable\n\u2022\nCallingafunction\n\u2022\nPerforminganarithmeticoperation (forexample,addingtwonumbers)\n\u2022\nComparingtwonumbers\n\u2022\nIndexing intoanarray\n\u2022\nFollowinganobjectreference\n\u2022\nReturning fromafunction\n\u2022\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 165 \u2014 #187\ni i\n4.2. AnalysisofAlgorithms 165\nCounting Primitive Operations\nSpecifically,aprimitiveoperationcorrespondstoalow-levelinstructionwithanex-\necution time that is constant. Instead of trying to determine the specific execution\ntimeof each primitive operation, wesimply counthow manyprimitive operations\nare executed, and use this number t as a measure of the running time of the algo-\nrithm.\nThisoperationcountcorrelatestoanactualrunningtimeinaspecificcomputer,\nsinceeachprimitiveoperationcorrespondstoaconstant-timeinstruction, andthere\nare only a fixed number of primitive operations. The implicit assumption in this\napproachisthattherunningtimesofdifferentprimitiveoperationsisfairlysimilar.\nThus, the number, t, ofprimitive operations an algorithm performs is proportional\ntotheactualrunning timeofthatalgorithm.\nAnalgorithm mayrunfasteronsomeinputsthanitdoesonothers ofthesame\nsize. Thus,wemaywishtoexpresstherunningtimeofanalgorithmasthefunction\noftheinputsizeobtainedbytakingtheaverageoverallpossibleinputsofthesame\nsize. Unfortunately, such an average-case analysis is typically quite challenging.\nItrequiresustodefineaprobability distribution onthesetofinputs,whichisoften\nadifficulttask. Figure4.4schematically showshow,depending ontheinputdistri-\nbution, the running time of an algorithm can be anywhere between the worst-case\ntime and the best-case time. For example, what if inputs are really only of types\n\u201cA\u201dor\u201cD\u201d?\nInput Instance\ni i\ni i\nemiT\ngninnuR\n5 ms worst-case time\n}\n4 ms\naverage-case time?\n3 ms\nbest-case time\n2 ms\n1 ms\nA B C D E F G\nFigure4.4: Thedifference between best-case andworst-case time. Eachbarrepre-\nsentstherunning timeofsomealgorithm onadifferent possible input.\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 166 \u2014 #188\ni i\n166 Chapter4. AnalysisTools\nFocusing on the Worst Case\nAnaverage-caseanalysisusuallyrequiresthatwecalculateexpectedrunningtimes\nbasedonagiveninputdistribution,whichusuallyinvolvessophisticatedprobability\ntheory. Therefore, fortheremainder ofthisbook, unless wespecify otherwise, we\ncharacterize running times in terms of the worst case, as a function of the input\nsize,n,ofthealgorithm.\nWorst-case analysis is much easier than average-case analysis, as it requires\nonly the ability to identify the worst-case input, which is often simple. Also, this\napproach typically leads to better algorithms. Making the standard of success for\nanalgorithmtoperformwellintheworstcasenecessarilyrequiresthatitdoeswell\non every input. That is, designing for the worst case leads to stronger algorithmic\n\u201cmuscles,\u201dmuchlikeatrackstarwhoalwayspractices byrunning upanincline.\n4.2.3 Asymptotic Notation\nIn general, each basic step in a pseudo-code description or a high-level language\nimplementation corresponds toasmall number ofprimitive operations (except for\nfunction calls, ofcourse). Thus, wecanperform asimple analysis ofanalgorithm\nwritten inpseudo-code that estimates thenumber ofprimitive operations executed\nuptoaconstantfactor,bypseudo-codesteps(butwemustbecareful,sinceasingle\nlineofpseudo-code maydenoteanumberofstepsinsomecases).\nIn algorithm analysis, we focus on the growth rate of the running time as a\nfunctionoftheinputsizen,takinga\u201cbig-picture\u201d approach. Itisoftenenoughjust\nto know that the running time of an algorithm such as arrayMax, shown in Code\nFragment4.1,growsproportionally ton,withitstruerunningtimebeingntimesa\nconstant factorthatdependsonthespecificcomputer.\nWe analyze algorithms using a mathematical notation for functions that disre-\ngardsconstantfactors. Namely,wecharacterizetherunningtimesofalgorithmsby\nusing functions that map the size of the input, n, to values that correspond to the\nmainfactor thatdetermines thegrowthrateintermsofn. Thisapproach allowsus\ntofocusonthe\u201cbig-picture\u201d aspectsofanalgorithm\u2019s running time.\nAlgorithmarrayMax(A,n):\nInput: AnarrayAstoringn 1integers.\n\u2265\nOutput: ThemaximumelementinA.\ncurrMax A[0]\n\u2190\nfori 1ton 1do\n\u2190 \u2212\nifcurrMax<A[i]then\ncurrMax A[i]\n\u2190\nreturncurrMax\nCodeFragment4.1: Algorithm arrayMax.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 167 \u2014 #189\ni i\n4.2. AnalysisofAlgorithms 167\nThe \u201cBig-Oh\u201d Notation\nLet f(n)andg(n)befunctions mapping nonnegative integers torealnumbers. We\nsay that f(n) is O(g(n)) if there is a real constant c>0 and an integer constant\nn 1suchthat\n0\n\u2265\nf(n) cg(n), for n n .\n0\n\u2264 \u2265\nThis definition is often referred to as the \u201cbig-Oh\u201d notation, for it is sometimes\npronounced as \u201cf(n) is big-Oh of g(n).\u201d Alternatively, we can also say \u201cf(n) is\norderofg(n).\u201d (Thisdefinitionisillustrated inFigure4.5.)\nInput Size\ni i\ni i\nemiT\ngninnuR\ncg(n)\nf(n)\nn\n0\nFigure 4.5: The \u201cbig-Oh\u201d notation. The function f(n) is O(g(n)), since f(n)\n\u2264\nc g(n)whenn n .\n0\n\u00b7 \u2265\nExample 4.6: Thefunction8n 2isO(n).\n\u2212\nJustification: Bythebig-Ohdefinition,weneedtofindarealconstantc>0and\nanintegerconstantn 1suchthat8n 2 cnforeveryintegern n . Itiseasy\n0 0\n\u2265 \u2212 \u2264 \u2265\nto see that a possible choice is c=8 and n =1. Indeed, this is one of infinitely\n0\nmany choices available because any real number greater than or equal to 8 works\nforc,andanyintegergreaterthanorequalto1worksforn .\n0\nThebig-Ohnotation allowsustosaythatafunction f(n)is\u201clessthanorequal\nto\u201d another function g(n) up to a constant factor and in the asymptotic sense as n\ngrowstowardinfinity. Thisabilitycomesfromthefactthatthedefinitionuses\u201c \u201d\n\u2264\ntocompare f(n)toag(n)timesaconstant,c,fortheasymptoticcaseswhenn n .\n0\n\u2265\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 168 \u2014 #190\ni i\n168 Chapter4. AnalysisTools\nCharacterizing Running Times using the Big-Oh Notation\nThebig-Ohnotationisusedwidelytocharacterizerunningtimesandspacebounds\nintermsofsomeparametern,whichvariesfromproblemtoproblem,butisalways\ndefined as a chosen measure of the \u201csize\u201d of the problem. For example, if we are\ninterested infinding thelargest element inanarray ofintegers, asinthearrayMax\nalgorithm, we should let n denote the number of elements of the array. Using the\nbig-Oh notation, we can write the following mathematically precise statement on\ntherunningtimeofalgorithm arrayMaxforanycomputer.\nProposition 4.7: TheAlgorithmarrayMax,forcomputingthemaximumelement\ninanarrayofnintegers,runsinO(n)time.\nJustification: Thenumberofprimitiveoperations executedbyalgorithm array-\nMax in each iteration is a constant. Hence, since each primitive operation runs in\nconstant time,wecansaythattherunning timeofalgorithm arrayMaxonaninput\nof size n is at most a constant times n, that is, we may conclude that the running\ntimeofalgorithm arrayMaxisO(n).\nSome Properties of the Big-Oh Notation\nThebig-Ohnotationallowsustoignoreconstantfactorsandlowerordertermsand\nfocusonthemaincomponents ofafunction thataffectitsgrowth.\nExample 4.8: 5n4+3n3+2n2+4n+1isO(n4).\nJustification: Notethat5n4+3n3+2n2+4n+1 (5+3+2+4+1)n4=cn4,\n\u2264\nforc=15,whenn n =1.\n0\n\u2265\nInfact,wecancharacterize thegrowthrateofanypolynomial function.\nProposition 4.9: If f(n)isapolynomialofdegreed,thatis,\nf(n)=a +a n+ +a nd,\n0 1 d\n\u00b7\u00b7\u00b7\nanda >0,then f(n)isO(nd).\nd\nJustification: Notethat,forn 1,wehave1 n n2 nd;hence,\n\u2265 \u2264 \u2264 \u2264\u00b7\u00b7\u00b7\u2264\na +a n+a n2+ +a nd (a +a +a + +a )nd.\n0 1 2 d 0 1 2 d\n\u00b7\u00b7\u00b7 \u2264 \u00b7\u00b7\u00b7\nTherefore,wecanshow f(n)isO(nd)bydefiningc=a +a + +a andn =1.\n0 1 d 0\n\u00b7\u00b7\u00b7\nThus, the highest-degree term in a polynomial is the term that determines the\nasymptoticgrowthrateofthatpolynomial. Weconsidersomeadditionalproperties\nof the big-Oh notation in the exercises. Let us consider some further examples\nhere, however, focusing oncombinations of the seven fundamental functions used\ninalgorithm design.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 169 \u2014 #191\ni i\n4.2. AnalysisofAlgorithms 169\nExample 4.10: 5n2+3nlogn+2n+5isO(n2).\nJustification: 5n2+3nlogn+2n+5 (5+3+2+5)n2=cn2,forc=15,when\n\u2264\nn n =2(notethatnlogniszeroforn=1).\n0\n\u2265\nExample 4.11: 20n3+10nlogn+5isO(n3).\nJustification: 20n3+10nlogn+5 35n3,forn 1.\n\u2264 \u2265\nExample 4.12: 3logn+2isO(logn).\nJustification: 3logn+2 5logn, for n 2. Note that logn is zero for n=1.\n\u2264 \u2265\nThatiswhyweusen n =2inthiscase.\n0\n\u2265\nExample 4.13: 2n+2isO(2n).\nJustification: 2n+2=2n22=4 2n;hence, wecantake c=4andn =1inthis\n0\n\u00b7\ncase.\nExample 4.14: 2n+100lognisO(n).\nJustification: 2n+100logn 102n,forn n =2;hence,wecantakec=102\n0\n\u2264 \u2265\ninthiscase.\nCharacterizing Functions in Simplest Terms\nIngeneral, weshould use thebig-Ohnotation tocharacterize afunction asclosely\nas possible. While it is true that the function f(n)=4n3+3n2 is O(n5) or even\nO(n4), itis more accurate to say that f(n) is O(n3). Consider, by wayof analogy,\nascenariowhereahungrytravelerdrivingalongalongcountryroadhappensupon\na local farmer walking home from a market. If the traveler asks the farmer how\nmuchlonger hemustdrivebeforehecanfindsomefood, itmaybetruthful forthe\nfarmer to say, \u201ccertainly no longer than 12 hours,\u201d but it is much more accurate\n(andhelpful)forhimtosay,\u201cyoucanfindamarketjustafewminutesdriveupthis\nroad.\u201d Thus, even with the big-Oh notation, we should strive as much as possible\ntotellthewholetruth.\nItisalsoconsideredpoortastetoincludeconstantfactorsandlowerorderterms\nin the big-Oh notation. For example, it is not fashionable to say that the function\n2n2 is O(4n2+6nlogn), although this is completely correct. We should strive\ninsteadtodescribethefunction inthebig-Ohinsimplestterms.\nTheseven functions listed in Section 4.1 are the most common functions used\ninconjunctionwiththebig-Ohnotationtocharacterizetherunningtimesandspace\nusageofalgorithms. Indeed, wetypically usethenamesofthesefunctions torefer\ntotherunningtimesofthealgorithmstheycharacterize. So,forexample,wewould\nsaythatanalgorithm that runsinworst-case time4n2+nlognisaquadratic-time\nalgorithm, since it runs in O(n2) time. Likewise, an algorithm running in time at\nmost5n+20logn+4wouldbecalledalinear-timealgorithm.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 170 \u2014 #192\ni i\n170 Chapter4. AnalysisTools\nBig-Omega\nJustasthebig-Ohnotation providesanasymptotic wayofsayingthatafunctionis\n\u201clessthanorequalto\u201danotherfunction, thefollowingnotationsprovideanasymp-\ntoticwayofsaying thatafunction growsataratethatis\u201cgreater thanorequal to\u201d\nthatofanother.\nLet f(n)andg(n) befunctions mapping nonnegative integers torealnumbers.\nWe say that f(n) is \u2126(g(n)) (pronounced \u201cf(n) is big-Omega of g(n)\u201d) if g(n) is\nO(f(n)), that is, there is areal constant c>0 and an integer constant n 1such\n0\n\u2265\nthat\nf(n) cg(n), for n n .\n0\n\u2265 \u2265\nThis definition allows us to say asymptotically that one function is greater than or\nequaltoanother, uptoaconstantfactor.\nExample 4.15: 3nlogn+2nis\u2126(nlogn).\nJustification: 3nlogn+2n 3nlogn,forn 2.\n\u2265 \u2265\nBig-Theta\nIn addition, there is a notation that allows us to say that two functions grow at the\nsame rate, up to constant factors. Wesay that f(n) is \u0398(g(n)) (pronounced \u201cf(n)\nisbig-Thetaofg(n)\u201d)if f(n)isO(g(n))and f(n)is\u2126(g(n)), thatis,therearereal\nconstants c\u2032>0andc\u2032\u2032>0,andanintegerconstant n 1suchthat\n0\n\u2265\nc\u2032g(n) f(n) c\u2032\u2032g(n), for n n .\n0\n\u2264 \u2264 \u2265\nExample 4.16: 3nlogn+4n+5lognis\u0398(nlogn).\nJustification: 3nlogn 3nlogn+4n+5logn (3+4+5)nlognforn 2.\n\u2264 \u2264 \u2265\n4.2.4 Asymptotic Analysis\nSuppose two algorithms solving the same problem are available: an algorithm A,\nwhich has a running time of O(n), and an algorithm B, which has a running time\nofO(n2). Whichalgorithm isbetter? WeknowthatnisO(n2),whichimplies that\nalgorithm A is asymptotically better than algorithm B, although for a small value\nofn,BmayhavealowerrunningtimethanA.\nWe can use the big-Oh notation to order classes of functions by asymptotic\ngrowth rate. Our seven functions are ordered by increasing growth rate in the se-\nquence below, that is, if a function f(n) precedes a function g(n) in the sequence,\nthen f(n)isO(g(n)):\n1 logn n nlogn n2 n3 2n.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 171 \u2014 #193\ni i\n4.2. AnalysisofAlgorithms 171\nWeillustrate thegrowthratesofsomeimportantfunctions inTable4.2.\nn logn n nlogn n2 n3 2n\n8 3 8 24 64 512 256\n16 4 16 64 256 4,096 65,536\n32 5 32 160 1,024 32,768 4,294,967,296\n64 6 64 384 4,096 262,144 1.84\u00d71019\n128 7 128 896 16,384 2,097,152 3.40\u00d71038\n256 8 256 2,048 65,536 16,777,216 1.15\u00d71077\n512 9 512 4,608 262,144 134,217,728 1.34\u00d710154\nTable4.2: Selectedvaluesoffundamental functions inalgorithm analysis.\nWe further illustrate the importance of the asymptotic viewpoint in Table 4.3.\nThis table explores the maximum size allowed for an input instance that is pro-\ncessed byanalgorithm in1second, 1minute, and1hour. Itshowstheimportance\nof good algorithm design, because an asymptotically slow algorithm is beaten in\nthe long run by an asymptotically faster algorithm, even if the constant factor for\ntheasymptotically fasteralgorithm isworse.\nRunning MaximumProblemSize(n)\nTime(\u00b5s) 1second 1minute 1hour\n400n 2,500 150,000 9,000,000\n2n2 707 5,477 42,426\n2n 19 25 31\nTable 4.3: Maximum size of a problem that can be solved in 1 second, 1 minute,\nand1hour, forvariousrunning timesmeasuredinmicroseconds.\nTheimportance ofgoodalgorithm designgoesbeyondjustwhatcanbesolved\neffectively on a given computer, however. As shown in Table 4.4, even if we\nachieve a dramatic speed-up in hardware, we still cannot overcome the handicap\nofanasymptotically slowalgorithm. Thistableshowsthenewmaximumproblem\nsize achievable for any fixed amount of time, assuming algorithms with the given\nrunning timesarenowrunonacomputer256timesfasterthantheprevious one.\nRunningTime NewMaximumProblemSize\n400n 256m\n2n2 16m\n2n m+8\nTable4.4: Increase inthemaximum sizeofaproblem thatcanbesolved inafixed\namountoftimebyusingacomputer thatis256timesfaster thantheprevious one.\nEachentryisafunction ofm,thepreviousmaximumproblemsize.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 172 \u2014 #194\ni i\n172 Chapter4. AnalysisTools\n4.2.5 Using the Big-Oh Notation\nHaving made the case of using the big-Oh notation for analyzing algorithms, let\nus briefly discuss a few issues concerning its use. It is considered poor taste, in\ngeneral, tosay\u201cf(n) O(g(n)),\u201dsince thebig-Ohalready denotes the\u201cless-than-\n\u2264\nor-equal-to\u201d concept. Likewise, although common, it is not fully correct to say\n\u201cf(n)=O(g(n))\u201d (with the usual understanding of the \u201c=\u201d relation), since there\nis no way to make sense of the statement \u201cO(g(n)) = f(n).\u201d In addition, it is\ncompletely wrongtosay\u201cf(n) O(g(n))\u201dor\u201cf(n)>O(g(n)),\u201dsincetheg(n)in\n\u2265\nthebig-Ohexpresses anupperboundon f(n). Itisbesttosay,\n\u201cf(n)isO(g(n)).\u201d\nForthemoremathematically inclined, itisalsocorrect tosay,\n\u201cf(n) O(g(n)),\u201d\n\u2208\nfor the big-Oh notation is, technically speaking, denoting a whole collection of\nfunctions. In this book, we stick to presenting big-Oh statements as \u201cf(n) is\nO(g(n)).\u201d Even with this interpretation, there is considerable freedom in how\nwe can use arithmetic operations with the big-Oh notation, and with this freedom\ncomesacertainamountofresponsibility.\nSome Words of Caution\nA few words of caution about asymptotic notation are in order at this point. First,\nnote that the use of the big-Oh and related notations can be somewhat misleading\nshould the constant factors they \u201chide\u201d be very large. For example, while it is\ntrue that the function 10100n is O(n), if this is the running time of an algorithm\nbeing compared to one whose running time is 10nlogn, we prefer the O(nlogn)\ntimealgorithm,eventhoughthelinear-timealgorithmisasymptoticallyfaster. This\npreference is because the constant factor, 10100, which is called \u201cone googol,\u201d is\nbelieved by many astronomers to be an upper bound on the number of atoms in\ntheobservable universe. Soweareunlikely toeverhaveareal-world problem that\nhas this number as its input size. Thus, even when using the big-Oh notation, we\nshould atleast be somewhat mindful ofthe constant factors andlower order terms\nweare\u201chiding.\u201d\nThe observation above raises the issue of what constitutes a \u201cfast\u201d algorithm.\nGenerally speaking, any algorithm running in O(nlogn) time (with a reasonable\nconstant factor) should be considered efficient. Even an O(n2) time method may\nbefastenoughinsomecontexts, thatis,whennissmall. Butanalgorithmrunning\ninO(2n)timeshouldalmostneverbeconsidered efficient.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 173 \u2014 #195\ni i\n4.2. AnalysisofAlgorithms 173\nExponential Running Times\nThereisafamousstoryabouttheinventorofthegameofchess. Heaskedonlythat\nhis king pay him 1 grain of rice for the first square on the board, 2 grains for the\nsecond, 4grains forthethird, 8forthefourth, andsoon. Itisaninteresting testof\nprogramming skillstowriteaprogram tocomputeexactlythenumberofgrainsof\nrice theking would have topay. Infact, anyC++program written tocompute this\nnumber ina single integer value causes an integer overflow to occur (although the\nrun-timemachineprobablywon\u2019tcomplain).\nIf we must draw a line between efficient and inefficient algorithms, therefore,\nit is natural to make this distinction be that between those algorithms running in\npolynomial time and those running inexponential time. Thatis, make the distinc-\ntionbetweenalgorithmswitharunningtimethatisO(nc),forsomeconstantc>1,\nandthosewitharunningtimethatisO(bn),forsomeconstantb>1. Likesomany\nnotions wehavediscussed inthissection, thistooshould betakenwitha\u201cgrainof\nsalt,\u201d for an algorithm running in O(n100) time should probably not be considered\n\u201cefficient.\u201d Evenso,thedistinctionbetweenpolynomial-timeandexponential-time\nalgorithms isconsidered arobustmeasureoftractability.\nTosummarize, the asymptotic notations of big-Oh, big-Omega, and big-Theta\nprovideaconvenient languageforustoanalyzedatastructures andalgorithms. As\nmentionedearlier, thesenotationsprovideconvenience becausetheyletusconcen-\ntrateonthe\u201cbigpicture\u201d ratherthanlow-leveldetails.\nTwo Examples of Asymptotic Algorithm Analysis\nWeconclude thissectionbyanalyzing twoalgorithmsthatsolvethesameproblem\nbut have rather different running times. The problem we are interested in is the\noneofcomputingtheso-calledprefixaveragesofasequenceofnumbers. Namely,\ngiven an array X storing n numbers, wewant to compute an array Asuch that A[i]\nistheaverageofelementsX[0],...,X[i],fori=0,...,n 1,thatis,\n\u2212\n\u2211i X[j]\nj=0\nA[i]= .\ni+1\nComputing prefix averages hasmanyapplications ineconomics andstatistics. For\nexample, given the year-by-year returns of a mutual fund, an investor typically\nwantstoseethefund\u2019saverageannualreturnsforthelastyear,thelastthreeyears,\nthe last five years, and the last ten years. Likewise, given a stream of daily Web\nusagelogs,aWebsitemanagermaywishtotrackaverageusagetrendsovervarious\ntimeperiods.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 174 \u2014 #196\ni i\n174 Chapter4. AnalysisTools\nA Quadratic-Time Algorithm\nOur first algorithm for the prefix averages problem, called prefixAverages1, is\nshowninCodeFragment4.2. ItcomputeseveryelementofAseparately, following\nthedefinition.\nAlgorithmprefixAverages1(X):\nInput: Ann-elementarrayX ofnumbers.\nOutput: Ann-element arrayAofnumberssuchthatA[i]is\ntheaverageofelementsX[0],...,X[i].\nLetAbeanarrayofnnumbers.\nfori 0ton 1do\n\u2190 \u2212\na 0\n\u2190\nfor j 0toido\n\u2190\na a+X[j]\n\u2190\nA[i] a/(i+1)\n\u2190\nreturnarrayA\nCodeFragment4.2: AlgorithmprefixAverages1.\nLetusanalyzetheprefixAverages1algorithm.\nInitializing and returning arrayAatthebeginning andend canbedone with\n\u2022\naconstant numberofprimitiveoperations perelementandtakesO(n)time.\nThere are two nested for loops that are controlled by counters i and j, re-\n\u2022\nspectively. The body of the outer loop, controlled by counter i, is executed\nn times for i=0,...,n 1. Thus, statements a=0 and A[i]=a/(i+1) are\n\u2212\nexecutedntimeseach. Thisimpliesthatthesetwostatements,plustheincre-\nmentingandtestingofcounteri,contributeanumberofprimitiveoperations\nproportional ton,thatis,O(n)time.\nThe body of the inner loop, which is controlled by counter j, is executed\n\u2022\ni+1times,depending onthecurrentvalueoftheouterloopcounteri. Thus,\nstatementa=a+X[j]intheinnerloopisexecuted1+2+3+ +ntimes.\n\u00b7\u00b7\u00b7\nByrecalling Proposition 4.3,weknowthat1+2+3+ +n=n(n+1)/2,\n\u00b7\u00b7\u00b7\nwhichimpliesthatthestatementintheinnerloopcontributes O(n2)time. A\nsimilarargumentcanbedonefortheprimitiveoperationsassociatedwiththe\nincrementing andtestingcounter j,whichalsotakeO(n2)time.\nTherunning timeofalgorithm prefixAverages1isgivenbythesumofthreeterms.\nThe first and the second term are O(n), and the third term is O(n2). By a simple\napplication ofProposition 4.9,therunning timeofprefixAverages1isO(n2).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 175 \u2014 #197\ni i\n4.2. AnalysisofAlgorithms 175\nA Linear-Time Algorithm\nInordertocomputeprefixaverages moreefficiently, wecanobserve thattwocon-\nsecutiveaverages A[i 1]andA[i]aresimilar:\n\u2212\nA[i 1] = (X[0]+X[1]+ +X[i 1])/i\n\u2212 \u00b7\u00b7\u00b7 \u2212\nA[i] = (X[0]+X[1]+ +X[i 1]+X[i])/(i+1).\n\u00b7\u00b7\u00b7 \u2212\nIf we denote with S the prefix sum X[0]+X[1]+ +X[i], we can compute\ni\n\u00b7\u00b7\u00b7\ntheprefixaveragesasA[i]=S/(i+1). Itiseasytokeeptrackofthecurrentprefix\ni\nsum while scanning array X with a loop. We are now ready to present Algorithm\nprefixAverages2inCodeFragment4.3.\nAlgorithmprefixAverages2(X):\nInput: Ann-elementarrayX ofnumbers.\nOutput: Ann-element arrayAofnumberssuchthatA[i]is\ntheaverageofelementsX[0],...,X[i].\nLetAbeanarrayofnnumbers.\ns 0\n\u2190\nfori 0ton 1do\n\u2190 \u2212\ns s+X[i]\n\u2190\nA[i] s/(i+1)\n\u2190\nreturnarrayA\nCodeFragment4.3: AlgorithmprefixAverages2.\nTheanalysis oftherunning timeofalgorithm prefixAverages2follows:\nInitializing and returning arrayAatthebeginning andend canbedone with\n\u2022\naconstant numberofprimitiveoperations perelement,andtakesO(n)time.\nInitializing variablesatthebeginning takesO(1)time.\n\u2022\nThereisasingle forloop, whichiscontrolled bycounter i. Thebody ofthe\n\u2022\nloop is executed n times, for i=0,...,n 1. Thus, statements s=s+X[i]\n\u2212\nand A[i]=s/(i+1) are executed n times each. This implies that these two\nstatementsplustheincrementingandtestingofcountericontributeanumber\nofprimitiveoperations proportional ton,thatis,O(n)time.\nTherunning timeofalgorithm prefixAverages2isgivenbythesumofthreeterms.\nThe first and the third term are O(n), and the second term is O(1). By a simple\napplication ofProposition 4.9,therunning timeofprefixAverages2isO(n),which\nismuchbetterthanthequadratic-time algorithm prefixAverages1.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 176 \u2014 #198\ni i\n176 Chapter4. AnalysisTools\n4.2.6 A Recursive Algorithm for Computing Powers\nAs a more interesting example of algorithm analysis, let us consider the problem\nof raising a number x to an arbitrary nonnegative integer, n. That is, we wish to\ncompute the power function p(x,n), defined as p(x,n)=xn. This function has an\nimmediaterecursivedefinitionbasedonlinearrecursion:\n1 ifn=0\np(x,n)=\nx p(x,n 1) otherwise\n(cid:26) \u00b7 \u2212\nThis definition leads immediately to a recursive algorithm that uses O(n) function\ncalls to compute p(x,n). We can compute the power function much faster than\nthis, however, by using the following alternative definition, also based on linear\nrecursion, whichemploysasquaringtechnique:\n1 ifn=0\np(x,n)= x p(x,(n 1)/2)2 ifn>0isodd\n\uf8f1 \u00b7 \u2212\np(x,n/2)2 ifn>0iseven\n\uf8f2\nToillustratehowthisdefinitionworks,considerthefollowingexamples:\n\uf8f3\n24 = 2(4/2)2=(24/2)2=(22)2=42=16\n25 = 21+(4/2)2=2(24/2)2=2(22)2=2(42)=32\n26 = 2(6/2)2=(26/2)2=(23)2=82=64\n27 = 21+(6/2)2=2(26/2)2=2(23)2=2(82)=128\nThisdefinition suggests thealgorithm ofCodeFragment4.4.\nAlgorithmPower(x,n):\nInput: Anumberxandintegern 0\n\u2265\nOutput: Thevaluexn\nifn=0then\nreturn1\nifnisoddthen\ny Power(x,(n 1)/2)\n\u2190 \u2212\nreturnx y y\n\u00b7 \u00b7\nelse\ny Power(x,n/2)\n\u2190\nreturny y\n\u00b7\nCodeFragment4.4: Computingthepowerfunctionusinglinearrecursion.\nTo analyze the running time of the algorithm, we observe that each recur-\nsive call of function Power(x,n) divides the exponent, n, by two. Thus, there\nare O(logn) recursive calls, not O(n). That is, by using linear recursion and the\nsquaring technique, we reduce the running time for the computation of the power\nfunction fromO(n)toO(logn),whichisabigimprovement.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 177 \u2014 #199\ni i\n4.2. AnalysisofAlgorithms 177\n4.2.7 Some More Examples of Algorithm Analysis\nNowthatwehavethebig-Ohnotationfordoingalgorithmanalysis,letusgivesome\nmoreexamplesofsimplealgorithmsthatcanhavetheirrunningtimescharacterized\nusing this notation. Moreover, in keeping with our earlier promise, we illustrate\nbelow how each of the seven functions given earlier in this chapter can be used to\ncharacterize therunningtimeofanexamplealgorithm.\nA Constant-Time Method\nToillustrateaconstant-timealgorithm,considerthefollowingC++function,which\nreturnsthesizeofanSTLvector, thatis,thecurrentnumberofcellsinthearray:\nint capacity(const vector<int>& arr)\n{\nreturn arr.size();\n}\nThis is a very simple algorithm, because the size of a vector is stored as a\nmember variable in the vector object, so it takes only a constant-time lookup to\nreturnthisvalue. Thus,thecapacityfunctionrunsinO(1)time;thatis,therunning\ntimeofthisfunction isindependent ofthevalueofn,thesizeofthearray.\nRevisiting the Method for Finding the Maximum in an Array\nFor our next example, let us reconsider a simple problem studied earlier, finding\nthe largest value in an array of integers. We assume that the array is stored as an\nSTLvector. ThiscanbedoneinC++asfollows:\nint findMax(const vector<int>& arr)\n{\nint max = arr[0];\nfor (int i = 1; i < arr.size(); i++)\n{\nif (max < arr[i]) max = arr[i];\n}\nreturn max;\n}\nThis function, which amounts to a C++ implementation of the arrayMax al-\ngorithm of Section 4.2.3, compares each of the n elements in the input array to a\ncurrent maximum, and each time it finds an element larger than the current maxi-\nmum, it updates the current maximum to be this value. Thus, it spends a constant\namount of timefor each of the nelements inthe array; hence, aswiththe pseudo-\ncodeversionofthearrayMaxalgorithm,therunningtimeofthisalgorithmisO(n).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 178 \u2014 #200\ni i\n178 Chapter4. AnalysisTools\nFurther Analysis of the Maximum-Finding Algorithm\nAmoreinterestingquestion,withrespecttotheabovemaximum-findingalgorithm,\nis to ask how many times we update the current maximum value. Note that this\nstatement is executed only if we encounter a value of the array that is larger than\nour current maximum. In the worst case, this condition could be true each time\nwe perform the test. For instance, this situation would occur if the input array is\ngiven to us in sorted order. Thus, in the worst-case, the statement max=arr[i] is\nperformedn 1times,henceO(n)times.\n\u2212\nButwhatiftheinputarrayisgiventousinrandomorder,withallordersequally\nlikely;whatwouldbetheexpectednumberoftimesweupdatedthemaximumvalue\ninthiscase? Toanswer thisquestion, notethatweupdate thecurrent maximumin\nthe ith iteration only if the ith element in the array is bigger than all the elements\nthat precede it. Butif the array isgiven tous inrandom order, the probability that\ntheithelementislargerthanallelementsthatprecedeitis1/i;hence,theexpected\nnumber of times we update the maximum in this case is H =\u2211n 1/i, which is\nn i=1\nknownasthenthHarmonicnumber. Itturnsout(seeProposition A.16)thatH is\nn\nO(logn). Therefore, the expected number oftimes themaximum isupdated when\ntheabovemaximum-findingalgorithm isrunonarandomarrayisO(logn).\nThree-Way Set Disjointness\nSupposewearegiventhreesets,A,B,andC,withthesesetsstoredinthreedifferent\ninteger arrays, a, b, andc, respectively. Thethree-way setdisjointness problem is\nto determine if these three sets are disjoint, that is, whether there is no element x\nsuchthatx A,x B,andx C. AsimpleC++functiontodeterminethisproperty\n\u2208 \u2208 \u2208\nisgivenbelow:\nbool areDisjoint(const vector<int>& a, const vector<int>& b,\nconst vector<int>& c)\n{\nfor (int i = 0; i < a.size(); i++)\nfor (int j = 0; j < b.size(); j++)\nfor (int k = 0; k < c.size(); k++)\nif ((a[i] == b[j]) && (b[j] == c[k])) return false;\nreturn true;\n}\nThis simple algorithm loops through each possible triple of indices i, j, and k\ntocheckiftherespectiveelementsindexedina,b,andcareequal. Thus,ifeachof\nthesearraysisofsizen,thentheworst-caserunningtimeofthisfunctionisO(n3).\nMoreover, the worst case is achieved when the sets are disjoint, since in this case\nwegothroughalln3 triplesofvalidindices, i, j,andk. Sucharunningtimewould\ngenerally not be considered very efficient, but, fortunately, there isabetter wayto\nsolvethisproblem, whichweexploreinExerciseC-4.3.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 179 \u2014 #201\ni i\n4.2. AnalysisofAlgorithms 179\nRecursion Run Amok\nThenextfewexamplealgorithmswestudyareforsolvingtheelementuniqueness\nproblem, in which we are given a range, i,i+1,...,j, of indices for an array, A,\nwhichweassumeisgivenasanSTLvector. Wewanttodetermine iftheelements\nof this range, A[i],A[i+1],...,A[j], are all unique, that is, there is no repeated\nelement in this group of array entries. The first algorithm we give for solving the\nelement uniqueness problem is a recursive one. But it uses recursion in a very\ninefficientmanner, asshowninthefollowingC++implementation.\nbool isUnique(const vector<int>& arr, int start, int end)\n{\nif (start >= end) return true;\nif (!isUnique(arr, start, end 1))\n\u2212\nreturn false;\nif (!isUnique(arr, start+1, end))\nreturn false;\nreturn (arr[start] != arr[end]);\n}\nYou should first convince yourself that the function is correct. To analyze this\nrecursive algorithm\u2019s running time,letusfirstdetermine howmuchtimewespend\noutsideofrecursivecallsinanyinvocationofthisfunction. Note,inparticular, that\nthere are no loops\u2014just comparisons, arithmetic operations, array element refer-\nences,andfunctionreturns. Thus,thenonrecursivepartofeachfunctioninvocation\nruns in constant time, that is, O(1) time; hence, to determine the worst-case run-\nning time of this function we only need to determine the worst-case total number\nofcallswemaketotheisUniquefunction.\nLetndenotethenumberofentriesunderconsideration, thatis,let\nn=end start+1.\n\u2212\nIfn=1,thentherunningtimeoftheisUniqueisO(1),sincetherearenorecursive\ncallsforthiscase. Tocharacterize therunning timeofthegeneral case, theimpor-\ntant observation tomake isthat inorder tosolve aproblem ofsize n, the isUnique\nfunction makes two recursive calls on problems of size n 1. Thus, in the worst\n\u2212\ncase, a call for a range of size n makes two calls on ranges of size n 1, which\n\u2212\neach maketwocalls onranges ofsize n 2, which each maketwocalls onranges\n\u2212\nofsizen 3,andsoon. Thus,intheworstcase,thetotalnumber offunction calls\n\u2212\nisgivenbythegeometricsummation\n1+2+4+ +2n\u22121,\n\u00b7\u00b7\u00b7\nwhich is equal to 2n 1 by Proposition 4.5. Thus, the worst-case running time of\n\u2212\nfunctionisUniqueisO(2n). Thisisanincrediblyinefficientmethodforsolvingthe\nelement uniqueness problem. Its inefficiency comes not from the fact that it uses\nrecursion\u2014it comesfromthefactthatitusesrecursionpoorly, whichissomething\nweaddressinExerciseC-4.2.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 180 \u2014 #202\ni i\n180 Chapter4. AnalysisTools\nAn Iterative Method for Solving the Element Uniqueness Problem\nWe can do much better than the above exponential-time method by using the fol-\nlowingiterativealgorithm:\nbool isUniqueLoop(const vector<int>& arr, int start, int end)\n{\nif (start >= end) return true;\nfor (int i = start; i < end; i++)\nfor (int j = i+1; j <= end; j++)\nif (arr[i] == arr[j]) return false;\nreturn true;\n}\nThis function solves the element uniqueness problem by looping through all\ndistinct pairs of indices, i and j, and checking if any of them indexes a pair of\nelements that areequal toeachother. Itdoesthis using twonested for loops, such\nthatthefirstiteration oftheouterloopcausesn 1iterations oftheinnerloop,the\n\u2212\nseconditerationoftheouterloopcausesn 2iterationsoftheinnerloop,thethird\n\u2212\niterationoftheouterloopcausesn 3iterationsoftheinnerloop,andsoon. Thus,\n\u2212\ntheworst-caserunning timeofthisfunction isproportional to\n1+2+3+ +(n 1),\n\u00b7\u00b7\u00b7 \u2212\nwhichisO(n2)aswesawearlierinthischapter (Proposition 4.3).\nUsing Sorting as a Problem-Solving Tool\nAn even better algorithm for the element uniqueness problem is based on using\nsorting asaproblem-solving tool. Inthiscase, bysorting anarrayofelements, we\nareguaranteed thatanyduplicate elementswillbeplacednexttoeachother. Thus,\nitsuffices tosortthearray andlookforduplicates among consecutive elements. A\nC++implementation ofthisalgorithm follows.\nbool isUniqueSort(const vector<int>& arr, int start, int end)\n{\nif (start >= end) return true;\nvector<int> buf(arr); // duplicate copy of arr\nsort(buf.begin()+start, buf.begin()+end); // sort the subarray\nfor (int i = start; i < end; i++) // check for duplicates\nif (buf[i] == buf[i+1]) return false;\nreturn true;\n}\nThefunctionsortisprovidedbytheSTL.Onmostsystems,itrunsinO(nlogn)\ntime. SincetheotherstepsruninO(n)time,theentirealgorithmrunsinO(nlogn)\ntime. Incidentally, we can solve the element uniqueness problem even faster, at\nleastintermsofitsaverage-caserunningtime,byusingthehashtabledatastructure\nweexploreinSection9.2.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 181 \u2014 #203\ni i\n4.3. SimpleJustificationTechniques 181\n4.3 Simple Justification Techniques\nSometimes,wewanttomakeclaimsaboutanalgorithm, suchasshowingthatitis\ncorrect or that it runs fast. In order to rigorously make such claims, we must use\nmathematical language, and in order to back up such claims, we must justify or\nproveourstatements. Fortunately, thereareseveralsimplewaystodothis.\n4.3.1 By Example\nSome claims are of the generic form, \u201cThere is an element x in a set S that has\nproperty P.\u201d To justify such a claim, we only need to produce a particular x in S\nthathaspropertyP. Likewise,somehard-to-believeclaimsareofthegenericform,\n\u201cEveryelementxinasetShaspropertyP.\u201d Tojustifythatsuchaclaimisfalse,we\nonly need to produce aparticular x from S that does not have property P. Such an\ninstance iscalledacounterexample.\nExample 4.17: ProfessorAmongusclaimsthateverynumberoftheform2i 1\n\u2212\nisaprime,wheniisanintegergreaterthan1.ProfessorAmongusiswrong.\nJustification: ToproveProfessorAmongusiswrong,wefindacounter-example.\nFortunately, weneednotlooktoofar,for24 1=15=3 5.\n\u2212 \u00b7\n4.3.2 The \u201cContra\u201d Attack\nAnother set of justification techniques involves the use of the negative. The two\nprimarysuchmethodsaretheuseofthecontrapositive andthecontradiction. The\nuse of the contrapositive method is like looking through a negative mirror. To\njustify the statement \u201cif pis true, then qis true\u201d weestablish that \u201cif qis not true,\nthen p is not true\u201d instead. Logically, these two statements are the same, but the\nlatter, whichiscalledthecontrapositive ofthefirst,maybeeasiertothinkabout.\nExample 4.18: Letaandbbeintegers.Ifabiseven,thenaisevenorbiseven.\nJustification: Tojustify thisclaim, consider thecontrapositive, \u201cIfaisoddand\nbisodd,thenabisodd.\u201d So,suppose a=2i+1andb=2j+1,forsomeintegers\niand j. Thenab=4ij+2i+2j+1=2(2ij+i+ j)+1;hence, abisodd.\nBesidesshowingauseofthecontrapositivejustificationtechnique,theprevious\nexample also contains an application of DeMorgan\u2019s Law. This law helps us deal\nwithnegations, foritstates thatthe negation ofastatement oftheform \u201cporq\u201dis\n\u201cnot p and not q.\u201d Likewise, it states that the negation of a statement of the form\n\u201cpandq\u201dis\u201cnot pornotq.\u201d\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 182 \u2014 #204\ni i\n182 Chapter4. AnalysisTools\nContradiction\nAnother negative justification technique is justification by contradiction, which\nalso often involves using DeMorgan\u2019s Law. In applying the justification by con-\ntradiction technique, we establish that a statement q is true by first supposing that\nq is false and then showing that this assumption leads to a contradiction (such as\n2=2or1>3). Byreaching such acontradiction, weshow that noconsistent sit-\n6\nuationexistswithqbeingfalse, soqmustbetrue. Ofcourse, inordertoreachthis\nconclusion, wemustbesureoursituationisconsistentbeforeweassumeqisfalse.\nExample 4.19: Letaandbbeintegers.Ifabisodd,thenaisoddandbisodd.\nJustification: Let ab be odd. We wish to show that a is odd and b is odd. So,\nwith the hope of leading to a contradiction, let us assume the opposite, namely,\nsuppose a is even or b is even. In fact, without loss of generality, we can assume\nthat a is even (since the case for b is symmetric). Then a=2i for some integer i.\nHence,ab=(2i)b=2(ib),thatis,abiseven. Butthisisacontradiction: abcannot\nsimultaneously beoddandeven. Thereforeaisoddandbisodd.\n4.3.3 Induction and Loop Invariants\nMostoftheclaimswemakeaboutarunningtimeoraspaceboundinvolveaninte-\ngerparametern(usually denotinganintuitivenotionofthe\u201csize\u201doftheproblem).\nMoreover,mostoftheseclaimsareequivalenttosayingsomestatementq(n)istrue\n\u201cfor all n 1.\u201d Since this is making a claim about an infinite set of numbers, we\n\u2265\ncannotjustifythisexhaustively inadirectfashion.\nInduction\nWe can often justify claims such as those above as true, however, by using the\ntechniqueofinduction. Thistechniqueamountstoshowingthat,foranyparticular\nn 1, there is a finite sequence of implications that starts with something known\n\u2265\ntobetrueandultimatelyleadstoshowingthatq(n)istrue. Specifically,webegina\njustificationbyinductionbyshowingthatq(n)istrueforn=1(andpossiblysome\nothervaluesn=2,3,...,k,forsomeconstantk). Thenwejustifythattheinductive\n\u201cstep\u201distrueforn>k,namely,weshow\u201cifq(i)istruefori<n,thenq(n)istrue.\u201d\nThecombination ofthesetwopiecescompletes thejustification byinduction.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 183 \u2014 #205\ni i\n4.3. SimpleJustificationTechniques 183\nProposition 4.20: ConsidertheFibonaccifunctionF(n),wherewedefineF(1)=\n1,F(2)=2,andF(n)=F(n 1)+F(n 2) forn>2. (SeeSection2.2.3.) We\n\u2212 \u2212\nclaimthatF(n)<2n.\nJustification: Weshowourclaimisrightbyinduction.\nBasecases: (n 2). F(1)=1<2=21 andF(2)=2<4=22.\n\u2264\nInductionstep: (n>2). Supposeourclaimistrueforn\u2032<n. ConsiderF(n). Since\nn>2, F(n)=F(n 1)+F(n 2). Moreover, since n 1<n and n 2<n, we\n\u2212 \u2212 \u2212 \u2212\ncan apply the inductive assumption (sometimes called the \u201cinductive hypothesis\u201d)\ntoimplythatF(n)<2n\u22121+2n\u22122,since\n2n\u22121+2n\u22122<2n\u22121+2n\u22121=2 2n\u22121=2n.\n\u00b7\nLetusdoanother inductiveargument, thistimeforafactwehaveseenbefore.\nProposition 4.21: (whichisthesameasProposition4.3)\n\u2211 n n(n+1)\ni= .\n2\ni=1\nJustification: Wejustifythisequality byinduction.\nBasecase: n=1. Trivial,for1=n(n+1)/2,ifn=1.\nInductionstep: n 2. Assumetheclaimistrueforn\u2032<n. Considern.\n\u2265\nn n\u22121\n\u2211 \u2211\ni=n+ i.\ni=1 i=1\nBytheinduction hypothesis, then\n\u2211 n (n 1)n\ni=n+ \u2212 ,\n2\ni=1\nwhichwecansimplifyas\n(n 1)n 2n+n2 n n2+n n(n+1)\nn+ \u2212 = \u2212 = = .\n2 2 2 2\nWemaysometimes feel overwhelmed by the task of justifying something true\nforalln 1. Weshouldremember,however,theconcretenessoftheinductivetech-\n\u2265\nnique. Itshows that, for anyparticular n, there is afinite step-by-step sequence of\nimplications thatstartswithsomethingtrueandleadstothetruthaboutn. Inshort,\ntheinductiveargument isaformulaforbuilding asequence ofdirectjustifications.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 184 \u2014 #206\ni i\n184 Chapter4. AnalysisTools\nLoop Invariants\nThefinaljustificationtechnique wediscussinthissectionistheloopinvariant. To\nprove some statement about a loop is correct, define in terms of a series of\nS S\nsmallerstatements , ,..., ,where:\n0 1 k\nS S S\n1. Theinitialclaim, ,istruebeforetheloopbegins.\n0\nS\n2. If istruebeforeiteration i,then istrueafteriteration i.\ni\u22121 i\nS S\n3. Thefinalstatement, ,impliesthestatement thatwewishtobetrue.\nk\nS S\nLet us give a simple example of using a loop-invariant argument to justify the\ncorrectness of an algorithm. In particular, let us consider using a loop invariant to\njustify the correctness of arrayFind, shown in Code Fragment 4.5, for finding an\nelementxinanarrayA.\nAlgorithmarrayFind(x,A):\nInput: Anelementxandann-element array,A.\nOutput: Theindexisuchthatx=A[i]or 1ifnoelementofAisequaltox.\n\u2212\ni 0\n\u2190\nwhilei<ndo\nifx=A[i]then\nreturni\nelse\ni i+1\n\u2190\nreturn 1\n\u2212\nCodeFragment4.5: Algorithm arrayFindforfindingagivenelementinanarray.\nToshowthatarrayFindiscorrect, weinductively defineaseries ofstatements,\n,that leadtothecorrectness ofouralgorithm. Specifically, weclaim thefollow-\ni\nS\ningistrueatthebeginning ofiteration iofthewhileloop:\n: xisnotequaltoanyofthefirstielementsofA.\ni\nS\nThis claim is true at the beginning of the first iteration of the loop, since there are\nnoelementsamongthefirst0inA(thiskindofatriviallytrueclaimissaidtohold\nvacuously). In iteration i, we compare element x to element A[i] and return the\nindex iifthese twoelements are equal, which is clearly correct and completes the\nalgorithm in this case. If the two elements x and A[i] are not equal, then we have\nfound one more element not equal to x and we increment the index i. Thus, the\nclaim istrueforthisnewvalueofi;hence, itistrueatthebeginning ofthenext\ni\nS\niteration. Ifthewhile-loopterminateswithouteverreturninganindexinA,thenwe\nhave i=n. That is, is true\u2014there are no elements of A equal to x. Therefore,\nn\nS\nthealgorithm correctly returns 1toindicate thatxisnotinA.\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 185 \u2014 #207\ni i\n4.4. Exercises 185\n4.4 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-4.1 There is a well-known city (which will go nameless here) whose inhabi-\ntants have the reputation of enjoying a meal only if that meal is the best\nthey have ever experienced in their life. Otherwise, they hate it. Assum-\ning meal quality is distributed uniformly across a person\u2019s life, what is\ntheexpected numberoftimesinhabitants ofthiscityarehappywiththeir\nmeals?\nR-4.2 Giveapseudo-codedescriptionoftheO(n)-timealgorithmforcomputing\nthepowerfunction p(x,n). Also,drawtherecursiontraceofthisalgorithm\nforthecomputation of p(2,5).\nR-4.3 Give a C++ description of Algorithm Power for computing the power\nfunction p(x,n)(CodeFragment4.4).\nR-4.4 Draw the recursion trace of the Power algorithm (Code Fragment 4.4,\nwhichcomputesthepowerfunction p(x,n)) forcomputing p(2,9).\nR-4.5 AnalyzetherunningtimeofAlgorithmBinarySum(CodeFragment3.41)\nforarbitrary valuesoftheinputparametern.\nR-4.6 Graphthefunctions 8n,4nlogn,2n2,n3,and2n usingalogarithmicscale\nfor the x- and y-axes. That is, if the function is f(n) is y, plot this as a\npointwithx-coordinate atlognandy-coordinate atlogy.\nR-4.7 Thenumber ofoperations executed byalgorithms AandBis8nlognand\n2n2,respectively. Determinen suchthatAisbetterthanBforn n .\n0 0\n\u2265\nR-4.8 The number of operations executed by algorithms A and B is 40n2 and\n2n3,respectively. Determinen suchthatAisbetterthanBforn n .\n0 0\n\u2265\nR-4.9 Give an example of a function that is plotted the same on a log-log scale\nasitisonastandard scale.\nR-4.10 Explainwhytheplotofthefunction nc isastraight linewithslopecona\nlog-logscale.\nR-4.11 What is the sum of all the even numbers from 0 to 2n, for any positive\nintegern?\nR-4.12 Showthatthefollowingtwostatementsareequivalent:\n(a)Therunningtimeofalgorithm AisalwaysO(f(n)).\n(b)Intheworstcase,therunningtimeofalgorithm AisO(f(n)).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 186 \u2014 #208\ni i\n186 Chapter4. AnalysisTools\nR-4.13 Orderthefollowingfunctions byasymptotic growthrate.\n4nlogn+2n 210 2logn\n3n+100logn 4n 2n\nn2+10n n3 nlogn\nR-4.14 Show that if d(n) is O(f(n)), then ad(n) is O(f(n)), for any constant\na>0.\nR-4.15 Showthatifd(n)isO(f(n))ande(n)isO(g(n)),thentheproductd(n)e(n)\nisO(f(n)g(n)).\nR-4.16 Give a big-Oh characterization, in terms of n, of the running time of the\nEx1function showninCodeFragment4.6.\nR-4.17 Give a big-Oh characterization, in terms of n, of the running time of the\nEx2function showninCodeFragment4.6.\nR-4.18 Give a big-Oh characterization, in terms of n, of the running time of the\nEx3function showninCodeFragment4.6.\nR-4.19 Give a big-Oh characterization, in terms of n, of the running time of the\nEx4function showninCodeFragment4.6.\nR-4.20 Give a big-Oh characterization, in terms of n, of the running time of the\nEx5function showninCodeFragment4.6.\nR-4.21 Bill has an algorithm, find2D, to find an element x in an n n array A.\n\u00d7\nThealgorithm find2D iterates overthe rowsofA, and calls thealgorithm\narrayFind, of Code Fragment 4.5, on each row, until x is found or it has\nsearched allrowsof A. Whatis theworst-case running time offind2Din\ntermsofn? Whatistheworst-case running timeoffind2DintermsofN,\nwhereN isthetotalsizeofA? WoulditbecorrecttosaythatFind2Disa\nlinear-time algorithm? Whyorwhynot?\nR-4.22 For each function f(n) and time t in the following table, determine the\nlargest size n ofa problem Pthat can besolved in timet ifthe algorithm\nforsolvingPtakes f(n)microseconds (oneentryisalreadycompleted).\n1Second 1Hour 1Month 1Century\nlogn 10300000\n\u2248\nn\nnlogn\nn2\n2n\nR-4.23 Show that if d(n) is O(f(n)) and e(n) is O(g(n)), then d(n)+e(n) is\nO(f(n)+g(n)).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 187 \u2014 #209\ni i\n4.4. Exercises 187\nAlgorithmEx1(A):\nInput: AnarrayAstoringn 1integers.\n\u2265\nOutput: ThesumoftheelementsinA.\ns A[0]\n\u2190\nfori 1ton 1do\n\u2190 \u2212\ns s+A[i]\n\u2190\nreturns\nAlgorithmEx2(A):\nInput: AnarrayAstoringn 1integers.\n\u2265\nOutput: ThesumoftheelementsatevencellsinA.\ns A[0]\n\u2190\nfori 2ton 1byincrementsof2do\n\u2190 \u2212\ns s+A[i]\n\u2190\nreturns\nAlgorithmEx3(A):\nInput: AnarrayAstoringn 1integers.\n\u2265\nOutput: ThesumoftheprefixsumsinA.\ns 0\n\u2190\nfori 0ton 1do\n\u2190 \u2212\ns s+A[0]\n\u2190\nfor j 1toido\n\u2190\ns s+A[j]\n\u2190\nreturns\nAlgorithmEx4(A):\nInput: AnarrayAstoringn 1integers.\n\u2265\nOutput: ThesumoftheprefixsumsinA.\ns A[0]\n\u2190\nt s\n\u2190\nfori 1ton 1do\n\u2190 \u2212\ns s+A[i]\n\u2190\nt t+s\n\u2190\nreturnt\nAlgorithmEx5(A,B):\nInput: ArraysAandBeachstoringn 1integers.\n\u2265\nOutput: ThenumberofelementsinBequaltothesumofprefixsumsinA.\nc 0\n\u2190\nfori 0ton 1do\n\u2190 \u2212\ns 0\n\u2190\nfor j 0ton 1do\n\u2190 \u2212\ns s+A[0]\n\u2190\nfork 1to jdo\n\u2190\ns s+A[k]\n\u2190\nifB[i]=sthen\nc c+1\n\u2190\nreturnc\nCodeFragment4.6: Somealgorithms.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 188 \u2014 #210\ni i\n188 Chapter4. AnalysisTools\nR-4.24 Showthatifd(n)isO(f(n))and e(n)isO(g(n)), thend(n) e(n) isnot\n\u2212\nnecessarily O(f(n) g(n)).\n\u2212\nR-4.25 Showthatifd(n)isO(f(n))and f(n)isO(g(n)),thend(n)isO(g(n)).\nR-4.26 ShowthatO(max f(n),g(n) )=O(f(n)+g(n)).\n{ }\nR-4.27 Showthat f(n)isO(g(n))ifandonlyifg(n)is\u2126(f(n)).\nR-4.28 Showthatif p(n)isapolynomial inn,thenlogp(n)isO(logn).\nR-4.29 Showthat(n+1)5 isO(n5).\nR-4.30 Showthat2n+1 isO(2n).\nR-4.31 ShowthatnisO(nlogn).\nR-4.32 Showthatn2 is\u2126(nlogn).\nR-4.33 Showthatnlognis\u2126(n).\nR-4.34 Showthat f(n) isO(f(n)),if f(n)isapositivenondecreasing function\n\u2308 \u2309\nthatisalwaysgreaterthan1.\nR-4.35 Algorithm A executes an O(logn)-time computation for each entry of an\nn-elementarray. Whatistheworst-caserunning timeofAlgorithmA?\nR-4.36 Given an n-element array X, Algorithm B chooses logn elements in X\nat random and executes an O(n)-time calculation for each. What is the\nworst-case runningtimeofAlgorithm B?\nR-4.37 Given an n-element array X of integers, Algorithm C executes an O(n)-\ntimecomputation foreach evennumber inX,and an O(logn)-time com-\nputationforeachoddnumberinX. Whatarethebest-caseandworst-case\nrunning timesofAlgorithmC?\nR-4.38 Given an n-element array X, Algorithm D calls Algorithm E on each el-\nement X[i]. Algorithm E runs in O(i) time when it is called on element\nX[i].Whatistheworst-case runningtimeofAlgorithm D?\nR-4.39 Al and Bob are arguing about their algorithms. Al claims his O(nlogn)-\ntimemethodisalwaysfasterthanBob\u2019sO(n2)-timemethod. Tosettlethe\nissue, theyperform asetofexperiments. ToAl\u2019sdismay, theyfindthatif\nn<100, the O(n2)-time algorithm runs faster, and only when n 100 is\n\u2265\ntheO(nlogn)-timeonebetter. Explainhowthisispossible.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 189 \u2014 #211\ni i\n4.4. Exercises 189\nCreativity\nC-4.1 Describe a recursive algorithm to compute the integer part of the base-2\nlogarithm ofnusingonlyadditionandintegerdivision.\nC-4.2 Describeanefficientrecursivemethodforsolvingtheelementuniqueness\nproblem,whichrunsintimethatisatmostO(n2)intheworstcasewithout\nusingsorting.\nC-4.3 Assuming it is possible to sort nnumbers in O(nlogn) time, show that it\nis possible to solve the three-way set disjointness problem in O(nlogn)\ntime.\nC-4.4 Describe an efficient algorithm for finding the 10 largest elements in an\narrayofsizen. Whatistherunning timeofyouralgorithm?\nC-4.5 Suppose you are given an n-element array A containing distinct integers\nthatarelisted inincreasing order. Givenanumberk,describe arecursive\nalgorithm to find two integers in A that sum to k, if such a pair exists.\nWhatistherunningtimeofyouralgorithm?\nC-4.6 Given an n-element unsorted array A of n integers and an integer k, de-\nscribe a recursive algorithm for rearranging the elements in A so that all\nelements less than or equal to k come before any elements larger than k.\nWhatistherunningtimeofyouralgorithm?\nC-4.7 Communication security is extremely important in computer networks,\nand one way manynetwork protocols achieve security is to encrypt mes-\nsages. Typicalcryptographic schemesforthesecuretransmissionofmes-\nsagesoversuchnetworksarebasedonthefactthatnoefficientalgorithms\nareknownforfactoringlargeintegers. Hence,ifwecanrepresentasecret\nmessage by a large prime number p, we can transmit, over the network,\nthenumberr= p q,whereq> pisanotherlargeprimenumberthatacts\n\u00b7\nastheencryption key. Aneavesdropper whoobtainsthetransmittednum-\nberronthenetworkwouldhavetofactorrinordertofigureoutthesecret\nmessage p.\nUsing factoring to figure out amessage is very difficult without knowing\nthe encryption key q. To understand why, consider the following naive\nfactoring algorithm:\nfor p=2, ,r 1do\n\u00b7\u00b7\u00b7 \u2212\nif pdividesrthen\nreturn\u201cThesecretmessageis p!\u201d\na. Suppose that the eavesdropper uses the above algorithm and has a\ncomputer that can carry out in 1 microsecond (1 millionth of a sec-\nond)adivisionbetweentwointegersofupto100bitseach. Givean\nestimateofthetimethatitwilltakeintheworstcasetodecipherthe\nsecretmessage pifthetransmittedmessagerhas100bits.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 190 \u2014 #212\ni i\n190 Chapter4. AnalysisTools\nb. What is the worst-case time complexity of the above algorithm?\nSince the input to the algorithm is just one large number r, assume\nthattheinputsizenisthenumberofbytesneeded tostorer,thatis,\nn= (log r)/8 +1,andthateachdivision takestimeO(n).\n\u230a 2 \u230b\nC-4.8 Giveanexampleofapositivefunction f(n)suchthat f(n)isneitherO(n)\nnor\u2126(n).\nC-4.9 Showthat\u2211n i2 isO(n3).\ni=1\nC-4.10 Showthat\u2211n i/2i <2.\ni=1\n(Hint: Trytoboundthissumtermbytermwithageometricprogression.)\nC-4.11 Showthatlog f(n)is\u0398(log f(n))ifb>1isaconstant.\nb\nC-4.12 Describeamethodforfindingboththeminimumandmaximumofnnum-\nbersusingfewerthan3n/2comparisons.\n(Hint: Firstconstructagroupofcandidateminimumsandagroupofcan-\ndidatemaximums.)\nC-4.13 Bob built a Web site and gave the URL only to his n friends, which he\nnumbered from 1 to n. He told friend number i that he/she can visit the\nWeb site at most i times. Now Bob has a counter, C, keeping track of\nthe total number of visits to the site (but not the identities of who visits).\nWhat isthe minimum value forC such that Bobshould know that one of\nhisfriendshasvisitedhis/hermaximumallowednumberoftimes?\nC-4.14 Alsayshecanprovethatallsheepinaflockarethesamecolor:\nBasecase: Onesheep. Itisclearlythesamecolorasitself.\nInduction step: A flock of n sheep. Take a sheep, a, out. The remaining\nn 1 are all the same color by induction. Now put sheep a back in and\n\u2212\ntake out a different sheep, b. By induction, the n 1 sheep (now with a)\n\u2212\nare all the same color. Therefore, all the sheep in the flock are the same\ncolor.\nWhatiswrongwithAl\u2019s\u201cjustification\u201d?\nC-4.15 Consider the following \u201cjustification\u201d that the Fibonacci function, F(n)\n(seeProposition 4.20)isO(n):\nBasecase(n 2): F(1)=1andF(2)=2.\n\u2264\nInduction step (n > 2): Assume the claim true for n\u2032 < n. Consider n.\nF(n) = F(n 1)+F(n 2). By induction, F(n 1) is O(n 1) and\n\u2212 \u2212 \u2212 \u2212\nF(n 2) is O(n 2). Then, F(n)is O((n 1)+(n 2)), bythe identity\n\u2212 \u2212 \u2212 \u2212\npresented inExerciseR-4.23. Therefore, F(n)isO(n).\nWhatiswrongwiththis\u201cjustification\u201d?\nC-4.16 Let p(x)beapolynomial ofdegreen,thatis, p(x)=\u2211n axi.\ni=0 i\n(a)DescribeasimpleO(n2)timemethodforcomputing p(x).\n(b)Nowconsider arewritingof p(x)as\np(x)=a +x(a +x(a +x(a + +x(a +xa ) ))),\n0 1 2 3 n\u22121 n\n\u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 191 \u2014 #213\ni i\n4.4. Exercises 191\nwhich isknownasHorner\u2019s method. Using thebig-Oh notation, charac-\nterizethenumberofarithmetic operations thismethodexecutes.\nC-4.17 Consider the Fibonacci function, F(n) (see Proposition 4.20). Show by\ninduction thatF(n)is\u2126((3/2)n).\nC-4.18 Given a set A= a ,a ,...,a of n integers, describe, in pseudo-code,\n1 2 n\n{ }\nan efficient method for computing each of partial sums s =\u2211k a, for\nk i=1 i\nk=1,2,...,n. Whatistherunningtimeofthismethod?\nC-4.19 Draw a visual justification of Proposition 4.3 analogous to that of Fig-\nure4.1(b)forthecasewhennisodd.\nC-4.20 An array A contains n 1 unique integers in the range [0,n 1], that is,\n\u2212 \u2212\nthere is one number from this range that is not in A. Design an O(n)-\ntimealgorithm forfindingthatnumber. YouareonlyallowedtouseO(1)\nadditional spacebesidesthearrayAitself.\nC-4.21 Let S be a set of n lines in the plane such that no two are parallel and\nno three meet in the same point. Show, by induction, that the lines in S\ndetermine\u0398(n2)intersection points.\nC-4.22 Showthatthesummation\u2211n log i isO(nlogn).\ni=1\u2308 2 \u2309\nC-4.23 An evil king has n bottles of wine, and a spy has just poisoned one of\nthem. Unfortunately, theydon\u2019t know whichoneitis. Thepoison isvery\ndeadly; just one drop diluted even abillion toone willstill kill. Evenso,\nit takes a full month for the poison to take effect. Design a scheme for\ndetermining exactly which one of the wine bottles was poisoned in just\nonemonth\u2019stimewhileexpending O(logn)tastetesters.\nC-4.24 AnarrayAcontains nintegers takenfromtheinterval[0,4n], withrepeti-\ntions allowed. Describe an efficient algorithm for determining an integer\nvalue k that occurs themost often in A. Whatis therunning timeofyour\nalgorithm?\nC-4.25 Describe, in pseudo-code, a method for multiplying an n m matrix A\n\u00d7\nand an m p matrix B. Recall that the productC=ABisdefined so that\n\u00d7\nC[i][j]=\u2211m A[i][k] B[k][j]. Whatistherunningtimeofyourmethod?\nk=1 \u00b7\nC-4.26 Suppose each rowofann narrayAconsists of1\u2019sand0\u2019ssuch that, in\n\u00d7\nanyrowiofA,allthe1\u2019scomebeforeany0\u2019s. Alsosupposethatthenum-\nberof1\u2019sinrowiisatleastthenumberinrowi+1,fori=0,1,...,n 2.\n\u2212\nAssuming A is already in memory, describe a method running in O(n)\ntime(notO(n2))forcounting thenumberof1\u2019sinA.\nC-4.27 Describe a recursive function for computing the nth Harmonic number,\nH =\u2211n 1/i.\nn i=1\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 192 \u2014 #214\ni i\n192 Chapter4. AnalysisTools\nProjects\nP-4.1 Implement prefixAverages1 and prefixAverages2 from Section 4.2.5, and\nperform an experimental analysis of their running times. Visualize their\nrunning timesasafunction oftheinputsizewithalog-logchart.\nP-4.2 Performacarefulexperimentalanalysisthatcomparestherelativerunning\ntimesofthefunctions showninCodeFragments4.6.\nP-4.3 PerformanexperimentalanalysistotestthehypothesisthattheSTLfunc-\ntion,sort,runsinO(nlogn)timeonaverage.\nP-4.4 Perform an experimental analysis to determine the largest value of n for\neach of the three algorithms given in the chapter for solving the element\nuniqueness problem such that the given algorithm runs in one minute or\nless.\nChapter Notes\nThe big-Oh notation has prompted several comments about its proper use [15, 43, 58].\nKnuth[59,58]definesitusingthenotation f(n)=O(g(n)),butsaysthis\u201cequality\u201disonly\n\u201cone way.\u201d We have chosen to take a more standard view of equality and view the big-\nOh notationas a set, followingBrassard [15]. Thereaderinterestedin studyingaverage-\ncase analysis is referred to the book chapter by Vitter and Flajolet [101]. We found the\nstory about Archimedesin [78]. For some additional mathematicaltools, please refer to\nAppendixA.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 193 \u2014 #215\ni i\nChapter\n5\nStacks, Queues, and Deques\nContents\n5.1 Stacks . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n5.1.1 The Stack Abstract Data Type . . . . . . . . . . . . 195\n5.1.2 The STL Stack . . . . . . . . . . . . . . . . . . . . 196\n5.1.3 A C++ Stack Interface . . . . . . . . . . . . . . . . 196\n5.1.4 A Simple Array-Based Stack Implementation . . . . 198\n5.1.5 Implementing a Stack with a Generic Linked List . . 202\n5.1.6 Reversing a Vector Using a Stack. . . . . . . . . . . 203\n5.1.7 Matching Parentheses and HTML Tags . . . . . . . 204\n5.2 Queues . . . . . . . . . . . . . . . . . . . . . . . . . . 208\n5.2.1 The Queue Abstract Data Type . . . . . . . . . . . 208\n5.2.2 The STL Queue . . . . . . . . . . . . . . . . . . . . 209\n5.2.3 A C++ Queue Interface . . . . . . . . . . . . . . . . 210\n5.2.4 A Simple Array-Based Implementation . . . . . . . . 211\n5.2.5 Implementing a Queue with a Circularly Linked List . 213\n5.3 Double-Ended Queues . . . . . . . . . . . . . . . . . . 217\n5.3.1 The Deque Abstract Data Type . . . . . . . . . . . 217\n5.3.2 The STL Deque . . . . . . . . . . . . . . . . . . . . 218\n5.3.3 Implementing a Deque with a Doubly Linked List . . 218\n5.3.4 Adapters and the Adapter Design Pattern . . . . . . 220\n5.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 223\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 194 \u2014 #216\ni i\n194 Chapter5. Stacks,Queues,andDeques\n5.1 Stacks\nAstackisacontainerofobjectsthatareinsertedandremovedaccordingtothelast-\nin first-out (LIFO)principle. Objects can be inserted into astack at any time, but\nonly the most recently inserted (that is, \u201clast\u201d) object can be removed at any time.\nThe name \u201cstack\u201d is derived from the metaphor of a stack of plates in a spring-\nloaded, cafeteria plate dispenser. In this case, the fundamental operations involve\nthe \u201cpushing\u201d and \u201cpopping\u201d of plates on the stack. When we need a new plate\nfrom the dispenser, we\u201cpop\u201d the top plate offthe stack, and whenweadd aplate,\nwe\u201cpush\u201ditdownonthestacktobecomethenewtopplate. Perhapsanevenmore\namusing metaphor would be a PEZ(cid:13)R candy dispenser, which stores mint candies\nin a spring-loaded container that \u201cpops\u201d out the top-most candy in the stack when\nthe top of the dispenser is lifted. (See Figure 5.1.) Stacks are a fundamental data\nstructure. Theyareusedinmanyapplications, including thefollowing.\nExample 5.1: InternetWebbrowsersstoretheaddressesofrecentlyvisitedsites\nonastack.Eachtimeauservisitsanewsite,thatsite\u2019saddressis\u201cpushed\u201dontothe\nstackofaddresses. Thebrowserthenallowstheuserto\u201cpop\u201dbacktopreviously\nvisitedsitesusingthe\u201cback\u201dbutton.\nExample 5.2: Texteditorsusuallyprovidean\u201cundo\u201dmechanismthatcancelsre-\ncenteditingoperationsandrevertstoformerstatesofadocument.Thisundooper-\nationcanbeaccomplishedbykeepingtextchangesinastack.\nFigure5.1: A schematic drawing ofaPEZ(cid:13)R dispenser; aphysical implementation\nofthestackADT.(PEZ(cid:13)R isaregistered trademarkofPEZCandy,Inc.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 195 \u2014 #217\ni i\n5.1. Stacks 195\n5.1.1 The Stack Abstract Data Type\nStacks are the simplest of all data structures, yet they are also among the most\nimportant, since theyareused inahostofdifferent applications thatinclude many\nmoresophisticateddatastructures. Formally,astackisanabstractdatatype(ADT)\nthatsupports thefollowingoperations:\npush(e): Insertelementeatthetopofthestack.\npop(): Remove the top element from the stack; an error occurs\nifthestackisempty.\ntop(): Return areference tothetopelement onthestack, with-\noutremovingit;anerroroccursifthestackisempty.\nAdditionally, letusalsodefinethefollowingsupporting functions:\nsize(): Returnthenumberofelementsinthestack.\nempty(): Returntrueifthestackisemptyandfalseotherwise.\nExample 5.3: Thefollowingtableshowsaseriesofstackoperationsandtheir\neffectsonaninitiallyemptystackofintegers.\nOperation Output StackContents\npush(5) \u2013 (5)\npush(3) \u2013 (5,3)\npop() \u2013 (5)\npush(7) \u2013 (5,7)\npop() \u2013 (5)\ntop() 5 (5)\npop() \u2013 ()\npop() \u201cerror\u201d ()\ntop() \u201cerror\u201d ()\nempty() true ()\npush(9) \u2013 (9)\npush(7) \u2013 (9,7)\npush(3) \u2013 (9,7,3)\npush(5) \u2013 (9,7,3,5)\nsize() 4 (9,7,3,5)\npop() \u2013 (9,7,3)\npush(8) \u2013 (9,7,3,8)\npop() \u2013 (9,7,3)\ntop() 3 (9,7,3)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 196 \u2014 #218\ni i\n196 Chapter5. Stacks,Queues,andDeques\n5.1.2 The STL Stack\nThe Standard Template Library provides an implementation of a stack. The un-\nderlying implementation is based on the STL vector class, which is presented in\nSections 1.5.5 and 6.1.4. In order to declare an object of type stack, it is neces-\nsary to first include the definition file, which is called \u201cstack.\u201d As with the STL\nvector, the class stack ispart of the stdnamespace, so it is necessary either to use\n\u201cstd::stack\u201d or to provide a \u201cusing\u201d statement. The stack class is templated with\ntheclassoftheindividualelements. Forexample,thecodefragmentbelowdeclares\nastackofintegers.\n#include <stack>\nusing std::stack; // make stack accessible\nstack<int> myStack; // a stack of integers\nWe refer to the type of individual elements as the stack\u2019s base type. As with STL\nvectors, anSTLstackdynamically resizesitselfasnewelementsarepushedon.\nThe STL stack class supports the same operators as our interface. Below, we\nlist theprincipal member functions. Letsbedeclared to beanSTLvector, and let\nedenote asingle object whose type isthe same as the base type ofthe stack. (For\nexample,sisavectorofintegers, andeisaninteger.)\nsize(): Returnthenumberofelementsinthestack.\nempty(): Returntrueifthestackisemptyandfalseotherwise.\npush(e): Pusheontothetopofthestack.\npop(): Poptheelementatthetopofthestack.\ntop(): Returnareference totheelementatthetopofthestack.\nThere is one significant difference between the STL implementation and our\nown definitions of the stack operations. In the STL implementation, the result of\napplying either of the operations top or pop to an empty stack is undefined. In\nparticular, no exception is thrown. Even though no exception is thrown, it may\nverylikely result inyourprogram aborting. Thus, itisuptotheprogrammer tobe\nsurethatnosuchillegalaccesses areattempted.\n5.1.3 A C++ Stack Interface\nBefore discussing specific implementations of the stack, let us first consider how\nto define an abstract data type for a stack. When defining an abstract data type,\nourprincipalconcernisspecifyingtheApplicationProgrammingInterface(API),\nor simply interface, which describes the names of the public members that the\nADT must support and how they are to be declared and used. An interface is not\nacomplete description ofallthepublicmembers. Forexample, itdoesnotinclude\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 197 \u2014 #219\ni i\n5.1. Stacks 197\nthe private data members. Rather, it is a list of members that any implementation\nmust provide. The C++ programming language does not provide a simple method\nfor defining interfaces, and therefore, the interface defined here is not an official\nC++class. Itisofferedprincipally forthepurposeofillustration.\nTheinformal interface for the stack ADTis given inCodeFragment 5.1. This\ninterface defines a class template. Recall from Section 2.3 that such a definition\nimplies that the base type ofelement being stored in thestack willbe provided by\nthe user. In Code Fragment 5.1, this element type is indicated by E. For example,\nEmaybeanyfundamentaltype(suchasint,char,bool,anddouble),anybuilt-in\noruser-defined class(suchasstring),orapointer toanyofthese.\ntemplate <typename E>\nclass Stack // an interface for a stack\n{\npublic:\nint size() const; // number of items in stack\nbool empty() const; // is the stack empty?\nconst E& top() const throw(StackEmpty); // the top element\nvoid push(const E& e); // push x onto the stack\nvoid pop() throw(StackEmpty); // remove the top element\n;\n}\nCodeFragment5.1: AninformalStackinterface(notacompleteC++class).\nObserve that the member functions size, empty, and top are all declared to be\nconst, whichinforms the compiler that they donot alter thecontents of thestack.\nThememberfunctiontopreturnsaconstantreferencetothetopofthestack,which\nmeansthatitsvaluemaybereadbutnotwritten.\nNotethatpopdoesnotreturntheelementthatwaspopped. Iftheuserwantsto\nknowthisvalue,itisnecessary toperformatopoperationfirst,andsavethevalue.\nThe member function push takes a constant reference to an object of type E as its\nargument. Recall from Section 1.4 that this is the most efficient way of passing\nobjectstoafunction.\nAnerrorconditionoccurswhencallingeitherofthefunctionspoportoponan\nemptystack. ThisissignaledbythrowinganexceptionoftypeStackEmpty,which\nisdefinedinCodeFragment5.2.\n// Exception thrown on performing top or pop of an empty stack.\nclass StackEmpty : public RuntimeException\n{\npublic:\nStackEmpty(const string& err) : RuntimeException(err)\n{}\n;\n}\nCodeFragment5.2: Exceptionthrownbyfunctionspopandtopwhencalledonan\nemptystack. ThisclassisderivedfromRuntimeExceptionfromSection2.4.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 198 \u2014 #220\ni i\n198 Chapter5. Stacks,Queues,andDeques\n5.1.4 A Simple Array-Based Stack Implementation\nWecanimplementastackbystoringitselementsinanarray. Specifically,thestack\nin this implementation consists of an N-element array S plus an integer variable t\nthatgivestheindexofthetopelementinarrayS. (SeeFigure5.2.)\nS\n0 1 2 t N\u22121\nFigure5.2: Realization of a stack by means of an array S. The top element in the\nstackisstoredinthecellS[t].\nRecalling thatarrays inC++start atindex0, weinitializet to 1,anduse this\n\u2212\nvalue fort to identify when the stack is empty. Likewise, wecan use this variable\nto determine the number of elements in a stack (t+1). We also introduce a new\ntype of exception, called StackFull, to signal the error condition that arises if we\ntrytoinsertanewelementandthearraySisfull. ExceptionStackFullisspecificto\nourimplementation ofastackand isnotdefined inthestackADT.Giventhisnew\nexception, we can then implement the stack ADT functions as described in Code\nFragment5.3.\nAlgorithmsize():\nreturnt+1\nAlgorithmempty():\nreturn(t <0)\nAlgorithmtop():\nifempty()then\nthrowStackEmptyexception\nreturnS[t]\nAlgorithmpush(e):\nifsize()=N then\nthrowStackFullexception\nt t+1\n\u2190\nS[t] e\n\u2190\nAlgorithmpop():\nifempty()then\nthrowStackEmptyexception\nt t 1\n\u2190 \u2212\nCodeFragment5.3: Implementation ofastackbymeansofanarray.\nThecorrectnessofthefunctionsinthearray-basedimplementationfollowsim-\nmediately from the definition of the functions themselves. Table 5.1 shows the\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 199 \u2014 #221\ni i\n5.1. Stacks 199\nrunning times for member functions in a realization of a stack by an array. Each\nof the stack functions in the array realization executes a constant number of state-\nmentsinvolvingarithmeticoperations,comparisons,andassignments. Thus,inthis\nimplementationoftheStackADT,eachfunctionrunsinconstanttime,thatis,they\neachruninO(1)time.\nOperation Time\nsize O(1)\nempty O(1)\ntop O(1)\npush O(1)\npop O(1)\nTable5.1: Performanceofanarray-based stack. ThespaceusageisO(N),whereN\nisthearray\u2019ssize. Notethatthespaceusageisindependentfromthenumbern N\n\u2264\nofelementsthatareactually inthestack.\nA C++ Implementation of a Stack\nIn this section, we present a concrete C++ implementation of the above pseudo-\ncodespecification bymeansofaclass,calledArrayStack. Ourapproachistostore\nthe elements of a stack in an array. To keep the code simple, we have omitted the\nstandardhousekeeping utilities, suchasadestructor, anassignmentoperator, anda\ncopyconstructor. Weleavetheirimplementations asanexercise.\nWebeginbyproviding theArrayStackclassdefinition inCodeFragment5.4.\ntemplate <typename E>\nclass ArrayStack\n{\nenum DEF CAPACITY = 100 ; // default stack capacity\n{ }\npublic:\nArrayStack(int cap = DEF CAPACITY); // constructor from capacity\nint size() const; // number of items in the stack\nbool empty() const; // is the stack empty?\nconst E& top() const throw(StackEmpty); // get the top element\nvoid push(const E& e) throw(StackFull); // push element onto stack\nvoid pop() throw(StackEmpty); // pop the stack\n// ...housekeeping functions omitted\nprivate: // member data\nE* S; // array of stack elements\nint capacity; // stack capacity\nint t; // index of the top of the stack\n;\n}\nCodeFragment5.4: TheclassArrayStack,whichimplementstheStackinterface.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 200 \u2014 #222\ni i\n200 Chapter5. Stacks,Queues,andDeques\nInaddition tothemember functions required bythe interface, wealso provide\naconstructor, thatisgiventhedesiredcapacityofthestackasitsonlyargument. If\nnoargument isgiven, the default value given by DEF CAPACITY isused. Thisis\nan example of using default arguments in function calls. Weuse an enumeration\ntodefinethisdefault capacity value. Thisisthesimplestwayofdefining symbolic\nintegerconstants withinaC++class. Ourclassistemplated withtheelementtype,\ndenoted by E. The stack\u2019s storage, denoted S, is a dynamically allocated array of\ntypeE,thatis,apointer toE.\nNext, we present the implementations of the ArrayStackmember functions in\nCodeFragment5.5. Theconstructorallocatesthearraystorage,whosesizeissetto\nthedefaultcapacity. Thememberscapacityandt arealsosettotheirinitialvalues.\nIn spite of the syntactical complexities of defining templated member functions in\nC++,theremainingmemberfunctionsarestraightforwardimplementationsoftheir\ndefinitions in Code 5.3. Observe that functions top and pop first check that the\nstack is not empty, and otherwise, they throw an exception. Similarly, push first\nchecksthatthestackisnotfull,andotherwise,itthrowsanexception.\ntemplate <typename E> ArrayStack<E>::ArrayStack(int cap)\n: S(new E[cap]), capacity(cap), t( 1) // constructor from capacity\n\u2212 { }\ntemplate <typename E> int ArrayStack<E>::size() const\nreturn (t + 1); // number of items in the stack\n{ }\ntemplate <typename E> bool ArrayStack<E>::empty() const\nreturn (t < 0); // is the stack empty?\n{ }\ntemplate <typename E> // return top of stack\nconst E& ArrayStack<E>::top() const throw(StackEmpty)\n{\nif (empty()) throw StackEmpty(\"Top of empty stack\");\nreturn S[t];\n}\ntemplate <typename E> // push element onto the stack\nvoid ArrayStack<E>::push(const E& e) throw(StackFull)\n{\nif (size() == capacity) throw StackFull(\"Push to full stack\");\nS[++t] = e;\n}\ntemplate <typename E> // pop the stack\nvoid ArrayStack<E>::pop() throw(StackEmpty)\n{\nif (empty()) throw StackEmpty(\"Pop from empty stack\");\nt;\n\u2212\u2212\n}\nCodeFragment5.5: Implementations ofthememberfunctions ofclassArrayStack\n(excluding housekeeping functions).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 201 \u2014 #223\ni i\n5.1. Stacks 201\nExample Output\nIn Code Fragment 5.6 below, wepresent an example ofthe use of our ArrayStack\nclass. Todemonstrate theflexibilityofourimplementation, weshowtwostacksof\ndifferent base types. The instance A is a stack of integers of the default capacity\n(100). Theinstance Bisastackofcharacter stringsofcapacity10.\nArrayStack<int> A; // A = [], size = 0\nA.push(7); // A = [7*], size = 1\nA.push(13); // A = [7, 13*], size = 2\ncout << A.top() << endl; A.pop(); // A = [7*], outputs: 13\nA.push(9); // A = [7, 9*], size = 2\ncout << A.top() << endl; // A = [7, 9*], outputs: 9\ncout << A.top() << endl; A.pop(); // A = [7*], outputs: 9\nArrayStack<string> B(10); // B = [], size = 0\nB.push(\"Bob\"); // B = [Bob*], size = 1\nB.push(\"Alice\"); // B = [Bob, Alice*], size = 2\ncout << B.top() << endl; B.pop(); // B = [Bob*], outputs: Alice\nB.push(\"Eve\"); // B = [Bob, Eve*], size = 2\nCodeFragment5.6: An example of the use of the ArrayStack class. The contents\nofthestackareshowninthecommentfollowingtheoperation. Thetopofthestack\nisindicated byanasterisk(\u201c*\u201d).\nNote that our implementation, while simple and efficient, could be enhanced\nin a number of ways. For example, it assumes a fixed upper bound N on the ulti-\nmate size of the stack. In Code Fragment 5.4, wechose the default capacity value\nN =100moreorlessarbitrarily (although theusercansetthecapacity inthecon-\nstructor). An application may actually need much less space than the given initial\nsize,andthiswouldbewastefulofmemory. Alternatively,anapplicationmayneed\nmorespace than this, inwhichcase our stack implementation might\u201ccrash\u201d iftoo\nmanyelementsarepushedontothestack.\nFortunately,thereareotherimplementationsthatdonotimposeanarbitrarysize\nlimitation. One such method is to use the STL stack class, which was introduced\nearlier in this chapter. The STL stack is also based on the STL vector class, and\nit offers the advantage that it is automatically expanded when the stack overflows\nitscurrent storage limits. Inpractice, theSTLstack would betheeasiest andmost\npracticalwaytoimplementanarray-basedstack. Laterinthischapter,weseeother\nmethodsthatusespaceproportional totheactualsizeofthestack.\nIninstanceswherewehaveagoodestimateonthenumberofitemsneedingto\ngointhestack,thearray-basedimplementationishardtobeatfromtheperspective\nofspeedandsimplicity. Stacksserveavitalroleinanumberofcomputingapplica-\ntions, so it is helpful to have afast stack ADTimplementation, such as the simple\narray-based implementation.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 202 \u2014 #224\ni i\n202 Chapter5. Stacks,Queues,andDeques\n5.1.5 Implementing a Stack with a Generic Linked List\nInthissection,weshowhowtoimplementthestackADTusingasinglylinkedlist.\nOurapproachistousethegenericsinglylinkedlist,calledSLinkedList,whichwas\npresented earlier inSection 3.2.4. Thedefinition ofour stack, called LinkedStack,\nispresented inCodeFragment5.7.\nTo avoid the syntactic messiness inherent in C++ templated classes, we have\nchosennottoimplementafullygenerictemplated class. Instead, wehaveoptedto\ndefineatypeforthestack\u2019selements,calledElem. Inthisexample,wedefineElem\ntobeoftypestring. Weleavethetaskofproducing atrulygenericimplementation\nasanexercise. (SeeExerciseR-5.7.)\ntypedef string Elem; // stack element type\nclass LinkedStack // stack as a linked list\n{\npublic:\nLinkedStack(); // constructor\nint size() const; // number of items in the stack\nbool empty() const; // is the stack empty?\nconst Elem& top() const throw(StackEmpty); // the top element\nvoid push(const Elem& e); // push element onto stack\nvoid pop() throw(StackEmpty); // pop the stack\nprivate: // member data\nSLinkedList<Elem> S; // linked list of elements\nint n; // number of elements\n;\n}\nCodeFragment5.7: TheclassLinkedStack,alinkedlistimplementation ofastack.\nThe principal data member of the class is the generic linked list of type Elem,\ncalled S. Since theSLinkedListclass does notprovide amemberfunction size,we\nstorethecurrentsizeinamembervariable, n.\nIn Code Fragment 5.8, we present the implementations of the constructor and\nthe size and empty functions. Our constructor creates the initial stack and initial-\nizes n to zero. We do not provide an explicit destructor, relying instead on the\nSLinkedListdestructor todeallocate thelinkedlistS.\nLinkedStack::LinkedStack()\n: S(), n(0) // constructor\n{ }\nint LinkedStack::size() const\nreturn n; // number of items in the stack\n{ }\nbool LinkedStack::empty() const\nreturn n == 0; // is the stack empty?\n{ }\nCodeFragment5.8: Constructor andsizefunctions fortheLinkedStackclass.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 203 \u2014 #225\ni i\n5.1. Stacks 203\nThe definitions of the stack operations, top, push, and pop, are presented in\nCodeFragment5.9. Whichsideofthelist,headortail,shouldwechoseforthetop\nofthestack? SinceSLinkedListcaninsertanddeleteelementsinconstanttimeonly\nat the head, the head is clearly the better choice. Therefore, the member function\ntop returns S.front(). The functions push and pop invoke the functions addFront\nandremoveFront,respectively, andupdatethenumberofelements.\n// get the top element\nconst Elem& LinkedStack::top() const throw(StackEmpty)\n{\nif (empty()) throw StackEmpty(\"Top of empty stack\");\nreturn S.front();\n}\nvoid LinkedStack::push(const Elem& e) // push element onto stack\n{\n++n;\nS.addFront(e);\n}\n// pop the stack\nvoid LinkedStack::pop() throw(StackEmpty)\n{\nif (empty()) throw StackEmpty(\"Pop from empty stack\");\nn;\n\u2212\u2212\nS.removeFront();\n}\nCodeFragment5.9: Principaloperations fortheLinkedStackclass.\n5.1.6 Reversing a Vector Using a Stack\nWecan use astack toreverse the elements inavector, thereby producing anonre-\ncursive algorithm for the array-reversal problem introduced in Section 3.5.1. The\nbasic idea is to push all the elements of the vector in order into a stack and then\nfill the vector back up again by popping the elements off of the stack. In Code\nFragment5.10,wegiveaC++implementation ofthisalgorithm.\ntemplate <typename E>\nvoid reverse(vector<E>& V) // reverse a vector\n{\nArrayStack<E> S(V.size());\nfor (int i = 0; i < V.size(); i++) // push elements onto stack\nS.push(V[i]);\nfor (int i = 0; i < V.size(); i++) // pop them in reverse order\n{\nV[i] = S.top(); S.pop();\n}\n}\nCodeFragment5.10: Agenericfunction thatusesastacktoreverseavector.\nFor example, if the input vector to function reverse contained the five strings\n[Jack, Kate, Hurley, Jin, Michael],thenonreturning fromthefunction, thevector\nwouldcontain[Michael, Jin, Hurley, Kate, Jack].\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 204 \u2014 #226\ni i\n204 Chapter5. Stacks,Queues,andDeques\n5.1.7 Matching Parentheses and HTML Tags\nInthissection, weexplore tworelated applications ofstacks. Thefirstismatching\nparentheses and grouping symbols in arithmetic expressions. Arithmetic expres-\nsionscancontainvariouspairsofgrouping symbols,suchas\nParentheses: \u201c(\u201dand\u201c)\u201d\n\u2022\nBraces: \u201c \u201dand\u201c \u201d\n\u2022 { }\nBrackets: \u201c[\u201dand\u201c]\u201d\n\u2022\nFloorfunction symbols: \u201c \u201dand\u201c \u201d\n\u2022 \u230a \u230b\nCeilingfunctionsymbols: \u201c \u201dand\u201c ,\u201d\n\u2022 \u2308 \u2309\nand each opening symbol must match with its corresponding closing symbol. For\nexample,aleftbracketsymbol(\u201c[\u201d)mustmatchwithacorrespondingrightbracket\n(\u201c]\u201d)asinthefollowingexpression:\nCorrect: ()(()) ([()])\n\u2022 { }\nCorrect: ((()(()) ([()]) ))\n\u2022 { }\nIncorrect: )(()) ([()])\n\u2022 { }\nIncorrect: ( [])\n\u2022 { }\nIncorrect: (\n\u2022\nWeleavetheprecisedefinitionofmatchingofgroupingsymbolstoExerciseR-5.8.\nAn Algorithm for Parentheses Matching\nAn important problem in processing arithmetic expressions is to make sure their\ngroupingsymbolsmatchupcorrectly. WecanuseastackStoperformthematching\nof grouping symbols in an arithmetic expression with a single left-to-right scan.\nThe algorithm tests that left and right symbols match up and also that the left and\nrightsymbolsarebothofthesametype.\nSuppose wearegivenasequence X =x x x ...x ,whereeach x isatoken\n0 1 2 n\u22121 i\nthatcanbeagroupingsymbol,avariablename,anarithmeticoperator,oranumber.\nThebasic idea behind checking that the grouping symbols inS match correctly, is\ntoprocessthetokensinX inorder. Eachtimeweencounteranopeningsymbol,we\npushthatsymbolontoS,andeachtimeweencounteraclosingsymbol,wepopthe\ntopsymbolfromthestackS(assumingSisnotempty)andwecheckthatthesetwo\nsymbols are of corresponding types. (For example, if the symbol \u201c(\u201d was pushed,\nthe symbol \u201c)\u201dshould beitsmatch.) Ifthestack isemptyafter wehave processed\nthewholesequence, thenthesymbolsinX match.\nAssumingthatthepushandpopoperations areimplementedtoruninconstant\ntime, this algorithm runs inO(n)total time. Wegive apseudo-code description of\nthisalgorithm inCodeFragment5.11.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 205 \u2014 #227\ni i\n5.1. Stacks 205\nAlgorithmParenMatch(X,n):\nInput: An array X of n tokens, each of which is either a grouping symbol, a\nvariable, anarithmeticoperator, oranumber\nOutput: trueifandonlyifallthegrouping symbolsinX match\nLetSbeanemptystack\nfori 0ton 1do\n\u2190 \u2212\nifX[i]isanopening grouping symbolthen\nS.push(X[i])\nelseifX[i]isaclosinggrouping symbolthen\nifS.empty()then\nreturnfalse nothing tomatchwith\n{ }\nifS.top()doesnotmatchthetypeofX[i]then\nreturnfalse wrongtype\n{ }\nS.pop()\nifS.empty()then\nreturntrue everysymbolmatched\n{ }\nelse\nreturnfalse somesymbolswerenevermatched\n{ }\nCode Fragment 5.11: Algorithm for matching grouping symbols in an arithmetic\nexpression.\nMatching Tags in an HTML Document\nAnother application in which matching is important is in the validation of HTML\ndocuments. HTML is the standard format for hyperlinked documents on the In-\nternet. In an HTML document, portions of text are delimited by HTML tags. A\nsimple opening HTMLtag has the form \u201c<name>\u201d and the corresponding closing\ntaghastheform\u201c</name>.\u201d CommonlyusedHTMLtagsinclude:\nbody: document body\n\u2022\nh1: sectionheader\n\u2022\ncenter: centerjustify\n\u2022\np: paragraph\n\u2022\nol: numbered(ordered) list\n\u2022\nli: listitem\n\u2022\nWe show a sample HTML document and a possible rendering in Figure 5.3. Our\ngoalistowriteaprogramtocheckthatthetagsproperlymatch.\nA very similar approach to that given in Code Fragment 5.11 can be used to\nmatch the tags in an HTMLdocument. We push each opening tag on a stack, and\nwhen we encounter a closing tag, we pop the stack and verify that the two tags\nmatch.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 206 \u2014 #228\ni i\n206 Chapter5. Stacks,Queues,andDeques\n<body>\n<center>\n<h1> The Little Boat </h1> The Little Boat\n</center>\n<p> The storm tossed the little\nThe storm tossed the little boat\nboat like a cheap sneaker in an\nlike a cheap sneaker in an old\nold washing machine. The three\nwashing machine. The three\ndrunken fishermen were used to\nsuch treatment, of course, but drunken fishermen were used to\nnot the tree salesman, who even suchtreatment,ofcourse,butnot\nas a stowaway now felt that he the tree salesman, who even as\nhad overpaid for the voyage. </p> a stowaway now felt that he had\n<ol>\noverpaidforthevoyage.\n<li> Will the salesman die? </li>\n1. Willthesalesmandie?\n<li> What color is the boat? </li>\n2. Whatcoloristheboat?\n<li> And what about Naomi? </li>\n</ol> 3. AndwhataboutNaomi?\n</body>\n(a) (b)\nFigure5.3: HTMLtags: (a)anHTMLdocument;(b)itsrendering.\nInCodeFragments5.12through5.14,wepresentaC++programformatching\ntags in an HTML document read from the standard input stream. For simplicity,\nweassumethatalltagsaresyntactically wellformed.\nFirst, the procedure getHtmlTags reads the input line by line, extracts all the\ntagsasstrings, andstorestheminavector, whichitreturns.\nvector<string> getHtmlTags() // store tags in a vector\n{\nvector<string> tags; // vector of html tags\nwhile (cin) // read until end of file\n{\nstring line;\ngetline(cin, line); // input a full line of text\nint pos = 0; // current scan position\nint ts = line.find(\"<\", pos); // possible tag start\nwhile (ts != string::npos) // repeat until end of string\n{\nint te = line.find(\">\", ts+1); // scan for tag end\ntags.push back(line.substr(ts, te ts+1)); // append tag to the vector\n\u2212\npos = te + 1; // advance our position\nts = line.find(\"<\", pos);\n}\n}\nreturn tags; // return vector of tags\n}\nCodeFragment5.12: GetavectorofHTMLtagsfromtheinput, andstore themin\navectorofstrings.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 207 \u2014 #229\ni i\n5.1. Stacks 207\nGiven the example shown in Figure 5.3(a), this procedure would return the\nfollowingvector:\n<body>,<center>,<h1>,</h1>,</center>,...,</body>\nIn Code Fragment 5.12, we employ a variable pos, which maintains the current\nposition intheinputline. Weusethebuilt-in stringmemberfunction findtolocate\nthefirstoccurrence of\u201c<\u201dthat follows thecurrent position. (Recall thediscussion\nof string operations from Section 1.5.5.) This tag start position is stored in the\nvariablets. Wethenfindthenextoccurrence of\u201c>,\u201dandstorethistagendposition\ninte. Thetagitselfconsistsofthesubstringoflengthte ts+1startingatposition\n\u2212\nts. This is pushed onto the vector tags. We then update the current position to be\nte+1andrepeatuntilwefindnofurther occurrences of\u201c<.\u201d Thisoccurswhenthe\nfindfunction returnsthespecialvaluestring::npos.\nNext, the procedure isHtmlMatched, shown in Code Fragments 5.12, imple-\nmentstheprocessofmatchingthetags.\n// check for matching tags\nbool isHtmlMatched(const vector<string>& tags)\n{\nLinkedStack S; // stack for opening tags\ntypedef vector<string>::const iterator Iter;// iterator type\n// iterate through vector\nfor (Iter p = tags.begin(); p != tags.end(); ++p)\n{\nif (p >at(1) != \u2019/\u2019) // opening tag?\n\u2212\nS.push(*p); // push it on the stack\nelse // else must be closing tag\n{\nif (S.empty()) return false; // nothing to match - failure\nstring open = S.top().substr(1); // opening tag excluding \u2019<\u2019\nstring close = p >substr(2); // closing tag excluding \u2019</\u2019\n\u2212\nif (open.compare(close) != 0) return false; // fail to match\nelse S.pop(); // pop matched element\n}\n}\nif (S.empty()) return true; // everything matched - good\nelse return false; // some unmatched - bad\n}\nCode Fragment 5.13: Check whether HTML tags stored in the vector tags are\nmatched.\nWecreateastack,calledS,inwhichwestoretheopeningtags. Wetheniterate\nthrough thevector oftags. Ifthesecond character tagstring isnot \u201c/,\u201dthen thisis\nan opening tag, and it is pushed onto the stack. Otherwise, it is a closing tag, and\nwe check that it matches the tag on top of the stack. Tocompare the opening and\nclosingtags,weusethestringsubstrmemberfunctiontostripthefirstcharacteroff\ntheopening tag(thusremovingthe\u201c<\u201d)andthefirsttwocharacters offtheclosing\ntag (thus removing the \u201c</\u201d). Wecheck thatthese twosubstrings areequal, using\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 208 \u2014 #230\ni i\n208 Chapter5. Stacks,Queues,andDeques\nthebuilt-instringfunctioncompare. Whentheloopterminates,weknowthatevery\nclosing tag matches its corresponding opening tag. To finish the job, we need to\ncheckthattherewerenounmatchedopeningtags. Wetestthisbycheckingthatthe\nstackisnowempty.\nFinally, the main program is presented in Code Fragment 5.14. It invokes the\nfunction getHtmlTags toread the tags, and then itpasses these toisHtmlMatched\ntotestthem.\nint main() // main HTML tester\n{\nif (isHtmlMatched(getHtmlTags())) // get tags and test them\ncout << \"The input file is a matched HTML document.\" << endl;\nelse\ncout << \"The input file is not a matched HTML document.\" << endl;\n}\nCode Fragment 5.14: The main program to test whether the input file consists of\nmatchingHTMLtags.\n5.2 Queues\nAnother fundamental data structure is the queue, which is a close relative of the\nstack. A queue is acontainer of elements that areinserted and removed according\ntothefirst-infirst-out(FIFO)principle. Elementscanbeinsertedinaqueueatany\ntime,butonlytheelementthathasbeeninthequeuethelongestcanberemovedat\nanytime. Weusuallysaythatelementsenterthequeueattherearandareremoved\nfromthefront. Themetaphorforthisterminologyisalineofpeoplewaitingtoget\non anamusement park ride. People enter atthe rear ofthe line and geton the ride\nfromthefrontoftheline.\n5.2.1 The Queue Abstract Data Type\nFormally, the queue abstract data type defines a container that keeps elements in\na sequence, where element access and deletion are restricted to the first element\nin the sequence, which is called the front of the queue, and element insertion is\nrestricted to the end of the sequence, which is called the rear of the queue. This\nrestrictionenforcestherulethatitemsareinsertedanddeletedinaqueueaccording\ntothefirst-infirst-out(FIFO)principle.\nThequeueabstract datatype(ADT)supports thefollowingoperations:\nenqueue(e): Insertelementeattherearofthequeue.\ndequeue(): Removeelementatthefrontofthequeue;anerroroccurs\nifthequeueisempty.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 209 \u2014 #231\ni i\n5.2. Queues 209\nfront(): Return, but do not remove, a reference to the front ele-\nmentinthequeue;anerroroccursifthequeueisempty.\nThequeueADTalsoincludesthefollowingsupporting memberfunctions:\nsize(): Returnthenumberofelementsinthequeue.\nempty(): Returntrueifthequeueisemptyandfalseotherwise.\nWeillustrate theoperations inthequeueADTinthefollowingexample.\nExample 5.4: Thefollowingtableshowsaseriesofqueueoperationsandtheir\neffectsonaninitiallyemptyqueue,Q,ofintegers.\nOperation Output front Q rear\n\u2190 \u2190\nenqueue(5) \u2013 (5)\nenqueue(3) \u2013 (5,3)\nfront() 5 (5,3)\nsize() 2 (5,3)\ndequeue() \u2013 (3)\nenqueue(7) \u2013 (3,7)\ndequeue() \u2013 (7)\nfront() 7 (7)\ndequeue() \u2013 ()\ndequeue() \u201cerror\u201d ()\nempty() true ()\n5.2.2 The STL Queue\nThe Standard Template Library provides an implementation of a queue. As with\nthe STL stack, the underlying implementation is based on the STL vector class\n(Sections 1.5.5 and 6.1.4). In order todeclare anobject oftype queue, itis neces-\nsary to first include the definition file, which is called \u201cqueue.\u201d As with the STL\nvector, theclassqueueispartofthestdnamespace, soitisnecessary either touse\n\u201cstd::queue\u201d or to provide an appropriate \u201cusing\u201d statement. The queue class is\ntemplated with the base type of the individual elements. For example, the code\nfragmentbelowdeclaresaqueueoffloats.\n#include <queue>\nusing std::queue; // make queue accessible\nqueue<float> myQueue; // a queue of floats\nAs with instances of STL vectors and stacks, an STL queue dynamically resizes\nitselfasnewelementsareadded.\nThe STL queue supports roughly the same operators as our interface, but the\nsyntax and semantics are slightly different. Below, we list the principal member\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 210 \u2014 #232\ni i\n210 Chapter5. Stacks,Queues,andDeques\nfunctions. Let q be declared to be an STL queue, and let e denote a single object\nwhosetypeisthesameasthebasetypeofthequeue. (Forexample,qisaqueueof\nfloats,andeisafloat.)\nsize(): Returnthenumberofelementsinthequeue.\nempty(): Returntrueifthequeueisemptyandfalseotherwise.\npush(e): Enqueueeattherearofthequeue.\npop(): Dequeuetheelementatthefrontofthequeue.\nfront(): Returnareference totheelementatthequeue\u2019sfront.\nback(): Returnareference totheelementatthequeue\u2019srear.\nUnlike our queue interface, the STL queue provides access to both the front\nand back of the queue. Similar to the STL stack, the result of applying any of\nthe operations front, back, or pop to an empty STL queue is undefined. Unlike\nour interface, no exception is thrown, but it may very likely result in the program\naborting. It is up to the programmer to be sure that no such illegal accesses are\nattempted.\n5.2.3 A C++ Queue Interface\nOurinterfaceforthequeueADTisgiveninCodeFragment5.15. Aswiththestack\nADT, the class is templated. The queue\u2019s base element type E is provided by the\nuser.\ntemplate <typename E>\nclass Queue // an interface for a queue\n{\npublic:\nint size() const; // number of items in queue\nbool empty() const; // is the queue empty?\nconst E& front() const throw(QueueEmpty); // the front element\nvoid enqueue (const E& e); // enqueue element at rear\nvoid dequeue() throw(QueueEmpty); // dequeue element at front\n;\n}\nCodeFragment5.15: AninformalQueueinterface (notacompleteC++class).\nNote that the size and empty functions have the same meaning as their coun-\nterparts in the Stack ADT. These two member functions and front are known as\naccessor functions, for they return a value and do not change the contents of the\ndatastructure. AlsonotetheuseoftheexceptionQueueEmptytoindicatetheerror\nstateofanemptyqueue.\nThe member functions size, empty, and front are all declared to be const,\nwhich informs the compiler that they do not alter the contents of the queue. Note\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 211 \u2014 #233\ni i\n5.2. Queues 211\nthatthememberfunctionfrontreturnsaconstantreferencetothetopofthequeue.\nAnerrorconditionoccurswhencallingeitherofthefunctionsfrontordequeue\nonanemptyqueue. ThisissignaledbythrowinganexceptionQueueEmpty,which\nisdefinedinCodeFragment5.16.\nclass QueueEmpty : public RuntimeException\n{\npublic:\nQueueEmpty(const string& err) : RuntimeException(err)\n{ }\n;\n}\nCodeFragment5.16: Exception thrownbyfunctions frontordequeuewhencalled\nonanemptyqueue. ThisclassisderivedfromRuntimeExceptionfromSection2.4.\n5.2.4 A Simple Array-Based Implementation\nWepresent asimple realization of a queue by means of an array, Q, with capacity\nN, for storing its elements. The main issue with this implementation is deciding\nhowtokeeptrackofthefrontandrearofthequeue.\nOnepossibility istoadapt theapproach weusedforthestack implementation.\nIn particular, let Q[0] be the front of the queue and have the queue grow from\nthere. This is not an efficient solution, however, for it requires that we move all\nthe elements forward one array cell each time we perform a dequeue operation.\nSuchanimplementationwouldthereforerequire\u0398(n)timetoperformthedequeue\nfunction, where n is the current number of elements in the queue. If we want to\nachieveconstanttimeforeachqueuefunction, weneedadifferent approach.\nUsing an Array in a Circular Way\nToavoidmovingobjectsoncetheyareplaced inQ,wedefinethreevariables, f,r,\nn,whichhavethefollowingmeanings:\nf is the index of the cell of Q storing the front of the queue. If the queue is\n\u2022\nnonempty, thisistheindexoftheelementtoberemovedbydequeue.\nr isan index ofthecell ofQfollowing the rearof thequeue. Ifthe queue is\n\u2022\nnotfull,thisistheindexwheretheelementisinserted byenqueue.\nnisthecurrentnumberofelementsinthequeue.\n\u2022\nInitially, we set n= 0 and f = r =0, indicating an empty queue. When we\ndequeue an element from the front of the queue, we decrement nand increment f\ntothe next cell inQ. Likewise, when weenqueue anelement, weincrement r and\nincrement n. This allows us to implement the enqueue and dequeue functions in\nconstant time\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 212 \u2014 #234\ni i\n212 Chapter5. Stacks,Queues,andDeques\nNonetheless, thereisstillaproblemwiththisapproach. Consider,forexample,\nwhat happens if we repeatedly enqueue and dequeue a single element N different\ntimes. We would have f = r = N. If we were then to try to insert the element\njust one more time, we would get an array-out-of-bounds error, even though there\nis plenty of room in the queue in this case. To avoid this problem and be able to\nutilize all of the array Q, we let the f and r indices \u201cwrap around\u201d the end of Q.\nThat is, we now view Q as a \u201ccircular array\u201d that goes from Q[0] to Q[N 1] and\n\u2212\nthenimmediately backtoQ[0]again. (SeeFigure5.4.)\n0 1 2 f r N\u22121 0 1 2 r f N\u22121\n(a) (b)\nFigure5.4: UsingarrayQinacircularfashion: (a)the\u201cnormal\u201dconfigurationwith\nf r;(b)the\u201cwrappedaround\u201d configuration withr< f. Thecellsstoring queue\n\u2264\nelementsareshaded.\nUsing the Modulo Operator to Implement a Circular Array\nImplementing this circular view of Q is actually pretty easy. Each time we in-\ncrement f or r, we simply need to compute this increment as \u201c(f +1) mod N\u201d\nor \u201c(r+1)mod N,\u201d respectively, where the operator \u201cmod\u201d is the modulo oper-\nator. This operator is computed for a positive number by taking the remainder\nafter an integral division. For example, 48 divided by 5 is 9 with remainder 3,\nso 48 mod 5=3. Specifically, given integers x and y, such that x 0 and y>0,\n\u2265\nx mod y is the unique integer 0 r <y such that x=qy+r, for some integer q.\n\u2264\nRecallthatC++uses\u201c%\u201dtodenotethemodulooperator.\nWe present our implementation in Code Fragment 5.17. Note that we have\nintroduced anewexception, calledQueueFull,tosignalthatnomoreelementscan\nbe inserted in the queue. Our implementation of a queue by means of an array is\nsimilartothatofastack, andisleftasanexercise.\nThe array-based queue implementation is quite efficient. All of the operations\nofthequeueADTareperformed inO(1)time. Thespaceusage isO(N),whereN\nis the size of the array, determined at the time the queue is created. Note that the\nspaceusageisindependent fromthenumbern<N ofelementsthatareactuallyin\nthequeue.\nAs with the array-based stack implementation, the only real disadvantage of\nthe array-based queue implementation is that weartificially set the capacity of the\nqueue to be some number N. In a real application, we may actually need more\nor less queue capacity than this, but if we have a good estimate of the number of\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 213 \u2014 #235\ni i\n5.2. Queues 213\nAlgorithmsize():\nreturnn\nAlgorithmempty():\nreturn(n=0)\nAlgorithmfront():\nifempty()then\nthrowQueueEmptyexception\nreturnQ[f]\nAlgorithmdequeue():\nifempty()then\nthrowQueueEmptyexception\nf (f +1)mod N\n\u2190\nn=n 1\n\u2212\nAlgorithmenqueue(e):\nifsize()=N then\nthrowQueueFullexception\nQ[r] e\n\u2190\nr (r+1) mod N\n\u2190\nn=n+1\nCodeFragment5.17: Implementation ofaqueueusingacirculararray.\nelements that will be in the queue at the same time, then the array-based imple-\nmentation is quite efficient. One such possible application of a queue is dynamic\nmemoryallocation inC++,whichisdiscussed inChapter14.\n5.2.5 Implementing a Queue with a Circularly Linked List\nInthissection, wepresentaC++implementation ofthequeueADTusingalinked\nrepresentation. Recall that we delete from the head of the queue and insert at the\nrear. Thus,unlikeourlinkedstackofCodeFragment5.7,wecannotuseoursingly\nlinked list class, since it provides efficient access only to one side of the list. In-\nstead, ourapproach istousethecircularly linked list, called CircleList,whichwas\nintroduced earlierinSection3.4.1.\nRecallthatCircleListmaintainsapointer,calledthecursor,whichpointstoone\nnode of the list. Also recall that CircleList provides two member functions, back\nandfront. Thefunctionbackreturnsareferencetotheelementtowhichthecursor\npoints, and the function front returns a reference to the element that immediately\nfollowsitinthecircularlist. Inordertoimplementaqueue,theelementreferenced\nbybackwillbetherearofthequeueandtheelementreferencedbyfrontwillbethe\nfront. (Whywoulditnotworktoreversematters usingthebackofthecircular list\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 214 \u2014 #236\ni i\n214 Chapter5. Stacks,Queues,andDeques\nasthefrontofthequeueandthefrontofthecircular listastherearofthequeue?)\nAlsorecallthatCircleListsupportsthefollowingmodifierfunctions. Thefunc-\ntion add inserts a new node just after the cursor, the function remove removes the\nnodeimmediatelyfollowingthecursor,andthefunctionadvancemovesthecursor\nforwardtothenextnodeofthecircular list.\nInordertoimplementthequeueoperationenqueue,wefirstinvokethefunction\nadd, which inserts a new element just after the cursor, that is, just after the rear\nof the queue. We then invoke advance, which advances the cursor to this new\nelement,thusmakingthenewnodetherearofthequeue. Theprocessisillustrated\ninFigure5.5.\ncursor\n(front) (rear)\nLAX MSP ATL\n(a)\ncursor\n(front) (rear)\nLAX MSP ATL BOS\n(b)\ncursor\n(front) (rear)\nLAX MSP ATL BOS\n(c)\nFigure5.5: Enqueueing \u201cBOS\u201dintoaqueue represented asacircularly linked list:\n(a) before the operation; (b) after adding the new node; (c) after advancing the\ncursor.\nIn order to implement the queue operation dequeue, we invoke the function\nremove,thusremovingthenodejustafterthecursor,thatis,thefrontofthequeue.\nTheprocessisillustrated inFigure5.6.\nThe class structure for the resulting class, called LinkedQueue, is shown in\nCode Fragment 5.18. To avoid the syntactic messiness inherent in C++ templated\nclasses, wehave chosen not toimplement afully generic templated class. Instead,\nwe have opted to define a type for the queue\u2019s elements, called Elem. In this ex-\nample, wedefine Elemto beoftype string. Thequeue isstored inthe circular list\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 215 \u2014 #237\ni i\n5.2. Queues 215\ncursor\n(front) (rear)\nLAX MSP ATL BOS\n(a)\ncursor\n(front) (rear)\nLAX MSP ATL BOS\n(b)\nFigure5.6: Dequeueing anelement(inthiscase\u201cLAX\u201d)fromthefrontqueue rep-\nresented as acircularly linked list: (a) before the operation; (b)after removing the\nnodeimmediately followingthecursor.\ndata structure C. In order to support the size function (which CircleList does not\nprovide), wealsomaintainthequeuesizeinthemembern.\ntypedef string Elem; // queue element type\nclass LinkedQueue // queue as doubly linked list\n{\npublic:\nLinkedQueue(); // constructor\nint size() const; // number of items in the queue\nbool empty() const; // is the queue empty?\nconst Elem& front() const throw(QueueEmpty); // the front element\nvoid enqueue(const Elem& e); // enqueue element at rear\nvoid dequeue() throw(QueueEmpty); // dequeue element at front\nprivate: // member data\nCircleList C; // circular list of elements\nint n; // number of elements\n;\n}\nCodeFragment5.18: Theclass LinkedQueue, animplementation ofaqueue based\nonacircularly linkedlist.\nInCodeFragment5.19,wepresenttheimplementations oftheconstructor and\nthe basic accessor functions, size, empty, and front. Our constructor creates the\ninitial queue and initializes n to zero. We do not provide an explicit destructor,\nrelying instead on the destructor provided by CircleList. Observe that the func-\ntion front throws an exception if an attempt is made to access the first element of\nan empty queue. Otherwise, it returns the element referenced by the front of the\ncircularlist,which,byourconvention, isalsothefrontelementofthequeue.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 216 \u2014 #238\ni i\n216 Chapter5. Stacks,Queues,andDeques\nLinkedQueue::LinkedQueue() // constructor\n: C(), n(0)\n{ }\nint LinkedQueue::size() const // number of items in the queue\nreturn n;\n{ }\nbool LinkedQueue::empty() const // is the queue empty?\nreturn n == 0;\n{ }\n// get the front element\nconst Elem& LinkedQueue::front() const throw(QueueEmpty)\n{\nif (empty())\nthrow QueueEmpty(\"front of empty queue\");\nreturn C.front(); // list front is queue front\n}\nCodeFragment5.19:ConstructorandaccessorfunctionsfortheLinkedQueueclass.\nThe definition of the queue operations, enqueue and dequeue are presented in\nCode Fragment 5.20. Recall that enqueuing involves invoking the add function to\ninsertthenewitemimmediatelyfollowingthecursorandthenadvancingthecursor.\nBefore dequeuing, we check whether the queue is empty, and, if so, we throw an\nexception. Otherwise, dequeuing involves removing the element that immediately\nfollowsthecursor. Ineithercase,weupdatethenumberofelementsinthequeue.\n// enqueue element at rear\nvoid LinkedQueue::enqueue(const Elem& e)\n{\nC.add(e); // insert after cursor\nC.advance(); // ...and advance\nn++;\n}\n// dequeue element at front\nvoid LinkedQueue::dequeue() throw(QueueEmpty)\n{\nif (empty())\nthrow QueueEmpty(\"dequeue of empty queue\");\nC.remove(); // remove from list front\nn ;\n\u2212\u2212\n}\nCodeFragment5.20: Theenqueue anddequeue functions forLinkedQueue.\nObserve that, all the operations of the queue ADT are implemented in O(1)\ntime. Therefore this implementation is quite efficient. Unlike the array-based im-\nplementation, byexpandingandcontractingdynamically,thisimplementationuses\nspace proportional to the number of elements that are present in the queue at any\ntime.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 217 \u2014 #239\ni i\n5.3. Double-EndedQueues 217\n5.3 Double-Ended Queues\nConsidernowaqueue-likedatastructurethatsupportsinsertionanddeletionatboth\nthefrontandtherearofthequeue. Suchanextensionofaqueueiscalledadouble-\nended queue, or deque, which is usually pronounced \u201cdeck\u201d to avoid confusion\nwith the dequeue function of the regular queue ADT, which is pronounced like\nthe abbreviation \u201cD.Q.\u201d An easy way to remember the \u201cdeck\u201d pronunciation is to\nobservethatadequeislikeadeckofcardsinthehandsofacrookedcarddealer\u2014it\nispossible todealoffboththetopandthebottom.\n5.3.1 The Deque Abstract Data Type\nThefunctions ofthedequeADTareasfollows,whereDdenotes thedeque:\ninsertFront(e): Insertanewelementeatthebeginning ofthedeque.\ninsertBack(e): Insertanewelementeattheendofthedeque.\neraseFront(): Removethefirstelementofthedeque;anerroroccursif\nthedequeisempty.\neraseBack(): Removethe lastelement of thedeque; anerror occurs if\nthedequeisempty.\nAdditionally, thedequeincludes thefollowingsupport functions:\nfront(): Return the first element of the deque; an error occurs if\nthedequeisempty.\nback(): Return the last element of the deque; an error occurs if\nthedequeisempty.\nsize(): Returnthenumberofelementsofthedeque.\nempty(): Returntrueifthedequeisemptyandfalseotherwise.\nExample 5.5: Thefollowingexampleshowsaseriesofoperationsandtheiref-\nfectsonaninitiallyemptydeque,D,ofintegers.\nOperation Output D\ninsertFront(3) \u2013 (3)\ninsertFront(5) \u2013 (5,3)\nfront() 5 (5,3)\neraseFront() \u2013 (3)\ninsertBack(7) \u2013 (3,7)\nback() 7 (3,7)\neraseFront() \u2013 (7)\neraseBack() \u2013 ()\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 218 \u2014 #240\ni i\n218 Chapter5. Stacks,Queues,andDeques\n5.3.2 The STL Deque\nAswiththestackandqueue,theStandardTemplateLibraryprovidesanimplemen-\ntationofadeque. Theunderlying implementation isbasedontheSTLvectorclass\n(Sections 1.5.5 and 6.1.4). Thepattern ofusage issimilar tothat of the STLstack\nand STL queue. First, we need to include the definition file \u201cdeque.\u201d Since it is a\nmember of the std namespace, we need to either preface each usage \u201cstd::deque\u201d\nor provide an appropriate \u201cusing\u201d statement. The deque class is templated with\nthe base type of the individual elements. For example, the code fragment below\ndeclares adequeofstrings.\n#include <deque>\nusing std::deque; // make deque accessible\ndeque<string> myDeque; // a deque of strings\nAs with STL stacks and queues, an STL deque dynamically resizes itself as new\nelementsareadded.\nWith minor differences, the STL deque class supports the same operators as\nourinterface. Hereisalistoftheprincipal operations.\nsize(): Returnthenumberofelementsinthedeque.\nempty(): Returntrueifthedequeisemptyandfalseotherwise.\npush front(e): Inserteatthebeginning thedeque.\npush back(e): Inserteattheendofthedeque.\npop front(): Removethefirstelementofthedeque.\npop back(): Removethelastelementofthedeque.\nfront(): Returnareference tothedeque\u2019sfirstelement.\nback(): Returnareference tothedeque\u2019slastelement.\nSimilar to STLstacks and queues, the result of applying any of the operations\nfront, back, push front, or push backto an empty STLqueue isundefined. Thus,\nnoexceptionisthrown,buttheprogram mayabort.\n5.3.3 Implementing a Deque with a Doubly Linked List\nIn this section, we show how to implement the deque ADT using a linked repre-\nsentation. Aswith the queue, a deque supports efficient access at both ends of the\nlist, so our implementation is based on the use of a doubly linked list. Again, we\nusethedoublylinkedlistclass,calledDLinkedList,whichwaspresented earlierin\nSection3.3.3. Weplace thefrontofthedequeattheheadofthelinked listandthe\nrearofthequeueatthetail. Anillustration isprovided inFigure5.7.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 219 \u2014 #241\ni i\n5.3. Double-EndedQueues 219\nFigure5.7: Adoublylinkedlistwithsentinels, header andtrailer. Thefrontofour\ndeque is stored just after the header (\u201cJFK\u201d), and the back of our deque is stored\njustbeforethetrailer(\u201cSFO\u201d).\nThe definition of the resulting class, called LinkedDeque, is shown in Code\nFragment 5.21. The deque is stored in the data member D. In order to support\nthe size function, we also maintain the queue size in the member n. As in some\nof our earlier implementations, we avoid the syntactic messiness inherent in C++\ntemplated classes, and instead use just a type definition to define the deque\u2019s base\nelementtype.\ntypedef string Elem; // deque element type\nclass LinkedDeque // deque as doubly linked list\n{\npublic:\nLinkedDeque(); // constructor\nint size() const; // number of items in the deque\nbool empty() const; // is the deque empty?\nconst Elem& front() const throw(DequeEmpty); // the first element\nconst Elem& back() const throw(DequeEmpty); // the last element\nvoid insertFront(const Elem& e); // insert new first element\nvoid insertBack(const Elem& e); // insert new last element\nvoid removeFront() throw(DequeEmpty); // remove first element\nvoid removeBack() throw(DequeEmpty); // remove last element\nprivate: // member data\nDLinkedList D; // linked list of elements\nint n; // number of elements\n;\n}\nCodeFragment5.21: Theclassstructure forclassLinkedDeque.\nWehavenotbotheredtoprovideanexplicitdestructor,becausetheDLinkedList\nclassprovidesitsowndestructor, whichisautomaticallyinvokedwhenourLinked-\nDequestructure isdestroyed.\nMost of the member functions for the LinkedDeque class are straightforward\ngeneralizations of the corresponding functions of the LinkedQueue class, so we\nhave omitted them. In Code Fragment 5.22, we present the implementations of\nthememberfunctionsforperforminginsertionsandremovalsofelementsfromthe\ndeque. Observethat,ineachcase,wesimplyinvoketheappropriateoperationfrom\ntheunderlying DLinkedListobject.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 220 \u2014 #242\ni i\n220 Chapter5. Stacks,Queues,andDeques\n// insert new first element\nvoid LinkedDeque::insertFront(const Elem& e)\n{\nD.addFront(e);\nn++;\n}\n// insert new last element\nvoid LinkedDeque::insertBack(const Elem& e)\n{\nD.addBack(e);\nn++;\n}\n// remove first element\nvoid LinkedDeque::removeFront() throw(DequeEmpty)\n{\nif (empty())\nthrow DequeEmpty(\"removeFront of empty deque\");\nD.removeFront();\nn ;\n\u2212\u2212\n}\n// remove last element\nvoid LinkedDeque::removeBack() throw(DequeEmpty)\n{\nif (empty())\nthrow DequeEmpty(\"removeBack of empty deque\");\nD.removeBack();\nn ;\n\u2212\u2212\n}\nCodeFragment5.22: Theinsertion andremovalfunctions forLinkedDeque.\nTable5.2showstherunning timesoffunctions inarealization ofadeque bya\ndoublylinkedlist. Notethateveryfunction ofthedequeADTrunsinO(1)time.\nOperation Time\nsize O(1)\nempty O(1)\nfront,back O(1)\ninsertFront,insertBack O(1)\neraseFront,eraseBack O(1)\nTable5.2: Performanceofadequerealizedbyadoublylinkedlist. Thespaceusage\nisO(n),wherenisnumberofelementsinthedeque.\n5.3.4 Adapters and the Adapter Design Pattern\nAninspection ofcodefragmentsofSections5.1.5,5.2.5,and5.3.3,revealsacom-\nmonpattern. In each case, wehave taken anexisting data structure and adapted it\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 221 \u2014 #243\ni i\n5.3. Double-EndedQueues 221\nto be used for a special purpose. For example, in Section 5.3.3, we showed how\ntheDLinkedListclassofSection3.3.3couldbeadaptedtoimplementadeque. Ex-\nceptfortheadditional featureofkeepingtrackofthenumberofelements,wehave\nsimply mapped each deque operation (such as insertFront) to the corresponding\noperation ofDLinkedList(suchastheaddFront).\nAn adapter (also called a wrapper) is a data structure, for example, a class in\nC++, that translates one interface to another. You can think of an adapter as the\nsoftware analogue to electric power plug adapters, which are often needed when\nyou want to plug your electric appliances into electric wall sockets in different\ncountries.\nAsanexampleofadaptation, observethatitispossible toimplement thestack\nADT by means of a deque data structure. That is, we can translate each stack\noperationtoafunctionallyequivalentdequeoperation. Suchamappingispresented\ninTable5.3.\nStackMethod DequeImplementation\nsize() size()\nempty() empty()\ntop() front()\npush(o) insertFront(o)\npop() eraseFront()\nTable5.3: Implementing astackwithadeque.\nNote that, because of the deque\u2019s symmetry, performing insertions and re-\nmovalsfromtherearofthedequewouldhavebeenequallyefficient.\nLikewise,wecandevelopthecorrespondences forthequeueADT,asshownin\nTable5.4.\nQueueMethod DequeImplementation\nsize() size()\nempty() empty()\nfront() front()\nenqueue(e) insertBack(e)\ndequeue() eraseFront()\nTable5.4: Implementing aqueuewithadeque.\nAs a more concrete example of the adapter design pattern, consider the code\nfragment shownin CodeFragment 5.23. Inthis code fragment, wepresent aclass\nDequeStack, which implements the stack ADT. It\u2019s implementation is based on\ntranslating eachstackoperation tothecorresponding operation onaLinkedDeque,\nwhichwasintroduced inSection5.3.3.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 222 \u2014 #244\ni i\n222 Chapter5. Stacks,Queues,andDeques\ntypedef string Elem; // element type\nclass DequeStack // stack as a deque\n{\npublic:\nDequeStack(); // constructor\nint size() const; // number of elements\nbool empty() const; // is the stack empty?\nconst Elem& top() const throw(StackEmpty); // the top element\nvoid push(const Elem& e); // push element onto stack\nvoid pop() throw(StackEmpty); // pop the stack\nprivate:\nLinkedDeque D; // deque of elements\n;\n}\nCodeFragment5.23: Implementation oftheStackinterfacebymeansofadeque.\nThe implementations of the various member functions are presented in Code\nFragment 5.24. In each case, we translate some stack operation into the corre-\nsponding dequeoperation.\nDequeStack::DequeStack() // constructor\n: D()\n{ }\n// number of elements\nint DequeStack::size() const\nreturn D.size();\n{ }\n// is the stack empty?\nbool DequeStack::empty() const\nreturn D.empty();\n{ }\n// the top element\nconst Elem& DequeStack::top() const throw(StackEmpty)\n{\nif (empty())\nthrow StackEmpty(\"top of empty stack\");\nreturn D.front();\n}\n// push element onto stack\nvoid DequeStack::push(const Elem& e)\nD.insertFront(e);\n{ }\n// pop the stack\nvoid DequeStack::pop() throw(StackEmpty)\n{\nif (empty())\nthrow StackEmpty(\"pop of empty stack\");\nD.removeFront();\n}\nCodeFragment5.24: Implementation oftheStackinterfacebymeansofadeque.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 223 \u2014 #245\ni i\n5.4. Exercises 223\n5.4 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-5.1 Describehowtoimplementacapacity-limitedstack,whichusesthefunc-\ntions of a capacity-limited deque to perform the functions of the stack\nADTinwaysthatdonotthrow exceptions whenweattempttoperform a\npushonafullstackorapoponanemptystack.\nR-5.2 Describehowtoimplementacapacity-limitedqueue,whichusesthefunc-\ntions of a capacity-limited deque to perform the functions of the queue\nADTinwaysthatdonotthrow exceptions whenweattempttoperform a\nenqueueonafullqueueoradequeueonanemptyqueue.\nR-5.3 SupposeaninitiallyemptystackShasperformed atotalof25pushoper-\nations, 12 top operations, and 10 pop operations, 3 of which generated a\nStackEmpty exception that was caught and ignored. What is the current\nsizeofS?\nR-5.4 IfweimplementedthestackSfromthepreviousproblemwithanarray,as\ndescribedinthischapter,thenwhatisthecurrentvalueofthetopmember\nvariable?\nR-5.5 Describe the output of the following series of stack operations: push(5),\npush(3),pop(),push(2),push(8),pop(),pop(),push(9),push(1),pop(),\npush(7),push(6),pop(),pop(),push(4),pop(),pop().\nR-5.6 Givearecursivefunction forremovingalltheelementsinastack.\nR-5.7 ModifythestackADTimplementation ofSection5.1.5asafullygeneric\nclass(throughtheuseoftemplates).\nR-5.8 Give a precise and complete definition of the concept of matching for\ngrouping symbolsinanarithmeticexpression.\nR-5.9 Describetheoutputforthefollowingsequence ofqueueoperations:\nenqueue(5),enqueue(3),dequeue(),enqueue(2),enqueue(8),dequeue(),\ndequeue(),enqueue(9),enqueue(1),dequeue(),enqueue(7),enqueue(6),\ndequeue(),dequeue(),enqueue(4), dequeue(),dequeue().\nR-5.10 Describetheoutputforthefollowingsequence ofdequeoperations:\ninsertFront(3),insertBack(8),insertBack(9),insertFront(5),removeFront(),\neraseBack(), first(), insertBack(7), removeFront(), last(), eraseBack().\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 224 \u2014 #246\ni i\n224 Chapter5. Stacks,Queues,andDeques\nR-5.11 Suppose youhave adeque Dcontaining the numbers (1,2,3,4,5,6,7,8),\nin this order. Suppose further that you have an initially empty queue\nQ. Give a pseudo-code description of a function that uses only D and\nQ(andnoothervariablesorobjects)andresultsinDstoringtheelements\n(1,2,3,5,4,6,7,8), inthisorder.\nR-5.12 Repeat the previous problem using the deque D and an initially empty\nstackS.\nCreativity\nC-5.1 ExplainhowyoucanimplementallthefunctionsofthedequeADTusing\ntwostacks.\nC-5.2 Suppose you have a stack S containing n elements and a queue Q that is\ninitiallyempty. DescribehowyoucanuseQtoscanStoseeifitcontainsa\ncertain elementx, withtheadditional constraint that your algorithm must\nreturn the elements back to S in their original order. You may not use\nan array orlinked list\u2014only Sand Q and aconstant number ofreference\nvariables.\nC-5.3 Giveapseudo-code description foranarray-based implementation ofthe\ndequeADT.Whatistherunning timeforeachoperation?\nC-5.4 Suppose Alice has picked three distinct integers and placed them into a\nstackSinrandomorder. Writeashort, straight-line pieceofpseudo-code\n(with no loops or recursion) that uses only one comparison and only one\nvariablex,yetguarantees withprobability 2/3thatattheendofthiscode\nthe variable x will store the largest of Alice\u2019s three integers. Argue why\nyourmethodiscorrect.\nC-5.5 DescribehowtoimplementthestackADTusingtwoqueues. Whatisthe\nrunning timeofthepushandpopfunctions inthiscase?\nC-5.6 Supposewehaveann ntwo-dimensionalarrayAthatwewanttouseto\n\u00d7\nstoreintegers,butwedon\u2019twanttospendtheO(n2)worktoinitializeitto\nall0\u2019s, because wealready know that weareonly going to useuptonof\nthese cells in our algorithm, which itself runs in O(n) time (not counting\nthe time to initialize A). Show how to use an array-based stack S storing\n(i,j,k) integer triples to allow us to use the array A without initializing\nit and still implement our algorithm in O(n) time, even though the initial\nvaluesinthecellsofAmightbetotalgarbage.\nC-5.7 Describeanonrecursivealgorithmforenumeratingallpermutationsofthe\nnumbers 1,2,...,n .\n{ }\nC-5.8 Postfix notation is an unambiguous way of writing an arithmetic expres-\nsion without parentheses. It is defined so that if \u201c(exp ) (exp )\u201d is a\n1 2\n\u25e6\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 225 \u2014 #247\ni i\n5.4. Exercises 225\nnormal fully parenthesized expression whose operation is \u201c \u201d, then the\n\u25e6\npostfix version of this is \u201cpexp pexp \u201d, where pexp is the postfix ver-\n1 2 1\n\u25e6\nsion of exp and pexp is the postfix version of exp . The postfix version\n1 2 2\nof asingle number orvariable isjust that number orvariable. So, forex-\nample, the postfix version of \u201c((5+2) (8 3))/4\u201d is \u201c5 2 + 8 3\n\u2217 \u2212 \u2212 \u2217\n4 /\u201d. Describe a nonrecursive way of evaluating an expression in postfix\nnotation.\nC-5.9 SupposeyouhavetwononemptystacksSandT andadequeD. Describe\nhow to use D so that S contains all the elements of T below all of its\noriginal elements,withbothsetsofelementsstillintheiroriginal order.\nC-5.10 Alice has three array-based stacks, A, B, andC, such that A has capacity\n100,Bhascapacity5,andChascapacity3. Initially,Aisfull,andBandC\nareempty. Unfortunately, thepersonwhoprogrammedtheclassforthese\nstacks madethepush andpopfunctions private. Theonly function Alice\ncan use is a static function, transfer(S,T), which transfers (by iteratively\napplying the private pop and push functions) elements from stack S to\nstackT untileitherSbecomesemptyorT becomesfull. So,forexample,\nstarting from our initial configuration and performing transfer(A,C) re-\nsultsinAnowholding97elementsandCholding3. Describeasequence\noftransferoperations that starts from theinitial configuration and results\ninBholding4elementsattheend.\nC-5.11 Showhowtouseastack Sandaqueue Qtogenerate allpossible subsets\nofann-elementsetT nonrecursively.\nProjects\nP-5.1 Giveanimplementation ofthedequeADTusinganarray, sothateachof\ntheupdatefunctions runinO(1)time.\nP-5.2 Design an ADT for a two-color, double-stack ADT that consists of two\nstacks\u2014one \u201cred\u201dandone\u201cblue\u201d\u2014and hasasitsoperations color-coded\nversions of the regular stack ADT operations. For example, this ADT\nshould allow for both a red push operation and a blue push operation.\nGivean efficient implementation of this ADTusing a single array whose\ncapacity is set at some value N that is assumed to always be larger than\nthesizesoftheredandbluestackscombined.\nP-5.3 Implement the stack ADT in a fully generic manner (through the use of\ntemplates) by means of a singly linked list. (Give your implementation\n\u201cfromscratch,\u201dwithouttheuseofanyclassesfromtheStandardTemplate\nLibraryordatastructures presented earlierinthisbook.)\nP-5.4 ImplementthestackADTinafullygenericmannerusingtheSTLvector\nclass.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 226 \u2014 #248\ni i\n226 Chapter5. Stacks,Queues,andDeques\nP-5.5 ImplementthequeueADTinafullygeneric mannerusingadynamically\nallocated C++array.\nP-5.6 ImplementthequeueADTwithasinglylinkedlist.\nP-5.7 ImplementthedequeADTwithanarrayusedinacircular fashion.\nP-5.8 ImplementthedequeADTwithadoubly linkedlist.\nP-5.9 Implement a capacity-limited version of the deque ADT based on an ar-\nray used in a circular fashion, similar to queue implementation of Sec-\ntion5.2.4.\nP-5.10 Implement theStackandQueueinterfaces withaunique classthatisde-\nrivedfromclassLinkedDeque(CodeFragment5.21).\nP-5.11 When a share of common stock of some company is sold, the capital\ngain (or, sometimes, loss) is the difference between the share\u2019s selling\nprice and the price originally paid to buy it. This rule is easy to under-\nstand for a single share, but if we sell multiple shares of stock bought\nover a long period of time, then we must identify the shares actually be-\ning sold. Astandard accounting principle foridentifying which shares of\na stock were sold in such a case is to use a FIFO protocol\u2014the shares\nsold are the ones that have been held the longest (indeed, this is the de-\nfault method built into several personal finance software packages). For\nexample, suppose we buy 100 shares at $20 each on day 1, 20 shares at\n$24onday2,200sharesat$36onday3,andthensell150sharesonday\n4 at $30 each. Then applying the FIFO protocol means that of the 150\nshares sold, 100 werebought on day 1, 20 were bought on day 2, and 30\nwere bought on day 3. The capital gain in this case would therefore be\n100 10+20 6+30 ( 6), or $940. Write aprogram that takes asinput\n\u00b7 \u00b7 \u00b7 \u2212\nasequence oftransactions oftheform\u201cbuy x share(s) at $y each\u201d\nor\u201csell x share(s) at $y each,\u201dassumingthatthetransactions oc-\ncur on consecutive days and the values x and y are integers. Given this\ninputsequence, theoutputshouldbethetotalcapitalgain(orloss)forthe\nentiresequence, usingtheFIFOprotocoltoidentifyshares.\nP-5.12 Implementaprogramthatcaninputanexpressioninpostfixnotation(see\nExerciseC-5.8)andoutputitsvalue.\nChapter Notes\nWewereintroducedtotheapproachofdefiningdatastructuresfirstintermsoftheirADTs\nandthenintermsofconcreteimplementationsbytheclassicbooksbyAho,Hopcroft,and\nUllman [4, 5], which incidentallyis where we first saw a problemsimilar to ExerciseC-\n5.6.ExerciseC-5.10issimilartointerviewquestionssaidtobefromawell-knownsoftware\ncompany.Forfurtherstudyofabstractdatatypes,seeLiskovandGuttag[68],Cardelliand\nWegner[19],orDemurjian[27].\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 227 \u2014 #249\ni i\nChapter\n6\nList and Iterator ADTs\nContents\n6.1 Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n6.1.1 The Vector Abstract Data Type . . . . . . . . . . . 228\n6.1.2 A Simple Array-Based Implementation . . . . . . . . 229\n6.1.3 An Extendable Array Implementation. . . . . . . . . 231\n6.1.4 STL Vectors . . . . . . . . . . . . . . . . . . . . . . 236\n6.2 Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\n6.2.1 Node-Based Operations and Iterators. . . . . . . . . 238\n6.2.2 The List Abstract Data Type . . . . . . . . . . . . . 240\n6.2.3 Doubly Linked List Implementation . . . . . . . . . . 242\n6.2.4 STL Lists . . . . . . . . . . . . . . . . . . . . . . . 247\n6.2.5 STL Containers and Iterators . . . . . . . . . . . . . 248\n6.3 Sequences . . . . . . . . . . . . . . . . . . . . . . . . 255\n6.3.1 The Sequence Abstract Data Type . . . . . . . . . . 255\n6.3.2 Implementing a Sequence with a Doubly Linked List 255\n6.3.3 Implementing a Sequence with an Array . . . . . . . 257\n6.4 Case Study: Bubble-Sort on a Sequence . . . . . . . 259\n6.4.1 The Bubble-Sort Algorithm . . . . . . . . . . . . . . 259\n6.4.2 A Sequence-Based Analysis of Bubble-Sort. . . . . . 260\n6.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 262\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 228 \u2014 #250\ni i\n228 Chapter6. ListandIteratorADTs\n6.1 Vectors\nSuppose we have a collection S of n elements stored in a certain linear order, so\nthat we can refer to the elements in S as first, second, third, and so on. Such a\ncollection is generically referred to as a list or sequence. We can uniquely refer\nto each element e in S using an integer in the range [0,n 1] that is equal to the\n\u2212\nnumber of elements of Sthat precede ein S. Theindex ofanelement einS isthe\nnumber of elements that are before e in S. Hence, the first element in S has index\n0 and the last element has index n 1. Also, if an element of S has index i, its\n\u2212\nprevious element (ifitexists) hasindex i 1, and itsnextelement (ifitexists) has\n\u2212\nindex i+1. This concept of index is related to that of the rank of an element in a\nlist,whichisusuallydefinedtobeonemorethanitsindex;sothefirstelementisat\nrank1,thesecondisatrank2,andsoon.\nAsequence thatsupports accesstoitselementsbytheirindicesiscalledavec-\ntor. Since our index definition is more consistent with the way arrays are indexed\ninC++andothercommonprogramminglanguages, werefertotheplacewherean\nelementisstoredinavectorasits\u201cindex,\u201dratherthanits\u201crank.\u201d\nThis concept of index is a simple yet powerful notion, since it can be used to\nspecifywheretoinsertanewelementintoalistorwheretoremoveanoldelement.\n6.1.1 The Vector Abstract Data Type\nA vector, also called an array list, is an ADT that supports the following funda-\nmental functions (in addition to the standard size() and empty() functions). In all\ncases,theindexparameter iisassumedtobeintherange0 i size() 1.\n\u2264 \u2264 \u2212\nat(i): Return the element ofV with index i; an error condition\noccursifiisoutofrange.\nset(i,e): Replace theelementatindexiwithe;anerror condition\noccursifiisoutofrange.\ninsert(i,e): Insert a new element e into V to have index i; an error\ncondition occursifiisoutofrange.\nerase(i): RemovefromV theelementatindexi;anerrorcondition\noccursifiisoutofrange.\nWedonotinsistthatanarraybeusedtoimplementavector,sothattheelement\natindex0isstoredatindex0inthearray,althoughthatisone(verynatural)possi-\nbility. Theindexdefinitionoffersusawaytorefertothe\u201cplace\u201dwhereanelement\nisstored inasequence without having toworryabout theexact implementation of\nthatsequence. Theindexofanelementmaychangewhenthesequenceisupdated,\nhowever,asweillustrate inthefollowingexample.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 229 \u2014 #251\ni i\n6.1. Vectors 229\nExample 6.1: WeshowbelowsomeoperationsonaninitiallyemptyvectorV.\nOperation Output V\ninsert(0,7) \u2013 (7)\ninsert(0,4) \u2013 (4,7)\nat(1) 7 (4,7)\ninsert(2,2) \u2013 (4,7,2)\nat(3) \u201cerror\u201d (4,7,2)\nerase(1) \u2013 (4,2)\ninsert(1,5) \u2013 (4,5,2)\ninsert(1,3) \u2013 (4,3,5,2)\ninsert(4,9) \u2013 (4,3,5,2,9)\nat(2) 5 (4,3,5,2,9)\nset(3,8) \u2013 (4,3,5,8,9)\n6.1.2 A Simple Array-Based Implementation\nAn obvious choice for implementing the vector ADT is to use a fixed size array\nA, where A[i] stores the element at index i. We choose the size N of array A to be\nsufficientlylarge,andwemaintainthenumbern<N ofelementsinthevectorina\nmembervariable.\nThe details of the implementation of the functions of the vector ADT are rea-\nsonablysimple. Toimplementtheat(i)operation, forexample,wejustreturnA[i].\nThe implementations of the functions insert(i,e) and erase(i) are given in Code\nFragment6.1.\nAlgorithminsert(i,e):\nfor j=n 1,n 2,...,ido\n\u2212 \u2212\nA[j+1] A[j] makeroomforthenewelement\n\u2190 { }\nA[i] e\n\u2190\nn n+1\n\u2190\nAlgorithmerase(i):\nfor j=i+1,i+2,...,n 1do\n\u2212\nA[j 1] A[j] fillinfortheremovedelement\n\u2212 \u2190 { }\nn n 1\n\u2190 \u2212\nCode Fragment6.1: Methods insert(i,e) and erase(i) in the array implementation\nofthevectorADT.Themembervariablenstoresthenumberofelements.\nAn important (and time-consuming) part of this implementation involves the\nshifting ofelementsupordowntokeeptheoccupied cellsinthearraycontiguous.\nThese shifting operations are required to maintain our rule of always storing an\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 230 \u2014 #252\ni i\n230 Chapter6. ListandIteratorADTs\nelementwhoselistindexiatindexiinthearrayA. (SeeFigure6.1.)\nS\n0 1 2 i n\u20131 N\u20131\n(a)\nS\n0 1 2 i n\u20131 N\u20131\n(b)\nFigure 6.1: Array-based implementation of a vector V that is storing n elements:\n(a)shiftingupforaninsertionatindexi;(b)shiftingdownforaremovalatindexi.\nThe Performance of a Simple Array-Based Implementation\nTable 6.1 shows the worst-case running times of the functions of a vector with n\nelements realized by means of an array. Methods empty, size, at, and set clearly\nrun in O(1) time, but the insertion and removal functions can take much longer\nthanthis. Inparticular,insert(i,e)runsintimeO(n). Indeed,theworstcaseforthis\noperation occurs when i=0, since all the existing n elements have to be shifted\nforward. Asimilarargumentappliestofunctionerase(i),whichrunsinO(n)time,\nbecausewehavetoshiftbackwardn 1elementsintheworstcase(i=0). Infact,\n\u2212\nassuming that each possible index is equally likely to bepassed asan argument to\nthese operations, their average running time is O(n) because we have to shift n/2\nelementsonaverage.\nOperation Time\nsize() O(1)\nempty() O(1)\nat(i) O(1)\nset(i,e) O(1)\ninsert(i,e) O(n)\nerase(i) O(n)\nTable6.1: Performanceofavectorwithnelementsrealized byanarray. Thespace\nusageisO(N),whereN isthesizeofthearray.\nLooking moreclosely atinsert(i,e)anderase(i),wenotethattheyeachrunin\ntime O(n i+1), for only those elements at index i and higher have to be shifted\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 231 \u2014 #253\ni i\n6.1. Vectors 231\nup or down. Thus, inserting or removing an item at the end of a vector, using the\nfunctionsinsert(n,e)anderase(n 1),takeO(1)timeeachrespectively. Moreover,\n\u2212\nthis observation has an interesting consequence for the adaptation of the vector\nADT to the deque ADT given in Section 5.3.1. If the vector ADT in this case is\nimplemented by means of an array as described above, then functions insertBack\nanderaseBackofthedequeeachruninO(1)time. However,functionsinsertFront\nanderaseFrontofthedequeeachruninO(n)time.\nActually, withalittleeffort, wecanproduce anarray-based implementation of\nthe vector ADTthat achieves O(1) time for insertions and removals at index 0, as\nwell as insertions and removals at the end of the vector. Achieving this requires\nthatwegiveuponourrulethatanelementatindexiisstoredinthearrayatindex\ni,however,aswewouldhavetouseacirculararrayapproach liketheoneweused\nin Section 5.2 to implement a queue. We leave the details of this implementation\nforanexercise(R-6.17).\n6.1.3 An Extendable Array Implementation\nA major weakness of the simple array implementation for the vector ADT given\nin Section 6.1.2 is that it requires advance specification of a fixed capacity, N, for\nthetotal numberofelementsthatmaybestored inthevector. Iftheactualnumber\nofelements, n,ofthevectorismuchsmallerthanN,thenthisimplementation will\nwaste space. Worse, if n increases past N, then this implementation will crash.\nFortunately, thereisasimplewaytofixthismajordrawback.\nLet us provide a means to grow the array A that stores the elements of a vec-\ntor V. Of course, in C++ (and most other programming languages) we cannot\nactually grow the array A; its capacity is fixed at some number N, as we have al-\nreadyobserved. Instead,whenanoverflowoccurs,thatis,whenn=N andfunction\ninsertiscalled,weperform thefollowingsteps:\n1. AllocateanewarrayBofcapacity N\n2. CopyA[i]toB[i],fori=0,...,N 1\n\u2212\n3. Deallocate Aandreassign AtopointtothenewarrayB\nThis array replacement strategy is known as an extendable array, for it can\nbe viewed as extending the end of the underlying array to make room for more\nelements. (SeeFigure6.2.) Intuitively, thisstrategy ismuchlikethatofthehermit\ncrab,whichmovesintoalarger shellwhenitoutgrowsitsprevious one.\nWe give an implementation of the vector ADT using an extendable array in\nCode Fragment 6.2. To avoid the complexities of templated classes, we have\nadopted our earlier practice of using a type definition to specify the base element\ntype, which is an int in this case. The class is called ArrayVector. We leave the\ndetailsofproducing afullygeneric templatedclassasanexercise(R-6.7).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 232 \u2014 #254\ni i\n232 Chapter6. ListandIteratorADTs\nA(cid:13) A(cid:13)\nB(cid:13) B(cid:13) A(cid:13)\n(a)(cid:13) (b)(cid:13) (c)(cid:13)\nFigure6.2: The three steps for \u201cgrowing\u201d an extendable array: (a) create new ar-\nray B; (b) copy elements from A to B; (c) reassign A to refer to the new array and\ndeletetheoldarray.\nOurclass definition differs slightly from the operations given in our ADT.For\nexample, we provide two means for accessing individual elements of the vector.\nThe first involves overriding the C++ array index operator (\u201c[]\u201d), and the second\nis the at function. The two functions behave the same, except that the at function\nperforms arange testbefore each access. (Notethe similarity withtheSTLvector\nclassgiveninSection6.1.4.) Iftheindexiisnotinbounds,thisfunctionthrowsan\nexception. Because both of these access operations return a reference, there is no\nneedtoexplicitly defineasetfunction. Instead, wecansimplyusetheassignment\noperator. Forexample,theADTfunctionv.set(i,5)couldbeimplementedeitheras\nv[i]=5or,moresafely, asv.at(i)=5.\ntypedef int Elem; // base element type\nclass ArrayVector\n{\npublic:\nArrayVector(); // constructor\nint size() const; // number of elements\nbool empty() const; // is vector empty?\nElem& operator[](int i); // element at index\nElem& at(int i) throw(IndexOutOfBounds); // element at index\nvoid erase(int i); // remove element at index\nvoid insert(int i, const Elem& e); // insert element at index\nvoid reserve(int N); // reserve at least N spots\n// ... (housekeeping functions omitted)\nprivate:\nint capacity; // current array size\nint n; // number of elements in vector\nElem* A; // array storing the elements\n;\n}\nCodeFragment6.2: Avectorimplementation usinganextendable array.\nThe member data for class ArrayVector consists of the array storage A, the\ncurrent number n of elements in the vector, and the current storage capacity. The\nclassArrayVectoralsoprovides theADTfunctions insertandremove. Wediscuss\ntheir implementations below. We have added a new function, called reserve, that\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 233 \u2014 #255\ni i\n6.1. Vectors 233\nis not part of the ADT. This function allows the user to explicitly request that the\narraybeexpanded toacapacity ofasizeatleastn. Ifthecapacity isalready larger\nthanthis,thenthefunction doesnothing.\nEventhough wehave notbothered toshowthem, theclassalso provides some\nof the standard housekeeping functions. These consist of a copy constructor, an\nassignment operator, and a destructor. Because this class allocates memory, their\ninclusion is essential for a complete and robust class implementation. We leave\nthemasanexercise(R-6.6). Weshouldalsoaddversionsoftheindexingoperators\nthatreturnconstant references.\nInCodeFragment6.3,wepresenttheclassconstructorandanumberofsimple\nmemberfunctions. Whenthevector isconstructed, wedonotallocate anystorage\nand simply set A to NULL. Note that the first attempt to add an element results in\narraystorage beingallocated.\nArrayVector::ArrayVector() // constructor\n: capacity(0), n(0), A(NULL)\n{ }\nint ArrayVector::size() const // number of elements\nreturn n;\n{ }\nbool ArrayVector::empty() const // is vector empty?\nreturn size() == 0;\n{ }\nElem& ArrayVector::operator[](int i) // element at index\nreturn A[i];\n{ }\n// element at index (safe)\nElem& ArrayVector::at(int i) throw(IndexOutOfBounds)\n{\nif (i < 0 i >= n)\n||\nthrow IndexOutOfBounds(\"illegal index in function at()\");\nreturn A[i];\n}\nCodeFragment6.3: Thesimplememberfunctions forclassArrayVector.\nIn Code Fragment 6.4, we present the member function erase. As mentioned\nabove, it removes an element at index i by shifting all subsequent elements from\nindexi+1tothelastelementofthearraydownbyoneposition.\nvoid ArrayVector::erase(int i) // remove element at index\n{\nfor (int j = i+1; j < n; j++) // shift elements down\nA[j 1] = A[j];\n\u2212\nn ; // one fewer element\n\u2212\u2212\n}\nCodeFragment6.4: Thememberfunction removeforclassArrayVector.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 234 \u2014 #256\ni i\n234 Chapter6. ListandIteratorADTs\nFinally,inCodeFragment6.5,wepresentthereserveandinsertfunctions. The\nreservefunctionfirstcheckswhetherthecapacityalreadyexceedsn,inwhichcase\nnothingneedstobedone. Otherwise,itallocatesanewarrayBofthedesiredsizes,\ncopies the contents ofAto B,deletes A,and makes Bthe current array. Theinsert\nfunction first checks whether there is sufficient capacity for one more element. If\nnot, it sets the capacity to the maximum of1 and twice the current capacity. Then\nstarting at the insertion point, it shifts elements up by one position, and stores the\nnewelementinthedesiredposition.\nvoid ArrayVector::reserve(int N) // reserve at least N spots\n{\nif (capacity >= N) return; // already big enough\nElem* B = new Elem[N]; // allocate bigger array\nfor (int j = 0; j < n; j++) // copy contents to new array\nB[j] = A[j];\nif (A != NULL) delete [] A; // discard old array\nA = B; // make B the new array\ncapacity = N; // set new capacity\n}\nvoid ArrayVector::insert(int i, const Elem& e)\n{\nif (n >= capacity) // overflow?\nreserve(max(1, 2 * capacity)); // double array size\nfor (int j = n 1; j >= i; j ) // shift elements up\n\u2212 \u2212\u2212\nA[j+1] = A[j];\nA[i] = e; // put in empty slot\nn++; // one more element\n}\nCodeFragment6.5:ThememberfunctionsreserveandinsertforclassArrayVector.\nIntermsofefficiency,thisarrayreplacementstrategymight,atfirst,seemrather\nslow. After all, performing just one array replacement required by an element in-\nsertion takes O(n) time, which is not very good. Notice, however, that, after we\nperform an array replacement, our new array allows us to add n new elements to\nthevectorbeforethearraymustbereplacedagain.\nThis simple observation allows us to show that the running time of a series\nof operations performed on an initially empty vector is proportional to the total\nnumber ofelements added. Asashorthand notation, letusrefertotheinsertion of\nanelement meanttobethelastelement inavector asa\u201cpush\u201d operation. Using a\ndesign pattern called amortization, we show below that performing a sequence of\npushoperationsonavectorimplementedwithanextendablearrayisquiteefficient.\nProposition 6.2: LetV beavectorimplementedbymeansofanextendablearray\nA,asdescribedabove.ThetotaltimetoperformaseriesofnpushoperationsinV,\nstartingfromV beingemptyandAhavingsizeN =1,isO(n).\nJustification: Toperformthisanalysis,weviewthecomputerasacoin-operated\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 235 \u2014 #257\ni i\n6.1. Vectors 235\nappliance, which requires the payment of one cyber-dollar for a constant amount\nofcomputing time. Whenanoperation isexecuted, weshould haveenough cyber-\ndollars available in our current \u201cbank account\u201d to pay for that operation\u2019s running\ntime. Thus, the totalamount ofcyber-dollars spent forany computation ispropor-\ntionaltothetotaltimespentonthatcomputation. Thebeautyofusingthisanalysis\nmethodisthatwecanoverchargesomeoperationsinordertosaveupcyber-dollars\ntopayforothers.\nLetusassume thatone cyber-dollar isenough topay fortheexecution ofeach\npush operation inV, excluding the time spent for growing the array. Also, let us\nassumethatgrowingthearrayfromsizektosize2krequireskcyber-dollarsforthe\ntimespentcopying theelements. Weshallchargeeachpushoperation threecyber-\ndollars. Thus, weovercharge each push operation that does not cause an overflow\nby two cyber-dollars. Think of the two cyber-dollars profited in an insertion that\ndoesnotgrowthearrayasbeing\u201cstored\u201d attheelementinserted.\nAnoverflowoccurswhenthevectorV has2i elements,forsomei 0,andthe\n\u2265\nsize of the array used byV is 2i. Thus, doubling the size of the array requires 2i\ncyber-dollars. Fortunately, these cyber-dollars can befound atthe elements stored\nin cells 2i\u22121 through 2i 1. (See Figure 6.3.) Note that the previous overflow\n\u2212\noccurred when the number of elements became larger than 2i\u22121 for the first time,\nand thus the cyber-dollars stored in cells 2i\u22121 through 2i 1 were not previously\n\u2212\nspent. Therefore, we have a valid amortization scheme inwhich each operation is\ncharged three cyber-dollars and allthecomputing timeispaid for. Thatis, wecan\npayfortheexecutionofnpushoperations using3ncyber-dollars.\n$ $ $ $\n$ $ $ $\n(a)\n0 1 2 3 4 5 6 7\n$\n$\n(b)\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\nFigure 6.3: A series of push operations on a vector: (a) an 8-cell array is full,\nwith two cyber-dollars \u201cstored\u201d at cells 4 through 7; (b) a push operation causes\nanoverflowandadoubling ofcapacity. Copyingtheeightoldelements tothenew\narray is paid for by the cyber-dollars already stored in the table; inserting the new\nelement is paid for by one of the cyber-dollars charged to the push operation; and\ntwocyber-dollars profitedarestoredatcell8.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 236 \u2014 #258\ni i\n236 Chapter6. ListandIteratorADTs\n6.1.4 STL Vectors\nIn Section 1.5.5, we introduced the vector class of the C++ Standard Template\nLibrary (STL). We mentioned that STL vectors behave much like standard arrays\nin C++, but they are superior to standard arrays in many respects. In this section\nweexplorethisclassingreaterdetail.\nTheStandardTemplateLibraryprovidesC++programmersanumberofuseful\nbuilt-in classes and algorithms. The classes provided by the STLare organized in\nvarious groups. Among the most important of these groups is the set of classes\ncalled containers. A container is a data structure that stores a collection of ob-\njects. Many of the data structures that we study later in this book, such as stacks,\nqueues, and lists, are examples ofSTLcontainers. Theclass vector isperhaps the\nmost basic example of an STL container class. We discuss containers further in\nSection6.2.1.\nThe definition of class vector is given in the system include file named \u201cvec-\ntor.\u201d The vector class is part of the std namespace, so it is necessary either to use\n\u201cstd::vector\u201dortoprovideanappropriateusingstatement. Thevectorclassistem-\nplated with the class of the individual elements. For example, the code fragment\nbelowdeclaresavectorcontaining 100integers.\n#include <vector> // provides definition of vector\nusing std::vector; // make vector accessible\nvector<int> myVector(100); // a vector with 100 integers\nWerefertothetypeofindividual elementsasthevector\u2019sbasetype. Eachelement\nisinitialized tothebasetype\u2019sdefaultvalue, whichforintegersiszero.\nSTLvectorobjects behaveinmanyrespects likestandard C++arrays, butthey\nprovidemanyadditional features.\nAs with arrays, individual elements of a vector object can be indexed using\n\u2022\ntheusualindexoperator (\u201c[]\u201d). Elementscanalsobeaccessed byamember\nfunction called at. The advantage of this member function over the index\noperator is that it performs range checking and generates an error exception\niftheindexisoutofbounds.\nUnlike C++ arrays, STL vectors can be dynamically resized, and new ele-\n\u2022\nmentsmaybeefficientlyappended orremovedfromtheendofanarray.\nWhen an STL vector of class objects is destroyed, it automatically invokes\n\u2022\nthedestructor foreachofitselements. (WithC++arrays, itistheobligation\noftheprogrammertodothisexplicitly.)\nSTLvectorsprovideanumberofusefulfunctions thatoperateonentirevec-\n\u2022\ntors, not just on individual elements. This includes, for example, the ability\ntocopyallorpartofonevectortoanother,theabilitytocomparethecontents\noftwoarrays,andtheabilitytoinsertanderasemultipleelements.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 237 \u2014 #259\ni i\n6.1. Vectors 237\nHerearetheprincipal memberfunctions ofthevectorclass. LetV bedeclared\ntobeanSTLvectorofsomebasetype,andletedenoteasingleobjectofthissame\nbasetype. (Forexample,V isavectorofintegers, andeisaninteger.)\nvector(n): Construct avectorwithspacefornelements; ifnoargu-\nmentisgiven,createanemptyvector.\nsize(): ReturnthenumberofelementsinV.\nempty(): ReturntrueifV isemptyandfalseotherwise.\nresize(n): ResizeV,sothatithasspacefornelements.\nreserve(n): Request thattheallocated storage spacebelargeenough\ntoholdnelements.\noperator[i]: Returnareference totheithelementofV.\nat(i): SameasV[i], butthrow anout of rangeexception ifiis\noutofbounds, thatis,ifi<0ori V.size().\n\u2265\nfront(): Returnareference tothefirstelementofV.\nback(): Returnareference tothelastelementofV.\npush back(e): Append a copy of the element e to the end of V, thus\nincreasing itssizebyone.\npop back(): Remove the last element ofV, thus reducing its size by\none.\nWhen the base type of an STL vector is class, all copying of elements (for\nexample, in push back) is performed by invoking the class\u2019s copy constructor.\nAlso, when elements are destroyed (for example, by invoking the destroyer or the\npop back member function) the class\u2019s destructor is invoked on each deleted ele-\nment. STLvectors areexpandable\u2014when thecurrent arrayspace isexhausted, its\nstoragesizeisincreased.\nAlthoughwehavenotdiscussedithere,theSTLvectoralsosupportsfunctions\nfor inserting elements at arbitrary positions within the vector, and for removing\narbitrary elementsofthevector. Thesearediscussed inSection6.1.4.\nThere are both similarities and differences between our ArrayVector class of\nSection6.1.3andtheSTLvector class. Onedifference isthattheSTLconstructor\nallows for an arbitrary number of initial elements, whereas our ArrayVect con-\nstructor always starts with an empty vector. The STL vector functions V.front()\nandV.back()areequivalent toourfunctionsV[0]andV[n 1],respectively, where\n\u2212\nnisequaltoV.size(). TheSTLvectorfunctionsV.push back(e)andV.pop back()\nare equivalent to our ArrayVect functions V.insert(n,e) andV.remove(n 1), re-\n\u2212\nspectively.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 238 \u2014 #260\ni i\n238 Chapter6. ListandIteratorADTs\n6.2 Lists\nUsing an index is not the only means of referring to the place where an element\nappears in a list. If we have a list L implemented with a (singly or doubly) linked\nlist,thenitcouldpossibly bemorenatural andefficienttouseanodeinsteadofan\nindex as a means of identifying where to access and update a list. In this section,\ndefinethelistADT,whichabstractstheconcretelinkedlistdatastructure(presented\nin Sections 3.2 and 3.3) using a related position ADT that abstracts the notion of\n\u201cplace\u201dinalist.\n6.2.1 Node-Based Operations and Iterators\nLet L be a (singly or doubly) linked list. We would like to define functions for L\nthat take nodes of the list as parameters and provide nodes as return types. Such\nfunctions could provide significant speedups over index-based functions, because\nfinding the index of an element in a linked list requires searching through the list\nincrementally fromitsbeginning orend,counting elementsaswego.\nFor instance, we might want to define a hypothetical function remove(v) that\nremoves the element of Lstored at node vof thelist. Usinga node asa parameter\nallowsustoremoveanelement inO(1)timebysimply going directly totheplace\nwherethatnodeisstoredandthen\u201clinkingout\u201dthisnodethroughanupdateofthe\nnext andprevlinksofitsneighbors. Similarly,inO(1)time,wecouldinsertanew\nelement e into L with an operation such as insert(v,e), which specifies the node\nv before which the node of the new element should be inserted. In this case, we\nsimply\u201clinkin\u201dthenewnode.\nDefining functions of a list ADTby adding such node-based operations raises\nthe issue of how much information we should be exposing about the implementa-\ntion of our list. Certainly, it is desirable for us to be able to use either a singly or\ndoubly linked listwithout revealing this detail toauser. Likewise, wedonotwish\nto allow a user to modify the internal structure of a list without our knowledge.\nSuchmodificationswouldbepossible, however,ifweprovided apointertoanode\ninourlistinaformthatallowstheusertoaccessinternaldatainthatnode(suchas\nthenext orprevfield).\nToabstract and unify the different ways of storing elements in the various im-\nplementations of a list, we introduce a data type that abstracts the notion of the\nrelativepositionorplaceofanelementwithinalist. Suchanobjectmightnaturally\nbe called a position. Because we want this object not only to access individual\nelements of a list, but also to move around in order to enumerate all the elements\nofalist, weadopt the convention used inthe C++Standard TemplateLibrary, and\ncallitaniterator.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 239 \u2014 #261\ni i\n6.2. Lists 239\nContainers and Positions\nIn order to safely expand the set of operations for lists, we abstract a notion of\n\u201cposition\u201d that allows us to enjoy the efficiency of doubly or singly linked list\nimplementationswithoutviolatingobject-oriented designprinciples. Inthisframe-\nwork, we think of a list as an instance of a more general class of objects, called\na container. A container is a data structure that stores any collection of elements.\nWe assume that the elements of a container can be arranged in a linear order. A\nposition is defined to be an abstract data type that is associated with a particular\ncontainer andwhichsupports thefollowingfunction.\nelement(): Returnareference totheelementstoredatthisposition.\nC++\u2019sabilitytooverloadoperatorsprovidesuswithanelegantalternativeman-\nnerinwhichtoexpresstheelementoperation. Inparticular, weoverloadthederef-\nerencingoperator(\u201c*\u201d),sothat,givenapositionvariable p,theassociatedelement\ncanbeaccessedby*p,ratherthan p.element(). Thiscanbeusedbothforaccessing\nandmodifying theelement\u2019s value.\nAposition isalways definedinarelative manner, thatis, intermsofitsneigh-\nbors. Unless it is the first or last of the container, a position q is always \u201cafter\u201d\nsomeposition pand\u201cbefore\u201dsomepositionr(seeFigure6.4). Apositionq,which\nisassociatedwithsomeelementeinacontainer, doesnotchange,eveniftheindex\nofechanges inthecontainer, unlessweexplicitly removee. Iftheassociated node\nisremoved, wesaythatqisinvalidated. Moreover, theposition qdoesnotchange\nevenifwereplaceorswaptheelementestoredatqwithanother element.\nBaltimore New York Beijing Delhi\np q r s\nFigure6.4: Alistcontainer. Thepositions inthecurrent orderare p,q,r,ands.\nIterators\nAlthough a position is a useful object, it would be more useful still to be able to\nnavigate through the container, for example, by advancing to the next position in\nthe container. Such an object is called an iterator. An iterator is an extension of a\nposition. Itsupports theability toaccess anode\u2019s element, but italso provides the\nabilitytonavigateforwards(andpossibly backwards) throughthecontainer.\nThere are a number of ways in which to define an ADT for an iterator object.\nFor example, given an iterator object p, we could define an operation p.next(),\nwhich returns an iterator that refers to the node just after p in the container. Be-\ncause of C++\u2019s ability to overload operators, there is a more elegant way to do\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 240 \u2014 #262\ni i\n240 Chapter6. ListandIteratorADTs\nthis by overloading the increment operator (\u201c++\u201d). In particular, the operation\n++padvances ptothenextposition ofthecontainer. Byrepeatedly applying this\noperation, we can step through all the elements of the container. For some imple-\nmentations of containers, such as a doubly linked list, navigation may be possible\nboth forwards and backwards. If so, we can also overload the decrement operator\n(\u201c\u2013\u2013\u201d)tomovetheiteratortotheprevious position inthecontainer.\nIn addition to navigating through the container, we need some way of initial-\nizing an iterator to the first node of a container and determining whether it has\ngone beyond the end of the container. To do this, we assume that each container\nprovides two special iterator values, begin and end. The beginning iterator refers\nto the first position of the container. We think of the ending iterator as referring\nto an imaginary position that lies just after the last node of the container. Given\na container object L, the operation L.begin() returns an instance of the beginning\niterator for L, and the operation L.end() returns an instance of the ending iterator.\n(SeeFigure6.5.)\nBaltimore New York Beijing Delhi\nL.begin() L.end()\nFigure6.5: Thespecialiterators L.begin()andL.end()foralistL.\nInordertoenumeratealltheelementsofagivencontainer L,wedefineaniter-\nator p whose value is initialized to L.begin(). The associated element is accessed\nusing*p. Wecanenumerate alloftheelements ofthecontainer byadvancing pto\nthenextnode using theoperation ++p. Werepeat thisuntil pisequal toL.end(),\nwhichmeansthatwehavefallenofftheendofthelist.\n6.2.2 The List Abstract Data Type\nUsing the concept of an iterator toencapsulate the idea of \u201cnode\u201d in alist, wecan\ndefineanothertypeofsequenceADT,calledsimplythelistADT.Inadditiontothe\nabove functions, we include the generic functions size and empty with the usual\nmeanings. ThisADTsupports thefollowing functions foralistLandaniterator p\nforthislist.\nbegin(): ReturnaniteratorreferringtothefirstelementofL;same\nasend()ifLisempty.\nend(): Return an iterator referring to animaginary element just\nafterthelastelementofL.\ninsertFront(e): InsertanewelementeintoLasthefirstelement.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 241 \u2014 #263\ni i\n6.2. Lists 241\ninsertBack(e): InsertanewelementeintoLasthelastelement.\ninsert(p,e): InsertanewelementeintoLbeforeposition pinL.\neraseFront(): RemovethefirstelementofL.\neraseBack(): RemovethelastelementofL.\nerase(p): Remove from L the element at position p; invalidates p\nasaposition.\nThefunctionsinsertFront(e)andinsertBack(e)areprovidedasaconvenience,\nsincetheyareequivalenttoinsert(L.begin(),e)andinsert(L.end(),e),respectively.\nSimilarly, eraseFront and eraseBack can be performed by the more general func-\ntionerase.\nAnerrorconditionoccursifaninvalidpositionispassedasanargumenttoone\nofthelistoperations. Reasonsforaposition ptobeinvalidinclude:\npwasneverinitialized orwassettoapositioninadifferentlist\n\u2022\npwaspreviously removedfromthelist\n\u2022\np results from an illegal operation, such as attempting to perform ++p,\n\u2022\nwhere p=L.end(), that is, attempting to access a position beyond the end\nposition\nWe do not check for these errors in our implementation. Instead, it is the re-\nsponsibility oftheprogrammertobesurethatonlylegalpositions areused.\nExample 6.3: WeshowaseriesofoperationsforaninitiallyemptylistLbelow.\nWeusevariables p andq todenotedifferentpositions,andweshowtheobject\ncurrentlystoredatsuchapositioninparenthesesintheOutputcolumn.\nOperation Output L\ninsertFront(8) \u2013 (8)\np=begin() p:(8) (8)\ninsertBack(5) \u2013 (8,5)\nq= p; ++q q:(5) (8,5)\np==begin() true (8,5)\ninsert(q,3) \u2013 (8,3,5)\n*q=7 \u2013 (8,3,7)\ninsertFront(9) \u2013 (9,8,3,7)\neraseBack() \u2013 (9,8,3)\nerase(p) \u2013 (9,3)\neraseFront() \u2013 (3)\nThe list ADT, with its built-in notion of position, is useful in a number of set-\ntings. Forexample, aprogram that models several people playing agameofcards\ncould model each person\u2019s hand as a list. Since most people like to keep cards of\nthe same suit together, inserting and removing cards from a person\u2019s hand could\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 242 \u2014 #264\ni i\n242 Chapter6. ListandIteratorADTs\nbe implemented using the functions of the list ADT, with the positions being de-\ntermined by a natural ordering of the suits. Likewise, a simple text editor embeds\nthenotionofpositionalinsertion andremoval,sincesucheditorstypicallyperform\nall updates relative to a cursor, which represents the current position in the list of\ncharacters oftextbeingedited.\n6.2.3 Doubly Linked List Implementation\nThereareanumberofdifferentwaystoimplementourlistADTinC++. Probably\nthe most natural and efficient way is to use a doubly linked list, similar to the one\nwe introduced in Section 3.3. Recall that our doubly linked list structure is based\non two sentinel nodes, called the header and trailer. These are created when the\nlist is first constructed. The other elements of the list are inserted between these\nsentinels.\nFollowingourusualpractice,inordertokeepthecodesimple,wesacrificegen-\neralitybyforgoing theuseofclasstemplates. Instead, weprovideatypedefinition\nElem, whichisthebase element typeofthelist. Weleavethedetails ofproducing\nafullygenerictemplatedclassasanexercise(R-6.11).\nBefore defining the class, which we call NodeList, we define two important\nstructures. Thefirstrepresents anodeofthelistandtheotherrepresents aniterator\nfor the list. Both of these objects are defined as nested classes within NodeList.\nSince users of the class access nodes exclusively through iterators, the node is de-\nclaredaprivatememberofNodeList,andtheiterator isapublicmember.\nThe node object is called Node and is presented in Code Fragment 6.6. This\nisasimpleC++structure, whichhasonly(public) datamembers,consisting ofthe\nnode\u2019s element, a link to the previous node of the list, and a link to the next node\nofthelist. SinceitisdeclaredtobeprivatetoNodeList,itsmembersareaccessible\nonlywithinNodeList.\nstruct Node // a node of the list\n{\nElem elem; // element value\nNode* prev; // previous in list\nNode* next; // next in list\n;\n}\nCodeFragment6.6: Thedeclaration ofanodeofadoublylinkedlist.\nOur iterator object is called Iterator. To users of class NodeList, it can be ac-\ncessed by the qualified type name NodeList::Iterator. Its definition, which is pre-\nsented inCodeFragment6.7,isplacedinthepublic partofNodeList. Anelement\nassociated withaniterator canbeaccessed byoverloading thedereferencing oper-\nator(\u201c*\u201d). Inordertomakeitpossibletocompareiteratorobjects,weoverloadthe\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 243 \u2014 #265\ni i\n6.2. Lists 243\nequalityandinequalityoperators(\u201c==\u201dand\u201c!=\u201d). Weprovidetheabilitytomove\nforwardorbackwardinthelistbyprovidingtheincrementanddecrementoperators\n(\u201c++\u201d and \u201c\u2013\u2013\u201d). We declare NodeList to be a friend, so that it may access the\nprivatemembersofIterator. Theprivatedatamemberconsists ofapointervtothe\nassociated nodeofthelist. Wealso provide aprivate constructor, whichinitializes\nthe node pointer. (The constructor is private so that only NodeList is allowed to\ncreatenewiterators.)\nclass Iterator // an iterator for the list\n{\npublic:\nElem& operator*(); // reference to the element\nbool operator==(const Iterator& p) const; // compare positions\nbool operator!=(const Iterator& p) const;\nIterator& operator++(); // move to next position\nIterator& operator (); // move to previous position\n\u2212\u2212\nfriend class NodeList; // give NodeList access\nprivate:\nNode* v; // pointer to the node\nIterator(Node* u); // create from node\n;\n}\nCodeFragment6.7: ClassIterator,realizing aniteratorforadoublylinkedlist.\nInCodeFragment6.8wepresenttheimplementationsofthememberfunctions\nfortheIteratorclass. Theseallfollowdirectly fromthedefinitions givenearlier.\nNodeList::Iterator::Iterator(Node* u) // constructor from Node*\nv = u;\n{ }\nElem& NodeList::Iterator::operator*() // reference to the element\nreturn v >elem;\n{ \u2212 }\n// compare positions\nbool NodeList::Iterator::operator==(const Iterator& p) const\nreturn v == p.v;\n{ }\nbool NodeList::Iterator::operator!=(const Iterator& p) const\nreturn v != p.v;\n{ }\n// move to next position\nNodeList::Iterator& NodeList::Iterator::operator++()\nv = v >next; return *this;\n{ \u2212 }\n// move to previous position\nNodeList::Iterator& NodeList::Iterator::operator ()\n\u2212\u2212\nv = v >prev; return *this;\n{ \u2212 }\nCodeFragment6.8: Implementations oftheIteratormemberfunctions.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 244 \u2014 #266\ni i\n244 Chapter6. ListandIteratorADTs\nTo keep the code simple, we have not implemented any error checking. We\nassumethatthefunctionsofCodeFragment6.8aredefinedoutsidetheclassbody.\nBecause of this, when referring to the nested class Iterator, we need to apply the\nscope resolution operator, as in NodeList::Iterator, so the compiler knows that we\nare referring to the iterator type associated with NodeList. Observe that the incre-\nment and decrement operators not only update the position, but they also return a\nreference to the updated position. This makes it possible to use the result of the\nincrementoperation, asin\u201cq=++p.\u201d\nHavingdefinedthesupporting structures NodeandIterator,letusnowpresent\nthedeclaration ofclass NodeList,which isgiveninCode Fragment6.9. Theclass\ndeclaration begins by inserting the Node and Iterator definitions from Code Frag-\nments6.6and6.7. Thisisfollowedbythepublicmembers,thatconsistofasimple\ndefaultconstructorandthemembersofthelistADT.Wehaveomittedthestandard\nhousekeeping functions from ourclass definition. Theseinclude theclass destruc-\ntor,acopyconstructor, andanassignmentoperator. Thedefinitionofthedestructor\nis important, since this class allocates memory, so it is necessary to delete this\nmemorywhen anobject ofthis type isdestroyed. Weleave the implementation of\nthesehousekeeping functions asanexercise(R-6.12).\ntypedef int Elem; // list base element type\nclass NodeList // node-based list\n{\nprivate:\n// insert Node declaration here...\npublic:\n// insert Iterator declaration here...\npublic:\nNodeList(); // default constructor\nint size() const; // list size\nbool empty() const; // is the list empty?\nIterator begin() const; // beginning position\nIterator end() const; // (just beyond) last position\nvoid insertFront(const Elem& e); // insert at front\nvoid insertBack(const Elem& e); // insert at rear\nvoid insert(const Iterator& p, const Elem& e); // insert e before p\nvoid eraseFront(); // remove first\nvoid eraseBack(); // remove last\nvoid erase(const Iterator& p); // remove p\n// housekeeping functions omitted...\nprivate: // data members\nint n; // number of items\nNode* header; // head-of-list sentinel\nNode* trailer; // tail-of-list sentinel\n;\n}\nCodeFragment6.9: ClassNodeListrealizing theC++-basedlistADT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 245 \u2014 #267\ni i\n6.2. Lists 245\nThe private data members include pointers to the header and trailer sentinel\nnodes. Inordertoimplementthefunctionsizeefficiently,wealsoprovideavariable\nn,whichstoresthenumberofelementsinthelist.\nNext, let us see how the various functions of class NodeList are implemented.\nIn Code Fragment 6.10, we begin by presenting a number of simple functions,\nincluding the constructor, the size and empty functions, and the begin and end\nfunctions. The constructor creates an initially empty list by setting n to zero, then\nallocating theheaderandtrailernodesandlinkingthemtogether. Thefunction be-\nginreturnsthepositionofthefirstnodeofthelist,whichisthenodejustfollowing\nthe header sentinel, and the function end returns the position of the trailer. Asde-\nsired,thisisthepositionfollowingthelastelementofthelist. Inbothcases,weare\ninvoking the private constructor declared within class Iterator. We are allowed to\ndosobecause NodeListisafriendofIterator.\nNodeList::NodeList() // constructor\n{\nn = 0; // initially empty\nheader = new Node; // create sentinels\ntrailer = new Node;\nheader >next = trailer; // have them point to each other\n\u2212\ntrailer >prev = header;\n\u2212\n}\nint NodeList::size() const // list size\nreturn n;\n{ }\nbool NodeList::empty() const // is the list empty?\nreturn (n == 0);\n{ }\nNodeList::Iterator NodeList::begin() const // begin position is first item\nreturn Iterator(header >next);\n{ \u2212 }\nNodeList::Iterator NodeList::end() const // end position is just beyond last\nreturn Iterator(trailer);\n{ }\nCodeFragment6.10: Implementations ofanumberofsimplememberfunctions of\nclassNodeList.\nLet us next see how to implement insertion. There are three different public\ninsertion functions, insert, insertFront, and insertBack, which are shown in Code\nFragment6.11. Thefunction insert(p,e)performs insertion intothedoubly linked\nlistusingthesameapproachthatwewasexplainedinSection3.3. Inparticular, let\nw be a pointer to p\u2019s node, let u be a pointer to p\u2019s predecessor. We create a new\nnode v, and link it before w and after u. Finally, we increment n to indicate that\nthereisoneadditional elementinthelist.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 246 \u2014 #268\ni i\n246 Chapter6. ListandIteratorADTs\n// insert e before p\nvoid NodeList::insert(const NodeList::Iterator& p, const Elem& e)\n{\nNode* w = p.v; // p\u2019s node\nNode* u = w >prev; // p\u2019s predecessor\n\u2212\nNode* v = new Node; // new node to insert\nv >elem = e;\n\u2212\nv >next = w; w >prev = v; // link in v before w\n\u2212 \u2212\nv >prev = u; u >next = v; // link in v after u\n\u2212 \u2212\nn++;\n}\nvoid NodeList::insertFront(const Elem& e) // insert at front\ninsert(begin(), e);\n{ }\nvoid NodeList::insertBack(const Elem& e) // insert at rear\ninsert(end(), e);\n{ }\nCodeFragment6.11: Implementations oftheinsertionfunctions ofclassNodeList.\nThe function insertFront invokes insert on the beginning of the list, and the\nfunction insertBackinvokes insertonthelist\u2019strailer.\nFinally, in Code Fragment 6.12 we present the implementation of the erase\nfunction,whichremovesanodefromthelist. Again,ourapproachfollowsdirectly\nfrom the method described in Section 3.3 for removal of a node from a doubly\nlinked list. Let v be a pointer to the node to be deleted, and let w be its successor\nandubeitspredecessor. Weunlink vbylinking uandwtoeachother. Oncevhas\nbeenunlinked fromthelist,weneedtoreturnitsallocated storagetothesystemin\nordertoavoidanymemoryleaks. Finally,wedecrementthenumberofelementsin\nthelist.\nvoid NodeList::erase(const Iterator& p) // remove p\n{\nNode* v = p.v; // node to remove\nNode* w = v >next; // successor\n\u2212\nNode* u = v >prev; // predecessor\n\u2212\nu >next = w; w >prev = u; // unlink p\n\u2212 \u2212\ndelete v; // delete this node\nn ; // one fewer element\n\u2212\u2212\n}\nvoid NodeList::eraseFront() // remove first\nerase(begin());\n{ }\nvoid NodeList::eraseBack() // remove last\nerase( end());\n{ \u2212\u2212 }\nCodeFragment6.12: Implementations ofthefunction eraseofclassNodeList.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 247 \u2014 #269\ni i\n6.2. Lists 247\nThere are number of other enhancements that could be added to our imple-\nmentationofNodeList,suchasbettererrorchecking, amoresophisticated suiteof\nconstructors, andapost-increment operator fortheiteratorclass.\nYoumightwonderwhywechosetodefinetheiteratorfunctionendtoreturnan\nimaginarypositionthatliesjustbeyondtheendofthelist,ratherthanthelastnode\nofthelist. Thischoiceoffersanumberofadvantages. First,itiswelldefined,even\nif the list is empty. Second, the function insert(p,e) can be used to insert a new\nelement at any position of the list. In particular, it is possible to insert an element\natthe endof thelist byinvoking insert(end(),e). Ifwehadinstead defined end to\nreturn the last position of the list, this would not be possible, and the only way to\ninsertanelementattheendofthelistwouldbethroughtheinsertBackfunction.\nObservethatourimplementationisquiteefficientwithrespecttobothtimeand\nspace. AlloftheoperationsofthelistADTrunintimeO(1). (Theonlyexceptions\ntothisaretheomittedhousekeepingfunctions,thedestructor,copyconstructor,and\nassignment operator. They require O(n) time, where n is the number of elements\nin the list.) The space used by the data structure is proportional to the number of\nelementsinthelist.\n6.2.4 STL Lists\nTheC++StandardTemplateLibraryprovidesanimplementationofalist,whichis\ncalledlist. LiketheSTLvector,theSTLlistisanexampleofanSTLcontainer. As\nin our implementation of class NodeList, the STLlist is implemented as a doubly\nlinkedlist.\nInorder todefine anobject tobeoftype list,itisnecessary tofirstinclude the\nappropriate system definition file, which is simply called \u201clist.\u201d As with the STL\nvector, the list class is a member of the std namespace, it is necessary either to\npreface references toitwiththenamespace resolution operator, asin\u201cstd::list\u201d,or\ntoprovideanappropriateusingstatement. Thelistclassistemplatedwiththebase\ntype of the individual elements. For example, the code fragment below declares a\nlistoffloats. Bydefault, theinitiallistisempty.\n#include <list>\nusing std::list; // make list accessible\nlist<float> myList; // an empty list of floats\nBelow is a list of the principal member functions of the list class. Let L be\ndeclaredtobeanSTLlistofsomebasetype,andletxdenoteasingleobjectofthis\nsamebasetype. (Forexample,Lisalistofintegers, andeisaninteger.)\nlist(n): Construct a list with n elements; if no argument list is\ngiven,anemptylistiscreated.\nsize(): ReturnthenumberofelementsinL.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 248 \u2014 #270\ni i\n248 Chapter6. ListandIteratorADTs\nempty(): ReturntrueifLisemptyandfalseotherwise.\nfront(): Returnareference tothefirstelementofL.\nback(): Returnareference tothelastelementofL.\npush front(e): Insertacopyofeatthebeginning ofL.\npush back(e): InsertacopyofeattheendofL.\npop front(): RemovethefistelementofL.\npop back(): RemovethelastelementofL.\nThe functions push front and push back are the STL equivalents of our func-\ntionsinsertFrontandinsertBack,respectively, ofourlistADT.Similarly,thefunc-\ntionspop frontandpop backareequivalenttotherespectivefunctionseraseFront\nanderaseBack.\nNote that, when the base type of an STL vector is class object, all copying of\nelements (for example, in push back) is performed by invoking the base class\u2019s\ncopy constructor. Whenever elements are destroyed (for example, by invoking the\ndestroyer or the pop back member function) the class\u2019s destructor is invoked on\neachdeleted element.\n6.2.5 STL Containers and Iterators\nIn order to develop a fuller understanding of STLvectors and lists, it is necessary\ntounderstandtheconceptsofSTLcontainersanditerators. Recallthatacontainer\nisadata structure that stores acollection of elements. TheSTLprovides avariety\nofdifferent container classes, manyofwhicharediscussed later.\nSTLContainer Description\nvector Vector\ndeque Doubleendedqueue\nlist List\nstack Last-in,first-outstack\nqueue First-in,first-outqueue\npriority queue Priorityqueue\nset(andmultiset) Set(andmultiset)\nmap(andmultimap) Map(andmulti-keymap)\nDifferent containers organize their elements in different ways, and hence sup-\nport different methods for accessing individual elements. STL iterators provide a\nrelatively uniform method for accessing and enumerating the elements stored in\ncontainers.\nBefore introducing how iterators work for STL containers, let us begin with a\nsimple function that sums the elements of an STLvector, denoted byV, shown in\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 249 \u2014 #271\ni i\n6.2. Lists 249\nCode Fragment 6.13. The elements are accessed in the standard manner through\ntheindexingoperator.\nint vectorSum1(const vector<int>& V)\n{\nint sum = 0;\nfor (int i = 0; i < V.size(); i++)\nsum += V[i];\nreturn sum;\n}\nCodeFragment6.13:AsimpleC++functionthatsumstheentriesofanSTLvector.\nThis particular method of iterating through the elements of a vector should be\nquitefamiliarbynow. Unfortunately, thismethodwouldnotbeapplicable toother\ntypes of containers, because it relies on the fact that the elements of a vector can\nbeaccessedefficientlythroughindexing. Thisisnottrueforallcontainers, suchas\nlists. Whatwedesireisauniform mechanism foraccessing elements.\nSTL Iterators\nEverySTLcontainer class defines aspecial associated class called aniterator. As\nmentionedearlier,aniteratorisanobjectthatspecifiesapositionwithinacontainer\nand which is endowed with the ability to navigate to other positions. If p is an\niteratorthatreferstosomepositionwithinacontainer, then*pyieldsareferenceto\ntheassociated element.\nAdvancing to the next element of the container is done by incrementing the\niterator. For example, either ++p or p++ advances p to point to the next ele-\nment of the container. The former returns the updated value of the iterator, and\nthe latter returns its original value. (In our implementation of an iterator for class\nNodeListinCodeFragment6.7,wedefinedonlythepreincrementoperator,butthe\npostincrement operatorwouldbeaneasyextension. SeeExerciseR-6.13.)\nEachSTLcontainerclassprovidestwomemberfunctions, beginandend,each\nofwhichreturnsaniteratorforthiscontainer. Thefirstreturnsaniteratorthatpoints\nto the first element of the container, and the second returns an iterator that can be\nthought ofaspointing toanimaginary element justbeyond the lastelement ofthe\ncontainer. AnexampleforthecaseoflistswasshowninFigure6.5,andanexample\nofhowthisworksfortheSTLvectorisshowninFigure6.6.\nV.begin() V.end()\nV[0] V[1] V[2] V[n\u22121]\nFigure6.6: ThespecialiteratorsV.begin()andV.end()foranSTLvectorV.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 250 \u2014 #272\ni i\n250 Chapter6. ListandIteratorADTs\nUsing Iterators\nLetusseehowwecanuseiteratorstoenumeratetheelementsofanSTLcontainer\nC. Suppose, for example, thatC is of type vector<int>, that is, itis an STLlist of\nintegers. Theassociatediteratortypeisdenoted\u201cvector<int>::iterator.\u201d Ingeneral,\nifC isan STLcontainer of some type cont and the base type is of type base, then\ntheiteratortypewouldbedenoted \u201ccont<base>::iterator.\u201d\nForexample,CodeFragment6.14demonstrateshowtosumtheelementsofan\nSTLvectorV usinganiterator. Webeginbyprovidingatypedefinitiontotheitera-\ntortype,calledIterator. Wethencreatealoop,whichiscontrolledbyaniterator p.\nWestart withV.begin(), and weterminate when p reachesV.end(). Although this\napproach islessdirect thantheapproach basedonindexing individual elements, it\nhastheadvantagethatitcanbeappliedtoanySTLcontainerclass,notjustvectors.\nint vectorSum2(vector<int> V)\n{\ntypedef vector<int>::iterator Iterator; // iterator type\nint sum = 0;\nfor (Iterator p = V.begin(); p != V.end(); ++p)\nsum += *p;\nreturn sum;\n}\nCodeFragment6.14: UsinganiteratortosumtheelementsofanSTLvector.\nDifferent containers provide iterators with different capabilities. Most STL\ncontainers (including lists, sets, and maps) provide the ability to move not only\nforwards,butbackwardsaswell. Forsuchcontainersthedecrementoperators\u2013\u2013p\nand p\u2013\u2013arealsodefinedfortheiriterators. Thisiscalledabidirectional iterator.\nA few STL containers (including vectors and deques) support the additional\nfeature of allowing the addition and subtraction of an integer. For example, for\nsuchaniterator, p,thevalue p+3references theelementthreepositions after pin\nthecontainer. Thisiscalledarandom-access iterator.\nAswithpointers, careisneeded intheuseofiterators. Forexample, itisupto\ntheprogrammertobesurethataniteratorpointstoavalidelementofthecontainer\nbefore attempting to dereference it. Attempting to dereference an invalid iterator\ncanresult inyour program aborting. Asmentioned earlier, iterators can beinvalid\nforvarious reasons. Forexample, aniterator becomes invalid iftheposition thatit\nreferstoisdeleted.\nConst Iterators\nObserve that in Code Fragment 6.14, we passed the vector V into the function\nby value (recall Section 1.4). This can be quite inefficient, because the system\nconstructs a complete copy of the actual argument. Since our function does not\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 251 \u2014 #273\ni i\n6.2. Lists 251\nmodify V, the best approach would be to declare the argument to be a constant\nreference instead, thatis,\u201cconst vector<int>&.\u201d\nA problem arises, however, if we declare an iterator for such a vector. Many\nSTLimplementations generateanerrormessageifweattempttousearegulariter-\natorwithaconstant vectorreference, sincesuchaniterator mayleadtoanattempt\ntomodifythevector\u2019scontents.\nThesolutionisaspecialread-onlyiterator, calledaconstiterator. Whenusing\naconstiterator,itispossibletoreadthevaluesofthecontainerbydereferencingthe\niterator,butitisnotpossibletomodifythecontainer\u2019svalues. Forexample,if pisa\nconstiterator, itispossibletoreadthevalueof*p,butyoucannotassignitavalue.\nTheconstiteratortypeforourvectortypeisdenoted\u201cvector<int>::const iterator.\u201d\nWemakeuseofthetypedef commandtorenamethislengthydefinitiontothemore\nconciseConstIterator. ThefinalcodefragmentispresentedinCodeFragment6.15.\nint vectorSum3(const vector<int>& V)\n{\ntypedef vector<int>::const iterator ConstIterator; // iterator type\nint sum = 0;\nfor (ConstIterator p = V.begin(); p != V.end(); ++p)\nsum += *p;\nreturn sum;\n}\nCodeFragment6.15: Usingaconstantiteratortosumtheelementsofavector.\nSTL Iterator-Based Container Functions\nSTLiterators offer aflexible and uniform waytoaccess theelements ofSTLcon-\ntainers. Many of the member functions and predefined algorithms that work with\nSTL containers use iterators as their arguments. Here are a few of the member\nfunctions oftheSTLvectorclassthat useiterators asarguments. LetV beanSTL\nvector ofsome given base type, and lete bean object of this base type. Let pand\nqbeiteratorsoverthisbasetype,bothdrawnfromthesamecontainer.\nvector(p,q): Constructavectorbyiteratingbetween pandq,copying\neachoftheseelementsintothenewvector.\nassign(p,q): Delete the contents of V, and assigns its new contents\nby iterating between p and q and copying each of these\nelementsintoV.\ninsert(p,e): Insert acopy ofejust prior tothe position given byiter-\nator pandshiftsthesubsequent elementsonepositionto\ntheright.\nerase(p): Remove and destroy the element of V at the position\ngiven by p and shifts the subsequent elements one po-\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 252 \u2014 #274\ni i\n252 Chapter6. ListandIteratorADTs\nsitiontotheleft.\nerase(p,q): Iterate between p and q, removing and destroying all\nthese elements and shifting subsequent elements to the\nlefttofillthegap.\nclear(): DeletealltheseelementsofV.\nWhen presenting a range of iterator values (as we have done above with the\nconstructorV(p,q), assign(p,q), and erase(p,q)), the iterator range is understood\nto start with p and end just prior to q. Borrowing from interval notation in math-\nematics, this iterator range isoften expressed as[p,q), implying that pisincluded\nin the range, but q is not. This convention holds whenever dealing with iterator\nranges.\nNotethat thevector memberfunctions insertand erasemoveelements around\nin the vector. They should be used with care, because they can be quite slow. For\nexample,inserting orerasinganelementatthebeginning ofavectorcausesallthe\nlaterelementsofthevectortobeshiftedoneposition.\nThe above functions are also defined for the STLlist and the STL deque (but,\nofcourse,theconstructorsarenameddifferently). Sincethelistisdefinedasadou-\nbly linked list, there is no need to shift elements when performing insert or erase.\nThese three STL containers (vector, list, and deque) are called sequence contain-\ners,becausetheyexplicitly storeelementsinsequential order. TheSTLcontainers\nset, multiset, map, and multimap support all of the above functions except assign.\nTheyarecalled associated containers, because elements aretypically accessed by\nproviding anassociated keyvalue. WediscusstheminChapter9.\nIt is worthwhile noting that, in the constructor and assignment functions, the\niterators pandqdonotneed tobedrawnfromthesametypeofcontainer asV,as\nlong as the container they are drawn from has the same base type. For example,\nsupposethatLisanSTLlistcontainerofintegers. WecancreateacopyofLinthe\nformofanSTLvectorV asfollows:\nlist<int> L; // an STL list of integers\n// ...\nvector<int> V(L.begin(), L.end()); // initialize V to be a copy of L\nThe iterator-based form of the constructor is quite handy, since it provides an\neasy waytoinitialize thecontents ofanSTLcontainer fromastandard C++array.\nHere,wemakeuseofalow-levelfeatureofC++,whichisinheritedfromitsprede-\ncessor, theCprogramminglanguage. RecallfromSection1.1.3thataC++arrayA\nisrepresented asapointertoitsfirstelementA[0]. Inaddition, A+1pointstoA[1],\nA+2pointstoA[2],andgenerally A+ipointstoA[i].\nAddressingtheelementsofanarrayinthismanneriscalledpointerarithmetic.\nIt is generally frowned upon as poor programming practice, but in this instance it\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 253 \u2014 #275\ni i\n6.2. Lists 253\nprovidesanelegantwaytoinitialize avectorfromanC++array,asfollows.\nint A[] = 2, 5, 3, 8, 6 ; // a C++ array of 5 integers\n{ \u2212 }\nvector<int> V(A, A+5); // V = (2, 5, -3, 8, 6)\nEven though the pointers A and A+5 are not STL iterators, through the magic of\npointer arithmetic, they essentially behave as though they were. This same trick\ncanbeusedtoinitialize anyoftheSTLsequence containers.\nSTL Vectors and Algorithms\nInaddition totheabove memberfunctions forSTLvectors, theSTLalsoprovides\nanumberofalgorithmsthatoperateoncontainers ingeneral,andvectorsinpartic-\nular. Toaccessthesefunctions,usetheincludestatement\u201c#include <algorithm>.\u201d\nLet pandqbeiteratorsoversomebasetype,andletedenoteanobjectofthisbase\ntype. Asabove,theseoperations applytotheiteratorrange[p,q),whichstartsat p\nandendsjustpriortoq.\nsort(p,q): Sort the elements in the range from p to q in ascending\norder. It is assumed that less-than operator (\u201c<\u201d) is de-\nfinedforthebasetype.\nrandom shuffle(p,q): Rearrange the elements in the range from p to q in ran-\ndomorder.\nreverse(p,q): Reversetheelementsintherangefrom ptoq.\nfind(p,q,e): Returnaniteratortothefirstelementintherangefrom p\ntoqthatisequaltoe;ifeisnotfound,qisreturned.\nmin element(p,q): Return an iterator to the minimum element in the range\nfrom ptoq.\nmax element(p,q): Return an iterator to the maximum element in the range\nfrom ptoq.\nfor each(p,q,f): Applythefunction f theelementsintherangefrom pto\nq.\nForexample,tosortanentirevectorV,wewouldusesort(V.begin(),V.end()).\nTosortjustthefirst10elements, wecouldusesort(V.begin(),V.begin()+10).\nAll of the above functions are supported for the STL deque. All of the above\nfunctions, exceptsortandrandom shufflearesupported fortheSTLlist.\nAn Illustrative Example\nIn Code Fragment 6.16, we provide a short example program of the functional-\nity of the STL vector class. The program begins with the necessary \u201c#include\u201d\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 254 \u2014 #276\ni i\n254 Chapter6. ListandIteratorADTs\nstatements. We include <vector>, for the definitions of vectors and iterators, and\n<algorithm>,forthedefinitions ofsortandrandom shuffle.\nWefirstinitializeastandardC++arraycontainingsixintegers,andwethenuse\ntheiterator-basedconstructortocreateasix-elementvectorcontainingthesevalues.\nWe show how to use the member functions size, pop back, push back, front, and\nback. Observethatpoppingdecreasesthearraysizeandpushingincreasesthearray\nsize. Wethenshowhowtouseiterator arithmetic tosortaportion ofthevector, in\nthis case, the first four elements. The call to the erase member function removes\ntwo of the last four elements of the vector. After the removal, the remaining two\nelementsattheendhavebeenshiftedforwardtofilltheemptypositions.\nNext, we demonstrate how to generate a vector of characters. We apply the\nfunction random shuffle to permute the elements of the vector randomly. Finally,\nweshow howtousethemember function insert,toinsert acharacter atthebegin-\nningofthevector. Observehowtheotherelementsareshiftedtotheright.\n#include <cstdlib> // provides EXIT SUCCESS\n#include <iostream> // I/O definitions\n#include <vector> // provides vector\n#include <algorithm> // for sort, random shuffle\nusing namespace std; // make std:: accessible\nint main ()\n{\nint a[] = 17, 12, 33, 15, 62, 45 ;\n{ }\nvector<int> v(a, a + 6); // v: 17 12 33 15 62 45\ncout << v.size() << endl; // outputs: 6\nv.pop back(); // v: 17 12 33 15 62\ncout << v.size() << endl; // outputs: 5\nv.push back(19); // v: 17 12 33 15 62 19\ncout << v.front() << \" \" << v.back() << endl; // outputs: 17 19\nsort(v.begin(), v.begin() + 4); // v: (12 15 17 33) 62 19\nv.erase(v.end() 4, v.end() 2); // v: 12 15 62 19\n\u2212 \u2212\ncout << v.size() << endl; // outputs: 4\nchar b[] = \u2019b\u2019, \u2019r\u2019, \u2019a\u2019, \u2019v\u2019, \u2019o\u2019 ;\n{ }\nvector<char> w(b, b + 5); // w: b r a v o\nrandom shuffle(w.begin(), w.end()); // w: o v r a b\nw.insert(w.begin(), \u2019s\u2019); // w: s o v r a b\nfor (vector<char>::iterator p = w.begin(); p != w.end(); ++p)\ncout << *p << \" \"; // outputs: s o v r a b\ncout << endl;\nreturn EXIT SUCCESS;\n}\nCodeFragment6.16: AnexampleoftheuseoftheSTLvectoranditerators.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 255 \u2014 #277\ni i\n6.3. Sequences 255\n6.3 Sequences\nIn this section, we define an abstract data type that generalizes the vector and list\nADTs. This ADTtherefore provides access toits elements using both indices and\npositions, andisaversatile datastructure forawidevarietyofapplications.\n6.3.1 The Sequence Abstract Data Type\nAsequenceisanADTthatsupports allthefunctions ofthelistADT(discussed in\nSection 6.2), but it also provides functions for accessing elements by their index,\nas we did in the vector ADT (discussed in Section 6.1). The interface consists of\ntheoperations ofthe listADT,plus thefollowing two\u201cbridging\u201d functions, which\nprovideconnections betweenindicesandpositions.\natIndex(i): Returntheposition oftheelementatindexi.\nindexOf(p): Returntheindexoftheelementatposition p.\n6.3.2 Implementing a Sequence with a Doubly Linked List\nOnepossible implementation ofasequence, ofcourse,iswithadoublylinkedlist.\nBydoing so, allofthe functions of thelist ADTcan beeasily implemented torun\nin O(1) time each. The functions atIndex and indexOf from the vector ADT can\nalsobeimplementedwithadoublylinkedlist,thoughinalessefficientmanner.\nInparticular,ifwewantthefunctionsfromthelistADTtorunefficiently(using\nposition objects to indicate where accesses and updates should occur), then we\ncan no longer explicitly store the indices of elements in the sequence. Hence, to\nperformtheoperation atIndex(i),wemustperformlink\u201chopping\u201d fromoneofthe\nends of the list until we locate the node storing the element at index i. As a slight\noptimization, we could start hopping from the closest end of the sequence, which\nwouldachievearunningtimeof\nO(min(i+1,n i)).\n\u2212\nThis is still O(n) in the worst case (when i is near the middle index), but it would\nbe more efficient in applications where many calls to atIndex(i) are expected to\ninvolve index values that are significantly closer to either end of the list. In our\nimplementation, we just use the simple approach of walking from the front of the\nlist,andweleavethetwo-sidedsolution asanexercise(R-6.14).\nIn Code Fragment 6.17, we present a definition of a class NodeSequence,\nwhich implements the sequence ADT. Observe that, because a sequence extends\nthedefinitionofalist,wehaveinherited ourclassbyextending theNodeListclass\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 256 \u2014 #278\ni i\n256 Chapter6. ListandIteratorADTs\nthat was introduced in Section 6.2. We simply add definitions of our bridging\nfunctions. Through the magic of inheritance, users of our class NodeSequence\nhave access to all the members of the NodeList class, including its nested class,\nNodeList::Iterator.\nclass NodeSequence : public NodeList\n{\npublic:\nIterator atIndex(int i) const; // get position from index\nint indexOf(const Iterator& p) const; // get index from position\n;\n}\nCodeFragment6.17: ThedefinitionofclassNodeSequence,whichimplementsthe\nsequence ADTusingadoubly linkedlist.\nNext,inCodeFragment6.18,weshowtheimplementationsoftheatIndexand\nindexOf member functions. The function atIndex(i) hops i positions to the right,\nstarting at the beginning, and returns the resulting position. The function indexOf\nhops through the list until finding the position that matches the given position p.\nObservethattheconditional\u201cq != p\u201dusestheoverloadedcomparisonoperatorfor\npositions definedinCodeFragment6.8.\n// get position from index\nNodeSequence::Iterator NodeSequence::atIndex(int i) const\n{\nIterator p = begin();\nfor (int j = 0; j < i; j++) ++p;\nreturn p;\n}\n// get index from position\nint NodeSequence::indexOf(const Iterator& p) const\n{\nIterator q = begin();\nint j = 0;\nwhile (q != p) // until finding p\n{\n++q; ++j; // advance and count hops\n}\nreturn j;\n}\nCodeFragment6.18:DefinitionofthefunctionsatIndexandindexOfofclassNode-\nSequence.\nBoth of these functions are quite fragile, and are likely to abort if their argu-\nments are not in bounds. A more careful implementation of atIndex would first\ncheck that the argument i lies in the range from 0 to n 1, where n is the size of\n\u2212\nthe sequence. The function indexOf should check that it does not run past the end\nofthesequence. Ineithercase,anappropriate exception shouldbethrown.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 257 \u2014 #279\ni i\n6.3. Sequences 257\nTheworst-case running timesofbothofthefunctions atIndexandindexOfare\nO(n), where n is the size of the list. Although this is not very efficient, we may\ntakeconsolation inthefactthatalltheotheroperations ofthelistADTrunintime\nO(1). A natural alternative approach would be to implement the sequence ADT\nusing an array. Although we could now provide very efficient implementations of\natIndex and indexOf, the insertion and removal operations of the list ADT would\nnow require O(n) time. Thus, neither solution is perfect under all circumstances.\nWeexplorethisalternative inthenextsection.\n6.3.3 Implementing a Sequence with an Array\nSuppose we want to implement a sequence S by storing each element e of S in\na cell A[i] of an array A. We can define a position object p to hold an index i\nand a reference to array A, as member variables. Wecan then implement function\nelement(p)bysimplyreturningareferencetoA[i]. Amajordrawbackwiththisap-\nproach,however,isthatthecellsinAhavenowaytoreferencetheircorresponding\npositions. For example, after performing an insertFront operation, the elements\nhave been shifted to new positions, but we have no way of informing the exist-\ning positions for S that the associated positions of their elements have changed.\n(Remember that positions in a sequence are defined relative to their neighboring\npositions,nottheirranks.) Hence,ifwearegoingtoimplementageneralsequence\nwithanarray,weneedtofindadifferentapproach.\nConsider an alternate solution in which, instead of storing the elements of S\nin array A, we store a pointer to a new kind of position object in each cell of A.\nEach new position object p stores a pair consisting of the index i and the element\ne associated with p. We can easily scan through the array to update the i value\nassociated with each position whose rank changes as the result of an insertion or\ndeletion. AnexampleisshowninFigure6.7,whereanewelementcontainingBWI\nisinsertedatindex1ofanexistingsequence. Aftertheinsertion,theelementsPVD\nand SFO are shifted to the right, so we increment the index value associated with\ntheirindex-element pairs.\n0 JFK 1 PVD 2 SFO 0 JFK 1 BWI 2 PVD 3 SFO\nA A\n0 1 2 3 N-1 0 1 2 3 N-1\nFigure6.7: Anarray-based implementation ofthesequence ADT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 258 \u2014 #280\ni i\n258 Chapter6. ListandIteratorADTs\nIn this array-based implementation of a sequence, the functions insertFront,\ninsert,and erasetake O(n)timebecause wehave toshift position objects tomake\nroom for the new position or to fill in the hole created by the removal of the old\nposition (just as in the insert and remove functions based on rank). All the other\nposition-based functions takeO(1)time.\nNotethatwecanuseanarrayinacircularfashion,aswedidforimplementinga\nqueue(seeSection5.2.4). Withalittlework,wecanthenperformfunctionsinsert-\nFrontinO(1)time. Notethatfunctions insertanderasestilltakeO(n)time. Now,\ntheworstcaseoccurswhentheelementtobeinsertedorremovedhasrank n/2 .\n\u230a \u230b\nTable 6.2 compares the running times of the implementations of the general\nsequence ADT,bymeansofacirculararrayandadoublylinkedlist.\nOperations CircularArray List\nsize,empty O(1) O(1)\natIndex,indexOf O(1) O(n)\nbegin,end O(1) O(1)\n*p,++p,\u2013\u2013p O(1) O(1)\ninsertFront,insertBack O(1) O(1)\ninsert,erase O(n) O(1)\nTable6.2: Comparison of the running times of the functions of a sequence imple-\nmentedwitheither anarray (usedinacircular fashion) oradoubly linkedlist. We\ndenote with n the number of elements in the sequence at the time the operation is\nperformed. ThespaceusageisO(n)forthedoublylinkedlistimplementation, and\nO(N)forthearrayimplementation, whereN isthesizeofthearray.\nSummarizingthistable,weseethatthearray-based implementationissuperior\ntothelinked-list implementation ontherank-based access operations, atIndexand\nindexOf. It is equal in performance to the linked-list implementation on all the\nother access operations. Regarding update operations, the linked-list implementa-\ntionbeatsthearray-based implementation intheposition-based update operations,\ninsertanderase. Forupdateoperations insertFrontandinsertBack,thetwoimple-\nmentations havecomparable performance.\nConsidering space usage, note that an array requires O(N) space, where N is\nthe size ofthearray (unless weutilize anextendable array), while adoubly linked\nlistusesO(n)space,wherenisthenumberofelementsinthesequence. Sincenis\nlessthanorequaltoN,thisimpliesthattheasymptoticspaceusageofalinked-list\nimplementation is superior to that of a fixed-size array, although there is a small\nconstantfactoroverheadthatislargerforlinkedlists,sincearraysdonotneedlinks\ntomaintaintheordering oftheircells.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 259 \u2014 #281\ni i\n6.4. CaseStudy:Bubble-SortonaSequence 259\n6.4 Case Study: Bubble-Sort on a Sequence\nIn this section, we illustrate the use of the sequence ADT and its implementation\ntrade-offswithsampleC++functions usingthewell-knownbubble-sortalgorithm.\n6.4.1 The Bubble-Sort Algorithm\nConsider a sequence of n elements such that any two elements in the sequence\ncanbecomparedaccordingtoanorderrelation(forexample,companiescompared\nbyrevenue,statescomparedbypopulation, orwordscomparedlexicographically).\nThe sorting problem is to reorder the sequence so that the elements are in non-\ndecreasing order. The bubble-sort algorithm (see Figure 6.8) solves this problem\nby performing a series of passes over the sequence. In each pass, the elements\nare scanned by increasing rank, from rank 0 to the end of the sequence. At each\nposition inapass, anelement iscompared withitsneighbor, andifthese twocon-\nsecutiveelementsarefoundtobeinthewrongrelativeorder(thatis,thepreceding\nelementislargerthanthesucceedingone),thenthetwoelementsareswapped. The\nsequence issortedbycompleting nsuchpasses.\npass swaps sequence\n(5,7,2,6,9,3)\n1st 7 2 7 6 9 3 (5,2,6,7,3,9)\n\u2194 \u2194 \u2194\n2nd 5 2 7 3 (2,5,6,3,7,9)\n\u2194 \u2194\n3rd 6 3 (2,5,3,6,7,9)\n\u2194\n4th 5 3 (2,3,5,6,7,9)\n\u2194\nFigure6.8: Thebubble-sort algorithmonasequenceofintegers. Foreachpass,the\nswapsperformedandthesequence afterthepassareshown.\nThebubble-sort algorithm hasthefollowingproperties:\nInthefirstpass,oncethelargestelementisreached,itkeepsonbeingswapped\n\u2022\nuntilitgetstothelastposition ofthesequence.\nIn the second pass, once the second largest element is reached, it keeps on\n\u2022\nbeingswappeduntilitgetstothesecond-to-last position ofthesequence.\nIngeneral,attheendoftheithpass,theright-mostielementsofthesequence\n\u2022\n(thatis,thoseatindicesfromn 1downton i)areinfinalposition.\n\u2212 \u2212\nThe last property implies that it is correct to limit the number of passes made\nbyabubble-sort onann-elementsequence ton. Moreover, itallowstheithpassto\nbelimitedtothefirstn i+1elementsofthesequence.\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 260 \u2014 #282\ni i\n260 Chapter6. ListandIteratorADTs\n6.4.2 A Sequence-Based Analysis of Bubble-Sort\nAssume that the implementation of the sequence is such that the accesses to ele-\nments and the swaps of elements performed by bubble-sort take O(1) time each.\nThat is, the running time of the ith pass is O(n i+1). We have that the overall\n\u2212\nrunning timeofbubble-sort is\nn\n\u2211\nO (n i+1) .\n\u2212\ni=1 !\nWecanrewritethesuminsidethebig-Ohnotationas\nn\n\u2211\nn+(n 1)+ +2+1= i.\n\u2212 \u00b7\u00b7\u00b7\ni=1\nByProposition 4.3,wehave\n\u2211 n n(n+1)\ni= .\n2\ni=1\nThus, bubble-sort runs in O(n2) time, provided that accesses and swaps can each\nbe implemented in O(1) time. As we see in future chapters, this performance for\nsorting is quite inefficient. We discuss the bubble-sort algorithm here. Our aim is\ntodemonstrate, notasanexampleofagoodsortingalgorithm.\nCode Fragments 6.19 and 6.20 present two implementations of bubble-sort on\nasequenceofintegers. TheparameterSisoftypeSequence,butwedonotspecify\nwhether it is a node-based or array-based implementation. The two bubble-sort\nimplementations differ in the preferred choice of functions to access and modify\nthe sequence. The first is based on accessing elements by their index. We use the\nfunction atIndextoaccessthetwoelementsofinterest.\nSince function bubbleSort1 accesses elements only through the index-based\ninterfacefunctionsatIndex,thisimplementationissuitableonlyforthearray-based\nimplementationofthesequence,forwhichatIndextakesO(1)time. Givensuchan\narray-based sequence, thisbubble-sort implementation runsinO(n2)time.\nOn the other hand, if we had used our node-based implementation of the se-\nquence, eachatIndexcallwouldtakeO(n)timeintheworstcase. Sincethisfunc-\ntioniscalled witheachiteration oftheinnerloop, theentirefunction wouldrunin\nO(n3)worst-casetime,whichisquiteslowifnislarge.\nIn contrast to bubbleSort1, our second function, bubbleSort2, accesses the el-\nements entirely through the use of iterators. The iterators prec and succ play the\nrolesthatindices j 1and jplay,respectively, inbubbleSort1. Observethatwhen\n\u2212\nwefirstentertheinnerloopofbubbleSort1,thevalueof j 1is0,thatis,itrefers\n\u2212\ntothefirstelementofthesequence. Thisiswhyweinitialize prectothebeginning\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 261 \u2014 #283\ni i\n6.4. CaseStudy:Bubble-SortonaSequence 261\nvoid bubbleSort1(Sequence& S) // bubble-sort by indices\n{\nint n = S.size();\nfor (int i = 0; i < n; i++) // i-th pass\n{\nfor (int j = 1; j < n i; j++)\n\u2212 {\nSequence::Iterator prec = S.atIndex(j 1); // predecessor\n\u2212\nSequence::Iterator succ = S.atIndex(j); // successor\nif (*prec > *succ) // swap if out of order\n{\nint tmp = *prec; *prec = *succ; *succ = tmp;\n}\n}\n}\n}\nCodeFragment6.19: AC++implementations ofbubble-sort basedonindices.\nofthesequencebeforeenteringtheinnerloop. Wheneverwereentertheinnerloop,\nwe initialize succ to prec and then immediately increment it. Thus, succ refers to\ntheposition immediatelyafterprec. Beforeresumingtheloop,weincrementprec.\nvoid bubbleSort2(Sequence& S) // bubble-sort by positions\n{\nint n = S.size();\nfor (int i = 0; i < n; i++) // i-th pass\n{\nSequence::Iterator prec = S.begin(); // predecessor\nfor (int j = 1; j < n i; j++)\n\u2212 {\nSequence::Iterator succ = prec;\n++succ; // successor\nif (*prec > *succ) // swap if out of order\n{\nint tmp = *prec; *prec = *succ; *succ = tmp;\n}\n++prec; // advance predecessor\n}\n}\n}\nCodeFragment6.20: TwoC++implementations ofbubble-sort.\nSince the iterator increment operator takes O(1) timein either the array-based\nornode-basedimplementationofasequence,thissecondimplementationofbubble-\nsort would run in O(n2) worst-case time, irrespective of the manner in which the\nsequence wasimplemented.\nThetwobubble-sortimplementations givenaboveshowtheimportanceofpro-\nvidingefficientimplementationsofADTs. Nevertheless,inspiteofitsimplementa-\ntionsimplicity,computingresearchersgenerallyfeelthatthebubble-sortalgorithm\nis not a good sorting method, because, even if implemented in the best possible\nway, it still takes quadratic time. Indeed, there are much more efficient sorting\nalgorithms thatruninO(nlogn)time. WeexploretheseinChapters8and11.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 262 \u2014 #284\ni i\n262 Chapter6. ListandIteratorADTs\n6.5 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-6.1 GiveaC++codefragmentforreversing anarray.\nR-6.2 GiveaC++codefragmentforrandomly permutinganarray.\nR-6.3 GiveaC++codefragmentforcircularly rotatinganarraybydistanced.\nR-6.4 Drawa representation of aninitially empty vector Aafter performing the\nfollowing sequence of operations: insert(0,4), insert(0,3), insert(0,2),\ninsert(2,1),insert(1,5),insert(1,6),insert(3,7),insert(0,8).\nR-6.5 GiveanadapterclasstosupporttheStackinterfaceusingthefunctionsof\nthevectorADT.\nR-6.6 Provide the missing housekeeping functions (copy constructor, assign-\nment operator, and destructor) for the class ArrayVector of Code Frag-\nment6.2.\nR-6.7 Provide a fully generic version of the class ArrayVector of Code Frag-\nment6.2usingatemplatedclass.\nR-6.8 Give a templated C++ function sum(v) that returns the sum of elements\nin an STL vector v. Use an STL iterator to enumerate the elements of v.\nAssumethattheelementtypeofvisanynumerictypethatsupportsthe+\noperator.\nR-6.9 Rewrite the justification of Proposition 6.2 under the assumption that the\ncost of growing the array from size k to size 2k is 3k cyber-dollars. How\nmuch should each push operation be charged to make the amortization\nwork?\nR-6.10 Draw pictures illustrating each of the major steps in the algorithms for\nfunctions insert(p,e), insertFront(e), and insertBack(e) of Code Frag-\nment6.5.\nR-6.11 ProvideafullygenericversionoftheclassNodeListofCodeFragment6.9\nusingatemplatedclass.\nR-6.12 Provide the missing housekeeping functions (copy constructor, assign-\nment operator, and destructor) for the class NodeList, which was pre-\nsentedinCodeFragment6.9.\nR-6.13 In our implementation of an iterator for class NodeList in Code Frag-\nment6.7,wedefinedonlythepreincrement operator. Provideadefinition\nforapostincrement operator.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 263 \u2014 #285\ni i\n6.5. Exercises 263\nR-6.14 In our implementation of the atRank(i) function in Code Fragment 6.18\nfor class NodeSequence, we walked from the front of the list. Present a\nmore efficient implementation, which walks from whichever end of the\nlistisclosertoindexi.\nR-6.15 Providethedetailsofanarrayimplementation ofthelistADT.\nR-6.16 Supposethatwehavemadekntotalaccesses totheelementsinalistLof\nnelements,forsomeintegerk 1. Whataretheminimumandmaximum\n\u2265\nnumberofelementsthathavebeenaccessedfewerthanktimes?\nR-6.17 Give pseudo-code describing how to implement all the operations in the\nsequence ADT using an array used in a circular fashion. What is the\nrunning timeforeachofthesefunctions?\nR-6.18 Using the Sequence interface functions, describe arecursive function for\ndeterminingifasequenceSofnintegerobjectscontainsagivenintegerk.\nYour function should not contain any loops. How much space does your\nfunction useinaddition tothespaceusedforS?\nR-6.19 Briefly describe how to perform a new sequence function makeFirst(p)\nthatmovesanelementofasequenceSatposition ptobethefirstelement\nin S while keeping the relative ordering of the remaining elements in S\nunchanged. Your function should run in O(1) time if S is implemented\nwithadoublylinkedlist.\nR-6.20 Describe howto implement aniterator for the class ArrayVector ofCode\nFragment 6.2, based onaninteger index. Include pseudo-code fragments\ndescribing thedereferencing operator(\u201c*\u201d),equality test(\u201c==\u201d),andin-\ncrementanddecrement(\u201c++\u201dand\u201c\u2013\u2013\u201d).\nCreativity\nC-6.1 Describe what changes need to be made to the extendable array imple-\nmentation given in Code Fragment 6.2 in order to avoid unexpected ter-\nmination due to anerror. Specify the new types ofexceptions you would\nadd,andwhenandwheretheyshouldbethrown.\nC-6.2 Give complete C++ code for a new class, ShrinkingVector, that extends\nthe ArrayVector class shown in Code Fragment 6.2 and adds a function,\nshrinkToFit,whichreplacestheunderlying arraywithanarraywhoseca-\npacityisexactlyequaltothenumberofelementscurrentlyinthevector.\nC-6.3 Describewhatchangesneedtobemadetotheextendablearrayimplemen-\ntationgiveninCodeFragment6.2inordertoshrinkthesizeNofthearray\nbyhalfanytimethenumberofelementsinthevectorgoesbelowN/4.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 264 \u2014 #286\ni i\n264 Chapter6. ListandIteratorADTs\nC-6.4 Show that, using an extendable array that grows and shrinks as in the\nprevious exercise, the following series of 2n operations takes O(n) time:\n(i) n push operations on a vector with initial capacity N =1; (ii) n pop\n(removalofthelastelement)operations.\nC-6.5 Describe a function for performing a card shuffle of an array of 2n el-\nements, by converting it into two lists. A card shuffle is a permutation\nwhere a list L is cut into two lists, L and L , where L is the first half of\n1 2 1\nL and L isthe second half of L, and then these two lists are merged into\n2\nonebytakingthefirstelementinL ,thenthefirstelementinL ,followed\n1 2\nbythesecondelementinL ,thesecondelementinL ,andsoon.\n1 2\nC-6.6 Showhowtoimprovetheimplementation offunction insert(i,e)inCode\nFragment 6.5sothat, incase ofanoverflow, theelements arecopied into\ntheirfinalplaceinthenewarray.\nC-6.7 ConsideranimplementationofthevectorADTusinganextendablearray,\nbut instead of copying the elements into an array of double the size (that\nis,fromN to2N)whenitscapacityisreached, wecopytheelementsinto\nanarraywith N/4 additionalcells,goingfromcapacityNtoN+ N/4 .\n\u2308 \u2309 \u2308 \u2309\nShowthat performing asequence ofnpush operations (that is, insertions\nattheend)stillrunsinO(n)timeinthiscase.\nC-6.8 TheNodeListimplementation giveninCodeFragments 6.9through 6.12\ndoes not do any checking to determine whether a given position p is ac-\ntually a member of this particular list. For example, if p is a position in\nlistSandwecallT.insert(p,e)onadifferent listT,thenweactually will\nadd theelement toS justbefore p. Describe how tochange the NodeList\nimplementation inanefficientmannertodisallowsuchmisuses.\nC-6.9 Describe an implementation of the functions insertBack and insertFront\nrealized byusingcombinations ofonlythefunctions emptyandinsert.\nC-6.10 ConsiderthefollowingfragmentofC++code,assumingthattheconstruc-\ntor Sequence creates an empty sequence of integer objects. Recall that\ndivision betweenintegersperformstruncation (forexample,7/2=3).\nSequence<int> seq;\nfor (int i = 0; i < n; i++)\nseq.insertAtRank(i/2, i);\na. Assume that the for loop is executed 10 times, that is, n=10, and\nshowthesequence aftereachiterationoftheloop.\nb. Draw a schematic illustration of the sequence at the end of the for\nloop,foragenericnumbernofiterations.\nC-6.11 SupposewewanttoextendtheSequenceabstractdatatypewithfunctions\nindexOfElement(e)andpositionOfElement(e),whichrespectively return\nthe index and the position of the (first occurrence of) element e in the\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 265 \u2014 #287\ni i\n6.5. Exercises 265\nsequence. Showhowtoimplementthesefunctions byexpressing themin\ntermsofotherfunctions oftheSequenceinterface.\nC-6.12 Describethestructureandpseudo-codeforanarray-basedimplementation\nof the vector ADT that achieves O(1) time for insertions and removals\nat index 0, as well as insertions and removals at the end of the vector.\nYourimplementationshouldalsoprovideforaconstanttimeelemAtRank\nfunction.\nC-6.13 Describeanefficientwayofputtingavectorrepresentingadeckofncards\ninto random order. You may use a function, randomInteger(n), which\nreturns a random number between 0 and n 1, inclusive. Your method\n\u2212\nshould guarantee that every possible ordering is equally likely. What is\ntherunningtimeofyourfunction?\nC-6.14 DesignacircularnodelistADTthatabstractsacircularlylinkedlistinthe\nsamewaythatthenodelistADTabstracts adoublylinkedlist.\nC-6.15 An array is sparse if most of its entries are NULL. A list L can be used\nto implement such an array, A, efficiently. In particular, for each nonnull\ncellA[i],wecanstore anentry(i,e)inL,whereeistheelement storedat\nA[i]. Thisapproachallowsustorepresent AusingO(m)storage,wherem\nisthenumberofnonnullentriesinA. Describeandanalyzeefficientways\nofperformingthefunctions ofthevectorADTonsucharepresentation.\nC-6.16 Showthatonlyn 1passesareneededintheexecutionofbubble-sort on\n\u2212\nasequence withnelements.\nC-6.17 Give a pseudo-code description of an implementation of the bubble-sort\nalgorithm thatuses onlytwostacks and, atmost,fiveadditional variables\nto sort a collection of objects stored initially in one of the stacks. You\nmay operate on the stacks using only functions of the stack ADT. The\nfinaloutputshouldbeoneofthestackscontaining alltheelementssothat\nasequence ofpopoperations wouldlisttheelementsinorder.\nC-6.18 Ausefuloperation indatabases isthenaturaljoin. Ifweviewadatabase\nas a list of ordered pairs of objects, then the natural join of databases A\nandBisthelistofallorderedtriples(x,y,z)suchthatthepair(x,y)isinA\nand thepair (y,z) isinB. Describe and analyze anefficient algorithm for\ncomputing thenaturaljoinofalistAofnpairsandalistBofmpairs.\nC-6.19 WhenBobwantstosendAliceamessageM ontheInternet, hebreaksM\ninto n data packets, numbers the packets consecutively, and injects them\ninto the network. When the packets arrive at Alice\u2019s computer, they may\nbeoutoforder,soAlicemustassemblethesequenceofnpacketsinorder\nbefore she can be sure she has the entire message. Describe an efficient\nschemeforAlicetodothis. Whatistherunning timeofthisalgorithm?\nC-6.20 GivenalistLofnpositiveintegers,eachrepresented withk= logn +1\n\u2308 \u2309\nbits,describe anO(n)-timefunction forfindingak-bitintegernotinL.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 266 \u2014 #288\ni i\n266 Chapter6. ListandIteratorADTs\nC-6.21 Arguewhyanysolutiontothepreviousproblem mustrunin\u2126(n)time.\nC-6.22 Given a list L of n arbitrary integers, design an O(n)-time function for\nfindinganintegerthatcannotbeformedasthesumoftwointegersinL.\nProjects\nP-6.1 Implement the vector ADT by means of an extendable array used in a\ncircular fashion, so thatinsertions and deletions atthebeginning and end\nofthevectorruninconstant time.\nP-6.2 Implement the vector ADT using a doubly linked list. Show experimen-\ntallythatthisimplementation isworsethanthearray-based approach.\nP-6.3 Writeasimpletexteditor,whichstoresastringofcharactersusingthelist\nADT, together with a cursor object that highlights the position of some\ncharacter inthestring (orpossibly theposition before thefirstcharacter).\nYoureditorshouldsupportthefollowingoperationsandredisplaythecur-\nrenttext(thatis,thelist)afterperforminganyoneofthem.\nleft: Movecursorleftonecharacter (ornothingifatthebeginning)\n\u2022\nright: Movecursorrightonecharacter (ordonothing ifattheend)\n\u2022\ndelete: Deletethe character totheright ofthecursor (ordonothing\n\u2022\nifattheend)\ninsert c: Insertthecharactercjustafterthecursor\n\u2022\nP-6.4 Implement the sequence ADTby means of an extendable array used in a\ncircular fashion, so thatinsertions and deletions atthebeginning and end\nofthesequence runinconstanttime.\nP-6.5 ImplementthesequenceADTbymeansofasinglylinkedlist.\nP-6.6 Write acomplete adapter class that implements the sequence ADTusing\nanSTLvectorobject.\nChapter Notes\nSequences and iterators are pervasive concepts in the C++ Standard Template Library\n(STL)[81],andtheyplayfundamentalrolesinJDSL,thedatastructureslibraryinJava.For\nfurtherinformationonSTLvectorandlistclasses,seebooksbyStroustrup[91],Lippmann\nandLajoie[67],andMusserandSaini[81].ThelistADTwasproposedbyseveralauthors,\nincluding Aho, Hopcroft, and Ullman [5], who introduce the \u201cposition\u201d abstraction, and\nWood[104],whodefinesalistADTsimilartoours. Implementationsofsequencesviaar-\nraysandlinkedlistsarediscussedinKnuth\u2019sseminalbook,FundamentalAlgorithms[56].\nKnuth\u2019scompanionvolume,SortingandSearching[57],describesthebubble-sortfunction\nandthehistoryofthisandothersortingalgorithms.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 267 \u2014 #289\ni i\nChapter\n7\nTrees\nContents\n7.1 General Trees . . . . . . . . . . . . . . . . . . . . . . 268\n7.1.1 Tree Definitions and Properties . . . . . . . . . . . . 269\n7.1.2 Tree Functions. . . . . . . . . . . . . . . . . . . . . 272\n7.1.3 A C++ Tree Interface . . . . . . . . . . . . . . . . . 273\n7.1.4 A Linked Structure for General Trees . . . . . . . . . 274\n7.2 Tree Traversal Algorithms . . . . . . . . . . . . . . . . 275\n7.2.1 Depth and Height . . . . . . . . . . . . . . . . . . . 275\n7.2.2 Preorder Traversal . . . . . . . . . . . . . . . . . . . 278\n7.2.3 Postorder Traversal . . . . . . . . . . . . . . . . . . 281\n7.3 Binary Trees . . . . . . . . . . . . . . . . . . . . . . . 284\n7.3.1 The Binary Tree ADT . . . . . . . . . . . . . . . . . 285\n7.3.2 A C++ Binary Tree Interface . . . . . . . . . . . . . 286\n7.3.3 Properties of Binary Trees . . . . . . . . . . . . . . 287\n7.3.4 A Linked Structure for Binary Trees . . . . . . . . . 289\n7.3.5 A Vector-Based Structure for Binary Trees . . . . . . 295\n7.3.6 Traversals of a Binary Tree . . . . . . . . . . . . . . 297\n7.3.7 The Template Function Pattern . . . . . . . . . . . 303\n7.3.8 Representing General Trees with Binary Trees . . . . 309\n7.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 310\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 268 \u2014 #290\ni i\n268 Chapter7. Trees\n7.1 General Trees\nProductivity experts say that breakthroughs come by thinking \u201cnonlinearly.\u201d In\nthis chapter, we discuss one of the most important nonlinear data structures in\ncomputing\u2014trees. Treestructures areindeed abreakthrough indata organization,\nfor they allow us to implement a host of algorithms much faster than when using\nlinear data structures, such as lists, vectors, and sequences. Trees also provide a\nnatural organization fordata, andconsequently havebecome ubiquitous structures\ninfilesystems, graphical userinterfaces, databases, Websites, andothercomputer\nsystems.\nIt is not always clear what productivity experts mean by \u201cnonlinear\u201d thinking,\nbut when we say that trees are \u201cnonlinear,\u201d we are referring to an organizational\nrelationship that is richer than the simple \u201cbefore\u201d and \u201cafter\u201d relationships be-\ntweenobjectsinsequences. Therelationships inatreearehierarchical,withsome\nobjects being \u201cabove\u201d and some \u201cbelow\u201d others. Actually, the main terminology\nfor tree data structures comes from family trees, with the terms \u201cparent,\u201d \u201cchild,\u201d\n\u201cancestor,\u201d and\u201cdescendant\u201d beingthemostcommonwordsusedtodescriberela-\ntionships. WeshowanexampleofafamilytreeinFigure7.1.\nFigure 7.1: A family tree showing some descendants of Abraham, as recorded in\nGenesis,chapters 25\u201336.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 269 \u2014 #291\ni i\n7.1. GeneralTrees 269\n7.1.1 Tree Definitions and Properties\nA tree is an abstract data type that stores elements hierarchically. With the excep-\ntion of the top element, each element in a tree has a parent element and zero or\nmore children elements. A tree is usually visualized by placing elements inside\novals or rectangles, and by drawing the connections between parents and children\nwith straight lines. (See Figure 7.2.) We typically call the top element the root\nof the tree, but it is drawn as the highest element, with the other elements being\nconnected below(justtheopposite ofabotanical tree).\nFigure7.2: Atree with 17 nodes representing the organizational structure of a fic-\ntitious corporation. Electronics R\u2019Usisstored attheroot. Thechildren ofthe root\nstoreR&D,Sales, Purchasing, andManufacturing. Theinternal nodesstoreSales,\nInternational, Overseas, Electronics R\u2019Us,andManufacturing.\nFormal Tree Definition\nFormally, we define tree T to be a set of nodes storing elements in a parent-child\nrelationship withthefollowingproperties:\nIf T is nonempty, it has a special node, called the root of T, that has no\n\u2022\nparent.\nEach node v ofT different from the root has aunique parent node w; every\n\u2022\nnodewithparentwisachildofw.\nNote that according to our definition, a tree can be empty, meaning that it doesn\u2019t\nhave any nodes. This convention also allows us to define a tree recursively, such\nthat a tree T is either empty or consists of a node r, called the root of T, and a\n(possibly empty)setoftreeswhoserootsarethechildren ofr.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 270 \u2014 #292\ni i\n270 Chapter7. Trees\nOther Node Relationships\nTwo nodes that are children of the same parent are siblings. A node v is external\nif v has no children. A node v is internal if it has one or more children. External\nnodesarealsoknownasleaves.\nExample 7.1: Inmostoperatingsystems,filesareorganizedhierarchicallyinto\nnesteddirectories(alsocalledfolders),whicharepresentedtotheuserintheform\nofatree. (SeeFigure7.3.) Morespecifically,theinternalnodesofthetreeare\nassociatedwithdirectoriesandtheexternalnodesareassociatedwithregularfiles.\nIntheUNIXandLinuxoperatingsystems,therootofthetreeisappropriately\ncalledthe\u201crootdirectory,\u201dandisrepresentedbythesymbol\u201c/.\u201d\nFigure7.3: Treerepresenting aportionofafilesystem.\nA node u is an ancestor of a node v if u=v or u is an ancestor of the parent\nofv. Conversely,wesaythatanodevisadescendentofanodeuifuisanancestor\nof v. For example, in Figure 7.3, cs252/ is an ancestor of papers/, and pr3 is a\ndescendent ofcs016/. ThesubtreeofT rooted atanodevisthetreeconsisting of\nallthedescendentsofvinT (includingvitself). InFigure7.3,thesubtreerootedat\ncs016/ consists of the nodes cs016/, grades, homeworks/, programs/, hw1, hw2,\nhw3,pr1,pr2,andpr3.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 271 \u2014 #293\ni i\n7.1. GeneralTrees 271\nEdges and Paths in Trees\nAn edge of tree T is a pair of nodes (u,v) such that u is the parent of v, or vice\nversa. A path of T is asequence of nodes such that any two consecutive nodes in\nthe sequence form an edge. For example, the tree in Figure 7.3 contains the path\n(cs252/, projects/,demos/,market).\nExample 7.2: Whenusingsingleinheritance, theinheritance relationbetween\nclassesinaC++programformsatree.Thebaseclassistherootofthetree.\nOrdered Trees\nAtreeisordered ifthereisalinearordering definedforthechildren ofeachnode;\nthat is, we can identify children of a node as being the first, second, third, and so\non. Suchanordering isdeterminedbyhowthetreeistobeused,andisusuallyin-\ndicatedbydrawingthetreewithsiblingsarrangedfromlefttoright,corresponding\nto their linear relationship. Ordered trees typically indicate the linear order rela-\ntionship existing between siblings by listing them in a sequence or iterator in the\ncorrectorder.\nExample 7.3: Astructureddocument,suchasabook,ishierarchicallyorganized\nasatreewhoseinternalnodesarechapters,sections,andsubsections,andwhose\nexternalnodesareparagraphs,tables,figures,thebibliography,andsoon. (See\nFigure7.4.)Therootofthetreecorrespondstothebookitself.Wecould,infact,\nconsiderexpandingthetreefurthertoshowparagraphsconsistingofsentences,\nsentencesconsistingofwords,andwordsconsistingofcharacters. Inanycase,\nsuchatreeisanexampleofanorderedtree,becausethereisawell-definedordering\namongthechildrenofeachnode.\nFigure7.4: Anorderedtreeassociated withabook.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 272 \u2014 #294\ni i\n272 Chapter7. Trees\n7.1.2 Tree Functions\nThetree ADTstores elements at the nodes of the tree. Because nodes are internal\naspects of our implementation, we do not allow access to them directly. Instead,\neach node of the tree is associated with a position object, which provides public\naccesstonodes. Forthisreason,whendiscussing thepublicinterfacesoffunctions\nof our ADT, we use the notation p (rather than v) to clarify that the argument to\nthe function is a position and not a node. But, given the tight connection between\nthese two objects, we often blur the distinction between them, and use the terms\n\u201cposition\u201d and\u201cnode\u201d interchangeably fortrees.\nAs we did with positions for lists in Chapter 6, we exploit C++\u2019s ability to\noverload the dereferencing operator (\u201c*\u201d) to access the element associated with a\nposition. Given a position variable p, the associated element is accessed by *p.\nThiscanbeusedbothforreading andmodifyingtheelement\u2019svalue.\nItisusefultostorecollectionsofpositions. Forexample,thechildrenofanode\ninatree canbepresented tothe useras such alist. Wedefineposition list, tobe a\nlistwhoseelementsaretreepositions.\nTherealpowerofatreepositionarisesfromitsabilitytoaccesstheneighboring\nelementsofthetree. Givenaposition poftreeT,wedefinethefollowing:\np.parent(): Returntheparentof p;anerroroccursif pistheroot.\np.children(): Returnapositionlistcontaining thechildrenofnode p.\np.isRoot(): Returntrueif pistherootandfalseotherwise.\np.isExternal(): Returntrueif pisexternal andfalseotherwise.\nIf atree T is ordered, then the list provided by p.children() provides access to the\nchildren of pin order. If pisanexternal node, then p.children()returns an empty\nlist. If we wanted, we could also provide a function p.isInternal(), which would\nsimplyreturnthecomplementof p.isExternal().\nThetreeitself provides thefollowing functions. Thefirsttwo, sizeandempty,\nare just the standard functions that wedefined for the other container types weal-\nreadysaw. Thefunctionrootyieldsthepositionoftherootandpositionsproduces\nalistcontaining allthetree\u2019snodes.\nsize(): Returnthenumberofnodesinthetree.\nempty(): Returntrueifthetreeisemptyandfalseotherwise.\nroot(): Returnapositionforthetree\u2019sroot;anerroroccursifthe\ntreeisempty.\npositions(): Returnapositionlistofallthenodesofthetree.\nWe have not defined any specialized update functions for a tree here. Instead,\nwe prefer to describe different tree update functions in conjunction with specific\napplications oftrees insubsequent chapters. Infact, wecanimagine several kinds\noftreeupdate operations beyondthosegiveninthisbook.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 273 \u2014 #295\ni i\n7.1. GeneralTrees 273\n7.1.3 A C++ Tree Interface\nLetuspresentaninformalC++interface forthetreeADT.Webeginbypresenting\nan informal C++ interface for the class Position, which represents a position in a\ntree. ThisisgiveninCodeFragment7.1.\ntemplate <typename E> // base element type\nclass Position<E> // a node position\n{\npublic:\nE& operator*(); // get element\nPosition parent() const; // get parent\nPositionList children() const; // get node\u2019s children\nbool isRoot() const; // root node?\nbool isExternal() const; // external node?\n;\n}\nCodeFragment7.1: An informal interface for a position in a tree (not a complete\nC++class).\nWe have provided a version of the derferencing operator (\u201c*\u201d) that returns a\nstandard (readable and writable) reference. (For simplicity, we did not provide a\nversionthatreturnsaconstant reference, butthiswouldbeaneasyaddition.)\nNext, in Code Fragment 7.2, wepresent our informal C++ interface for a tree.\nTokeep the interface as simple aspossible, weignore error processing; hence, we\ndonotdeclareanyexceptions tobethrown.\ntemplate <typename E> // base element type\nclass Tree<E>\n{\npublic: // public types\nclass Position; // a node position\nclass PositionList; // a list of positions\npublic: // public functions\nint size() const; // number of nodes\nbool empty() const; // is tree empty?\nPosition root() const; // get the root\nPositionList positions() const; // get positions of all nodes\n;\n}\nCodeFragment7.2: AninformalinterfaceforthetreeADT(notacompleteclass).\nAlthough we have not formally defined an interface for the class PositionList,\nwe may assume that it satisfies the standard list ADT as given in Chapter 6. In\nour code examples, we assume that PositionList is implemented as an STL list of\nobjectsoftypePosition,ormoreconcretely,\u201cstd::list<Position>.\u201d Inparticular,we\nassumethatPositionListprovidesaniteratortype,whichwesimplycallIteratorin\nourlaterexamples.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 274 \u2014 #296\ni i\n274 Chapter7. Trees\n7.1.4 A Linked Structure for General Trees\nA natural way to realize a tree T is to use a linked structure, where we represent\neachnodeofT byaposition object p(seeFigure7.5(a))withthefollowing fields:\na reference to the node\u2019s element, a link to the node\u2019s parent, and some kind of\ncollection (for example, a list or array) to store links to the node\u2019s children. If p\nis the root of T, then the parent field of p is NULL. Also, we store a reference to\nthe root of T and the number of nodes of T in internal variables. This structure is\nschematically illustrated inFigure7.5(b).\nparent\nPVD\nelement\nchildrenContainer\nATL BWI JFK LAX\n(a) (b)\nFigure 7.5: The linked structure for a general tree: (a) the node structure; (b) the\nportionofthedatastructure associated withanodeanditschildren.\nTable 7.1 summarizes the performance of the linked-structure implementation\nof a tree. The analysis is left as an exercise (C-7.27), but wenote that, by using a\ncontainer to store the children of each node p, we can implement the children(p)\nfunction byusingtheiteratorforthecontainer toenumerate itselements.\nOperation Time\nisRoot,isExternal O(1)\nparent O(1)\nchildren(p) O(c )\np\nsize,empty O(1)\nroot O(1)\npositions O(n)\nTable7.1: Runningtimesofthefunctionsofann-nodelinkedtreestructure. Letc\np\ndenotethenumberofchildrenofanode p. ThespaceusageisO(n).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 275 \u2014 #297\ni i\n7.2. TreeTraversalAlgorithms 275\n7.2 Tree Traversal Algorithms\nIn this section, we present algorithms for performing traversal computations on a\ntreebyaccessing itthrough thetreeADTfunctions.\n7.2.1 Depth and Height\nLet pbeanodeofatreeT. Thedepthof pisthenumberofancestorsof p,exclud-\ning p itself. For example, in the tree of Figure 7.2, the node storing International\nhas depth 2. Note that this definition implies that the depth of the root of T is 0.\nThedepthof p\u2019snodecanalsoberecursively definedasfollows:\nIf pistheroot,thenthedepthof pis0\n\u2022\nOtherwise,thedepthof pisoneplusthedepthoftheparentof p\n\u2022\nBased on the above definition, the recursive algorithm depth(T,p) shown in\nCodeFragment7.3,computesthedepthofanodereferencedbyposition pofT by\ncallingitselfrecursively ontheparentof p,andadding1tothevaluereturned.\nAlgorithmdepth(T,p):\nif p.isRoot()then\nreturn0\nelse\nreturn1+depth(T,p.parent())\nCodeFragment7.3: Analgorithm tocomputethedepthofanode pinatreeT.\nAsimpleC++implementation ofalgorithm depthisshowninCodeFragment7.4.\nint depth(const Tree& T, const Position& p)\n{\nif (p.isRoot())\nreturn 0; // root has depth 0\nelse\nreturn 1 + depth(T, p.parent()); // 1 + (depth of parent)\n}\nCodeFragment7.4: AC++implementationofthealgorithmofCodeFragment7.3.\nThe running time of algorithm depth(T,p) is O(d ), where d denotes the\np p\ndepth of the node p in the tree T, because the algorithm performs a constant-time\nrecursive step for each ancestor of p. Thus, in the worst case, the depth algorithm\nruns in O(n) time, where n is the total number of nodes in the tree T, since some\nnodes may have this depth in T. Although such a running time is a function of\nthe input size, it is more accurate to characterize the running time in terms of the\nparameterd ,sinceitisoftenmuchsmallerthann.\np\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 276 \u2014 #298\ni i\n276 Chapter7. Trees\nTheheightofanode pinatreeT isalsodefinedrecursively.\nIf pisexternal, thentheheightof pis0\n\u2022\nOtherwise,theheightof pisoneplusthemaximumheightofachildof p\n\u2022\nThe height of a tree T is the height of the root of T. For example, the tree of\nFigure7.2hasheight4. Inaddition, heightcanalsobeviewedasfollows.\nProposition 7.4: Theheightofatreeisequaltothemaximumdepthofitsexter-\nnalnodes.\nWe leave the justification of this fact to an exercise (R-7.7). Based on this\nproposition,wepresentanalgorithm,height1,forcomputingtheheightofatreeT.\nItisshowninCodeFragment7.5. Itenumeratesallthenodesinthetreeandinvokes\nfunction depth(CodeFragment7.3)tocomputethedepthofeachexternalnode.\nAlgorithmheight1(T):\nh=0\nforeach p T.positions()do\n\u2208\nif p.isExternal()then\nh=max(h,depth(T,p))\nreturnh\nCode Fragment 7.5: Algorithm height1(T) for computing the height of a tree T\nbasedoncomputing themaximumdepthoftheexternalnodes.\nTheC++implementation ofthisalgorithmisshowninCodeFragment7.6. We\nassume that Iteratoris the iterator class for PositionList. Given such an iterator q,\nwecanaccesstheassociated positionas*q.\nint height1(const Tree& T)\n{\nint h = 0;\nPositionList nodes = T.positions(); // list of all nodes\nfor (Iterator q = nodes.begin(); q != nodes.end(); ++q)\n{\nif (q >isExternal())\n\u2212\nh = max(h, depth(T, *q)); // get max depth among leaves\n}\nreturn h;\n}\nCodeFragment7.6: AC++implementation ofthefunctionheight1.\nUnfortunately, algorithmheight1isnotveryefficient. Sinceheight1callsalgo-\nrithm depth(p)oneach external node pofT,therunning timeofheight1isgiven\nbyO(n+\u2211 (1+d )),wherenisthenumberofnodesofT,d isthedepthofnode\np p p\np, and E is the set of external nodes of T. In the worst case, the sum \u2211 (1+d )\np p\nisproportional ton2. (SeeExerciseC-7.8.) Thus, algorithm height1runs inO(n2)\ntime.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 277 \u2014 #299\ni i\n7.2. TreeTraversalAlgorithms 277\nAlgorithm height2, shown in Code Fragment 7.7 and implemented in C++ in\nCode Fragment 7.8, computes the height of tree T in a more efficient manner by\nusingtherecursivedefinitionofheight.\nAlgorithmheight2(T,p):\nif p.isExternal() then\nreturn0\nelse\nh=0\nforeachq p.children()do\n\u2208\nh=max(h,height2(T,q))\nreturn1+h\nCode Fragment 7.7: A more efficient algorithm for computing the height of the\nsubtreeoftreeT rootedatanode p.\nint height2(const Tree& T, const Position& p)\n{\nif (p.isExternal()) return 0; // leaf has height 0\nint h = 0;\nPositionList ch = p.children(); // list of children\nfor (Iterator q = ch.begin(); q != ch.end(); ++q)\nh = max(h, height2(T, *q));\nreturn 1 + h; // 1 + max height of children\n}\nCodeFragment7.8: Methodheight2writteninC++.\nAlgorithm height2 is more efficient than height1 (from Code Fragment 7.5).\nThe algorithm is recursive, and, if it is initially called on the root of T, it will\neventually be called on each node of T. Thus, we can determine the running time\nof this method by summing, over all the nodes, the amount of time spent at each\nnode (on the nonrecursive part). Processing each node in children(p) takes O(c )\np\ntime, where c denotes the number of children of node p. Also, the while loop\np\nhas c iterations and each iteration of the loop takes O(1) time plus the time for\np\nthe recursive call on a child of p. Thus, algorithm height2 spends O(1+c ) time\np\nat each node p, and its running time is O(\u2211 (1+c )). In order to complete the\np p\nanalysis, wemakeuseofthefollowingproperty.\nProposition 7.5: LetT beatreewithn nodes,andletc denotethenumberof\np\nchildrenofanodepofT.Then\u2211 c =n 1.\np p\n\u2212\nJustification: EachnodeofT,withtheexceptionoftheroot,isachildofanother\nnode,andthuscontributes oneunittotheabovesum.\nByProposition 7.5, therunning timeofalgorithm height2, whencalled onthe\nrootofT,isO(n),wherenisthenumberofnodesofT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 278 \u2014 #300\ni i\n278 Chapter7. Trees\n7.2.2 Preorder Traversal\nAtraversalofatreeT isasystematicwayofaccessing, or\u201cvisiting,\u201dallthenodes\nof T. In this section, we present a basic traversal scheme for trees, called pre-\nordertraversal. Inthenextsection,westudyanotherbasictraversalscheme,called\npostorder traversal.\nIn a preorder traversal of a tree T, the root of T is visited first and then the\nsubtrees rooted at its children are traversed recursively. Ifthe tree isordered, then\nthesubtreesaretraversedaccordingtotheorderofthechildren. Thespecificaction\nassociatedwiththe\u201cvisit\u201dofanodedependsontheapplicationofthistraversal,and\ncould involve anything from incrementing a counter to performing some complex\ncomputationforthisnode. Thepseudo-codeforthepreordertraversalofthesubtree\nrooted at a node referenced by position p is shown in Code Fragment 7.9. We\ninitially invokethisroutinewiththecallpreorder(T,T.root()).\nAlgorithmpreorder(T,p):\nperformthe\u201cvisit\u201dactionfornode p\nfor eachchildqof p do\nrecursively traversethesubtreerootedatqbycalling preorder(T,q)\nCodeFragment7.9: Algorithmpreorderforperformingthepreordertraversalofthe\nsubtreeofatreeT rootedatanode p.\nThe preorder traversal algorithm is useful for producing a linear ordering of\nthe nodes of a tree where parents must always come before their children in the\nordering. Such orderings have several different applications. Weexplore a simple\ninstance ofsuchanapplication inthenextexample.\nPaper\nTitle Abstract \u00a7 1 \u00a7 2 \u00a7 3 References\n\u00a7 1.1 \u00a7 1.2 \u00a7 2.1 \u00a7 2.2 \u00a7 2.3 \u00a7 3.1 \u00a7 3.2\nFigure7.6: Preorder traversal of an ordered tree, where the children of each node\nareorderedfromlefttoright.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 279 \u2014 #301\ni i\n7.2. TreeTraversalAlgorithms 279\nExample 7.6: Thepreordertraversalofthetreeassociatedwithadocument,asin\nExample7.3,examinesanentiredocumentsequentially,frombeginningtoend.If\ntheexternalnodesareremovedbeforethetraversal,thenthetraversalexaminesthe\ntableofcontentsofthedocument.(SeeFigure7.6.)\nThepreorder traversal isalso an efficient waytoaccess allthe nodes ofatree.\nTo justify this, let us consider the running time of the preorder traversal of a tree\nT with n nodes under the assumption that visiting a node takes O(1) time. The\nanalysis of the preorder traversal algorithm is actually similar to that of algorithm\nheight2 (Code Fragment 7.8), given in Section 7.2.1. At each node p, the nonre-\ncursive part of the preorder traversal algorithm requires time O(1+c ), where c\np p\nis the number of children of p. Thus, by Proposition 7.5, the overall running time\nofthepreorder traversalofT isO(n).\nAlgorithm preorderPrint(T,p), implemented in C++ in Code Fragment 7.10,\nperformsapreorderprintingofthesubtreeofanode pofT,thatis,itperformsthe\npreorder traversalofthesubtree rootedat pandprintstheelementstoredatanode\nwhenthenodeisvisited. Recallthat,foranorderedtreeT,function T.children(p)\nreturns aniterator thataccesses thechildren of pinorder. WeassumethatIterator\nisthisiterator type. Givenaniteratorq,theassociated position isgivenby*q.\nvoid preorderPrint(const Tree& T, const Position& p)\n{\ncout << *p; // print element\nPositionList ch = p.children(); // list of children\nfor (Iterator q = ch.begin(); q != ch.end(); ++q)\n{\ncout << \" \";\npreorderPrint(T, *q);\n}\n}\nCodeFragment7.10: MethodpreorderPrint(T,p)thatperformsapreorderprinting\noftheelementsinthesubtree associated withposition pofT.\nThere is an interesting variation of the preorderPrint function that outputs a\ndifferent representation of an entire tree. The parenthetic string representation\nP(T) of tree T is recursively defined as follows. If T consists of a single node\nreferenced byaposition p,then\nP(T)=*p.\nOtherwise,\nP(T)=*p+\"(\"+P(T )+P(T )+ +P(T )+\")\",\n1 2 k\n\u00b7\u00b7\u00b7\nwhere p is the root position of T and T ,T ,...,T are the subtrees rooted at the\n1 2 k\nchildren of p,whicharegiveninorderifT isanorderedtree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 280 \u2014 #302\ni i\n280 Chapter7. Trees\nNote that the definition of P(T) is recursive. Also, we are using \u201c+\u201d here\nto denote string concatenation. (Recall the string type from Section 1.1.3.) The\nparenthetic representation ofthetreeofFigure7.2isshowninFigure7.7.\nElectronics R\u2019Us(\nR&D\nSales(\nDomestic\nInternational (\nCanada\nS.America\nOverseas(Africa Europe Asia Australia)))\nPurchasing\nManufacturing (TV CD Tuner ))\nFigure 7.7: Parenthetic representation of the tree of Figure 7.2. Indentation, line\nbreaks, andspaceshavebeenaddedforclarity.\nNote that, technically speaking, there are some computations that occur be-\ntweenand aftertherecursive calls atanode\u2019s children intheabove algorithm. We\nstill consider this algorithm to be a preorder traversal, however, since the primary\nactionofprinting anode\u2019scontents occurspriortotherecursivecalls.\nThe C++ function parenPrint, shown in Code Fragment 7.11, is a variation of\nfunction preorderPrint (Code Fragment 7.10). It implements the definition given\nabovetooutputaparenthetic stringrepresentation ofatreeT. Itfirstprintstheele-\nmentassociatedwitheachnode. Foreachinternalnode,wefirstprint\u201c(\u201d,followed\nbytheparenthetical representation ofeachofitschildren, followedby\u201c)\u201d.\nvoid parenPrint(const Tree& T, const Position& p)\n{\ncout << *p; // print node\u2019s element\nif (!p.isExternal())\n{\nPositionList ch = p.children(); // list of children\ncout << \"( \"; // open\nfor (Iterator q = ch.begin(); q != ch.end(); ++q)\n{\nif (q != ch.begin()) cout << \" \"; // print separator\nparenPrint(T, *q); // visit the next child\n}\ncout << \" )\"; // close\n}\n}\nCodeFragment7.11: AC++implementation ofalgorithm parenPrint.\nWe explore a modification of Code Fragment 7.11 in Exercise R-7.10, to dis-\nplayatreeinafashionmorecloselymatchingthatgiveninFigure7.7.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 281 \u2014 #303\ni i\n7.2. TreeTraversalAlgorithms 281\n7.2.3 Postorder Traversal\nAnother important tree traversal algorithm is the postorder traversal. This algo-\nrithmcanbeviewedastheoppositeofthepreordertraversal,becauseitrecursively\ntraversesthesubtreesrootedatthechildrenoftherootfirst,andthenvisitstheroot.\nItissimilartothepreordertraversal,however,inthatweuseittosolveaparticular\nproblem by specializing an action associated with the \u201cvisit\u201d of a node p. Still,\nas with the preorder traversal, if the tree is ordered, we make recursive calls for\nthe children of a node p according to their specified order. Pseudo-code for the\npostorder traversal isgiveninCodeFragment7.12.\nAlgorithmpostorder(T,p):\nfor eachchildqof p do\nrecursively traversethesubtreerootedatqbycalling postorder(T,q)\nperformthe\u201cvisit\u201dactionfornode p\nCodeFragment7.12: Algorithmpostorderforperformingthepostordertraversalof\nthesubtreeofatreeT rootedatanode p.\nThe name of the postorder traversal comes from the fact that this traversal\nmethod visits a node pafter it has visited all the other nodes in the subtree rooted\nat p. (SeeFigure7.8.)\nPaper\nTitle Abstract \u00a7 1 \u00a7 2 \u00a7 3 References\n\u00a7 1.1 \u00a7 1.2 \u00a7 2.1 \u00a7 2.2 \u00a7 2.3 \u00a7 3.1 \u00a7 3.2\nFigure7.8: Postordertraversal oftheorderedtreeofFigure7.6.\nTheanalysisoftherunningtimeofapostorder traversalisanalogous tothatof\na preorder traversal. (See Section 7.2.2.) The total time spent in the nonrecursive\nportions of the algorithm is proportional to the time spent visiting the children of\neach node in the tree. Thus, a postorder traversal of a tree T with n nodes takes\nO(n)time,assumingthatvisitingeachnodetakesO(1)time. Thatis,thepostorder\ntraversal runsinlineartime.\nIn Code Fragment 7.13, wepresent a C++ function postorderPrint which per-\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 282 \u2014 #304\ni i\n282 Chapter7. Trees\nformsapostorder traversal ofatreeT. Thisfunction printstheelementstored ata\nnodewhenitisvisited.\nvoid postorderPrint(const Tree& T, const Position& p)\n{\nPositionList ch = p.children(); // list of children\nfor (Iterator q = ch.begin(); q != ch.end(); ++q)\n{\npostorderPrint(T, *q);\ncout << \" \";\n}\ncout << *p; // print element\n}\nCodeFragment7.13: ThefunctionpostorderPrint(T,p),whichprintstheelements\nofthesubtree ofposition pofT.\nThe postorder traversal method is useful for solving problems where we wish\nto compute some property for each node p in a tree, but computing that property\nfor p requires that we have already computed that same property for p\u2019s children.\nSuchanapplication isillustrated inthefollowingexample.\nExample 7.7: Considerafile-systemtreeT,whereexternalnodesrepresentfiles\nandinternalnodesrepresentdirectories(Example7.1).Supposewewanttocom-\nputethediskspaceusedbyadirectory,whichisrecursivelygivenbythesumof\nthefollowing(seeFigure7.9):\nThesizeofthedirectoryitself\n\u2022\nThesizesofthefilesinthedirectory\n\u2022\nThespaceusedbythechildrendirectories\n\u2022\nFigure7.9: ThetreeofFigure7.3representingafilesystem,showingthenameand\nsizeoftheassociatedfile/directoryinsideeachnode,andthediskspaceusedbythe\nassociated directory aboveeachinternalnode.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 283 \u2014 #305\ni i\n7.2. TreeTraversalAlgorithms 283\nThiscomputationcanbedonewithapostordertraversaloftreeT. Afterthe\nsubtreesofaninternalnodephavebeentraversed,wecomputethespaceusedby\np byaddingthesizesofthedirectory p itselfandofthefilescontainedin p,to\nthespaceusedbyeachinternalchildofp,whichwascomputedbytherecursive\npostordertraversalsofthechildrenofp.\nMotivated by Example 7.7, algorithm diskSpace, which is presented in Code\nFragment 7.14, performs a postorder traversal of a file-system tree T, printing the\nname and disk space used by the directory associated with each internal node of\nT. When called on the root of tree T, diskSpaceruns in timeO(n), where nis the\nnumberofnodesofthetree,provided theauxiliary functions name(p)andsize(p)\ntakeO(1)time.\nint diskSpace(const Tree& T, const Position& p)\n{\nint s = size(p); // start with size of p\nif (!p.isExternal()) // if p is internal\n{\nPositionList ch = p.children(); // list of p\u2019s children\nfor (Iterator q = ch.begin(); q != ch.end(); ++q)\ns += diskSpace(T, *q); // sum the space of subtrees\ncout << name(p) << \": \" << s << endl; // print summary\n}\nreturn s;\n}\nCodeFragment7.14:ThefunctiondiskSpace,whichprintsthenameanddiskspace\nused by the directory associated with p, for each internal node p of a file-system\ntree T. Thisfunction calls the auxiliary functions nameand size,which should be\ndefinedtoreturnthenameandsizeofthefile/directory associated withanode.\nOther Kinds of Traversals\nPreordertraversalisusefulwhenwewanttoperformanactionforanodeandthen\nrecursively perform that action for its children, and postorder traversal is useful\nwhen we want to first perform an action on the descendents of a node and then\nperform thatactiononthenode.\nAlthough the preorder and postorder traversals are common ways of visiting\nthe nodes of a tree, we can also imagine other traversals. For example, we could\ntraverse atree so that wevisit all the nodes at depth d before wevisit the nodes at\ndepthd+1. Suchatraversal,calledabreadth-firsttraversal,couldbeimplemented\nusingaqueue,whereasthepreorderandpostordertraversalsuseastack. (Thisstack\nis implicit in our use of recursion to describe these functions, but we could make\nthis use explicit, as well, to avoid recursion.) In addition, binary trees, which we\ndiscussnext,supportanadditionaltraversalmethodknownastheinordertraversal.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 284 \u2014 #306\ni i\n284 Chapter7. Trees\n7.3 Binary Trees\nAbinarytreeisanorderedtreeinwhicheverynodehasatmosttwochildren.\n1. Everynodehasatmosttwochildren.\n2. Eachchildnodeislabeledasbeingeitheraleftchildorarightchild.\n3. Aleftchildprecedes arightchildintheordering ofchildren ofanode.\nThe subtree rooted at a left or right child of an internal node is called the node\u2019s\nleftsubtreeorrightsubtree, respectively. Abinary treeisproper ifeachnode has\neitherzeroortwochildren. Somepeoplealsorefertosuchtreesasbeingfullbinary\ntrees. Thus, in a proper binary tree, every internal node has exactly two children.\nAbinarytreethatisnotproperisimproper.\nExample 7.8: Animportantclassofbinarytreesarisesincontextswherewewish\ntorepresentanumberofdifferentoutcomesthatcanresultfromansweringaseries\nofyes-or-noquestions.Eachinternalnodeisassociatedwithaquestion.Startingat\ntheroot,wegototheleftorrightchildofthecurrentnode,dependingonwhether\ntheanswertothequestionis\u201cYes\u201dor\u201cNo.\u201d Witheachdecision,wefollowan\nedgefromaparenttoachild,eventuallytracingapathinthetreefromtheroot\ntoanexternalnode. Suchbinarytreesareknownasdecision trees,becauseeach\nexternalnodepinsuchatreerepresentsadecisionofwhattodoifthequestions\nassociatedwith p\u2019sancestorsareansweredinawaythatleadsto p. Adecision\ntreeisaproperbinarytree. Figure7.10illustratesadecisiontreethatprovides\nrecommendationstoaprospectiveinvestor.\nFigure7.10: Adecision treeprovidinginvestment advice.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 285 \u2014 #307\ni i\n7.3. BinaryTrees 285\nExample 7.9: Anarithmeticexpressioncanberepresentedbyatreewhoseexter-\nnalnodesareassociatedwithvariablesorconstants,andwhoseinternalnodesare\nassociatedwithoneoftheoperators+, , ,and/.(SeeFigure7.11.)Eachnode\n\u2212 \u00d7\ninsuchatreehasavalueassociatedwithit.\nIfanodeisexternal,thenitsvalueisthatofitsvariableorconstant.\n\u2022\nIfanodeisinternal,thenitsvalueisdefinedbyapplyingitsoperationtothe\n\u2022\nvaluesofitschildren.\nSuchanarithmetic-expressiontreeisaproperbinarytree,sinceeachoftheoper-\nators+, , ,and/ takeexactlytwooperands. Ofcourse,ifweweretoallow\n\u2212 \u00d7\nforunaryoperators,likenegation( ),asin\u201c x,\u201dthenwecouldhaveanimproper\n\u2212 \u2212\nbinarytree.\nFigure7.11: A binary tree representing an arithmetic expression. This tree repre-\nsentstheexpression((((3+1) 3)/((9 5)+2)) ((3 (7 4))+6)). Thevalue\n\u00d7 \u2212 \u2212 \u00d7 \u2212\nassociated withtheinternalnodelabeled \u201c/\u201dis2.\nA Recursive Binary Tree Definition\nIncidentally, wecan also define a binary tree inarecursive waysuch that abinary\ntreeiseitheremptyorconsistsof:\nAnoder,calledtherootofT andstoringanelement\n\u2022\nAbinarytree,calledtheleftsubtreeofT\n\u2022\nAbinarytree,calledtherightsubtreeofT\n\u2022\nWediscusssomeofthespecialized topicsforbinarytreesbelow.\n7.3.1 The Binary Tree ADT\nIn this section, we introduce an abstract data type for a binary tree. As with our\nearlier tree ADT, each node of the tree stores an element and is associated with a\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 286 \u2014 #308\ni i\n286 Chapter7. Trees\nposition object, which provides public access to nodes. Byoverloading the deref-\nerencing operator, theelementassociated withaposition pcanbeaccessed by*p.\nInaddition, aposition psupports thefollowingoperations.\np.left(): Return the left child of p; an error condition occurs if p\nisanexternal node.\np.right(): Returntherightchildof p;anerrorconditionoccursif p\nisanexternal node.\np.parent(): Returntheparentof p;anerroroccursif pistheroot.\np.isRoot(): Returntrueif pistherootandfalseotherwise.\np.isExternal(): Returntrueif pisexternal andfalseotherwise.\nThe tree itself provides the same operations as the standard tree ADT. Recall\nthataposition listisalistoftreepositions.\nsize(): Returnthenumberofnodesinthetree.\nempty(): Returntrueifthetreeisemptyandfalseotherwise.\nroot(): Returnapositionforthetree\u2019sroot;anerroroccursifthe\ntreeisempty.\npositions(): Returnapositionlistofallthenodesofthetree.\nAsinSection7.1.2forthetreeADT,wedonotdefinespecializedupdatefunctions\nforbinarytrees,butweconsiderthemlater.\n7.3.2 A C++ Binary Tree Interface\nLet us present an informal C++ interface for the binary tree ADT. We begin in\nCode Fragment 7.15 by presenting an informal C++ interface for the class Posi-\ntion,whichrepresents aposition inatree. Itdiffers from thetreeinterface ofSec-\ntion 7.1.3 by replacing the tree member function children with the two functions\nleftandright.\ntemplate <typename E> // base element type\nclass Position<E> // a node position\n{\npublic:\nE& operator*(); // get element\nPosition left() const; // get left child\nPosition right() const; // get right child\nPosition parent() const; // get parent\nbool isRoot() const; // root of tree?\nbool isExternal() const; // an external node?\n;\n}\nCodeFragment7.15:AninformalinterfaceforthebinarytreeADT(notacomplete\nC++class).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 287 \u2014 #309\ni i\n7.3. BinaryTrees 287\nNext,inCodeFragment7.16,wepresentaninformalC++interfaceforabinary\ntree. Tokeeptheinterfaceassimpleaspossible, wehaveignorederrorprocessing,\nandhencewedonotdeclareanyexceptions tobethrown.\ntemplate <typename E> // base element type\nclass BinaryTree<E> // binary tree\n{\npublic: // public types\nclass Position; // a node position\nclass PositionList; // a list of positions\npublic: // member functions\nint size() const; // number of nodes\nbool empty() const; // is tree empty?\nPosition root() const; // get the root\nPositionList positions() const; // list of nodes\n;\n}\nCodeFragment7.16:AninformalinterfaceforthebinarytreeADT(notacomplete\nC++class).\nAlthough we have not formally defined an interface for the class PositionList,\nwe may assume that it satisfies the standard list ADT as given in Chapter 6. In\nour code examples, we assume that PositionList is implemented as an STL list of\nobjectsoftypePosition.\n7.3.3 Properties of Binary Trees\nBinarytrees haveseveral interesting properties dealing withrelationships between\ntheirheightsandnumberofnodes. WedenotethesetofallnodesofatreeT,atthe\nsamedepth d, asthelevel d ofT. Inabinary tree, level0has one node (the root),\nlevel 1has, atmost, two nodes (the children ofthe root), level 2has, atmost, four\nnodes, andsoon. (SeeFigure7.12.) Ingeneral, leveld has,atmost,2d nodes.\nWe can see that the maximum number of nodes on the levels of a binary tree\ngrowsexponentially aswegodownthetree. Fromthissimpleobservation, wecan\nderive the following properties relating the height of a binary T to its number of\nnodes. Adetailed justification oftheseproperties isleftasanexercise(R-7.16).\nProposition 7.10: LetT beanonemptybinarytree,andletn,n ,n andhdenote\nE I\nthenumberofnodes, numberofexternalnodes, numberofinternalnodes, and\nheightofT,respectively.ThenT hasthefollowingproperties:\n1. h+1 n 2h+1 1\n\u2264 \u2264 \u2212\n2. 1 n 2h\nE\n\u2264 \u2264\n3. h n 2h 1\nI\n\u2264 \u2264 \u2212\n4. log(n+1) 1 h n 1\n\u2212 \u2264 \u2264 \u2212\nAlso,ifT isproper,thenithasthefollowingproperties:\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 288 \u2014 #310\ni i\n288 Chapter7. Trees\n1. 2h+1 n 2h+1 1\n\u2264 \u2264 \u2212\n2. h+1 n 2h\nE\n\u2264 \u2264\n3. h n 2h 1\nI\n\u2264 \u2264 \u2212\n4. log(n+1) 1 h (n 1)/2\n\u2212 \u2264 \u2264 \u2212\nFigure7.12: Maximumnumberofnodesinthelevelsofabinarytree.\nIn addition to the binary tree properties above, we also have the following re-\nlationship between the number of internal nodes and external nodes in a proper\nbinarytree.\nProposition 7.11: InanonemptyproperbinarytreeT,thenumberofexternal\nnodesisonemorethanthenumberofinternalnodes.\nJustification: We can see this using an argument based on induction. If the\ntree consists of a single root node, then clearly we have one external node and no\ninternalnodes, sotheproposition holds.\nIf,ontheotherhand,wehavetwoormore,thentheroothastwosubtrees. Since\nthesubtrees aresmaller thantheoriginal tree, wemayassume thattheysatisfy the\nproposition. Thus, each subtree has one more external node than internal nodes.\nBetween the two of them, there are two more external nodes than internal nodes.\nBut, the root of the tree is an internal node. When we consider the root and both\nsubtreestogether,thedifferencebetweenthenumberofexternalandinternalnodes\nis2 1=1,whichisjustwhatwewant.\n\u2212\nNotethat theabove relationship does nothold, ingeneral, forimproper binary\ntreesandnonbinarytrees,althoughthereareotherinterestingrelationshipsthatcan\nholdasweexploreinanexercise(C-7.9).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 289 \u2014 #311\ni i\n7.3. BinaryTrees 289\n7.3.4 A Linked Structure for Binary Trees\nIn this section, we present an implementation of a binary tree T as alinked struc-\nture, called LinkedBinaryTree. We represent each node v of T by a node object\nstoring the associated element and pointers to its parent and two children. (See\nFigure7.13.) Forsimplicity, weassumethetreeisproper, meaningthateachnode\nhaseitherzeroortwochildren.\nFigure7.13: Anodeinalinkeddatastructure forrepresenting abinarytree.\nInFigure7.14, weshow alinked structure representation ofabinary tree. The\nstructurestoresthetree\u2019ssize,thatis,thenumberofnodesinthetree,andapointer\ntotherootofthetree. Therestofthestructureconsistsofthenodeslinkedtogether\nappropriately. IfvistherootofT,thenthepointertotheparentnodeisNULL,and\nifvisanexternalnode, thenthepointerstothechildrenofvareNULL.\nFigure7.14: Anexampleofalinkeddatastructure forrepresenting abinarytree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 290 \u2014 #312\ni i\n290 Chapter7. Trees\nWebeginbydefiningthebasicconstituentsthatmakeuptheLinkedBinaryTree\nclass. The most basic entity is the structure Node, shown in Code Fragment 7.17,\nthatrepresents anodeofthetree.\nstruct Node // a node of the tree\n{\nElem elt; // element value\nNode* par; // parent\nNode* left; // left child\nNode* right; // right child\nNode() : elt(), par(NULL), left(NULL), right(NULL) // constructor\n{ }\n;\n}\nCode Fragment 7.17: Structure Node implementing a node of a binary tree. It is\nnestedintheprotected section ofclassBinaryTree.\nAlthoughallitsmembersarepublic,classNodeisdeclaredwithintheprotected\nsection of the LinkedBinaryTree class. Thus, it is not publicly accessible. Each\nnodehasamembervariableelt,whichcontainstheassociatedelement,andpointers\npar,left,andright,whichpointtotheassociated relatives.\nNext,wedefinethepublicclassPositioninCodeFragment7.18. Itsdatamem-\nber consists of a pointer v to a node of the tree. Access to the node\u2019s element\nis provided by overloading the dereferencing operator (\u201c*\u201d). We declare Linked-\nBinaryTreetobeafriend, providing itaccesstotheprivatedata.\nclass Position // position in the tree\n{\nprivate:\nNode* v; // pointer to the node\npublic:\nPosition(Node* v = NULL) : v( v) // constructor\n{ }\nElem& operator*() // get element\nreturn v >elt;\n{ \u2212 }\nPosition left() const // get left child\nreturn Position(v >left);\n{ \u2212 }\nPosition right() const // get right child\nreturn Position(v >right);\n{ \u2212 }\nPosition parent() const // get parent\nreturn Position(v >par);\n{ \u2212 }\nbool isRoot() const // root of the tree?\nreturn v >par == NULL;\n{ \u2212 }\nbool isExternal() const // an external node?\nreturn v >left == NULL && v >right == NULL;\n{ \u2212 \u2212 }\nfriend class LinkedBinaryTree; // give tree access\n;\n}\ntypedef std::list<Position> PositionList; // list of positions\nCodeFragment7.18: Class Position implementing aposition inabinary tree. Itis\nnestedinthepublicsection ofclassLinkedBinaryTree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 291 \u2014 #313\ni i\n7.3. BinaryTrees 291\nMostofthefunctionsofclassPositionsimplyinvolveaccessingtheappropriate\nmembers of the Node structure. We have also included a declaration of the class\nPositionList, as an STL list of positions. This is used to represent collections of\nnodes. To keep the code simple, we have omitted error checking, and, rather than\nusing templates, we simply provide a type definition for the base element type,\ncalledElem. (SeeExerciseP-7.2.)\nWepresentthemajorpartoftheclassLinkedBinaryTreeinCodeFragment7.19.\nThe class declaration begins by inserting the above declarations of Node and Po-\nsition. This is followed by a declaration of the public members, local utility func-\ntions,andtheprivatememberdata. Wehaveomittedhousekeeping functions, such\nasadestructor, assignment operator, andcopyconstructor.\ntypedef int Elem; // base element type\nclass LinkedBinaryTree\n{\nprotected:\n// insert Node declaration here...\npublic:\n// insert Position declaration here...\npublic:\nLinkedBinaryTree(); // constructor\nint size() const; // number of nodes\nbool empty() const; // is tree empty?\nPosition root() const; // get the root\nPositionList positions() const; // list of nodes\nvoid addRoot(); // add root to empty tree\nvoid expandExternal(const Position& p); // expand external node\nPosition removeAboveExternal(const Position& p); // remove p and parent\n// housekeeping functions omitted...\nprotected: // local utilities\nvoid preorder(Node* v, PositionList& pl) const; // preorder utility\nprivate:\nNode* root; // pointer to the root\nint n; // number of nodes\n;\n}\nCodeFragment7.19: Implementation ofaLinkedBinaryTreeclass.\nThe private data for class LinkedBinaryTree consists of a pointer root to the\nroot node and avariable n, containing the number of nodes in thetree. (Weadded\ntheunderscore tothenameroottoavoidanameconflictwiththememberfunction\nroot.) In addition to the functions of the ADT, we have introduced a few update\nfunctions, addRoot, expandExternal, and removeAboveExternal, which provide\nthemeanstobuildandmodifytrees. Theyarediscussed below. Wedefineautility\nfunction preorder, whichisusedintheimplementation ofthefunction positions.\nIn Code Fragment 7.20, we present the definitions of the constructor and sim-\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 292 \u2014 #314\ni i\n292 Chapter7. Trees\nplermemberfunctions ofclassLinkedBinaryTree. Thefunction addRootassumes\nthatthetreeisempty, anditcreates asingle rootnode. (Itshouldnotbeinvoked if\nthetreeisnonempty, sinceotherwiseamemoryleakresults.)\nLinkedBinaryTree::LinkedBinaryTree() // constructor\n: root(NULL), n(0)\n{ }\nint LinkedBinaryTree::size() const // number of nodes\nreturn n;\n{ }\nbool LinkedBinaryTree::empty() const // is tree empty?\nreturn size() == 0;\n{ }\nLinkedBinaryTree::Position LinkedBinaryTree::root() const // get the root\nreturn Position( root);\n{ }\nvoid LinkedBinaryTree::addRoot() // add root to empty tree\nroot = new Node; n = 1;\n{ }\nCodeFragment7.20: Simplememberfunctions forclassLinkedBinaryTree.\nBinary Tree Update Functions\nInaddition totheBinaryTreeinterface functions andaddRoot,theclassLinkedBi-\nnaryTreealsoincludes thefollowing update functions givenaposition p. Thefirst\nisusedforadding nodestothetreeandthesecondisusedforremovingnodes.\nexpandExternal(p): Transform pfromanexternal nodeintoaninternal node\nbycreatingtwonewexternalnodesandmakingthemthe\nleft and right children of p, respectively; an error condi-\ntionoccursif pisaninternalnode.\nremoveAboveExternal(p): Removetheexternal node ptogether withitsparent q,\nreplacing qwiththesibling of p(seeFigure7.15, where\np\u2019snodeiswandq\u2019snodeisv);anerrorconditionoccurs\nif pisaninternalnodeor pistheroot.\n(a) (b) (c)\nFigure7.15:OperationremoveAboveExternal(p),whichremovestheexternalnode\nwtowhich prefersanditsparentnodev.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 293 \u2014 #315\ni i\n7.3. BinaryTrees 293\nThe function expandExternal(p) is shown in Code Fragment 7.21. Letting v\nbe p\u2019s associated node, it creates two new nodes. One becomes v\u2019s left child and\nthe other becomes v\u2019s right child. The constructor for Node initializes the node\u2019s\npointers toNULL,soweneedonlyupdatethenewnode\u2019sparentlinks.\n// expand external node\nvoid LinkedBinaryTree::expandExternal(const Position& p)\n{\nNode* v = p.v; // p\u2019s node\nv >left = new Node; // add a new left child\n\u2212\nv >left >par = v; // v is its parent\n\u2212 \u2212\nv >right = new Node; // and a new right child\n\u2212\nv >right >par = v; // v is its parent\n\u2212 \u2212\nn += 2; // two more nodes\n}\nCodeFragment7.21: ThefunctionexpandExternal(p)ofclassLinkedBinaryTree.\nThe function removeAboveExternal(p) is shown in Code Fragment 7.22. Let\nw be p\u2019s associated node and let v be its parent. Weassume that w is external and\nisnot the root. There aretwocases. Ifwisachild of theroot, removing wand its\nparent(theroot)causesw\u2019ssiblingtobecomethetree\u2019snewroot. Ifnot,wereplace\nw\u2019sparentwithw\u2019ssibling. Thisinvolves findingw\u2019sgrandparent anddetermining\nwhether v is the grandparent\u2019s left or right child. Depending on which, we set the\nlinkfortheappropriatechildofthegrandparent. Afterunlinkingwandv,wedelete\nthesenodes. Finally,weupdate thenumberofnodesinthetree.\nLinkedBinaryTree::Position // remove p and parent\nLinkedBinaryTree::removeAboveExternal(const Position& p)\n{\nNode* w = p.v; Node* v = w >par; // get p\u2019s node and parent\n\u2212\nNode* sib = (w == v >left ? v >right : v >left);\n\u2212 \u2212 \u2212\nif (v == root) // child of root?\n{\nroot = sib; // ...make sibling root\nsib >par = NULL;\n\u2212\n}\nelse\n{\nNode* gpar = v >par; // w\u2019s grandparent\n\u2212\nif (v == gpar >left) gpar >left = sib; // replace parent by sib\n\u2212 \u2212\nelse gpar >right = sib;\n\u2212\nsib >par = gpar;\n\u2212\n}\ndelete w; delete v; // delete removed nodes\nn = 2; // two fewer nodes\n\u2212\nreturn Position(sib);\n}\nCodeFragment7.22:AnimplementationofthefunctionremoveAboveExternal(p).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 294 \u2014 #316\ni i\n294 Chapter7. Trees\nThe function positions is shown in Code Fragment 7.23. It invokes the utility\nfunction preorder, whichtraverses thetreeandstoresthenodepositions inanSTL\nvector.\n// list of all nodes\nLinkedBinaryTree::PositionList LinkedBinaryTree::positions() const\n{\nPositionList pl;\npreorder( root, pl); // preorder traversal\nreturn PositionList(pl); // return resulting list\n}\n// preorder traversal\nvoid LinkedBinaryTree::preorder(Node* v, PositionList& pl) const\n{\npl.push back(Position(v)); // add this node\nif (v >left != NULL) // traverse left subtree\n\u2212\npreorder(v >left, pl);\n\u2212\nif (v >right != NULL) // traverse right subtree\n\u2212\npreorder(v >right, pl);\n\u2212\n}\nCodeFragment7.23: Animplementation ofthefunctionpositions.\nWehave omitted thehousekeeping functions (the destructor, copy constructor,\nand assignment operator). We leave these as exercises (Exercise C-7.22), but they\nalsoinvolve performing atraversalofthetree.\nPerformance of the LinkedBinaryTree Implementation\nLet us now analyze the running times of the functions of class LinkedBinaryTree,\nwhichusesalinkedstructure representation.\nEachofthepositionfunctionsleft,right,parent,isRoot,andisExternaltakes\n\u2022\nO(1)time.\nByaccessingthemembervariablen,whichstoresthenumberofnodesofT,\n\u2022\nfunctions sizeandemptyeachruninO(1)time.\nTheaccessor function rootrunsinO(1)time.\n\u2022\nThe update functions expandExternal and removeAboveExternal visit only\n\u2022\naconstant numberofnodes, sotheybothruninO(1)time.\nFunctionpositionsisimplementedbyperformingapreordertraversal,which\n\u2022\ntakes O(n) time. (We discuss three different binary-tree traversals in Sec-\ntion 7.3.6. Anyofthese suffice.) Thenodes visited bythetraversal areeach\naddedinO(1)timetoanSTLlist. Thus,function positionstakesO(n)time.\nTable7.2summarizestheperformance ofthisimplementation ofabinary tree.\nThere is an object of class Node (Code Fragment 7.17) for each node of tree T.\nThus,theoverallspacerequirement isO(n).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 295 \u2014 #317\ni i\n7.3. BinaryTrees 295\nOperation Time\nleft,right,parent,isExternal,isRoot O(1)\nsize,empty O(1)\nroot O(1)\nexpandExternal,removeAboveExternal O(1)\npositions O(n)\nTable 7.2: Running times for the functions of an n-node binary tree implemented\nwithalinked structure. ThespaceusageisO(n).\n7.3.5 A Vector-Based Structure for Binary Trees\nAsimplestructureforrepresenting abinarytreeT isbasedonawayofnumbering\nthenodesofT. ForeverynodevofT,let f(v)betheintegerdefinedasfollows:\nIfvistherootofT,then f(v)=1\n\u2022\nIfvistheleftchildofnodeu,then f(v)=2f(u)\n\u2022\nIfvistherightchildofnodeu,then f(v)=2f(u)+1\n\u2022\nThenumbering function f isknown asalevelnumberingofthenodes inabinary\ntree T, because it numbers the nodes on each level of T in increasing order from\nlefttoright, althoughitmayskipsomenumbers. (SeeFigure7.16.)\nThe level numbering function f suggests a representation of a binary tree T\nby means of a vector S, such that node v of T is associated with the element of\nS at rank f(v). (See Figure 7.17.) Typically, we realize the vector S by means\nof an extendable array. (See Section 6.1.3.) Such an implementation is simple\nand efficient, for we can use it to easily perform the functions root, parent, left,\nright, sibling, isExternal, and isRoot by using simple arithmetic operations on the\nnumbers f(v)associated witheach node vinvolved inthe operation. Thatis, each\nposition object v is simply a \u201cwrapper\u201d for the index f(v) into the vector S. We\nleavethedetailsofsuchimplementations asasimpleexercise(R-7.26).\nLet n be the number of nodes of T, and let f be the maximum value of f(v)\nM\noverallthenodesofT. ThevectorShassizeN= f +1,sincetheelementofSat\nM\nindex0isnotassociatedwithanynodeofT. Also,Swillhave,ingeneral,anumber\nof empty elements that do not refer to existing nodes of T. For a tree of height h,\nN =O(2h). In the worst case, this can be as high as 2n 1. The justification is\n\u2212\nleftasanexercise(R-7.24). InSection8.3,wediscussaclassofbinarytreescalled\n\u201cheaps,\u201dforwhichN=n+1. Thus,inspiteoftheworst-casespaceusage,thereare\napplicationsforwhichthearray-listrepresentationofabinarytreeisspaceefficient.\nStill,forgeneral binarytrees, theexponential worst-case spacerequirement ofthis\nrepresentation isprohibitive.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 296 \u2014 #318\ni i\n296 Chapter7. Trees\nTable7.3summarizestherunningtimesofthefunctionsofabinarytreeimple-\nmentedwithavector. Wedonotincludeanytreeupdatefunctionshere. Thevector\nimplementation of a binary tree is a fast and easy way of realizing the binary-tree\nADT,butitcanbeveryspaceinefficientiftheheightofthetreeislarge.\n(a)\n(b)\nFigure7.16: Binarytreelevelnumbering: (a)generalscheme;(b)anexample.\nFigure7.17: Representation ofabinarytreeT bymeansofavectorS.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 297 \u2014 #319\ni i\n7.3. BinaryTrees 297\nOperation Time\nleft,right,parent,isExternal,isRoot O(1)\nsize,empty O(1)\nroot O(1)\nexpandExternal,removeAboveExternal O(1)\npositions O(n)\nTable 7.3: Running times for a binary tree T implemented with a vector S. We\ndenote the number of nodes of T with n, and N denotes the size of S. The space\nusageisO(N),whichisO(2n)intheworstcase.\n7.3.6 Traversals of a Binary Tree\nAswithgeneraltrees,binary-tree computations ofteninvolve traversals.\nPreorder Traversal of a Binary Tree\nSince any binary tree can also be viewed as a general tree, the preorder traversal\nfor general trees (Code Fragment 7.9) can be applied to any binary tree. We can\nsimplify the algorithm in the case of a binary-tree traversal, however, as we show\ninCodeFragment7.24. (AlsoseeCodeFragment7.23.)\nAlgorithmbinaryPreorder(T,p):\nperformthe\u201cvisit\u201dactionfornode p\nif pisaninternal nodethen\nbinaryPreorder(T,p.left()) recursively traverse leftsubtree\n{ }\nbinaryPreorder(T,p.right()) recursively traverserightsubtree\n{ }\nCode Fragment 7.24: Algorithm binaryPreorder, which performs the preorder\ntraversal ofthesubtreeofabinarytreeT rootedatnode p.\nForexample,apreorder traversal ofthebinarytreeshowninFigure7.14visits\nthe nodes in the order LAX,BWI,ATL,JFK,PVD . As is the case for general\nh i\ntrees,therearemanyapplications ofthepreorder traversalforbinarytrees.\nPostorder Traversal of a Binary Tree\nAnalogously, thepostordertraversalforgeneraltrees(CodeFragment7.12)canbe\nspecialized forbinarytreesasshowninCodeFragment7.25.\nApostordertraversalofthebinarytreeshowninFigure7.14visitsthenodesin\ntheorder ATL,JFK,BWI,PVD,LAX .\nh i\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 298 \u2014 #320\ni i\n298 Chapter7. Trees\nAlgorithmbinaryPostorder(T,p):\nif pisaninternal nodethen\nbinaryPostorder(T,p.left()) recursively traverseleftsubtree\n{ }\nbinaryPostorder(T,p.right()) recursively traverserightsubtree\n{ }\nperformthe\u201cvisit\u201dactionforthenode p\nCode Fragment 7.25: Algorithm binaryPostorder for performing the postorder\ntraversal ofthesubtreeofabinarytreeT rootedatnode p.\nEvaluating an Arithmetic Expression\nThe postorder traversal of a binary tree can be used to solve the expression eval-\nuation problem. In this problem, we are given an arithmetic-expression tree, that\nis, a binary tree where each external node has a value associated with it and each\ninternalnodehasanarithmeticoperation associated withit(seeExample7.9),and\nwewanttocomputethevalueofthearithmeticexpression represented bythetree.\nAlgorithmevaluateExpression,giveninCodeFragment7.26,evaluatestheex-\npression associated withthesubtree rootedatanode pofanarithmetic-expression\ntreeT byperformingapostordertraversalofT startingat p. Inthiscase,the\u201cvisit\u201d\nactionconsists ofperforming asinglearithmeticoperation.\nAlgorithmevaluateExpression(T,p):\nif pisaninternal nodethen\nx evaluateExpression(T,p.left())\n\u2190\ny evaluateExpression(T,p.right())\n\u2190\nLet betheoperator associated with p\n\u25e6\nreturnx y\n\u25e6\nelse\nreturnthevaluestoredat p\nCode Fragment7.26: Algorithm evaluateExpression for evaluating the expression\nrepresented bythesubtreeofanarithmetic-expression treeT rootedatnode p.\nThe expression-tree evaluation application of the postorder traversal provides\nan O(n)-time algorithm for evaluating an arithmetic expression represented by a\nbinarytreewithnnodes. Indeed, likethegeneralpostorder traversal, thepostorder\ntraversal for binary trees can be applied toother \u201cbottom-up\u201d evaluation problems\n(such as the size computation given in Example 7.7) as well. The specialization\nofthepostorder traversalforbinarytreessimplifiesthatforgeneraltrees,however,\nbecauseweusetheleftandrightfunctions toavoidaloopthatiteratesthrough the\nchildren ofaninternalnode.\nInterestingly, the specialization ofthe general preorder and postorder traversal\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 299 \u2014 #321\ni i\n7.3. BinaryTrees 299\nmethods to binary trees suggests a third traversal in a binary tree that is different\nfrom both the preorder and postorder traversals. We explore this third kind of\ntraversal forbinarytreesinthenextsubsection.\nInorder Traversal of a Binary Tree\nAn additional traversal method for a binary tree is the inorder traversal. In this\ntraversal, wevisit a node between the recursive traversals of its left and right sub-\ntrees. The inorder traversal of the subtree rooted at a node p in a binary tree T is\ngiveninCodeFragment7.27.\nAlgorithminorder(T,p):\nif pisaninternal nodethen\ninorder(T,p.left()) recursively traverseleftsubtree\n{ }\nperformthe\u201cvisit\u201dactionfornode p\nif pisaninternal nodethen\ninorder(T,p.right()) recursively traverserightsubtree\n{ }\nCodeFragment7.27: Algorithm inorder forperforming theinorder traversal ofthe\nsubtreeofabinarytreeT rootedatanode p.\nForexample,aninordertraversal ofthebinarytreeshowninFigure7.14visits\nthe nodes in the order ATL,BWI,JFK,LAX,PVD . The inorder traversal of a\nh i\nbinary tree T can be informally viewed as visiting the nodes of T \u201cfrom left to\nright.\u201d Indeed, for every node p, the inorder traversal visits p after all the nodes\nin the left subtree of p and before all the nodes in the right subtree of p. (See\nFigure7.18.)\nFigure7.18: Inordertraversalofabinarytree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 300 \u2014 #322\ni i\n300 Chapter7. Trees\nBinary Search Trees\nLetSbeasetwhoseelementshaveanorderrelation. Forexample,Scouldbeaset\nofintegers. Abinarysearch treeforSisaproperbinarytreeT suchthat:\nEachinternalnode pofT storesanelementofS,denotedwithx(p)\n\u2022\nForeachinternalnode pofT,theelementsstoredintheleftsubtreeof pare\n\u2022\nlessthanorequaltox(p)andtheelementsstoredintherightsubtreeof pare\ngreaterthanorequaltox(p)\nTheexternal nodesofT donotstoreanyelement\n\u2022\nAn inorder traversal of the internal nodes of a binary search tree T visits the\nelementsinnondecreasing order. (SeeFigure7.19.)\nWe can use a binary search tree T to locate an element with a certain value x\nby traversing down the tree T. At each internal node wecompare the value of the\ncurrent node to our search element x. If the answer to the question is \u201csmaller,\u201d\nthen the search continues in the left subtree. If the answer is \u201cequal,\u201d then the\nsearchterminatessuccessfully. Iftheansweris\u201cgreater,\u201dthenthesearchcontinues\nintherightsubtree. Finally,ifwereachanexternalnode(whichisempty),thenthe\nsearchterminatesunsuccessfully. (SeeFigure7.19.)\nNotethatthetimeforsearching inabinarysearch treeT isproportional tothe\nheight of T. Recall from Proposition 7.10 that the height of a tree with n nodes\ncan be as small as O(logn) or as large as \u2126(n). Thus, binary search trees are\nmost efficient when they have small height. We illustrate an example search in a\nbinary search tree in Figure 7.19. We study binary search trees in more detail in\nSection10.1.\nFigure7.19: A binary search tree storing integers. The blue solid path is traversed\nwhen searching (successfully) for 36. The blue dashed path is traversed when\nsearching (unsuccessfully) for70.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 301 \u2014 #323\ni i\n7.3. BinaryTrees 301\nUsing Inorder Traversal for Tree Drawing\nTheinordertraversalcanalsobeappliedtotheproblemofcomputingadrawingof\na binary tree. We can draw a binary tree T with an algorithm that assigns x- and\ny-coordinates toanode pofT usingthefollowingtworules(seeFigure7.20).\nx(p)isthenumberofnodesvisited before pintheinordertraversal ofT.\n\u2022\ny(p)isthedepthof pinT.\n\u2022\nIn this application, we take the convention common in computer graphics that x-\ncoordinates increase left to right and y-coordinates increase top to bottom. So the\noriginisintheupperleftcornerofthecomputerscreen.\nFigure7.20: Theinorderdrawingalgorithm forabinarytree.\nThe Euler Tour Traversal of a Binary Tree\nThe tree-traversal algorithms we have discussed so far are all forms of iterators.\nEachtraversalvisitsthenodesofatreeinacertainorder, andisguaranteed tovisit\neachnodeexactlyonce. Wecanunifythetree-traversalalgorithmsgivenaboveinto\nasingleframework,however,byrelaxingtherequirementthateachnodebevisited\nexactly once. The resulting traversal method is called the Euler tour traversal,\nwhich we study next. The advantage of this traversal is that it allows for more\ngeneralkindsofalgorithms tobeexpressed easily.\nTheEulertourtraversalofabinarytreeT canbeinformallydefinedasa\u201cwalk\u201d\naround T, where we start by going from the root toward its left child, viewing the\nedges of T as being \u201cwalls\u201d that we always keep to our left. (See Figure 7.21.)\nEachnode pofT isencountered threetimesbytheEulertour:\n\u201cOntheleft\u201d(beforetheEulertourof p\u2019sleftsubtree)\n\u2022\n\u201cFrombelow\u201d(betweentheEulertoursof p\u2019stwosubtrees)\n\u2022\n\u201cOntheright\u201d(aftertheEulertourof p\u2019srightsubtree)\n\u2022\nIf pisexternal, thenthesethree\u201cvisits\u201dactually allhappen atthesametime.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 302 \u2014 #324\ni i\n302 Chapter7. Trees\nFigure7.21: Eulertourtraversal ofabinarytree.\nWe give pseudo-code for the Euler tour of the subtree rooted at a node p in\nCodeFragment7.28.\nAlgorithmeulerTour(T,p):\nperformtheactionforvisitingnode pontheleft\nif pisaninternal nodethen\nrecursively tourtheleftsubtreeof pbycallingeulerTour(T,p.left())\nperformtheactionforvisitingnode pfrombelow\nif pisaninternal nodethen\nrecursively tourtherightsubtree of pbycallingeulerTour(T,p.right())\nperformtheactionforvisitingnode pontheright\nCode Fragment 7.28: Algorithm eulerTour for computing the Euler tour traversal\nofthesubtree ofabinarytreeT rootedatanode p.\nThe preorder traversal of a binary tree is equivalent to an Euler tour traversal\nin which each node has an associated \u201cvisit\u201d action occur only when it is encoun-\nteredontheleft. Likewise,theinorder andpostorder traversals ofabinary treeare\nequivalent toanEulertour,whereeachnodehasanassociated \u201cvisit\u201dactionoccur\nonlywhenitisencountered frombeloworontheright,respectively.\nTheEulertourtraversalextendsthepreorder, inorder, andpostorder traversals,\nbut it can also perform other kinds of traversals. For example, suppose we wish\nto compute the number of descendants of each node p in an n node binary tree T.\nWestartanEulertourbyinitializingacounterto0,andthenincrementthecounter\neach time we visit a node on the left. To determine the number of descendants of\na node p, we compute the difference between the values of the counter when p is\nvisited on the left and when it is visited on the right, and add 1. This simple rule\ngives us the number of descendants of p, because each node in the subtree rooted\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 303 \u2014 #325\ni i\n7.3. BinaryTrees 303\nat piscountedbetween p\u2019svisitontheleftand p\u2019svisitontheright. Therefore,we\nhaveanO(n)-timemethodforcomputing thenumberofdescendants ofeachnode\ninT.\nThe running time of the Euler tour traversal is easy to analyze, assuming that\nvisiting a node takes O(1) time. Namely, in each traversal, we spend a constant\namountoftimeateachnodeofthetreeduring thetraversal, sotheoverallrunning\ntimeisO(n)forannnodetree.\nAnother application of the Euler tour traversal is to print afully parenthesized\narithmetic expression from its expression tree (Example 7.9). Algorithm printEx-\npression, shown inCode Fragment 7.29, accomplishes this task byperforming the\nfollowingactionsinanEulertour:\n\u201cOntheleft\u201daction: ifthenodeisinternal, print\u201c(\u201d\n\u2022\n\u201cFrombelow\u201daction: printthevalueoroperator storedatthenode\n\u2022\n\u201cOntheright\u201daction: ifthenodeisinternal, print\u201c)\u201d\n\u2022\nAlgorithmprintExpression(T,p):\nif p.isExternal()then\nprintthevaluestoredat p\nelse\nprint\u201c(\u201d\nprintExpression(T,p.left())\nprinttheoperator storedat p\nprintExpression(T,p.right())\nprint\u201c)\u201d\nCodeFragment7.29: Analgorithmforprintingthearithmeticexpressionassociated\nwiththesubtreeofanarithmetic-expression treeT rootedat p.\n7.3.7 The Template Function Pattern\nThetreetraversalfunctionsdescribedaboveareactuallyexamplesofaninteresting\nobject-oriented software design pattern, the template functionpattern. Thisisnot\nto be confused with templated classes or functions in C++, but the principal is\nsimilar. Thetemplatefunctionpatterndescribesagenericcomputation mechanism\nthatcanbespecialized foraparticular application byredefining certainsteps.\nEuler Tour with the Template Function Pattern\nFollowing the template function pattern, we can design an algorithm, template-\nEulerTour, that implements a generic Euler tour traversal of a binary tree. When\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 304 \u2014 #326\ni i\n304 Chapter7. Trees\ncalled onanode p, function templateEulerTour calls several other auxiliary func-\ntions at different phases of the traversal. First of all, it creates a three-element\nstructure r to store the result of the computation calling auxiliary function initRe-\nsult. Next, if p is an external node, templateEulerTour calls auxiliary function\nvisitExternal, else (p is an internal node) templateEulerTour executes the follow-\ningsteps:\nCalls auxiliary function visitLeft, which performs the computations associ-\n\u2022\natedwithencountering thenodeontheleft\nRecursively callsitselfontheleftchild\n\u2022\nCalls auxiliary function visitBelow, which performs the computations asso-\n\u2022\nciatedwithencountering thenodefrombelow\nRecursively callsitselfontherightsubtree\n\u2022\nCallsauxiliaryfunctionvisitRight,whichperformsthecomputations associ-\n\u2022\natedwithencountering thenodeontheright\nFinally,templateEulerTourreturnstheresultofthecomputationbycallingaux-\niliaryfunction returnResult. Function templateEulerTourcanbeviewedasatem-\nplateor\u201cskeleton\u201d ofanEulertour. (SeeCodeFragment7.30.)\nAlgorithmtemplateEulerTour(T,p):\nr initResult()\n\u2190\nif p.isExternal() then\nr.finalResult visitExternal(T,p,r)\n\u2190\nelse\nvisitLeft(T,p,r)\nr.leftResult templateEulerTour(T,p.left())\n\u2190\nvisitBelow(T,p,r)\nr.rightResult templateEulerTour(T,p.right())\n\u2190\nvisitRight(T,p,r)\nreturnreturnResult(r)\nCode Fragment 7.30: Function templateEulerTour for computing a generic Euler\ntour traversal of the subtree of a binary tree T rooted at a node p, following the\ntemplate function pattern. This function calls the functions initResult, visitExter-\nnal,visitLeft,visitBelow,visitRight,andreturnResult.\nInanobject-oriented context, wecanthenwriteaclassEulerTourthat:\nContainsfunction templateEulerTour\n\u2022\nContains all the auxiliary functions called by templateEulerTour as empty\n\u2022\nplaceholders(thatis,withnoinstructions orreturning NULL)\nContainsafunction executethatcallstemplateEulerTour(T,T.root())\n\u2022\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 305 \u2014 #327\ni i\n7.3. BinaryTrees 305\nClassEulerTour itself does notperform anyuseful computation. However, we\ncan extend it with the inheritance mechanism and override the empty functions to\ndousefultasks.\nTemplate Function Examples\nAs a first example, we can evaluate the expression associated with an arithmetic-\nexpression tree(seeExample7.9)bywritinganewclassEvaluateExpressionthat:\nExtendsclassEulerTour\n\u2022\nOverridesfunction initResultbyreturning anarrayofthreenumbers\n\u2022\nOverridesfunction visitExternalbyreturning thevaluestoredatthenode\n\u2022\nOverridesfunctionvisitRightbycombiningr.leftResultandr.rightResultwith\n\u2022\ntheoperatorstoredatthenode,andsettingr.finalResult equaltotheresultof\ntheoperation\nOverridesfunction returnResultbyreturning r.finalResult\n\u2022\nThisapproach shouldbecompared withthedirectimplementation ofthealgo-\nrithmshowninCodeFragment7.26.\nAsasecondexample,wecanprinttheexpressionassociatedwithanarithmetic-\nexpression tree(seeExample7.9)usinganewclassPrintExpressionthat:\nExtendsclassEulerTour\n\u2022\nOverridesfunctionvisitExternalbyprinting thevalueofthevariableorcon-\n\u2022\nstantassociated withthenode\nOverridesfunction visitLeftbyprinting \u201c(\u201d\n\u2022\nOverrides function visitBelow by printing the operator associated with the\n\u2022\nnode\nOverridesfunction visitRightbyprinting \u201c)\u201d\n\u2022\nThisapproach shouldbecompared withthedirectimplementation ofthealgo-\nrithmshowninCodeFragment7.29.\nC++ Implementation\nA complete C++ implementation of the generic EulerTour class and of its spe-\ncializations EvaluateExpressionTour and PrintExpressionTour are shown in Code\nFragments7.31through7.34. Thesearebasedonalinkedbinarytreeimplementa-\ntion.\nWebeginbydefiningalocalstructureResultwithfieldsleftResult,rightResult,\nand finalResult, which store the intermediate results of the tour. In order to avoid\ntyping lengthy qualified type names, wegivetwotype definitions, BinaryTreeand\nPosition,forthetreeandapositioninthetree,respectively. Theonlydatamember\nis a pointer to the binary tree. We provide a simple function, called initialize, that\nsets this pointer to an existing binary tree. The remaining functions are protected,\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 306 \u2014 #328\ni i\n306 Chapter7. Trees\nsincetheyarenotinvokeddirectly,butratherbythederivedclasses,whichproduce\nthedesiredspecialized behavior.\ntemplate <typename E, typename R> // element and result types\nclass EulerTour // a template for Euler tour\n{\nprotected:\nstruct Result // stores tour results\n{\nR leftResult; // result from left subtree\nR rightResult; // result from right subtree\nR finalResult; // combined result\n;\n}\ntypedef BinaryTree<E> BinaryTree; // the tree\ntypedef typename BinaryTree::Position Position; // a position in the tree\nprotected: // data member\nconst BinaryTree* tree; // pointer to the tree\npublic:\nvoid initialize(const BinaryTree& T) // initialize\ntree = &T;\n{ }\nprotected: // local utilities\nint eulerTour(const Position& p) const; // perform the Euler tour\n// functions given by subclasses\nvirtual void visitExternal(const Position& p, Result& r) const\n{}\nvirtual void visitLeft(const Position& p, Result& r) const\n{}\nvirtual void visitBelow(const Position& p, Result& r) const\n{}\nvirtual void visitRight(const Position& p, Result& r) const\n{}\nResult initResult() const return Result();\n{ }\nint result(const Result& r) const return r.finalResult;\n{ }\n;\n}\nCodeFragment7.31: ClassEulerTourdefiningagenericEulertourofabinarytree.\nThisclassrealizesthetemplatefunctionpatternandmustbespecializedinorderto\ngenerate aninteresting computation.\nNext,inCodeFragment7.32,wepresenttheprincipaltraversalfunction,called\neulerTour. This recursive function performs an Euler traversal on the tree and in-\nvokes the appropriate functions as it goes. If run on the generic Euler tree, noth-\ning interesting would result, because these functions (as defined in Code Frag-\nment7.31)donothing. Itisuptothederivedfunctions toprovidemoreinteresting\ndefinitions forthesegenericfunctions.\nIn Code Fragment 7.33, we present our first example of a derived class us-\ning the template pattern, called EvaluateExpressionTour. It evaluates an integer\narithmetic-expression tree. We assume that each external node of an expression\ntree provides a function called value, which returns the value associated with this\nnode. Weassume thateachinternal nodeofanexpression treeprovides afunction\ncalledoperation,whichperformstheoperationassociatedwiththisnodetothetwo\noperands arisingfromitsleftandrightsubtrees, andreturnstheresult.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 307 \u2014 #329\ni i\n7.3. BinaryTrees 307\ntemplate <typename E, typename R> // do the tour\nint EulerTour<E, R>::eulerTour(const Position& p) const\n{\nResult r = initResult();\nif (p.isExternal()) // external node\n{\nvisitExternal(p, r);\n}\nelse // internal node\n{\nvisitLeft(p, r);\nr.leftResult = eulerTour(p.left()); // recurse on left\nvisitBelow(p, r);\nr.rightResult = eulerTour(p.right()); // recurse on right\nvisitRight(p, r);\n}\nreturn result(r);\n}\nCodeFragment7.32: Theprincipal member function eulerTour, which recursively\ntraverses thetreeandaccumulates theresults.\nUsing these two functions, we can evaluate the expression recursively as we\ntraversethetree. Themainentrypointisthefunctionexecute,whichinitializesthe\ntree,invokes therecursiveEulertourstarting attheroot,andprintsthefinalresult.\nForexample,giventheexpressiontreeofFigure7.21,thisprocedurewouldoutput\nthestring\u201cThe value is: -13\u201d.\ntemplate <typename E, typename R>\nclass EvaluateExpressionTour : public EulerTour<E, R>\n{\nprotected: // shortcut type names\ntypedef typename EulerTour<E, R>::BinaryTree BinaryTree;\ntypedef typename EulerTour<E, R>::Position Position;\ntypedef typename EulerTour<E, R>::Result Result;\npublic:\nvoid execute(const BinaryTree& T) // execute the tour\n{\ninitialize(T);\nstd::cout << \"The value is: \" << eulerTour(T.root()) << \"\\n\";\n}\nprotected: // leaf: return value\nvirtual void visitExternal(const Position& p, Result& r) const\nr.finalResult = (*p).value();\n{ }\n// internal: do operation\nvirtual void visitRight(const Position& p, Result& r) const\nr.finalResult = (*p).operation(r.leftResult, r.rightResult);\n{ }\n;\n}\nCode Fragment 7.33: Implementation of class EvaluateExpressionTour which\nspecializes EulerTour to evaluate the expression associated with an arithmetic-\nexpression tree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 308 \u2014 #330\ni i\n308 Chapter7. Trees\nFinally,inCodeFragment7.34,wepresentasecondexampleofaderivedclass,\ncalled PrintExpressionTour. In contrast to the previous function, which evaluates\nthevalueofanexpressiontree,thisoneprintstheexpression. Weassumethateach\nnodeofanexpressiontreeprovidesafunctioncalledprint. Foreachexternalnode,\nthis function prints the value associated with this node. For each internal node,\nthis function prints the operator, for example, printing \u201c+\u201d for addition or \u201c*\u201d for\nmultiplication.\ntemplate <typename E, typename R>\nclass PrintExpressionTour : public EulerTour<E, R>\n{\nprotected: // ...same type name shortcuts as in EvaluateExpressionTour\npublic:\nvoid execute(const BinaryTree& T) // execute the tour\n{\ninitialize(T);\ncout << \"Expression: \"; eulerTour(T.root()); cout << endl;\n}\nprotected: // leaf: print value\nvirtual void visitExternal(const Position& p, Result& r) const\n(*p).print();\n{ }\n// left: open new expression\nvirtual void visitLeft(const Position& p, Result& r) const\ncout << \"(\";\n{ }\n// below: print operator\nvirtual void visitBelow(const Position& p, Result& r) const\n(*p).print();\n{ }\n// right: close expression\nvirtual void visitRight(const Position& p, Result& r) const\ncout << \")\";\n{ }\n;\n}\nCodeFragment7.34: Aclassthatprintsanarithmetic-expression tree.\nWhenenteringasubtree,thefunctionvisitLefthasbeenoverriddentoprint\u201c(\u201d\nand on exiting a subtree, the function visitRight has been overridden to print \u201c).\u201d\nThemainentrypointisthefunctionexecute,whichinitializesthetree,andinvokes\ntherecursive Euler tour starting attheroot. Whencombined, these functions print\ntheentireexpression(albeitwithlotsofredundantparentheses). Forexample,given\ntheexpressiontreeofFigure7.21,thisprocedurewouldoutputthefollowingstring.\n((((3 + 1) * 3) / ((9 - 5) + 2)) - ((3 * (7 - 4)) + 6))\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 309 \u2014 #331\ni i\n7.3. BinaryTrees 309\n7.3.8 Representing General Trees with Binary Trees\nAnalternativerepresentation ofageneraltreeT isobtainedbytransformingT into\na binary tree T\u2032. (See Figure 7.22.) We assume that either T is ordered or that it\nhasbeenarbitrarily ordered. Thetransformation isasfollows:\nForeachnodeuofT,thereisaninternal nodeu\u2032 ofT\u2032 associated withu\n\u2022\nIfuisanexternalnodeofT anddoesnothaveasiblingimmediatelyfollow-\n\u2022\ningit,thenthechildren ofu\u2032 inT\u2032 areexternalnodes\nIfuisaninternalnodeofT andvisthefirstchildofuinT,thenv\u2032 istheleft\n\u2022\nchildofu\u2032 inT\nIf node v has a sibling w immediately following it, then w\u2032 is the right child\n\u2022\nofv\u2032 inT\u2032\nNote that the external nodes of T\u2032 are not associated with nodes of T, and serve\nonlyasplaceholders (hence,mayevenbenull).\n(a) (b)\nFigure 7.22: Representation of a tree by means of a binary tree: (a) tree T; (b)\nbinarytreeT\u2032 associated withT. ThedashededgesconnectnodesofT\u2032 associated\nwithsibling nodesofT.\nIt is easy to maintain the correspondence between T and T\u2032, and to express\noperations in T in terms of corresponding operations in T\u2032. Intuitively, we can\nthink of the correspondence in terms of a conversion of T into T\u2032 that takes each\nsetofsiblings v ,v ,...,v inT withparentvandreplacesitwithachainofright\n1 2 k\n{ }\nchildren rootedatv ,whichthenbecomestheleftchildofv.\n1\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 310 \u2014 #332\ni i\n310 Chapter7. Trees\n7.4 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-7.1 Describe analgorithm forcounting thenumberofleftexternal nodesina\nbinarytree,usingtheBinarytreeADT.\nR-7.2 Thefollowingquestions refertothetreeofFigure7.3.\na. Whichnodeistheroot?\nb. Whataretheinternal nodes?\nc. Howmanydescendents doesnodecs016/have?\nd. Howmanyancestors doesnodecs016/have?\ne. Whatarethesiblings ofnodehomeworks/?\nf. Whichnodesareinthesubtreerootedatnodeprojects/?\ng. Whatisthedepthofnodepapers/?\nh. Whatistheheightofthetree?\nR-7.3 Find the value of the arithmetic expression associated with each subtree\nofthebinarytreeofFigure7.11.\nR-7.4 Let T be an n-node improper binary tree (that is, each internal node has\none or two children). Describe how to represent T by means of a proper\nbinarytreeT\u2032 withO(n)nodes.\nR-7.5 What are the minimum and maximum number of internal and external\nnodesinanimproperbinarytreewithnnodes?\nR-7.6 Showatreeachieving theworst-case running timeforalgorithm depth.\nR-7.7 Giveajustification ofProposition 7.4.\nR-7.8 Whatistherunningtimeofalgorithm height2(T,v)(CodeFragment7.7)\nwhencalledonanodevdistinctfromtherootofT?\nR-7.9 LetT bethetreeofFigure7.3.\na. GivetheoutputofpreorderPrint(T,T.root())(CodeFragment7.10).\nb. GivetheoutputofparenPrint(T,T.root())(CodeFragmentcod:paren:Print).\nR-7.10 Describe a modification to the parenPrint function given in Code Frag-\nment7.11, sothat itusesthe sizefunction forstringobjects tooutput the\nparenthetic representation of a tree with line breaks and spaces added to\ndisplaythetreeinatextwindowthatis80characters wide.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 311 \u2014 #333\ni i\n7.4. Exercises 311\nR-7.11 Draw an arithmetic-expression tree that has four external nodes, storing\nthenumbers 1,5,6, and7(witheachnumberstored inadistinct external\nnode,butnotnecessarily inthisorder), andhasthreeinternal nodes,each\nstoring anoperator fromtheset +, , ,/ ,sothatthevalueoftheroot\n{ \u2212 \u00d7 }\nis21. Theoperators mayreturnandactonfractions, andanoperatormay\nbeusedmorethanonce.\nR-7.12 Let T be an ordered tree with more than one node. Is it possible that the\npreorder traversal ofT visits thenodes inthesameorder asthepostorder\ntraversal of T? If so, give an example; otherwise, argue why this cannot\noccur. Likewise, is it possible that the preorder traversal of T visits the\nnodes in the reverse order of the postorder traversal of T? If so, give an\nexample;otherwise, arguewhythiscannotoccur.\nR-7.13 Answertheprevious question forthe casewhen T isaproper binary tree\nwithmorethanonenode.\nR-7.14 Let T be a tree with n nodes. What is the running time of the function\nparenPrint(T,T.root())? (SeeCodeFragment7.11.)\nR-7.15 Drawa(single) binarytreeT,suchthat:\nEachinternalnodeofT storesasinglecharacter\n\u2022\nApreorder traversalofT yieldsEXAMFUN\n\u2022\nAninordertraversal ofT yieldsMAFXUEN\n\u2022\nR-7.16 Answerthefollowingquestions soastojustifyProposition 7.10.\na. What is the minimum number of external nodes for a binary tree\nwithheighth? Justify youranswer.\nb. What is the maximum number of external nodes for a binary tree\nwithheighth? Justify youranswer.\nc. LetT beabinarytreewithheighthandnnodes. Showthat\nlog(n+1) 1 h (n 1)/2.\n\u2212 \u2264 \u2264 \u2212\nd. For which values of n and h can the above lower and upper bounds\nonhbeattained withequality?\nR-7.17 DescribeageneralizationoftheEulertourtraversaloftreessuchthateach\ninternalnodehasthreechildren. Describehowyoucouldusethistraversal\ntocomputetheheightofeachnodeinsuchatree.\nR-7.18 ModifytheC++function preorderPrint, giveninCodeFragment7.10,so\nthatitwillprintthestringsassociatedwiththenodesofatreeoneperline,\nandindented proportionally tothedepthofthenode.\nR-7.19 LetT bethetreeofFigure7.3. Draw,asbestasyoucan,theoutputofthe\nalgorithm postorderPrint(T,T.root())(CodeFragment7.13).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 312 \u2014 #334\ni i\n312 Chapter7. Trees\nR-7.20 Let T be the tree of Figure 7.9. Compute, in terms of the values given\nin this figure, the output of algorithm diskSpace(T,T.root()). (See Code\nFragment7.14.)\nR-7.21 LetT bethebinarytreeofFigure7.11.\na. GivetheoutputofpreorderPrint(T,T.root())(CodeFragment7.10).\nb. Give the output of the function printExpression(T,T.root()) (Code\nFragment7.29).\nR-7.22 Describe, in pseudo-code, an algorithm for computing the number of de-\nscendents of each node of a binary tree. The algorithm should be based\nontheEulertourtraversal.\nR-7.23 LetT bea(possibly improper) binary tree withnnodes, andlet Dbethe\nsum of the depths of all the external nodes of T. Show that if T has the\nminimumnumberofexternal nodespossible, thenDisO(n)andifT has\nthemaximumnumberofexternalnodespossible, thenDisO(nlogn).\nR-7.24 Let T be a binary tree with n nodes, and let f be the level numbering of\nthenodesofT asgiveninSection7.3.5.\na. Showthat,foreverynodevofT, f(v) 2n 1.\n\u2264 \u2212\nb. Show an example of a binary tree with seven nodes that attains the\naboveupperboundon f(v)forsomenodev.\nR-7.25 Draw the binary tree representation of the following arithmetic expres-\nsion: \u201c(((5+2) (2 1))/((2+9)+((7 2) 1)) 8).\u201d\n\u2217 \u2212 \u2212 \u2212 \u2217\nR-7.26 LetT beabinarytreewithnnodesthatisrealizedwithavector,S,andlet\nf bethelevelnumberingofthenodesinT asgiveninSection7.3.5. Give\npseudo-code descriptions ofeach ofthefunctions root,parent, leftChild,\nrightChild,isExternal,andisRoot.\nR-7.27 Show how to use the Euler tour traversal to compute the level number,\ndefinedinSection7.3.5,ofeachnodeinabinarytreeT.\nCreativity\nC-7.1 Show that there are more than 2n different potentially improper binary\ntrees with n internal nodes, where two trees are considered different if\ntheycanbedrawnasdifferent lookingtrees.\nC-7.2 Describe an efficient algorithm for converting a fully balanced string of\nparentheses intoanequivalent tree. Thetreeassociated withsuchastring\nis defined recursively. Theouter-most pair of balanced parentheses isas-\nsociated with the root and each substring inside this pair, defined by the\nsubstring between twobalanced parentheses, is associated with asubtree\nofthisroot.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 313 \u2014 #335\ni i\n7.4. Exercises 313\nC-7.3 For each node v in a tree T, let pre(v) be the rank of v in a preorder\ntraversalofT,letpost(v)betherankofvinapostorder traversalofT,let\ndepth(v) be the depth of v, and let desc(v) be the number of descendents\nof v, not counting v itself. Derive a formula defining post(v) in terms of\ndesc(v),depth(v),andpre(v),foreachnodevinT.\nC-7.4 LetT beatreewhosenodesstorestrings. Giveanalgorithmthatcomputes\nand prints, for every internal node v of T, the string stored at v and the\nheightofthesubtree rootedatv.\nC-7.5 Designalgorithms forthefollowingoperations forabinarytreeT.\npreorderNext(v): return the node visited after node v in a preorder\n\u2022\ntraversal ofT.\ninorderNext(v): return the node visited after node v in an inorder\n\u2022\ntraversal ofT.\npostorderNext(v): returnthenodevisitedafternodevinapostorder\n\u2022\ntraversal ofT.\nWhataretheworst-case runningtimesofyouralgorithms?\nC-7.6 Give an O(n)-time algorithm for computing the depth of all the nodes of\natreeT,wherenisthenumberofnodesofT.\nC-7.7 The indented parenthetic representation of a tree T is a variation of the\nparenthetic representation of T (see Figure 7.7) that uses indentation and\nlinebreaksasillustrated inFigure7.23. Giveanalgorithm thatprintsthis\nrepresentation ofatree.\nSales(\nDomestic\nInternational(\nCanada\nS.America\nOverseas(\nAfrica\nEurope\nAsia\nAustralia\n)\n)\n)\n(a) (b)\nFigure7.23: (a)TreeT;(b)indented parenthetic representation ofT.\nC-7.8 LetT bea(possibly improper) binary tree withnnodes, andlet Dbethe\nsumofthedepthsofalltheexternalnodesofT. Describeaconfiguration\nfor T such that D is \u2126(n2). Such a tree would be the worst case for the\nasymptotic runningtimeofAlgorithm height1(CodeFragment7.6).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 314 \u2014 #336\ni i\n314 Chapter7. Trees\nC-7.9 For a tree T, let n denote the number of its internal nodes, and let n\nI E\ndenote thenumber ofitsexternal nodes. Showthat ifeveryinternal node\ninT hasexactly3children, thenn =2n +1.\nE I\nC-7.10 Theupdate operations expandExternalandremoveAboveExternaldonot\npermitthecreationofanimproperbinarytree. Givepseudo-codedescrip-\ntions for alternate update operations suitable for improper binary trees.\nYoumayneedtodefinenewqueryoperations aswell.\nC-7.11 Thebalance factor ofaninternal node vofabinary treeisthedifference\nbetween the heights of the right and left subtrees of v. Show how to spe-\ncializetheEulertourtraversalofSection7.3.7toprintthebalancefactors\nofallthenodesofabinarytree.\nC-7.12 Two ordered trees T\u2032 and T\u2032\u2032 are said to be isomorphic if one of the fol-\nlowingholds:\nBothT\u2032 andT\u2032\u2032 consistofasinglenode\n\u2022\nBoth T\u2032 and T\u2032\u2032 have the same number k of subtrees, and the ith\n\u2022\nsubtreeofT\u2032 isisomorphic totheithsubtreeofT\u2032\u2032,fori=1,...,k.\nDesign an algorithm that tests whether two given ordered trees are iso-\nmorphic. Whatistherunningtimeofyouralgorithm?\nC-7.13 ExtendtheconceptofanEulertourtoanorderedtreethatisnotnecessar-\nilyabinarytree.\nC-7.14 AsmentionedinExerciseC-5.8,postfixnotationisanunambiguous way\nof writing an arithmetic expression without parentheses. It is defined so\nthatif\u201c(exp ) (exp )\u201disanormal(infix)fully parenthesized expression\n1 2\n\u25e6\nwith operation \u201c ,\u201d then its postfix equivalent is \u201cpexp pexp ,\u201d where\n1 2\n\u25e6 \u25e6\npexp is the postfix version of exp and pexp is the postfix version of\n1 1 2\nexp . Thepostfixversionofasinglenumberofvariablesisjustthatnum-\n2\nberorvariable. So,forexample,thepostfixversionoftheinfixexpression\n\u201c((5+2) (8 3))/4\u201d is\u201c52+83 4/.\u201d Giveanefficientalgorithm,\n\u2217 \u2212 \u2212\u2217\nthatwhengivenanexpressiontree,outputstheexpressioninpostfixnota-\ntion.\nC-7.15 Given a proper binary tree T, define the reflection of T to be the binary\ntreeT\u2032 suchthateachnodevinT isalsoinT\u2032,buttheleftchildofvinT\nis v\u2019s right child in T\u2032 and the right child of v in T is v\u2019s left child in T\u2032.\nShowthatapreorder traversalofaproperbinarytreeT isthesameasthe\npostorder traversal ofT\u2019sreflection,butinreverseorder.\nC-7.16 Algorithm preorderDraw draws a binary tree T by assigning x- and y-\ncoordinatestoeachnodevsuchthatx(v)isthenumberofnodespreceding\nvinthepreorder traversal ofT andy(v)isthedepthofvinT. Algorithm\npostorderDrawissimilartopreorderDrawbutassignsx-coordinatesusing\napostorder traversal.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 315 \u2014 #337\ni i\n7.4. Exercises 315\na. ShowthatthedrawingofT produced bypreorderDraw hasnopairs\nofcrossingedges.\nb. RedrawthebinarytreeofFigure7.20usingpreorderDraw.\nc. ShowthatthedrawingofT producedbypostorderDrawhasnopairs\nofcrossingedges.\nd. RedrawthebinarytreeofFigure7.20usingpostorderDraw.\nC-7.17 Let a visit action in the Euler tour traversal be denoted by a pair (v,a),\nwherevisthevisitednodeandaisoneofleft,below,orright. Designan\nalgorithmforperformingoperationtourNext(v,a),whichreturnsthevisit\naction(w,b)following(v,a). Whatistheworst-caserunningtimeofyour\nalgorithm?\nC-7.18 Algorithm preorderDraw draws a binary tree T by assigning x- and y-\ncoordinates toeachnodevasfollows:\nSet x(v) equal to the number of nodes preceding v in the preorder\n\u2022\ntraversal ofT.\nSety(v)equaltothedepthofvinT.\n\u2022\na. Show that the drawing of T produced by algorithm preorderDraw\nhasnopairsofcrossingedges.\nb. UsealgorithmpreorderDrawtoredrawthebinarytreeshowninFig-\nure7.20.\nc. UsealgorithmpostorderDraw,whichissimilartopreorderDrawbut\nassigns x-coordinates using a postorder traversal, to redraw the bi-\nnarytreeofFigure7.20.\nC-7.19 Designanalgorithmfordrawinggeneraltreesthatgeneralizestheinorder\ntraversal approach fordrawingbinarytrees.\nC-7.20 Consider a variation of the linked data structure for binary trees where\neachnodeobjecthaspointerstothenodeobjectsofthechildrenbutnotto\nthenodeobjectoftheparent. Describeanimplementationofthefunctions\nof a binary tree with this data structure and analyze the time complexity\nforthesefunctions.\nC-7.21 Design an alternative implementation of the linked data structure for bi-\nnary trees using a class for nodes that specializes into subclasses for an\ninternal node,anexternalnode, andtherootnode.\nC-7.22 Providethemissinghousekeepingfunctions(destructor,copyconstructor,\nand assignment operator) for the class LinkedBinaryTree given in Code\nFragment7.19.\nC-7.23 Our linked binary tree implementation given in Code Fragment 7.19 as-\nsumesthatthetreeisproper. Designanalternative implementation ofthe\nlinkeddatastructure forageneral(possibly improper) binarytree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 316 \u2014 #338\ni i\n316 Chapter7. Trees\nC-7.24 LetT beatreewithnnodes. Definethelowestcommonancestor (LCA)\nbetween two nodes v and w as the lowest node in T that has both v and\nw as descendents (where we allow a node to be a descendent of itself).\nGiven two nodes v and w, describe an efficient algorithm for finding the\nLCAofvandw. Whatistherunningtimeofyourmethod?\nC-7.25 Let T be a tree with n nodes, and, for any node v in T, let d denote\nv\nthe depth of v in T. The distance between two nodes v and w in T is\nd +d 2d ,whereuistheLCAuofvandw(asdefinedintheprevious\nv w u\n\u2212\nexercise). ThediameterofT isthemaximumdistancebetweentwonodes\ninT. Describe anefficientalgorithm forfindingthediameter ofT. What\nistherunning timeofyourmethod?\nC-7.26 Suppose each node v of a binary tree T is labeled with its value f(v) in\na level numbering of T. Design a fast method for determining f(u) for\nthe lowest common ancestor (LCA), u, of two nodes v and w in T, given\nf(v) and f(w). You do not need to find node u, just compute its level-\nnumbering label.\nC-7.27 Justify Table7.1,summarizing therunning timeofthefunctions ofatree\nrepresented withalinkedstructure, byproviding, foreachfunction, ade-\nscription ofitsimplementation, andananalysisofitsrunningtime.\nC-7.28 Describe efficient implementations of the expandExternal and remove-\nAboveExternal binary tree update functions, described in Section 7.3.4,\nfor the case when the binary tree isimplemented using avector S, where\nSisrealized usinganexpandable array. Yourfunctions should workeven\nfor null external nodes, assuming we represent such a node as a wrapper\nobject storing anindextoanemptyornonexistent cellinS. Whatarethe\nworst-case running times of these functions? What is the running time\nof removeAboveExternal if the internal node removed has only external\nnodechildren?\nC-7.29 Describe a nonrecursive method for evaluating a binary tree representing\nanarithmeticexpression.\nC-7.30 Let T be a binary tree with n nodes. Define a Roman node to be a node\nvinT,suchthatthenumber ofdescendents inv\u2019sleftsubtree differfrom\nthe number of descendants in v\u2019s right subtree by at most 5. Describe\na linear-time method for finding each node v of T, such that v is not a\nRomannode, butallofvdescendants areRomannodes.\nC-7.31 LetT\u2032 bethebinarytreerepresenting atreeT. (SeeSection7.3.8.)\na. Isapreordertraversal ofT\u2032 equivalent toapreordertraversal ofT?\nb. IsapostordertraversalofT\u2032equivalenttoapostordertraversalofT?\nc. IsaninordertraversalofT\u2032equivalenttosomewell-structuredtraver-\nsalofT?\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 317 \u2014 #339\ni i\n7.4. Exercises 317\nC-7.32 Describe anonrecursive method forperforming anEulertourtraversal of\nabinarytreethatrunsinlineartimeanddoesnotuseastack.\n(Hint: Youcantellwhichvisitaction toperform atanode bytaking note\nofwhereyouarecomingfrom.)\nC-7.33 Describe, in pseudo-code, a nonrecursive method for performing an in-\nordertraversalofabinarytreeinlineartime.\n(Hint: Useastack.)\nC-7.34 LetT beabinary treewithnnodes (T mayormaynotberealized witha\nvector). Give a linear-time method that uses the functions of the Binary-\nTreeinterface totraverse thenodes ofT byincreasing values ofthelevel\nnumbering function f given in Section 7.3.5. This traversal is known as\nthelevelordertraversal.\n(Hint: Useaqueue.)\nC-7.35 ThepathlengthofatreeT isthesumofthedepthsofallthenodesinT.\nDescribe a linear-time method for computing the path length of a tree T\n(whichisnotnecessarily binary).\nC-7.36 Define the internal path length, I(T), of a tree T, to be the sum of the\ndepths of all the internal nodes in T. Likewise, define the external path\nlength, E(T), of a tree T, to be the sum of the depths of all the external\nnodes in T. Show that if T is a binary tree with n internal nodes, then\nE(T)=I(T)+2n.\n(Hint: UsethefactthatwecanbuildT fromasinglerootnodeviaaseries\nofnexpandExternaloperations.)\nProjects\nP-7.1 Writeaprogram thattakesasinput arooted treeT andanodevofT and\nconverts T toanother tree withthe same set ofnode adjacencies but now\nrootedatv.\nP-7.2 Givea fully generic implementation of the class LinkedBinaryTree using\nclasstemplatesandtakingintoaccounterrorconditions.\nP-7.3 ImplementthebinarytreeADTusingavector.\nP-7.4 ImplementthebinarytreeADTusingalinkedstructure.\nP-7.5 Writeaprogram thatdrawsabinarytree.\nP-7.6 Writeaprogram thatdrawsageneral tree.\nP-7.7 Writeaprogram thatcaninputanddisplay aperson\u2019sfamilytree.\nP-7.8 Implementthebinary treerepresentation ofthetreeADT.Youmayreuse\ntheLinkedBinaryTreeimplementation ofabinarytree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 318 \u2014 #340\ni i\n318 Chapter7. Trees\nP-7.9 Aslicingfloorplan isadecomposition ofarectangle withhorizontal and\nvertical sides using horizontal and vertical cuts (see Figure 7.24(a)). A\nslicingfloorplan canberepresented byabinarytree,calledaslicingtree,\nwhose internal nodes represent the cuts, and whose external nodes repre-\nsent the basic rectangles into which the floorplan is decomposed by the\ncuts(seeFigure7.24(b)). Thecompaction problem isdefinedasfollows.\nAssumethateachbasicrectangle ofaslicing floorplanisassigned amin-\nimum width w and a minimum height h. The compaction problem is to\nfind the smallest possible height and width for each rectangle of the slic-\ningfloorplanthatiscompatiblewiththeminimumdimensionsofthebasic\nrectangles. Namely, this problem requires the assignment of values h(v)\nandw(v)toeachnodevoftheslicingtree,suchthat\nif v is an external node whose basic rect-\nw\nanglehasminimumwidthw\n\uf8f1\n\uf8f4\n\uf8f4 \uf8f4 if v is an internal node associated with a\n\uf8f4\n\uf8f4\n\uf8f4 \uf8f4 max(w(w),w(z)) horizontal cut with left child w and right\nw(v)=\uf8f4\n\uf8f4\n\uf8f4 \uf8f4 childz\n\uf8f4\n\uf8f4\n\uf8f2\nif v is an internal node associated with\n\uf8f4 \uf8f4 w(w)+w(z) a vertical cut with left child w and right\n\uf8f4\n\uf8f4\n\uf8f4 \uf8f4 childz\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4 \uf8f3 if v is an external node whose basic rect-\nh\nanglehasminimumheighth\n\uf8f1\n\uf8f4\n\uf8f4 \uf8f4 if v is an internal node associated with a\n\uf8f4\n\uf8f4\n\uf8f4 \uf8f4 h(w)+h(z) horizontal cut with left child w and right\nh(v)=\uf8f4\n\uf8f4\n\uf8f4 \uf8f4 childz\n\uf8f4\n\uf8f4\n\uf8f2\nif v is an internal node associated with\n\uf8f4 max(h(w),h(z)) a vertical cut with left child w and right\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4 \uf8f4 childz\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\nDesign\uf8f4 \uf8f4a data structure for slicing floorplans that supports the following\n\uf8f3\noperations:\nCreateafloorplanconsisting ofasinglebasicrectangle\n\u2022\nDecomposeabasicrectangle bymeansofahorizontal cut\n\u2022\nDecomposeabasicrectangle bymeansofaverticalcut\n\u2022\nAssignminimumheightandwidthtoabasicrectangle\n\u2022\nDrawtheslicingtreeassociated withthefloorplan\n\u2022\nCompactthefloorplan\n\u2022\nDrawthecompacted floorplan\n\u2022\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 319 \u2014 #341\ni i\n7.4. Exercises 319\n(a) (b)\nFigure7.24: (a)Slicingfloorplan; (b)slicing treeassociated withthefloorplan.\nP-7.10 Writeaprogram that takes, asinput, afully parenthesized, arithmetic ex-\npression andconverts ittoabinaryexpression tree. Yourprogram should\ndisplay the tree in some way and also print the value associated with the\nroot. For an additional challenge, allow for the leaves to store variables\nof the form x , x , x , and so on, which are initially 0 and which can be\n1 2 3\nupdated interactively by your program, with the corresponding update in\ntheprintedvalueoftherootoftheexpression tree.\nP-7.11 WriteaprogramthatcanplayTic-Tac-Toeeffectively. (SeeSection3.1.3.)\nTo do this, you will need to create a game tree T, which is a tree where\neach node corresponds to a game configuration, which, in this case, is\na representation of the tic-tac-toe board. The root node corresponds to\nthe initial configuration. For each internal node v in T, the children of v\ncorrespondtothegamestateswecanreachfromv\u2019sgamestateinasingle\nlegalmovefortheappropriate player, A(thefirstplayer)orB(thesecond\nplayer). Nodes at even depths correspond to moves for A and nodes at\nodd depths correspond to moves for B. External nodes are either final\ngamestatesorareatadepthbeyond whichwedon\u2019t wanttoexplore. We\nscore each external node with a value that indicates how good this state\nis for player A. In large games, like chess, we have to use a heuristic\nscoring function, but for small games, like tic-tac-toe, we can construct\nthe entire game tree and score external nodes as +1, 0, 1, indicating\n\u2212\nwhether player A has a win, draw, or lose in that configuration. A good\nalgorithm forchoosing movesisminimax. Inthisalgorithm, weassign a\nscore to each internal node v in T, such that if v represents A\u2019s turn, we\ncompute v\u2019s score as the maximum of the scores of v\u2019s children (which\ncorresponds to A\u2019s optimal play from v). If an internal node v represents\nB\u2019s turn, then we compute v\u2019s score as the minimum of the scores of v\u2019s\nchildren (whichcorresponds toB\u2019soptimalplayfromv).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 320 \u2014 #342\ni i\n320 Chapter7. Trees\nChapter Notes\nOuruseofthepositionabstractionderivesfromthepositionandnodeabstractionsintro-\nduced by Aho, Hopcroft, and Ullman [5]. Discussions of the classic preorder, inorder,\nand postorder tree traversal methods can be found in Knuth\u2019s Fundamental Algorithms\nbook[56]. TheEulertourtraversaltechniquecomesfromtheparallelalgorithmscommu-\nnity, as it is introducedby Tarjan and Vishkin [93] and is discussed by Ja\u00b4Ja\u00b4 [49] and by\nKarp and Ramachandran [53]. The algorithm for drawing a tree is generally considered\ntobeapartofthe\u201cfolklore\u201dofgraphdrawingalgorithms. Thereaderinterestedingraph\ndrawing is referred to the book by Di Battista, Eades, Tamassia and Tollis [28] and the\nsurveybyTamassiaandLiotta[92].ThepuzzlerinExerciseR-7.11wascommunicatedby\nMichaSharir.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 321 \u2014 #343\ni i\nChapter\n8\nHeaps and Priority Queues\nContents\n8.1 The Priority Queue Abstract Data Type. . . . . . . . 322\n8.1.1 Keys, Priorities, and Total Order Relations . . . . . . 322\n8.1.2 Comparators . . . . . . . . . . . . . . . . . . . . . . 324\n8.1.3 The Priority Queue ADT . . . . . . . . . . . . . . . 327\n8.1.4 A C++ Priority Queue Interface . . . . . . . . . . . . 328\n8.1.5 Sorting with a Priority Queue . . . . . . . . . . . . . 329\n8.1.6 The STL priority queue Class . . . . . . . . . . . . . 330\n8.2 Implementing a Priority Queue with a List . . . . . . 331\n8.2.1 A C++ Priority Queue Implementation using a List . 333\n8.2.2 Selection-Sort and Insertion-Sort . . . . . . . . . . . 335\n8.3 Heaps . . . . . . . . . . . . . . . . . . . . . . . . . . . 337\n8.3.1 The Heap Data Structure . . . . . . . . . . . . . . . 337\n8.3.2 Complete Binary Trees and Their Representation . . 340\n8.3.3 Implementing a Priority Queue with a Heap . . . . . 344\n8.3.4 C++ Implementation . . . . . . . . . . . . . . . . . 349\n8.3.5 Heap-Sort . . . . . . . . . . . . . . . . . . . . . . . 351\n\u22c6\n8.3.6 Bottom-Up Heap Construction . . . . . . . . . . 353\n8.4 Adaptable Priority Queues . . . . . . . . . . . . . . . 357\n8.4.1 A List-Based Implementation . . . . . . . . . . . . . 358\n8.4.2 Location-Aware Entries . . . . . . . . . . . . . . . . 360\n8.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 361\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 322 \u2014 #344\ni i\n322 Chapter8. HeapsandPriorityQueues\n8.1 The Priority Queue Abstract Data Type\nApriority queueis anabstract data type for storing acollection ofprioritized ele-\nmentsthatsupportsarbitraryelementinsertionbutsupportsremovalofelementsin\norderofpriority, thatis,theelementwithfirstprioritycanberemovedatanytime.\nThis ADT is fundamentally different from the position-based data structures such\nas stacks, queues, deques, lists, and even trees, wediscussed inprevious chapters.\nThese other data structures store elements at specific positions, which are often\npositions in a linear arrangement of the elements determined by the insertion and\ndeletion operations performed. Thepriority queueADTstoreselements according\ntotheirpriorities, andhasnoexternalnotionof\u201cposition.\u201d\n8.1.1 Keys, Priorities, and Total Order Relations\nApplications commonly require comparing and ranking objects according to pa-\nrameters or properties, called \u201ckeys,\u201d that are assigned to each object in a collec-\ntion. Formally, we define a key to be an object that is assigned to an element as a\nspecific attribute for that element and that can be used to identify, rank, or weigh\nthatelement. Notethatthekeyisassigned toanelement, typicallybyauserorap-\nplication;hence,akeymightrepresentapropertythatanelementdidnotoriginally\npossess.\nThekeyanapplicationassignstoanelementisnotnecessarilyunique,however,\nand an application may even change an element\u2019s key if it needs to. For example,\nwecan compare companies byearnings orby numberofemployees; hence, either\nof these parameters can be used as a key for a company, depending on the infor-\nmationwewishtoextract. Likewise,wecancomparerestaurants byacritic\u2019sfood\nquality rating or by average entre\u00b4e price. To achieve the most generality then, we\nallowakeytobeofanytypethatisappropriate foraparticular application.\nAs in the examples above, the key used for comparisons is often more than\na single numerical value, such as price, length, weight, or speed. That is, a key\ncansometimesbeamorecomplex property thatcannot bequantified withasingle\nnumber. Forexample, the priority of standby passengers is usually determined by\ntaking into account a host of different factors, including frequent-flyer status, the\nfare paid, and check-in time. In some applications, the key for an object is data\nextractedfromtheobjectitself(forexample,itmightbeamembervariablestoring\nthelistpriceofabook,ortheweightofacar). Inotherapplications, thekeyisnot\npart of the object but is externally generated by the application (for example, the\nquality rating given to a stock by a financial analyst, or the priority assigned to a\nstandby passenger byagateagent).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 323 \u2014 #345\ni i\n8.1. ThePriorityQueueAbstractDataType 323\nComparing Keys with Total Orders\nApriority queue needs acomparison rulethat nevercontradicts itself. Inorder for\na comparison rule, which we denote by , to be robust in this way, it must define\n\u2264\natotal order relation, whichis tosay that the comparison rule isdefined for every\npairofkeysanditmustsatisfy thefollowingproperties:\nReflexiveproperty: k k\n\u2022 \u2264\nAntisymmetricproperty: ifk k andk k ,thenk =k\n1 2 2 1 1 2\n\u2022 \u2264 \u2264\nTransitiveproperty: ifk k andk k ,thenk k\n1 2 2 3 1 3\n\u2022 \u2264 \u2264 \u2264\nAny comparison rule, , that satisfies these three properties never leads to a\n\u2264\ncomparisoncontradiction. Infact,sucharuledefinesalinearorderingrelationship\namongasetofkeys. Ifafinitecollectionofkeyshasatotalorderdefinedforit,then\nthe notion of the smallest key, k , is well defined as the key, such that k k,\nmin min\n\u2264\nforanyotherkeykinourcollection.\nA priority queue is a container of elements, each associated with a key. The\nname\u201cpriority queue\u201d comesfromthefactthatkeysdetermine the\u201cpriority\u201d used\nto pick elements to be removed. The fundamental functions of a priority queue P\nareasfollows:\ninsert(e): Inserttheelemente(withanimplicitassociatedkeyvalue)\nintoP.\nmin(): Return an element of P with the smallest associated key\nvalue, thatis,anelementwhosekeyislessthanorequal\ntothatofeveryotherelementinP.\nremoveMin(): RemovefromPtheelementmin().\nNote that more than one element can have the same key, which is why we were\ncareful to define removeMin to remove not just any minimum element, but the\nsame element returned by min. Some people refer to the removeMin function as\nextractMin.\nThere are many applications where operations insert and removeMin play an\nimportantrole. Weconsider suchanapplication intheexamplethatfollows.\nExample 8.1: Supposeacertainflightisfullybookedanhourpriortodeparture.\nBecauseofthepossibilityofcancellations,theairlinemaintainsapriorityqueueof\nstandbypassengershopingtogetaseat. Thepriorityofeachpassengerisdeter-\nminedbythefarepaid,thefrequent-flyerstatus,andthetimewhenthepassengeris\ninsertedintothepriorityqueue.Whenapassengerrequeststoflystandby,theasso-\nciatedpassengerobjectisinsertedintothepriorityqueuewithaninsertoperation.\nShortlybeforetheflightdeparture,ifseatsbecomeavailable(forexample,dueto\nlast-minutecancellations),theairlinerepeatedlyremovesastandbypassengerwith\nfirstpriorityfromthepriorityqueue,usingacombinationofminandremoveMin\noperations,andletsthispersonboard.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 324 \u2014 #346\ni i\n324 Chapter8. HeapsandPriorityQueues\n8.1.2 Comparators\nAn important issue in the priority queue ADT that we have so far left undefined\nis how to specify the total order relation for comparing the keys associated with\neachelement. Thereareanumberofwaysofdoing this, eachhaving itsparticular\nadvantages anddisadvantages.\nThe most direct solution is to implement a different priority queue based on\nthe element type and the manner of comparing elements. While this approach is\narguably simple, it is certainly not very general, since it would require that we\nmakemanycopiesofessentiallythesamecode. Maintainingmultiplecopiesofthe\nnearlyequivalent codeismessyanderrorprone.\nA better approach would be to design the priority queue as a templated class,\nwhere the element type is specified by an abstract template argument, say E. We\nassumethateachconcreteclassthatcouldserveasanelementofourpriorityqueue\nprovides a means for comparing two objects of type E. This could be done in\nmany ways. Perhaps we require that each object of type E provides a function\ncalled comp that compares two objects of type E and determines which is larger.\nPerhaps werequire that theprogrammer defines afunction that overloads theC++\ncomparison operator \u201c<\u201d for two objects of type E. (Recall Section 1.4.2 for a\ndiscussion ofoperator overloading). InC++jargon thisiscalledafunctionobject.\nLetusconsideramoreconcreteexample. SupposethatclassPoint2Ddefinesa\ntwo-dimensional point. Ithastwopublicmemberfunctions, getXandgetY,which\naccessitsxandycoordinates, respectively. Wecoulddefinealexicographical less-\nthan operator as follows. If the x coordinates differ we use their relative values;\notherwise, weusetherelativevaluesoftheycoordinates.\nbool operator<(const Point2D& p, const Point2D& q)\n{\nif (p.getX() == q.getX()) return p.getY() < q.getY();\nelse return p.getX() < q.getX();\n}\nThis approach of overloading the relational operators is general enough for\nmany situations, but it relies on the assumption that objects of the same type are\nalways compared in the same way. There are situations, however, where it is de-\nsirable to apply different comparisons to objects of the same type. Consider the\nfollowingexamples.\nExample 8.2: ThereareatleasttwowaysofcomparingtheC++characterstrings,\n\"4\"and\"12\".Inthelexicographic ordering,whichisanextensionofthealpha-\nbeticorderingtocharacterstrings,wehave\"4\">\"12\".Butifweinterpretthese\nstringsasintegers,then\"4\"<\"12\".\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 325 \u2014 #347\ni i\n8.1. ThePriorityQueueAbstractDataType 325\nExample 8.3: Ageometricalgorithmmaycomparepointspandqintwo-dimen-\nsionalspace,bytheirx-coordinate(thatis,p qifp q ),tosortthemfromleft\nx x\n\u2264 \u2264\ntoright,whileanotheralgorithmmaycomparethembytheiry-coordinate(thatis,\np q ifp q ),tosortthemfrombottomtotop. Inprinciple,thereisnothing\ny y\n\u2264 \u2264\npertainingtotheconceptofapointthatsayswhetherpointsshouldbecompared\nbyx-ory-coordinates.Also,manyotherwaysofcomparingpointscanbedefined\n(forexample,wecancomparethedistancesofpandqfromtheorigin).\nThere are a couple of ways to achieve the goal of independence of element\ntype and comparison method. The most general approach, called the composition\nmethod, is based on defining each entry of our priority queue to be a pair (e,k),\nconsisting of an element e and a key k. The element part stores the data, and the\nkey part stores the information that defines the priority ordering. Each key object\ndefinesitsowncomparisonfunction. Bychangingthekeyclass,wecanchangethe\nwayinwhichthequeueisordered. Thisapproach isverygeneral, because thekey\npartdoesnotneedtodependonthedatapresentintheelementpart. Westudythis\napproach ingreaterdetailinChapter9.\nThe approach that we use is a bit simpler than the composition method. It is\nbased on defining aspecial object, called a comparator, whose job is to provide a\ndefinitionofthecomparison functionbetweenanytwoelements. Thiscanbedone\nin various ways. In C++, a comparator for element type E can be implemented as\na class that defines a single function whose job is to compare two objects of type\nE. Onewaytodothisistooverloadthe\u201c()\u201doperator. Theresultingfunctiontakes\ntwo arguments, a and b, and returns a boolean whose value is true if a<b. For\nexample,if\u201cisLess\u201disthenameofourcomparatorobject,thecomparisonfunction\nisinvoked usingthefollowingoperation:\nisLess(a,b): Returntrueifa<bandfalseotherwise.\nItmightseematfirstthatdefiningjustaless-thanfunctionisratherlimited,but\nnotethatitispossibletoderivealltheotherrelationaloperatorsbycombiningless-\nthan comparisons with other boolean operators. Forexample, wecan test whether\naandbareequalwith(!isLess(a,b) && !isLess(b, a)). (SeeExerciseR-8.3.)\nDefining and Using Comparator Objects\nLet us consider a more concrete example of a comparator class. As mentioned in\nthe above example, let us suppose that we have defined a class structure, called\nPoint2D, for storing a two-dimensional point. In Code Fragment 8.1, we present\ntwo comparators. The comparator LeftRight implements a left-to-right order by\ncomparing thex-coordinates of the points, and the comparator BottomTop imple-\nmentsabottom-to-top orderbycomparing they-coordinates ofthepoints.\nTo use these comparators, we would declare two objects, one of each type.\nLet us call them leftRight and bottomTop. Observe that these objects store no\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 326 \u2014 #348\ni i\n326 Chapter8. HeapsandPriorityQueues\nclass LeftRight // a left-right comparator\n{\npublic:\nbool operator()(const Point2D& p, const Point2D& q) const\nreturn p.getX() < q.getX();\n{ }\n;\n}\nclass BottomTop // a bottom-top comparator\n{\npublic:\nbool operator()(const Point2D& p, const Point2D& q) const\nreturn p.getY() < q.getY();\n{ }\n;\n}\nCodeFragment8.1: Twocomparatorclassesforcomparingpoints. Thefirstimple-\nmentsaleft-to-right orderandthesecondimplementsabottom-to-top order.\ndata members. They are used solely for the purposes of specifying a particular\ncomparison operator. Given two objects p and q, each of type Point2D, to test\nwhether pistotheleftofq,wewouldinvokeleftRight(p,q),andtotestwhether p\nisbelow q,wewould invoke bottomTop(p,q). Eachinvokes the\u201c()\u201doperator for\nthecorresponding class.\nNext,letusseehowwecanuseourcomparatorstoimplementtwodifferentbe-\nhaviors. Consider the generic function printSmallershown in Code Fragment 8.2.\nIt prints the smaller of its two arguments. The function definition is templated by\nthe element type E and the comparator typeC. The comparator class is assumed\ntoimplement aless-than function for twoobjects of type E. Thefunction is given\nthreearguments,thetwoelements pandqtobecomparedandaninstanceisLessof\nacomparatorfortheseelements. Thefunctioninvokesthecomparatortodetermine\nwhichelementissmaller,andthenprintsthisvalue.\ntemplate <typename E, typename C> // element type and comparator\nvoid printSmaller(const E& p, const E& q, const C& isLess)\n{\ncout << (isLess(p, q) ? p : q) << endl; // print the smaller of p and q\n}\nCode Fragment 8.2: A generic function that prints the smaller of two elements,\ngivenacomparator fortheseelements.\nFinally, let us see how we can apply our function on two points. The code\nis shown in Code Fragment 8.3. We declare to points p and q and initialize their\ncoordinates. (We have not presented the class definition for Point2D, but let us\nassumethattheconstructorisgiventhex-andy-coordinates, andwehaveprovided\nanoutputoperator.) Wethendeclaretwocomparatorobjects,oneforaleft-to-right\norderingandtheotherforabottom-to-topordering. Finally,weinvokethefunction\nprintSmalleronthetwopoints,changing onlythecomparatorobjectsineachcase.\nObservethat,depending onwhichcomparatorisprovided, thecalltothefunc-\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 327 \u2014 #349\ni i\n8.1. ThePriorityQueueAbstractDataType 327\nPoint2D p(1.3, 5.7), q(2.5, 0.6); // two points\nLeftRight leftRight; // a left-right comparator\nBottomTop bottomTop; // a bottom-top comparator\nprintSmaller(p, q, leftRight); // outputs: (1.3, 5.7)\nprintSmaller(p, q, bottomTop); // outputs: (2.5, 0.6)\nCodeFragment8.3: The use of two comparators to implement different behaviors\nfromthefunction printSmaller.\ntion isLess in function printSmaller invokes either the \u201c()\u201d operator of class Left-\nRight or BottomTop. In this way, we obtain the desired result, two different be-\nhaviors forthesametwo-dimensional pointclass.\nThrough the use of comparators, a programmer can write a general priority\nqueue implementation that works correctly in a wide variety of contexts. In par-\nticular, the priority queues presented in this chapter are generic classes that are\ntemplatedbytwotypes,theelementE andthecomparatorC.\nThe comparator approach is a bit less general than the composition method,\nbecause the comparator bases its decisions on the contents of the elements them-\nselves. Inthecompositionmethod,thekeymaycontaininformationthatisnotpart\nof the element object. The comparator approach has the advantage of being sim-\npler, since wecan insert elements directly into our priority queue without creating\nelement-key pairs. Furthermore, in Exercise R-8.4 we show that there is no real\nlossofgenerality inusingcomparators.\n8.1.3 The Priority Queue ADT\nHavingdescribedthepriorityqueueabstractdatatypeatanintuitivelevel,wenow\ndescribe it in more detail. As an ADT, a priority queue P supports the following\nfunctions:\nsize(): ReturnthenumberofelementsinP.\nempty(): ReturntrueifPisemptyandfalseotherwise.\ninsert(e): InsertanewelementeintoP.\nmin(): Return a reference to an element of P with the smallest\nassociatedkeyvalue(butdonotremoveit);anerrorcon-\nditionoccursifthepriority queueisempty.\nremoveMin(): Remove from Pthe element referenced by min(); an er-\nrorcondition occursifthepriority queueisempty.\nAs mentioned above, the primary functions of the priority queue ADT are the\ninsert, min, and removeMin operations. The other functions, size and empty, are\ngenericcollection operations. Notethatweallowapriority queuetohavemultiple\nentrieswiththesamekey.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 328 \u2014 #350\ni i\n328 Chapter8. HeapsandPriorityQueues\nExample 8.4: Thefollowingtableshowsaseriesofoperationsandtheireffects\nonaninitiallyemptypriorityqueueP.Eachelementconsistsofaninteger,which\nweassumetobesortedaccordingtothenaturalorderingoftheintegers.Notethat\neachcalltominreturnsareferencetoanentryinthequeue,nottheactualvalue.\nAlthoughthe\u201cPriorityQueue\u201dcolumnshowstheitemsinsortedorder,thepriority\nqueueneednotstoreelementsinthisorder.\nOperation Output PriorityQueue\ninsert(5) \u2013 5\n{ }\ninsert(9) \u2013 5,9\n{ }\ninsert(2) \u2013 2,5,9\n{ }\ninsert(7) \u2013 2,5,7,9\n{ }\nmin() [2] 2,5,7,9\n{ }\nremoveMin() \u2013 5,7,9\n{ }\nsize() 3 5,7,9\n{ }\nmin() [5] 5,7,9\n{ }\nremoveMin() \u2013 7,9\n{ }\nremoveMin() \u2013 9\n{ }\nremoveMin() \u2013\n{}\nempty() true\n{}\nremoveMin() \u201cerror\u201d\n{}\n8.1.4 A C++ Priority Queue Interface\nBefore discussing specific implementations of the priority queue, we first define\nan informal C++ interface for a priority queue in Code Fragment 8.4. It is not a\ncompleteC++class, justadeclaration ofthepublicfunctions.\ntemplate <typename E, typename C> // element and comparator\nclass PriorityQueue // priority-queue interface\n{\npublic:\nint size() const; // number of elements\nbool isEmpty() const; // is the queue empty?\nvoid insert(const E& e); // insert element\nconst E& min() const throw(QueueEmpty); // minimum element\nvoid removeMin() throw(QueueEmpty); // remove minimum\n;\n}\nCodeFragment8.4: AninformalPriorityQueueinterface(notacompleteclass).\nAlthoughthecomparatortypeCisincludedasatemplateargument,itdoesnot\nappearinthepublicinterface. Ofcourse,itsvalueisrelevanttoanyconcreteimple-\nmentation. Observethatthefunctionminreturnsaconstantreferencetotheelement\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 329 \u2014 #351\ni i\n8.1. ThePriorityQueueAbstractDataType 329\ninthequeue, whichmeans thatitsvaluemaybereadand copied butnotmodified.\nThisisimportantbecause otherwiseauseroftheclassmightinadvertently modify\nthe element\u2019s associated key value, and this could corrupt the integrity of the data\nstructure. Thememberfunctionssize,empty,andminarealldeclaredtobeconst,\nwhichinformsthecompilerthattheydonotalterthecontents ofthequeue.\nAnerrorcondition occursifeitherofthefunctionsminorremoveMiniscalled\non an empty priority queue. This is signaled by throwing an exception of type\nQueueEmpty. Its definition is similar to others we have seen. (See Code Frag-\nment5.2.)\n8.1.5 Sorting with a Priority Queue\nAnother important application of apriority queue is sorting, where weare given a\ncollection Lofnelementsthatcanbecomparedaccording toatotalorderrelation,\nand we want to rearrange them in increasing order (or at least in nondecreasing\norder if there are ties). Thealgorithm for sorting Lwithapriority queue Q, called\nPriorityQueueSort,isquitesimpleandconsists ofthefollowingtwophases:\n1. In the first phase, we put the elements of L into an initially empty priority\nqueuePthrough aseriesofninsertoperations, oneforeachelement.\n2. In the second phase, weextract the elements from Pinnondecreasing order\nby means of a series of n combinations of min and removeMin operations,\nputting thembackintoLinorder.\nPseudo-code for thisalgorithm isgiven inCode Fragment 8.5. Itassumes that\nLisgivenasanSTLlist,butthecodecanbeadaptedtoothercontainers.\nAlgorithmPriorityQueueSort(L,P):\nInput: An STL list L of n elements and a priority queue, P, that compares\nelementsusingatotalorderrelation\nOutput: ThesortedlistL\nwhile !L.empty() do\ne L.front\n\u2190\nL.pop front() removeanelementefromthelist\n{ }\nP.insert(e) ...andittothepriority queue\n{ }\nwhile !P.empty() do\ne P.min()\n\u2190\nP.removeMin() removethesmallestelementefromthequeue\n{ }\nL.push back(e) ...andappend ittothebackofL\n{ }\nCodeFragment8.5: Algorithm PriorityQueueSort, which sorts an STL list L with\ntheaidofapriority queueP.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 330 \u2014 #352\ni i\n330 Chapter8. HeapsandPriorityQueues\nThe algorithm works correctly for any priority queue P, no matter how P is\nimplemented. However, the running time of the algorithm is determined by the\nrunning timesofoperations insert,min,andremoveMin,whichdodepend onhow\nPisimplemented. Indeed, PriorityQueueSort shouldbeconsidered moreasorting\n\u201cscheme\u201d than a sorting \u201calgorithm,\u201d because it does not specify how the priority\nqueuePisimplemented. ThePriorityQueueSortschemeistheparadigmofseveral\npopular sorting algorithms, including selection-sort, insertion-sort, and heap-sort,\nwhichwediscussinthischapter.\n8.1.6 The STL priority queue Class\nThe C++ Standard Template Library (STL) provides an implementation of a pri-\nority queue, called priority queue. As with the other STL classes we have seen,\nsuch as stacks and queues, the STL priority queue is an example of a container.\nIn order to declare an object of type priority queue, it is necessary to first include\nthe definition file, which is called \u201cqueue.\u201d As with other STL objects, the pri-\nority queue is part of the std namespace, and hence it is necessary either to use\n\u201cstd::priority queue\u201dortoprovideanappropriate \u201cusing\u201dstatement.\nThe priority queue class is templated with three parameters: the base type of\nthe elements, the underlying STL container in which the priority queue is stored,\nandthecomparatorobject. Onlythefirsttemplateargumentisrequired. Thesecond\nparameter (the underlying container) defaults to the STLvector. The third param-\neter (the comparator) defaults to using the standard C++ less-than operator (\u201c<\u201d).\nTheSTLpriorityqueueusescomparatorsinthesamemanneraswedefinedinSec-\ntion 8.1.2. In particular, a comparator is a class that overrides the \u201c()\u201d operator in\nordertodefineaboolean functionthatimplementstheless-than operator.\nThe code fragment below defines two STL priority queues. The first stores\nintegers. Thesecondstorestwo-dimensional pointsundertheleft-to-right ordering\n(recallSection8.1.2).\n#include <queue>\nusing namespace std; // make std accessible\npriority queue<int> p1; // a priority queue of integers\n// a priority queue of points with left-to-right order\npriority queue<Point2D, vector<Point2D>, LeftRight> p2;\nTheprincipalmemberfunctionsoftheSTLpriorityqueuearegivenbelow. Let\np be declared to be an STL priority queue, and let e denote a single object whose\ntypeisthesameasthebasetypeofthepriorityqueue. (Forexample, pisapriority\nqueueofintegers, andeisaninteger.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 331 \u2014 #353\ni i\n8.2. ImplementingaPriorityQueuewithaList 331\nsize(): Returnthenumberofelementsinthepriorityqueue.\nempty(): Return true if the priority queue is empty and false oth-\nerwise.\npush(e): Inserteinthepriorityqueue.\ntop(): Return a constant reference to the largest element of the\npriority queue.\npop(): Removetheelementatthetopofthepriority queue.\nOther than the differences in function names, the most significant difference\nbetweenourinterface andtheSTLpriority queueisthatthefunctions topandpop\naccess the largest item in the queue according to priority order, rather than the\nsmallest. An example of the usage of the STL priority queue is shown in Code\nFragment8.6.\npriority queue<Point2D, vector<Point2D>, LeftRight> p2;\np2.push( Point2D(8.5, 4.6) ); // add three points to p2\np2.push( Point2D(1.3, 5.7) );\np2.push( Point2D(2.5, 0.6) );\ncout << p2.top() << endl; p2.pop(); // output: (8.5, 4.6)\ncout << p2.top() << endl; p2.pop(); // output: (2.5, 0.6)\ncout << p2.top() << endl; p2.pop(); // output: (1.3, 5.7)\nCodeFragment8.6: AnexampleoftheuseoftheSTLpriority queue.\nOfcourse, itispossible tosimulate thesamebehavior asourpriority queueby\ndefiningthecomparatorobjectsothatitimplementsthegreater-thanrelationrather\nthan the less-than relation. This effectively reverses all order relations, and thus\nthe top function would instead return the smallest element, just as function min\ndoes inour interface. NotethattheSTLpriority queue doesnot perform anyerror\nchecking.\n8.2 Implementing a Priority Queue with a List\nInthissection, weshowhowtoimplementapriority queuebystoringitselements\nin an STL list. (Recall this data structure from Section 6.2.4.) We consider two\nrealizations, depending onwhetherwesorttheelementsofthelist.\nImplementation with an Unsorted List\nLetusfirstconsidertheimplementationofapriorityqueuePbyanunsorteddoubly\nlinked list L. A simple way to perform the operation insert(e) on P is by adding\neach new element at the end of L by executing the function L.push back(e). This\nimplementation ofinserttakesO(1)time.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 332 \u2014 #354\ni i\n332 Chapter8. HeapsandPriorityQueues\nSincetheinsertiondoesnotconsiderkeyvalues,theresultinglistLisunsorted.\nAs a consequence, in order to perform either of the operations min or removeMin\non P, we must inspect all the entries of the list to find one with the minimum key\nvalue. Thus, functions min and removeMin take O(n) time each, where n is the\nnumber of elements in P at the time the function is executed. Moreover, each of\nthesefunctions runsintimeproportional toneveninthebestcase,sincetheyeach\nrequire searching the entire list tofindthe smallest element. Using the notation of\nSection 4.2.3, we can say that these functions run in \u0398(n) time. We implement\nfunctionssizeandemptybysimplyreturningtheoutputofthecorresponding func-\ntions executed on list L. Thus, by using an unsorted list to implement a priority\nqueue, weachieveconstant-time insertion, butlinear-time searchandremoval.\nImplementation with a Sorted List\nAn alternative implementation of a priority queue P also uses a list L, except that\nthistimeletusstoretheelementssortedbytheirkeyvalues. Specifically,werepre-\nsentthepriorityqueuePbyusingalistLofelementssortedbynondecreasing key\nvalues,whichmeansthatthefirstelementofLhasthesmallestkey.\nWecanimplementfunctionmininthiscasebyaccessingtheelementassociated\nwith the first element of the list with the begin function of L. Likewise, we can\nimplement the removeMin function of P as L.pop front(). Assuming that L is\nimplementedasadoublylinkedlist,operationsminandremoveMininPtakeO(1)\ntime,soarequiteefficient.\nThisbenefitcomesatacost,however,fornowfunctioninsertofPrequiresthat\nwescanthroughthelistLtofindtheappropriatepositioninwhichtoinsertthenew\nentry. Thus, implementing the insert function of P now takes O(n) time, where\nn is the number of entries in P at the time the function is executed. In summary,\nwhenusingasortedlisttoimplementapriorityqueue,insertionrunsinlineartime\nwhereasfindingandremovingtheminimumcanbedoneinconstant time.\nTable8.1compares therunning timesofthefunctions ofapriority queuereal-\nized by means of an unsorted and sorted list, respectively. There is an interesting\ncontrast between the two functions. An unsorted list allows for fast insertions but\nslowqueriesanddeletions, whileasortedlistallowsforfastqueriesanddeletions,\nbutslowinsertions.\nOperation UnsortedList SortedList\nsize,empty O(1) O(1)\ninsert O(1) O(n)\nmin,removeMin O(n) O(1)\nTable8.1: Worst-case running times of the functions of a priority queue of size n,\nrealized by means of an unsorted or sorted list, respectively. We assume that the\nlistisimplemented byadoubly linkedlist. Thespacerequirement isO(n).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 333 \u2014 #355\ni i\n8.2. ImplementingaPriorityQueuewithaList 333\n8.2.1 A C++ Priority Queue Implementation using a List\nIn Code Fragments 8.7 through 8.10, we present a priority queue implementation\nthat stores the elements in a sorted list. The list is implemented using an STL list\nobject(seeSection6.3.2),butanyimplementation ofthelistADTwouldsuffice.\nIn Code Fragment 8.7, we present the class definition for our priority queue.\nThe public part of the class is essentially the same as the interface that was pre-\nsented earlier in Code Fragment 8.4. In order tokeep the code as simple as possi-\nble, we have omitted error checking. The class\u2019s data members consists of a list,\nwhichholdsthepriorityqueue\u2019scontents,andaninstanceofthecomparatorobject,\nwhichwecallisLess.\ntemplate <typename E, typename C>\nclass ListPriorityQueue\n{\npublic:\nint size() const; // number of elements\nbool empty() const; // is the queue empty?\nvoid insert(const E& e); // insert element\nconst E& min() const; // minimum element\nvoid removeMin(); // remove minimum\nprivate:\nstd::list<E> L; // priority queue contents\nC isLess; // less-than comparator\n;\n}\nCodeFragment8.7: TheclassdefinitionforapriorityqueuebasedonanSTLlist.\nWe have not bothered to give an explicit constructor for our class, relying in-\nstead on the default constructor. Thedefault constructor for the STLlist produces\nanemptylist,whichisexactlywhatwewant.\nNext, in Code Fragment 8.8, we present the implementations of the simple\nmemberfunctionssizeandempty. Recallthat,whendealingwithtemplatedclasses,\nitisnecessarytorepeatthefulltemplatespecificationswhendefiningmemberfunc-\ntions outside the class. Each of these functions simply invokes the corresponding\nfunction fortheSTLlist.\ntemplate <typename E, typename C> // number of elements\nint ListPriorityQueue<E,C>::size() const\nreturn L.size();\n{ }\ntemplate <typename E, typename C> // is the queue empty?\nbool ListPriorityQueue<E,C>::empty() const\nreturn L.empty();\n{ }\nCodeFragment8.8: Implementations ofthefunctions sizeandempty.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 334 \u2014 #356\ni i\n334 Chapter8. HeapsandPriorityQueues\nLet us now consider how to insert an element e into our priority queue. We\ndefine ptobeaniterator forthelist. Ourapproach istowalkthrough thelistuntil\nwefirstfindanelementwhosekeyvalueislargerthane\u2019s,andthenweinsertejust\npriorto p. Recallthat*paccessestheelementreferencedby p,and++padvances\np to the next element of the list. We stop the search either when we reach the\nend of the list or when we first encounter a larger element, that is, one satisfying\nisLess(e,*p). Onreachingsuchanentry,weinsertejustpriortoit,byinvokingthe\nSTLlistfunction insert. ThecodeisshowninCodeFragment8.9.\ntemplate <typename E, typename C> // insert element\nvoid ListPriorityQueue<E,C>::insert(const E& e)\n{\ntypename std::list<E>::iterator p;\np = L.begin();\nwhile (p != L.end() && !isLess(e, *p)) ++p; // find larger element\nL.insert(p, e); // insert e before p\n}\nCodeFragment8.9: Implementation ofthepriorityqueuefunction insert.\nConsider how the above function behaves when e has a key value larger than\nany inthe queue. Insuch acase, the while loop exits under the condition that pis\nequal to L.end(). Recall that L.end() refers to an imaginary element that lies just\nbeyond the end of the list. Thus, by inserting before this element, we effectively\nappendetothebackofthelist,asdesired.\nYoumightnoticetheuseofthekeyword\u201ctypename\u201dinthedeclaration ofthe\niterator p. This isdue toasubtle issue inC++involving dependent names, which\nariseswhenprocessing namebindingswithintemplatedobjectsinC++. Wedonot\ndelve into the intricacies of this issue. For now, it suffices to remember to simply\nCaution include the keyword typename when using a template parameter (in this case E)\ntodefineanother type.\nFinally, let us consider the operations min and removeMin. Since the list is\nsorted in ascending order by key values, in order to implement min, we simply\nreturnareferencetothefrontofthelist. ToimplementremoveMin,weremovethe\nfrontelementofthelist. Theimplementations aregiveninCodeFragment8.10.\ntemplate <typename E, typename C> // minimum element\nconst E& ListPriorityQueue<E,C>::min() const\nreturn L.front(); // minimum is at the front\n{ }\ntemplate <typename E, typename C> // remove minimum\nvoid ListPriorityQueue<E,C>::removeMin()\nL.pop front();\n{ }\nCode Fragment 8.10: Implementations of the priority queue functions min and\nremoveMin.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 335 \u2014 #357\ni i\n8.2. ImplementingaPriorityQueuewithaList 335\n8.2.2 Selection-Sort and Insertion-Sort\nRecallthePriorityQueueSortschemeintroduced inSection8.1.5. Wearegivenan\nunsortedlistLcontainingnelements,whichwesortusingapriorityqueuePintwo\nphases. In the first phase, we insert all the elements, and in the second phase, we\nrepeatedly removeelementsusingtheminandremoveMinoperations.\nSelection-Sort\nIf we implement the priority queue P with an unsorted list, then the first phase of\nPriorityQueueSort takes O(n) time, since we can insert each element in constant\ntime. Inthesecond phase, therunning timeofeachminandremoveMin operation\nis proportional to the number of elements currently in P. Thus, the bottleneck\ncomputation in this implementation is the repeated \u201cselection\u201d of the minimum\nelement from an unsorted list in the second phase. For this reason, this algorithm\nisbetterknownasselection-sort. (SeeFigure8.1.)\nListL PriorityQueueP\nInput (7,4,8,2,5,3,9) ()\nPhase1 (a) (4,8,2,5,3,9) (7)\n(b) (8,2,5,3,9) (7,4)\n. . .\n. . .\n. . .\n(g) () (7,4,8,2,5,3,9)\nPhase2 (a) (2) (7,4,8,5,3,9)\n(b) (2,3) (7,4,8,5,9)\n(c) (2,3,4) (7,8,5,9)\n(d) (2,3,4,5) (7,8,9)\n(e) (2,3,4,5,7) (8,9)\n(f) (2,3,4,5,7,8) (9)\n(g) (2,3,4,5,7,8,9) ()\nFigure8.1: Executionofselection-sort onlistL=(7,4,8,2,5,3,9).\nAs noted above, the bottleneck is the second phase, where we repeatedly re-\nmoveanelement with smallest key from thepriority queue P. Thesize ofPstarts\natnanddecreases to0witheachremoveMin. Thus,thefirstremoveMinoperation\ntakestimeO(n),thesecondonetakestimeO(n 1),andsoon. Therefore,thetotal\n\u2212\ntimeneeded forthesecondphaseis\nO(n+(n 1)+ +2+1)=O(\u2211n i).\n\u2212 \u00b7\u00b7\u00b7 i=1\nBy Proposition 4.3, we have \u2211n i = n(n+1)/2. Thus, phase two takes O(n2)\ni=1\ntime,asdoestheentireselection-sort algorithm.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 336 \u2014 #358\ni i\n336 Chapter8. HeapsandPriorityQueues\nInsertion-Sort\nIfweimplement the priority queue Pusing asorted list, then weimprove the run-\nningtimeofthesecondphasetoO(n),becauseeachoperationminandremoveMin\non P now takes O(1) time. Unfortunately, the first phase now becomes the bottle-\nneckfortherunningtime,since,intheworstcase,eachinsertoperation takestime\nproportional to the size of P. This sorting algorithm is therefore better known as\ninsertion-sort(seeFigure8.2),forthebottleneck inthissortingalgorithm involves\ntherepeated\u201cinsertion\u201dofanewelementattheappropriatepositioninasortedlist.\nListL PriorityQueueP\nInput (7,4,8,2,5,3,9) ()\nPhase1 (a) (4,8,2,5,3,9) (7)\n(b) (8,2,5,3,9) (4,7)\n(c) (2,5,3,9) (4,7,8)\n(d) (5,3,9) (2,4,7,8)\n(e) (3,9) (2,4,5,7,8)\n(f) (9) (2,3,4,5,7,8)\n(g) () (2,3,4,5,7,8,9)\nPhase2 (a) (2) (3,4,5,7,8,9)\n(b) (2,3) (4,5,7,8,9)\n. . .\n. . .\n. . .\n(g) (2,3,4,5,7,8,9) ()\nFigure 8.2: Execution of insertion-sort on list L = (7,4,8,2,5,3,9). In Phase 1,\nwe repeatedly remove the first element of L and insert it into P, by scanning the\nlist implementing P until we find the correct place for this element. In Phase 2,\nwerepeatedly perform removeMinoperations onP,eachofwhichreturns thefirst\nelementofthelistimplementing P,andweaddtheelementattheendofL.\nAnalyzing therunning timeofPhase1ofinsertion-sort, wenotethat\nO(1+2+...+(n 1)+n)=O(\u2211n i).\n\u2212 i=1\nAgain, by recalling Proposition 4.3, the first phase runs in O(n2) time; hence, so\ndoestheentirealgorithm.\nAlternately, we could change our definition of insertion-sort so that we insert\nelements starting from the end of the priority-queue sequence in the first phase,\nin which case performing insertion-sort on a list that is already sorted would run\nin O(n) time. Indeed, the running time of insertion-sort is O(n+I) in this case,\nwhereI isthenumberofinversionsintheinput list,thatis,thenumberofpairsof\nelementsthatstartoutintheinputlistinthewrongrelativeorder.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 337 \u2014 #359\ni i\n8.3. Heaps 337\n8.3 Heaps\nThetwoimplementations ofthePriorityQueueSort scheme presented intheprevi-\noussectionsuggestapossiblewayofimprovingtherunningtimeforpriority-queue\nsorting. One algorithm (selection-sort) achieves a fast running time for the first\nphase, but has a slow second phase, whereas the other algorithm (insertion-sort)\nhasaslowfirstphase, butachieves afastrunning timeforthesecond phase. Ifwe\ncould somehow balance the running times of the two phases, we might be able to\nsignificantlyspeeduptheoverallrunningtimeforsorting. Thisapproachis,infact,\nexactly whatwecanachieve using thepriority-queue implementation discussed in\nthissection.\nAn efficient realization of a priority queue uses a data structure called a heap.\nThis data structure allows us to perform both insertions and removals in logarith-\nmic time, which is a significant improvement over the list-based implementations\ndiscussedinSection8.2. Thefundamentalwaytheheapachievesthisimprovement\nis to abandon the idea of storing elements and keys in alist and take the approach\nofstoring elementsandkeysinabinarytreeinstead.\n8.3.1 The Heap Data Structure\nAheap (see Figure 8.3) isabinary tree T that stores acollection ofelements with\ntheir associated keys at its nodes and that satisfies two additional properties: a\nrelationalproperty,definedintermsofthewaykeysarestoredinT,andastructural\nproperty, defined in terms of the nodes of T itself. We assume that a total order\nrelationonthekeysisgiven,forexample,byacomparator.\nTherelational propertyofT,definedintermsofthewaykeysarestored,isthe\nfollowing:\nHeap-OrderProperty: Inaheap T,for everynode vother than the root, thekey\nassociatedwithvisgreaterthanorequaltothekeyassociatedwithv\u2019sparent.\nAsaconsequence oftheheap-order property, thekeysencountered onapathfrom\ntheroottoanexternalnodeofT areinnondecreasing order. Also,aminimumkey\nis always stored at the root of T. Thisis the most important key and is informally\nsaid to be \u201cat the top of the heap,\u201d hence, the name \u201cheap\u201d for the data structure.\nBy the way, the heap data structure defined here has nothing to do with the free-\nstore memory heap (Section 14.1.1) used in the run-time environment supporting\nprogramming languages likeC++.\nYou might wonder why heaps are defined with the smallest key at the top,\nrather than the largest. The distinction is arbitrary. (This is evidenced by the fact\nthat the STL priority queue does exactly the opposite.) Recall that a comparator\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 338 \u2014 #360\ni i\n338 Chapter8. HeapsandPriorityQueues\nFigure 8.3: Example of a heap storing 13 elements. Each element is a key-value\npair of the form (k,v). The heap is ordered based on the key value, k, of each\nelement.\nimplements the less-than operator between twokeys. Suppose that wehadinstead\ndefined our comparator toindicate theopposite ofthestandard total order relation\nbetweenkeys(sothat, forexample,isLess(x,y)wouldreturntrueifxweregreater\nthan y). Then the root of the resulting heap would store the largest key. This\nversatility comes essentially for free from our use of the comparator pattern. By\nCaution defining the minimum key in terms of the comparator, the \u201cminimum\u201d key with\na \u201creverse\u201d comparator is in fact the largest. Thus, without loss of generality, we\nassume that we are always interested in the minimum key, which is always at the\nrootoftheheap.\nFor the sake of efficiency, which becomes clear later, we want the heap T to\nhaveassmallaheightaspossible. Weenforcethisdesirebyinsistingthattheheap\nT satisfy an additional structural property, it must be complete. Before we define\nthis structural property, we need some definitions. We recall from Section 7.3.3\nthatleveliofabinarytreeT isthesetofnodesofT thathavedepthi. Givennodes\nvandwonthe samelevelofT,wesay that vistotheleftofwifvisencountered\nbefore w in an inorder traversal of T. That is, there is a node u of T such that vis\nintheleftsubtreeofuandwisintherightsubtreeofu. Forexample,inthebinary\ntree of Figure 8.3, the node storing entry (15,K) is to the left of the node storing\nentry (7,Q). In a standard drawing of a binary tree, the \u201cto the left of\u201d relation is\nvisualized bytherelativehorizontal placementofthenodes.\nCompleteBinaryTreeProperty: A heap T with height h is a complete binary\ntree,thatis,levels0,1,2,...,h 1ofT havethemaximumnumberofnodes\n\u2212\npossible (namely, level i has 2i nodes, for 0 i h 1) and the nodes at\n\u2264 \u2264 \u2212\nlevelhfillthislevelfromlefttoright.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 339 \u2014 #361\ni i\n8.3. Heaps 339\nThe Height of a Heap\nLet h denote the height of T. Another way of defining the last node of T is that\nit is the node on level h such that all the other nodes of level h are to the left of\nit. Insisting that T be complete also has an important consequence as shown in\nProposition 8.5.\nProposition 8.5: AheapT storingnentrieshasheight\nh= logn .\n\u230a \u230b\nJustification: FromthefactthatT iscomplete, weknowthatthereare2i nodes\nin level, i for 0 i h 1, and level h has at least 1 node. Thus, the number of\n\u2264 \u2264 \u2212\nnodesofT isatleast\n(1+2+4+ +2h\u22121)+1 = (2h 1)+1\n\u00b7\u00b7\u00b7 \u2212\n= 2h.\nLevelhhasatmost2h nodes,andthusthenumberofnodesofT isatmost\n(1+2+4+ +2h\u22121)+2h = 2h+1 1.\n\u00b7\u00b7\u00b7 \u2212\nSincethenumberofnodesisequaltothenumbernofentries,weobtain\n2h n\n\u2264\nand\nn 2h+1 1.\n\u2264 \u2212\nThus,bytakinglogarithmsofbothsidesofthesetwoinequalities, weseethat\nh logn\n\u2264\nand\nlog(n+1) 1 h.\n\u2212 \u2264\nSincehisaninteger, thetwoinequalities aboveimplythat\nh= logn .\n\u230a \u230b\nProposition8.5hasanimportantconsequence. Itimpliesthatifwecanperform\nupdateoperationsonaheapintimeproportionaltoitsheight,thenthoseoperations\nwill run in logarithmic time. Therefore, let us turn to the problem of how to effi-\ncientlyperform variouspriorityqueuefunctions usingaheap.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 340 \u2014 #362\ni i\n340 Chapter8. HeapsandPriorityQueues\n8.3.2 Complete Binary Trees and Their Representation\nLetusdiscuss moreaboutcompletebinarytreesandhowtheyarerepresented.\nThe Complete Binary Tree ADT\nAsanabstract datatype, acomplete binary tree T supports allthefunctions ofthe\nbinarytreeADT(Section7.3.1),plusthefollowingtwofunctions:\nadd(e): Add to T and return a new external node v storing ele-\nment e, such that the resulting tree is a complete binary\ntreewithlastnodev.\nremove(): RemovethelastnodeofT andreturnitselement.\nByusingonlytheseupdateoperations, theresultingtreeisguaranteedtobeacom-\nplete binary. Asshown in Figure 8.4, there are essentially two cases for the effect\nofanadd(andremoveissimilar).\nIfthebottomlevelofT isnotfull,thenaddinsertsanewnodeonthebottom\n\u2022\nlevelofT,immediatelyaftertherightmostnodeofthislevel(thatis,thelast\nnode);hence, T\u2019sheightremainsthesame.\nIfthebottom levelisfull,thenaddinsertsanewnodeastheleftchildofthe\n\u2022\nleftmostnodeofthebottomlevelofT;hence, T\u2019sheightincreases byone.\nw(cid:13)\n(a) (b)\nw(cid:13)\n(c) (d)\nFigure 8.4: Examples of operations add and remove on a complete binary tree,\nwhere w denotes the node inserted by add or deleted by remove. The trees shown\nin(b)and(d)aretheresultsofperformingaddoperationsonthetreesin(a)and(c),\nrespectively. Likewise, the trees shownin (a)and (c) arethe results ofperforming\nremoveoperations onthetreesin(b)and(d),respectively.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 341 \u2014 #363\ni i\n8.3. Heaps 341\nA Vector Representation of a Complete Binary Tree\nThevector-based binarytreerepresentation (recallSection7.3.5)isespeciallysuit-\nableforacomplete binary treeT. Werecall thatinthisimplementation, thenodes\nof T are stored in a vector A such that node v in T is the element of A with index\nequaltothelevelnumber f(v)definedasfollows:\nIfvistherootofT,then f(v)=1\n\u2022\nIfvistheleftchildofnodeu,then f(v)=2f(u)\n\u2022\nIfvistherightchildofnodeu,then f(v)=2f(u)+1\n\u2022\nWiththisimplementation,thenodesofT havecontiguousindicesintherange[1,n]\nand the last node of T is always at index n, where n is the number of nodes of T.\nFigure8.5showstwoexamplesillustrating thisproperty ofthelastnode.\nw(cid:13)\nw(cid:13)\n(a) (b)\n01(cid:13)(cid:13) 2(cid:13) 3(cid:13) 4(cid:13) 5(cid:13) 6(cid:13) 10(cid:13)(cid:13) 2(cid:13) 3(cid:13) 4(cid:13) 5(cid:13) 6(cid:13) 7(cid:13) 8(cid:13)\nw(cid:13) w(cid:13)\n(c) (d)\nFigure 8.5: Two examples showing that the last node w of a heap with n nodes\nhas level number n: (a) heap T with more than one node on the bottom level;\n1\n(b) heap T with one node on the bottom level; (c) vector-based representation\n2\nofT ;(d)vector-based representation ofT .\n1 2\nThesimplifications thatcomefromrepresenting acomplete binarytreeT with\na vector aid in the implementation of functions add and remove. Assuming that\nno array expansion is necessary, functions add and remove can be performed in\nO(1)timebecause they simply involve adding or removing the lastelement ofthe\nvector. Moreover, the vector associated with T has n+1elements (the element at\nindex 0 is a placeholder). If we use an extendable array that grows and shrinks\nfortheimplementation ofthevector(forexample,theSTLvectorclass),thespace\nused by the vector-based representation of a complete binary tree with n nodes is\nO(n)andoperations addandremovetakeO(1)amortizedtime.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 342 \u2014 #364\ni i\n342 Chapter8. HeapsandPriorityQueues\nA C++ Implementation of a Complete Binary Tree\nWe present the complete binary tree ADT as an informal interface, called Com-\npleteTree,inCodeFragment8.11. Aswithourotherinformalinterfaces,thisisnot\nacompleteC++class. Itjustgivesthepublicportion oftheclass.\nTheinterfacedefinesanestedclass,calledPosition,whichrepresentsanodeof\nthetree. Weprovidethenecessaryfunctionstoaccesstherootandlastpositionsand\ntonavigate through thetree. Themodifierfunctions addandremoveareprovided,\nalongwithafunction swap,whichswapsthecontents oftwogivennodes.\ntemplate <typename E>\nclass CompleteTree // left-complete tree interface\n{\npublic: // publicly accessible types\nclass Position; // node position type\nint size() const; // number of elements\nPosition left(const Position& p); // get left child\nPosition right(const Position& p); // get right child\nPosition parent(const Position& p); // get parent\nbool hasLeft(const Position& p) const; // does node have left child?\nbool hasRight(const Position& p) const; // does node have right child?\nbool isRoot(const Position& p) const; // is this the root?\nPosition root(); // get root position\nPosition last(); // get last node\nvoid addLast(const E& e); // add a new last node\nvoid removeLast(); // remove the last node\nvoid swap(const Position& p, const Position& q); // swap node contents\n;\n}\nCodeFragment8.11: Interface CompleteBinaryTreeforacompletebinarytree.\nIn order to implement this interface, we store the elements in an STL vector,\ncalledV. Weimplementatreepositionasaniteratortothisvector. Toconvertfrom\nthe index representation of a node to this positional representation, we provide a\nfunction pos. The reverse conversion is provided by function idx. This portion of\ntheclassdefinition isgiveninCodeFragment8.12.\nprivate: // member data\nstd::vector<E> V; // tree contents\npublic: // publicly accessible types\ntypedef typename std::vector<E>::iterator Position; // a position in the tree\nprotected: // protected utility functions\nPosition pos(int i) // map an index to a position\nreturn V.begin() + i;\n{ }\nint idx(const Position& p) const // map a position to an index\nreturn p V.begin();\n{ \u2212 }\nCodeFragment8.12: Memberdataandprivateutilitiesforacompletetreeclass.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 343 \u2014 #365\ni i\n8.3. Heaps 343\nGiven the index of a node i, the function pos maps it to a position by adding\ni to V.begin(). Here we are exploiting the fact that the STL vector supports a\nrandom-access iterator (recall Section 6.2.5). In particular, given an integer i, the\nexpression V.begin()+i yields the position of the ith element of the vector, and,\ngivenaposition p,theexpression p V.begin()yieldstheindexofposition p.\n\u2212\nWepresentafullimplementationofavector-basedcompletetreeADTinCode\nFragment 8.13. Because the class consists of a large number of small one-line\nfunctions, wehavechosen toviolate ournormalcoding conventions byplacing all\nthefunction definitionsinsidetheclassdefinition.\ntemplate <typename E>\nclass VectorCompleteTree\n{\n//... insert private member data and protected utilities here\npublic:\nVectorCompleteTree() : V(1) // constructor\n{}\nint size() const return V.size() 1;\n{ \u2212 }\nPosition left(const Position& p) return pos(2*idx(p));\n{ }\nPosition right(const Position& p) return pos(2*idx(p) + 1);\n{ }\nPosition parent(const Position& p) return pos(idx(p)/2);\n{ }\nbool hasLeft(const Position& p) const return 2*idx(p) <= size();\n{ }\nbool hasRight(const Position& p) const return 2*idx(p) + 1 <= size();\n{ }\nbool isRoot(const Position& p) const return idx(p) == 1;\n{ }\nPosition root() return pos(1);\n{ }\nPosition last() return pos(size());\n{ }\nvoid addLast(const E& e) V.push back(e);\n{ }\nvoid removeLast() V.pop back();\n{ }\nvoid swap(const Position& p, const Position& q)\nE e = *q; *q = *p; *p = e;\n{ }\n;\n}\nCodeFragment8.13: Avector-based implementation ofthecompletetreeADT.\nRecall from Section 7.3.5 that the root node is at index 1 of the vector. Since\nSTLvectorsareindexedstartingat0,ourconstructorcreatestheinitialvectorwith\none element. This element at index 0is never used. Asa consequence, the size of\nthepriorityqueueisonelessthanthesizeofthevector.\nRecallfromSection7.3.5that,givenanodeatindexi,itsleftandrightchildren\narelocatedatindices2iand2i+1,respectively. Itsparentislocatedatindex i/2 .\n\u230a \u230b\nGiven a position p, the functions left, right, and parent first convert p to an index\nusing the utility idx, which is followed by the appropriate arithmetic operation on\nthisindex,andfinallytheyconverttheindexbacktoapositionusingtheutilitypos.\nWe determine whether a node has a child by evaluating the index of this child\nand testing whether the node at that index exists in the vector. Operations add\nand remove are implemented by adding or removing the last entry of the vector,\nrespectively.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 344 \u2014 #366\ni i\n344 Chapter8. HeapsandPriorityQueues\n8.3.3 Implementing a Priority Queue with a Heap\nWenow discuss how to implement a priority queue using a heap. Ourheap-based\nrepresentation forapriorityqueuePconsists ofthefollowing(seeFigure8.6):\nheap: AcompletebinarytreeT whosenodesstoretheelementsofthequeue\n\u2022\nandwhosekeyssatisfytheheap-orderproperty. WeassumethebinarytreeT\nis implemented using avector, as described in Section 8.3.2. Foreach node\nvofT,wedenotetheassociated keybyk(v).\ncomp: Acomparator thatdefinesthetotalorderrelationamongthekeys.\n\u2022\nFigure8.6: Illustration oftheheap-based implementation ofapriorityqueue.\nWith this data structure, functions size and empty take O(1) time, as usual. In\naddition, function mincan also be easily performed inO(1) timeby accessing the\nentrystoredattherootoftheheap(whichisatindex1inthevector).\nInsertion\nLet us consider how to perform insert on a priority queue implemented with a\nheapT. TostoreanewelementeinT,weaddanewnodeztoT withoperationadd,\nsothatthisnewnodebecomesthelastnodeofT,andthenstoreeinthisnode.\nAfterthisaction,thetreeT iscomplete,butitmayviolatetheheap-orderprop-\nerty. Hence, unless node z is the root of T (that is, the priority queue was empty\nbefore the insertion), we compare key k(z) with the key k(u) stored at the parent\nu of z. If k(z) k(u), the heap-order property is satisfied and the algorithm ter-\n\u2265\nminates. If instead k(z)<k(u), then we need to restore the heap-order property,\nwhichcan belocally achieved byswapping theentries stored atzand u. (SeeFig-\nures 8.7(c) and (d).) This swap causes the new entry (k,e) to move up one level.\nAgain,theheap-order property maybeviolated, andwecontinue swapping, going\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 345 \u2014 #367\ni i\n8.3. Heaps 345\n(a) (b)\n(c) (d)\n(e) (f)\n(g) (h)\nFigure8.7: Insertionofanewentrywithkey2intotheheapofFigure8.6: (a)initial\nheap; (b) after performing operation add; (c) and (d) swap to locally restore the\npartialorderproperty; (e)and(f)anotherswap;(g)and(h)finalswap.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 346 \u2014 #368\ni i\n346 Chapter8. HeapsandPriorityQueues\nup in T until no violation of the heap-order property occurs. (See Figures8.7(e)\nand(h).)\nThe upward movement of the newly inserted entry by means of swaps is con-\nventionally called up-heap bubbling. A swap either resolves the violation of the\nheap-orderpropertyorpropagatesitonelevelupintheheap. Intheworstcase,up-\nheap bubbling causes the new entry to move all the way up to the root of heap T.\n(See Figure 8.7.) Thus, in the worst case, the number of swaps performed in the\nexecution of function insert is equal to the height of T, that is, it is logn by\n\u230a \u230b\nProposition 8.5.\nRemoval\nLetusnow turntofunction removeMinofthe priority queue ADT. Thealgorithm\nforperformingfunction removeMinusingheapT isillustrated inFigure8.8.\nWeknowthatanelementwiththesmallestkeyisstoredattherootrofT (even\nif there is more than one entry with the smallest key). However, unless r is the\nonlynode ofT,wecannot simplydelete noder,because thisactionwoulddisrupt\nthe binary tree structure. Instead, we access the last node w of T, copy its entry\nto the root r, and then delete the last node by performing operation remove of the\ncompletebinarytreeADT.(SeeFigure8.8(a)and(b).)\nDown-Heap Bubbling after a Removal\nWearenotnecessarily done, however, for,eventhough T isnowcomplete, T may\nnow violate the heap-order property. If T has only one node (the root), then the\nheap-order property is trivially satisfied and the algorithm terminates. Otherwise,\nwedistinguish twocases,whererdenotestherootofT:\nIfrhasnorightchild,letsbetheleftchildofr\n\u2022\nOtherwise(rhasbothchildren), letsbeachildofr withthesmallerkey\n\u2022\nIf k(r) k(s), the heap-order property is satisfied and the algorithm terminates.\n\u2264\nIf instead k(r)>k(s), then we need to restore the heap-order property, which can\nbe locally achieved by swapping the entries stored at r and s. (See Figure 8.8(c)\nand (d).) (Note that we shouldn\u2019t swap r with s\u2019s sibling.) The swap we perform\nrestores the heap-order property for node r and itschildren, but itmayviolate this\nproperty ats;hence, wemayhavetocontinue swapping downT untilnoviolation\noftheheap-order propertyoccurs. (SeeFigure8.8(e)and(h).)\nThisdownwardswappingprocessiscalleddown-heapbubbling. Aswapeither\nresolvestheviolationoftheheap-orderproperty orpropagates itoneleveldownin\nthe heap. In the worst case, an entry moves all the way down to the bottom level.\n(SeeFigure8.8.) Thus,thenumberofswapsperformedintheexecutionoffunction\nremoveMin is, intheworstcase, equal tothe height ofheap T,that is, itis logn\n\u230a \u230b\nbyProposition 8.5\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 347 \u2014 #369\ni i\n8.3. Heaps 347\n(a) (b)\n(c) (d)\n(e) (f)\n(g) (h)\nFigure8.8: Removing the element with the smallest key from a heap: (a) and (b)\ndeletion of the last node, whose element is moved to the root; (c) and (d) swap to\nlocally restore the heap-order property; (e) and (f) another swap; (g) and (h) final\nswap.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 348 \u2014 #370\ni i\n348 Chapter8. HeapsandPriorityQueues\nAnalysis\nTable8.2showstherunningtimeofthepriorityqueueADTfunctions fortheheap\nimplementation of a priority queue, assuming that two keys can be compared in\nO(1)timeand thatthe heap T isimplemented witheither avector orlinked struc-\nture.\nOperation Time\nsize,empty O(1)\nmin O(1)\ninsert O(logn)\nremoveMin O(logn)\nTable 8.2: Performance of a priority queue realized by means of a heap, which\nis in turn implemented with a vector or linked structure. We denote with n the\nnumber of entries in the priority queue at the time a method is executed. The\nspace requirement is O(n). The running time of operations insert and removeMin\nis worst case for the array-list implementation of the heap and amortized for the\nlinkedrepresentation.\nIn short, each of the priority queue ADT functions can be performed in O(1)\ntimeorinO(logn)time,wherenisthenumberofelementsatthetimethefunction\nisexecuted. Thisanalysis isbasedonthefollowing:\nTheheapT hasnnodes,eachstoring areference toanentry\n\u2022\nOperations add and remove on T take either O(1) amortized time (vector\n\u2022\nrepresentation) orO(logn)worst-case time\nIn the worst case, up-heap and down-heap bubbling perform a number of\n\u2022\nswapsequaltotheheightofT\nTheheightofheapT isO(logn),sinceT iscomplete(Proposition 8.5)\n\u2022\nThus,ifheapT isimplementedwiththelinkedstructureforbinarytrees,thespace\nneeded is O(n). If we use a vector-based implementation for T instead, then the\nspaceisproportional tothesizeN ofthearrayusedforthevectorrepresenting T.\nWe conclude that the heap data structure is a very efficient realization of the\npriorityqueueADT,independentofwhethertheheapisimplementedwithalinked\nstructure or a vector. The heap-based implementation achieves fast running times\nfor both insertion and removal, unlike the list-based priority queue implementa-\ntions. Indeed,animportantconsequence oftheefficiencyoftheheap-based imple-\nmentation is that it can speed up priority-queue sorting to be much faster than the\nlist-based insertion-sort andselection-sort algorithms.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 349 \u2014 #371\ni i\n8.3. Heaps 349\n8.3.4 C++ Implementation\nIn this section, we present a heap-based priority queue implementation. The heap\nis implemented using the vector-based complete tree implementation, which we\npresented inSection8.3.2.\nIn Code Fragment 8.7, we present the class definition. The public part of the\nclass isessentially thesame astheinterface, but, inorder tokeep the code simple,\nwehaveignorederrorchecking. Theclass\u2019sdatamembersconsistsofthecomplete\ntree, named T, and an instance of the comparator object, named isLess. We have\nalsoprovided atypedefinitionforanodepositioninthetree,calledPosition.\ntemplate <typename E, typename C>\nclass HeapPriorityQueue\n{\npublic:\nint size() const; // number of elements\nbool empty() const; // is the queue empty?\nvoid insert(const E& e); // insert element\nconst E& min(); // minimum element\nvoid removeMin(); // remove minimum\nprivate:\nVectorCompleteTree<E> T; // priority queue contents\nC isLess; // less-than comparator\n// shortcut for tree position\ntypedef typename VectorCompleteTree<E>::Position Position;\n;\n}\nCodeFragment8.14: Aheap-based implementation ofapriorityqueue.\nIn Code Fragment 8.15, we present implementations of the simple member\nfunctions size, empty, and min. The function min returns a reference to the root\u2019s\nelementthroughtheuseofthe\u201c*\u201doperator,whichisprovidedbythePositionclass\nofVectorCompleteTree.\ntemplate <typename E, typename C> // number of elements\nint HeapPriorityQueue<E,C>::size() const\nreturn T.size();\n{ }\ntemplate <typename E, typename C> // is the queue empty?\nbool HeapPriorityQueue<E,C>::empty() const\nreturn size() == 0;\n{ }\ntemplate <typename E, typename C> // minimum element\nconst E& HeapPriorityQueue<E,C>::min()\nreturn *(T.root()); // return reference to root element\n{ }\nCodeFragment8.15: Thememberfunctions size,empty,andmin.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 350 \u2014 #372\ni i\n350 Chapter8. HeapsandPriorityQueues\nNext, in Code Fragment 8.16, we present an implementation of the insert op-\neration. Asoutlined intheprevious section, thisworksbyadding thenewelement\ntothelastposition ofthetreeandthenitperformsup-heap bubbling byrepeatedly\nswappingthiselementwithitsparentuntilitsparenthasasmallerkeyvalue.\ntemplate <typename E, typename C> // insert element\nvoid HeapPriorityQueue<E,C>::insert(const E& e)\n{\nT.addLast(e); // add e to heap\nPosition v = T.last(); // e\u2019s position\nwhile (!T.isRoot(v)) // up-heap bubbling\n{\nPosition u = T.parent(v);\nif (!isLess(*v, *u)) break; // if v in order, we\u2019re done\nT.swap(v, u); // ...else swap with parent\nv = u;\n}\n}\nCodeFragment8.16: Animplementation ofthefunction insert.\nFinally,letusconsidertheremoveMinoperation. Ifthetreehasonlyonenode,\nthen we simply remove it. Otherwise, we swap the root\u2019s element with the last\nelementofthetreeandremovethelastelement. Wethenapplydown-heapbubbling\ntotheroot. Lettingudenotethecurrentnode,thisinvolvesdeterminingu\u2019ssmaller\nchild, which is stored in v. If the child\u2019s key is smaller than u\u2019s, we swap u\u2019s\ncontents withthischild\u2019s. Thecodeispresented inCodeFragment8.17.\ntemplate <typename E, typename C> // remove minimum\nvoid HeapPriorityQueue<E,C>::removeMin()\n{\nif (size() == 1) // only one node?\nT.removeLast(); // ...remove it\nelse\n{\nPosition u = T.root(); // root position\nT.swap(u, T.last()); // swap last with root\nT.removeLast(); // ...and remove last\nwhile (T.hasLeft(u)) // down-heap bubbling\n{\nPosition v = T.left(u);\nif (T.hasRight(u) && isLess(*(T.right(u)), *v))\nv = T.right(u); // v is u\u2019s smaller child\nif (isLess(*v, *u)) // is u out of order?\n{\nT.swap(u, v); // ...then swap\nu = v;\n}\nelse break; // else we\u2019re done\n}\n}\n}\nCodeFragment8.17: Aheap-based implementation ofapriorityqueue.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 351 \u2014 #373\ni i\n8.3. Heaps 351\n8.3.5 Heap-Sort\nAs we have previously observed, realizing a priority queue with a heap has the\nadvantagethatallthefunctionsinthepriorityqueueADTruninlogarithmictimeor\nbetter. Hence, this realization issuitable for applications where fast running times\naresought forallthepriority queue functions. Therefore, letusagainconsider the\nPriorityQueueSort sorting schemefromSection8.1.5, whichusesapriority queue\nPtosortalistL.\nDuring Phase 1, the i-th insert operation (1 i n) takes O(1+logi) time,\n\u2264 \u2264\nsince the heap has i entries after the operation is performed. Likewise, during\nPhase2,the j-thremoveMinoperation(1 j n)runsintimeO(1+log(n j+1),\n\u2264 \u2264 \u2212\nsince the heap has n j+1 entries at the time the operation is performed. Thus,\n\u2212\neachphasetakesO(nlogn)time,sotheentirepriority-queuesortingalgorithmruns\ninO(nlogn)timewhenweuseaheaptoimplementthepriorityqueue. Thissorting\nalgorithm is better known as heap-sort, and its performance is summarized in the\nfollowingproposition.\nProposition 8.6: Theheap-sortalgorithmsortsalistLofnelementsinO(nlogn)\ntime,assumingtwoelementsofLcanbecomparedinO(1)time.\nLetusstressthattheO(nlogn)runningtimeofheap-sortisconsiderably better\nthantheO(n2)runningtimeofselection-sort andinsertion-sort (Section8.2.2)and\nisessentially thebestpossible foranysortingalgorithm.\nImplementing Heap-Sort In-Place\nIfthelistLtobesortedisimplementedbymeansofanarray,wecanspeedupheap-\nsortandreduceitsspacerequirementbyaconstantfactorusingaportionofthelist\nL itself to store the heap, thus avoiding the use of an external heap data structure.\nThisperformance isaccomplished bymodifying thealgorithm asfollows:\n1. Weuseareverse comparator, whichcorresponds toaheapwherethelargest\nelement isat the top. Atany timeduring the execution ofthe algorithm, we\nusetheleftportionofL,uptoacertainranki 1,tostoretheelementsinthe\n\u2212\nheap, andtherightportion ofL,from rankiton 1tostore theelements in\n\u2212\nthelist. Thus,thefirstielementsofL(atranks0,...,i 1)providethevector\n\u2212\nrepresentation oftheheap(withmodifiedlevelnumbers starting at0instead\nof1),thatis,theelementatrankkisgreaterthanorequaltoits\u201cchildren\u201dat\nranks2k+1and2k+2.\n2. Inthefirstphaseofthealgorithm,westartwithanemptyheapandmovethe\nboundary betweentheheap andthelistfrom lefttoright, onestep atatime.\nInstepi(i=1,...,n),weexpandtheheapbyaddingtheelementatranki 1\n\u2212\nandperform up-heapbubbling.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 352 \u2014 #374\ni i\n352 Chapter8. HeapsandPriorityQueues\n3. In the second phase of the algorithm, we start with an empty list and move\nthe boundary between the heap and the list from right to left, one step at a\ntime. Atstep i(i=1,...,n), weremove amaximum element from theheap\nandstoreitatrankn i.\n\u2212\nTheabovevariationofheap-sortissaidtobein-place,sinceweuseonlyacon-\nstant amount ofspace inaddition tothe listitself. Instead oftransferring elements\nout of the list and then back in, we simply rearrange them. We illustrate in-place\nheap-sort in Figure 8.9. In general, wesay that asorting algorithm is in-place ifit\nuses only a constant amount of memory in addition to the memory needed for the\nobjects being sorted themselves. A sorting algorithm is considered space-efficient\nifitcanbeimplementedin-place.\n3 4\n(a) 3 7 2 1 4 (f) 4 3 2 1 7\n3 2\n1\n7 3\n(b) 7 3 2 1 4 (g) 3 1 2 4 7\n3 1 2\n7 2\n(c) 7 3 2 1 4 (h) 2 1 3 4 7\n3 2 1\n7\n(d) 7 3 2 1 4 (i) 1 2 3 4 7 1\n3 2\n1\n7\n(e) 7 4 2 1 3 (j) 1 2 3 4 7\n4 2\n1 3\nFigure8.9: In-place heap-sort. Parts (a) through (e) show the addition of elements\ntotheheap; (f)through (j)show theremoval ofsuccessive elements. Theportions\nofthearraythatareusedfortheheapstructure areshowninblue.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 353 \u2014 #375\ni i\n8.3. Heaps 353\n8.3.6 Bottom-Up Heap Construction \u22c6\nThe analysis of the heap-sort algorithm shows that we can construct a heap stor-\ning nelements in O(nlogn) time, by means of nsuccessive insert operations, and\nthen use that heap toextract the elements inorder. However, ifall the elements to\nbe stored in the heap are given in advance, there is an alternative bottom-up con-\nstruction function thatrunsinO(n)time. Wedescribe thisfunction inthissection,\nobserving thatitcanbeincluded asoneoftheconstructors inaHeapclassinstead\nof filling a heap using a series of n insert operations. For simplicity, we describe\nthisbottom-upheapconstructionassumingthenumbernofkeysisanintegerofthe\ntype n=2h 1. That is, the heap is a complete binary tree with every level being\n\u2212\nfull,sotheheaphasheighth=log(n+1). Viewednonrecursively, bottom-upheap\nconstruction consists ofthefollowingh=log(n+1)steps:\n1. Inthefirststep(seeFigure8.10(a)),weconstruct(n+1)/2elementaryheaps\nstoring oneentryeach.\n2. In the second step (see Figure 8.10(b)\u2013(c)), we form (n+1)/4 heaps, each\nstoring three entries, by joining pairs ofelementary heaps andadding anew\nentry. Thenew entry isplaced at theroot and may have tobe swapped with\ntheentrystoredatachildtopreservetheheap-order property.\n3. In the third step (see Figure 8.10(d)\u2013(e)), we form (n+1)/8 heaps, each\nstoring 7 entries, by joining pairs of 3-entry heaps (constructed in the pre-\nvious step) and adding a new entry. The new entry is placed initially at the\nroot,butmayhavetomovedownwithadown-heapbubblingtopreservethe\nheap-order property.\n.\n.\n.\ni. Inthegenericithstep,2 i h,weform(n+1)/2iheaps,eachstoring2i 1\n\u2264 \u2264 \u2212\nentries,byjoiningpairsofheapsstoring(2i\u22121 1)entries(constructedinthe\n\u2212\nprevious step) and adding a new entry. The new entry is placed initially at\ntheroot,butmayhavetomovedownwithadown-heapbubblingtopreserve\ntheheap-order property.\n.\n.\n.\nh+1. In the last step (see Figure 8.10(f)\u2013(g)), we form the final heap, storing all\nthe n entries, by joining two heaps storing (n 1)/2 entries (constructed in\n\u2212\nthepreviousstep)andaddinganewentry. Thenewentryisplacedinitiallyat\ntheroot,butmayhavetomovedownwithadown-heapbubblingtopreserve\ntheheap-order property.\nWeillustrate bottom-upheapconstruction inFigure8.10forh=3.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 354 \u2014 #376\ni i\n354 Chapter8. HeapsandPriorityQueues\n(a) (b)\n(c) (d)\n(e) (f)\n(g)\nFigure 8.10: Bottom-up construction of a heap with 15 entries: (a) we begin by\nconstructing one-entry heaps on the bottom level; (b) and (c) we combine these\nheaps into three-entry heaps; (d) and (e) seven-entry heaps; (f) and (g) we create\nthe final heap. The paths of the down-heap bubblings are highlighted in blue. For\nsimplicity, weonlyshowthekeywithineachnodeinsteadoftheentireentry.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 355 \u2014 #377\ni i\n8.3. Heaps 355\nRecursive Bottom-Up Heap Construction\nWe can also describe bottom-up heap construction as a recursive algorithm, as\nshown in Code Fragment 8.18, which we call by passing a list storing the keys\nforwhichwewishtobuildaheap.\nAlgorithmBottomUpHeap(L):\nInput: AnSTLlistLstoringn=2h+1 1entries\n\u2212\nOutput: AheapT storingtheentriesofL.\nifL.empty()then\nreturnanemptyheap\ne L.front()\n\u2190\nL.pop front()\nSplitLintotwolists,L andL ,eachofsize(n 1)/2\n1 2\n\u2212\nT BottomUpHeap(L )\n1 1\n\u2190\nT BottomUpHeap(L )\n2 2\n\u2190\nCreatebinarytreeT withrootrstoringe,leftsubtreeT ,andrightsubtree T\n1 2\nPerformadown-heap bubbling fromtherootrofT,ifnecessary\nreturnT\nCodeFragment8.18: Recursivebottom-up heapconstruction.\nAlthough the algorithm has been expressed in terms of an STL list, the con-\nstruction couldhavebeenperformedequallywellwithavector. Insuchacase,the\nsplittingofthevectorisperformedconceptually, bydefiningtworangesofindices,\nonerepresenting thefronthalfL andtheotherrepresenting thebackhalfL .\n1 2\nAtfirstglance, itmayseem that there isnosubstantial difference between this\nalgorithm and the incremental heap construction used in the heap-sort algorithm\nof Section 8.3.5. One works by down-heap bubbling and the other uses up-heap\nbubbling. Itissomewhatsurprising,therefore,thatthebottom-upheapconstruction\nisactuallyasymptoticallyfasterthanincrementallyinsertingnkeysintoaninitially\nemptyheap. Thefollowingproposition showsthis.\nProposition 8.7: Bottom-up construction ofaheapwith n entriestakes O(n)\ntime,assumingtwokeyscanbecomparedinO(1)time.\nJustification: We analyze bottom-up heap construction using a \u201cvisual\u201d ap-\nproach, whichisillustrated inFigure8.11.\nLetT bethefinalheap, letvbeanodeofT,andletT(v)denotethesubtreeof\nT rootedatv. Intheworstcase,thetimeforformingT(v)fromthetworecursively\nformed subtrees rooted at v\u2019s children is proportional to the height of T(v). The\nworstcaseoccurs whendown-heap bubbling from vtraverses apath fromvallthe\nwaytoabottommostnodeofT(v).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 356 \u2014 #378\ni i\n356 Chapter8. HeapsandPriorityQueues\nNow consider the path p(v) of T from node v to its inorder successor external\nnode,thatis,thepaththatstartsatv,goestotherightchildofv,andthengoesdown\nleftwarduntilitreaches anexternalnode. Wesaythatpath p(v)isassociated with\nnodev. Notethat p(v)isnotnecessarily thepathfollowedbydown-heap bubbling\nwhen forming T(v). Clearly, the size (number of nodes) of p(v) is equal to the\nheightofT(v)plusone. Hence,formingT(v)takestimeproportional tothesizeof\np(v),intheworstcase. Thus,thetotalrunningtimeofbottom-upheapconstruction\nisproportional tothesumofthesizesofthepathsassociated withthenodesofT.\nObservethateachnodevofT belongstoatmosttwosuchpaths: thepath p(v)\nassociated with v itself and possibly also the path p(u) associated with the closest\nancestor uofvpreceding vinaninorder traversal. (SeeFigure8.11.) Inparticular,\nthe root r of T and thenodes on the leftmost root-to-leaf path each belong only to\none path, the one associated with the node itself. Therefore, the sum of the sizes\nofthepathsassociated withtheinternalnodesofT isatmost2n 1. Weconclude\n\u2212\nthatthebottom-upconstruction ofheapT takesO(n)time.\nFigure8.11: Visual justification ofthe linear running time of bottom-up heap con-\nstruction, wherethepathsassociatedwiththeinternalnodeshavebeenhighlighted\nwith alternating colors. For example, the path associated with the root consists of\nthenodesstoringkeys4,6,7,and11. Also,thepathassociatedwiththerightchild\noftherootconsists oftheinternal nodesstoringkeys6,20,and23.\nTo summarize, Proposition 8.7 states that the running time for the first phase\nof heap-sort can be reduced to be O(n). Unfortunately, the running time of the\nsecond phase of heap-sort cannot be made asymptotically better than O(nlogn)\n(thatis,itwillalwaysbe\u2126(nlogn)intheworstcase). Wedonotjustifythislower\nbound until Chapter 11, however. Instead, we conclude this chapter by discussing\nadesignpatternthatallowsustoextendthepriorityqueueADTtohaveadditional\nfunctionality.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 357 \u2014 #379\ni i\n8.4. AdaptablePriorityQueues 357\n8.4 Adaptable Priority Queues\nThe functions of the priority queue ADT given in Section 8.1.3 are sufficient for\nmostbasicapplications ofpriority queuessuchassorting. However,therearesitu-\nationswhereadditional functions wouldbeusefulasshowninthescenarios below\nthatrefertothestandbyairlinepassenger application.\nAstandbypassengerwithapessimisticattitudemaybecometiredofwaiting\n\u2022\nand decide to leave ahead of the boarding time, requesting to be removed\nfrom the waiting list. Thus, we would like to remove the entry associated\nwith this passenger from the priority queue. Operation removeMin is not\nsuitable for this purpose, since it only removes the entry with the lowest\npriority. Instead, wewantanewoperation thatremovesanarbitrary entry.\nAnotherstandby passengerfindshergoldfrequent-flyer cardandshowsitto\n\u2022\ntheagent. Thus,herpriority hastobemodifiedaccordingly. Toachieve this\nchange of priority, we would like to have a new operation that changes the\ninformation associated with a given entry. This might affect the entry\u2019s key\nvalue (such as frequent-flyer status) or not (such as correcting a misspelled\nname).\nFunctions of the Adaptable Priority Queue ADT\nThe above scenarios motivate the definition of a new ADT for priority queues,\nwhich includes functions for modifying or removing specified entries. In order to\ndothis, weneed somewayofindicating whichentryofthequeueistobeaffected\nby the operation. Note that we cannot use the entry\u2019s key value, because keys are\nnot distinct. Instead, we assume that the priority queue operation insert(e) isaug-\nmented so that, after inserting the element e, it returns a reference to the newly\ncreated entry, called aposition (recall Section6.2.1). Thisposition ispermanently\nattached to the entry, so that, even if the location of the entry changes within the\npriorityqueue\u2019sinternaldatastructure (asisdonewhenperformingbubblingoper-\nations in a heap), the position remains fixed to this entry. Thus, positions provide\nuswithameanstouniquely specify theentrytowhicheachoperation isapplied.\nWeformallydefineanadaptablepriorityqueuePtobeapriorityqueuethat,in\nadditiontothestandardpriorityqueueoperations, supportsthefollowingenhance-\nments.\ninsert(e): InserttheelementeintoPandreturnapositionreferring\ntoitsentry.\nremove(p): Removetheentryreferenced by pfromP.\nreplace(p,e): Replacewithetheelementassociated withtheentryref-\nerenced by pandreturntheposition ofthealteredentry.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 358 \u2014 #380\ni i\n358 Chapter8. HeapsandPriorityQueues\n8.4.1 A List-Based Implementation\nInthissection,wepresentasimpleimplementation ofanadaptable priorityqueue,\ncalled AdaptPriorityQueue. Our implementation is a generalization of the sorted-\nlistpriorityqueueimplementation giveninSection8.2.\nInCodeFragment8.7,wepresenttheclassdefinition,withtheexceptionofthe\nclass Position, which is presented later. The public part of the class is essentially\nthe same as the standard priority queue interface, which was presented in Code\nFragment 8.4, together with the new functions remove and replace. Note that the\nfunction insertnowreturnsaposition.\ntemplate <typename E, typename C>\nclass AdaptPriorityQueue // adaptable priority queue\n{\nprotected:\ntypedef std::list<E> ElementList; // list of elements\npublic:\n// ...insert Position class definition here\npublic:\nint size() const; // number of elements\nbool empty() const; // is the queue empty?\nconst E& min() const; // minimum element\nPosition insert(const E& e); // insert element\nvoid removeMin(); // remove minimum\nvoid remove(const Position& p); // remove at position p\nPosition replace(const Position& p, const E& e); // replace at position p\nprivate:\nElementList L; // priority queue contents\nC isLess; // less-than comparator\n;\n}\nCodeFragment8.19: Theclassdefinitionforanadaptable priorityqueue.\nWe next define the class Position, which is nested within the public part of\nclass AdaptPriorityQueue. Its data member is an iterator to the STLlist. This list\ncontains the contents of the priority queue. Themain public member isafunction\nthat returns a \u201cconst\u201d reference the underlying element, which is implemented by\noverloading the\u201c*\u201doperator. Thisispresented inCodeFragment8.20.\nclass Position // a position in the queue\n{\nprivate:\ntypename ElementList::iterator q; // a position in the list\npublic:\nconst E& operator*() return *q; // the element at this position\n{ }\nfriend class AdaptPriorityQueue; // grant access\n;\n}\nCodeFragment8.20: Theclassrepresenting aposition inAdaptPriorityQueue.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 359 \u2014 #381\ni i\n8.4. AdaptablePriorityQueues 359\nThe operation insert is presented in Code Fragment 8.21. It is essentially the\nsameaspresentedinthestandardlistpriorityqueue(seeCodeFragment8.9). Since\nit is declared outside the class, we need to provide the complete template specifi-\ncations for the function. We search for the first entry p whose key value exceeds\nours,andinsertejustpriortothisentry. Wethencreateapositionthatreferstothe\nentryjustpriorto pandreturnit.\ntemplate <typename E, typename C> // insert element\ntypename AdaptPriorityQueue<E,C>::Position\nAdaptPriorityQueue<E,C>::insert(const E& e)\n{\ntypename ElementList::iterator p = L.begin();\nwhile (p != L.end() && !isLess(e, *p)) ++p; // find larger element\nL.insert(p, e); // insert before p\nPosition pos; pos.q = p;\n\u2212\u2212\nreturn pos; // inserted position\n}\nCodeFragment8.21: Thefunction insertforclassAdaptPriorityQueue.\nWeomitthedefinitionsofthememberfunctionssize,empty,min,andremove-\nMin,sincetheyarethesameasinthestandardlist-basedpriorityqueueimplemen-\ntation(seeCodeFragments8.8and8.10). Next,inCodeFragment8.22,wepresent\ntheimplementations ofthefunctions removeandreplace. Thefunctionremovein-\nvokestheerasefunctionoftheSTLlisttoremovetheentryreferredtobythegiven\nposition.\ntemplate <typename E, typename C> // remove at position p\nvoid AdaptPriorityQueue<E,C>::remove(const Position& p)\nL.erase(p.q);\n{ }\ntemplate <typename E, typename C> // replace at position p\ntypename AdaptPriorityQueue<E,C>::Position\nAdaptPriorityQueue<E,C>::replace(const Position& p, const E& e)\n{\nL.erase(p.q); // remove the old entry\nreturn insert(e); // insert replacement\n}\nCodeFragment8.22: Thefunctions removeandreplaceforAdaptPriorityQueue.\nWe have chosen perhaps the simplest way to implement the function replace.\nWe remove the entry to be modified and simply insert the new element e into the\npriority queue. Ingeneral, thekeyinformation mayhavechanged, andtherefore it\nmay need to be moved to a new location in the sorted list. Under the assumption\nthatkeychangesarerare,amorecleversolutionwouldinvolvesearching forwards\norbackwardstodeterminetheproperpositionforthemodifiedentry. Whileitmay\nnotbeveryefficient,ourapproach hasthevirtueofsimplicity.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 360 \u2014 #382\ni i\n360 Chapter8. HeapsandPriorityQueues\n8.4.2 Location-Aware Entries\nIn our implementation of the adaptable priority queue, AdaptPriorityQueue, pre-\nsentedintheprevioussection,weexploitedanicepropertyofthelist-basedpriority\nqueue implementation. In particular, once a new entry is added to the sorted list,\ntheelementassociatedwiththisentryneverchanges. Thismeansthatthepositions\nreturned bytheinsertandreplacefunctions alwaysrefertothesameelement.\nNote, however, that this same approach would fail if we tried to apply it to\nthe heap-based priority queue of Section 8.3.3. The reason is that the heap-based\nimplementation moves the entries around the heap (for example, through up-heap\nbubbling and down-heap bubbling). When an element e is inserted, we return a\nreference to the entry p containing e. But if e were to be moved as a result of\nsubsequentoperationsappliedtothepriorityqueue, pdoesnotchange. Asaresult,\np might be pointing to a different element of the priority queue. An attempt to\napply remove(p) or replace(p,e\u2032), would not be applied to e but instead to some\notherelement.\nThe solution to this problem involves decoupling positions and entries. In our\nimplementation of AdaptPriorityQueue, each position pis essentially apointer to\na node of the underlying data structure (for this is how an STL iterator is imple-\nmented). If we move an entry, we need to also change the associated pointer. In\nordertodealwithmovingentries,eachtimeweinsertanewelementeintheprior-\nityqueue, inaddition tocreating anewentryinthedatastructure, wealsoallocate\nmemory for an object, called a locator. The locator\u2019s job is to store the current\nposition pofelementeinthedatastructure. Eachentryofthepriorityqueueneeds\ntoknow its associated locator l. Thus, rather than just storing the element itself in\nthepriorityqueue,westoreapair(e,&l),consisting oftheelementeandapointer\ntoitslocator. Wecall this alocator-aware entry. Afterinserting anew element in\nthepriorityqueue,wereturntheassociatedlocatorobject,whichpointstothispair.\nHow does this solve the decoupling problem? First, observe that whenever\ntheuserofthepriorityqueuewantstolocatetheposition pofapreviouslyinserted\nelement,itsufficestoaccessthelocatorthatstoresthisposition. Suppose,however,\nthat the entry moves to a different position p\u2032 within the data structure. To handle\nthis,wefirstaccessthelocation-awareentry(e,&l)toaccessthelocatorl. Wethen\nmodifyl sothatitreferstothenewposition p\u2032. Theusermayfindthenewposition\nbyaccessing thelocator.\nThe price we pay for this extra generality is fairly small. For each entry, we\nneed to two store two additional pointers (the locator and the locator\u2019s address).\nEach time we move an object in the data structure, we need to modify a constant\nnumberofpointers. Therefore,therunningtimeincreasesbyjustaconstantfactor.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 361 \u2014 #383\ni i\n8.5. Exercises 361\n8.5 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-8.1 Whataretherunningtimesofeachofthefunctionsofthe(standard)prior-\nityqueueADTifweimplementitbyadapting theSTLpriority queue?\nR-8.2 How long would it take to remove the logn smallest elements from a\n\u2308 \u2309\nheapthatcontainsnentries usingtheremoveMin()operation?\nR-8.3 Showthat,givenonlytheless-thanoperator(<)andthebooleanoperators\nand (&&), or (||), and not (!), it is possible to implement all of the other\ncomparators: >,<=,>=,==,!=.\nR-8.4 Explain how to implement a priority queue based on the composition\nmethod (ofstoring key-element pairs) byadapting apriority queue based\nonthecomparatorapproach.\nR-8.5 Suppose you label each node vof abinary tree T with a key equal to the\npreorder rankofv. Underwhatcircumstances isT aheap?\nR-8.6 Show the output from the following sequence of priority queue ADTop-\nerations. Theentries arekey-element pairs, wheresorting isbased onthe\nkeyvalue: insert(5,a),insert(4,b),insert(7,i),insert(1,d),removeMin(),\ninsert(3,j),insert(6,c),removeMin(),removeMin(),insert(8,g),remove-\nMin(),insert(2,h),removeMin(),removeMin().\nR-8.7 An airport is developing a computer simulation of air-traffic control that\nhandleseventssuchaslandingsandtakeoffs. Eacheventhasatime-stamp\nthat denotes the time when the event occurs. The simulation program\nneedstoefficientlyperform thefollowingtwofundamental operations:\nInsertaneventwithagiventime-stamp(thatis,addafutureevent)\n\u2022\nExtract the event with smallest time-stamp (that is, determine the\n\u2022\nnexteventtoprocess)\nWhichdatastructure shouldbeusedfortheaboveoperations? Why?\nR-8.8 Although it is correct to use a \u201creverse\u201d comparator with our priority\nqueue ADT so that we retrieve and remove an element with the maxi-\nmumkeyeachtime,itisconfusingtohaveanelementwiththemaximum\nkey returned by a function named \u201cremoveMin.\u201d Write a short adapter\nclass that can take any priority queue P and an associated comparator C\nandimplement apriority queue thatconcentrates ontheelement withthe\nmaximumkey,usingfunctions withnameslikeremoveMax.\n(Hint: DefineanewcomparatorC\u2032 intermsofC.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 362 \u2014 #384\ni i\n362 Chapter8. HeapsandPriorityQueues\nR-8.9 Illustratetheperformanceoftheselection-sort algorithmonthefollowing\ninputsequence: (22,15,36,44,10,3,9,13,29,25).\nR-8.10 Illustrate the performance of the insertion-sort algorithm on the input se-\nquenceofthepreviousproblem.\nR-8.11 Give an example of a worst-case sequence with n elements for insertion-\nsort,andshowthatinsertion-sortrunsin\u2126(n2)timeonsuchasequence.\nR-8.12 Atwhichnodesofaheapcananentrywiththelargestkeybestored?\nR-8.13 Indefiningtherelation\u201ctotheleftof\u201dfortwonodesofabinarytree(Sec-\ntion8.3.1),canweuseapreordertraversalinsteadofaninordertraversal?\nHowaboutapostorder traversal?\nR-8.14 Illustrate the performance oftheheap-sort algorithm onthe following in-\nputsequence: (2,5,16,4,10,23,39,18,26,15).\nR-8.15 LetT beacompletebinarytreesuchthatnodevstoresthekey-entrypairs\n(f(v),0), where f(v) is the level number of v. Is tree T a heap? Why or\nwhynot?\nR-8.16 Explainwhythecasewheretherightchildofrisinternalandtheleftchild\nisexternalwasnotconsideredinthedescriptionofdown-heapbubbling.\nR-8.17 Is there a heap T storing seven distinct elements such that a preorder\ntraversal of T yields the elements of T in sorted order? How about an\ninordertraversal? Howaboutapostorder traversal?\nR-8.18 Consider the numbering of the nodes of a binary tree defined in Sec-\ntion 7.3.5, and show that the insertion position in a heap with n keys is\nthenodewithnumbern+1.\nR-8.19 Let H be a heap storing 15 entries using the vector representation of a\ncomplete binary tree. What is the sequence of indices of the vector that\nare visited in a preorder traversal of H? What about an inorder traversal\nofH? Whataboutapostorder traversalofH?\nR-8.20 Show that the sum \u2211n logi, which appears in the analysis of heap-sort,\ni=1\nis\u2126(nlogn).\nR-8.21 Bill claims that a preorder traversal of a heap will list its keys in nonde-\ncreasing order. Drawanexampleofaheapthatproveshimwrong.\nR-8.22 Hillaryclaimsthatapostorder traversalofaheapwilllistitskeysinnon-\nincreasing order. Drawanexampleofaheapthatprovesherwrong.\nR-8.23 Showallthestepsofthealgorithm forremoving key16fromtheheapof\nFigure8.3.\nR-8.24 Drawanexampleofaheapwhosekeysarealltheoddnumbersfrom1to\n59(withnorepeats),suchthattheinsertionofanentrywithkey32would\ncause up-heap bubbling to proceed all the way up to a child of the root\n(replacing thatchild\u2019s keywith32).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 363 \u2014 #385\ni i\n8.5. Exercises 363\nR-8.25 Giveapseudo-code descriptionofanonrecursive in-placeheap-sortalgo-\nrithm.\nR-8.26 A group of children want to play a game, called Unmonopoly, where in\neachturntheplayerwiththemostmoneymustgivehalfofhis/hermoney\nto the player with the least amount of money. What data structure(s)\nshouldbeusedtoplaythisgameefficiently? Why?\nCreativity\nC-8.1 An online computer system for trading stock needs to process orders of\nthe form \u201cbuy 100 shares at $x each\u201d or \u201csell 100 shares at $y each.\u201d A\nbuy order for $x can only be processed if there is an existing sell order\nwith price $y such that y x. Likewise, a sell order for $y can only be\n\u2264\nprocessed if there is an existing buy order with price $x such that x y.\n\u2265\nIf a buy or sell order is entered but cannot be processed, it must wait\nfor a future order that allows it to be processed. Describe a scheme that\nallowsforbuyandsellorderstobeentered inO(logn)time,independent\nofwhetherornottheycanbeimmediatelyprocessed.\nC-8.2 Extend a solution to the previous problem so that users are allowed to\nupdatethepricesfortheirbuyorsellordersthathaveyettobeprocessed.\nC-8.3 Writeacomparator forinteger objects thatdetermines orderbased onthe\nnumberof1sineachnumber\u2019sbinaryexpansion, sothati< jifthenum-\nber of1s inthe binary representation ofiis less than the number of 1sin\nthebinaryrepresentation of j.\nC-8.4 Show how to implement the stack ADT using only a priority queue and\noneadditional membervariable.\nC-8.5 Show how to implement the (standard) queue ADT using only a priority\nqueueandoneadditional membervariable.\nC-8.6 Describe, in detail, an implementation of a priority queue based on a\nsorted array. Show that this implementation achieves O(1) time for op-\nerations minandremoveMinandO(n)timeforoperation insert.\nC-8.7 Describeanin-placeversionoftheselection-sort algorithmthatusesonly\nO(1)spaceformembervariables inadditiontoaninputarrayitself.\nC-8.8 AssumingtheinputtothesortingproblemisgiveninanarrayA,describe\nhowtoimplementtheinsertion-sort algorithm usingonlythearrayAand,\natmost,sixadditional (base-type) variables.\nC-8.9 AssumingtheinputtothesortingproblemisgiveninanarrayA,describe\nhow to implement the heap-sort algorithm using only the array A and, at\nmost,sixadditional (base-type) variables.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 364 \u2014 #386\ni i\n364 Chapter8. HeapsandPriorityQueues\nC-8.10 Describeasequenceofninsertionstoaheapthatrequires\u2126(nlogn)time\ntoprocess.\nC-8.11 An alternative method for finding the last node during an insertion in a\nheap T istostore, inthe last node and each external node of T, apointer\nto the external node immediately to its right (wrapping to the first node\nin the next lower level for the rightmost external node). Show how to\nmaintain such a pointer in O(1) time per operation of the priority queue\nADT,assumingT isimplementedasalinkedstructure.\nC-8.12 Wecan represent apath from the root toa given node of abinary tree by\nmeansofabinarystring,where0means\u201cgototheleftchild\u201dand1means\n\u201cgo to the right child.\u201d For example, the path from the root to the node\nstoring8intheheapofFigure8.3isrepresented bythebinarystring101.\nDesignanO(logn)-timealgorithm forfindingthelastnodeofacomplete\nbinary tree with n nodes based on the above representation. Show how\nthis algorithm can be used in the implementation of a complete binary\ntree by means of a linked structure that does not keep a reference to the\nlastnode.\nC-8.13 SupposethebinarytreeT usedtoimplementaheapcanbeaccessedusing\nonly the functions of the binary tree ADT. That is, we cannot assume T\nis implemented as a vector. Given a pointer to the current last node, v,\ndescribe an efficient algorithm for finding the insertion point (that is, the\nnew last node) using just the functions of the binary tree interface. Be\nsure and handle all possible cases as illustrated in Figure 8.12. What is\ntherunningtimeofthisfunction?\n(a) (b)\nFigure8.12: Updatingthelastnodeinacompletebinarytreeafteroperationaddor\nremove. Node w is the last node before operation add or after operation remove.\nNodezisthelastnodeafteroperation addorbeforeoperation remove.\nC-8.14 GivenaheapT andakeyk,giveanalgorithmtocomputealltheentriesin\nT with akey less than or equal to k. Forexample, given the heap ofFig-\nure 8.12(a) and query k=7, the algorithm should report the entries with\nkeys 2, 4, 5, 6, and 7 (but not necessarily in this order). Your algorithm\nshouldrunintimeproportional tothenumberofentriesreturned.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 365 \u2014 #387\ni i\n8.5. Exercises 365\nC-8.15 Show that, for any n, there is a sequence of insertions in a heap that re-\nquires\u2126(nlogn)timetoprocess.\nC-8.16 Provideajustification ofthetimeboundsinTable8.1.\nC-8.17 Developanalgorithm thatcomputesthekthsmallestelementofasetofn\ndistinct integersinO(n+klogn)time.\nC-8.18 Suppose the internal nodes of two binary trees, T and T respectively,\n1 2\nhold items that satisfy the heap-order property. Describe a method for\ncombining these two trees into a tree T, whose internal nodes hold the\nunion of the items in T and T and also satisfy the heap-order property.\n1 2\nYour algorithms should run in time O(h +h ) where h and h are the\n1 2 1 2\nrespective heightsofT andT .\n1 2\nC-8.19 Give an alternative analysis of bottom-up heap construction by showing\nthat,foranypositiveintegerh,\u2211h (i/2i)isO(1).\ni=1\nC-8.20 Let T be a heap storing n keys. Give an efficient algorithm for reporting\nall the keys in T that are smaller than or equal to a given query key x\n(whichisnotnecessarily inT). Forexample,giventheheapofFigure8.3\nand query key x=7, the algorithm should report 4, 5, 6, 7. Note that the\nkeys do not need to be reported in sorted order. Ideally, your algorithm\nshouldruninO(k)time,wherekisthenumberofkeysreported.\nC-8.21 Giveanalternatedescription ofthein-place heap-sort algorithm thatuses\nastandard comparator insteadofareverseone.\nC-8.22 Describe efficient algorithms for performing operations remove(e) on an\nadaptablepriorityqueuerealizedbymeansofanunsortedlistwithlocation-\nawareentries.\nC-8.23 Let S be a set of n points in the plane with distinct integer x- and y-\ncoordinates. Let T be a complete binary tree storing the points from S\nat its external nodes, such that the points are ordered left-to-right by in-\ncreasingx-coordinates. ForeachnodevinT,letS(v)denotethesubsetof\nS consisting of points stored in the subtree rooted at v. For the root r of\nT, definetop(r) to be the point in S=S(r) with maximum y-coordinate.\nFor every other node v, definetop(r) to be the point in S with highest y-\ncoordinate inS(v)that isnotalso thehighest y-coordinate inS(u), where\nuistheparentofvinT (ifsuchapointexists). SuchlabelingturnsT into\naprioritysearchtree. Describealinear-timealgorithm forturningT into\napriority searchtree.\nProjects\nP-8.1 Generalize the Heap data structure of Section 8.3 from a binary tree to\na k-ary tree, for an arbitrary k 2. Study the relative efficiencies of the\n\u2265\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 366 \u2014 #388\ni i\n366 Chapter8. HeapsandPriorityQueues\nresulting datastructure forvariousvaluesofk,byinserting andremoving\nalargenumberofrandomlygenerated keysintoeachdatastructure.\nP-8.2 GiveaC++implementationofapriorityqueuebasedonanunsortedlist.\nP-8.3 DevelopaC++implementation ofapriorityqueuethatisbasedonaheap\nandsupports thelocator-based functions.\nP-8.4 Implement the in-place heap-sort algorithm. Compare its running time\nwiththatofthestandard heap-sort thatusesanexternal heap.\nP-8.5 Implement a heap-based priority queue that supports the following addi-\ntionaloperation inlineartime:\nreplaceComparator(c): Replacethecurrentcomparator withc.\nAfterchanging thecomparator, theheapwillneedtoberestructured.\n(Hint: Utilizethebottom-up heapconstruction algorithm.)\nP-8.6 Writeaprogram thatcan process asequence ofstock buy andsell orders\nasdescribed inExerciseC-8.1.\nP-8.7 Oneofthemainapplications ofpriority queuesisinoperating systems\u2014\nfor scheduling jobs on a CPU.In this project you are to build a program\nthat schedules simulated CPU jobs. Your program should run in a loop,\neachiteration ofwhichcorresponds toatimeslicefortheCPU.Eachjob\nis assigned a priority, which is an integer between 20 (highest priority)\n\u2212\nand 19 (lowest priority), inclusive. From among all jobs waiting to be\nprocessed in a time slice, the CPU must work on the job with highest\npriority. In this simulation, each job will also come with a length value,\nwhich is an integer between 1 and 100, inclusive, indicating the number\noftimeslicesthat areneeded toprocess thisjob. Forsimplicity, youmay\nassumejobscannotbeinterrupted\u2014onceitisscheduledontheCPU,ajob\nruns for a number of time slices equal to its length. Your simulator must\noutputthenameofthejobrunningontheCPUineachtimesliceandmust\nprocess a sequence of commands, one per time slice, each of which is of\ntheform \u201cadd jobnamewithlength nand priority p\u201dor\u201cnonewjob this\nslice.\u201d\nChapter Notes\nKnuth\u2019s book on sorting and searching [57] describes the motivation and history for the\nselection-sort, insertion-sort, and heap-sort algorithms. The heap-sort algorithm is due\nto Williams [103], and the linear-time heap construction algorithm is due to Floyd [33].\nAdditional algorithms and analyses for heaps and heap-sort variations can be found in\npapersbyBentley[12],Carlsson[20],GonnetandMunro[38],McDiarmidandReed[70],\nandSchafferandSedgewick[88]. Thedesignpatternofusinglocation-awareentries(also\ndescribedin[39]),appearstobenew.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 367 \u2014 #389\ni i\nChapter\n9\nHash Tables, Maps, and Skip Lists\nContents\n9.1 Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . 368\n9.1.1 The Map ADT . . . . . . . . . . . . . . . . . . . . 369\n9.1.2 A C++ Map Interface . . . . . . . . . . . . . . . . . 371\n9.1.3 The STL map Class . . . . . . . . . . . . . . . . . . 372\n9.1.4 A Simple List-Based Map Implementation . . . . . . 374\n9.2 Hash Tables . . . . . . . . . . . . . . . . . . . . . . . 375\n9.2.1 Bucket Arrays . . . . . . . . . . . . . . . . . . . . . 375\n9.2.2 Hash Functions . . . . . . . . . . . . . . . . . . . . 376\n9.2.3 Hash Codes . . . . . . . . . . . . . . . . . . . . . . 376\n9.2.4 Compression Functions . . . . . . . . . . . . . . . . 380\n9.2.5 Collision-HandlingSchemes . . . . . . . . . . . . . . 382\n9.2.6 Load Factors and Rehashing . . . . . . . . . . . . . 386\n9.2.7 A C++ Hash Table Implementation . . . . . . . . . . 387\n9.3 Ordered Maps . . . . . . . . . . . . . . . . . . . . . . 394\n9.3.1 Ordered Search Tables and Binary Search . . . . . . 395\n9.3.2 Two Applications of Ordered Maps . . . . . . . . . . 399\n9.4 Skip Lists . . . . . . . . . . . . . . . . . . . . . . . . . 402\n9.4.1 Search and Update Operations in a Skip List . . . . 404\n\u22c6\n9.4.2 A Probabilistic Analysis of Skip Lists . . . . . . . 408\n9.5 Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . 411\n9.5.1 The Dictionary ADT . . . . . . . . . . . . . . . . . 411\n9.5.2 A C++ Dictionary Implementation . . . . . . . . . . 413\n9.5.3 Implementations with Location-Aware Entries . . . . 415\n9.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 417\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 368 \u2014 #390\ni i\n368 Chapter9. HashTables,Maps,andSkipLists\n9.1 Maps\nkey\nvalue\nMap\nentry\nFigure9.1: Aconceptualillustration ofthemapADT.Keys(labels)areassignedto\nvalues (folders) by a user. The resulting entries (labeled folders) are inserted into\nthemap(filecabinet). Thekeyscanbeusedlatertoretrieveorremovevalues.\nA map allows us to store elements so they can be located quickly using keys.\nThe motivation for such searches is that each element typically stores additional\nusefulinformationbesidesitssearchkey,buttheonlywaytogetatthatinformation\nistousethesearchkey. Specifically, amapstores key-value pairs(k,v),whichwe\ncallentries,wherekisthekeyandvisitscorrespondingvalue. Inaddition,themap\nADTrequiresthateachkeybeunique,sotheassociationofkeystovaluesdefinesa\nmapping. Inordertoachievethehighestlevelofgenerality, weallowboththekeys\nandthevalues storedinamaptobeofanyobject type. (SeeFigure9.1.) Inamap\nstoring student records (such as the student\u2019s name, address, and course grades),\nthe key might be the student\u2019s ID number. In some applications, the key and the\nvalue may be the same. Forexample, ifwe had a map storing prime numbers, we\ncoulduseeachnumberitselfasbothakeyanditsvalue.\nIn either case, weuse a key as a unique identifier that is assigned by an appli-\ncation or user to an associated value object. Thus, a map is most appropriate in\nsituations whereeachkeyistobeviewed asakindofunique indexaddress forits\nvalue, that is, an object that serves as a kind of location for that value. For exam-\nple,ifwewishtostorestudent records, wewouldprobably wanttousestudent ID\nobjects as keys (and disallow two students having the same student ID). In other\nwords, the key associated with an object can be viewed as an \u201caddress\u201d for that\nobject. Indeed, mapsaresometimesreferred toasassociative stores orassociative\ncontainers, because the key associated with an object determines its \u201clocation\u201d in\nthedatastructure.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 369 \u2014 #391\ni i\n9.1. Maps 369\nEntries and the Composition Pattern\nAsmentionedabove,amapstoreskey-valuepairs,calledentries. Anentryisactu-\nally an example ofamore general object-oriented design pattern, thecomposition\npattern, which defines a single object that is composed of other objects. A pair is\nthesimplestcomposition,becauseitcombinestwoobjectsintoasinglepairobject.\nToimplement this concept, we define a class that stores two objects in its first\nand second member variables, respectively, and provides functions to access and\nupdate these variables. InCodeFragment 9.1, wepresent such animplementation\nstoring a single key-value pair. We define a class Entry, which is templated based\non the key and value types. In addition to a constructor, it provides member func-\ntions that return references to the key and value. It also provides functions that\nallowustosetthekeyandvaluemembers.\ntemplate <typename K, typename V>\nclass Entry // a (key, value) pair\n{\npublic: // public functions\nEntry(const K& k = K(), const V& v = V()) // constructor\n: key(k), value(v)\n{ }\nconst K& key() const return key; // get key\n{ }\nconst V& value() const return value; // get value\n{ }\nvoid setKey(const K& k) key = k; // set key\n{ }\nvoid setValue(const V& v) value = v; // set value\n{ }\nprivate: // private data\nK key; // key\nV value; // value\n;\n}\nCodeFragment9.1: AC++classforanentrystoringakey-value pair.\n9.1.1 The Map ADT\nIn this section, we describe a map ADT. Recall that a map is a collection of key-\nvalueentries,witheachvalueassociatedwithadistinctkey. Weassumethatamap\nprovides aspecial pointerobject, whichpermitsustoreference entries ofthemap.\nSuch an object would normally be called a position. As we did in Chapter 6, in\norder to be more consistent with the C++ Standard Template Library, we define a\nsomewhatmoregeneral object calledaniterator, whichcanboth reference entries\nand navigate around the map. Givenamapiterator p, the associated entry maybe\naccessedbydereferencing theiterator,namelyas*p. Theindividualkeyandvalue\ncanbeaccessed using p->key()and p->value(),respectively.\nInordertoadvanceaniteratorfromitscurrentpositiontothenext,weoverload\ntheincrement operator. Thus,++padvances theiterator ptothenextentry ofthe\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 370 \u2014 #392\ni i\n370 Chapter9. HashTables,Maps,andSkipLists\nmap. We can enumerate all the entries of a map M by initializing p to M.begin()\nandthenrepeatedly incrementing paslongasitisnotequaltoM.end().\nIn order to indicate that an object is not present in the map, we assume that\nthereexistsaspecialsentineliteratorcalledend. Byconvention,thissentinelrefers\ntoanimaginaryelementthatliesjustbeyondthelastelementofthemap.\nThemapADTconsists ofthefollowing:\nsize(): ReturnthenumberofentriesinM.\nempty(): ReturntrueifM isemptyandfalseotherwise.\nfind(k): IfMcontainsanentrye=(k,v),withkeyequaltok,then\nreturn an iterator preferring to this entry, and otherwise\nreturnthespecialiterator end.\nput(k,v): If M does not have an entry with key equal to k, then\nadd entry (k,v) to M, and otherwise, replace the value\nfield of this entry with v; return an iterator to the in-\nserted/modified entry.\nerase(k): Remove from M the entry with key equal to k; an error\ncondition occursifM hasnosuchentry.\nerase(p): Remove from M the entry referenced by iterator p; an\nerrorcondition occursif ppointstotheendsentinel.\nbegin(): ReturnaniteratortothefirstentryofM.\nend(): ReturnaniteratortoapositionjustbeyondtheendofM.\nWe have provided two means of removing entries, one given a key and the other\ngiven an iterator. The key-based operation should be used only when it is known\nthat the key ispresent inthe map. Otherwise, it isnecessary to firstcheck that the\nkeyexists using theoperation \u201cp=M.find(k),\u201dandifso, then apply theoperation\nM.erase(p). The iterator-based removal operation has the advantage that it does\nnotneedtorepeatthesearchforthekey,andhenceismoreefficient.\nTheoperation put, mayeither insert anentry ormodify anexisting entry. Itis\ndesigned explicitly in this way, since werequire that the keys be unique. Later, in\nSection9.5,weconsideradifferentdatastructure, whichallowsmultipleinstances\ntohavethesamekeys. Notethataniterator remainsassociated withanentry, even\nifitsvalueischanged.\nExample 9.1: Inthefollowing,weshowtheeffectofaseriesofoperationsonan\ninitiallyemptymapstoringentrieswithintegerkeysandsingle-charactervalues.\nInthecolumn\u201cOutput,\u201dweusethenotationp :[(k,v)]tomeanthattheoperation\ni\nreturnsaniteratordenotedbyp thatreferstotheentry(k,v). Theentriesofthe\ni\nmaparenotlistedinanyparticularorder.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 371 \u2014 #393\ni i\n9.1. Maps 371\nOperation Output Map\nempty() true\n\u2205\nput(5,A) p :[(5,A)] (5,A)\n1\n{ }\nput(7,B) p :[(7,B)] (5,A),(7,B)\n2\n{ }\nput(2,C) p :[(2,C)] (5,A),(7,B),(2,C)\n3\n{ }\nput(2,E) p :[(2,E)] (5,A),(7,B),(2,E)\n3\n{ }\nfind(7) p :[(7,B)] (5,A),(7,B),(2,E)\n2\n{ }\nfind(4) end (5,A),(7,B),(2,E)\n{ }\nfind(2) p :[(2,E)] (5,A),(7,B),(2,E)\n3\n{ }\nsize() 3 (5,A),(7,B),(2,E)\n{ }\nerase(5) \u2013 (7,B),(2,E)\n{ }\nerase(p ) \u2013 (7,B)\n3\n{ }\nfind(2) end (7,B)\n{ }\n9.1.2 A C++ Map Interface\nBeforediscussing specificimplementations ofthemapADT,wefirstdefineaC++\ninterface for a map in Code Fragment 9.2. It is not a complete C++ class, just a\ndeclaration of the public functions. The interface is templated by two types, the\nkeytypeK,andthevaluetypeV.\ntemplate <typename K, typename V>\nclass Map // map interface\n{\npublic:\nclass Entry; // a (key,value) pair\nclass Iterator; // an iterator (and position)\nint size() const; // number of entries in the map\nbool empty() const; // is the map empty?\nIterator find(const K& k) const; // find entry with key k\nIterator put(const K& k, const V& v); // insert/replace pair (k,v)\nvoid erase(const K& k) // remove entry with key k\nthrow(NonexistentElement);\nvoid erase(const Iterator& p); // erase entry at p\nIterator begin(); // iterator to first entry\nIterator end(); // iterator to end entry\n;\n}\nCodeFragment9.2: AninformalC++Mapinterface (notacompleteclass).\nInaddition toits memberfunctions, the interface defines twotypes, Entry and\nIterator. These two classes provide the types for the entry and iterator objects,\nrespectively. Outside the class, these would be accessed with Map<K,V>::Entry\nandMap<K,V>::Iterator,respectively.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 372 \u2014 #394\ni i\n372 Chapter9. HashTables,Maps,andSkipLists\nWe have not presented an interface for the iterator object, but its definition is\nsimilar to the STLiterator. It supports the operator \u201c*\u201d, which returns a reference\nto the associated entry. The unary increment and decrement operators \u201c++\u201d and\n\u201c\u2013\u2013\u201dmoveaniteratorforwardandbackwards,respectively. Also,twoiteratorscan\nbecomparedforequality using\u201c==\u201d.\nAmoresophisticatedimplementationwouldhavealsoprovidedforathirdtype,\nnamely a \u201cconst\u201d iterator. Such an iterator provides a function for reading entries\nwithoutmodifyingthem. (RecallSection6.1.4.) Weomitthistypeinordertokeep\nourinterface relativelysimple.\nTheremainderoftheinterfacefollowsfromourearlierdescriptions ofthemap\noperations. An error condition occurs if the function erase(k) is called with a key\nk that is notin themap. Thisis signaled by throwing an exception oftype Nonex-\nistentElement. Itsdefinition issimilar toother exceptions that wehaveseen. (See\nCodeFragment5.2.)\n9.1.3 The STL map Class\nThe C++ Standard Template Library (STL) provides an implementation of a map\nsimplycalled map. Aswithmanyoftheother STLclasses wehave seen, theSTL\nmapisanexampleofacontainer, andhencesupports accessbyiterators.\nIn order to declare an object of type map, it is necessary to first include the\ndefinition filecalled \u201cmap.\u201d Themap is part of the std namespace, and hence itis\nnecessary eithertouse\u201cstd::map\u201dortoprovideanappropriate \u201cusing\u201dstatement.\nTheSTLmapistemplatedwithtwoarguments,thekeytypeandthevaluetype.\nThe declaration \u201cmap<K,V>\u201d defines a map whose keys are of type K and whose\nvaluesareoftypeV.AswiththeotherSTLcontainers, aniteratortypeisprovided\nboth for referencing individual entries and enumerating multiple entries. Themap\niterator type is \u201cmap<K,E>::iterator.\u201d The (k,v) entries are stored in a composite\nobject called pair. Given an iterator p, its associated key and value members can\nbereferenced using p->first and p->second,respectively. (Theseareequivalentto\np->key() and p->value() in our map ADT, but note that there are no parentheses\nfollowingfirst andsecond.)\nAs with other iterators we have seen, each map object M defines two special\niterators through the functions begin and end, where M.begin() yields an iterator\nto the first element of the map, and M.end() yields an iterator to an imaginary\nelementjustbeyondtheendofthemap. Amapiterator pisbidirectional, meaning\nthat we can move forwards and backwards through the map using the increment\nanddecrementoperators, ++pand\u2013\u2013p,respectively.\nThe principal member functions of the STL map are given below. Let M be\ndeclaredtobeanSTLmap,letkbeakeyobject, andletvbeavalueobjectforthe\nclassM. Let pbeaniteratorforM.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 373 \u2014 #395\ni i\n9.1. Maps 373\nsize(): Returnthenumberofelementsinthemap.\nempty(): Returntrueifthemapisemptyandfalseotherwise.\nfind(k): Findtheentrywithkeykandreturnaniteratortoit;ifno\nsuchkeyexistsreturnend.\noperator[k]: Produce areference tothevalue ofkeyk;ifnosuch key\nexists, createanewentryforkeyk.\ninsert(pair(k,v)): Insertpair(k,v),returning aniterator toitsposition.\nerase(k): Removetheelementwithkeyk.\nerase(p): Removetheelementreferenced byiterator p.\nbegin(): Returnaniteratortothebeginning ofthemap.\nend(): Returnaniteratorjustpasttheendofthemap.\nOur map ADTis quite similar to the above functions. The insert function is a\nbitdifferent. InourADT,itisgiventwoarguments. IntheSTLmap,theargument\nisacompositeobjectoftypepair,whosefirstandsecondelementsarethekeyand\nvalue,respectively.\nThe STL map provides a very convenient way to search, insert, and modify\nentriesbyoverloadingthesubscriptoperator(\u201c[]\u201d). GivenamapM,theassignment\n\u201cM[k]=v\u201d inserts the pair (k,v) if k is not already present, or modifies the value\nif it is. Thus, the subscript assignment behaves essentially the same as our ADT\nfunction put(k,v). Reading the value of M[k] is equivalent to performing find(k)\nand accessing thevalue part ofthe resulting iterator. Anexample of theuse ofthe\nSTLmapisshowninCodeFragment9.3.\nmap<string, int> myMap; // a (string,int) map\nmap<string, int>::iterator p; // an iterator to the map\nmyMap.insert(pair<string, int>(\"Rob\", 28)); // insert (\u201cRob\u201d,28)\nmyMap[\"Joe\"] = 38; // insert(\u201cJoe\u201d,38)\nmyMap[\"Joe\"] = 50; // change to (\u201cJoe\u201d,50)\nmyMap[\"Sue\"] = 75; // insert(\u201cSue\u201d,75)\np = myMap.find(\"Joe\"); // *p = (\u201cJoe\u201d,50)\nmyMap.erase(p); // remove (\u201cJoe\u201d,50)\nmyMap.erase(\"Sue\"); // remove (\u201cSue\u201d,75)\np = myMap.find(\"Joe\");\nif (p == myMap.end()) cout << \"nonexistent\\n\"; // outputs: \u201cnonexistent\u201d\nfor (p = myMap.begin(); p != myMap.end(); ++p) // print all entries\n{\ncout << \"(\" << p >first << \",\" << p >second << \")\\n\";\n\u2212 \u2212\n}\nCodeFragment9.3: ExampleoftheusageofSTLmap.\nAs with the other STL containers we have seen, the STL does not check for\nerrors. Itisuptotheprogrammertobesurethatnoillegaloperationsareperformed.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 374 \u2014 #396\ni i\n374 Chapter9. HashTables,Maps,andSkipLists\n9.1.4 A Simple List-Based Map Implementation\nA simple way of implementing a map is to store its n entries in a list L, imple-\nmented as a doubly linked list. Performing the fundamental functions, find(k),\nput(k,v), and erase(k), involves simple scans down L looking for an entry with\nkey k. Pseudo-code is presented in Code Fragments 9.4. We use the notation\n[L.begin(),L.end()) to denote all the positions of list L, from L.begin()and up to,\nbutnotincluding, L.end().\nAlgorithmfind(k):\nInput: Akeyk\nOutput: ThepositionofthematchingentryofL,orendifthereisnokeykinL\nforeachposition p [L.begin(),L.end())do\n\u2208\nif p.key()=kthen\nreturn p\nreturnend thereisnoentrywithkeyequaltok\n{ }\nAlgorithmput(k,v):\nInput: Akey-value pair(k,v)\nOutput: Thepositionoftheinserted/modified entry\nforeachposition p [L.begin(),L.end())do\n\u2208\nif p.key()=kthen\n*p (k,v)\n\u2190\nreturn p returntheposition ofthemodifiedentry\n{ }\np L.insertBack((k,v))\n\u2190\nn n+1 incrementvariable storingnumberofentries\n\u2190 { }\nreturn p returnthepositionoftheinsertedentry\n{ }\nAlgorithmerase(k):\nInput: Akeyk\nOutput: None\nforeachposition p [L.begin(),L.end())do\n\u2208\nif p.key()=kthen\nL.erase(p)\nn n 1 decrementvariable storingnumberofentries\n\u2190 \u2212 { }\nCodeFragment9.4: Algorithmsforfind,put,anderaseforamapstoredinalistL.\nThis list-based map implementation is simple, but it is only efficient for very\nsmall maps. Every one of the fundamental functions takes O(n) time on a map\nwith n entries, because each function involves searching through the entire list in\ntheworstcase. Thus,wewouldlikesomething muchfaster.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 375 \u2014 #397\ni i\n9.2. HashTables 375\n9.2 Hash Tables\nThekeysassociatedwithvaluesinamaparetypicallythoughtofas\u201caddresses\u201dfor\nthosevalues. Examplesofsuchapplications includeacompiler\u2019ssymboltableand\naregistry ofenvironment variables. Bothofthesestructures consistofacollection\nof symbolic names where each name serves as the \u201caddress\u201d for properties about\navariable\u2019s type and value. One ofthe mostefficient ways toimplement amapin\nsuchcircumstances istouseahashtable. Although,aswewillsee,theworst-case\nrunning timeof mapoperations inan n-entry hash table is O(n). A hash table can\nusually perform these operations in O(1) expected time. In general, a hash table\nconsists oftwomajorcomponents, abucketarrayandahashfunction.\n9.2.1 Bucket Arrays\nA bucket array for a hash table is an array A of size N, where each cell of A is\nthought of as a \u201cbucket\u201d (that is, a collection of key-value pairs) and the integer\nN defines the capacity of the array. If the keys are integers well distributed in the\nrange [0,N 1], this bucket array is all that is needed. An entry e with key k is\n\u2212\nsimplyinserted intothebucketA[k]. (SeeFigure9.2.)\nFigure9.2: Abucketarrayofsize11fortheentries(1,D),(3,C),(3,F),(3,Z),(6,A),\n(6,C),and(7,Q).\nIf our keys are unique integers in the range [0,N 1], then each bucket holds\n\u2212\natmostoneentry. Thus,searches,insertions, andremovalsinthebucketarraytake\nO(1) time. This sounds like a great achievement, but it has two drawbacks. First,\nthe space used is proportional to N. Thus, if N is much larger than the number of\nentries nactually present inthemap, wehave awaste ofspace. Thesecond draw-\nbackisthatkeysarerequiredtobeintegersintherange[0,N 1],whichisoftennot\n\u2212\nthe case. Because ofthese twodrawbacks, weuse the bucket array in conjunction\nwitha\u201cgood\u201d mappingfromthekeystotheintegersintherange[0,N 1].\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 376 \u2014 #398\ni i\n376 Chapter9. HashTables,Maps,andSkipLists\n9.2.2 Hash Functions\nThe second part of a hash table structure is a function, h, called a hash function,\nthat maps each key k in our map to an integer in the range [0,N 1], where N is\n\u2212\nthecapacity ofthebucket arrayforthistable. Equippedwithsuchahashfunction,\nh, we can apply the bucket array method to arbitrary keys. The main idea of this\napproach istouse thehash function value, h(k), asan index into ourbucket array,\nA,insteadofthekeyk(whichismostlikelyinappropriate foruseasabucketarray\nindex). Thatis,westoretheentry(k,v)inthebucketA[h(k)].\nOf course, if there are two or more keys with the same hash value, then two\ndifferent entries will be mapped to the same bucket in A. In this case, we say\nthat a collision has occurred. Clearly, if each bucket of A can store only a single\nentry, then we cannot associate more than one entry with a single bucket, which\nis a problem in the case of collisions. To be sure, there are ways of dealing with\ncollisions, which we discuss later, but the best strategy is to try to avoid them in\nthefirstplace. Wesaythatahashfunctionis\u201cgood\u201difitmapsthekeysinourmap\ninsuchawayastominimizecollisions asmuchaspossible. Forpractical reasons,\nwealsowouldlikeahashfunctiontobefastandeasytocompute.\nWeviewtheevaluationofahashfunction, h(k),asconsisting oftwoactions\u2014\nmapping thekey k toaninteger, called the hashcode, and mapping the hash code\nto an integer within the range of indices ([0,N 1]) of a bucket array, called the\n\u2212\ncompression function. (SeeFigure9.3.)\nFigure9.3: Thetwopartsofahashfunction: hashcodeandcompression function.\n9.2.3 Hash Codes\nThefirstactionthatahashfunctionperformsistotakeanarbitrarykeykinourmap\nand assign it an integer value. The integer assigned to a key k is called the hash\ncodefork. Thisinteger valueneed notbeintherange [0,N 1],andmayevenbe\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 377 \u2014 #399\ni i\n9.2. HashTables 377\nnegative,butwewantthesetofhashcodesassignedtoourkeystoavoidcollisions\nasmuchaspossible. Ifthehashcodesofourkeyscausecollisions, thenthereisno\nhopeforourcompressionfunctiontoavoidthem. Inaddition,tobeconsistentwith\nall of our keys, the hash code we use for a key k should be the same as the hash\ncodeforanykeythatisequaltok.\nHash Codes in C++\nThe hash codes described below are based on the assumption that the number of\nbitsofeachtypeisknown. Thisinformationisprovidedinthestandardincludefile\n<limits>. This include file defines a templated class numeric limits. Given a base\ntype T (such as char, int, or float), the number of bits in a variable of type T is\ngiven by \u201cnumeric limits<T>.digits.\u201d Let us consider several common data types\nandsomeexamplefunctions forassigning hashcodestoobjectsofthesetypes.\nConverting to an Integer\nTo begin, we note that, for any data type X that is represented using at most as\nmanybitsasourintegerhashcodes,wecansimplytakeanintegerinterpretationof\nitsbitsasahashcodeforX. Thus,fortheC++fundamentaltypeschar,short,and\nint,wecanachieveagoodhashcodesimplybycastingthistypetoint.\nOnmanymachines, thetypelong hasabitrepresentation that istwiceaslong\nas type int. One possible hash code for a long object is to simply cast it down to\nan integer and then apply the integer hash code. The problem is that such a hash\ncode ignores half of the information present in the original value. If many of the\nkeys in our map only differ in these bits, they will collide using this simple hash\ncode. Abetter hashcode, whichtakesalltheoriginal bitsintoconsideration, sums\nanintegerrepresentationofthehigh-orderbitswithanintegerrepresentation ofthe\nlow-orderbits.\nIndeed, theapproach ofsummingcomponents canbeextended toanyobject x\nwhosebinaryrepresentationcanbeviewedasak-tuple(x ,x ,...,x )ofintegers,\n0 1 k\u22121\nbecause we can then form a hash code for x as \u2211k\u22121x. For example, given any\ni=0 i\nfloating-point number, wecansumitsmantissa andexponent aslongintegers, and\nthenapplyahashcodeforlongintegerstotheresult.\nPolynomial Hash Codes\nThe summation hash code, described above, is not a good choice for character\nstrings or other variable-length objects that can be viewed as tuples of the form\n(x ,x ,...,x ), where the order of the x\u2019s is significant. For example, consider\n0 1 k\u22121 i\na hash code for a character string s that sums the ASCII values of the characters\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 378 \u2014 #400\ni i\n378 Chapter9. HashTables,Maps,andSkipLists\nin s. Unfortunately, this hash code produces lots of unwanted collisions for com-\nmon groups of strings. In particular, \"temp01\" and \"temp10\" collide using this\nfunction, as do \"stop\", \"tops\", \"pots\", and \"spot\". A better hash code takes\ninto consideration the positions of the x\u2019s. An alternative hash code, which does\ni\nexactlythis,choosesanonzero constant, a=1,anduses\n6\nx ak\u22121+x ak\u22122+ +x a+x\n0 1 k\u22122 k\u22121\n\u00b7\u00b7\u00b7\nasahashcodevalue. Mathematicallyspeaking,thisissimplyapolynomialinathat\ntakes the components (x ,x ,...,x )of anobject x as itscoefficients. Thishash\n0 1 k\u22121\ncodeisthereforecalledapolynomialhashcode. ByHorner\u2019srule(seeExerciseC-\n4.16),thispolynomial canberewrittenas\nx +a(x +a(x + +a(x +a(x +ax )) )).\nk\u22121 k\u22122 k\u22123 2 1 0\n\u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7\nIntuitively, a polynomial hash code uses multiplication by the constant a as a\nwayof\u201cmakingroom\u201dforeachcomponentinatupleofvalues,whilealsopreserv-\ning a characterization of the previous components. Of course, on a typical com-\nputer, evaluating apolynomial isdone using thefinitebitrepresentation forahash\ncode; hence, the value periodically overflows the bits used for an integer. Since\nweare more interested in agood spread of the object xwith respect to other keys,\nwe simply ignore such overflows. Still, we should be mindful that such overflows\nare occurring and choose the constant a so that it has some nonzero, low-order\nbits, which serve to preserve some of the information content even if weare in an\noverflowsituation.\nWe have done some experimental studies that suggest that 33, 37, 39, and 41\naregoodchoicesforawhenworkingwithcharacterstringsthatareEnglishwords.\nInfact,inalistofover50,000Englishwordsformedastheunionofthewordlists\nprovided in two variants of Unix, we found that taking a to be 33, 37, 39, or 41\nproduced less than seven collisions in each case! Many implementations of string\nhashing choose a polynomial hash function, using one of these constants for a, as\na default hash code. For the sake of speed, however, some implementations only\napplythepolynomialhashfunction toafraction ofthecharacters inlongstrings.\nCyclic Shift Hash Codes\nA variant of the polynomial hash code replaces multiplication by a with a cyclic\nshift of a partial sum by a certain number of bits. Such a function, applied to\ncharacter strings in C++ could, for example, look like the following. We assume\na32-bit integer wordlength, and weassume access to afunction hashCode(x) for\nintegers. Toachieve a5-bit cyclic shift weform the\u201cbitwise or\u201d (see Section 1.2)\nof a 5-bit left shift and a 27-bit right shift. As before, we use an unsigned integer\nsothatrightshiftsfillwithzeros.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 379 \u2014 #401\ni i\n9.2. HashTables 379\nint hashCode(const char* p, int len) // hash a character array\n{\nunsigned int h = 0;\nfor (int i = 0; i < len; i++)\n{\nh = (h << 5) (h >> 27); // 5-bit cyclic shift\n|\nh += (unsigned int) p[i]; // add in next character\n}\nreturn hashCode(int(h));\n}\nAs with the traditional polynomial hash code, using the cyclic-shift hash code re-\nquiressomefine-tuning. Inthiscase,wemustwiselychoosetheamounttoshiftby\nforeachnewcharacter.\nExperimental Results\nIn Table 9.1, we show the results of some experiments run on a list of just over\n25,000 English words, which compare the number of collisions for various shift\namounts.\nCollisions Collisions\nShift Total Max Shift Total Max\n0 23739 86 9 18 2\n1 10517 21 10 277 3\n2 2254 6 11 453 4\n3 448 3 12 43 2\n4 89 2 13 13 2\n5 4 2 14 135 3\n6 6 2 15 1082 6\n7 14 2 16 8760 9\n8 105 2\nTable9.1: Comparisonofcollision behavior forthecyclicshiftvariantofthepoly-\nnomialhashcodeasappliedtoalistofjustover25,000Englishwords. The\u201cTotal\u201d\ncolumn records the total number of collisions and the \u201cMax\u201d column records the\nmaximumnumberofcollisionsforanyonehashcode. Notethat,withacyclicshift\nof0,thishashcoderevertstotheonethatsimplysumsallthecharacters.\nThese and our previous experiments show that if we choose our constant a\nor our shift value wisely, then either the polynomial hash code or its cyclic-shift\nvariant are suitable for any object that can be written as a tuple (x ,x ,...,x ),\n0 1 k\u22121\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 380 \u2014 #402\ni i\n380 Chapter9. HashTables,Maps,andSkipLists\nwhere the order in tuples matters. In particular, note that using a shift of 5 or 6 is\nparticularly good for English words. Also, note how poorly a simple addition of\nthevalueswouldbewithnoshifting (thatis,forashiftof0).\nHashing Floating-Point Quantities\nOnmostmachines, typesintandfloatareboth32-bitquantities. Nonetheless, the\napproach of casting a float variable to type int would not produce a good hash\nfunction, since this would truncate the fractional part of the floating-point value.\nFor the purposes of hashing, we do not really care about the number\u2019s value. It\nis sufficient to treat the number as a sequence of bits. Assuming that a char is\nstoredasan8-bitbyte,wecouldinterpreta32-bitfloatasafour-elementcharacter\narray, and a 64-bit double as an eight-element character array. C++ provides an\noperation called areinterpret cast, tocastbetween suchunrelated types. Thiscast\ntreatsquantities asasequence ofbitsandmakesnoattempttointelligently convert\nthemeaningofonequantity toanother.\nForexample,wecoulddesignahashfunctionforafloatbyfirstreinterpreting\nitasanarrayofcharactersandthenapplyingthecharacter-arrayhashCodefunction\ndefinedabove. Weusetheoperator sizeof, whichreturns thenumber ofbytesina\ntype.\nint hashCode(const float& x) // hash a float\n{\nint len = sizeof(x);\nconst char* p = reinterpret cast<const char*>(&x);\nreturn hashCode(p, len);\n}\nReinterpretcastsaregenerallynotportableoperations, sincetheresultdepends\non the particular machine\u2019s encoding of types as a pattern of bits. In our case,\nportability is not an issue since we are interested only in interpreting the floating\npoint value as a sequence of bits. The only property that we require is that float\nvariables withequalvaluesmusthavethesamebitsequence.\n9.2.4 Compression Functions\nThehashcodeforakeykistypically notsuitable forimmediateusewithabucket\narray, because the range of possible hash codes for our keys typically exceeds the\nrange oflegalindices ofourbucket array A. Thatis,incorrectly using ahashcode\nasanindexintoourbucketarraymayresultinanerrorcondition,eitherbecausethe\nindexisnegativeoritexceedsthecapacityofA. Thus,oncewehavedeterminedan\ninteger hash code for akey object k,there isstill the issue ofmapping that integer\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 381 \u2014 #403\ni i\n9.2. HashTables 381\ninto the range [0,N 1]. This compression step is the second action that a hash\n\u2212\nfunction performs.\nThe Division Method\nOnesimplecompression functiontouseis\nh(k)= k mod N,\n| |\nwhich is called the division method. Additionally, if we take N to be a prime\nnumber,thenthishashfunctionhelps\u201cspreadout\u201dthedistributionofhashedvalues.\nIndeed,ifNisnotprime,thereisahigherlikelihoodthatpatternsinthedistribution\nofkeyswillberepeatedinthedistributionofhashcodes,therebycausingcollisions.\nFor example, if we hash the keys 200,205,210,215,220,...,600 to a bucket\n{ }\narray of size 100 using the division method, then each hash code collides with\nthree others. But if this same set of keys is similarly hashed to a bucket array of\nsize 101, then there are no collisions. If a hash function is chosen well, it should\nensure thatthe probability oftwodifferent keys getting hashed tothesamebucket\nis1/N. ChoosingN tobeaprimenumberisnotalwaysenough, however,because\nif there is a repeated pattern of key values of the form iN+ j for several different\ni\u2019s,thentherearestillcollisions.\nThe MAD Method\nA more sophisticated compression function, which helps eliminate repeated pat-\nternsinasetofintegerkeysisthemultiplyaddanddivide(or\u201cMAD\u201d)method. In\nusingthismethod,wedefinethecompression functionas\nh(k)= ak+b mod N,\n| |\nwhereN isaprimenumber, andaandbarenonnegativeintegersrandomlychosen\nat the time the compression function is determined, so that a mod N = 0. This\n6\ncompression functionischoseninordertoeliminaterepeated patterns inthesetof\nhashcodesandtogetusclosertohavinga\u201cgood\u201dhashfunction,thatis,onehaving\ntheprobabilitythatanytwodifferentkeyscollideis1/N. Thisgoodbehaviorwould\nbethesameasifthesekeyswere\u201cthrown\u201dintoAuniformlyatrandom.\nWith a compression function such as this, that spreads n integers fairly evenly\nin the range [0,N 1], and a mapping of the keys in our map to integers, we have\n\u2212\naneffectivehashfunction. Together,suchahashfunctionandabucketarraydefine\nthekeyingredients ofthehashtableimplementation ofthemapADT.\nBut before we can give the details of how to perform such operations as find,\ninsert,anderase,wemustfirstresolvetheissueofhowwetohandle collisions.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 382 \u2014 #404\ni i\n382 Chapter9. HashTables,Maps,andSkipLists\n9.2.5 Collision-Handling Schemes\nThe main idea of a hash table is to take a bucket array, A, and a hash function,\nh, and use them to implement a map by storing each entry (k,v) in the \u201cbucket\u201d\nA[h(k)]. Thissimpleidea ischallenged, however, whenwehavetwodistinct keys,\nk and k , such that h(k )=h(k ). The existence of such collisions prevents us\n1 2 1 2\nfrom simply inserting a new entry (k,v) directly in the bucket A[h(k)]. Collisions\nalso complicate our procedure for performing the find(k), put(k,v), and erase(k)\noperations.\nSeparate Chaining\nA simple and efficient way for dealing with collisions is to have each bucket A[i]\nstore a small map, M, implemented using a list, as described in Section 9.1.4,\ni\nholding entries (k,v) such that h(k)=i. That is, each separate M chains together\ni\nthe entries that hash to index i in a linked list. This collision-resolution rule is\nknownasseparate chaining. Assumingthatweinitialize eachbucketA[i]tobean\nempty list-based map, we can easily use the separate-chaining rule to perform the\nfundamental mapoperations asshowninCodeFragment9.5.\nAlgorithmfind(k):\nOutput: Thepositionofthematchingentryofthemap,orendifthereisnokey\nkinthemap\nreturnA[h(k)].find(k) delegatethefind(k)tothelist-based mapatA[h(k)]\n{ }\nAlgorithmput(k,v):\np A[h(k)].put(k,v) delegatetheputtothelist-based mapatA[h(k)]\n\u2190 { }\nn n+1\n\u2190\nreturn p\nAlgorithmerase(k):\nOutput: None\nA[h(k)].erase(k) delegatetheerasetothelist-based mapatA[h(k)]\n{ }\nn n 1\n\u2190 \u2212\nCodeFragment9.5: ThefundamentalfunctionsofthemapADT,implementedwith\nahashtablethatusesseparate chaining toresolvecollisions amongitsnentries.\nFor each fundamental map operation involving a key k, the separate-chaining\napproach delegates the handling of this operation to the miniature list-based map\nstored at A[h(k)]. So, put(k,v) scans this list looking for an entry with key equal\nto k; if it finds one, it replaces its value with v, otherwise, it puts (k,v) at the end\nof this list. Likewise, find(k) searches through this list until it reaches the end or\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 383 \u2014 #405\ni i\n9.2. HashTables 383\nfinds an entry with key equal to k. And erase(k) performs a similar search but\nadditionally removesanentryafteritisfound. Wecan\u201cgetaway\u201dwiththissimple\nlist-basedapproachbecausethespreadingpropertiesofthehashfunctionhelpkeep\neach bucket\u2019s list small. Indeed, a good hash function tries to minimize collisions\nas much as possible, which implies that most of our buckets are either empty or\nstore just a single entry. In Figure 9.4, we give an illustration of a hash table with\nseparate chaining.\nFigure9.4: Ahashtableofsize13, storing 10entries withintegerkeys, withcolli-\nsionsresolvedbyseparatechaining. Thecompressionfunctionish(k)=k mod 13.\nForsimplicity, wedonotshowthevaluesassociated withthekeys.\nAssuming we use a good hash function to index the n entries of our map in a\nbucket array of capacity N, we expect each bucket to be of size n/N. This value,\ncalled the load factor of the hash table (and denoted with \u03bb), should be bounded\nbyasmallconstant, preferably below 1. Givenagood hashfunction, theexpected\nrunning time of operations find, put, and erase in amap implemented with ahash\ntablethatusesthisfunctionisO( n/N ). Thus,wecanimplementtheseoperations\n\u2308 \u2309\ntoruninO(1)expected timeprovided nisO(N).\nOpen Addressing\nThe separate-chaining rule has many nice properties, such as allowing for simple\nimplementations of map operations, but it nevertheless has one slight disadvan-\ntage. Itrequires theuseofanauxiliary data structure\u2014a list\u2014to hold entries with\ncolliding keys. Wecan handle collisions in other ways besides using the separate-\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 384 \u2014 #406\ni i\n384 Chapter9. HashTables,Maps,andSkipLists\nchaining rule, however. In particular, if space is at a premium (for example, if we\narewritingaprogramforasmallhandheld device),thenwecanusethealternative\napproach of always storing each entry directly in a bucket, at most one entry per\nbucket. This approach saves space because no auxiliary structures are employed,\nbutitrequiresabitmorecomplexitytodealwithcollisions. Thereareseveralvari-\nants of this approach, collectively referred to as open-addressing schemes, which\nwediscuss next. Open addressing requires that the load factor isalways at most 1\nandthatentriesarestoreddirectlyinthecellsofthebucket arrayitself.\nLinear Probing and its Variants\nAsimple open-addressing method for collision handling is linear probing. In this\nmethod,ifwetrytoinsertanentry(k,v)intoabucketA[i]thatisalreadyoccupied\n(where i=h(k)), then wetry next atA[(i+1) mod N]. IfA[(i+1) mod N]is also\noccupied, then we try A[(i+2) mod N], and so on, until we find an empty bucket\nthatcanaccept thenewentry. Oncethisbucket islocated, wesimplyinserttheen-\ntry there. Of course, this collision-resolution strategy requires that we change the\nimplementation of the get(k,v) operation. In particular, to perform such a search,\nfollowed byeither areplacement orinsertion, wemustexamine consecutive buck-\nets, starting from A[h(k)], until we either find an entry with key equal to k or we\nfindanemptybucket. (SeeFigure9.5.) Thename\u201clinearprobing\u201dcomesfromthe\nfactthataccessing acellofthebucketarraycanbeviewedasa\u201cprobe.\u201d\nFigure9.5: Aninsertionintoahashtableusinglinearprobingtoresolvecollisions.\nHereweusethecompression function h(k)=k mod 11.\nTo implement erase(k), we might, at first, think we need to do a considerable\namount of shifting of entries to make it look as though the entry with key k was\nneverinserted, whichwouldbeverycomplicated. Atypicalwaytogetaroundthis\ndifficultyistoreplaceadeletedentrywithaspecial\u201cavailable\u201dmarkerobject. With\nthis special marker possibly occupying buckets in our hash table, we modify our\nsearchalgorithmforerase(k)orfind(k)sothatthesearchforakeykskipsovercells\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 385 \u2014 #407\ni i\n9.2. HashTables 385\ncontaining the available marker and continue probing until reaching the desired\nentryoranemptybucket(orreturningbacktowherewestarted). Additionally, our\nalgorithm for put(k,v) should remember an available cell encountered during the\nsearchfork,sincethisisavalidplacetoputanewentry(k,v). Thus,linearprobing\nsavesspace, butitcomplicates removals.\nEvenwiththeuseoftheavailablemarkerobject,linearprobingsuffersfroman\nadditional disadvantage. It tends to cluster the entries of the map into contiguous\nruns,whichmayevenoverlap(particularly ifmorethanhalfofthecellsinthehash\ntable are occupied). Such contiguous runs of occupied hash cells causes searches\ntoslowdownconsiderably.\nQuadratic Probing\nAnotheropen-addressingstrategy,knownasquadraticprobing,involvesiteratively\ntrying the buckets A[(i+ f(j)) mod N], for j =0,1,2,..., where f(j)= j2, until\nfinding an empty bucket. As with linear probing, the quadratic-probing strategy\ncomplicatestheremovaloperation,butitdoesavoidthekindsofclusteringpatterns\nthat occur with linear probing. Nevertheless, it creates its own kind of clustering,\ncalled secondary clustering, where the set of filled array cells \u201cbounces\u201d around\nthearrayinafixedpattern. IfNisnotchosenasaprime,thenthequadratic-probing\nstrategy maynot findan emptybucket inAeven ifone exists. In fact, evenif N is\nprime, this strategy may not find an empty slot if the bucket array is at least half\nfull. Weexplorethecauseofthistypeofclusteringinanexercise(ExerciseC-9.9).\nDouble Hashing\nAnother open-addressing strategy that does not cause clustering of the kind pro-\nducedbylinearprobing orbyquadratic probingisthedouble-hashingstrategy. In\nthis approach, wechoose asecondary hash function, h\u2032, and ifh mapssome key k\nto a bucket A[i], with i=h(k), that is already occupied, then weiteratively try the\nbuckets A[(i+ f(j))mod N]next,for j=1,2,3,...,where f(j)= j h\u2032(k). Inthis\n\u00b7\nscheme, thesecondary hash function isnotallowedtoevaluate tozero; acommon\nchoiceish\u2032(k)=q (k mod q),forsomeprimenumberq<N. Also,N shouldbe\n\u2212\na prime. Moreover, we should choose a secondary hash function that attempts to\nminimizeclustering asmuchaspossible.\nThese open-addressing schemes save some space over the separate-chaining\nmethod, but they are not necessarily faster. In experimental and theoretical anal-\nyses, the chaining method is either competitive or faster than the other methods,\ndepending ontheloadfactor ofthebucket array. So,ifmemoryspace isnotama-\njorissue,thecollision-handling methodofchoiceseemstobeseparate chaining.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 386 \u2014 #408\ni i\n386 Chapter9. HashTables,Maps,andSkipLists\n9.2.6 Load Factors and Rehashing\nInall ofthe hash-table schemes described above, theload factor, \u03bb=n/N, should\nbe kept below 1. Experiments and average-case analyses suggest that we should\nmaintain\u03bb<0.5fortheopen-addressing schemesandweshouldmaintain\u03bb<0.9\nforseparatechaining.\nAs we explore in Exercise C-9.9, some open-addressing schemes can start to\nfail when \u03bb 0.5. Although the details of the average-case analysis of hashing\n\u2265\nare beyond the scope of this book, its probabilistic basis is quite intuitive. If our\nhash function is good, then we expect the hash function values to be uniformly\ndistributed in the range [0,N 1]. Thus, to store nitems in our map, the expected\n\u2212\nnumberofkeysinabucketwouldbe n/N atmost,whichisO(1)ifnisO(N).\n\u2308 \u2309\nWith open addressing, as the load factor \u03bb grows beyond 0.5 and starts ap-\nproaching 1, clusters of items in the bucket array start to grow as well. These\nclusterscausetheprobingstrategiesto\u201cbouncearound\u201dthebucketarrayforacon-\nsiderable amount of time before they can finish. At the limit, when \u03bb is close to\n1, all map operations have linear expected running times, since, in this case, we\nexpect toencounter alinear number of occupied buckets before finding one of the\nfewremainingemptycells.\nRehashing into a New Table\nKeepingtheloadfactorbelowacertainthresholdisvitalforopen-addressingschemes\nandisalsoofconcern totheseparate-chaining method. Iftheloadfactorofahash\ntable goes significantly above a specified threshold, then it is common to require\nthat the table be resized (to regain the specified load factor) and all the objects in-\nsertedintothisnewresizedtable. Indeed,ifweletourhashtablebecomefull,some\nimplementations may crash. When rehashing to a new table, a good requirement\nis having the new array\u2019s size be at least double the previous size. Once we have\nallocated this new bucket array, we must define a new hash function to go with it\n(possiblycomputingnewparameters,asintheMADmethod). Giventhisnewhash\nfunction, we then reinsert every item from the old array into the new array using\nthisnewhashfunction. Thisprocessisknownasrehashing.\nEvenwithperiodic rehashing, ahash tableisanefficientmeansofimplement-\ning anunordered map. Indeed, ifwealways double the sizeof thetable witheach\nrehashing operation, then we can amortize the cost of rehashing all the elements\nin the table against the time used to insert them in the first place. The analysis\nof this rehashing process is similar to that used to analyze vector growth. (See\nSection 6.1.3.) Eachrehashing generally scatters theelements throughout the new\nbucket array. Thus, a hash table is a practical and effective implementation for an\nunordered map.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 387 \u2014 #409\ni i\n9.2. HashTables 387\n9.2.7 A C++ Hash Table Implementation\nInCodeFragments9.6through9.13,wepresentaC++implementation ofthemap\nADT, called HashMap, which is based on hashing with separate chaining. The\nclass is templated with the key type K, the value typeV, and the hash comparator\ntypeH. Thehashcomparatordefinesafunction,hash(k),whichmapsakeyintoan\nintegerindex. Aswithless-thancomparators(seeSection8.1.2),ahashcomparator\nclassdoesthisbyoverridingthe\u201c()\u201doperator.\nWe present the general class structure in Code Fragment 9.6. The definition\nbegins with the public types required by the map interface, the entry type Entry,\nand the iterator type Iterator. This is followed by the declarations of the public\nmember functions. We then give the private member data, which consists of the\nnumber of entries n, the hash comparator function hash, and the bucket array B.\nWe have omitted two sections, which are filled in later. The first is a declaration\nof some utility types and functions and the second is the declaration of the map\u2019s\niteratorclass.\ntemplate <typename K, typename V, typename H>\nclass HashMap\n{\npublic: // public types\ntypedef Entry<const K,V> Entry; // a (key,value) pair\nclass Iterator; // a iterator/position\npublic: // public functions\nHashMap(int capacity = 100); // constructor\nint size() const; // number of entries\nbool empty() const; // is the map empty?\nIterator find(const K& k); // find entry with key k\nIterator put(const K& k, const V& v); // insert/replace (k,v)\nvoid erase(const K& k); // remove entry with key k\nvoid erase(const Iterator& p); // erase entry at p\nIterator begin(); // iterator to first entry\nIterator end(); // iterator to end entry\nprotected: // protected types\ntypedef std::list<Entry> Bucket; // a bucket of entries\ntypedef std::vector<Bucket> BktArray; // a bucket array\n// ...insert HashMap utilities here\nprivate:\nint n; // number of entries\nH hash; // the hash comparator\nBktArray B; // bucket array\npublic: // public types\n// ...insert Iterator class declaration here\n;\n}\nCodeFragment9.6: TheclassHashMap,whichimplementsthemapADT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 388 \u2014 #410\ni i\n388 Chapter9. HashTables,Maps,andSkipLists\nWe have defined the key part of Entry to be \u201cconst K,\u201d rather than \u201cK.\u201d This\nprevents a user from inadvertently modifying a key. The class makes use of two\nmajordatatypes. ThefirstisanSTLlistofentries, calledaBucket,eachstoring a\nsinglebucket. TheotherisanSTLvectorofbuckets, calledBktArray.\nBeforedescribingthemainelementsoftheclass,weintroduceafewlocal(pro-\ntected) utilities in Code Fragment 9.7. We declare three helper functions, finder,\ninserter,anderaser,which,respectively, handlethelow-leveldetailsoffinding,in-\nserting, and removing entries. For convenience, we define two iterator types, one\ncalledBItorforiterating overthebucketsofthebucketarray,andonecalledEItor,\nforiteratingovertheentriesofabucket. Wealsogivetwoutilityfunctions,nextBkt\nandendOfBkt,whichareusedtoiteratethroughtheentriesofasinglebucket.\nIterator finder(const K& k); // find utility\nIterator inserter(const Iterator& p, const Entry& e); // insert utility\nvoid eraser(const Iterator& p); // remove utility\ntypedef typename BktArray::iterator BItor; // bucket iterator\ntypedef typename Bucket::iterator EItor; // entry iterator\nstatic void nextEntry(Iterator& p) // bucket\u2019s next entry\n++p.ent;\n{ }\nstatic bool endOfBkt(const Iterator& p) // end of bucket?\nreturn p.ent == p.bkt >end();\n{ \u2212 }\nCodeFragment9.7: Declarations ofutilitiestobeinserted intoHashMap.\nWepresent the class Iterator in Code Fragment 9.8. Aniterator needs tostore\nenoughinformationaboutthepositionofanentrytoallowittonavigate. Themem-\nbers ent, bkt, and ba store, respectively, an iterator to the current entry, the bucket\ncontaining this entry, and thebucket array containing thebucket. Thefirsttwoare\nof types EItor and BItor, respectively, and the third is a pointer. Our implementa-\ntionisminimal. Inadditiontoaconstructor,weprovideoperatorsfordereferencing\n(\u201c*\u201d),testing equality(\u201c==\u201d),andadvancing through themap(\u201c++\u201d).\nclass Iterator // an iterator (& position)\n{\nprivate:\nEItor ent; // which entry\nBItor bkt; // which bucket\nconst BktArray* ba; // which bucket array\npublic:\nIterator(const BktArray& a, const BItor& b, const EItor& q = EItor())\n: ent(q), bkt(b), ba(&a)\n{ }\nEntry& operator*() const; // get entry\nbool operator==(const Iterator& p) const; // are iterators equal?\nIterator& operator++(); // advance to next entry\nfriend class HashMap; // give HashMap access\n;\n}\nCodeFragment9.8: DeclarationoftheIteratorclassforHashMap.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 389 \u2014 #411\ni i\n9.2. HashTables 389\nIterator Dereferencing and Condensed Function Definitions\nLet us now present the definitions of the class member functions for our map\u2019s\nIterator class. In Code Fragment 9.9, we present an implementation of the deref-\nerencing operator. The function body itself is very simple and involves return-\ning a reference to the corresponding entry. However, the rules of C++ syntax de-\nmandanextraordinary numberoftemplate qualifiers. First,weneed toqualify the\nfunction itself as being a member of HashMap\u2019s iterator class, which we do with\nthe qualifier HashMap<K,V,H>::Iterator. Second, we need to qualify the func-\ntion\u2019s return type as being HashMap\u2019s entry class, which we do with the qualifier\nHashMap<K,V,H>::Entry. On top of this, we must recall from Section 8.2.1 that,\nsince we are using a template parameter to define a type, we need to include the\nkeywordtypename.\ntemplate <typename K, typename V, typename H> // get entry\ntypename HashMap<K,V,H>::Entry&\nHashMap<K,V,H>::Iterator::operator*() const\nreturn *ent;\n{ }\nCodeFragment9.9: TheIteratordereferencing operator(complete form).\nInordertomakeourfunction definitions morereadable, weadopt anotational\nconventioninsomeofourfuturecodefragmentsofspecifyingthescopingqualifier\nforthecodefragmentinitalicbluefont. Weomitthisqualifierfromthecodefrag-\nment, and we also omit the template statement and the typename specifications.\nAddingthesebackisasimplemechanical exercise. AlthoughthisisnotvalidC++\nCaution syntax, it conveys the important content in a much more succinct manner. An ex-\nampleofthesamedereferencing operator isshowninCodeFragment9.10.\n/* HashMap K,V,H :: */ // get entry\nh i\nEntry& Iterator::operator*() const\nreturn *ent;\n{ }\nCode Fragment 9.10: The same dereferencing operator of Code Fragment 9.9 in\ncondensed form.\nDefinitions of the Other Iterator Member Functions\nLetusnextconsidertheIteratoroperator\u201coperator==(p),\u201dwhichtestswhether\nthisiteratorisequaltoiterator p. Wefirstcheckthattheybelongtothesamebucket\narray and the same bucket within this array. If not, the iterators certainly differ.\nOtherwise, wecheckwhethertheybothrefertotheendofthebucket array. (Since\nwehave established that the buckets areequal, it suffices totest just one ofthem.)\nIf so, they are both equal to HashMap::end(). If not, we check whether they both\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 390 \u2014 #412\ni i\n390 Chapter9. HashTables,Maps,andSkipLists\nrefertothesameentryofthebucket. Thisisimplemented inCodeFragment9.11.\n/* HashMap K,V,H :: */ // are iterators equal?\nh i\nbool Iterator::operator==(const Iterator& p) const\n{\nif (ba != p.ba bkt != p.bkt) return false; // ba or bkt differ?\n||\nelse if (bkt == ba >end()) return true; // both at the end?\n\u2212\nelse return (ent == p.ent); // else use entry to decide\n}\nCodeFragment9.11: TheIteratoroperators forequalitytestingandincrement.\nNext, let us consider the Iterator increment operator, shown in Code Frag-\nment 9.12. The objective is to advance the iterator to the next valid entry. Typ-\nically, this involves advancing to the next entry within the current bucket. But, if\nwefall off the end ofthis bucket, wemust advance tothe first element of the next\nnonemptybucket. Todothis,wefirstadvancetothenextbucketentrybyapplying\nthe STLincrement operator on the entry iterator ent. Wethen use the utility func-\ntion endOfBkt to determine whether we have arrived at the end of this bucket. If\nso, we search for the next nonempty bucket. To do this, we repeatedly increment\nbkt and check whether we have fallen off the end of the bucket array. If so, this is\nthe end of the map and we are done. Otherwise, we check whether the bucket is\nempty. Whenwefirstfindanonemptybucket,wemoveenttothefirstentryofthis\nbucket.\n/* HashMap K,V,H :: */ // advance to next entry\nh i\nIterator& Iterator::operator++()\n{\n++ent; // next entry in bucket\nif (endOfBkt(*this)) // at end of bucket?\n{\n++bkt; // go to next bucket\nwhile (bkt != ba >end() && bkt >empty()) // find nonempty bucket\n\u2212 \u2212\n++bkt;\nif (bkt == ba >end()) return *this; // end of bucket array?\n\u2212\nent = bkt >begin(); // first nonempty entry\n\u2212\n}\nreturn *this; // return self\n}\nCodeFragment9.12: TheIteratoroperators forequalitytestingandincrement.\nDefinitions of the HashMap Member Functions\nBeforediscussingthemainfunctionsofclassHashMap,letuspresentthefunctions\nbegin and end. These are given in Code Fragment 9.13. The function end is the\nsimplerofthetwo. Itinvolvesgeneratinganiteratorwhosebucketcomponentisthe\nendofthebucketarray. Wedonotbothertospecifyavaluefortheentrypartofthe\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 391 \u2014 #413\ni i\n9.2. HashTables 391\niterator. Thereasonisthatouriteratorequalitytest(showninCodeFragment9.11)\ndoesnotbothertocomparetheentryiteratorvaluesifthebucketiteratorsareatthe\nendofthebucket array.\n/* HashMap K,V,H :: */ // iterator to end\nh i\nIterator end()\nreturn Iterator(B, B.end());\n{ }\n/* HashMap K,V,H :: */ // iterator to front\nh i\nIterator begin()\n{\nif (empty()) return end(); // emtpty - return end\nBItor bkt = B.begin(); // else search for an entry\nwhile (bkt >empty()) ++bkt; // find nonempty bucket\n\u2212\nreturn Iterator(B, bkt, bkt >begin()); // return first of bucket\n\u2212\n}\nCodeFragment9.13:ThefunctionsofHashMapreturningiteratorstothebeginning\nandendofthemap.\nThe function begin, shown in the bottom part of Code Fragment 9.13, ismore\ncomplex, since we need to search for a nonempty bucket. We first check whether\nthemapisempty. Ifso,wesimplyreturn themap\u2019send. Otherwise, starting atthe\nbeginningofthebucketarray,wesearchforanonemptybucket. (Weknowwewill\nsucceedinfindingone.) Oncewefindit,wereturnaniteratorthatpointstothefirst\nentryofthisbucket.\nNow that we have presented the iterator-related functions, we are ready to\npresent the functions for class HashMap. We begin with the constructor and sim-\nple container functions. The constructor is given the bucket array\u2019s capacity and\ncreatesavectorofthissize. Thememberntracksthenumberofentries. Theseare\ngiveninCodeFragment9.14.\n/* HashMap K,V,H :: */ // constructor\nh i\nHashMap(int capacity) : n(0), B(capacity)\n{ }\n/* HashMap K,V,H :: */ // number of entries\nh i\nint size() const return n;\n{ }\n/* HashMap K,V,H :: */ // is the map empty?\nh i\nbool empty() const return size() == 0;\n{ }\nCodeFragment9.14: Theconstructor andstandard functions forHashMap.\nNext, we present the functions related to finding keys in the top part of Code\nFragment 9.15. Most of the work is done by the utility function finder. It first\napplies the hash function associated with the given hash comparator to the key k.\nIt converts this to an index into the bucket array by taking the hash value modulo\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 392 \u2014 #414\ni i\n392 Chapter9. HashTables,Maps,andSkipLists\nthe array size. To obtain an iterator to the desired bucket, we add this index to\nthe beginning iterator of the bucket array. (We are using the fact mentioned in\nSection 6.1.4 that STL vectors provide a random access iterator, so addition is\nallowed.) Let bkt be an iterator to this bucket. We create an iterator p, which is\ninitialized to the beginning of this bucket. We then perform a search for an entry\nwhosekeymatcheskoruntilwefallofftheendofthelist. Ineithercase,wereturn\nthefinalvalueoftheiteratorasthesearchresult.\n/* HashMap K,V,H :: */ // find utility\nh i\nIterator finder(const K& k)\n{\nint i = hash(k) % B.size(); // get hash index i\nBItor bkt = B.begin() + i; // the ith bucket\nIterator p(B, bkt, bkt >begin()); // start of ith bucket\n\u2212\nwhile (!endOfBkt(p) && (*p).key() != k) // search for k\nnextEntry(p);\nreturn p; // return final position\n}\n/* HashMap K,V,H :: */ // find key\nh i\nIterator find(const K& k)\n{\nIterator p = finder(k); // look for k\nif (endOfBkt(p)) // didn\u2019t find it?\nreturn end(); // return end iterator\nelse\nreturn p; // return its position\n}\nCodeFragment9.15: Thefunctions ofHashMaprelatedtofindingkeys.\nThe public member function find is shown in the bottom part of Code Frag-\nment 9.15. It invokes the finder utility. If the entry component is at the end of the\nbucket,weknowthatthekeywasnotfound,sowereturnthespecialiteratorend()\nto the end of the map. (In this way, all unsuccessful searches produce the same\nresult.) ThisisshowninCodeFragment9.15.\nThe insertion utility, inserter, is shown in the top part of Code Fragment 9.16.\nThisutilityisgiventhedesiredpositionatwhichtoinsertthenewentry. Itinvokes\ntheSTLlistinsertfunctiontoperformtheinsertion. Italsoincrementsthecountof\nthenumberofentriesinthemapandreturns aniteratortotheinsertedposition.\nThe public insert function, put, first applies finder to determine whether any\nentry with this key exists inthe map. Wefirstdetermine whether it was not found\nby testing whether the iterator as fallen off the end of the bucket. If so, we insert\nit at the end of this bucket. Otherwise, we modify the existing value of this entry.\nLater, in Section 9.5.2, we present an alternative approach, which inserts a new\nentry,evenwhenaduplicate keyisdiscovered.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 393 \u2014 #415\ni i\n9.2. HashTables 393\n/* HashMap K,V,H :: */ // insert utility\nh i\nIterator inserter(const Iterator& p, const Entry& e)\n{\nEItor ins = p.bkt >insert(p.ent, e); // insert before p\n\u2212\nn++; // one more entry\nreturn Iterator(B, p.bkt, ins); // return this position\n}\n/* HashMap K,V,H :: */ // insert/replace (v,k)\nh i\nIterator put(const K& k, const V& v)\n{\nIterator p = finder(k); // search for k\nif (endOfBkt(p)) // k not found?\n{\nreturn inserter(p, Entry(k, v)); // insert at end of bucket\n}\nelse // found it?\n{\np.ent >setValue(v); // replace value with v\n\u2212\nreturn p; // return this position\n}\n}\nCodeFragment9.16: ThefunctionsofHashMapforinsertingandreplacingentries.\nThe removal functions are also quite straightforward and are given in Code\nFragment 9.17. The main utility is the function eraser, which removes an entry at\na given position by invoking the STL list erase function. It also decrements the\nnumberofentries. Theiterator-based removalfunction simplyinvokeseraser. The\nkey-based removalfunctionfirstappliesthefinderutilitytolookupthekey. Ifitis\nnot found, that is, if the returned position is the end of the bucket, an exception is\nthrown. Otherwise,theeraserutilityisinvoked toremovetheentry.\n/* HashMap K,V,H :: */ // remove utility\nh i\nvoid eraser(const Iterator& p)\n{\np.bkt >erase(p.ent); // remove entry from bucket\n\u2212\nn ; // one fewer entry\n\u2212\u2212\n}\n/* HashMap K,V,H :: */ // remove entry at p\nh i\nvoid erase(const Iterator& p)\neraser(p);\n{ }\n/* HashMap K,V,H :: */ // remove entry with key k\nh i\nvoid erase(const K& k)\n{\nIterator p = finder(k); // find k\nif (endOfBkt(p)) // not found?\nthrow NonexistentElement(\"Erase of nonexistent\"); // ...error\neraser(p); // remove it\n}\nCodeFragment9.17: Thefunctions ofHashMapinvolved withremovingentries.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 394 \u2014 #416\ni i\n394 Chapter9. HashTables,Maps,andSkipLists\n9.3 Ordered Maps\nIn some applications, simply looking up values based on associated keys is not\nenough. Weoften also want tokeep the entries in amapsorted according tosome\ntotal order and be able to look up keys and values based on this ordering. That is,\ninanorderedmap,wewanttoperformtheusualmapoperations,butalsomaintain\nan order relation for the keys in our map and use this order in some of the map\nfunctions. We can use a comparator to provide the order relation among keys,\nallowing us to define an ordered map relative to this comparator, which can be\nprovided totheorderedmapasanargument toitsconstructor.\nWhen the entries of a map are stored in order, we can provide efficient im-\nplementations for additional functions in the map ADT.Aswith the standard map\nADT, in order to indicate that an object is not present, the class provides a spe-\ncial sentinel iterator called end. The ordered map includes all the functions of the\nstandard mapADTplusthefollowing:\nfirstEntry(k): Returnaniteratortotheentrywithsmallestkeyvalue;if\nthemapisempty,itreturnsend.\nlastEntry(k): Return an iterator to the entry with largest key value; if\nthemapisempty,itreturnsend.\nceilingEntry(k): Return an iterator to the entry with the least key value\ngreater than or equal to k; if there is no such entry, it\nreturns end.\nfloorEntry(k): Returnaniteratortotheentrywiththegreatestkeyvalue\nlessthanorequaltok;ifthereisnosuchentry,itreturns\nend.\nlowerEntry(k): Returnaniteratortotheentrywiththegreatestkeyvalue\nlessthank;ifthereisnosuchentry,itreturns end.\nhigherEntry(k): Return an iterator to the entry with the least key value\ngreater thank;ifthereisnosuchentry,itreturns end.\nImplementing an Ordered Map\nTheordered nature oftheoperations givenabovefortheordered mapADTmakes\nthe use of an unordered list or a hash table inappropriate, because neither of these\ndatastructuresmaintainsanyorderinginformationforthekeysinthemap. Indeed,\nhash tables achieve theirbest search speeds whentheir keys aredistributed almost\nat random. Thus, we should consider an alternative implementation when dealing\nwithorderedmaps. Wediscussonesuchimplementationnext,andwediscussother\nimplementations inSection9.4andChapter10.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 395 \u2014 #417\ni i\n9.3. OrderedMaps 395\n9.3.1 Ordered Search Tables and Binary Search\nIf the keys in a map come from a total order, we can store the map\u2019s entries in a\nvector L in increasing order of the keys. (See Figure 9.6.) We specify that L is\na vector, rather than a node list, because the ordering of the keys in the vector L\nallows for faster searching than would be possible had L been, say, implemented\nwith a linked list. Admittedly, a hash table has good expected running time for\nsearching. But itsworst-case time for searching is no better than a linked list, and\ninsomeapplications,suchasinreal-timeprocessing,weneedtoguaranteeaworst-\ncasesearchingbound. Thefastalgorithmforsearchinginanorderedvector,which\nwediscussinthissubsection, hasagoodworst-caseguarantee onitsrunning time.\nSo it might be preferred over a hash table in certain applications. We refer to this\norderedvectorimplementation ofamapasanordered searchtable.\nFigure 9.6: Realization of a map by means of an ordered search table. We show\nonlythekeysforthismapinordertohighlight theirordering.\nThe space requirement of an ordered search table is O(n), which is similar to\nthe list-based map implementation (Section 9.1.4), assuming we grow and shrink\nthe array supporting the vector L to keep the size of this array proportional to the\nnumber of entries in L. Unlike an unordered list, however, performing updates in\na search table takes a considerable amount of time. In particular, performing the\ninsert(k,v)operationinasearchtablerequiresO(n)timeintheworstcase,sincewe\nneedtoshiftupalltheentriesinthevectorwithkeygreaterthanktomakeroomfor\nthe new entry (k,v). A similar observation applies tothe operation erase(k), since\nit takes O(n) time in the worst case to shift all the entries in the vector with key\ngreaterthanktoclosethe\u201chole\u201dleftbytheremovedentry(orentries). Thesearch\ntableimplementationisthereforeinferiortothelinkedlistimplementationinterms\nof the worst-case running times of the map update operations. Nevertheless, we\ncanperformthefindfunctionmuchfasterinasearchtable.\nBinary Search\nA significant advantage of using an ordered vector L to implement a map with n\nentries is that accessing an element of L by its index takes O(1) time. We recall,\nfromSection6.1,thattheindexofanelementinavectoristhenumberofelements\npreceding it. Thus, the first element in L has index 0, and the last element has\nindex n 1. In this subsection, we give a classic algorithm, binary search, to\n\u2212\nlocate an entry in an ordered search table. Weshow how this method can be used\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 396 \u2014 #418\ni i\n396 Chapter9. HashTables,Maps,andSkipLists\ntoquickly perform the findfunction ofthe mapADT,but asimilar method can be\nused for each of the ordered-map functions, ceilingEntry, floorEntry, lowerEntry,\nandhigherEntry.\nTheelementsstoredinLaretheentriesofamap,andsinceLisordered,theen-\ntryatindexihasakeynosmallerthanthekeysoftheentriesatindices0,...,i 1,\n\u2212\nandnolargerthanthekeysoftheentriesatindicesi+1,...,n 1. Thisobservation\n\u2212\nallows us to quickly \u201chome in\u201d on a search key k using a variant of the children\u2019s\ngame \u201chigh-low.\u201d We call an entry of our map a candidate if, at the current stage\nof the search, we cannot rule out that this entry has key equal to k. Thealgorithm\nmaintains two parameters, low and high, such that all the candidate entries have\nindex at least low and at most high in L. Initially, low=0 and high=n 1. We\n\u2212\nthencomparektothekeyofthemediancandidate e,thatis,theentryewithindex\nmid= (low+high)/2 .\n\u230a \u230b\nWeconsiderthreecases:\nIf k =e.key(), then we have found the entry we were looking for, and the\n\u2022\nsearchterminates successfully returning e\nIf k < e.key(), then we recur on the first half of the vector, that is, on the\n\u2022\nrangeofindices fromlowtomid 1\n\u2212\nIfk>e.key(),werecurontherangeofindicesfrommid+1tohigh\n\u2022\nThis search method is called binary search, and is given in pseudo-code in Code\nFragment9.18. Operationfind(k)onann-entry mapimplementedwithanordered\nvectorLconsists ofcallingBinarySearch(L,k,0,n 1).\n\u2212\nAlgorithmBinarySearch(L,k,low,high):\nInput: AnorderedvectorLstoring nentriesandintegerslowandhigh\nOutput: Anentry of L withkey equal to k and index between low and high, if\nsuchanentryexists,andotherwisethespecialsentinel end\niflow>highthen\nreturn end\nelse\nmid (low+high)/2\n\u2190\u230a \u230b\ne L.at(mid)\n\u2190\nif k=e.key() then\nreturne\nelseif k<e.key() then\nreturnBinarySearch(L,k,low,mid 1)\n\u2212\nelse\nreturnBinarySearch(L,k,mid+1,high)\nCodeFragment9.18: Binarysearchinanordered vector.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 397 \u2014 #419\ni i\n9.3. OrderedMaps 397\nWeillustrate thebinarysearchalgorithm inFigure9.7.\nFigure 9.7: Example of a binary search to perform operation find(22), in a map\nwith integer keys, implemented with an ordered vector. For simplicity, we show\nthekeys,notthewholeentries.\nConsideringtherunningtimeofbinarysearch,weobservethataconstantnum-\nber of primitive operations are executed at each recursive call of function Binary-\nSearch. Hence, the running time is proportional to the number of recursive calls\nperformed. A crucial fact is that with each recursive call the number of candidate\nentriesstilltobesearched inthevectorLisgivenbythevalue\nhigh low+1.\n\u2212\nMoreover, thenumberofremainingcandidates isreduced byatleastonehalfwith\neachrecursivecall. Specifically, fromthedefinitionofmid,thenumberofremain-\ningcandidates iseither\nlow+high high low+1\n(mid 1) low+1= low \u2212\n\u2212 \u2212 2 \u2212 \u2264 2\n(cid:22) (cid:23)\nor\nlow+high high low+1\nhigh (mid+1)+1=high \u2212 .\n\u2212 \u2212 2 \u2264 2\n(cid:22) (cid:23)\nInitially, thenumberofcandidate entriesisn;afterthefirstcalltoBinarySearch,it\nisatmostn/2;afterthesecondcall,itisatmostn/4;andsoon. Ingeneral,afterthe\nithcalltoBinarySearch,thenumberofcandidateentriesremainingisatmostn/2i.\nIn the worst case (unsuccessful search), the recursive calls stop when there are no\nmorecandidateentries. Hence,themaximumnumberofrecursivecallsperformed,\nisthesmallestintegerm,suchthat\nn/2m <1.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 398 \u2014 #420\ni i\n398 Chapter9. HashTables,Maps,andSkipLists\nIn other words (recalling that weomit a logarithm\u2019s base when it is 2), m>logn.\nThus,wehave\nm= logn +1,\n\u230a \u230b\nwhichimpliesthatbinarysearchrunsinO(logn)time.\nThus,wecanuseanorderedsearchtabletoperformfastsearchesinanordered\nmap, but using such a table for lots of map updates would take a considerable\namount of time. For this reason, the primary applications for search tables are in\nsituations whereweexpect fewupdates butmanysearches. Suchasituation could\narise,forexample,inanorderedlistofEnglishwordsweusetoorderentriesinan\nencyclopedia orhelpfile.\nComparing Map Implementations\nNote that we can use an ordered search table to implement the map ADT even if\nwe don\u2019t want to use the additional functions of the ordered map ADT. Table 9.2\ncompares therunning timesofthefunctions ofa(standard) maprealized byeither\nan unordered list, a hash table, or an ordered search table. Note that an unordered\nlist allows for fast insertions but slow searches and removals, whereas asearch ta-\nbleallowsforfastsearchesbutslowinsertionsandremovals. Incidentally,although\nwedon\u2019t explicitly discussit,wenotethatasortedlistimplemented withadoubly\nlinked list would be slow in performing almost all the mapoperations. (SeeExer-\nciseR-9.5.) Nevertheless, thelist-like datastructure wediscuss inthenextsection\ncanperformthefunctions oftheorderedmapADTquiteefficiently.\nMethod List HashTable SearchTable\nsize,empty O(1) O(1) O(1)\nfind O(n) O(1)exp.,O(n)worst-case O(logn)\ninsert O(1) O(1) O(n)\nerase O(n) O(1)exp.,O(n)worst-case O(n)\nTable 9.2: Comparison of the running times of the functions of a map realized\nby means of an unordered list, a hash table, or an ordered search table. We let n\ndenote the number of entries in the map and we let N denote the capacity of the\nbucket array in the hash table implementation. The space requirement of all the\nimplementations is O(n), assuming that the arrays supporting the hash-table and\nsearch-tableimplementationsaremaintainedsuchthattheircapacityisproportional\ntothenumberofentriesinthemap.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 399 \u2014 #421\ni i\n9.3. OrderedMaps 399\n9.3.2 Two Applications of Ordered Maps\nAswehavementionedintheprecedingsections,unorderedandorderedmapshave\nmanyapplications. Inthissection,weexploresomespecificapplicationsofordered\nmaps.\nFlight Databases\nThere are several web sites on the Internet that allow users to perform queries on\nflight databases to find flights between various cities, typically with the intent of\nbuying a ticket. To make a query, a user specifies origin and destination cities, a\ndeparture date, and a departure time. To support such queries, we can model the\nflight database as a map, where keys are Flight objects that contain fields corre-\nsponding tothesefourparameters. Thatis,akeyisatuple\nk=(origin, destination, date, time).\nAdditionalinformationaboutaflight,suchastheflightnumber,thenumberofseats\nstill available in first (F) and coach (Y)class, the flight duration, and the fare, can\nbestoredinthevalueobject.\nFinding a requested flight is not simply a matter of finding a key in the map\nmatchingtherequested query,however. Themaindifficultyisthat,althoughauser\ntypically wants to exactly match the origin and destination cities, as well as the\ndeparture date, he or she will probably be content with any departure time that is\nclosetohisorherrequesteddeparturetime. Wecanhandlesuchaquery,ofcourse,\nby ordering our keys lexicographically. Thus, given auser query key k, wecould,\nfor instance, call ceilingEntry(k) to return the flight between the desired cities on\nthe desired date, with departure time at the desired time or after. A similar use\nof floorEntry(k) would give us the flight with departure time at the desired time\nor before. Given these entries, we could then use the higherEntry or lowerEntry\nfunctionstofindflightswiththenextclose-bydeparturetimesthatarerespectively\nhigherorlowerthanthedesiredtime,k. Therefore,anefficientimplementation for\nanordered mapwouldbeagoodwaytosatisfysuchqueries. Forexample, calling\nceilingEntry(k) on a query key k=(ORD, PVD, 05May, 09:30), followed by the\nrespective callstohigherEntry,mightresultinthefollowingsequence ofentries:\n((ORD, PVD, 05May, 09:53), (AA 1840, F5, Y15, 02:05, $251))\n((ORD, PVD, 05May, 13:29), (AA 600, F2, Y0, 02:16, $713))\n((ORD, PVD, 05May, 17:39), (AA 416, F3, Y9, 02:09, $365))\n((ORD, PVD, 05May, 19:50), (AA 1828, F9, Y25, 02:13, $186))\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 400 \u2014 #422\ni i\n400 Chapter9. HashTables,Maps,andSkipLists\nMaxima Sets\nLifeisfulloftrade-offs. Weoftenhavetotradeoffadesiredperformancemeasure\nagainstacorrespondingcost. Suppose,forthesakeofanexample,weareinterested\nin maintaining a database rating automobiles by their maximum speeds and their\ncost. Wewouldliketoallowsomeonewithacertainamounttospendtoqueryour\ndatabase tofindthefastestcartheycanpossibly afford.\nWe can model such a trade-off problem as this by using a key-value pair to\nmodel the two parameters that we are trading off, which in this case would be the\npair (cost,speed) for each car. Notice that some cars are strictly better than other\ncars using this measure. For example, a car with cost-speed pair (20,000, 100) is\nstrictlybetterthanacarwithcost-speed pair(30,000, 90). Atthesametime,there\nare some cars that are not strictly dominated by another car. For example, a car\nwith cost-speed pair (20,000, 100) may be better or worse than a car with cost-\nspeed pair (30,000, 120), depending onhow muchmoneywehave tospend. (See\nFigure9.8.)\nFigure 9.8: The cost-performance trade-off with key-value pairs represented by\npoints intheplane. Noticethat point pisstrictly better than points c,d,ande, but\nmaybebetterorworsethanpoints a,b, f,g,andh,depending onthepriceweare\nwillingtopay. Thus, ifweweretoadd ptoourset, wecould removethepoints c,\nd,ande,butnottheothers.\nFormally,wesayaprice-performancepair(a,b)dominatesapair(c,d)ifa<c\nandb>d. Apair(a,b)iscalledamaximumpairifitisnotdominatedbyanyother\npairs. WeareinterestedinmaintainingthesetofmaximaofacollectionCofprice-\nperformance pairs. That is, we would like to add new pairs to this collection (for\nexample,whenanewcarisintroduced), andwewouldliketoquerythiscollection\nforagivendollaramount,d,tofindthefastestcarthatcostsnomorethanddollars.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 401 \u2014 #423\ni i\n9.3. OrderedMaps 401\nMaintaining a Maxima Set with an Ordered Map\nWecanstorethesetofmaximapairsinanorderedmap,M,orderedbycost,sothat\nthe cost is the key field and performance (speed) is the value field. We can then\nimplement operations add(c,p), which adds a new cost-performance pair (c,p),\nand best(c), which returns the best pair with cost at most c, as shown in Code\nFragments9.19and9.20.\nAlgorithmbest(c):\nInput: Acostc\nOutput: Thecost-performance pairinM withlargest costless thanorequalto\nc,orthespecial sentinelend,ifthereisnosuchpair\nreturnM.floorEntry(c)\nCodeFragment9.19: Thebest()function, usedinaclassmaintainingasetofmax-\nimaimplemented withanordered mapM.\nAlgorithmadd(c,p):\nInput: Acost-performance pair(c,p)\nOutput: None (but M will have (c,p) added to the set of cost-performance\npairs)\ne M.floorEntry(c) thegreatest pairwithcostatmostc\n\u2190 { }\nife=endthen\n6\nife.value()> pthen\nreturn (c,p)isdominated, sodon\u2019tinsertitinM\n{ }\ne M.ceilingEntry(c) nextpairwithcostatleastc\n\u2190 { }\nRemoveallthepairsthataredominatedby(c,p)\n{ }\nwhilee=end and e.value()< pdo\n6\nM.erase(e.key()) thispairisdominatedby(c,p)\n{ }\ne M.higherEntry(e.key()) thenextpairaftere\n\u2190 { }\nM.put(c,p) Addthepair(c,p),whichisnotdominated\n{ }\nCodeFragment9.20: Theadd(c,p)functionusedinaclassformaintainingasetof\nmaximaimplementedwithanorderedmapM.\nUnfortunately, if we implement M using any of the data structures described\nabove, it results in a poor running time for the above algorithm. If, on the other\nhand, we implement M using a skip list, which we describe next, then we can\nperformbest(c)queriesinO(logn)expectedtimeandadd(c,p)updatesinO((1+\nr)logn)expectedtime,whereristhenumberofpointsremoved.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 402 \u2014 #424\ni i\n402 Chapter9. HashTables,Maps,andSkipLists\n9.4 Skip Lists\nAn interesting data structure for efficiently realizing the ordered map ADT is the\nskiplist. Thisdatastructuremakesrandomchoicesinarrangingtheentriesinsuch\nawaythatsearchandupdatetimesareO(logn)onaverage,wherenisthenumber\nof entries in the dictionary. Interestingly, the notion of average time complexity\nused here does not depend on the probability distribution of the keys in the input.\nInstead,itdependsontheuseofarandom-numbergeneratorintheimplementation\nof the insertions to help decide where to place the new entry. The running time is\naveraged over all possible outcomes of the random numbers used when inserting\nentries.\nBecausetheyareusedextensively incomputergames,cryptography, andcom-\nputer simulations, functions that generate numbers that can be viewed as random\nnumbers are built into most modern computers. Some functions, called pseudo-\nrandomnumbergenerators,generaterandom-likenumbers,startingwithaninitial\nseed. Otherfunctionsusehardwaredevicestoextract\u201ctrue\u201drandomnumbersfrom\nnature. In any case, we assume that our computer has access to numbers that are\nsufficiently randomforouranalysis.\nThe main advantage of using randomization in data structure and algorithm\ndesignisthatthestructuresandfunctionsthatresultareusuallysimpleandefficient.\nWecandeviseasimplerandomizeddatastructure,calledtheskiplist,whichhasthe\nsamelogarithmic timeboundsforsearching asisachieved bythebinary searching\nalgorithm. Nevertheless, the bounds are expected for the skip list, while they are\nworst-case bounds for binary searching ina lookup table. Onthe other hand, skip\nlistsaremuchfasterthanlookuptablesformapupdates.\nAskip list S foramap M consists ofaseries oflists S ,S ,...,S . Eachlist\n0 1 h\n{ }\nS stores a subset of the entries of M sorted by increasing keys plus entries with\ni\ntwospecialkeys,denoted and+ ,where issmallerthaneverypossible\n\u2212\u221e \u221e \u2212\u221e\nkeythatcanbeinserted inM and+ islargerthaneverypossible keythatcanbe\n\u221e\ninserted inM. Inaddition, thelistsinSsatisfythefollowing:\nListS contains everyentryofthemapM (plusthespecialentries withkeys\n0\n\u2022\nand+ )\n\u2212\u221e \u221e\nFori=1,...,h 1,listS contains(inadditionto and+ )arandomly\ni\n\u2022 \u2212 \u2212\u221e \u221e\ngenerated subsetoftheentriesinlistS\ni\u22121\nListS contains only and+ .\nh\n\u2022 \u2212\u221e \u221e\nAnexampleofaskiplistisshowninFigure9.9. Itiscustomarytovisualizeaskip\nlist S with list S at the bottom and lists S ,...,S above it. Also, we refer to h as\n0 1 h\ntheheightofskiplistS.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 403 \u2014 #425\ni i\n9.4. SkipLists 403\nFigure9.9: Example ofaskip list storing 10 entries. Forsimplicity, weshow only\nthekeysoftheentries.\nIntuitively, the lists are set up so that S contains more or less every other\ni+1\nentryinS. Ascanbeseeninthedetailsoftheinsertionmethod,theentriesinS\ni i+1\nare chosen at random from the entries in S by picking each entry from S to also\ni i\nbeinS withprobability 1/2. Thatis, inessence, we\u201cflipacoin\u201dforeachentry\ni+1\ninS andplace thatentry inS ifthecoincomesup\u201cheads.\u201d Thus, weexpectS\ni i+1 1\nto have about n/2 entries, S to have about n/4 entries, and, in general, S to have\n2 i\nabout n/2i entries. In other words, we expect the height h of S to be about logn.\nThehalving ofthenumberofentries fromonelisttothenextisnotenforced asan\nexplicitproperty ofskiplists,however. Instead, randomization isused.\nUsing the position abstraction used for lists and trees, we view a skip list as a\ntwo-dimensional collection of positions arranged horizontally into levels and ver-\ntically intotowers. EachlevelisalistS and each towercontains positions storing\ni\nthesameentryacrossconsecutivelists. Thepositionsinaskiplistcanbetraversed\nusingthefollowingoperations:\nafter(p): Returntheposition following ponthesamelevel.\nbefore(p): Returntheposition preceding ponthesamelevel.\nbelow(p): Returntheposition below pinthesametower.\nabove(p): Returntheposition above pinthesametower.\nWe conventionally assume that the above operations return a null position if the\nposition requested does not exist. Without going into the details, we note that we\ncaneasily implement askiplistbymeansofalinked structure such thattheabove\ntraversal functions each takeO(1)time, givenaskip-list position p. Suchalinked\nstructureisessentiallyacollectionofhdoublylinkedlistsalignedattowers,which\narealsodoublylinkedlists.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 404 \u2014 #426\ni i\n404 Chapter9. HashTables,Maps,andSkipLists\n9.4.1 Search and Update Operations in a Skip List\nTheskipliststructureallowsforsimplemapsearchandupdatealgorithms. Infact,\nalloftheskiplistsearchandupdatealgorithmsarebasedonanelegantSkipSearch\nfunctionthattakesakeykandfindstheposition poftheentryeinlistS suchthat\n0\nehasthelargestkey(whichispossibly )lessthanorequaltok.\n\u2212\u221e\nSearching in a Skip List\nSupposewearegivenasearchkeyk. WebegintheSkipSearchfunction bysetting\naposition variable ptothetop-most, leftposition intheskiplistS,called thestart\nposition of S. That is, the start position is the position of S storing the special\nh\nentrywithkey . Wethenperform thefollowingsteps(seeFigure9.10),where\n\u2212\u221e\nkey(p)denotesthekeyoftheentryatposition p:\n1. If S.below(p) is null, then the search terminates\u2014we are at the bottom and\nhave located the largest entry in S with key less than or equal to the search\nkeyk. Otherwise, wedrop downtothenextlowerlevelinthepresent tower\nbysetting p S.below(p).\n\u2190\n2. Startingatposition p,wemove pforwarduntilitisattheright-mostposition\nonthepresentlevelsuchthatkey(p) k. Wecallthisthescanforwardstep.\n\u2264\nNote that such a position always exists, since each level contains the keys\n+ and . In fact, after we perform the scan forward for this level, p\n\u221e \u2212\u221e\nmayremainwhereitstarted. Inanycase,wethenrepeatthepreviousstep.\nFigure9.10:Exampleofasearchinaskiplist. Thepositionsvisitedwhensearching\nforkey50arehighlighted inblue.\nWegiveapseudo-codedescriptionoftheskip-listsearchalgorithm,SkipSearch,\nin Code Fragment 9.21. Given this function, it is now easy to implement the op-\neration find(k)\u2014we simply perform p SkipSearch(k) and test whether or not\n\u2190\nkey(p)=k. Ifthesetwokeysareequal,wereturn p;otherwise, wereturnnull.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 405 \u2014 #427\ni i\n9.4. SkipLists 405\nAlgorithmSkipSearch(k):\nInput: Asearchkeyk\nOutput: Position pinthe bottom listS such that theentry at phasthelargest\n0\nkeylessthanorequaltok\np s\n\u2190\nwhile below(p)=null do\n6\np below(p) dropdown\n\u2190 { }\nwhilek key(after(p))do\n\u2265\np after(p) scanforward\n\u2190 { }\nreturn p.\nCodeFragment9.21: SearchinaskiplistS. VariablesholdsthestartpositionofS.\nAs it turns out, the expected running time of algorithm SkipSearch on a skip\nlist with n entries is O(logn). We postpone the justification of this fact, however,\nuntilafterwediscuss theimplementation oftheupdatefunctions forskiplists.\nInsertion in a Skip List\nTheinsertionalgorithmforskiplistsusesrandomizationtodecidetheheightofthe\ntowerforthenewentry. Webegintheinsertion ofanewentry(k,v)byperforming\na SkipSearch(k) operation. This gives us the position p of the bottom-level entry\nwith the largest key less than or equal to k (note that p may hold the special entry\nwith key ). We then insert (k,v) immediately after position p. After inserting\n\u2212\u221e\nthe new entry at the bottom level, we \u201cflip\u201d a coin. If the flipcomes up tails, then\nwe stop here. Else (the flip comes up heads), we backtrack to the previous (next\nhigher) level and insert (k,v) in this level at the appropriate position. We again\nflip a coin; if it comes up heads, we go to the next higher level and repeat. Thus,\nwe continue to insert the new entry (k,v) in lists until we finally get a flip that\ncomes up tails. We link together all the references to the new entry (k,v) created\nin this process to create the tower for the new entry. A coin flip can be simulated\nwithC++\u2019sbuilt-in,pseudo-randomnumbergeneratorbytestingwhetherarandom\nintegerisevenorodd.\nWegivetheinsertion algorithm foraskiplistSinCodeFragment9.22andwe\nillustrateitinFigure9.11. ThealgorithmusesfunctioninsertAfterAbove(p,q,(k,v))\nthat inserts aposition storing the entry (k,v) after position p(on the same level as\np) and above position q, returning the position r of the new entry (and setting in-\nternal references so that after, before, above, and below functions work correctly\nfor p,q,andr). Theexpected runningtimeoftheinsertion algorithm onaskiplist\nwithnentriesisO(logn),whichweshowinSection9.4.2.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 406 \u2014 #428\ni i\n406 Chapter9. HashTables,Maps,andSkipLists\nAlgorithmSkipInsert(k,v):\nInput: Keykandvaluev\nOutput: Topmostposition oftheentryinsertedintheskiplist\np SkipSearch(k)\n\u2190\nq null\n\u2190\ne (k,v)\n\u2190\ni 1\n\u2190\u2212\nrepeat\ni i+1\n\u2190\nif i h then\n\u2265\nh h+1 addanewleveltotheskiplist\n\u2190 { }\nt after(s)\n\u2190\ns insertAfterAbove(null,s,( ,null))\n\u2190 \u2212\u221e\ninsertAfterAbove(s,t,(+ ,null))\n\u221e\nwhileabove(p)=nulldo\np before(p) scanbackward\n\u2190 { }\np above(p) jumpuptohigherlevel\n\u2190 { }\nq insertAfterAbove(p,q,e) addapositiontothetowerofthenewentry\n\u2190 { }\nuntilcoinFlip()=tails\nn n+1\n\u2190\nreturnq\nCodeFragment9.22: Insertion inaskip list. Method coinFlip()returns \u201cheads\u201d or\n\u201ctails,\u201deachwithprobability 1/2. Variablesn,h,andsholdthenumberofentries,\ntheheight, andthestartnodeoftheskiplist.\nFigure9.11: Insertion of an entry with key 42 into the skip list of Figure 9.9. We\nassume that the random \u201ccoin flips\u201d for the new entry came up heads three times\nin a row, followed by tails. The positions visited are highlighted in blue. The\npositionsinsertedtoholdthenewentryaredrawnwiththicklines,andthepositions\npreceding themareflagged.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 407 \u2014 #429\ni i\n9.4. SkipLists 407\nRemoval in a Skip List\nLike the search and insertion algorithms, the removal algorithm for a skip list is\nquite simple. In fact, it is even easier than the insertion algorithm. That is, to\nperform an erase(k) operation, we begin by executing function SkipSearch(k). If\ntheposition pstores anentrywithkeydifferent fromk,wereturn null. Otherwise,\nwe remove p and all the positions above p, which are easily accessed by using\naboveoperations toclimbupthetowerofthisentryinSstartingatposition p. The\nremoval algorithm is illustrated in Figure 9.12 and a detailed description of it is\nleftasanexercise(ExerciseR-9.17). Asweshowinthenextsubsection, operation\neraseinaskiplistwithnentrieshasO(logn)expectedrunning time.\nBefore we give this analysis, however, there are some minor improvements to\nthe skip list data structure we would like to discuss. First, we don\u2019t actually need\nto store references to entries at the levels of the skip list above the bottom level,\nbecause all that is needed at these levels are references to keys. Second, we don\u2019t\nactually needtheabovefunction. Infact,wedon\u2019tneedthebeforefunction either.\nWe can perform entry insertion and removal in strictly a top-down, scan-forward\nfashion, thus saving space for \u201cup\u201d and \u201cprev\u201d references. We explore the details\nof this optimization in Exercise C-9.10. Neither of these optimizations improve\nthe asymptotic performance of skip lists by more than a constant factor, but these\nimprovements can, nevertheless, be meaningful in practice. In fact, experimental\nevidencesuggeststhatoptimizedskiplistsarefasterinpracticethanAVLtreesand\notherbalancedsearchtrees,whicharediscussed inChapter10.\nThe expected running time of the removal algorithm is O(logn), which we\nshowinSection9.4.2.\nFigure 9.12: Removal of the entry with key 25 from the skip list of Figure 9.11.\nThe positions visited after the search for the position of S holding the entry are\n0\nhighlighted inblue. Thepositions removedaredrawnwithdashedlines.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 408 \u2014 #430\ni i\n408 Chapter9. HashTables,Maps,andSkipLists\nMaintaining the Top-most Level\nA skip list S must maintain a reference to the start position (the top-most, left\nposition in S) as a member variable, and must have a policy for any insertion that\nwishes to continue inserting a new entry past the top level of S. There are two\npossible coursesofactionwecantake,bothofwhichhavetheirmerits.\nOnepossibility istorestrict thetoplevel, h,tobekeptatsomefixedvaluethat\nis a function of n, the number of entries currently in the map (from the analysis\nweseethath=max 10,2 logn isareasonablechoice,andpickingh=3 logn\n{ \u2308 \u2309} \u2308 \u2309\nis even safer). Implementing this choice means that wemust modify the insertion\nalgorithmtostopinsertinganewpositiononcewereachthetop-mostlevel(unless\nlogn < log(n+1) ,inwhichcasewecannowgoatleastonemorelevel,since\n\u2308 \u2309 \u2308 \u2309\ntheboundontheheightisincreasing).\nThe other possibility is to let an insertion continue inserting a new position as\nlong as heads keeps getting returned from the random number generator. This is\nthe approach taken in Algorithm SkipInsert of Code Fragment 9.22. As we show\nintheanalysisofskiplists,theprobabilitythataninsertionwillgotoalevelthatis\nmorethanO(logn)isverylow,sothisdesignchoiceshouldalsowork.\nEither choice still results in the expected O(logn) time to perform search, in-\nsertion, andremoval,however,whichweshowinthenextsection.\n9.4.2 A Probabilistic Analysis of Skip Lists \u22c6\nAswehaveshownabove,skiplistsprovideasimpleimplementation ofanordered\nmap. In terms of worst-case performance, however, skip lists are not a superior\ndata structure. In fact, if we don\u2019t officially prevent an insertion from continuing\nsignificantly pastthecurrent highestlevel, thentheinsertion algorithm cangointo\nwhat is almost an infinite loop (it is not actually an infinite loop, however, since\ntheprobability ofhavingafaircoinrepeatedly comeupheadsforeveris0). More-\nover, we cannot infinitely add positions to a list without eventually running out of\nmemory. Inanycase, ifweterminate position insertion atthehighest levelh,then\ntheworst-caserunningtimeforperformingthefind,insert,anderaseoperationsin\na skip list S with n entries and height h is O(n+h). This worst-case performance\noccurswhenthetowerofeveryentryreacheslevelh 1,wherehistheheightofS.\n\u2212\nHowever, this event has very low probability. Judging from this worst case, we\nmight conclude that the skip list structure is strictly inferior to the other map im-\nplementationsdiscussedearlierinthischapter. Butthiswouldnotbeafairanalysis\nbecausethisworst-casebehavior isagrossoverestimate.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 409 \u2014 #431\ni i\n9.4. SkipLists 409\nBounding the Height of a Skip List\nBecausetheinsertionstepinvolvesrandomization,amoreaccurateanalysisofskip\nlistsinvolvesabitofprobability. Atfirst,thismightseemlikeamajorundertaking,\nsinceacompleteandthoroughprobabilistic analysiscouldrequiredeepmathemat-\nics (and, indeed, there are several such deep analyses that have appeared in the\nresearch literature related to data structures). Fortunately, such an analysis is not\nnecessary to understand the expected asymptotic behavior ofskip lists. The infor-\nmal and intuitive probabilistic analysis wegive below uses only basic concepts of\nprobability theory.\nLet us begin by determining the expected value of the height h of a skip list S\nwithnentries(assumingthatwedonotterminateinsertionsearly). Theprobability\nthatagivenentryhasatowerofheighti 1isequal totheprobability ofgetting i\n\u2265\nconsecutive headswhenflippingacoin, thatis,thisprobability is1/2i. Hence,the\nprobability P thatlevelihasatleastoneposition isatmost\ni\nn\nP ,\ni \u2264 2i\nbecausetheprobability thatanyoneofndifferent eventsoccursisatmostthesum\noftheprobabilities thateachoccurs.\nTheprobability thattheheight hofSislarger than iisequal totheprobability\nthatlevelihasatleastoneposition, thatis,itisnomorethanP. Thismeansthath\ni\nislargerthan,say,3lognwithprobability atmost\nn\nP\n3logn \u2264 23logn\nn 1\n= = .\nn3 n2\nFor example, if n=1000, this probability is a one-in-a-million long shot. More\ngenerally, given a constant c>1, h is larger than clogn with probability at most\n1/nc\u22121. Thatis, the probability that his smaller than clognisatleast 1 1/nc\u22121.\n\u2212\nThus,withhighprobability, theheighthofSisO(logn).\nAnalyzing Search Time in a Skip List\nNext, consider the running time of a search in skip list S, and recall that such a\nsearchinvolvestwonestedwhileloops. Theinnerloopperformsascanforwardon\nalevelofSaslongasthenextkeyisnogreaterthanthesearchkeyk,andtheouter\nloopdrops downtothenextlevelandrepeats thescan forwarditeration. Sincethe\nheight h of S is O(logn) with high probability, the number of drop-down steps is\nO(logn)withhighprobability.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 410 \u2014 #432\ni i\n410 Chapter9. HashTables,Maps,andSkipLists\nSowehaveyettobound thenumberofscan-forward stepswemake. Letn be\ni\nthenumberofkeysexaminedwhilescanningforwardatleveli. Observethat,after\nthe key at the starting position, each additional key examined in a scan-forward at\nlevel i cannot also belong to level i+1. If any of these keys were on the previous\nlevel, we would have encountered them in the previous scan-forward step. Thus,\ntheprobabilitythatanykeyiscountedinn is1/2. Therefore,theexpectedvalueof\ni\nn is exactly equal to the expected number of times wemust flipa fair coin before\ni\nitcomesupheads. Thisexpected valueis2.\nHence, the expected amount of time spent scanning forward at any level i\nis O(1). Since S has O(logn) levels with high probability, a search in S takes ex-\npectedtimeO(logn). Byasimilaranalysis,wecanshowthattheexpectedrunning\ntimeofaninsertion oraremovalisO(logn).\nSpace Usage in a Skip List\nFinally, let us turn to the space requirement of a skip list S with n entries. As we\nobserved above, the expected number of positions at level i is n/2i, which means\nthattheexpectedtotalnumberofpositions inSis\n\u2211 h n \u2211 h 1\n=n .\n2i 2i\ni=0 i=0\nUsingProposition 4.5ongeometricsummations, wehave\n\u2211 h 1 = 1 2 h+1 \u2212 1 =2 1 1 <2 forallh 0.\n2i 1 1 \u00b7 \u22122h+1 \u2265\ni=0 (cid:0) (cid:1)2\u2212 (cid:18) (cid:19)\nHence,theexpected spacerequirement ofSisO(n).\nTable 9.3 summarizes the performance of an ordered map realized by a skip\nlist.\nOperation Time\nsize,empty O(1)\nfirstEntry,lastEntry O(1)\nfind,insert,erase O(logn)(expected)\nceilingEntry,floorEntry,lowerEntry,higherEntry O(logn)(expected)\nTable 9.3: Performance of an ordered map implemented with a skip list. We use\nn to denote the number of entries in the dictionary at the time the operation is\nperformed. Theexpectedspacerequirement isO(n).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 411 \u2014 #433\ni i\n9.5. Dictionaries 411\n9.5 Dictionaries\nLikeamap,adictionary storeskey-valuepairs(k,v),whichwecallentries,where\nk is the key and v is the value. Similarly, a dictionary allows for keys and values\ntobe ofany object type. But, whereas amapinsists that entries have unique keys,\nadictionary allowsformultipleentriestohavethesamekey,muchlikeanEnglish\ndictionary, whichallowsformultipledefinitions forthesameword.\nTheabilitytostoremultipleentrieswiththesamekeyhasseveralapplications.\nForexample,wemightwanttostorerecordsforcomputerscienceauthorsindexed\nby their first and last names. Since there are a few cases of different authors with\nthesamefirstandlastname,therewillnaturally besomeinstances wherewehave\nto deal with different entries having equal keys. Likewise, a multi-user computer\ngameinvolving players visiting various rooms ina large castle might need amap-\nping from rooms to players. It is natural in this application to allow users to be\nin the same room simultaneously, however, to engage in battles. Thus, this game\nwouldnaturallybeanotherapplication whereitwouldbeusefultoallowformulti-\npleentrieswithequalkeys.\n9.5.1 The Dictionary ADT\nThedictionaryADTisquitesimilartothemapADT,whichwaspresentedinSec-\ntion 9.1. The principal differences involve the issue of multiple values sharing a\ncommon key. As with the map ADT, we assume that there is an object, called It-\nerator,thatprovides awaytoreference entries ofthedictionary. Thereisaspecial\nsentinel value, end,whichisusedtoindicate anonexistent entry. Theiterator may\nbe incremented from entry to entry, making it possible to enumerate entries from\nthecollection.\nAsanADT,a(unordered) dictionary Dsupportsthefollowingfunctions:\nsize(): ReturnthenumberofentriesinD.\nempty(): ReturntrueifDisemptyandfalseotherwise.\nfind(k): IfDcontainsanentrywithkeyequaltok,thenreturnan\niterator preferringanysuchentry,elsereturnthespecial\niterator end.\nfindAll(k): Return a pair of iterators (b,e), such that all the entries\nwith key value k lie in the range from b up to, but not\nincluding, e.\ninsert(k,v): Insert an entry with key k and value v into D, returning\naniteratorreferring tothenewlycreatedentry.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 412 \u2014 #434\ni i\n412 Chapter9. HashTables,Maps,andSkipLists\nerase(k): Remove from D an arbitrary entry with key equal to k;\nanerrorcondition occursifDhasnosuchentry.\nerase(p): Remove from D the entry referenced by iterator p; an\nerrorcondition occursif ppointstotheendsentinel.\nbegin(): ReturnaniteratortothefirstentryofD.\nend(): Returnaniteratortoaposition justbeyondtheendofD.\nNotethatoperation find(k)returns anarbitrary entry, whosekeyisequaltok,and\nerase(k)removesanarbitrary entrywithkeyvaluek. Inordertoremoveaspecific\nentry among those having the same key, it would be necessary to remember the\niteratorvalue preturnedbyinsert(k,v),andthenusetheoperation erase(p).\nExample 9.2: Inthefollowing, weshowaseriesofoperationsonaninitially\nemptydictionarystoringentrieswithintegerkeysandcharactervalues. Inthe\ncolumn\u201cOutput,\u201dweusethenotationp :[(k,v)]tomeanthattheoperationreturns\ni\naniteratordenotedbyp thatreferstotheentry(k,v).\ni\nAlthoughtheentriesarenotnecessarilystoredinanyparticularorder,inorder\ntoimplementtheoperationfindAll,weassumethatitemswiththesamekeysare\nstoredcontiguously. (Alternatively,theoperationfindAll wouldneedtoreturna\nsmarterformofiteratorthatreturnskeysofequalvalue.)\nOperation Output Dictionary\nempty() true\n\u2205\ninsert(5,A) p :[(5,A)] (5,A)\n1\n{ }\ninsert(7,B) p :[(7,B) (5,A),(7,B)\n2\n{ }\ninsert(2,C) p :[(2,C) (5,A),(7,B),(2,C)\n3\n{ }\ninsert(8,D) p :[(8,D) (5,A),(7,B),(2,C),(8,D)\n4\n{ }\ninsert(2,E) p :[(2,E) (5,A),(7,B),(2,C),(2,E),(8,D)\n5\n{ }\nfind(7) p :[(7,B) (5,A),(7,B),(2,C),(2,E),(8,D)\n2\n{ }\nfind(4) end (5,A),(7,B),(2,C),(2,E),(8,D)\n{ }\nfind(2) p :[(2,C) (5,A),(7,B),(2,C),(2,E),(8,D)\n3\n{ }\nfindAll(2) (p ,p ) (5,A),(7,B),(2,C),(2,E),(8,D)\n3 4\n{ }\nsize() 5 (5,A),(7,B),(2,C),(2,E),(8,D)\n{ }\nerase(5) \u2013 (7,B),(2,C),(2,E),(8,D)\n{ }\nerase(p ) \u2013 (7,B),(2,E),(8,D)\n3\n{ }\nfind(2) p :[(2,E)] (7,B),(2,E),(8,D)\n5\n{ }\nTheoperationfindAll(2) returnstheiteratorpair(p ,p ),referringtotheen-\n3 4\ntries (2,C) and(8,D). Assumingthattheentriesarestoredintheorderlisted\nabove,iteratingfromp upto,butnotincluding, p ,wouldenumeratetheentries\n3 4\n(2,C),(2,E) .\n{ }\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 413 \u2014 #435\ni i\n9.5. Dictionaries 413\n9.5.2 A C++ Dictionary Implementation\nIn this Section, we describe a C++ implementation of the dictionary ADT. Our\nimplementation, called HashDict, is a subclass of the HashMap class, from Sec-\ntion 9.2.7. Themap ADT already includes most of the functions of the dictionary\nADT.OurHashDictclassimplementsthenewfunctioninsert,whichinsertsakey-\nvalue pair, and the function findAll, which generates an iterator range for all the\nvaluesequaltoagivenkey. Alltheotherfunctions areinherited fromHashMap.\nIn order to support the return type of findAll, we define a nested class called\nRange. It is presented in Code Fragment 9.23. This simple class stores a pair of\nobjectsoftypeIterator,aconstructor,andtwomemberfunctionsforaccessingeach\nof them. This definition will be nested inside the public portion of the HashMap\nclassdefinition.\nclass Range // an iterator range\n{\nprivate:\nIterator begin; // front of range\nIterator end; // end of range\npublic:\nRange(const Iterator& b, const Iterator& e) // constructor\n: begin(b), end(e)\n{ }\nIterator& begin() return begin; // get beginning\n{ }\nIterator& end() return end; // get end\n{ }\n;\n}\nCodeFragment9.23: DefinitionoftheRangeclasstobeaddedtoHashMap.\nTheHashDictclassdefinitionispresentedinCodeFragment9.24. Asindicated\ninthe firstline ofthe declaration, this isasubclass ofHashMap. Theclass begins\nwith type definitions for the Iterator and Entry types from the base class. This is\nfollowed by the code for class Range from Code Fragment 9.23, and the public\nfunction declarations.\ntemplate <typename K, typename V, typename H>\nclass HashDict : public HashMap<K,V,H>\n{\npublic: // public functions\ntypedef typename HashMap<K,V,H>::Iterator Iterator;\ntypedef typename HashMap<K,V,H>::Entry Entry;\n// ...insert Range class declaration here\npublic: // public functions\nHashDict(int capacity = 100); // constructor\nRange findAll(const K& k); // find all entries with k\nIterator insert(const K& k, const V& v); // insert pair (k,v)\n;\n}\nCodeFragment9.24: TheclassHashDict,whichimplementsthedictionary ADT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 414 \u2014 #436\ni i\n414 Chapter9. HashTables,Maps,andSkipLists\nObservethat, whenreferring totheparent class, HashMap,weneedtospecify\nitstemplate parameters. Toavoid theneed forcontinually repeating theseparame-\nters, we have provided type definitions for the iterator and entry classes. Because\nmostofthedictionary ADTfunctions arealready provided byHashMap,weneed\nonlyprovideaconstructor andthemissingdictionary ADTfunctions.\nThe constructor definition is presented in Code Fragment 9.25. It simply in-\nvokes theconstructor forthebaseclass. Notethatweemploythecondensed func-\ntionnotation thatweintroduced inSection9.2.7.\n/* HashDict K,V,H :: */ // constructor\nh i\nHashDict(int capacity) : HashMap<K,V,H>(capacity)\n{ }\nCodeFragment9.25: TheclassHashDictconstructor.\nInCodeFragment9.26,wepresentanimplementationofthefunctioninsert. It\nfirstlocatesthekeybyinvokingthefinderutility(seeCodeFragment9.15). Recall\nthat this utility returns an iterator to an entry containing this key, if found, and\notherwiseitreturnsaniteratortotheendofthebucket. Ineithercase,weinsertthe\nnew entry immediately prior to this location by invoking the inserter utility. (See\nCodeFragment9.16.) Aniteratorreferencing theresulting locationisreturned.\n/* HashDict K,V,H :: */ // insert pair (k,v)\nh i\nIterator insert(const K& k, const V& v)\n{\nIterator p = finder(k); // find key\nIterator q = inserter(p, Entry(k, v)); // insert it here\nreturn q; // return its position\n}\nCodeFragment9.26: Animplementation ofthedictionary function insert.\nWe exploit a property of how insert works. Whenever a new entry (k,v) is\ninserted,ifthestructurealreadycontainsanotherentry(k,v\u2032)withthesamekey,the\nfinder utility function returns an iterator to the first such occurrence. The inserter\nutility then inserts the new entry just prior to this. It follows that all the entries\nhaving the same key are stored in a sequence of contiguous positions, all within\nthe same bucket. (In fact, they appear in the reverse of their insertion order.) This\nmeans that, in order to produce an iterator range (b,e) for the call findAll(k), it\nsufficestosetbtothefirstentryofthissequenceandsetetotheentryimmediately\nfollowingthelastone.\nOurimplementationoffindAllisgiveninCodeFragment9.27. Wefirstinvoke\nthe finder function to locate the key. If the finder returns a position at the end of\nsomebucket, weknowthatthekeyisnotpresent, andwereturntheemptyiterator\n(end,end). Otherwise, recall from CodeFragment9.15that finderreturns the first\nentrywiththegivenkeyvalue. Westorethisintheentryiteratorb. Wethentraverse\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 415 \u2014 #437\ni i\n9.5. Dictionaries 415\nthe bucket until either coming to the bucket\u2019s end or encountering an entry with a\nkey of different value. Let p be this iterator value. We return the iterator range\n(b,p).\n/* HashDict K,V,H :: */ // find all entries with k\nh i\nRange findAll(const K& k)\n{\nIterator b = finder(k); // look up k\nIterator p = b;\nwhile (!endOfBkt(p) && (*p).key() == (*b).key()) // find next unequal key\n{\n++p;\n}\nreturn Range(b, p); // return range of positions\n}\nCodeFragment9.27: Animplementation ofthedictionary functionfindAll.\n9.5.3 Implementations with Location-Aware Entries\nAs with the map ADT, there are several possible ways we can implement the dic-\ntionary ADT,including an unordered list, a hash table, an ordered search table, or\na skip list. As we did for adaptable priority queues (Section 8.4.2), we can also\nuse location-aware entries to speed up the running time for some operations in a\ndictionary. In removing a location-aware entry e, for instance, we could simply\ngo directly to the place in our data structure where we are storing e and remove\nit. We could implement a location-aware entry, for example, by augmenting our\nentry class with a private location variable and protected functions location() and\nsetLocation(p), whichreturn andsetthisvariable respectively. Wewouldthenre-\nquire that the location variable foran entry ewould always refer toe\u2019s position or\nindex in the data structure. We would, of course, have to update this variable any\ntimewemovedanentry,asfollows.\nUnordered list: In an unordered list, L, implementing a dictionary, we can\n\u2022\nmaintain the location variable of each entry e to point to e\u2019s position in the\nunderlying linked list for L. This choice allows us to perform erase(e) as\nL.erase(e.location()),whichwouldruninO(1)time.\nHashtablewithseparatechaining: Considerahashtable,withbucketarray\n\u2022\nA and hash function h, that uses separate chaining for handling collisions.\nWeusethelocationvariableofeachentryetopointtoe\u2019spositioninthelist\nLimplementingthelistA[h(k)]. Thischoiceallowsustoperformanerase(e)\nasL.erase(e.location()),whichwouldruninconstant expectedtime.\nOrderedsearchtable: Inanorderedtable,T,implementing adictionary, we\n\u2022\nshould maintain the location variable of each entry e to be e\u2019s index in T.\nThis choice would allow us to perform erase(e) as T.erase(e.location()).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 416 \u2014 #438\ni i\n416 Chapter9. HashTables,Maps,andSkipLists\n(Recallthatlocation()nowreturnsaninteger.) Thisapproachwouldrunfast\nifentryewasstoredneartheendofT.\nSkiplist: Inaskiplist,S,implementingadictionary, weshouldmaintainthe\n\u2022\nlocation variable of each entry e to point to e\u2019s position in the bottom level\nofS. Thischoice wouldallow ustoskipthesearchstepinouralgorithm for\nperforming erase(e)inaskiplist.\nWe summarize the performance of entry removal in a dictionary with location-\nawareentries inTable9.4.\nList HashTable SearchTable SkipList\nO(1) O(1)(expected) O(n) O(logn)(expected)\nTable 9.4: Performance of the erase function in dictionaries implemented with\nlocation-aware entries. Weusentodenotethenumberofentriesinthedictionary.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 417 \u2014 #439\ni i\n9.6. Exercises 417\n9.6 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-9.1 Which of the hash table collision-handling schemes could tolerate aload\nfactorabove1andwhichcouldnot?\nR-9.2 Whatistheworst-case running timeforinserting nkey-value entries into\naninitiallyemptymapM thatisimplemented withalist?\nR-9.3 Whatistheworst-caseasymptoticrunningtimeforperformingn(correct)\nerase() operations on a map, implemented with an ordered search table,\nthatinitially contains 2nentries?\nR-9.4 Describe how to use a skip-list map to implement the dictionary ADT,\nallowingtheusertoinsertdifferententrieswithequalkeys.\nR-9.5 Describehowanorderedlistimplementedasadoublylinkedlistcouldbe\nusedtoimplementthemapADT.\nR-9.6 Whatwouldbeagoodhashcodeforavehicleidentificationthatisastring\nofnumbersandlettersoftheform\u201c9X9XX99X9XX999999,\u201dwherea\u201c9\u201d\nrepresents adigitandan\u201cX\u201drepresents aletter?\nR-9.7 Draw the 11-entry hash table that results from using the hash function,\nh(i)=(3i+5) mod 11,tohashthekeys12,44,13,88,23,94,11,39,20,\n16,and5,assuming collisions arehandledbychaining.\nR-9.8 What is the result of the previous exercise, assuming collisions are han-\ndledbylinearprobing?\nR-9.9 Show the result of Exercise R-9.7, assuming collisions are handled by\nquadratic probing, uptothepointwherethemethodfails.\nR-9.10 WhatistheresultofExerciseR-9.7whencollisionsarehandledbydouble\nhashing usingthesecondary hashfunction h\u2032(k)=7 (k mod7)?\n\u2212\nR-9.11 Giveapseudo-code description ofaninsertion into ahash table thatuses\nquadratic probing toresolve collisions, assuming wealso use the trick of\nreplacing deleteditemswithaspecial\u201cdeactivated item\u201dobject.\nR-9.12 Describe a set of operations for an ordered dictionary ADT that would\ncorrespond to the functions of the ordered map ADT. Be sure to define\nthe meaning of the functions so that they can deal with the possibility of\ndifferent entrieswithequalkeys.\nR-9.13 Show the result of rehashing the hash table shown in Figure 9.4, into a\ntableofsize19,usingthenewhashfunction h(k)=3k mod17.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 418 \u2014 #440\ni i\n418 Chapter9. HashTables,Maps,andSkipLists\nR-9.14 Explain why a hash table is not suited to implement the ordered dictio-\nnaryADT.\nR-9.15 Whatistheworst-case running timeforinserting nitemsinto aninitially\nemptyhash table, wherecollisions areresolved bychaining? Whatisthe\nbestcase?\nR-9.16 Draw an example skip list that results from performing the following\nseries of operations on the skip list shown in Figure 9.12: erase(38),\ninsert(48,x), insert(24,y),erase(55). Recordyourcoinflips,aswell.\nR-9.17 Giveapseudo-code description oftheeraseoperation inaskiplist.\nR-9.18 Whatistheexpectedrunningtimeofthefunctionsformaintainingamax-\nima set if weinsert npairs such that each pair has lower cost and perfor-\nmancethantheonebeforeit? Whatiscontainedintheordereddictionary\nattheendofthisseries ofoperations? Whatifeach pairhadalowercost\nandhigherperformance thantheonebeforeit?\nR-9.19 Argue why location-aware entries are not really needed for a dictionary\nimplemented withagoodhashtable.\nCreativity\nC-9.1 Describe how you could perform each of the additional functions of the\norderedmapADTusingaskiplist.\nC-9.2 DescribehowtouseaskiplisttoimplementthevectorADT,sothatindex-\nbasedinsertions andremovalsbothruninO(logn)expectedtime.\nC-9.3 SupposewearegiventwoordereddictionariesSandT,eachwithnitems,\nand that S and T are implemented by means of array-based ordered se-\nquences. Describe an O(log2n)-time algorithm for finding the kth small-\nestkeyintheunionofthekeysfromSandT (assuming noduplicates).\nC-9.4 GiveanO(logn)-timesolution fortheprevious problem.\nC-9.5 DesignavariationofbinarysearchforperformingfindAll(k)inanordered\ndictionary implemented with an ordered array, and show that it runs in\ntimeO(logn+s),wherenisthenumberofelementsinthedictionaryand\nsisthesizeoftheiteratorreturned.\nC-9.6 The hash table dictionary implementation requires that we find a prime\nnumberbetweenanumberMandanumber2M. Implementafunctionfor\nfinding such a prime by using the sieve algorithm. In this algorithm, we\nallocate a 2M cell Boolean array A, such that cell iis associated with the\ninteger i. We then initialize the array cells to all be \u201ctrue\u201d and we \u201cmark\noff\u201d all the cells that are multiples of 2, 3, 5, 7, and so on. This process\ncanstopafteritreachesanumberlargerthan\u221a2M.\n(Hint: Consider a bootstrapping method for computing the primes up to\n\u221a2M.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 419 \u2014 #441\ni i\n9.6. Exercises 419\nC-9.7 Describe how to perform a removal from a hash table that uses linear\nprobing to resolve collisions where we do not use a special marker to\nrepresentdeletedelements. Thatis,wemustrearrangethecontentssothat\nitappears thattheremovedentrywasneverinserted inthefirstplace.\nC-9.8 GivenacollectionC ofncost-performance pairs (c,p), describe analgo-\nrithmforfindingthemaximapairsofC inO(nlogn)time.\nC-9.9 The quadratic probing strategy has a clustering problem that relates to\nthe way it looks for open slots when a collision occurs. Namely, when\na collision occurs at bucket h(k), we check A[(h(k)+ f(j)) mod N], for\nf(j)= j2,using j=1,2,...,N 1.\n\u2212\na. Show that f(j) mod N will assume at most (N+1)/2 distinct val-\nues, for N prime, as j ranges from 1 to N 1. As a part of this\n\u2212\njustification, notethat f(R)= f(N R)forallR.\n\u2212\nb. A better strategy is to choose a prime N, such that N is congruent\nto 3 modulo 4 and then to check the buckets A[(h(k) j2) mod N]\n\u00b1\nas j ranges from 1 to (N 1)/2, alternating between addition and\n\u2212\nsubtraction. Show that this alternate type of quadratic probing is\nguaranteed tocheckeverybucketinA.\nC-9.10 Show that the functions above(p) and before(p) are not actually needed\nto efficiently implement a dictionary using a skip list. That is, we can\nimplement entry insertion and removal in a skip list using a strictly top-\ndown, scan-forward approach, without ever using the above or before\nfunctions.\n(Hint: Intheinsertionalgorithm,firstrepeatedlyflipthecointodetermine\nthelevelwhereyoushouldstartinserting thenewentry.)\nC-9.11 Supposethateachrowofann narrayAconsistsof1\u2019sand0\u2019ssuchthat,\n\u00d7\nin any row of A, all the 1\u2019s come before any 0\u2019s in that row. Assuming A\nis already in memory, describe a method running in O(nlogn) time (not\nO(n2)time!) forcounting thenumberof1\u2019sinA.\nC-9.12 Describe an efficient ordered dictionary structure for storing n elements\nthat have an associated set of k < n keys that come from a total order.\nThat is, the set of keys is smaller than the number of elements. Your\nstructureshouldperformalltheordereddictionaryoperationsinO(logk+\ns)expected time,wheresisthenumberofelementsreturned.\nC-9.13 Describeanefficientdictionarystructureforstoringnentrieswhoser<n\nkeys have distinct hash codes. Your structure should perform operation\nfindAll in O(1+s) expected time, where s is the number of entries re-\nturned, and the remaining operations of the dictionary ADT in O(1) ex-\npectedtime.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 420 \u2014 #442\ni i\n420 Chapter9. HashTables,Maps,andSkipLists\nC-9.14 DescribeanefficientdatastructureforimplementingthebagADT,which\nsupports a function add(e), for adding an element e to the bag, and a\nfunction remove, which removes an arbitrary element in the bag. Show\nthatbothofthesefunctions canbedoneinO(1)time.\nC-9.15 Describehowtomodifytheskiplistdatastructuretosupportthefunction\nmedian(), which returns the position of the element in the \u201cbottom\u201d list\nS atindex n/2 . Showthatyourimplementationofthisfunctionrunsin\n0\n\u230a \u230b\nO(logn)expectedtime.\nProjects\nP-9.1 Write a spell-checker class that stores a set of words, W, in a hash table\nand implements a function, spellCheck(s), which performs a spell check\non the string s with respect to the set of words, W. If s is in W, then\nthe call to spellCheck(s) returns an iterable collection that contains only\ns, since it is assumed to be spelled correctly in this case. Otherwise, if s\nis not inW, then the call to spellCheck(s) returns a list of every word in\nW that could be a correct spelling of s. Your program should be able to\nhandle all the common ways that s might be a misspelling of a word in\nW, including swapping adjacent characters in a word, inserting a single\ncharacter inbetween two adjacent characters in a word, deleting a single\ncharacter from a word, and replacing a character in a word with another\ncharacter. Foranextrachallenge,considerphoneticsubstitutionsaswell.\nP-9.2 Writeanimplementation ofthedictionary ADTusingalinkedlist.\nP-9.3 Writeanimplementation ofthemapADTusingavector.\nP-9.4 ImplementaclassthatimplementsaversionofanordereddictionaryADT\nusing a skip list. Be sure to carefully define and implement dictionary\nversionsofcorresponding functions oftheorderedmapADT.\nP-9.5 Implement the map ADT with a hash table with separate-chaining colli-\nsionhandling (donotadaptanyoftheSTLclasses).\nP-9.6 ImplementtheorderedmapADTusingaskiplist.\nP-9.7 Extend the previous project by providing a graphical animation of the\nskip list operations. Visualize how entries move up the skip list during\ninsertions and are linked out of the skip list during removals. Also, in a\nsearchoperation, visualize thescan-forward anddrop-downactions.\nP-9.8 Implement a dictionary that supports location-aware entries by means of\nanorderedlist.\nP-9.9 Performacomparative analysis thatstudies thecollision ratesforvarious\nhash codes for character strings, such as various polynomial hash codes\nfor different values of the parameter a. Use a hash table to determine\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 421 \u2014 #443\ni i\nChapterNotes 421\ncollisions, but only count collisions where different strings map to the\nsame hash code (not if they map to the same location in this hash table).\nTestthesehashcodesontextfilesfoundontheInternet.\nP-9.10 Performacomparativeanalysisasinthepreviousexercisebutfor10-digit\ntelephone numbersinsteadofcharacter strings.\nP-9.11 Design a C++ class that implements the skip-list data structure. Use this\nclass to create implementations of both the map and dictionary ADTs,\nincluding location-aware functions forthedictionary.\nChapter Notes\nHashingisawellstudiedtechnique.Thereaderinterestedinfurtherstudyisencouragedto\nexplorethebookbyKnuth[60],aswellasthebookbyVitterandChen[100].Interestingly,\nbinary search was first published in 1946, but was not published in a fully correct form\nuntil1962. For furtherdiscussionsonlessons learned,please see papersbyBentley [11]\nand Levisse [64]. Skip lists were introduced by Pugh [86]. Our analysis of skip lists is\na simplification of a presentation given by Motwani and Raghavan [80]. For a more in-\ndepth analysis of skip lists, please see the variousresearch papers on skip lists that have\nappearedin the datastructuresliterature[54, 82, 83]. Exercise C-9.9was contributedby\nJamesLee.\ni i\ni i\nThis page intentionally left blank\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 423 \u2014 #445\ni i\nChapter\n10\nSearch Trees\nContents\n10.1 Binary Search Trees . . . . . . . . . . . . . . . . . . . 424\n10.1.1 Searching . . . . . . . . . . . . . . . . . . . . . . . 426\n10.1.2 Update Operations . . . . . . . . . . . . . . . . . . 428\n10.1.3 C++ Implementation of a Binary Search Tree . . . . 432\n10.2 AVL Trees . . . . . . . . . . . . . . . . . . . . . . . . 438\n10.2.1 Update Operations . . . . . . . . . . . . . . . . . . 440\n10.2.2 C++ Implementation of an AVL Tree . . . . . . . . . 446\n10.3 Splay Trees . . . . . . . . . . . . . . . . . . . . . . . . 450\n10.3.1 Splaying . . . . . . . . . . . . . . . . . . . . . . . . 450\n10.3.2 When to Splay. . . . . . . . . . . . . . . . . . . . . 454\n\u22c6\n10.3.3 Amortized Analysis of Splaying . . . . . . . . . . 456\n10.4 (2,4) Trees . . . . . . . . . . . . . . . . . . . . . . . . 461\n10.4.1 Multi-Way Search Trees . . . . . . . . . . . . . . . . 461\n10.4.2 Update Operations for (2,4) Trees . . . . . . . . . . 467\n10.5 Red-Black Trees . . . . . . . . . . . . . . . . . . . . . 473\n10.5.1 Update Operations . . . . . . . . . . . . . . . . . . 475\n10.5.2 C++ Implementation of a Red-Black Tree . . . . . . 488\n10.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 492\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 424 \u2014 #446\ni i\n424 Chapter10. SearchTrees\n10.1 Binary Search Trees\nAllofthestructuresthatwediscussinthischapteraresearchtrees,thatis,treedata\nstructures that can be used to implement ordered maps and ordered dictionaries.\nRecall from Chapter 9 that a map is a collection of key-value entries, with each\nvalue associated with a distinct key. A dictionary differs in that multiple values\nmay share the same key value. Our presentation focuses mostly on maps, but we\nconsider bothdatastructures inthischapter.\nWeassumethatmapsanddictionariesprovideaspecialpointerobject,calledan\niterator,whichpermitsustoreferenceandenumeratetheentriesofthestructure. In\nordertoindicatethatanobjectisnotpresent, thereexistsaspecialsentineliterator\ncalledend. Byconvention,thissentinelreferstoanimaginaryelementthatliesjust\nbeyondthelastelementofthestructure.\nLetM beamap. Inaddition tothestandard container operations (size,empty,\nbegin,andend)themapADT(Section9.1)includes thefollowing:\nfind(k): IfMcontainsanentrye=(k,v),withkeyequaltok,then\nreturn an iterator preferring to this entry, and otherwise\nreturnthespecialiterator end.\nput(k,v): If M does not have an entry with key equal to k, then\nadd entry (k,v) to M, and otherwise, replace the value\nfield of this entry with v; return an iterator to the in-\nserted/modified entry.\nerase(k): Remove from M the entry with key equal to k; an error\ncondition occursifM hasnosuchentry.\nerase(p): Remove from M the entry referenced by iterator p; an\nerrorcondition occursif ppointstotheendsentinel.\nbegin(): ReturnaniteratortothefirstentryofM.\nend(): ReturnaniteratortoapositionjustbeyondtheendofM.\nThedictionaryADT(Section9.5)providestheadditionaloperationsinsert(k,v),\nwhich inserts the entry (k,v), and findAll(k), which returns an iterator range (b,e)\nofallentrieswhosekeyvalueisk.\nGiven an iterator p, the associated entry may be accessed using *p. The indi-\nvidualkeyandvaluecanbeaccessedusing p->key()and p->value(),respectively.\nWe assume that the key elements are drawn from a total order, which is defined\nby overloading the C++ relational less-than operator (\u201c<\u201d). Given an iterator p to\nsome entry, it may be advanced to the next entry in this order using the increment\noperator (\u201c++p\u201d).\nThe ordered map and dictionary ADTsalso include some additional functions\nfor finding predecessor and successor entries with respect to a given key, but their\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 425 \u2014 #447\ni i\n10.1. BinarySearchTrees 425\nperformance is similar to that of find. So, we focus on find as the primary search\noperation inthischapter.\nBinary Search Trees and Ordered Maps\nBinary trees are an excellent data structure for storing the entries of a map, as-\nsuming we have an order relation defined on the keys. As mentioned previously\n(Section7.3.6),abinarysearchtreeisabinarytreeT suchthateachinternalnode\nvofT storesanentry(k,x)suchthat:\nKeysstoredatnodesintheleftsubtree ofvarelessthanorequaltok\n\u2022\nKeysstoredatnodesintherightsubtreeofvaregreaterthanorequaltok.\n\u2022\nAnexampleofasearchtreestoringintegerkeysisshowninFigure10.1.\n44\n17 88\n32 65 97\n28 54 82\n29 76\n80\nFigure10.1: AbinarysearchtreeT representing amapwithintegerkeys.\nAs we show below, the keys stored at the nodes of T provide a way of per-\nforming asearch by making comparisons at aseries ofinternal nodes. The search\ncan stop at the current node v or continue at v\u2019s left or right child. Thus, we take\nthe view here that binary search trees are nonempty proper binary trees. That is,\nwestore entries only at the internal nodes of abinary search tree, and the external\nnodes serve as \u201cplaceholders.\u201d This approach simplifies several of our search and\nupdate algorithms. Incidentally, we could allow for improper binary search trees,\nwhich havebetter space usage, but attheexpense ofmorecomplicated search and\nupdatefunctions.\nIndependent of whether we view binary search trees as proper or not, the im-\nportant property of a binary search tree is the realization of an ordered map (or\ndictionary). That is, a binary search tree should hierarchically represent an order-\ning of its keys, using relationships between parent and children. Specifically, an\ninorder traversal (Section 7.3.6)ofthenodes ofabinary search treeT should visit\nthe keysin nondecreasing order. Incrementing aniterator through amapvisits the\nentriesinthissameorder.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 426 \u2014 #448\ni i\n426 Chapter10. SearchTrees\n10.1.1 Searching\nTo perform operation find(k) in a map M that is represented with a binary search\ntree T, we view the tree T as a decision tree (recall Figure 7.10). In this case, the\nquestionaskedateachinternalnodevofT iswhetherthesearchkeykislessthan,\nequalto,orgreaterthanthekeystoredatnodev,denotedwithkey(v). Iftheanswer\nis\u201csmaller,\u201d then the search continues inthe left subtree. Ifthe answer is\u201cequal,\u201d\nthen the search terminates successfully. If the answer is \u201cgreater,\u201d then the search\ncontinuesintherightsubtree. Finally,ifwereachanexternalnode,thenthesearch\nterminatesunsuccessfully. (SeeFigure10.2.)\nFigure 10.2: (a) A binary search tree T representing a map with integer keys; (b)\nnodes of T visited when executing operations find(76) (successful) and find(25)\n(unsuccessful) onM. Forsimplicity, weshowonlythekeysoftheentries.\nWedescribethisapproachindetailinCodeFragment10.1. Givenasearchkey\nk and a node v of T, this function, TreeSearch, returns a node (position) w of the\nsubtreeT(v)ofT rootedatv,suchthatoneofthefollowingoccurs:\nwisaninternalnodeandw\u2019sentryhaskeyequaltok\n\u2022\nwisanexternal noderepresenting k\u2019sproper placeinaninorder traversal of\n\u2022\nT(v),butkisnotakeycontained inT(v)\nThus,function find(k)canbeperformed bycallingTreeSearch(k,T.root()). Letw\nbe the node of T returned by this call. If w is an internal node, then wereturn w\u2019s\nentry;otherwise, wereturnnull.\nAlgorithmTreeSearch(k,v):\nifT.isExternal(v)then\nreturnv\nifk<key(v)then\nreturnTreeSearch(k,T.left(v))\nelseifk>key(v)then\nreturnTreeSearch(k,T.right(v))\nreturnv weknowk=key(v)\n{ }\nCodeFragment10.1: Recursivesearchinabinarysearchtree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 427 \u2014 #449\ni i\n10.1. BinarySearchTrees 427\nAnalysis of Binary Tree Searching\nTheanalysis of the worst-case running time ofsearching inabinary search tree T\nis simple. Algorithm TreeSearch is recursive and executes a constant number of\nprimitive operations for each recursive call. Each recursive call of TreeSearch is\nmade on a child of the previous node. That is, TreeSearch is called on the nodes\nof a path of T that starts at the root and goes down one level at a time. Thus, the\nnumber of such nodes is bounded by h+1, where h is the height of T. In other\nwords,sincewespendO(1)timepernodeencountered inthesearch,functionfind\nonmapM runsinO(h)time,wherehistheheightofthebinarysearchtreeT used\ntoimplementM. (SeeFigure10.3.)\nFigure10.3: The running timeof searching ina binary search tree. Weuse astan-\ndard visualization shortcut of viewing a binary search tree as a big triangle and a\npathfromtherootasazig-zag line.\nWe can also show that a variation of the above algorithm performs operation\nfindAll(k)ofthedictionaryADTintimeO(h+s),wheresisthenumberofentries\nreturned. However, this function is slightly more complicated, and the details are\nleftasanexercise(ExerciseC-10.2).\nAdmittedly, the height h of T can be as large as the number of entries, n, but\nwe expect that it is usually much smaller. Indeed, we show how to maintain an\nupperboundofO(logn)ontheheightofasearchtreeT inSection10.2. Beforewe\ndescribe such a scheme, however, let us describe implementations for map update\nfunctions.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 428 \u2014 #450\ni i\n428 Chapter10. SearchTrees\n10.1.2 Update Operations\nBinarysearchtreesallowimplementations oftheinsertanderaseoperations using\nalgorithms thatarefairlystraightforward, butnottrivial.\nInsertion\nLetusassumeaproperbinarytreeT supports thefollowingupdateoperation:\ninsertAtExternal(v,e): Insert the element e at the external node v, and expand\nv to be internal, having new (empty) external node chil-\ndren;anerroroccursifvisaninternal node.\nGiven this function, we perform insert(k,x) for a dictionary implemented with a\nbinary search tree T by calling TreeInsert(k,x,T.root()), which is given in Code\nFragment10.2.\nAlgorithmTreeInsert(k,x,v):\nInput: Asearchkeyk,anassociated value,x,andanodevofT\nOutput: AnewnodewinthesubtreeT(v)thatstorestheentry(k,x)\nw TreeSearch(k,v)\n\u2190\nifT.isInternal(w)then\nreturnTreeInsert(k,x,T.left(w)) goingtotherightwouldbecorrecttoo\n{ }\nT.insertAtExternal(w,(k,x)) thisisanappropriate placetoput(k,x)\n{ }\nreturnw\nCodeFragment10.2: Recursivealgorithm forinsertion inabinarysearchtree.\nThis algorithm traces a path from T\u2019s root to an external node, which is ex-\npanded into a new internal node accommodating the new entry. An example of\ninsertion intoabinarysearchtreeisshowninFigure10.4.\nFigure10.4: Insertion of an entry with key 78 into the search tree of Figure 10.1:\n(a)findingtheposition toinsert;(b)theresultingtree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 429 \u2014 #451\ni i\n10.1. BinarySearchTrees 429\nRemoval\nThe implementation of the erase(k) operation on a map M implemented with a\nbinary search tree T is a bit more complex, since we do not wish to create any\n\u201choles\u201d in the tree T. We assume, in this case, that a proper binary tree supports\nthefollowingadditional updateoperation:\nremoveAboveExternal(v): Removeanexternalnodevanditsparent, replacing v\u2019s\nparentwithv\u2019ssibling;anerroroccursifvisnotexternal.\nGiven this operation, we begin our implementation of operation erase(k) of\nthe map ADT by calling TreeSearch(k,T.root()) on T to find a node of T storing\nan entry with key equal to k. If TreeSearch returns an external node, then there\nis no entry with key k in map M, and an error condition is signaled. If, instead,\nTreeSearch returns an internal node w, then w stores an entry we wish to remove,\nandwedistinguish twocases:\nIfoneofthechildrenofnodewisanexternalnode,saynodez,wesimplyre-\n\u2022\nmovewandzfromT bymeansofoperation removeAboveExternal(z)onT.\nThisoperation restructures T byreplacing wwiththe sibling ofz, removing\nbothwandzfromT. (SeeFigure10.5.)\nIf both children of node w are internal nodes, we cannot simply remove the\n\u2022\nnodewfromT,sincethiswouldcreatea\u201chole\u201dinT. Instead,weproceedas\nfollows(seeFigure10.6):\nWe find the first internal node y that follows w in an inorder traversal\n\u25e6\nof T. Node y is the left-most internal node in the right subtree of w,\nand is found by going first to the right child of w and then down T\nfrom there, following the leftchildren. Also, theleft child xofyisthe\nexternal node that immediately follows node win the inorder traversal\nofT.\nWe move the entry of y into w. This action has the effect of removing\n\u25e6\ntheformerentrystoredatw.\nWeremove nodes xand yfrom T by calling removeAboveExternal(x)\n\u25e6\nonT. Thisactionreplaces ywithx\u2019ssibling, andremovesbothxandy\nfromT.\nAs with searching and insertion, this removal algorithm traverses a path from\nthe root to an external node, possibly moving an entry between two nodes of this\npath,andthenperformsaremoveAboveExternaloperation atthatexternalnode.\nTheposition-based variant of removalisthe same, except that wecan skip the\ninitial step of invoking TreeSearch(k,T.root()) to locate the node containing the\nkey.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 430 \u2014 #452\ni i\n430 Chapter10. SearchTrees\nFigure10.5: Removalfrom thebinary search treeofFigure 10.4b, wheretheentry\nto remove (with key 32) is stored at a node (w) with an external child: (a) before\ntheremoval;(b)aftertheremoval.\nFigure10.6: Removalfrom thebinary search treeofFigure 10.4b, wheretheentry\nto remove (with key 65) is stored at a node (w) whose children are both internal:\n(a)beforetheremoval;(b)aftertheremoval.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 431 \u2014 #453\ni i\n10.1. BinarySearchTrees 431\nPerformance of a Binary Search Tree\nTheanalysisofthesearch,insertion,andremovalalgorithmsaresimilar. Wespend\nO(1)timeateachnodevisited, and, intheworstcase,thenumberofnodes visited\nis proportional to the height h of T. Thus, in amap M implemented with a binary\nsearch treeT,thefind,insert,anderasefunctions runinO(h)time,wherehisthe\nheight of T. Thus, a binary search tree T is an efficient implementation of a map\nwith n entries only if the height of T is small. In the best case, T has height h=\nlog(n+1) ,whichyieldslogarithmic-timeperformanceforallthemapoperations.\n\u2308 \u2309\nIntheworstcase,however,T hasheightn,inwhichcaseitwouldlookandfeellike\nan ordered list implementation of a map. Such a worst-case configuration arises,\nfor example, if we insert a series of entries with keys in increasing or decreasing\norder. (SeeFigure10.7.)\n10\n20\n30\n40\nFigure10.7: Exampleofabinarysearchtreewithlinearheight,obtained byinsert-\ningentrieswithkeysinincreasing order.\nThe performance of a map implemented with a binary search tree is summa-\nrizedinthefollowingproposition andinTable10.1.\nProposition 10.1: AbinarysearchtreeT withheighth forn key-valueentries\nusesO(n)spaceandexecutesthemapADToperationswiththefollowingrunning\ntimes.OperationssizeandemptyeachtakeO(1)time.Operationsfind,insert,and\neraseeachtakeO(h)time.\nOperation Time\nsize,empty O(1)\nfind,insert,erase O(h)\nTable 10.1: Running times of the main functions of a map realized by a binary\nsearch tree. We denote the current height of the tree with h. The space usage\nisO(n),wherenisthenumberofentriesstoredinthemap.\nNote that the running time of search and update operations in a binary search\ntree varies dramatically depending on the tree\u2019s height. We can nevertheless take\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 432 \u2014 #454\ni i\n432 Chapter10. SearchTrees\ncomfort that, on average, a binary search tree with n keys generated from a ran-\ndomseriesofinsertionsandremovalsofkeyshasexpectedheightO(logn). Sucha\nstatementrequirescarefulmathematicallanguagetopreciselydefinewhatwemean\nbyarandomseriesofinsertionsandremovals,andsophisticated probabilitytheory\nto prove; hence, its justification is beyond the scope of this book. Nevertheless,\nkeep in mind the poor worst-case performance and take care in using standard bi-\nnary search trees in applications where updates are not random. There are, after\nall,applications whereitisessential tohaveamapwithfastworst-case searchand\nupdatetimes. Thedatastructures presented inthenextsectionsaddress thisneed.\n10.1.3 C++ Implementation of a Binary Search Tree\nIn this section, we present a C++ implementation of the dictionary ADTbased on\na binary search tree, which we call SearchTree. Recall that a dictionary differs\nfrom a map in that it allows multiple copies of the same key to be inserted. For\nsimplicity, wehavenotimplemented thefindAllfunction.\nTo keep the number of template parameters small, rather than templating our\nclass on the key and value types, we have chosen instead to template our binary\nsearch treeonjust theentry typedenoted E. Toobtain access tothekeyandvalue\ntypes,weassumethattheentryclassdefinestwopublictypesdefiningthem. Given\nan entry object of type E, we may access these types E::Key and E::Value. Oth-\nerwise, our entry class is essentially the same as the entry class given in Code\nFragment9.1. Itispresented inCodeFragment10.3.\ntemplate <typename K, typename V>\nclass Entry // a (key, value) pair\n{\npublic: // public types\ntypedef K Key; // key type\ntypedef V Value; // value type\npublic: // public functions\nEntry(const K& k = K(), const V& v = V()) // constructor\n: key(k), value(v)\n{ }\nconst K& key() const return key; // get key (read only)\n{ }\nconst V& value() const return value; // get value (read only)\n{ }\nvoid setKey(const K& k) key = k; // set key\n{ }\nvoid setValue(const V& v) value = v; // set value\n{ }\nprivate: // private data\nK key; // key\nV value; // value\n;\n}\nCodeFragment10.3: AC++classforakey-value entry.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 433 \u2014 #455\ni i\n10.1. BinarySearchTrees 433\nIn Code Fragment 10.4, we present the main parts of the class definition for\nour binary search tree. We begin by defining the publicly accessible types for the\nentry, key, value, and the class iterator. This is followed by a declaration of the\npublic memberfunctions. Wedefinetwolocaltypes, BinaryTreeandTPos,which\nrepresent a binary search tree and position within this binary tree, respectively.\nWe also declare a number of local utility functions to help in finding, inserting,\nand erasing entries. The member data consists of a binary tree and the number of\nentriesinthetree.\ntemplate <typename E>\nclass SearchTree // a binary search tree\n{\npublic: // public types\ntypedef typename E::Key K; // a key\ntypedef typename E::Value V; // a value\nclass Iterator; // an iterator/position\npublic: // public functions\nSearchTree(); // constructor\nint size() const; // number of entries\nbool empty() const; // is the tree empty?\nIterator find(const K& k); // find entry with key k\nIterator insert(const K& k, const V& x); // insert (k,x)\nvoid erase(const K& k) throw(NonexistentElement); // remove key k entry\nvoid erase(const Iterator& p); // remove entry at p\nIterator begin(); // iterator to first entry\nIterator end(); // iterator to end entry\nprotected: // local utilities\ntypedef BinaryTree<E> BinaryTree; // linked binary tree\ntypedef typename BinaryTree::Position TPos; // position in the tree\nTPos root() const; // get virtual root\nTPos finder(const K& k, const TPos& v); // find utility\nTPos inserter(const K& k, const V& x); // insert utility\nTPos eraser(TPos& v); // erase utility\nTPos restructure(const TPos& v) // restructure\nthrow(BoundaryViolation);\nprivate: // member data\nBinaryTree T; // the binary tree\nint n; // number of entries\npublic:\n// ...insert Iterator class declaration here\n;\n}\nCodeFragment10.4: ClassSearchTree,whichimplementsabinarysearchtree.\nWe have omitted the definition of the iterator class for our binary search tree.\nThis is presented in Code Fragment 10.5. An iterator consists of a single position\nin the tree. We overload the dereferencing operator (\u201c*\u201d) to provide both read-\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 434 \u2014 #456\ni i\n434 Chapter10. SearchTrees\nonly and read-write access tothe node referenced by the iterator. Wealso provide\nan operator for checking the equality of two iterators. This is useful for checking\nwhetheraniteratorisequaltoend.\nclass Iterator // an iterator/position\n{\nprivate:\nTPos v; // which entry\npublic:\nIterator(const TPos& vv) : v(vv) // constructor\n{ }\nconst E& operator*() const return *v; // get entry (read only)\n{ }\nE& operator*() return *v; // get entry (read/write)\n{ }\nbool operator==(const Iterator& p) const // are iterators equal?\nreturn v == p.v;\n{ }\nIterator& operator++(); // inorder successor\nfriend class SearchTree; // give search tree access\n;\n}\nCodeFragment10.5: DeclarationoftheIteratorclass,whichispartofSearchTree.\nCodeFragment10.6presentsthedefinitionoftheiterator\u2019sincrementoperator,\nwhichadvancestheiteratorfromagivenpositionofthetreetoitsinordersuccessor.\nOnly internal nodes are visited, since external nodes do not contain entries. If the\nnode v has a right child, the inorder successor is the leftmost internal node of its\nrightsubtree. Otherwise, vmustbethelargestkeyintheleftsubtreeofsomenode\nw. Tofindw,wewalkupthetreethrough successive ancestors. Aslongasweare\ntherightchild ofthecurrent ancestor, wecontinue tomoveupwards. Whenthisis\nnolongertrue,theparentisthedesirednodew. Notethatweemploythecondensed\nfunction notation, whichweintroduced inSection 9.2.7, wherethe messyscoping\nqualifiersinvolving SearchTreehavebeenomitted.\n/* SearchTree E :: */ // inorder successor\nh i\nIterator& Iterator::operator++()\n{\nTPos w = v.right();\nif (w.isInternal()) // have right subtree?\n{\ndo v = w; w = w.left(); // move down left chain\n{ }\nwhile (w.isInternal());\n}\nelse\n{\nw = v.parent(); // get parent\nwhile (v == w.right()) // move up right chain\nv = w; w = w.parent();\n{ }\nv = w; // and first link to left\n}\nreturn *this;\n}\nCodeFragment10.6: Theincrement operator(\u201c++\u201d)forIterator.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 435 \u2014 #457\ni i\n10.1. BinarySearchTrees 435\nThe implementation of the increment operator appears to contain an obvious\nbug. If the iterator points to the rightmost node of the entire tree, then the above\nfunction would loop until arriving atthe root, which has no parent. Therightmost\nnodeofthetreehasnosuccessor, sotheiteratorshould returnthevalueend.\nThere is a simple and elegant way to achieve the desired behavior. We add a\nspecial sentinel node to our tree, called the super root, which is created when the\ninitial tree is constructed. The root of the binary search tree, which we call the\nvirtualroot,ismadetheleftchildofthesuperroot. Wedefineendtobeaniterator\nthatreturnstheposition ofthesuperroot. Observethat,ifweattempttoincrement\naniterator that points tothe rightmost node ofthetree, thefunction given inCode\nFragment 10.6 moves up the right chain until reaching the virtual root, and then\nstops at its parent, the super root, since the virtual root is its left child. Therefore,\nit returns an iterator pointing to the super root, which is equivalent to end. This is\nexactlythebehavior wedesire.\nTo implement this strategy, we define the constructor to create the super root.\nWealsodefineafunctionroot,whichreturnsthevirtualroot\u2019sposition, thatis,the\nleftchildofthesuperroot. Thesefunctions aregiveninCodeFragment10.7.\n/* SearchTree E :: */ // constructor\nh i\nSearchTree() : T(), n(0)\nT.addRoot(); T.expandExternal(T.root()); // create the super root\n{ }\n/* SearchTree E :: */ // get virtual root\nh i\nTPos root() const\nreturn T.root().left(); // left child of super root\n{ }\nCodeFragment10.7: Theconstructor andtheutilityfunctionroot. Theconstructor\ncreatesthesuperroot,androotreturns thevirtual rootofthebinarysearchtree.\nNext, in Code Fragment 10.8, we define the functions begin and end. The\nfunction beginreturns thefirstnodeaccording toaninorder traversal, whichisthe\nleftmostinternalnode. Thefunction endreturnsthepositionofthesuperroot.\n/* SearchTree E :: */ // iterator to first entry\nh i\nIterator begin()\n{\nTPos v = root(); // start at virtual root\nwhile (v.isInternal()) v = v.left(); // find leftmost node\nreturn Iterator(v.parent());\n}\n/* SearchTree E :: */ // iterator to end entry\nh i\nIterator end()\nreturn Iterator(T.root()); // return the super root\n{ }\nCodeFragment10.8: The begin and end functions of class SearchTree. Thefunc-\ntionendreturnsapointertothesuperroot.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 436 \u2014 #458\ni i\n436 Chapter10. SearchTrees\nWe are now ready to present implementations of the principal class functions,\nfor finding, inserting, and removing entries. We begin by presenting the func-\ntion find(k)inCodeFragment 10.9. Itinvokes therecursive utility function finder\nstarting at the root. This utility function is based on the algorithm given in Code\nFragment 10.1. The code has been structured so that only the less-than operator\nneedstobedefinedonkeys.\n/* SearchTree E :: */ // find utility\nh i\nTPos finder(const K& k, const TPos& v)\n{\nif (v.isExternal()) return v; // key not found\nif (k < v >key()) return finder(k, v.left()); // search left subtree\n\u2212\nelse if (v >key() < k) return finder(k, v.right()); // search right subtree\n\u2212\nelse return v; // found it here\n}\n/* SearchTree E :: */ // find entry with key k\nh i\nIterator find(const K& k)\n{\nTPos v = finder(k, root()); // search from virtual root\nif (v.isInternal()) return Iterator(v); // found it\nelse return end(); // didn\u2019t find it\n}\nCodeFragment10.9: Thefunctions ofSearchTreerelatedtofindingkeys.\nTheinsertionfunctionsareshowninCodeFragment10.10. Theinserterutility\ndoesallthework. First,itsearchesforthekey. Iffound,wecontinuetosearchuntil\nreaching an external node. (Recall that we allow duplicate keys.) We then create\nanode, copy the entry information into thisnode, and update theentry count. The\ninsert function simply invokes the inserter utility, and converts the resulting node\nposition intoaniterator.\n/* SearchTree E :: */ // insert utility\nh i\nTPos inserter(const K& k, const V& x)\n{\nTPos v = finder(k, root()); // search from virtual root\nwhile (v.isInternal()) // key already exists?\nv = finder(k, v.right()); // look further\nT.expandExternal(v); // add new internal node\nv >setKey(k); v >setValue(x); // set entry\n\u2212 \u2212\nn++; // one more entry\nreturn v; // return insert position\n}\n/* SearchTree E :: */ // insert (k,x)\nh i\nIterator insert(const K& k, const V& x)\nTPos v = inserter(k, x); return Iterator(v);\n{ }\nCodeFragment10.10: Thefunctions ofSearchTreeforinserting entries.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 437 \u2014 #459\ni i\n10.1. BinarySearchTrees 437\nFinally, wepresent theremoval functions inCodeFragment 10.11. Weimple-\nment the approach presented in Section 10.1.2. If the node has an external child,\nwesetwtopointtothischild. Otherwise,weletwbetheleftmostexternalnodein\nv\u2019srightsubtree. Letubew\u2019sparent. Wecopyu\u2019sentrycontents tov. Inallcases,\nwe then remove the external node w and its parent through the use of the binary\ntreefunctions removeAboveExternal.\n/* SearchTree E :: */ // remove utility\nh i\nTPos eraser(TPos& v)\n{\nTPos w;\nif (v.left().isExternal()) w = v.left(); // remove from left\nelse if (v.right().isExternal()) w = v.right(); // remove from right\nelse // both internal?\n{\nw = v.right(); // go to right subtree\ndo w = w.left(); while (w.isInternal()); // get leftmost node\n{ }\nTPos u = w.parent();\nv >setKey(u >key()); v >setValue(u >value()); // copy w\u2019s parent to v\n\u2212 \u2212 \u2212 \u2212\n}\nn ; // one less entry\n\u2212\u2212\nreturn T.removeAboveExternal(w); // remove w and parent\n}\n/* SearchTree E :: */ // remove key k entry\nh i\nvoid erase(const K& k) throw(NonexistentElement)\n{\nTPos v = finder(k, root()); // search from virtual root\nif (v.isExternal()) // not found?\nthrow NonexistentElement(\"Erase of nonexistent\");\neraser(v); // remove it\n}\n/* SearchTree E :: */ // erase entry at p\nh i\nvoid erase(const Iterator& p)\neraser(p.v);\n{ }\nCodeFragment10.11:ThefunctionsofSearchTreeinvolvedwithremovingentries.\nWhenupdating nodeentries(ininserteranderaser),weexplicitly changeonly\nthe key and value (using setKey and setValue). You might wonder, what else is\nthere to change? Later in this chapter, we present data structures that are based\non modifying the Entry class. It is important that only the key and value data are\nalteredwhencopyingnodesforthesestructures.\nOurimplementationhasfocusedonthemainelementsofthebinarysearchtree\nimplementation. There are a few more things that could have been included. It is\na straightforward exercise to implement the dictionary operation findAll. It would\nalso be worthwhile to implement the decrement operator (\u201c\u2013\u2013\u201d), which moves an\niteratortoitsinorder predecessor.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 438 \u2014 #460\ni i\n438 Chapter10. SearchTrees\n10.2 AVL Trees\nIn the previous section, we discussed what should be an efficient map data struc-\nture,buttheworst-case performance itachievesforthevariousoperations islinear\ntime, which is no better than the performance of list- and array-based map imple-\nmentations (such as the unordered lists and search tables discussed in Chapter 9).\nIn this section, we describe a simple way of correcting this problem in order to\nachievelogarithmictimeforallthefundamental mapoperations.\nDefinition of an AVL Tree\nThesimplecorrectionistoaddaruletothebinarysearchtreedefinitionthatmain-\ntains a logarithmic height for the tree. The rule we consider in this section is the\nfollowing height-balance property, which characterizes the structure of a binary\nsearchtreeT intermsoftheheightsofitsinternalnodes(recallfromSection7.2.1\nthat the height of a node v in a tree is the length of the longest path from v to an\nexternalnode):\nHeight-BalanceProperty: Forevery internal node vof T, the heights of the chil-\ndrenofvdifferbyatmost1.\nAnybinary search tree T that satisfies the height-balance property is said to be an\nAVL tree, named after the initials of its inventors, Adel\u2019son-Vel\u2019skii and Landis.\nAnexampleofanAVLtreeisshowninFigure10.8.\nFigure10.8: Anexample ofanAVLtree. Thekeys ofthe entries areshown inside\nthenodes,andtheheights ofthenodesareshownnexttothenodes.\nAnimmediateconsequenceoftheheight-balancepropertyisthatasubtreeofan\nAVLtreeisitselfanAVLtree. Theheight-balance property hasalsotheimportant\nconsequence ofkeepingtheheightsmall,asshowninthefollowingproposition.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 439 \u2014 #461\ni i\n10.2. AVLTrees 439\nProposition 10.2: TheheightofanAVLtreestoringnentriesisO(logn).\nJustification: Instead oftrying tofindanupper bound on theheight ofanAVL\ntreedirectly, itturnsouttobeeasiertoworkonthe\u201cinverse problem\u201d offinding a\nlower bound on the minimum number of internal nodes n(h) of an AVL tree with\nheight h. We show that n(h) grows at least exponentially. From this, it is an easy\nsteptoderivethattheheightofanAVLtreestoringnentriesisO(logn).\nTostartwith,noticethatn(1)=1andn(2)=2,becauseanAVLtreeofheight\n1musthaveatleastoneinternalnodeandanAVLtreeofheight2musthaveatleast\ntwo internal nodes. Now, for h 3, an AVL tree with height h and the minimum\n\u2265\nnumber of nodes is such that both its subtrees are AVL trees with the minimum\nnumberofnodes: onewithheighth 1andtheotherwithheighth 2. Takingthe\n\u2212 \u2212\nrootintoaccount,weobtainthefollowingformulathatrelatesn(h)ton(h 1)and\n\u2212\nn(h 2),forh 3:\n\u2212 \u2265\nn(h)=1+n(h 1)+n(h 2). (10.1)\n\u2212 \u2212\nAtthispoint,thereaderfamiliarwiththepropertiesofFibonacciprogressions(Sec-\ntion2.2.3andExerciseC-4.17)alreadyseesthatn(h)isafunctionexponentialinh.\nFortherestofthereaders, wewillproceedwithourreasoning.\nFormula 10.1 implies that n(h) is a strictly increasing function of h. Thus, we\nknow that n(h 1)>n(h 2). Replacing n(h 1) with n(h 2) in Formula 10.1\n\u2212 \u2212 \u2212 \u2212\nanddropping the1,weget,forh 3,\n\u2265\nn(h) > 2 n(h 2). (10.2)\n\u00b7 \u2212\nFormula10.2indicatesthatn(h)atleastdoubleseachtimehincreasesby2,which\nintuitively meansthatn(h)growsexponentially. Toshowthisfactinaformalway,\nweapplyFormula10.2repeatedly, yielding thefollowingseriesofinequalities:\nn(h) > 2 n(h 2)\n\u00b7 \u2212\n> 4 n(h 4)\n\u00b7 \u2212\n> 8 n(h 6)\n\u00b7 \u2212\n.\n.\n.\n> 2i n(h 2i). (10.3)\n\u00b7 \u2212\nThatis,n(h)>2i n(h 2i),foranyintegeri,suchthath 2i 1. Sincewealready\n\u00b7 \u2212 \u2212 \u2265\nknow the values ofn(1) and n(2), wepick iso thath 2i isequal to either 1or2.\n\u2212\nThatis,wepick\nh\ni= 1.\n2 \u2212\n(cid:24) (cid:25)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 440 \u2014 #462\ni i\n440 Chapter10. SearchTrees\nBysubstituting theabovevalueofiinformula10.3,weobtain, forh 3,\n\u2265\nh\nn(h) > 2 \u2308 h 2\u2309 \u22121 n h 2 +2\n\u00b7 \u2212 2\n(cid:18) (cid:24) (cid:25) (cid:19)\n2 \u2308 h 2\u2309 \u22121n(1)\n\u2265\n2 h 2 \u22121. (10.4)\n\u2265\nBytakinglogarithmsofbothsidesofformula10.4,weobtain\nh\nlogn(h) > 1,\n2\u2212\nfromwhichweget\nh < 2logn(h)+2, (10.5)\nwhichimpliesthatanAVLtreestoring nentrieshasheightatmost2logn+2.\nByProposition10.2andtheanalysisofbinarysearchtreesgiveninSection10.1,\ntheoperation find,inamapimplemented withanAVLtree, runs intimeO(logn),\nwherenisthe number ofentries inthe map. Ofcourse, westill have toshow how\ntomaintaintheheight-balance property afteraninsertion orremoval.\n10.2.1 Update Operations\nTheinsertion and removaloperations forAVLtrees aresimilar to those for binary\nsearchtrees,butwithAVLtreeswemustperform additional computations.\nInsertion\nAn insertion in an AVL tree T begins as in an insert operation described in Sec-\ntion 10.1.2 for a (simple) binary search tree. Recall that this operation always\ninserts the new entry at a node w in T that was previously an external node, and\nit makes w become an internal node with operation insertAtExternal. That is, it\nadds two external node children to w. This action may violate the height-balance\nproperty,however,forsomenodesincreasetheirheightsbyone. Inparticular,node\nw,andpossibly someofitsancestors, increase their heights byone. Therefore, let\nusdescribehowtorestructure T torestoreitsheightbalance.\nGiven a binary search tree T, we say that an internal node v of T is balanced\nif the absolute value of the difference between the heights of the children of v is\nat most 1, and we say that it is unbalanced otherwise. Thus, the height-balance\nproperty characterizing AVL trees is equivalent to saying that every internal node\nisbalanced.\nSupposethatT satisfiestheheight-balance property, andhenceisanAVLtree,\nprior to our inserting the new entry. As we have mentioned, after performing the\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 441 \u2014 #463\ni i\n10.2. AVLTrees 441\noperation insertAtExternal on T, the heights of some nodes of T, including w,\nincrease. AllsuchnodesareonthepathofT fromwtotherootofT,andtheseare\nthe only nodes of T that may have just become unbalanced. (See Figure 10.9(a).)\nOf course, if this happens, then T is no longer an AVL tree; hence, we need a\nmechanism tofixthe\u201cunbalance\u201d thatwehavejustcaused.\nFigure 10.9: An example insertion of an entry with key 54 in the AVL tree of\nFigure 10.8: (a) after adding a new node for key 54, the nodes storing keys 78\nand 44 become unbalanced; (b) a trinode restructuring restores the height-balance\nproperty. Weshowtheheights ofnodes nexttothem,and weidentify the nodes x,\ny,andzparticipating inthetrinode restructuring.\nWe restore the balance of the nodes in the binary search tree T by a simple\n\u201csearch-and-repair\u201dstrategy. Inparticular,letzbethefirstnodeweencounteringo-\ningupfromwtowardtherootofT suchthatzisunbalanced. (SeeFigure10.9(a).)\nAlso, let y denote the child of z with higher height (and note that node y must be\nan ancestor of w). Finally, let x be the child of y with higher height (there cannot\nbe a tie and node x must be an ancestor of w). Also, node x is a grandchild of z\nandcouldbeequaltow. Sincezbecameunbalanced becauseofaninsertion inthe\nsubtreerootedatitschildy,theheightofyis2greaterthanitssibling.\nWe now rebalance the subtree rooted at z by calling the trinode restructur-\ning function, restructure(x), given in Code Fragment 10.12 and illustrated in Fig-\nures 10.9 and 10.10. A trinode restructuring temporarily renames the nodes x, y,\nand z as a, b, and c, so that a precedes b and b precedes c in an inorder traversal\nofT. There are four possible waysof mapping x, y, and ztoa, b, and c, as shown\nin Figure 10.10, which are unified into one case by our relabeling. The trinode\nrestructuringthenreplaceszwiththenodecalledb,makesthechildrenofthisnode\nbe a and c, and makes the children of a and c be the four previous children of x,\ny, and z (other than x and y) while maintaining the inorder relationships of all the\nnodesinT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 442 \u2014 #464\ni i\n442 Chapter10. SearchTrees\nAlgorithmrestructure(x):\nInput: Anodexofabinary searchtreeT thathasbothaparentyandagrand-\nparentz\nOutput: Tree T after a trinode restructuring (which corresponds to a single or\ndoublerotation) involving nodesx,y,andz\n1: Let (a,b,c) be a left-to-right (inorder) listing of the nodes x, y, and z, and let\n(T ,T ,T ,T )bealeft-to-right(inorder)listingofthefoursubtreesofx,y,and\n0 1 2 3\nznotrootedatx,y,orz.\n2: Replacethesubtreerootedatzwithanewsubtreerootedatb.\n3: Letabetheleftchild ofbandletT 0 andT 1 betheleftand rightsubtrees ofa,\nrespectively.\n4: LetcbetherightchildofbandletT 2 andT 3 betheleftandrightsubtreesofc,\nrespectively.\nCodeFragment10.12: Thetrinoderestructuring operation inabinarysearchtree.\nThemodificationofatreeT causedbyatrinoderestructuringoperationisoften\ncalledarotation,becauseofthegeometricwaywecanvisualizethewayitchanges\nT. If b=y, the trinode restructuring method is called a single rotation, for it can\nbe visualized as \u201crotating\u201d y over z. (See Figure 10.10(a) and (b).) Otherwise,\nif b=x, the trinode restructuring operation is called a double rotation, for it can\nbe visualized as first \u201crotating\u201d x over y and then over z. (See Figure 10.10(c)\nand (d), and Figure 10.9.) Some computer researchers treat these two kinds of\nrotations as separate methods, each with two symmetric types. We have chosen,\nhowever, to unify these four types of rotations into a single trinode restructuring\noperation. No matter how we view it, though, the trinode restructuring method\nmodifiesparent-childrelationshipsofO(1)nodesinT,whilepreservingtheinorder\ntraversal orderingofallthenodesinT.\nInaddition toitsorder-preserving property, atrinode restructuring changes the\nheights of several nodes in T, so as to restore balance. Recall that we execute the\nfunction restructure(x) because z, the grandparent of x, is unbalanced. Moreover,\nthis unbalance is due to one of the children of x now having too large a height\nrelative to the height of z\u2019s other child. As a result of a rotation, we move up the\n\u201ctall\u201d child ofxwhile pushing downthe \u201cshort\u201d child ofz. Thus, after performing\nrestructure(x), all the nodes in the subtree now rooted atthe node wecalled b are\nbalanced. (SeeFigure10.10.) Thus,werestoretheheight-balance property locally\natthenodes x, y, andz. Inaddition, since afterperforming the newentry insertion\nthesubtreerootedatbreplacestheoneformerlyrootedatz,whichwastallerbyone\nunit, all the ancestors of z that were formerly unbalanced become balanced. (See\nFigure 10.9.) (Thejustification ofthis factisleft asExercise C-10.14.) Therefore,\nthisonerestructuring alsorestorestheheight-balance propertyglobally.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 443 \u2014 #465\ni i\n10.2. AVLTrees 443\n(a)\n(b)\n(c)\n(d)\nFigure 10.10: Schematic illustration of a trinode restructuring operation (Code\nFragment10.12): (a)and(b)asinglerotation; (c)and(d)adoublerotation.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 444 \u2014 #466\ni i\n444 Chapter10. SearchTrees\nRemoval\nAs was the case for the insert map operation, we begin the implementation of the\nerase map operation on an AVLtree T by using the algorithm for performing this\noperation on a regular binary search tree. The added difficulty in using this ap-\nproach with an AVL tree is that it may violate the height-balance property. In\nparticular, after removing an internal node with operation removeAboveExternal\nandelevatingoneofitschildrenintoitsplace,theremaybeanunbalanced nodein\nT on the path from the parent w of the previously removed node to the root of T.\n(SeeFigure10.11(a).) Infact,therecanbeonesuchunbalancednodeatmost. (The\njustification ofthisfactisleftasExerciseC-10.13.)\nFigure10.11: Removalof theentry withkey 32 from the AVLtree of Figure 10.8:\n(a) after removing the node storing key 32, the root becomes unbalanced; (b) a\n(single)rotation restorestheheight-balance property.\nAswithinsertion, weusetrinode restructuring torestore balance inthetreeT.\nInparticular,letzbethefirstunbalancednodeencounteredgoingupfromwtoward\ntherootofT. Also,letybethechildofzwithlargerheight(notethatnodeyisthe\nchildofzthatisnotanancestorofw),andletxbethechildofydefinedasfollows:\nif one of the children of y is taller than the other, let x be the taller child of y; else\n(bothchildrenofyhavethesameheight),letxbethechildofyonthesamesideas\ny (that is, if y is a left child, let x be the left child of y, else let x be the right child\nof y). In any case, we then perform a restructure(x) operation, which restores the\nheight-balance property locally, at the subtree that was formerly rooted atz and is\nnowrootedatthenodewetemporarily calledb. (SeeFigure10.11(b).)\nUnfortunately, this trinode restructuring may reduce the height of the subtree\nrooted at b by 1, which may cause an ancestor of b to become unbalanced. So,\nafterrebalancing z,wecontinuewalkingupT lookingforunbalanced nodes. Ifwe\nfindanother,weperformarestructureoperationtorestoreitsbalance,andcontinue\nmarchingupT lookingformore,allthewaytotheroot. Still,sincetheheightofT\nisO(logn),wherenisthenumberofentries,byProposition 10.2,O(logn)trinode\nrestructurings aresufficienttorestoretheheight-balance property.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 445 \u2014 #467\ni i\n10.2. AVLTrees 445\nPerformance of AVL Trees\nWe summarize the analysis of the performance of an AVL tree T as follows. Op-\nerations find, insert, and erase visit the nodes along a root-to-leaf path of T, plus,\npossibly, theirsiblings, andspend O(1)timepernode. Thus, sincetheheight ofT\nis O(logn) by Proposition 10.2, each of the above operations takes O(logn) time.\nInTable10.2,wesummarizetheperformance ofamapimplementedwithanAVL\ntree. Weillustrate thisperformance inFigure10.12.\nOperation TimeTime\nsize,empty O(1)\nfind,insert,erase O(logn)\nTable 10.2: Performance of an n-entry map realized by an AVL tree. The space\nusageisO(n).\nFigure10.12: Illustrating therunning timeofsearches andupdates inanAVLtree.\nThe time performance is O(1) per level, broken into a down phase, which typi-\ncallyinvolvessearching,andanupphase,whichtypicallyinvolvesupdatingheight\nvaluesandperforminglocaltrinoderestructurings (rotations).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 446 \u2014 #468\ni i\n446 Chapter10. SearchTrees\n10.2.2 C++ Implementation of an AVL Tree\nLetusnowturntotheimplementation details andanalysis ofusing anAVLtreeT\nwithninternalnodestoimplementanordereddictionaryofnentries. Theinsertion\nand removal algorithms for T require that we are able to perform trinode restruc-\nturingsanddeterminethedifferencebetweentheheightsoftwosiblingnodes. Re-\ngarding restructurings, we now need to make sure our underlying implementation\nofabinarysearchtreeincludesthemethodrestructure(x),whichperformsatrinode\nrestructuring operation (Code Fragment 10.12). (Wedonotprovide animplemen-\ntation of this function, but it is a straightforward addition to the linked binary tree\nclass given in Section 7.3.4.) It is easy to see that a restructure operation can be\nperformed in O(1) time if T is implemented with a linked structure. We assume\nthattheSearchTreeclassincludesthisfunction.\nRegardingheightinformation, wehavechosentostoretheheightofeachinter-\nnalnode,v,explicitlyineachnode. Alternatively,wecouldhavestoredthebalance\nfactorofvatv,whichisdefinedastheheightoftheleftchildofvminustheheight\noftheright child ofv. Thus, the balance factor ofvisalways equal to 1, 0, or1,\n\u2212\nexcept during an insertion or removal, when it may become temporarily equal to\n2or+2. Duringtheexecutionofaninsertionorremoval,theheightsandbalance\n\u2212\nfactorsofO(logn)nodesareaffectedandcanbemaintained inO(logn)time.\nInordertostoretheheightinformation, wederiveasubclass,calledAVLEntry,\nfrom the standard entry class given earlier in Code Fragment 10.3. It is templated\nwith the base entry type, from which it inherits the key and value members. It\ndefines a member variable ht, which stores the height of the subtree rooted at the\nassociatednode. Itprovidesmemberfunctionsforaccessingandsettingthisvalue.\nThesefunctions areprotected, sothatausercannotaccessthem,butAVLTreecan.\ntemplate <typename E>\nclass AVLEntry : public E // an AVL entry\n{\nprivate:\nint ht; // node height\nprotected: // local types\ntypedef typename E::Key K; // key type\ntypedef typename E::Value V; // value type\nint height() const return ht; // get height\n{ }\nvoid setHeight(int h) ht = h; // set height\n{ }\npublic: // public functions\nAVLEntry(const K& k = K(), const V& v = V()) // constructor\n: E(k,v), ht(0)\n{ }\nfriend class AVLTree<E>; // allow AVLTree access\n;\n}\nCodeFragment10.13: Anenhanced key-value entry for class AVLTree, containing\ntheheightoftheassociated node.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 447 \u2014 #469\ni i\n10.2. AVLTrees 447\nIn Code Fragment 10.14, we present the class definition for AVLTree. This\nclass is derived from the class SearchTree, but using our enhanced AVLEntry in\norder to maintain height information for the nodes of the tree. The class defines a\nnumber of typedef shortcuts for referring to entities such as keys, values, and tree\npositions. The class declares all the standard dictionary public member functions.\nAt the end, it also defines a number of protected utility functions, which are used\ninmaintaining theAVLtreebalanceproperties.\ntemplate <typename E> // an AVL tree\nclass AVLTree : public SearchTree< AVLEntry<E> >\n{\npublic: // public types\ntypedef AVLEntry<E> AVLEntry; // an entry\ntypedef typename SearchTree<AVLEntry>::Iterator Iterator; // an iterator\nprotected: // local types\ntypedef typename AVLEntry::Key K; // a key\ntypedef typename AVLEntry::Value V; // a value\ntypedef SearchTree<AVLEntry> ST; // a search tree\ntypedef typename ST::TPos TPos; // a tree position\npublic: // public functions\nAVLTree(); // constructor\nIterator insert(const K& k, const V& x); // insert (k,x)\nvoid erase(const K& k) throw(NonexistentElement); // remove key k entry\nvoid erase(const Iterator& p); // remove entry at p\nprotected: // utility functions\nint height(const TPos& v) const; // node height utility\nvoid setHeight(TPos v); // set height utility\nbool isBalanced(const TPos& v) const; // is v balanced?\nTPos tallGrandchild(const TPos& v) const; // get tallest grandchild\nvoid rebalance(const TPos& v); // rebalance utility\n;\n}\nCodeFragment10.14: ClassAVLTree,anAVLtreeimplementation ofadictionary.\nNext, in Code Fragment 10.15, we present the constructor and height utility\nfunction. Theconstructorsimplyinvokestheconstructorforthebinarysearchtree,\nwhich creates a tree having no entries. The function height returns the height of\na node, by extracting the height information from the AVLEntry. We employ the\ncondensed function notation thatweintroduced inSection9.2.7.\n/* AVLTree E :: */ // constructor\nh i\nAVLTree() : ST()\n{ }\n/* AVLTree E :: */ // node height utility\nh i\nint height(const TPos& v) const\nreturn (v.isExternal() ? 0 : v >height());\n{ \u2212 }\nCodeFragment10.15:TheconstructorforclassAVLTreeandautilityforextracting\nheights.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 448 \u2014 #470\ni i\n448 Chapter10. SearchTrees\nIn Code Fragment 10.16, we present a few utility functions needed for main-\ntaining thetree\u2019sbalance. Thefunction setHeightsetstheheightinformation fora\nnode as one more than the maximum of the heights of its two children. The func-\ntionisBalanceddetermineswhetheranodesatisfiestheAVLbalancecondition, by\nchecking that the height difference between its children is at most 1. Finally, the\nfunctiontallGrandchilddeterminesthetallestgrandchildofanode. Recallthatthis\nprocedure is needed by the removal operation to determine the node to which the\nrestructuring operation willbeapplied.\n/* AVLTree E :: */ // set height utility\nh i\nvoid setHeight(TPos v)\n{\nint hl = height(v.left());\nint hr = height(v.right());\nv >setHeight(1 + std::max(hl, hr)); // max of left & right\n\u2212\n}\n/* AVLTree E :: */ // is v balanced?\nh i\nbool isBalanced(const TPos& v) const\n{\nint bal = height(v.left()) height(v.right());\n\u2212\nreturn (( 1 <= bal) && (bal <= 1));\n\u2212\n}\n/* AVLTree E :: */ // get tallest grandchild\nh i\nTPos tallGrandchild(const TPos& z) const\n{\nTPos zl = z.left();\nTPos zr = z.right();\nif (height(zl) >= height(zr)) // left child taller\nif (height(zl.left()) >= height(zl.right()))\nreturn zl.left();\nelse\nreturn zl.right();\nelse // right child taller\nif (height(zr.right()) >= height(zr.left()))\nreturn zr.right();\nelse\nreturn zr.left();\n}\nCode Fragment10.16: Some utility functions used for maintaining balance in the\nAVLtree.\nNext, we present the principal function for rebalancing the AVL tree after an\ninsertion or removal. Theprocedure starts at the node vaffected by the operation.\nIt then walks up the tree to the root level. On visiting each node z, it updates\nz\u2019s height information (which may have changed due to the update operation) and\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 449 \u2014 #471\ni i\n10.2. AVLTrees 449\nchecks whether z isbalanced. If not, it finds z\u2019s tallest grandchild, and applies the\nrestructuring operation tothisnode. Sinceheights mayhavechanged asaresult,it\nupdatestheheightinformation forz\u2019schildrenanditself.\n/* AVLTree E :: */ // rebalancing utility\nh i\nvoid rebalance(const TPos& v)\n{\nTPos z = v;\nwhile (!(z == ST::root())) // rebalance up to root\n{\nz = z.parent();\nsetHeight(z); // compute new height\nif (!isBalanced(z)) // restructuring needed\n{\nTPos x = tallGrandchild(z);\nz = restructure(x); // trinode restructure\nsetHeight(z.left()); // update heights\nsetHeight(z.right());\nsetHeight(z);\n}\n}\n}\nCodeFragment10.17: Rebalancing thetreeafteranupdateoperation.\nFinally, in Code Fragment 10.18, we present the functions for inserting and\nerasing keys. (We have omitted the iterator-based erase function, since it is very\nsimple.) Each invokes the associated utility function (inserter or eraser, respec-\ntively) from the base class SearchTree. Each then invokes rebalance to restore\nbalancetothetree.\n/* AVLTree E :: */ // insert (k,x)\nh i\nIterator insert(const K& k, const V& x)\n{\nTPos v = inserter(k, x); // insert in base tree\nsetHeight(v); // compute its height\nrebalance(v); // rebalance if needed\nreturn Iterator(v);\n}\n/* AVLTree E :: */ // remove key k entry\nh i\nvoid erase(const K& k) throw(NonexistentElement)\n{\nTPos v = finder(k, ST::root()); // find in base tree\nif (Iterator(v) == ST::end()) // not found?\nthrow NonexistentElement(\"Erase of nonexistent\");\nTPos w = eraser(v); // remove it\nrebalance(w); // rebalance if needed\n}\nCodeFragment10.18: Theinsertion anderasurefunctions.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 450 \u2014 #472\ni i\n450 Chapter10. SearchTrees\n10.3 Splay Trees\nAnother way we can implement the fundamental map operations is to use a bal-\nanced search tree data structure known asa splay tree. This structure is conceptu-\nallyquite different from theother balanced search trees wediscuss inthischapter,\nforasplaytreedoesnotuseanyexplicitrulestoenforceitsbalance. Instead, itap-\npliesacertain move-to-root operation, calledsplaying, after everyaccess, inorder\nto keep the search tree balanced in an amortized sense. The splaying operation is\nperformedatthebottom-mostnodexreachedduringaninsertion, deletion,oreven\na search. The surprising thing about splaying is that it allows us to guarantee an\namortized running time for insertions, deletions, and searches, that is logarithmic.\nThe structure of asplay tree is simply abinary search tree T. In fact, there are no\nadditional height, balance, or color labels that we associate with the nodes of this\ntree.\n10.3.1 Splaying\nGiven an internal node x of a binary search tree T, we splay x by moving x to\nthe root of T through a sequence of restructurings. The particular restructurings\nwe perform are important, for it is not sufficient to move x to the root of T by\njust any sequence of restructurings. The specific operation we perform to move\nx up depends upon the relative positions of x, its parent y, and (if it exists) x\u2019s\ngrandparent z. Therearethreecasesthatweconsider.\nzig-zig: The node x and its parent y are both left children or both right children.\n(SeeFigure10.13.) Wereplace zbyx,making yachildofxandzachildof\ny,whilemaintaining theinorderrelationships ofthenodesinT.\n(a) (b)\nFigure10.13: Zig-zig: (a) before; (b) after. There is another symmetric configura-\ntionwherexandyareleftchildren.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 451 \u2014 #473\ni i\n10.3. SplayTrees 451\nzig-zag: One of x and y is a left child and the other is a right child. (See Fig-\nure 10.14.) In this case, we replace z by x and make x have y and z as its\nchildren, whilemaintaining theinorder relationships ofthenodesinT.\n(a) (b)\nFigure10.14: Zig-zag: (a) before; (b)after. There isanother symmetric configura-\ntionwherexisarightchildandyisaleftchild.\nzig: x does not have a grandparent (or we are not considering x\u2019s grandparent for\nsomereason). (SeeFigure10.15.) Inthiscase,werotatexovery,makingx\u2019s\nchildren bethenodeyandoneofx\u2019sformerchildrenw,inordertomaintain\ntherelativeinorderrelationships ofthenodesinT.\n(a) (b)\nFigure10.15: Zig: (a) before; (b) after. There is another symmetric configuration\nwherexandwareleftchildren.\nWeperform azig-zigorazig-zag whenxhasagrandparent, andweperform a\nzigwhenxhasaparentbutnotagrandparent. Asplayingstepconsistsofrepeating\nthese restructurings at x until x becomes the root of T. Note that this is not the\nsameasasequence ofsimplerotations thatbringsxtotheroot. Anexampleofthe\nsplaying ofanodeisshowninFigures10.16and10.17.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 452 \u2014 #474\ni i\n452 Chapter10. SearchTrees\n(a)\n(b)\n(c)\nFigure10.16: Example of splaying a node: (a) splaying the node storing 14 starts\nwith a zig-zag; (b) after the zig-zag; (c) the next step is a zig-zig. (Continues in\nFigure10.17.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 453 \u2014 #475\ni i\n10.3. SplayTrees 453\n(d)\n(e)\n(f)\nFigure10.17: Exampleofsplaying anode: (d)afterthezig-zig; (e)thenextstepis\nagainazig-zig; (f)afterthezig-zig (ContinuedfromFigure10.17.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 454 \u2014 #476\ni i\n454 Chapter10. SearchTrees\n10.3.2 When to Splay\nTherulesthatdictatewhensplaying isperformedareasfollows:\nWhensearchingforkeyk,ifkisfoundatanodex,wesplayx,elsewesplay\n\u2022\ntheparentoftheexternalnodeatwhichthesearchterminatesunsuccessfully.\nFor example, the splaying in Figures 10.16 and 10.17 would be performed\naftersearching successfully forkey14orunsuccessfully forkey14.5.\nWhen inserting key k, we splay the newly created internal node where k\n\u2022\ngets inserted. For example, the splaying in Figures 10.16 and 10.17 would\nbe performed if 14 were the newly inserted key. We show a sequence of\ninsertions inasplaytreeinFigure10.18.\n(a) (b) (c)\n(d) (e) (f)\n(g)\nFigure 10.18: A sequence of insertions in a splay tree: (a) initial tree; (b) after\ninserting 2; (c) after splaying; (d) after inserting 3; (e) after splaying; (f) after\ninserting 4;(g)aftersplaying.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 455 \u2014 #477\ni i\n10.3. SplayTrees 455\nWhendeleting akeyk,wesplaytheparentofthenodewthatgetsremoved,\n\u2022\nthatis,wiseitherthenodestoringkoroneofitsdescendents. (Recallthere-\nmovalalgorithm forbinary search trees.) Anexample ofsplaying following\nadeletion isshowninFigure10.19.\n(a) (b)\n(c) (d)\n(e)\nFigure10.19: Deletion from a splay tree: (a) the deletion of 8 from node r is per-\nformedbymoving thekeyoftheright-most internal nodrvtor, intheleftsubtree\nofr, deleting v,and splaying theparent uofv; (b)splaying ustarts withazig-zig;\n(c)afterthezig-zig;(d)thenextstepisazig;(e)afterthezig.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 456 \u2014 #478\ni i\n456 Chapter10. SearchTrees\n10.3.3 Amortized Analysis of Splaying \u22c6\nAfterazig-zigorzig-zag,thedepthofxdecreasesbytwo,andafterazigthedepth\nof xdecreases by one. Thus, ifx has depth d, splaying xconsists ofasequence of\nd/2 zig-zigsand/orzig-zags,plusonefinalzigifd isodd. Sinceasinglezig-zig,\n\u230a \u230b\nzig-zag, or zig effects a constant number of nodes, it can be done in O(1) time.\nThus, splaying a node x in a binary search tree T takes time O(d), where d is the\ndepthofxinT. Inotherwords,thetimeforperformingasplayingstepforanodex\nisasymptotically thesameasthetimeneededjusttoreachthatnodeinatop-down\nsearchfromtherootofT.\nWorst-Case Time\nIn the worst case, the overall running time of a search, insertion, or deletion in a\nsplaytreeofheighthisO(h),sincethenodewesplaymightbethedeepestnodein\nthetree. Moreover,itispossibleforhtobeaslargeasn,asshowninFigure10.18.\nThus,fromaworst-casepointofview,asplaytreeisnotanattractivedatastructure.\nIn spite of its poor worst-case performance, a splay tree performs well in an\namortized sense. That is, in a sequence of intermixed searches, insertions, and\ndeletions, each operation takes, on average, logarithmic time. We perform the\namortizedanalysis ofsplaytreesusingtheaccounting method.\nAmortized Performance of Splay Trees\nForouranalysis,wenotethatthetimeforperformingasearch,insertion,ordeletion\nis proportional to the time for the associated splaying. So let us consider only\nsplaying time.\nLetT bea splay tree with n keys, and let vbe anode of T. Wedefine the size\nn(v)ofvasthenumberofnodesinthesubtreerootedatv. Notethatthisdefinition\nimplies that the size of an internal node is one more than the sum of the sizes of\nits twochildren. Wedefine the rankr(v) of anode vas the logarithm in base 2of\nthesizeofv,thatis,r(v)=log(n(v)). Clearly,therootofT hasthemaximumsize\n(2n+1) and the maximum rank, log(2n+1), while each external node has size 1\nandrank0.\nWe use cyber-dollars to pay for the work we perform in splaying a node x in\nT,andweassumethatonecyber-dollar paysforazig,whiletwocyber-dollars pay\nforazig-zigorazig-zag. Hence,thecostofsplaying anodeatdepthd isd cyber-\ndollars. Wekeepavirtualaccount storingcyber-dollars ateachinternal nodeofT.\nNote that this account exists only for the purpose of our amortized analysis, and\ndoesnotneedtobeincludedinadatastructure implementing thesplaytreeT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 457 \u2014 #479\ni i\n10.3. SplayTrees 457\nAn Accounting Analysis of Splaying\nWhen weperform asplaying, wepay a certain number of cyber-dollars (the exact\nvalueofthepaymentwillbedeterminedattheendofouranalysis). Wedistinguish\nthreecases:\nIfthepaymentisequaltothesplaying work,thenweuseitalltopayforthe\n\u2022\nsplaying.\nIfthepaymentisgreaterthanthesplayingwork,wedeposittheexcessinthe\n\u2022\naccounts ofseveralnodes.\nIfthepaymentislessthanthesplayingwork,wemakewithdrawalsfromthe\n\u2022\naccounts ofseveralnodestocoverthedeficiency.\nWeshowbelowthatapaymentofO(logn)cyber-dollars peroperationissufficient\nto keep the system working, that is, to ensure that each node keeps a nonnegative\naccountbalance.\nAn Accounting Invariant for Splaying\nWe use a scheme in which transfers are made between the accounts of the nodes\ntoensurethattherewillalwaysbeenoughcyber-dollars towithdrawforpayingfor\nsplaying workwhenneeded.\nIn order to use the accounting method to perform our analysis of splaying, we\nmaintainthefollowinginvariant:\nBefore andafter asplaying, each nodevofT hasr(v) cyber-dollars\ninitsaccount.\nNotethattheinvariant is\u201cfinancially sound,\u201dsinceitdoesnotrequireustomakea\npreliminary deposittoendowatreewithzerokeys.\nLetr(T)bethesumoftheranksofallthenodesofT. Topreservetheinvariant\nafterasplaying, wemustmakeapaymentequaltothesplayingworkplusthetotal\nchangeinr(T). Werefertoasinglezig,zig-zig, orzig-zagoperation inasplaying\nasasplaying substep. Also,wedenotetherankofanodevofT beforeandaftera\nsplaying substep withr(v)andr\u2032(v),respectively. Thefollowing proposition gives\nan upper bound on the change of r(T) caused by a single splaying substep. We\nrepeatedly usethislemmainouranalysis ofafullsplaying ofanodetotheroot.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 458 \u2014 #480\ni i\n458 Chapter10. SearchTrees\nProposition 10.3: Let\u03b4bethevariationofr(T)causedbyasinglesplayingsub-\nstep(azig,zig-zig,orzig-zag)foranodexinT.Wehavethefollowing:\n\u03b4 3(r\u2032(x) r(x)) 2ifthesubstepisazig-zigorzig-zag\n\u2022 \u03b4\u2264\n3(r\u2032(x)\n\u2212\nr(x))\n\u2212\nifthesubstepisazig\n\u2022 \u2264 \u2212\nJustification: Weusethefact (seeProposition A.1,Appendix A)that, ifa>0,\nb>0,andc>a+b,\nloga+logb 2logc 2. (10.6)\n\u2264 \u2212\nLetusconsider thechangeinr(T)caused byeachtypeofsplaying substep.\nzig-zig: (Recall Figure 10.13.) Since the size of each node is one more than the\nsize of its two children, note that only the ranks of x, y, and z change in a\nzig-zig operation, where y is the parent of x and z is the parent of y. Also,\nr\u2032(x)=r(z),r\u2032(y) r\u2032(x),andr(y) r(x). Thus\n\u2264 \u2265\n\u03b4 = r\u2032(x)+r\u2032(y)+r\u2032(z) r(x) r(y) r(z)\n\u2212 \u2212 \u2212\nr\u2032(y)+r\u2032(z) r(x) r(y)\n\u2264 \u2212 \u2212\nr\u2032(x)+r\u2032(z) 2r(x). (10.7)\n\u2264 \u2212\nNotethatn(x)+n\u2032(z) n\u2032(x). By10.6,r(x)+r\u2032(z) 2r\u2032(x) 2,thatis,\n\u2264 \u2264 \u2212\nr\u2032(z) 2r\u2032(x) r(x) 2.\n\u2264 \u2212 \u2212\nThisinequality and10.7imply\n\u03b4 r\u2032(x)+(2r\u2032(x) r(x) 2) 2r(x)\n\u2264 \u2212 \u2212 \u2212\n3(r\u2032(x) r(x)) 2.\n\u2264 \u2212 \u2212\nzig-zag: (Recall Figure 10.14.) Again, bythe definition ofsize and rank, only the\nranksofx,y,andzchange,whereydenotestheparentofxandzdenotesthe\nparentofy. Also,r\u2032(x)=r(z)andr(x) r(y). Thus\n\u2264\n\u03b4 = r\u2032(x)+r\u2032(y)+r\u2032(z) r(x) r(y) r(z)\n\u2212 \u2212 \u2212\nr\u2032(y)+r\u2032(z) r(x) r(y)\n\u2264 \u2212 \u2212\nr\u2032(y)+r\u2032(z) 2r(x). (10.8)\n\u2264 \u2212\nNote that n\u2032(y)+n\u2032(z) n\u2032(x); hence, by 10.6, r\u2032(y)+r\u2032(z) 2r\u2032(x) 2.\n\u2264 \u2264 \u2212\nThus\n\u03b4 2r\u2032(x) 2 2r(x)\n\u2264 \u2212 \u2212\n3(r\u2032(x) r(x)) 2.\n\u2264 \u2212 \u2212\nzig: (Recall Figure10.15.) Inthis case, only the ranks ofxand ychange, where y\ndenotes theparentofx. Also,r\u2032(y) r(y)andr\u2032(x) r(x). Thus\n\u2264 \u2265\n\u03b4 = r\u2032(y)+r\u2032(x) r(y) r(x)\n\u2212 \u2212\nr\u2032(x) r(x)\n\u2264 \u2212\n3(r\u2032(x) r(x)).\n\u2264 \u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 459 \u2014 #481\ni i\n10.3. SplayTrees 459\nProposition 10.4: LetT beasplaytreewithroott,andlet\u2206bethetotalvariation\nofr(T)causedbysplayinganodexatdepthd.Wehave\n\u2206 3(r(t) r(x)) d+2.\n\u2264 \u2212 \u2212\nJustification: Splaying node x consists of p= d/2 splaying substeps, each\n\u2308 \u2309\nof which is a zig-zig or a zig-zag, except possibly the last one, which is a zig if d\nis odd. Let r (x)=r(x) be the initial rank of x, and for i=1,...,p, let r(x) be\n0 i\nthe rank of x after the ith substep and \u03b4 be the variation of r(T)caused by the ith\ni\nsubstep. ByLemma10.3,thetotalvariation\u2206ofr(T)causedbysplayingxis\np\n\u2206 = \u2211\u03b4\ni\ni=1\np\n\u2211\n(3(r(x) r (x)) 2)+2\ni i\u22121\n\u2264 \u2212 \u2212\ni=1\n= 3(r (x) r (x)) 2p+2\np 0\n\u2212 \u2212\n3(r(t) r(x)) d+2.\n\u2264 \u2212 \u2212\nByProposition 10.4, ifwemake apayment of3(r(t) r(x))+2 cyber-dollars\n\u2212\ntowards the splaying of node x, we have enough cyber-dollars to maintain the in-\nvariant,keepingr(v)cyber-dollarsateachnodevinT,andpayfortheentiresplay-\ning work, which costs d dollars. Since the size of the root t is 2n+1, its rank\nr(t) = log(2n+1). In addition, we have r(x) < r(t). Thus, the payment to be\nmade for splaying is O(logn) cyber-dollars. Tocomplete our analysis, wehave to\ncomputethecostformaintaining theinvariant whenanodeisinserted ordeleted.\nWhen inserting anew node v into a splay tree with nkeys, the ranks of all the\nancestors of v are increased. Namely, let v ,v,...,v be the ancestors of v, where\n0 i d\nv =v, v is the parent of v , and v is the root. For i=1,...,d, let n\u2032(v) and\n0 i i\u22121 d i\nn(v)bethesize ofv before andafter theinsertion, respectively, andletr\u2032(v)and\ni i i\nr(v)betherankofv beforeandaftertheinsertion, respectively. Wehave\ni i\nn\u2032(v)=n(v)+1.\ni i\nAlso, since n(v)+1 n(v ), for i=0,1,...,d 1, we have the following for\ni i+1\n\u2264 \u2212\neachiinthisrange\nr\u2032(v)=log(n\u2032(v))=log(n(v)+1) log(n(v ))=r(v ).\ni i i i+1 i+1\n\u2264\nThus,thetotalvariation ofr(T)causedbytheinsertion is\nd d\u22121\n\u2211 r\u2032(v) r(v) r\u2032(v )+ \u2211 (r(v ) r(v))\ni i d i+1 i\n\u2212 \u2264 \u2212\ni=1 i=1\n(cid:0) (cid:1) = r\u2032(v ) r(v )\nd 0\n\u2212\nlog(2n+1).\n\u2264\nTherefore,apaymentofO(logn)cyber-dollarsissufficienttomaintaintheinvariant\nwhenanewnodeisinserted.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 460 \u2014 #482\ni i\n460 Chapter10. SearchTrees\nWhen deleting a node v from a splay tree with n keys, the ranks of all the\nancestorsofvaredecreased. Thus,thetotalvariationofr(T)causedbythedeletion\nis negative, and we do not need to make any payment to maintain the invariant\nwhen a node is deleted. Therefore, we may summarize our amortized analysis in\nthefollowingproposition (whichissometimescalledthe\u201cbalanceproposition\u201d for\nsplaytrees).\nProposition 10.5: Considerasequenceofmoperationsonasplaytree,eachone\nasearch,insertion,ordeletion,startingfromasplaytreewithzerokeys.Also,let\nn bethenumberofkeysinthetreeafteroperationi,andnbethetotalnumberof\ni\ninsertions.Thetotalrunningtimeforperformingthesequenceofoperationsis\nm\n\u2211\nO m+ logn ,\ni\ni=1 !\nwhichisO(mlogn).\nInotherwords,theamortizedrunningtimeofperformingasearch,insertion,or\ndeletion inasplaytreeisO(logn),wherenisthesizeofthesplay treeatthetime.\nThus, asplay tree can achieve logarithmic-time amortized performance for imple-\nmentinganorderedmapADT. Thisamortizedperformancematchestheworst-case\nperformance of AVL trees, (2,4) trees, and red-black trees, but it does so using a\nsimple binary tree that does not need any extra balance information stored ateach\nof its nodes. In addition, splay trees have a number of other interesting properties\nthatarenotsharedbytheseotherbalancedsearchtrees. Weexploreonesuchaddi-\ntional property inthefollowing proposition (whichissometimescalled the\u201cStatic\nOptimality\u201dproposition forsplaytrees).\nProposition 10.6: Considerasequenceofmoperationsonasplaytree,eachone\nasearch,insertion,ordeletion,startingfromasplaytreeT withzerokeys.Also,let\nf(i)denotethenumberoftimestheentryiisaccessedinthesplaytree,thatis,its\nfrequency,andletndenotethetotalnumberofentries.Assumingthateachentryis\naccessedatleastonce,thenthetotalrunningtimeforperformingthesequenceof\noperationsis\nn\n\u2211\nO m+ f(i)log(m/f(i)) .\ni=1 !\nWeomittheproofofthisproposition,butitisnotashardtojustifyasonemight\nimagine. The remarkable thing is that this proposition states that the amortized\nrunning timeofaccessing anentryiisO(log(m/f(i))).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 461 \u2014 #483\ni i\n10.4. (2,4)Trees 461\n10.4 (2,4) Trees\nSome data structures we discuss in this chapter, including (2,4) trees, are multi-\nway search trees, that is, trees with internal nodes that have two or more children.\nThus,beforewedefine(2,4)trees,letusdiscussmulti-waysearchtrees.\n10.4.1 Multi-Way Search Trees\nRecall that multi-way trees are defined so that each internal node can have many\nchildren. In this section, we discuss how multi-way trees can be used as search\ntrees. Recall that the entries that we store in a search tree are pairs of the form\n(k,x), where k is the key and x is the value associated with the key. However, we\ndo not discuss how to perform updates in multi-way search trees now, since the\ndetailsforupdatemethodsdependonadditionalpropertieswewanttomaintainfor\nmulti-waytrees,whichwediscuss inSection14.3.1.\nDefinition of a Multi-way Search Tree\nLet v be a node of an ordered tree. We say that v is a d-node if v has d children.\nWe define a multi-way search tree to be an ordered tree T that has the following\nproperties, whichareillustrated inFigure10.1(a):\nEachinternalnodeofT hasatleasttwochildren. Thatis,eachinternalnode\n\u2022\nisad-nodesuchthatd 2.\n\u2265\nEach internal d-node v of T with children v ,...,v stores an ordered set of\n1 d\n\u2022\nd 1key-valueentries(k ,x ),...,(k ,x ),wherek k .\n1 1 d\u22121 d\u22121 1 d\u22121\n\u2212 \u2264\u00b7\u00b7\u00b7\u2264\nLet us conventionally define k = and k =+ . For each entry (k,x)\n0 d\n\u2022 \u2212\u221e \u221e\nstored at a node in the subtree of v rooted at v, i= 1,...,d, we have that\ni\nk k k.\ni\u22121 i\n\u2264 \u2264\nThat is, if we think of the set of keys stored at v as including the special fictitious\nkeys k = and k =+ , then a key k stored in the subtree of T rooted at a\n0 d\n\u2212\u221e \u221e\nchild node v must be \u201cin between\u201d two keys stored at v. This simple viewpoint\ni\ngives rise to the rule that a d-node stores d 1 regular keys, and it also forms the\n\u2212\nbasisofthealgorithm forsearching inamulti-waysearchtree.\nBy the above definition, the external nodes of a multi-way search do not store\nanyentriesandserveonlyas\u201cplaceholders,\u201dashasbeenourconventionwithbinary\nsearch trees (Section 10.1); hence, a binary search tree can be viewed as a special\ncase ofamulti-way search tree, where eachinternal node stores one entryand has\ntwo children. In addition, while the external nodes could be null, we make the\nsimplifying assumption herethattheyareactualnodesthatdon\u2019tstoreanything.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 462 \u2014 #484\ni i\n462 Chapter10. SearchTrees\n(a)\n(b)\n(c)\nFigure10.20: (a) A multi-way search tree T; (b) search path in T for key 12 (un-\nsuccessful search); (c)searchpathinT forkey24(successful search).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 463 \u2014 #485\ni i\n10.4. (2,4)Trees 463\nWhetherinternalnodesofamulti-waytreehavetwochildrenormany,however,\nthere is an interesting relationship between the number of entries and the number\nofexternal nodes.\nProposition 10.7: Ann-entrymulti-waysearchtreehasn+1externalnodes.\nWeleavethejustificationofthisproposition asanexercise(ExerciseC-10.17).\nSearching in a Multi-Way Tree\nGivenamulti-way search tree T, wenote that searching for anentry withkey k is\nsimple. Weperform such a search by tracing a path in T starting at the root. (See\nFigure10.1(b)and(c).) Whenweareatad-nodevduringthissearch,wecompare\nthe key k with the keys k ,...,k stored at v. If k=k for some i, the search is\n1 d\u22121 i\nsuccessfully completed. Otherwise,wecontinuethesearchinthechildv ofvsuch\ni\nthatk <k<k. (Recallthatweconventionally definek = andk =+ .)\ni\u22121 i 0 d\n\u2212\u221e \u221e\nIf wereach an external node, then weknow that there isno entry with key k in T,\nandthesearchterminatesunsuccessfully.\nData Structures for Representing Multi-way Search Trees\nInSection 7.1.4, wediscuss alinked data structure for representing ageneral tree.\nThisrepresentation canalsobeusedforamulti-waysearchtree. Infact,inusinga\ngeneral treetoimplement amulti-way search tree, theonly additional information\nthat we need to store at each node is the set of entries (including keys) associated\nwiththat node. Thatis, weneed tostorewithvareference tosomecollection that\nstorestheentriesforv.\nRecall that when we use a binary search tree to represent an ordered map M,\nwesimplystoreareferencetoasingleentryateachinternalnode. Inusingamulti-\nway search tree T to represent M, we must store a reference to the ordered set of\nentries associated with v at each internal node v of T. This reasoning may at first\nseemlikeacircularargument,sinceweneedarepresentation ofanorderedmapto\nrepresentanorderedmap. Wecanavoidanycirculararguments, however,byusing\nthe bootstrapping technique, where we use a previous (less advanced) solution to\na problem to create a new (more advanced) solution. In this case, bootstrapping\nconsists of representing the ordered set associated with each internal node using\na map data structure that we have previously constructed (for example, a search\ntable based on a sorted array, as shown in Section 9.3.1). In particular, assuming\nwealready haveawayofimplementing ordered maps,wecanrealize amulti-way\nsearchtreebytakingatreeT andstoring suchamapateachnodeofT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 464 \u2014 #486\ni i\n464 Chapter10. SearchTrees\nThe map we store at each node v is known as a secondary data structure, be-\ncause weare using it to support the bigger, primary data structure. Wedenote the\nmapstored atanodevofT asM(v). Theentries westoreinM(v)allowustofind\nwhich child node to moveto nextduring asearch operation. Specifically, foreach\nnodevofT,withchildrenv ,...,v andentries(k ,x ),...,(k ,x ),westore,\n1 d 1 1 d\u22121 d\u22121\ninthemapM(v),theentries\n(k ,(x ,v )),(k ,(x ,v )),...,(k ,(x ,v )),(+ ,( ,v )).\n1 1 1 2 2 2 d\u22121 d\u22121 d\u22121 d\n\u221e \u2205\nThatis,anentry(k,(x,v))ofmapM(v)haskeyk andvalue(x,v). Notethatthe\ni i i i i i\nlastentrystoresthespecialkey+ .\n\u221e\nWiththerealization ofthemulti-waysearchtreeT above,processing ad-node\nvwhilesearching foranentryofT withkeykcanbedonebyperforming asearch\noperation to find the entry (k,(x,v)) in M(v) with smallest key greater than or\ni i i\nequaltok. Wedistinguish twocases:\nIfk<k,thenwecontinuethesearchbyprocessingchildv. (Notethatifthe\ni i\n\u2022\nspecial keyk =+ isreturned, thenkisgreater thanallthekeysstoredat\nd\n\u221e\nnodev,andwecontinue thesearchprocessing childv .)\nd\nOtherwise(k=k),thenthesearchterminatessuccessfully.\ni\n\u2022\nConsiderthespacerequirement fortheaboverealization ofamulti-waysearch\ntreeT storingnentries. ByProposition10.7,usinganyofthecommonrealizations\nof an ordered map (Chapter 9) for the secondary structures of the nodes of T, the\noverallspacerequirement forT isO(n).\nConsider next the time spent answering a search in T. The time spent at a d-\nnodevofT duringasearchdependsonhowwerealizethesecondarydatastructure\nM(v). If M(v) is realized with a sorted array (that is, an ordered search table),\nthen we can process v in O(logd) time. If M(v) is realized using an unsorted list\ninstead, then processing vtakes O(d)time. Letd denote themaximumnumber\nmax\nofchildrenofanynodeofT,andlethdenotetheheightofT. Thesearchtimeina\nmulti-waysearchtreeiseitherO(hd )orO(hlogd ),dependingonthespecific\nmax max\nimplementation of the secondary structures at the nodes of T (the map M(v)). If\nd isaconstant, therunningtimeforperformingasearchisO(h),irrespectiveof\nmax\ntheimplementation ofthesecondary structures.\nThus, the primary efficiency goal for a multi-way search tree is to keep the\nheightassmallaspossible, thatis,wewanthtobealogarithmicfunction ofn,the\ntotal number of entries stored in the map. A search tree with logarithmic height\nsuchasthisiscalledabalancedsearch tree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 465 \u2014 #487\ni i\n10.4. (2,4)Trees 465\nDefinition of a (2,4) Tree\nAmulti-waysearchtreethatkeepsthesecondarydatastructuresstoredateachnode\nsmall and also keeps the primary multi-way tree balanced is the (2,4) tree, which\nissometimes called 2-4tree or2-3-4 tree. Thisdata structure achieves these goals\nbymaintaining twosimpleproperties (seeFigure10.21):\nSizeProperty: Everyinternalnodehasatmostfourchildren\nDepthProperty: Alltheexternalnodeshavethesamedepth\nFigure10.21: A(2,4)tree.\nAgain,weassumethatexternalnodesareemptyand,forthesakeofsimplicity,\nwe describe our search and update methods assuming that external nodes are real\nnodes, althoughthislatterrequirement isnotstrictly needed.\nEnforcing the size property for (2,4) trees keeps the nodes in the multi-way\nsearch tree simple. It also gives rise to the alternative name \u201c2-3-4 tree,\u201d since it\nimpliesthateachinternal nodeinthetreehas2,3,or4children. Anotherimplica-\ntionofthisruleisthatwecanrepresent themapM(v)stored ateach internal node\nv using an unordered list or an ordered array, and still achieve O(1)-time perfor-\nmance for all operations (since d =4). The depth property, on the other hand,\nmax\nenforces animportantboundontheheightofa(2,4)tree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 466 \u2014 #488\ni i\n466 Chapter10. SearchTrees\nProposition 10.8: Theheightofa(2,4)treestoringnentriesisO(logn).\nJustification: Lethbethe height of a(2,4) treeT storing nentries. Wejustify\ntheproposition byshowingthattheclaims\n1\nlog(n+1) h (10.9)\n2 \u2264\nand\nh log(n+1) (10.10)\n\u2264\naretrue.\nTojustifytheseclaimsnotefirstthat,bythesizeproperty, wecanhaveatmost\n4 nodes at depth 1, at most 42 nodes at depth 2, and so on. Thus, the number of\nexternalnodesinT isatmost4h. Likewise,bythedepthpropertyandthedefinition\nofa(2,4) tree, wemusthaveatleast 2nodes atdepth 1,atleast22 nodes atdepth\n2,andsoon. Thus,thenumberofexternalnodesinT isatleast2h. Inaddition, by\nProposition 10.7,thenumberofexternalnodesinT isn+1. Therefore,weobtain\n2h n+1\n\u2264\nand\nn+1 4h.\n\u2264\nTakingthelogarithm inbase2ofeachoftheaboveterms,wegetthat\nh log(n+1)\n\u2264\nand\nlog(n+1) 2h,\n\u2264\nwhichjustifiesourclaims(10.9and10.10).\nProposition10.8statesthatthesizeanddepthpropertiesaresufficientforkeep-\ningamulti-waytreebalanced (Section 10.4.1). Moreover, thisproposition implies\nthat performing a search in a (2,4) tree takes O(logn) time and that the specific\nrealization of the secondary structures at the nodes is not a crucial design choice,\nsince the maximum number of children d is a constant (4). We can, for exam-\nmax\nple, use a simple ordered map implementation, such as an array-list search table,\nforeachsecondary structure.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 467 \u2014 #489\ni i\n10.4. (2,4)Trees 467\n10.4.2 Update Operations for (2,4) Trees\nMaintaining the size and depth properties requires some effort after performing\ninsertionsandremovalsina(2,4)tree,however. Wediscusstheseoperations next.\nInsertion\nTo insert a new entry (k,x), with key k, into a (2,4) tree T, we first perform a\nsearch for k. Assuming that T has no entry with key k, this search terminates\nunsuccessfully at an external node z. Let v be the parent of z. We insert the new\nentryintonodevandaddanewchildw(anexternalnode)tovontheleftofz. That\nis,weaddentry(k,x,w)tothemapM(v).\nOurinsertionmethodpreservesthedepthproperty,sinceweaddanewexternal\nnode at the same level as existing external nodes. Nevertheless, it may violate the\nsize property. Indeed, if a node v was previously a 4-node, then it may become a\n5-nodeaftertheinsertion,whichcausesthetreeT tonolongerbea(2,4)tree. This\ntype of violation of the size property is called an overflow at node v, and it must\nbe resolved in order to restore the properties of a (2,4) tree. Let v ,...,v be the\n1 5\nchildren of v, and let k ,...,k be the keys stored at v. To remedy the overflow at\n1 4\nnodev,weperform asplitoperation onvasfollows(seeFigure10.22):\nReplacevwithtwonodesv\u2032 andv\u2032\u2032,where\n\u2022\nv\u2032 isa3-nodewithchildrenv ,v ,v storingkeysk andk\n1 2 3 1 2\n\u25e6\nv\u2032\u2032 isa2-nodewithchildrenv ,v storingkeyk\n4 5 4\n\u25e6\nIfvwastherootofT,createanewrootnodeu;else,letubetheparentofv\n\u2022\nInsert keyk into uand makev\u2032 and v\u2032\u2032 children ofu, sothat ifvwaschild i\n3\n\u2022\nofu,thenv\u2032 andv\u2032\u2032 becomechildren iandi+1ofu,respectively\nWeshowasequence ofinsertions ina(2,4)treeinFigure10.23.\n(a) (b) (c)\nFigure10.22:Anodesplit: (a)overflowata5-nodev;(b)thethirdkeyofvinserted\nintotheparentuofv;(c)nodevreplaced witha3-nodev\u2032 anda2-nodev\u2032\u2032.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 468 \u2014 #490\ni i\n468 Chapter10. SearchTrees\n(a) (b) (c) (d)\n(e) (f)\n(g) (h)\n(i) (j)\n(k) (l)\nFigure 10.23: A sequence of insertions into a (2,4) tree: (a) initial tree with one\nentry; (b) insertion of 6; (c) insertion of 12; (d) insertion of 15, which causes an\noverflow;(e)split, whichcauses thecreation ofanewrootnode;(f)afterthesplit;\n(g)insertionof3;(h)insertionof5,whichcausesanoverflow;(i)split;(j)afterthe\nsplit;(k)insertion of10;(l)insertion of8.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 469 \u2014 #491\ni i\n10.4. (2,4)Trees 469\nAnalysis of Insertion in a (2,4) Tree\nA split operation affects a constant number of nodes of the tree and O(1) entries\nstoredatsuchnodes. Thus,itcanbeimplementedtoruninO(1)time.\nAsaconsequence ofa split operation onnode v, anew overflow may occur at\ntheparentuofv. Ifsuchanoverflowoccurs,ittriggersasplitatnodeuinturn. (See\nFigure10.24.) Asplitoperationeithereliminatestheoverfloworpropagatesitinto\ntheparentofthecurrentnode. Hence,thenumberofsplitoperationsisboundedby\nthe height of the tree, which is O(logn) by Proposition 10.8. Therefore, the total\ntimetoperformaninsertion ina(2,4)treeisO(logn).\n(a) (b)\n(c) (d)\n(e) (f)\nFigure10.24: An insertion in a (2,4) tree that causes a cascading split: (a) before\ntheinsertion; (b)insertion of17, causing anoverflow;(c)asplit; (d)afterthesplit\nanewoverflowoccurs;(e)anothersplit,creating anewrootnode;(f)finaltree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 470 \u2014 #492\ni i\n470 Chapter10. SearchTrees\nRemoval\nLet us now consider the removal of an entry with key k from a (2,4) tree T. We\nbegin such an operation by performing a search in T for an entry with key k. Re-\nmoving such an entry from a (2,4) tree can always be reduced to the case where\nthe entry to be removed is stored at a node v whose children are external nodes.\nSuppose, forinstance, thattheentrywithkeykthatwewishtoremoveisstoredin\nthe ith entry (k,x) at a node z that has only internal-node children. In this case,\ni i\nwe swap the entry (k,x) with an appropriate entry that is stored at a node v with\ni i\nexternal-node children asfollows(seeFigure10.25(d)):\n1. Wefindtheright-mostinternalnodevinthesubtreerootedattheithchildof\nz,notingthatthechildren ofnodevareallexternalnodes.\n2. Weswaptheentry(k,x)atzwiththelastentryofv.\ni i\nOnce we ensure that the entry to remove is stored at a node v with only external-\nnodechildren(becauseeitheritwasalreadyatvorweswappeditintov),wesimply\nremove the entry from v (that is, from the map M(v)) and remove the ith external\nnodeofv.\nRemoving an entry (and a child) from a node v as described above preserves\nthe depth property, because wealways remove anexternal node child from anode\nv with only external-node children. However, in removing such an external node\nwe may violate the size property at v. Indeed, if v was previously a 2-node, then\nit becomes a 1-node with no entries after the removal (Figure 10.25(d) and (e)),\nwhich is not allowed in a (2,4) tree. This type of violation of the size property\nis called an underflow at node v. To remedy an underflow, we check whether an\nimmediate sibling of v is a 3-node or a 4-node. If we find such a sibling w, then\nweperformatransferoperation, inwhichwemoveachildofwtov,akeyofwto\ntheparent uofvandw,andakeyofutov. (SeeFigure10.25(b) and(c).) Ifvhas\nonlyonesibling, orifbothimmediatesiblings ofvare2-nodes, thenweperform a\nfusion operation, in which wemerge v with asibling, creating a new node v\u2032, and\nmoveakeyfromtheparentuofvtov\u2032. (SeeFigure10.26(e)and(f).)\nAfusionoperationatnodevmaycauseanewunderflowtooccurattheparentu\nofv,whichinturntriggersatransferorfusionatu. (SeeFigure10.26.) Hence,the\nnumberoffusionoperationsisboundedbytheheightofthetree,whichisO(logn)\nby Proposition 10.8. If an underflow propagates all the way up to the root, then\nthe root is simply deleted. (See Figure 10.26(c) and (d).) We show a sequence of\nremovalsfroma(2,4)treeinFigures10.25and10.26.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 471 \u2014 #493\ni i\n10.4. (2,4)Trees 471\n(a) (b)\n(c) (d)\n(e) (f)\n(g) (h)\nFigure10.25: Asequence ofremovals from a(2,4) tree: (a)removal of4, causing\nan underflow; (b) atransfer operation; (c) after the transfer operation; (d) removal\nof 12, causing an underflow; (e) a fusion operation; (f) after the fusion operation;\n(g)removalof13;(h)afterremoving13.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 472 \u2014 #494\ni i\n472 Chapter10. SearchTrees\n(a) (b)\n(c) (d)\nFigure10.26: Apropagating sequence offusions ina(2,4)tree: (a)removalof14,\nwhichcausesanunderflow;(b)fusion,whichcausesanotherunderflow;(c)second\nfusionoperation, whichcausestheroottoberemoved;(d)finaltree.\nPerformance of (2,4) Trees\nTable10.3summarizes therunning timesofthemainoperations ofamaprealized\nwitha(2,4)tree. Thetimecomplexityanalysis isbasedonthefollowing:\nTheheightofa(2,4)treestoring nentriesisO(logn),byProposition 10.8\n\u2022\nAsplit,transfer, orfusionoperation takesO(1)time\n\u2022\nAsearch,insertion, orremovalofanentryvisitsO(logn)nodes.\n\u2022\nOperation Time\nsize,empty O(1)\nfind,insert,erase O(logn)\nTable 10.3: Performance of an n-entry map realized by a (2,4) tree. The space\nusageisO(n).\nThus,(2,4)treesprovideforfastmapsearchandupdateoperations. (2,4)trees\nalsohaveaninteresting relationship tothedatastructure wediscuss next.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 473 \u2014 #495\ni i\n10.5. Red-BlackTrees 473\n10.5 Red-Black Trees\nAlthough AVL trees and (2,4) trees have a number of nice properties, there are\nsomemapapplications forwhichtheyarenotwellsuited. Forinstance, AVLtrees\nmay require many restructure operations (rotations) to be performed after a re-\nmoval,and(2,4)treesmayrequiremanyfusingorsplitoperationstobeperformed\nafter either an insertion or removal. The data structure we discuss in this section,\nthered-black tree,doesnothavethesedrawbacks, however,asitrequiresthatonly\nO(1)structural changes bemadeafteranupdateinordertostaybalanced.\nA red-black tree is a binary search tree (see Section 10.1) with nodes colored\nredandblackinawaythatsatisfiesthefollowingproperties:\nRootProperty: Therootisblack.\nExternalProperty: Everyexternal nodeisblack.\nInternalProperty: Thechildren ofarednodeareblack.\nDepthProperty: Allthe external nodes have the sameblack depth, defined asthe\nnumber of black ancestors minus one. (Recall that a node is an ancestor of\nitself.)\nAnexampleofared-black treeisshowninFigure10.27.\nFigure10.27: Red-black tree associated with the (2,4) tree of Figure 10.21. Each\nexternalnodeofthisred-blacktreehas4blackancestors(includingitself);hence,it\nhasblackdepth3. Weusethecolorblueinsteadofred. Also,weusetheconvention\nofgivinganedgeofthetreethesamecolorasthechildnode.\nAs for previous types of search trees, we assume that entries are stored at the\ninternal nodes of a red-black tree, with the external nodes being empty placehold-\ners. Also, weassume that the external nodes are actual nodes, but wenote that, at\ntheexpenseofslightly morecomplicated methods,externalnodescouldbenull.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 474 \u2014 #496\ni i\n474 Chapter10. SearchTrees\nWecanmakethered-black tree definition moreintuitive bynoting aninterest-\ning correspondence between red-black trees and (2,4) trees as illustrated in Fig-\nure10.28. Namely,givenared-black tree,wecanconstruct acorresponding (2,4)\ntree by merging every red node v into its parent and storing the entry from v at its\nparent. Conversely,wecantransformany(2,4)treeintoacorresponding red-black\ntree by coloring each node black and performing the following transformation for\neachinternal nodev:\nIfvisa2-node, thenkeepthe(black)childrenofvasis\n\u2022\nIf v is a 3-node, then create a new red node w, give v\u2019s first two (black)\n\u2022\nchildren tow,andmakewandv\u2019sthirdchildbethetwochildrenofv\nIf v is a 4-node, then create two new red nodes w and z, give v\u2019s first two\n\u2022\n(black) children tow,givev\u2019slasttwo(black)children toz,andmakewand\nzbethetwochildren ofv\n\u2212\u2192\n(a)\n\u2212\u2192\n(b)\n\u2212\u2192\n(c)\nFigure10.28:Correspondencebetweena(2,4)treeandared-blacktree: (a)2-node;\n(b)3-node;(c)4-node.\nThecorrespondencebetween(2,4)treesandred-blacktreesprovidesimportant\nintuitionthatweuseinourdiscussionofhowtoperformupdatesinred-blacktrees.\nInfact,theupdatealgorithmsforred-blacktreesaremysteriouslycomplexwithout\nthisintuition.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 475 \u2014 #497\ni i\n10.5. Red-BlackTrees 475\nProposition 10.9: Theheightofared-blacktreestoringnentriesisO(logn).\nJustification: LetT beared-black treestoring nentries, andlethbetheheight\nofT. Wejustifythisproposition byestablishing thefollowingfact\nlog(n+1) h 2log(n+1).\n\u2264 \u2264\nLet d be the common black depth of all the external nodes of T. Let T\u2032 be the\n(2,4) tree associated with T, and let h\u2032 be the height of T\u2032. Because of the corre-\nspondence between red-black trees and (2,4) trees, we know that h\u2032 =d. Hence,\nby Proposition 10.8, d =h\u2032 log(n+1). By the internal node property, h 2d.\n\u2264 \u2264\nThus, we obtain h 2log(n+1). The other inequality, log(n+1) h, follows\n\u2264 \u2264\nfromProposition 7.10andthefactthatT hasninternal nodes.\nWe assume that a red-black tree is realized with a linked structure for binary\ntrees (Section 7.3.4), in which we store a map entry and a color indicator at each\nnode. Thus, the space requirement for storing n keys is O(n). The algorithm for\nsearching inared-black treeT isthesameasthatforastandard binarysearch tree\n(Section10.1). Thus,searching inared-black treetakesO(logn)time.\n10.5.1 Update Operations\nPerforming the update operations in a red-black tree is similar to that of a binary\nsearchtree,exceptthatwemustadditionally restorethecolorproperties.\nInsertion\nNowconsider the insertion of an entry with key k into ared-black tree T, keeping\nin mind the correspondence between T and its associated (2,4) tree T\u2032 and the\ninsertion algorithm for T\u2032. The algorithm initially proceeds as in a binary search\ntree(Section10.1.2). Namely,wesearchforkinT untilwereachanexternalnode\nofT,andwereplacethisnodewithaninternalnodez,storing(k,x)andhavingtwo\nexternal-node children. If z is the root of T, we color z black, else we color z red.\nWealsocolorthechildrenofzblack. Thisactioncorrespondstoinserting(k,x)into\nanodeofthe(2,4)treeT\u2032 withexternalchildren. Inaddition, thisactionpreserves\ntheroot,external,anddepthpropertiesofT,butitmayviolatetheinternalproperty.\nIndeed,ifzisnottherootofT andtheparentvofzisred,thenwehaveaparentand\nachild(namely, vandz)thatarebothred. Notethatbytherootproperty, vcannot\nbetheroot ofT, andbythe internal property (which waspreviously satisfied), the\nparent uofvmustbeblack. Sincezandits parent are red, but z\u2019sgrandparent uis\nblack,wecallthisviolation oftheinternal property adoubleredatnodez.\nToremedyadoublered,weconsider twocases.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 476 \u2014 #498\ni i\n476 Chapter10. SearchTrees\nCase1: TheSiblingwofvisBlack. (See Figure 10.29.) In this case, the double\nreddenotesthefactthatwehavecreatedinourred-blacktreeT amalformed\nreplacementforacorresponding 4-nodeofthe(2,4)treeT\u2032,whichhasasits\nchildren the four black children of u, v, and z. Our malformed replacement\nhasonerednode(v)thatistheparentofanotherrednode(z),whilewewant\nit to have the two red nodes as siblings instead. To fix this problem, we\nperform a trinode restructuring of T. The trinode restructuring is done by\ntheoperationrestructure(z),whichconsistsofthefollowingsteps(seeagain\nFigure10.29;thisoperation isalsodiscussed inSection10.2):\nTake node z, its parent v, and grandparent u, and temporarily relabel\n\u2022\nthem as a, b, and c, in left-to-right order, so that a, b, and c will be\nvisitedinthisorderbyaninordertreetraversal.\nReplace the grandparent u with the node labeled b, and make nodes a\n\u2022\nandcthechildren ofb,keeping inorderrelationships unchanged.\nAfterperformingtherestructure(z)operation,wecolorbblackandwecolor\naandcred. Thus,therestructuring eliminatesthedoubleredproblem.\n(a)\n(b)\nFigure 10.29: Restructuring a red-black tree to remedy a double red: (a) the four\nconfigurations foru,v,andzbeforerestructuring; (b)afterrestructuring.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 477 \u2014 #499\ni i\n10.5. Red-BlackTrees 477\nCase2: TheSiblingwofvisRed. (SeeFigure10.30.) Inthiscase,thedoublered\ndenotes an overflow in the corresponding (2,4) tree T. To fix the problem,\nweperform theequivalent ofasplit operation. Namely, wedoarecoloring:\nwecolor v and w black and their parent u red (unless uis the root, in which\ncase, it is colored black). It is possible that, after such a recoloring, the\ndouble redproblem reappears, although higher upinthetreeT,sinceumay\nhave a red parent. If the double red problem reappears at u, then we repeat\nthe consideration of the two cases at u. Thus, a recoloring either eliminates\nthe double red problem at node z, or propagates itto the grandparent u of z.\nWe continue going up T performing recolorings until wefinally resolve the\ndoubleredproblem(witheitherafinalrecoloringoratrinoderestructuring).\nThus, the number ofrecolorings caused byaninsertion isnomorethan half\ntheheightoftreeT,thatis,nomorethanlog(n+1)byProposition 10.9.\n(a)\n(b)\nFigure10.30: Recoloring to remedy the double red problem: (a) before recoloring\nandthecorresponding 5-node intheassociated (2,4)treebeforethesplit;(b)after\ntherecoloring(andcorrespondingnodesintheassociated(2,4)treeafterthesplit).\nFigures10.31and10.32showasequenceofinsertionoperationsinared-black\ntree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 478 \u2014 #500\ni i\n478 Chapter10. SearchTrees\n(a) (b) (c) (d)\n(e) (f) (g) (h)\n(i) (j)\n(k) (l)\nFigure 10.31: A sequence of insertions in a red-black tree: (a) initial tree; (b) in-\nsertion of7; (c)insertion of12, which causes adouble red; (d) after restructuring;\n(e)insertionof15,whichcausesadoublered;(f)afterrecoloring(therootremains\nblack); (g) insertion of 3; (h) insertion of 5; (i) insertion of 14, which causes a\ndouble red; (j) after restructuring; (k) insertion of 18, which causes a double red;\n(l)afterrecoloring. (Continues inFigure10.32.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 479 \u2014 #501\ni i\n10.5. Red-BlackTrees 479\n(m) (n)\n(o) (p)\n(q)\nFigure 10.32: A sequence of insertions in a red-black tree: (m) insertion of 16,\nwhichcausesadoublered;(n)afterrestructuring; (o)insertionof17,whichcauses\na double red; (p) after recoloring there is again a double red, to be handled by a\nrestructuring; (q)afterrestructuring. (Continued fromFigure10.31.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 480 \u2014 #502\ni i\n480 Chapter10. SearchTrees\nThecasesforinsertionimplyaninterestingpropertyforred-blacktrees. Namely,\nsincetheCase1actioneliminates thedouble-red problem withasingle trinodere-\nstructuring andtheCase2actionperformsnorestructuring operations, atmostone\nrestructuring isneeded inared-black treeinsertion. Bytheaboveanalysis andthe\nfactthatarestructuring orrecoloring takesO(1)time,wehavethefollowing.\nProposition 10.10: Theinsertionofakey-valueentryinared-blacktreestoring\nn entriescanbedoneinO(logn) timeandrequiresO(logn) recoloringsandone\ntrinoderestructuring(arestructureoperation).\nRemoval\nSuppose now that we are asked to remove an entry with key k from a red-black\ntree T. Removing such an entry initially proceeds like a binary search tree (Sec-\ntion 10.1.2). First, we search for a node u storing such an entry. If node u does\nnot have an external child, we find the internal node v following u in the inorder\ntraversalofT,movetheentryatvtou,andperformtheremovalatv. Thus,wemay\nconsideronlytheremovalofanentrywithkeykstoredatanodevwithanexternal\nchild w. Also, as we did for insertions, we keep in mind the correspondence be-\ntweenred-black tree T anditsassociated (2,4) treeT\u2032 (andtheremovalalgorithm\nforT\u2032).\nToremovetheentrywithkeykfromanodevofT withanexternalchildwwe\nproceed as follows. Let r be the sibling of w and x be the parent of v. Weremove\nnodes v and w, and make r a child of x. If v was red (hence r is black) or r is red\n(hencevwasblack), wecolorr blackandwearedone. If,instead, r isblackandv\nwasblack, then, topreserve thedepth property, wegiver afictitious double black\ncolor. We now have a color violation, called the double black problem. A double\nblack in T denotes an underflow in the corresponding (2,4) tree T\u2032. Recall that x\nistheparentofthedouble blacknoder. Toremedythedouble-black problem atr,\nweconsiderthreecases.\nCase1: TheSibling y of r is Black and Has a Red Child z. (See Figure 10.33.)\nResolving this case corresponds to a transfer operation in the (2,4) tree T\u2032.\nWe perform a trinode restructuring by means of operation restructure(z).\nRecall that the operation restructure(z) takes the node z, its parent y, and\ngrandparentx,labelsthemtemporarilylefttorightasa,b,andc,andreplaces\nx with the node labeled b, making it the parent of the other two. (See the\ndescription of restructure in Section 10.2.) We color a and c black, give b\ntheformercolorofx,andcolorrblack. Thistrinoderestructuringeliminates\nthe double black problem. Hence, at most one restructuring isperformed in\naremovaloperation inthiscase.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 481 \u2014 #503\ni i\n10.5. Red-BlackTrees 481\n(a)\n(b)\n(c)\nFigure10.33:Restructuringofared-blacktreetoremedythedoubleblackproblem:\n(a) and (b) configurations before the restructuring, where r is a right child and\nthe associated nodes inthecorresponding (2,4) tree before the transfer (twoother\nsymmetricconfigurationswhererisaleftchildarepossible);(c)configurationafter\ntherestructuring andtheassociated nodes inthecorresponding (2,4) treeafterthe\ntransfer. The grey color for node x in parts (a) and (b) and for node b in part (c)\ndenotesthefactthatthisnodemaybecoloredeitherredorblack.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 482 \u2014 #504\ni i\n482 Chapter10. SearchTrees\nCase2: TheSiblingyofrisBlackandBothChildrenofyAreBlack. (SeeFig-\nures10.34and10.35.) Resolvingthiscasecorresponds toafusionoperation\ninthecorresponding (2,4)treeT\u2032. Wedoarecoloring;wecolorrblack,we\ncolor y red, and, if x is red, we color it black (Figure 10.34); otherwise, we\ncolorxdoubleblack(Figure10.35). Hence,afterthisrecoloring, thedouble\nblack problem may reappear at the parent x of r. (See Figure 10.35.) That\nis, this recoloring either eliminates the double black problem or propagates\nitintotheparentofthecurrentnode. Wethenrepeataconsideration ofthese\nthreecasesattheparent. Thus,sinceCase1performsatrinoderestructuring\noperation andstops(and,aswewillsoonsee,Case3issimilar), thenumber\nofrecolorings caused byaremovalisnomorethanlog(n+1).\n(a)\n(b)\nFigure10.34:Recoloringofared-blacktreethatfixesthedoubleblackproblem: (a)\nbefore the recoloring and corresponding nodes in the associated (2,4) tree before\nthe fusion (other similar configurations are possible); (b) after the recoloring and\ncorresponding nodesintheassociated (2,4)treeafterthefusion.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 483 \u2014 #505\ni i\n10.5. Red-BlackTrees 483\n(a)\n(b)\nFigure10.35: Recoloring ofared-blacktreethatpropagates thedoubleblackprob-\nlem: (a) configuration before the recoloring and corresponding nodes in the asso-\nciated (2,4) tree before the fusion (other similar configurations are possible); (b)\nconfiguration after the recoloring and corresponding nodes in the associated (2,4)\ntreeafterthefusion.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 484 \u2014 #506\ni i\n484 Chapter10. SearchTrees\nCase3: TheSiblingyofrIsRed. (See Figure 10.36.) In this case, we perform\nan adjustment operation, as follows. If y is the right child of x, let z be the\nright child of y; otherwise, let z be the left child of y. Execute the trinode\nrestructuring operation restructure(z), whichmakes ytheparent ofx. Color\ny black and x red. An adjustment corresponds to choosing a different rep-\nresentation of a3-node in the (2,4) tree T\u2032. After the adjustment operation,\nthesibling ofrisblack, andeitherCase1orCase2applies, withadifferent\nmeaning of x and y. Note that if Case 2 applies, the double-black problem\ncannot reappear. Thus, to complete Case 3 we make one more application\nof either Case 1 or Case 2 above and we are done. Therefore, at most one\nadjustment isperformed inaremovaloperation.\n(a)\n(b)\nFigure 10.36: Adjustment of a red-black tree in the presence of a double black\nproblem: (a) configuration before the adjustment and corresponding nodes in the\nassociated(2,4)tree(asymmetricconfigurationispossible);(b)configurationafter\ntheadjustment withthesamecorresponding nodesintheassociated (2,4)tree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 485 \u2014 #507\ni i\n10.5. Red-BlackTrees 485\nFrom the above algorithm description, we see that the tree updating needed\nafter a removal involves an upward march in the tree T, while performing at most\naconstant amountofwork(inarestructuring, recoloring, oradjustment) pernode.\nThus, since any changes we make at a node in T during this upward march takes\nO(1)time(becauseitaffectsaconstantnumberofnodes), wehavethefollowing.\nProposition 10.11: Thealgorithmforremovinganentryfromared-blacktree\nwithn entriestakesO(logn) timeandperformsO(logn) recoloringsandatmost\noneadjustmentplusoneadditionaltrinoderestructuring.Thus,itperformsatmost\ntworestructureoperations.\nIn Figures 10.37 and 10.38, we show a sequence of removal operations on a\nred-black tree. We illustrate Case 1 restructurings in Figure 10.37(c) and (d). We\nillustrate Case 2 recolorings at several places in Figures 10.37 and 10.38. Finally,\ninFigure10.38(i)and(j),weshowanexampleofaCase3adjustment.\n(a) (b)\n(c) (d)\nFigure 10.37: Sequence of removals from a red-black tree: (a) initial tree; (b) re-\nmoval of 3; (c) removal of 12, causing a double black (handled by restructuring);\n(d)afterrestructuring. (Continues inFigure10.38.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 486 \u2014 #508\ni i\n486 Chapter10. SearchTrees\n(e) (f)\n(g) (h)\n(i) (j)\n(k)\nFigure10.38: Sequence of removals in a red-black tree : (e) removal of 17; (f) re-\nmoval of 18, causing a double black (handled by recoloring); (g) after recoloring;\n(h)removalof15;(i)removalof16,causingadoubleblack(handledbyanadjust-\nment);(j)aftertheadjustmentthedoubleblackneedstobehandledbyarecoloring;\n(k)aftertherecoloring. (Continued fromFigure10.37.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 487 \u2014 #509\ni i\n10.5. Red-BlackTrees 487\nPerformance of Red-Black Trees\nTable10.4summarizes therunning timesofthemainoperations ofamaprealized\nby means of a red-black tree. We illustrate the justification for these bounds in\nFigure10.39.\nOperation Time\nsize,empty O(1)\nfind,insert,erase O(logn)\nTable10.4: Performance ofann-entry maprealized byared-black tree. Thespace\nusageisO(n).\nFigure 10.39: The running time of searches and updates in a red-black tree. The\ntime performance is O(1) per level, broken into a down phase, which typically\ninvolves searching, and anupphase, whichtypically involves recolorings andper-\nforminglocaltrinoderestructurings (rotations).\nThus, a red-black tree achieves logarithmic worst-case running times for both\nsearching andupdating inamap. Thered-black treedatastructure isslightlymore\ncomplicated than its corresponding (2,4) tree. Even so, a red-black tree has a\nconceptualadvantagethatonlyaconstantnumberoftrinoderestructuringsareever\nneededtorestorethebalanceinared-black treeafteranupdate.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 488 \u2014 #510\ni i\n488 Chapter10. SearchTrees\n10.5.2 C++ Implementation of a Red-Black Tree\nInthis section, wediscuss aC++implementation ofthedictionary ADTbymeans\nof a red-black tree. It is interesting to note that the C++ Standard Template Li-\nbrary uses ared-black treeinits implementation ofits classes mapand multimap.\nThe difference between the two is similar to the difference between our map and\ndictionary ADTs. The STL map class does not allow entries with duplicate keys,\nwhereas the STLmultimap does. There isasignificant difference, however, inthe\nbehavior ofthe map\u2019sinsert(k,x)function and ourmap\u2019s put(k,x)function. Ifthe\nkeykisnotpresent,bothfunctionsinsertthenewentry(k,x)inthemap. Ifthekey\nisalreadypresent,theSTLmapsimplyignorestherequest,andthecurrententryis\nunchanged. In contrast, our put function replaces the existing value with the new\nvaluex. Theimplementation presented inthissectionallowsformultiplekeys.\nWepresentthemajorportionsoftheimplementationinthissection. Tokeepthe\npresentation concise, wehaveomittedtheimplementations ofanumberofsimpler\nutilityfunctions.\nWebeginbypresenting theenhanced entryclass,calledRBEntry. Itisderived\nfromtheentryclassofCodeFragment10.3. Itinheritsthekeyandvaluemembers,\nanditdefinesamembervariablecol,whichstores thecolorofthenode. Thecolor\nis either RED or BLACK. It provides member functions for accessing and setting\nthis value. Thesefunctions have been protected, so auser cannot access them, but\nRBTreecan.\nenum Color RED, BLACK ; // node colors\n{ }\ntemplate <typename E>\nclass RBEntry : public E // a red-black entry\n{\nprivate:\nColor col; // node color\nprotected: // local types\ntypedef typename E::Key K; // key type\ntypedef typename E::Value V; // value type\nColor color() const return col; // get color\n{ }\nbool isRed() const return col == RED;\n{ }\nbool isBlack() const return col == BLACK;\n{ }\nvoid setColor(Color c) col = c;\n{ }\npublic: // public functions\nRBEntry(const K& k = K(), const V& v = V()) // constructor\n: E(k,v), col(BLACK)\n{ }\nfriend class RBTree<E>; // allow RBTree access\n;\n}\nCodeFragment10.19: A key-value entry for class RBTree, containing the associ-\natednode\u2019scolor.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 489 \u2014 #511\ni i\n10.5. Red-BlackTrees 489\nInCodeFragment 10.20, wepresent the classdefinition forRBTree. Thedec-\nlarationisalmostentirelyanalogoustothatofAVLTree,exceptthattheutilityfunc-\ntions used to maintain the structure are different. We have chosen to present only\nthe two most interesting utility functions, remedyDoubleRed and remedyDouble-\nBlack. The meanings of most of the omitted utilities are easy to infer. (For ex-\nample hasTwoExternalChildren(v) determines whether a node v has two external\nchildren.)\ntemplate <typename E> // a red-black tree\nclass RBTree : public SearchTree< RBEntry<E> >\n{\npublic: // public types\ntypedef RBEntry<E> RBEntry; // an entry\ntypedef typename SearchTree<RBEntry>::Iterator Iterator; // an iterator\nprotected: // local types\ntypedef typename RBEntry::Key K; // a key\ntypedef typename RBEntry::Value V; // a value\ntypedef SearchTree<RBEntry> ST; // a search tree\ntypedef typename ST::TPos TPos; // a tree position\npublic: // public functions\nRBTree(); // constructor\nIterator insert(const K& k, const V& x); // insert (k,x)\nvoid erase(const K& k) throw(NonexistentElement); // remove key k entry\nvoid erase(const Iterator& p); // remove entry at p\nprotected: // utility functions\nvoid remedyDoubleRed(const TPos& z); // fix double-red z\nvoid remedyDoubleBlack(const TPos& r); // fix double-black r\n// ...(other utilities omitted)\n;\n}\nCodeFragment10.20: ClassRBTree, whichimplements adictionary ADTusing a\nred-black tree.\nWefirstdiscuss theimplementation ofthefunction insert(k,x), whichisgiven\nin Code Fragment 10.21. We invoke the inserter utility function of SearchTree,\nwhichreturnsthepositionoftheinsertednode. Ifthisnodeistherootofthesearch\ntree,wesetitscolortoblack. Otherwise,wesetitscolortoredandcheckwhether\nrestructuring isneededbyinvoking remedyDoubleRed.\nThislatterutility performs thenecessary checks andrestructuring presented in\nthediscussion ofinsertion inSection10.5.1. Letzdenotethelocationofthenewly\ninserted node. If both z and its parent are red, we need to remedy the situation.\nTo do so, we consider two cases. Let v denote z\u2019s parent and let w be v\u2019s sibling.\nIf w is black, we fall under Case 1 of the insertion update procedure. We apply\nrestructuring at z. The top vertex of the resulting subtree, denoted by v, is set to\nblack,anditstwochildren aresettored.\nOntheotherhand,ifwisred,thenwefallunderCase2oftheupdateprocedure.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 490 \u2014 #512\ni i\n490 Chapter10. SearchTrees\nWeresolvethesituationbycoloringbothvanditssiblingwblack. Iftheircommon\nparent is not the root, we set its color to red. This may induce another double-red\nproblem atv\u2019sparentu,soweinvoke thefunctionrecursively onu.\n/* RBTree E :: */ // insert (k,x)\nh i\nIterator insert(const K& k, const V& x)\n{\nTPos v = inserter(k, x); // insert in base tree\nif (v == ST::root())\nsetBlack(v); // root is always black\nelse\n{\nsetRed(v);\nremedyDoubleRed(v); // rebalance if needed\n}\nreturn Iterator(v);\n}\n/* RBTree E :: */ // fix double-red z\nh i\nvoid remedyDoubleRed(const TPos& z)\n{\nTPos v = z.parent(); // v is z\u2019s parent\nif (v == ST::root() v >isBlack()) return; // v is black, all ok\n|| \u2212\n// z, v are double-red\nif (sibling(v) >isBlack()) // Case 1: restructuring\n\u2212 {\nv = restructure(z);\nsetBlack(v); // top vertex now black\nsetRed(v.left()); setRed(v.right()); // set children red\n}\nelse // Case 2: recoloring\n{\nsetBlack(v); setBlack(sibling(v)); // set v and sibling black\nTPos u = v.parent(); // u is v\u2019s parent\nif (u == ST::root()) return;\nsetRed(u); // make u red\nremedyDoubleRed(u); // may need to fix u now\n}\n}\nCode Fragment 10.21: The functions related to insertion for class RBTree. The\nfunctioninsertinvokestheinserterutilityfunction, whichwasgiveninCodeFrag-\nment10.10.\nFinally,inCodeFragment10.22,wepresenttheimplementationoftheremoval\nfunction for the red-black tree. (We have omitted the simpler iterator-based erase\nfunction.) The removal follows the process discussed in Section 10.5.1. We first\nsearchforthekeytoberemoved,andgenerate anexception ifitisnotfound. Oth-\nerwise,weinvoke theeraserutilityofclassSearchTree,whichreturnstheposition\nof the node r that replaced the deleted node. If either r or its former parent was\nred,wecolorrblackandwearedone. Otherwise,wefaceapotentialdouble-black\nproblem. Wehandlethisbyinvoking thefunctionremedyDoubleBlack.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 491 \u2014 #513\ni i\n10.5. Red-BlackTrees 491\n/* RBTree E :: */ // remove key k entry\nh i\nvoid erase(const K& k) throw(NonexistentElement)\n{\nTPos u = finder(k, ST::root()); // find the node\nif (Iterator(u) == ST::end())\nthrow NonexistentElement(\"Erase of nonexistent\");\nTPos r = eraser(u); // remove u\nif (r == ST::root() r >isRed() wasParentRed(r))\n|| \u2212 ||\nsetBlack(r); // fix by color change\nelse // r, parent both black\nremedyDoubleBlack(r); // fix double-black r\n}\n/* RBTree E :: */ // fix double-black r\nh i\nvoid remedyDoubleBlack(const TPos& r)\n{\nTPos x = r.parent(); // r\u2019s parent\nTPos y = sibling(r); // r\u2019s sibling\nif (y >isBlack())\n\u2212 {\nif (y.left() >isRed() y.right() >isRed()) // Case 1: restructuring\n\u2212 || \u2212 {\n// z is y\u2019s red child\nTPos z = (y.left() >isRed() ? y.left() : y.right());\n\u2212\nColor topColor = x >color(); // save top vertex color\n\u2212\nz = restructure(z); // restructure x,y,z\nsetColor(z, topColor); // give z saved color\nsetBlack(r); // set r black\nsetBlack(z.left()); setBlack(z.right()); // set z\u2019s children black\n}\nelse // Case 2: recoloring\n{\nsetBlack(r); setRed(y); // r=black, y=red\nif (x >isBlack() && !(x == ST::root()))\n\u2212\nremedyDoubleBlack(x); // fix double-black x\nsetBlack(x);\n}\n}\nelse // Case 3: adjustment\n{\nTPos z = (y == x.right() ? y.right() : y.left()); // grandchild on y\u2019s side\nrestructure(z); // restructure x,y,z\nsetBlack(y); setRed(x); // y=black, x=red\nremedyDoubleBlack(r); // fix r by Case 1 or 2\n}\n}\nCode Fragment 10.22: The functions related to removal for class RBTree. The\nfunction erase invokes the eraser utility function, which was given in Code Frag-\nment10.11.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 492 \u2014 #514\ni i\n492 Chapter10. SearchTrees\n10.6 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-10.1 Ifweinserttheentries(1,A),(2,B),(3,C),(4,D),and(5,E),inthisorder,\nintoaninitiallyemptybinarysearchtree,whatwillitlooklike?\nR-10.2 We defined a binary search tree so that keys equal to a node\u2019s key can\nbe in either the left or right subtree of that node. Suppose we change the\ndefinition so that werestrict equal keys tothe right subtree. Whatmust a\nsubtreeofabinarysearchtreecontainingonlyequalkeyslooklikeinthis\ncase?\nR-10.3 Insert, into an empty binary search tree, entries with keys 30, 40, 24, 58,\n48,26,11,13(inthisorder). Drawthetreeaftereachinsertion.\nR-10.4 Howmanydifferentbinarysearchtreescanstorethekeys 1,2,3 ?\n{ }\nR-10.5 Jack claims that theorder in whichafixedsetof entries isinserted into a\nbinarysearchtreedoesnotmatter\u2014thesametreeresultseverytime. Give\nasmallexamplethatprovesheiswrong.\nR-10.6 Rose claims that the order in which a fixed set of entries is inserted into\nanAVLtreedoesnotmatter\u2014thesameAVLtreeresultseverytime. Give\nasmallexamplethatprovessheiswrong.\nR-10.7 Aretherotations inFigures10.9and10.11singleordoublerotations?\nR-10.8 Draw the AVL tree resulting from the insertion of an entry with key 52\nintotheAVLtreeofFigure10.11(b).\nR-10.9 Draw the AVL tree resulting from the removal of the entry with key 62\nfromtheAVLtreeofFigure10.11(b).\nR-10.10 Explain why performing a rotation in an n-node binary tree represented\nusingavectortakes\u2126(n)time.\nR-10.11 IsthesearchtreeofFigure10.1(a)a(2,4)tree? Whyorwhynot?\nR-10.12 An alternative way of performing a split at a node v in a (2,4) tree is to\npartition v into v\u2032 and v\u2032\u2032, with v\u2032 being a 2-node and v\u2032\u2032 a3-node. Which\nofthekeysk ,k ,k ,ork dowestoreatv\u2019sparentinthiscase? Why?\n1 2 3 4\nR-10.13 Cal claims that a (2,4) tree storing a set of entries will always have the\nsame structure, regardless of the order in which the entries are inserted.\nShowthatheiswrong.\nR-10.14 Draw four different red-black trees that correspond to the same (2,4)\ntree.\nR-10.15 ConsiderthesetofkeysK = 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 .\n{ }\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 493 \u2014 #515\ni i\n10.6. Exercises 493\na. Draw a (2,4) tree storing K as its keys using the fewest number of\nnodes.\nb. Drawa(2,4) treestoring K asits keys using the maximum number\nofnodes.\nR-10.16 Considerthesequence ofkeys(5,16,22,45,2,10,18,30,50,12,1). Draw\ntheresultofinserting entrieswiththesekeys(inthegivenorder)into\na. Aninitially empty(2,4)tree.\nb. Aninitially emptyred-black tree.\nR-10.17 Forthefollowing statements aboutred-black trees, provide ajustification\nforeachtruestatementandacounterexample foreachfalseone.\na. Asubtree ofared-black treeisitselfared-black tree.\nb. Thesiblingofanexternal nodeiseitherexternaloritisred.\nc. Thereisaunique(2,4)treeassociated withagivenred-black tree.\nd. Thereisauniquered-black treeassociated withagiven(2,4)tree.\nR-10.18 Drawanexamplered-black treethatisnotanAVLtree.\nR-10.19 Consider a tree T storing 100,000 entries. What is the worst-case height\nofT inthefollowingcases?\na. T isanAVLtree.\nb. T isa(2,4)tree.\nc. T isared-black tree.\nd. T isasplaytree.\ne. T isabinarysearchtree.\nR-10.20 Perform the following sequence of operations in an initially empty splay\ntreeanddrawthetreeaftereachsetofoperations.\na. Insertkeys0,2,4,6,8,10,12,14,16,18,inthisorder.\nb. Searchforkeys1,3,5,7,9,11,13,15,17,19,inthisorder.\nc. Deletekeys0,2,4,6,8,10,12,14,16,18,inthisorder.\nR-10.21 What does a splay tree look like if its entries are accessed in increasing\norderbytheirkeys?\nR-10.22 Explain how to use an AVL tree or a red-black tree to sort n comparable\nelementsinO(nlogn)timeintheworstcase.\nR-10.23 Can weuse a splay tree to sort n comparable elements in O(nlogn) time\nintheworstcase? Whyorwhynot?\nR-10.24 Explain why you would get the same output in an inorder listing of the\nentriesinabinarysearchtree,T,independent ofwhetherT ismaintained\ntobeanAVLtree,splaytree,orred-black tree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 494 \u2014 #516\ni i\n494 Chapter10. SearchTrees\nCreativity\nC-10.1 Describeamodificationtothebinarysearchtreedatastructurethatwould\nallow you tofindthe median entry, thatis theentry with rank n/2 , in a\n\u230a \u230b\nbinary search tree. Describe both the modification and the algorithm for\nfindingthemedianassumingallkeysaredistinct.\nC-10.2 Design a variation of algorithm TreeSearch for performing the operation\nfindAll(k)inanordered dictionary implemented withabinarysearchtree\nT,andshowthatitrunsintimeO(h+s),wherehistheheightofT ands\nisthesizeofthecollection returned.\nC-10.3 Describe howtoperform anoperation eraseAll(k),whichremovesallthe\nentries whose keys equal k in an ordered dictionary implemented with a\nbinary search tree T, and show that this method runs in time O(h+s),\nwherehistheheightofT andsisthesizeoftheiteratorreturned.\nC-10.4 Drawaschematic ofanAVLtreesuchthatasingleeraseoperation could\nrequire\u2126(logn)trinoderestructurings(orrotations)fromaleaftotheroot\ninordertorestoretheheight-balance property.\nC-10.5 Showhowtoperformanoperation,eraseAll(k),whichremovesallentries\nwithkeysequal toK,inanordered dictionary implemented withanAVL\ntree in time O(slogn), where n is the number of entries in the map and s\nisthesizeoftheiteratorreturned.\nC-10.6 Describe the changes that would need to be made to the binary search\ntreeimplementation giveninthebook toallowittobeusedtosupport an\nordereddictionary, whereweallowfordifferententrieswithequalkeys.\nC-10.7 Ifwemaintainareferencetothepositionoftheleft-mostinternalnodeof\nan AVLtree, then operation first (Section 9.3) can be performed in O(1)\ntime. Describe howtheimplementation oftheother mapfunctions needs\ntobemodifiedtomaintainareferencetotheleft-mostposition.\nC-10.8 Show that any n-node binary tree can be converted to any other n-node\nbinarytreeusingO(n)rotations.\nC-10.9 Let M be an ordered map with n entries implemented by means of an\nAVLtree. Showhow toimplement the following operation on M intime\nO(logn+s),wheresisthesizeoftheiteratorreturned.\nfindAllInRange(k ,k ): Return an iterator of all the entries in M with\n1 2\nkeyksuchthatk k k .\n1 2\n\u2264 \u2264\nC-10.10 Let M be an ordered map with n entries. Show how to modify the AVL\ntreetoimplementthefollowingfunction forM intimeO(logn).\ncountAllInRange(k ,k ): ComputeandreturnthenumberofentriesinM\n1 2\nwithkeyksuchthatk k k .\n1 2\n\u2264 \u2264\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 495 \u2014 #517\ni i\n10.6. Exercises 495\nC-10.11 Drawasplaytree,T ,togetherwiththesequenceofupdatesthatproduced\n1\nit, and a red-black tree, T , on the same set of ten entries, such that a\n2\npreorder traversalofT wouldbethesameasapreorder traversalofT .\n1 2\nC-10.12 Show that the nodes that become unbalanced in an AVL tree during an\ninsert operation may be nonconsecutive on the path from the newly in-\nsertednodetotheroot.\nC-10.13 Show that at most one node in an AVL tree becomes unbalanced after\noperation removeAboveExternal is performed within the execution of a\nerasemapoperation.\nC-10.14 Showthatatmostonetrinode restructuring operation isneededtorestore\nbalanceafteranyinsertion inanAVLtree.\nC-10.15 Let T and U be (2,4) trees storing n and m entries, respectively, such\nthat all the entries in T have keys less than the keys of all the entries in\nU. Describe an O(logn+logm) time method for joining T andU into a\nsingletreethatstoresalltheentriesinT andU.\nC-10.16 Repeattheprevious problemforred-black treesT andU.\nC-10.17 JustifyProposition 10.7.\nC-10.18 The Boolean indicator used to mark nodes in a red-black tree as being\n\u201cred\u201d or \u201cblack\u201d is not strictly needed when we have distinct keys. De-\nscribe a scheme for implementing a red-black tree without adding any\nextraspacetostandard binarysearchtreenodes.\nC-10.19 LetT beared-black treestoringnentries,andletkbethekeyofanentry\ninT. ShowhowtoconstructfromT,inO(logn)time,twored-blacktrees\nT\u2032 and T\u2032\u2032, such that T\u2032 contains all the keys of T less than k, and T\u2032\u2032\ncontains allthekeysofT greaterthank. Thisoperation destroys T.\nC-10.20 Showthatthenodes ofanyAVLtreeT canbecolored \u201cred\u201d and\u201cblack\u201d\nsothatT becomesared-black tree.\nC-10.21 ThemergeableheapADTconsistsofoperationsinsert(k,x),removeMin(),\nunionWith(h), and min(), where the unionWith(h) operation performs a\nunion of the mergeable heap h with the present one, destroying the old\nversions of both. Describe a concrete implementation of the mergeable\nheapADTthatachievesO(logn)performance forallitsoperations.\nC-10.22 Consideravariationofsplaytrees,calledhalf-splaytrees,wheresplaying\nanodeatdepthd stopsassoonasthenodereachesdepth d/2 . Perform\n\u230a \u230b\nanamortizedanalysis ofhalf-splay trees.\nC-10.23 The standard splaying step requires two passes, one downward pass to\nfind the node x to splay, followed by an upward pass to splay the node\nx. Describe a method for splaying and searching for x in one downward\npass. Each substep now requires that you consider the next two nodes\nin the path down to x, with a possible zig substep performed at the end.\nDescribehowtoperform thezig-zig, zig-zag, andzigsteps.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 496 \u2014 #518\ni i\n496 Chapter10. SearchTrees\nC-10.24 Describeasequenceofaccessestoann-nodesplaytreeT,wherenisodd,\nthatresultsinT consistingofasinglechainofinternalnodeswithexternal\nnodechildren,suchthattheinternal-nodepathdownT alternatesbetween\nleftchildren andrightchildren.\nC-10.25 Explain how to implement a vector of n elements so that the functions\ninsertandattakeO(logn)timeintheworstcase.\nProjects\nP-10.1 Writeaprogramthatperformsasimplen-bodysimulation, called\u201cJump-\ningLeprechauns.\u201d Thissimulationinvolvesnleprechauns, numbered1to\nn. It maintains a gold value g for each leprechaun i, which begins with\ni\neach leprechaun starting out with a million dollars worth of gold, that is,\ng = 1000000 for each i = 1,2,...,n. In addition, the simulation also\ni\nmaintains, for each leprechaun, i, a place on the horizon, which is repre-\nsented as a double-precision floating point number, x. In each iteration\ni\nofthesimulation, thesimulation processes theleprechauns inorder. Pro-\ncessing a leprechaun i during this iteration begins by computing a new\nplaceonthehorizon fori,whichisdetermined bytheassignment\nx x +rg,\ni i i\n\u2190\nwhere r is a random floating-point number between 1 and 1. The lep-\n\u2212\nrechaun i then steals half the gold from the nearest leprechauns on either\nside ofhim and adds thisgold tohis gold value, g. Writeaprogram that\ni\ncanperformaseriesofiterations inthissimulationforagivennumber,n,\nof leprechauns. You must maintain the set of horizon positions using an\norderedmapdatastructure described inthischapter.\nP-10.2 Extend class BinarySearchTree (Section 10.1.3) to support the functions\noftheordered mapADT(seeSection9.3).\nP-10.3 ImplementaclassRestructurableNodeBinaryTreethatsupportsthefunc-\ntionsofthebinarytreeADT,plusafunctionrestructureforperforming a\nrotation operation. Thisclassisacomponent oftheimplementation ofan\nAVLtreegiveninSection10.2.2.\nP-10.4 Write a C++ class that implements all the functions of the ordered map\nADT(seeSection9.3)usinganAVLtree.\nP-10.5 Write a C++ class that implements all the functions of the ordered map\nADT(seeSection9.3)usinga(2,4)tree.\nP-10.6 Write a C++ class that implements all the functions of the ordered map\nADT(seeSection9.3)usingared-black tree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 12:30 \u2014 page 497 \u2014 #519\ni i\nChapterNotes 497\nP-10.7 Formathree-programmer team andhave each memberimplement amap\nusing adifferent search treedatastructure. Perform acooperative experi-\nmentalstudytocomparethespeedofthesethreeimplementations.\nP-10.8 Write a C++ class that can take any red-black tree and convert it into its\ncorresponding (2,4)treeandcantakeany(2,4)treeandconvertitintoits\ncorresponding red-black tree.\nP-10.9 ImplementthemapADTusingasplaytree,andcompareitsperformance\nexperimentally withtheSTLmapclass,whichusesared-black tree.\nP-10.10 Prepare an implementation of splay trees that uses bottom-up splaying\nas described in this chapter and another that uses top-down splaying as\ndescribed inExerciseC-10.23. Performextensiveexperimental studiesto\nseewhichimplementation isbetterinpractice, ifany.\nP-10.11 Implement a binary search tree data structure so that it can support the\ndictionary ADT, where different entries can have equal keys. In addi-\ntion,implementthefunctionsentrySetPreorder(),entrySetInorder(),and\nentrySetPostorder(),whichproduceaniterablecollectionoftheentriesin\nthebinarysearchtreeinthesameordertheywouldrespectivelybevisited\ninapreorder, inorder, andpostorder traversalofthetree.\nChapter Notes\nSomeofthedatastructuresdiscussedinthischapterareextensivelycoveredbyKnuthinhis\nSortingandSearchingbook[60],andbyMehlhornin[73].AVLtreesareduetoAdel\u2019son-\nVel\u2019skiiandLandis[1], whoinventedthis classofbalancedsearchtreesin1962. Binary\nsearchtrees,AVLtrees,andhashingaredescribedinKnuth\u2019sSortingandSearching[60]\nbook. Average-heightanalysesforbinarysearchtreescanbefoundinthebooksbyAho,\nHopcroft, and Ullman [5] and Cormen, Leiserson, Rivest and Stein [25]. The handbook\nbyGonnetandBaeza-Yates[37]containsa numberoftheoreticalandexperimentalcom-\nparisonsamongmapimplementations.Aho,Hopcroft,andUllman[4]discuss(2,3)trees,\nwhicharesimilarto(2,4)trees.[9].Variationsandinterestingpropertiesofred-blacktrees\narepresentedinapaperbyGuibasandSedgewick[42]. Thereaderinterestedinlearning\nmoreaboutdifferentbalancedtreedatastructuresisreferredtothebooksbyMehlhorn[73]\nandTarjan[95],andthebookchapterbyMehlhornandTsakalidis[75]. Knuth[60]isex-\ncellent additional reading that includes early approaches to balancing trees. Splay trees\nwereinventedbySleatorandTarjan[89](seealso[95]).\ni i\ni i\nThis page intentionally left blank\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 499 \u2014 #521\ni i\nChapter\n11\nSorting, Sets, and Selection\nContents\n11.1 Merge-Sort . . . . . . . . . . . . . . . . . . . . . . . . 500\n11.1.1 Divide-and-Conquer . . . . . . . . . . . . . . . . . . 500\n11.1.2 Merging Arrays and Lists . . . . . . . . . . . . . . . 505\n11.1.3 The Running Time of Merge-Sort . . . . . . . . . . 508\n11.1.4 C++ Implementations of Merge-Sort . . . . . . . . . 509\n\u22c6\n11.1.5 Merge-Sort and Recurrence Equations . . . . . . . 511\n11.2 Quick-Sort . . . . . . . . . . . . . . . . . . . . . . . . 513\n11.2.1 Randomized Quick-Sort . . . . . . . . . . . . . . . . 521\n11.2.2 C++ Implementations and Optimizations . . . . . . . 523\n11.3 Studying Sorting through an Algorithmic Lens . . . . 526\n11.3.1 A Lower Bound for Sorting . . . . . . . . . . . . . . 526\n11.3.2 Linear-Time Sorting: Bucket-Sort and Radix-Sort . . 528\n11.3.3 Comparing Sorting Algorithms . . . . . . . . . . . . 531\n11.4 Sets and Union/Find Structures . . . . . . . . . . . . 533\n11.4.1 The Set ADT . . . . . . . . . . . . . . . . . . . . . 533\n11.4.2 Mergable Sets and the Template Method Pattern . . 534\n11.4.3 Partitions with Union-Find Operations . . . . . . . . 538\n11.5 Selection . . . . . . . . . . . . . . . . . . . . . . . . . 542\n11.5.1 Prune-and-Search . . . . . . . . . . . . . . . . . . . 542\n11.5.2 Randomized Quick-Select . . . . . . . . . . . . . . . 543\n11.5.3 Analyzing Randomized Quick-Select . . . . . . . . . 544\n11.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 545\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 500 \u2014 #522\ni i\n500 Chapter11. Sorting,Sets,andSelection\n11.1 Merge-Sort\nIn this section, we present a sorting technique, called merge-sort, which can be\ndescribed inasimpleandcompactwayusingrecursion.\n11.1.1 Divide-and-Conquer\nMerge-sort is based on an algorithmic design pattern called divide-and-conquer.\nThedivide-and-conquer pattern consistsofthefollowingthreesteps:\n1. Divide: If the input size is smaller than a certain threshold (say, one or two\nelements), solve the problem directly using a straightforward method and\nreturn the solution obtained. Otherwise, divide the input data into two or\nmoredisjointsubsets.\n2. Recur: Recursivelysolvethesubproblems associated withthesubsets.\n3. Conquer: Take the solutions to the subproblems and \u201cmerge\u201d them into a\nsolution totheoriginal problem.\nUsing Divide-and-Conquer for Sorting\nRecall that in a sorting problem we are given a sequence of n objects, stored in a\nlinkedlistoranarray,togetherwithsomecomparatordefiningatotalorderonthese\nobjects,andweareaskedtoproduceanorderedrepresentation oftheseobjects. To\nallow for sorting of either representation, we describe our sorting algorithm at a\nhigh level for sequences and explain the details needed to implement it for linked\nlists and arrays. To sort a sequence S with n elements using the three divide-and-\nconquer steps,themerge-sort algorithm proceeds asfollows:\n1. Divide: If S has zero or one element, return S immediately; it is already\nsorted. Otherwise (S has at least two elements), remove all the elements\nfrom S and put them into two sequences, S and S , each containing about\n1 2\nhalf of the elements of S; that is, S contains the first n/2 elements of S,\n1\n\u2308 \u2309\nandS contains theremaining n/2 elements.\n2\n\u230a \u230b\n2. Recur: Recursivelysortsequences S andS .\n1 2\n3. Conquer: Put back the elements into S by merging the sorted sequences S\n1\nandS intoasortedsequence.\n2\nIn reference tothe divide step, werecall that the notation x indicates theceiling\n\u2308 \u2309\nof x, that is, the smallest integer m, such that x m. Similarly, the notation x\n\u2264 \u230a \u230b\nindicates thefloorofx,thatis,thelargestintegerk,suchthatk x.\n\u2264\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 501 \u2014 #523\ni i\n11.1. Merge-Sort 501\nWecanvisualizeanexecutionofthemerge-sortalgorithmbymeansofabinary\ntreeT,calledthemerge-sorttree. EachnodeofT representsarecursiveinvocation\n(orcall)ofthemerge-sortalgorithm. WeassociatethesequenceSthatisprocessed\nbytheinvocation associated withv,witheachnodevofT. Thechildren ofnode v\nareassociatedwiththerecursivecallsthatprocessthesubsequences S andS ofS.\n1 2\nTheexternalnodesofT areassociatedwithindividualelementsofS,corresponding\ntoinstances ofthealgorithm thatmakenorecursive calls.\nFigure 11.1 summarizes an execution of the merge-sort algorithm by showing\ntheinput and output sequences processed ateachnode ofthe merge-sort tree. The\nstep-by-stepevolutionofthemerge-sorttreeisshowninFigures11.2through11.4.\nThis algorithm visualization in terms of the merge-sort tree helps us analyze\nthe running time of the merge-sort algorithm. In particular, since the size of the\ninput sequence roughly halves at each recursive call of merge-sort, the height of\nthemerge-sort treeisaboutlogn(recallthatthebaseoflogis2ifomitted).\n(a)\n(b)\nFigure 11.1: Merge-sort tree T for an execution of the merge-sort algorithm on a\nsequence with eight elements: (a) input sequences processed at each node of T;\n(b)outputsequences generated ateachnodeofT.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 502 \u2014 #524\ni i\n502 Chapter11. Sorting,Sets,andSelection\n(a) (b)\n(c) (d)\n(e) (f)\nFigure 11.2: Visualization of an execution of merge-sort. Each node of the tree\nrepresentsarecursivecallofmerge-sort. Thenodesdrawnwithdashedlinesrepre-\nsentcallsthathavenotbeenmadeyet. Thenodedrawnwiththicklinesrepresents\nthecurrent call. Theempty nodes drawnwiththinlines represent completed calls.\nTheremainingnodes(drawnwiththinlinesandnotempty)represent callsthatare\nwaitingforachildinvocation toreturn. (Continues inFigure11.3.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 503 \u2014 #525\ni i\n11.1. Merge-Sort 503\n(g) (h)\n(i) (j)\n(k) (l)\nFigure 11.3: Visualization of an execution of merge-sort. (Continues in Fig-\nure11.4.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 504 \u2014 #526\ni i\n504 Chapter11. Sorting,Sets,andSelection\n(m) (n)\n(o) (p)\nFigure 11.4: Visualization of an execution of merge-sort. Several invocations are\nomitted between (l) and (m) and between (m) and (n). Note the conquer step per-\nformedinstep(p). (Continued fromFigure11.3.)\nProposition 11.1: Themerge-sorttreeassociatedwithanexecutionofmerge-\nsortonasequenceofsizenhasheight logn .\n\u2308 \u2309\nWeleavethejustificationofProposition11.1asasimpleexercise(R-11.4). We\nusethisproposition toanalyze therunningtimeofthemerge-sort algorithm.\nHaving given an overview of merge-sort and an illustration of how it works,\nlet us consider each of the steps of this divide-and-conquer algorithm in more de-\ntail. The divide and recur steps of the merge-sort algorithm are simple; dividing a\nsequence of size n involves separating it at the element with index n/2 , and the\n\u2308 \u2309\nrecursive calls simply involve passing these smaller sequences asparameters. The\ndifficult step is the conquer step, which merges twosorted sequences into a single\nsorted sequence. Thus, before we present our analysis of merge-sort, we need to\nsaymoreabouthowthisisdone.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 505 \u2014 #527\ni i\n11.1. Merge-Sort 505\n11.1.2 Merging Arrays and Lists\nTo merge two sorted sequences, it is helpful to know if they are implemented as\narrays or lists. We begin with the array implementation, which we show in Code\nFragment11.1. WeillustrateastepinthemergeoftwosortedarraysinFigure11.5.\nAlgorithmmerge(S ,S ,S):\n1 2\nInput: Sorted sequences S and S and an empty sequence S, all of which are\n1 2\nimplemented asarrays\nOutput: Sortedsequence Scontaining theelementsfromS andS\n1 2\ni j 0\n\u2190 \u2190\nwhilei<S .size()and j<S .size()do\n1 2\nifS [i] S [j]then\n1 2\n\u2264\nS.insertBack(S [i]) copyithelementofS toendofS\n1 1\n{ }\ni i+1\n\u2190\nelse\nS.insertBack(S [j]) copy jthelementofS toendofS\n2 2\n{ }\nj j+1\n\u2190\nwhilei<S .size()do copytheremainingelementsofS toS\n1 1\n{ }\nS.insertBack(S [i])\n1\ni i+1\n\u2190\nwhile j<S .size()do copytheremainingelementsofS toS\n2 2\n{ }\nS.insertBack(S [j])\n2\nj j+1\n\u2190\nCodeFragment11.1: Algorithm formergingtwosortedarray-based sequences.\n(a) (b)\nFigure11.5: Astepinthemerge oftwosorted arrays: (a)before thecopy step; (b)\nafterthecopystep.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 506 \u2014 #528\ni i\n506 Chapter11. Sorting,Sets,andSelection\nMerging Two Sorted Lists\nInCodeFragment11.2,wegivealist-basedversionofalgorithmmerge,formerg-\ningtwosorted sequences, S andS ,implemented aslinkedlists. Themainideais\n1 2\ntoiterativelyremovethesmallestelementfromthefrontofoneofthetwolistsand\naddittotheendoftheoutputsequence, S,untiloneofthetwoinputlistsisempty,\nat which point we copy the remainder of the other list to S. We show an example\nexecutionofthisversionofalgorithm mergeinFigure11.6.\nAlgorithmmerge(S ,S ,S):\n1 2\nInput: Sorted sequences S and S and an empty sequence S, implemented as\n1 2\nlinkedlists\nOutput: Sortedsequence Scontaining theelementsfromS andS\n1 2\nwhileS isnotemptyandS isnotemptydo\n1 2\nifS .front().element() S .front().element()then\n1 2\n\u2264\nmovethefirstelementofS attheendofS\n1\n{ }\nS.insertBack(S .eraseFront())\n1\nelse\nmovethefirstelementofS attheendofS\n2\n{ }\nS.insertBack(S .eraseFront())\n2\nmovetheremainingelementsofS toS\n1\n{ }\nwhileS isnotemptydo\n1\nS.insertBack(S .eraseFront())\n1\nmovetheremainingelementsofS toS\n2\n{ }\nwhileS isnotemptydo\n2\nS.insertBack(S .eraseFront())\n2\nCode Fragment 11.2: Algorithm merge for merging two sorted sequences imple-\nmentedaslinkedlists.\nThe Running Time for Merging\nWe analyze the running time of the merge algorithm by making some simple ob-\nservations. Let n and n be the number of elements of S and S , respectively.\n1 2 1 2\nAlgorithm merge hasthree whileloops. Independent ofwhether weare analyzing\nthe array-based version or the list-based version, the operations performed inside\neach loop take O(1) time each. The key observation is that during each iteration\nof one of the loops, one element is copied or moved from either S or S into S\n1 2\n(and that element isno longer considered). Since noinsertions are performed into\nS or S , this observation implies that the overall number of iterations of the three\n1 2\nloopsisn +n . Thus,therunningtimeofalgorithm mergeisO(n +n ).\n1 2 1 2\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 507 \u2014 #529\ni i\n11.1. Merge-Sort 507\n(a) (b) (c)\n(d) (e) (f)\n(g) (h)\n(i)\nFigure11.6: Anexecution ofthealgorithm mergeshowninCodeFragment11.2.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 508 \u2014 #530\ni i\n508 Chapter11. Sorting,Sets,andSelection\n11.1.3 The Running Time of Merge-Sort\nNow that we have given the details of the merge-sort algorithm in both its array-\nbasedandlist-basedversions,andwehaveanalyzedtherunningtimeofthecrucial\nmerge algorithm used in the conquer step, let us analyze the running time of the\nentire merge-sort algorithm, assuming itis given aninput sequence of nelements.\nFor simplicity, we restrict our attention to the case where n is a power of 2. We\nleaveitasanexercise(ExerciseR-11.7)toshowthattheresultofouranalysis also\nholdswhennisnotapowerof2.\nAs we did in the analysis of the merge algorithm, we assume that the input\nsequenceSandtheauxiliary sequencesS andS ,createdbyeachrecursivecallof\n1 2\nmerge-sort, areimplementedbyeitherarraysorlinkedlists(thesameasS),sothat\nmergingtwosortedsequences canbedoneinlineartime.\nAs we mentioned earlier, we analyze the merge-sort algorithm by referring to\nthe merge-sort tree T. (Recall Figures 11.2 through 11.4.) We call the time spent\natanodevofT therunning timeoftherecursivecallassociated withv,excluding\nthe time taken waiting for the recursive calls associated with the children of v to\nterminate. Inotherwords,thetimespentatnodevincludestherunningtimesofthe\ndivideandconquer steps, butexcludestherunningtimeoftherecurstep. Wehave\nalready observed that the details of the divide step are straightforward; this step\nrunsintimeproportional tothesizeofthesequenceforv. Inaddition,asdiscussed\nabove, the conquer step, which consists of merging twosorted subsequences, also\ntakeslineartime,independentofwhetherwearedealingwitharraysorlinkedlists.\nThat is, letting i denote the depth of node v, the time spent at node v is O(n/2i),\nsince the size of the sequence handled by the recursive call associated with v is\nequalton/2i.\nLookingatthetreeT moreglobally,asshowninFigure11.7,weseethat,given\nour definition of\u201ctime spent at anode,\u201d the running timeof merge-sort isequal to\nthesumofthetimesspentatthenodesofT. ObservethatT hasexactly2i nodesat\ndepth i. This simple observation has an important consequence, for it implies that\ntheoveralltimespentatallthenodesofT atdepthiisO(2i n/2i),whichisO(n).\n\u00b7\nByProposition 11.1, the height of T is logn . Thus, since the time spent at each\n\u2308 \u2309\nofthe logn +1levelsofT isO(n),wehavethefollowingresult.\n\u2308 \u2309\nProposition 11.2: Algorithmmerge-sortsortsasequenceSofsizeninO(nlogn)\ntime,assumingtwoelementsofScanbecomparedinO(1)time.\nIn other words, the merge-sort algorithm asymptotically matches the fast run-\nningtimeoftheheap-sort algorithm.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 509 \u2014 #531\ni i\n11.1. Merge-Sort 509\nFigure11.7: A visual time analysis of the merge-sort tree T. Each node is shown\nlabeledwiththesizeofitssubproblem.\n11.1.4 C++ Implementations of Merge-Sort\nIn this subsection, we present two complete C++ implementations of the merge-\nsortalgorithm, onefor listsandone forvectors. Inbothcases acomparator object\n(seeSection8.1.2)isusedtodecidetherelativeorderoftheelements. Recallthata\ncomparatorisaclassthatimplementstheless-thanoperatorbyoverloadingthe\u201c()\u201d\noperator. Forexample, givenacomparator object less,therelational testx<ycan\nbeimplementedwithless(x,y),andthetestx ycanbeimplementedas!less(y,x).\n\u2264\nFirst,inCodeFragment11.3,wepresent aC++implementation ofalist-based\nmerge-sort algorithm as the recursive function mergeSort. We represent each se-\nquence as an STL list (Section 6.2.4). The merge process is loosely based on the\nalgorithm presented in Code Fragment 11.2. The main function mergeSort parti-\ntionstheinputlistSintotwoauxiliarylists,S andS ,ofroughlyequalsizes. They\n1 2\nareeachsortedrecursively,andtheresultsarethencombinedbyinvokingthefunc-\ntion merge. The function merge repeatedly moves the smaller element of the two\nlistsS andS intotheoutputlistS.\n1 2\nFunctionsfromourlistADT,suchasfrontandinsertBack,havebeenreplaced\nby their STL equivalents, such as begin and push back, respectively. Access to\nelements of the list is provided by list iterators. Given an iterator p, recall that *p\naccesses the current element, and *p++ accesses the current element and incre-\nmentstheiteratortothenextelementofthelist.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 510 \u2014 #532\ni i\n510 Chapter11. Sorting,Sets,andSelection\nEachlistismodifiedbyinsertionsanddeletionsonlyattheheadandtail;hence,\neachlistupdatetakesO(1)time,assuminganylistimplementationbasedondoubly\nlinked lists (see Table 6.2). For a list S of size n, function mergeSort(S,c) runs in\ntimeO(nlogn).\ntemplate <typename E, typename C> // merge-sort S\nvoid mergeSort(list<E>& S, const C& less)\n{\ntypedef typename list<E>::iterator Itor; // sequence of elements\nint n = S.size();\nif (n <= 1) return; // already sorted\nlist<E> S1, S2;\nItor p = S.begin();\nfor (int i = 0; i < n/2; i++) S1.push back(*p++); // copy first half to S1\nfor (int i = n/2; i < n; i++) S2.push back(*p++); // copy second half to S2\nS.clear(); // clear S\u2019s contents\nmergeSort(S1, less); // recur on first half\nmergeSort(S2, less); // recur on second half\nmerge(S1, S2, S, less); // merge S1 and S2 into S\n}\ntemplate <typename E, typename C> // merge utility\nvoid merge(list<E>& S1, list<E>& S2, list<E>& S, const C& less)\n{\ntypedef typename list<E>::iterator Itor; // sequence of elements\nItor p1 = S1.begin();\nItor p2 = S2.begin();\nwhile(p1 != S1.end() && p2 != S2.end()) // until either is empty\n{\nif(less(*p1, *p2)) // append smaller to S\nS.push back(*p1++);\nelse\nS.push back(*p2++);\n}\nwhile(p1 != S1.end()) // copy rest of S1 to S\nS.push back(*p1++);\nwhile(p2 != S2.end()) // copy rest of S2 to S\nS.push back(*p2++);\n}\nCode Fragment 11.3: Functions mergeSort and merge implementing a list-based\nmerge-sort algorithm.\nNext, in Code Fragment 11.4, we present a nonrecursive vector-based version\nof merge-sort, which also runs in O(nlogn) time. It is a bit faster than recursive\nlist-based merge-sort inpractice, asitavoids theextraoverheads ofrecursive calls\nandnode creation. Themainidea istoperform merge-sort bottom-up, performing\nthemergeslevel-by-level goingupthemerge-sort tree. Theinput isanSTLvector\nS.\nWebeginbymergingeveryodd-evenpairofelementsintosortedrunsoflength\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 511 \u2014 #533\ni i\n11.1. Merge-Sort 511\ntwo. In order to keep from overwriting the vector elements, we copy elements\nfrom an input vector in to an output vector out. For example, we merge in[0] and\nin[1] into the subvector out[0..1], then we merge in[2] and in[3] into the subvector\nout[2..3],andsoon.\nWethenswaptherollsofinandout,andwemergetheserunsoflengthtwointo\nrunsoflength four. Forexample wemerge in[0..1]within[2..3] intothesubvector\nout[0..3], thenwemergein[4..5]within[6..7]intothesubvector out[4..7]. Wethen\nmergeconsecutiverunsoflengthfourintonewrunsoflengtheight,andsoon,until\nthearrayissorted.\nThe variable b stores the start of the runs and m stores their length. The vari-\nablesi, j,andkstorethecurrentindicesinthevarioussubvectors. Whenswapping\nvectors, we do not copy their entire contents. Instead, we maintain pointers to the\ntwoarraysandswapthesepointers attheendofeachroundofsubvectormerges.\n11.1.5 Merge-Sort and Recurrence Equations \u22c6\nThereisanotherwaytojustifythattherunningtimeofthemerge-sortalgorithm is\nO(nlogn)(Proposition11.2). Namely,wecandealmoredirectlywiththerecursive\nnature of the merge-sort algorithm. In this section, wepresent such an analysis of\ntherunningtimeofmerge-sort,andinsodoingintroducethemathematicalconcept\nofarecurrenceequation(alsoknownasrecurrencerelation).\nLet the function t(n) denote the worst-case running time of merge-sort on an\ninput sequence of size n. Since merge-sort is recursive, we can characterize func-\ntiont(n)by meansofanequation wherethe functiont(n)isrecursively expressed\nintermsofitself. Inorder tosimplify ourcharacterization oft(n), letusfocus our\nattention on the case where n is a power of 2. We leave the problem of showing\nthat our asymptotic characterization still holds in the general case as an exercise\n(ExerciseR-11.7). Inthiscase,wecanspecifythedefinitionoft(n)as\nb ifn 1\nt(n) = \u2264\n2t(n/2)+cn otherwise.\n(cid:26)\nAn expression such as the one above is called a recurrence equation, since the\nfunction appears onboththeleft-andright-hand sidesoftheequalsign. Although\nsuch a characterization is correct and accurate, what we really want is a big-Oh\ntype of characterization oft(n) that does not involve the function t(n) itself. That\nis,wewantaclosed-form characterization oft(n).\nWecanobtainaclosed-formsolutionbyapplyingthedefinitionofarecurrence\nequation, assuming n is relatively large. For example, after one more application\noftheequation above,wecanwriteanewrecurrence fort(n)as\nt(n) = 2(2t(n/22)+(cn/2))+cn\n= 22t(n/22)+2(cn/2)+cn = 22t(n/22)+2cn.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 512 \u2014 #534\ni i\n512 Chapter11. Sorting,Sets,andSelection\ntemplate <typename E, typename C> // merge-sort S\nvoid mergeSort(vector<E>& S, const C& less)\n{\ntypedef vector<E> vect;\nint n = S.size();\nvect v1(S); vect* in = &v1; // initial input vector\nvect v2(n); vect* out = &v2; // initial output vector\nfor (int m = 1; m < n; m *= 2) // list sizes doubling\n{\nfor (int b = 0; b < n; b += 2*m) // beginning of list\n{\nmerge(*in, *out, less, b, m); // merge sublists\n}\nstd::swap(in, out); // swap input with output\n}\nS = *in; // copy sorted array to S\n}\n// merge in[b..b+m-1] and in[b+m..b+2*m-1]\ntemplate <typename E, typename C>\nvoid merge(vector<E>& in, vector<E>& out, const C& less, int b, int m)\n{\nint i = b; // index into run #1\nint j = b + m; // index into run #2\nint n = in.size();\nint e1 = std::min(b + m, n); // end of run #1\nint e2 = std::min(b + 2*m, n); // end of run #2\nint k = b;\nwhile ((i < e1) && (j < e2))\n{\nif(!less(in[j], in[i])) // append smaller to S\nout[k++] = in[i++];\nelse\nout[k++] = in[j++];\n}\nwhile (i < e1) // copy rest of run 1 to S\nout[k++] = in[i++];\nwhile (j < e2) // copy rest of run 2 to S\nout[k++] = in[j++];\n}\nCodeFragment11.4:FunctionsmergeSortandmergeimplementingavector-based\nmerge-sort algorithm. We employ the STL functions swap, which swaps two val-\nues,andmin,whichreturnstheminimumoftwovalues. Notethatthecalltoswap\nswapsonlythepointers tothearraysand,hence,runsinO(1)time.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 513 \u2014 #535\ni i\n11.2. Quick-Sort 513\nIf we apply the equation again, we get t(n)=23t(n/23)+3cn. At this point, we\nshouldseeapatternemerging, sothatafterapplying thisequation itimesweget\nt(n) = 2it(n/2i)+icn.\nTheissuethatremains,then,istodeterminewhentostopthisprocess. Toseewhen\ntostop,recallthatweswitchtotheclosedformt(n)=bwhenn 1,whichoccurs\n\u2264\nwhen2i =n. Inother words, thisoccurs when i=logn. Making this substitution,\nthen,yields\nt(n) = 2lognt(n/2logn)+(logn)cn\n= nt(1)+cnlogn\n= nb+cnlogn.\nThatis,wegetanalternativejustification ofthefactthatt(n)isO(nlogn).\n11.2 Quick-Sort\nThe next sorting algorithm we discuss is called quick-sort. Like merge-sort, this\nalgorithm is also based onthe divide-and-conquer paradigm, but ituses this tech-\nnique in a somewhat opposite manner, as all the hard work is done before the\nrecursivecalls.\nHigh-Level Description of Quick-Sort\nThe quick-sort algorithm sorts a sequence S using a simple recursive approach.\nThe main idea is to apply the divide-and-conquer technique, whereby we divide\nS into subsequences, recur to sort each subsequence, and then combine the sorted\nsubsequences by a simple concatenation. In particular, the quick-sort algorithm\nconsists ofthefollowingthreesteps(seeFigure11.8):\n1. Divide: If S has at least two elements (nothing needs to be done if S has\nzero or one element), select a specific element x from S, which is called the\npivot. Asiscommonpractice, choose thepivot xtobethelastelement inS.\nRemovealltheelementsfromSandputthemintothreesequences:\nL,storingtheelementsinSlessthanx\n\u2022\nE,storingtheelementsinSequaltox\n\u2022\nG,storing theelementsinSgreaterthanx.\n\u2022\nOfcourse,iftheelementsofSarealldistinct,thenEholdsjustoneelement\u2014\nthepivotitself.\n2. Recur: Recursivelysortsequences LandG.\n3. Conquer: PutbacktheelementsintoSinorderbyfirstinsertingtheelements\nofL,thenthoseofE,andfinallythoseofG.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 514 \u2014 #536\ni i\n514 Chapter11. Sorting,Sets,andSelection\n1. Split using pivot (cid:13)x(cid:13).(cid:13)\nE(cid:13) (= (cid:13)x(cid:13))(cid:13)\n2. Recur.(cid:13) 2. Recur.(cid:13)\nL(cid:13) (< (cid:13)x(cid:13))(cid:13) G(cid:13) (> (cid:13)x(cid:13))(cid:13)\n3. Concatenate.(cid:13)\nFigure11.8: Avisualschematicofthequick-sort algorithm.\nLikemerge-sort,theexecutionofquick-sortcanbevisualizedbymeansofabi-\nnaryrecursiontree,calledthequick-sorttree. Figure11.9summarizesanexecution\nofthequick-sortalgorithmbyshowingtheinputandoutputsequencesprocessedat\neach node of the quick-sort tree. The step-by-step evolution of the quick-sort tree\nisshowninFigures11.10,11.11,and11.12.\nUnlike merge-sort, however, the height of the quick-sort tree associated with\nan execution of quick-sort is linear in the worst case. This happens, for example,\nifthesequence consists ofndistinct elementsandisalreadysorted. Indeed, inthis\ncase, the standard choice of the pivot as the largest element yields a subsequence\nL of size n 1, while subsequence E has size 1 and subsequence Ghas size 0. At\n\u2212\neach invocation of quick-sort on subsequence L, the size decreases by 1. Hence,\ntheheightofthequick-sort treeisn 1.\n\u2212\nPerforming Quick-Sort on Arrays and Lists\nInCode Fragment 11.5, wegive apseudo-code description ofthe quick-sort algo-\nrithmthatisefficientforsequencesimplementedasarraysorlinkedlists. Thealgo-\nrithmfollowsthetemplateforquick-sortgivenabove,addingthedetailofscanning\nthe input sequence S backwards to divide it into the lists L, E, and G of elements\nthatarerespectivelylessthan,equalto,andgreaterthanthepivot. Weperformthis\nscan backwards, since removing the last element in a sequence is a constant-time\noperation independent of whether the sequence is implemented as an array or a\nlinked list. We then recur on the L and G lists, and copy the sorted lists L, E, and\nGbacktoS. Weperform thislattersetofcopiesintheforwarddirection, sincein-\nserting elements atthe endofasequence isaconstant-time operation independent\nofwhetherthesequence isimplemented asanarrayoralinkedlist.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 515 \u2014 #537\ni i\n11.2. Quick-Sort 515\n(a)\n(b)\nFigure 11.9: Quick-sort tree T for an execution of the quick-sort algorithm on a\nsequence with eight elements: (a) input sequences processed at each node of T;\n(b) output sequences generated at each node of T. The pivot used at each level of\ntherecursion isshowninbold.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 516 \u2014 #538\ni i\n516 Chapter11. Sorting,Sets,andSelection\n(a) (b)\n(c) (d)\n(e) (f)\nFigure 11.10: Visualization of quick-sort. Each node of the tree represents a re-\ncursive call. Thenodes drawn withdashed lines represent calls that have notbeen\nmadeyet. Thenode drawnwiththick lines represents therunning invocation. The\nemptynodesdrawnwiththinlinesrepresentterminatedcalls. Theremainingnodes\nrepresent suspended calls(thatis,activeinvocations thatarewaitingforachildin-\nvocation toreturn). Notethedividestepsperformedin(b),(d),and(f). (Continues\ninFigure11.11.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 517 \u2014 #539\ni i\n11.2. Quick-Sort 517\n(g) (h)\n(i) (j)\n(k) (l)\nFigure 11.11: Visualization of an execution of quick-sort. Note the conquer step\nperformedin(k). (ContinuesinFigure11.12.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 518 \u2014 #540\ni i\n518 Chapter11. Sorting,Sets,andSelection\n(m) (n)\n(o) (p)\n(q) (r)\nFigure11.12: Visualization of an execution of quick-sort. Several invocations be-\ntween (p) and (q) have been omitted. Note the conquer steps performed in (o)\nand(r). (Continued fromFigure11.11.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 519 \u2014 #541\ni i\n11.2. Quick-Sort 519\nAlgorithmQuickSort(S):\nInput: Asequence Simplemented asanarrayorlinkedlist\nOutput: Thesequence Sinsortedorder\nifS.size() 1then\n\u2264\nreturn Sisalreadysortedinthiscase\n{ }\np S.back().element() thepivot\n\u2190 { }\nLetL,E,andGbeemptylist-based sequences\nwhile!S.empty()do scanSbackwards, dividing itintoL,E,andG\n{ }\nifS.back().element()< pthen\nL.insertBack(S.eraseBack())\nelseifS.back().element()= pthen\nE.insertBack(S.eraseBack())\nelse thelastelementinSisgreaterthan p\n{ }\nG.insertBack(S.eraseBack())\nQuickSort(L) Recurontheelementslessthan p\n{ }\nQuickSort(G) Recurontheelementsgreaterthan p\n{ }\nwhile!L.empty()do copybacktoSthesortedelementslessthan p\n{ }\nS.insertBack(L.eraseFront())\nwhile!E.empty()do copybacktoStheelementsequalto p\n{ }\nS.insertBack(E.eraseFront())\nwhile!G.empty()do copybacktoSthesortedelementsgreaterthan p\n{ }\nS.insertBack(G.eraseFront())\nreturn Sisnowinsortedorder\n{ }\nCodeFragment11.5: Quick-sortforaninputsequenceSimplementedwithalinked\nlistoranarray.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 520 \u2014 #542\ni i\n520 Chapter11. Sorting,Sets,andSelection\nRunning Time of Quick-Sort\nWe can analyze the running time of quick-sort with the same technique used for\nmerge-sort inSection 11.1.3. Namely, wecanidentify thetimespent ateachnode\nofthequick-sort treeT andsumuptherunning timesforallthenodes.\nExamining Code Fragment 11.5, we see that the divide step and the conquer\nstepofquick-sortcanbeimplementedinlineartime. Thus,thetimespentatanode\nvofT isproportional totheinputsizes(v)ofv,definedasthesizeofthesequence\nhandledbytheinvocation ofquick-sort associated withnodev. Sincesubsequence\nE hasatleast one element (the pivot), the sum oftheinput sizes of thechildren of\nvisatmosts(v) 1.\n\u2212\nGiven a quick-sort tree T, let s denote the sum of the input sizes of the nodes\ni\nat depth i in T. Clearly, s =n, since the root r of T is associated with the entire\n0\nsequence. Also, s n 1, since the pivot is not propagated to the children of r.\n1\n\u2264 \u2212\nConsider next s . If both children of r have nonzero input size, then s =n 3.\n2 2\n\u2212\nOtherwise(onechildoftheroothaszerosize,theotherhassizen 1),s =n 2.\n2\n\u2212 \u2212\nThus, s n 2. Continuing this line of reasoning, we obtain that s n i.\n2 i\n\u2264 \u2212 \u2264 \u2212\nAs observed in Section 11.2, the height of T is n 1 in the worst case. Thus, the\nworst-caserunningtimeofquick-sortisO \u2211n\u22121s \u2212 ,whichisO \u2211n\u22121(n i) ,that\ni=0 i i=0 \u2212\nis, O(\u2211n i) . ByProposition 4.3, \u2211n i isO(n2). Thus, quick-sort runs in O(n2)\ni=1 i=1 (cid:0) (cid:1) (cid:0) (cid:1)\nworst-case time.\nGiven its name, we would expect quick-sort to run quickly. However, the\nquadratic boundaboveindicatesthatquick-sort isslowintheworstcase. Paradox-\nically, this worst-case behavior occurs for problem instances when sorting should\nbeeasy\u2014ifthesequence isalready sorted.\nGoingbacktoouranalysis, notethatthebestcaseforquick-sort onasequence\nofdistinctelementsoccurswhensubsequencesLandGhappentohaveroughlythe\nsamesize. Thatis,inthebestcase,wehave\ns = n\n0\ns = n 1\n1\n\u2212\ns = n (1+2)=n 3\n2\n. \u2212 \u2212\n.\n.\ns = n (1+2+22+ +2i\u22121)=n (2i 1).\ni\n\u2212 \u00b7\u00b7\u00b7 \u2212 \u2212\nThus,inthebestcase,T hasheightO(logn)andquick-sortrunsinO(nlogn)time.\nWeleavethejustification ofthisfactasanexercise(ExerciseR-11.12).\nTheinformalintuitionbehindtheexpectedbehaviorofquick-sortisthatateach\ninvocation the pivot will probably divide the input sequence about equally. Thus,\nweexpecttheaveragerunningtimequick-sorttobesimilartothebest-caserunning\ntime,thatis,O(nlogn). Inthenextsection, weseethatintroducing randomization\nmakesquick-sort behaveexactlyinthisway.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 521 \u2014 #543\ni i\n11.2. Quick-Sort 521\n11.2.1 Randomized Quick-Sort\nOne common method for analyzing quick-sort is to assume that the pivot always\ndividesthesequencealmostequally. Wefeelsuchanassumptionwouldpresuppose\nknowledge abouttheinputdistribution thatistypically notavailable, however. For\nexample, we would have to assume that we will rarely be given \u201calmost\u201d sorted\nsequences to sort, which are actually common in many applications. Fortunately,\nthis assumption is not needed in order for usto match our intuition to quick-sort\u2019s\nbehavior.\nIn general, we desire some way of getting close to the best-case running time\nforquick-sort. Thewaytogetclosetothebest-case running time,ofcourse, isfor\nthe pivot to divide the input sequence S almost equally. If this outcome were to\noccur, then it would result in arunning time that isasymptotically the sameas the\nbest-case running time. That is, having pivots close to the \u201cmiddle\u201d of the set of\nelementsleadstoanO(nlogn)runningtimeforquick-sort.\nPicking Pivots at Random\nSince the goal of the partition step of the quick-sort method is to divide the se-\nquence S almost equally, let us introduce randomization into the algorithm and\npickarandomelementoftheinputsequence asthepivot. Thatis,instead ofpick-\ning the pivot as the last element of S, we pick an element of S at random as the\npivot, keeping the rest of the algorithm unchanged. This variation of quick-sort is\ncalled randomized quick-sort. The following proposition shows that the expected\nrunningtimeofrandomizedquick-sortonasequencewithnelementsisO(nlogn).\nThisexpectationistakenoverallthepossiblerandomchoicesthealgorithmmakes,\nand is independent of any assumptions about the distribution of the possible input\nsequences thealgorithm islikelytobegiven.\nProposition 11.3: Theexpectedrunningtimeofrandomizedquick-sortonase-\nquenceSofsizenisO(nlogn).\nJustification: We assume two elements of S can be compared in O(1) time.\nConsiderasinglerecursivecallofrandomized quick-sort, andletndenotethesize\noftheinputforthiscall. Saythatthiscallis\u201cgood\u201difthepivotchosenissuchthat\nsubsequences L and G have size at least n/4 and at most 3n/4 each; otherwise, a\ncallis\u201cbad.\u201d\nNow, consider the implications of our choosing a pivot uniformly at random.\nNote that there are n/2 possible good choices for the pivot for any given call of\nsizenoftherandomizedquick-sortalgorithm. Thus,theprobabilitythatanycallis\ngood is1/2. Notefurther that agood callwillatleast partition alist ofsize ninto\ntwolistsofsize3n/4andn/4,andabadcallcouldbeasbadasproducingasingle\ncallofsizen 1.\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 522 \u2014 #544\ni i\n522 Chapter11. Sorting,Sets,andSelection\nNowconsider arecursion traceforrandomized quick-sort. Thistracedefinesa\nbinarytree,T,suchthateachnodeinT corresponds toadifferentrecursivecallon\nasubproblem ofsortingaportionoftheoriginallist.\nSaythat anodevinT isinsize groupiifthesize ofv\u2019ssubproblem isgreater\nthan(3/4)i+1nandatmost(3/4)in. Letusanalyzetheexpectedtimespentworking\non all the subproblems for nodes in size group i. By the linearity of expectation\n(Proposition A.19), the expected time for working on all these subproblems is the\nsum of the expected times for each one. Some of these nodes correspond to good\ncallsandsomecorrespond tobadcalls. Butnotethat,sinceagoodcalloccurswith\nprobability 1/2, theexpected number ofconsecutive calls wehave tomakebefore\ngetting a good call is 2. Moreover, notice that as soon as we have a good call for\na node in size group i, its children will be in size groups higher than i. Thus, for\nany element x from the input list, the expected number of nodes in size group i\ncontaining xintheirsubproblemsis2. Inotherwords,theexpectedtotalsizeofall\nthesubproblems insizegroupiis2n. Sincethenonrecursive workweperform for\nanysubproblem isproportional toits size, this implies that thetotal expected time\nspentprocessing subproblems fornodesinsizegroupiisO(n).\nThe number of size groups is log n, since repeatedly multiplying by 3/4 is\n4/3\nthe same as repeatedly dividing by 4/3. That is, the number of size groups is\nO(logn). Therefore, the total expected running time of randomized quick-sort is\nO(nlogn). (SeeFigure11.13.)\nFigure11.13: A visual time analysis of the quick-sort tree T. Each node is shown\nlabeledwiththesizeofitssubproblem.\nActually,wecanshowthattherunningtimeofrandomizedquick-sortisO(nlogn)\nwithhighprobability.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 523 \u2014 #545\ni i\n11.2. Quick-Sort 523\n11.2.2 C++ Implementations and Optimizations\nRecallfromSection8.3.5thatasortingalgorithmisin-placeifitusesonlyasmall\namount of memory in addition to that needed for the objects being sorted them-\nselves. The merge-sort algorithm, as described above, does not use this optimiza-\ntiontechnique, andmaking itbein-place seemstobequitedifficult. In-place sort-\ning is not inherently difficult, however. For, as with heap-sort, quick-sort can be\nadapted to be in-place, and this is the version of quick-sort that is used in most\ndeployed implementations.\nPerforming the quick-sort algorithm in-place requires a bit of ingenuity, how-\never, for we must use the input sequence itself to store the subsequences for all\ntherecursivecalls. WeshowalgorithminPlaceQuickSort,whichperformsin-place\nquick-sort, in Code Fragment 11.6. Algorithm inPlaceQuickSort assumes that the\ninput sequence, S, is given as an array of distinct elements. The reason for this\nrestriction is explored in Exercise R-11.15. The extension to the general case is\ndiscussed inExerciseC-11.9.\nAlgorithminPlaceQuickSort(S,a,b):\nInput: AnarraySofdistinctelements;integersaandb\nOutput: Array S with elements originally from indices from a to b, inclusive,\nsortedinnondecreasing orderfromindices atob\nifa bthenreturn atmostoneelementinsubrange\n\u2265 { }\np S[b] thepivot\n\u2190 { }\nl a willscanrightward\n\u2190 { }\nr b 1 willscanleftward\n\u2190 \u2212 { }\nwhilel r do\n\u2264\nfindanelementlargerthanthepivot\n{ }\nwhilel randS[l] pdo\n\u2264 \u2264\nl l+1\n\u2190\nfindanelementsmallerthanthepivot\n{ }\nwhiler l andS[r] pdo\n\u2265 \u2265\nr r 1\n\u2190 \u2212\nifl<rthen\nswaptheelementsatS[l]andS[r]\nputthepivotintoitsfinalplace\n{ }\nswaptheelementsatS[l]andS[b]\nrecursivecalls\n{ }\ninPlaceQuickSort(S,a,l 1)\n\u2212\ninPlaceQuickSort(S,l+1,b)\nwearedoneatthispoint, sincethesortedsubarrays arealreadyconsecutive\n{ }\nCodeFragment11.6: In-place quick-sort foraninputarrayS.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 524 \u2014 #546\ni i\n524 Chapter11. Sorting,Sets,andSelection\nIn-place quick-sort modifies the input sequence using element swapping and\ndoes not explicitly create subsequences. Indeed, a subsequence of the input se-\nquence is implicitly represented by a range of positions specified by a left-most\nindex l and a right-most index r. The divide step is performed by scanning the\narray simultaneously from l forward and from r backward, swapping pairs of ele-\nments that are in reverse order as shown in Figure 11.14. When these two indices\n\u201cmeet,\u201d subvectors L and G are on opposite sides of the meeting point. The algo-\nrithmcompletesbyrecurring onthesetwosubvectors.\nIn-place quick-sort reduces the running time caused by the creation of new\nsequences and the movement of elements between them by a constant factor. It is\nsoefficientthattheSTL\u2019ssorting algorithm isbasedinpartonquick-sort.\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\n(g)\nFigure11.14: Divide step of in-place quick-sort. Index l scans the sequence from\nlefttoright,andindexrscansthesequencefromrighttoleft. Aswapisperformed\nwhenl isatanelementlargerthanthepivotandr isatanelementsmallerthanthe\npivot. Afinalswapwiththepivotcompletesthedividestep.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 525 \u2014 #547\ni i\n11.2. Quick-Sort 525\nWe show a C++ version of in-place quick-sort in Code Fragment 11.7. The\ninputtothesortingprocedureisanSTLvectorofelementsandacomparatorobject,\nwhich provides the less-than function. Our implementation is a straightforward\nadaptation of Code Fragment 11.6. The main procedure, quickSort, invokes the\nrecursiveprocedure quickSortSteptodomostofthework.\ntemplate <typename E, typename C> // quick-sort S\nvoid quickSort(std::vector<E>& S, const C& less)\n{\nif (S.size() <= 1) return; // already sorted\nquickSortStep(S, 0, S.size() 1, less); // call sort utility\n\u2212\n}\ntemplate <typename E, typename C>\nvoid quickSortStep(std::vector<E>& S, int a, int b, const C& less)\n{\nif (a >= b) return; // 0 or 1 left? done\nE pivot = S[b]; // select last as pivot\nint l = a; // left edge\nint r = b 1; // right edge\n\u2212\nwhile (l <= r)\n{\nwhile (l <= r && !less(pivot, S[l])) l++; // scan right till larger\nwhile (r >= l && !less(S[r], pivot)) r ; // scan left till smaller\n\u2212\u2212\nif (l < r) // both elements found\nstd::swap(S[l], S[r]);\n// until indices cross\n}\nstd::swap(S[l], S[b]); // store pivot at l\nquickSortStep(S, a, l 1, less); // recur on both sides\n\u2212\nquickSortStep(S, l+1, b, less);\n}\nCodeFragment11.7: Acodingofin-place quick-sort, assumingdistinctelements.\nThefunctionquickSortStepisgivenindicesaandb,whichindicatethebounds\nof the subvector to be sorted. The pivot element is chosen to be the last element\nof the vector. The indices l and r mark the left and right ends of the subvectors\nbeing processed in the partitioning function. They are initialized to a and b 1,\n\u2212\nrespectively. During each round, elements that are on the wrong side of the pivot\nareswappedwitheachother, untilthesemarkersbumpintoeachother.\nMuch of the efficiency of quick-sort depends on how the pivot is chosen. As\nwe have seen, quick-sort is most efficient if the pivot is near the middle of the\nsubvector being sorted. Our choice of setting the pivot to the last element of the\nsubvector relies on the assumption that the last element is reflective ofthe median\nkey valye. A better choice, if the subvector is moderately sized, is to select the\npivot as the median of three values, taken respectively from the front, middle, and\ntail of the array. This is referred to as the median-of-three heuristic. It tends to\nperformwellinpractice,andisfasterthanselectingarandompivotthroughtheuse\nofarandom-number generator.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 526 \u2014 #548\ni i\n526 Chapter11. Sorting,Sets,andSelection\n11.3 Studying Sorting through an Algorithmic Lens\nRecappingourdiscussionsonsortingtothispoint,wehavedescribedseveralmeth-\nodswitheitheraworst-case orexpected running timeofO(nlogn)onaninputse-\nquence of size n. These methods include merge-sort and quick-sort, described in\nthis chapter, as well as heap-sort (Section 8.3.5). In this section, we study sorting\nasanalgorithmic problem,addressing generalissuesaboutsortingalgorithms.\n11.3.1 A Lower Bound for Sorting\nA natural first question to ask is whether we can sort any faster than O(nlogn)\ntime. Interestingly,ifthecomputationalprimitiveusedbyasortingalgorithmisthe\ncomparison oftwoelements,thenthisis,infact,thebestwecando\u2014comparison-\nbasedsortinghasan\u2126(nlogn)worst-caselowerboundonitsrunningtime. (Recall\nthe notation \u2126() from Section 4.2.3.) To focus on the main cost of comparison-\n\u00b7\nbasedsorting, letusonlycountcomparisons, forthesakeofalowerbound.\nSupposewearegivenasequenceS=(x ,x ,...,x )thatwewishtosort,and\n0 1 n\u22121\nassume that all the elements of S are distinct (this is not really a restriction since\nwearederivingalowerbound). WedonotcareifSisimplementedasanarrayora\nlinkedlist,forthesakeofourlowerbound,sinceweareonlycountingcomparisons.\nEach time a sorting algorithm compares two elements x and x , that is, it asks,\ni j\n\u201cis x <x ?\u201d, there are two outcomes: \u201cyes\u201d or \u201cno.\u201d Based on the result of this\ni j\ncomparison, the sorting algorithm may perform some internal calculations (which\nwearenotcountinghere)andeventuallyperformsanothercomparisonbetweentwo\nother elements of S, which again has two outcomes. Therefore, we can represent\nacomparison-based sorting algorithm withadecision treeT (recall Example7.8).\nThatis, eachinternal node vinT corresponds toacomparison andtheedgesfrom\nnodev\u2032 toitschildrencorrespondtothecomputations resultingfromeithera\u201cyes\u201d\nor \u201cno\u201d answer. It is important to note that the hypothetical sorting algorithm in\nquestion probably has no explicit knowledge of the tree T. T simply represents\nall the possible sequences of comparisons that a sorting algorithm might make,\nstarting from the first comparison (associated with the root) and ending with the\nlastcomparison (associated withtheparentofanexternalnode).\nEachpossible initial ordering, or permutation, oftheelements inScauses our\nhypotheticalsortingalgorithmtoexecuteaseriesofcomparisons, traversingapath\nin T from the root to some external node. Let us associate with each external\nnode v in T, then, the set of permutations of S that cause our sorting algorithm to\nend up in v. The most important observation in our lower-bound argument is that\neach external node v in T can represent the sequence of comparisons for at most\none permutation of S. The justification for this claim is simple: if two different\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 527 \u2014 #549\ni i\n11.3. StudyingSortingthroughanAlgorithmicLens 527\npermutations P andP ofSareassociated withthesameexternal node, thenthere\n1 2\nare at least two objects x and x , such that x is before x in P but x is after x\ni j i j 1 i j\ninP . Atthesametime, theoutput associated withvmustbeaspecific reordering\n2\nofS,witheitherx orx appearingbeforetheother. ButifP andP bothcausethe\ni j 1 2\nsortingalgorithmtooutputtheelementsofSinthisorder,thenthatimpliesthereis\nawaytotrickthealgorithm intooutputting x andx inthewrongorder. Sincethis\ni j\ncannot beallowedbyacorrect sorting algorithm, each external node ofT mustbe\nassociated withexactly onepermutation ofS. Weusethisproperty ofthedecision\ntreeassociated withasortingalgorithm toprovethefollowingresult.\nProposition 11.4: Therunningtimeofanycomparison-basedalgorithmforsort-\ningann-elementsequenceis\u2126(nlogn)intheworstcase.\nJustification: The running time of a comparison-based sorting algorithm must\nbe greater than or equal to the height of the decision tree T associated with this\nalgorithm, as described above. (See Figure 11.15.) By the argument above, each\nexternal node in T must be associated with one permutation of S. Moreover, each\npermutation of S must result in a different external node of T. The number of\npermutationsofnobjectsisn!=n(n 1)(n 2) 2 1. Thus,T musthaveatleast\n\u2212 \u2212 \u00b7\u00b7\u00b7 \u00b7\nn! external nodes. By Proposition 7.10, the height of T is at least log(n!). This\nimmediately justifies the proposition, because there are at least n/2 terms that are\ngreaterthanorequalton/2intheproduct n!;hence\nn n n n\nlog(n!) log 2 = log ,\n\u2265 2 2 2\n(cid:16) (cid:17)\nwhichis\u2126(nlogn).\nFigure11.15: Visualizingthelowerboundforcomparison-based sorting.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 528 \u2014 #550\ni i\n528 Chapter11. Sorting,Sets,andSelection\n11.3.2 Linear-Time Sorting: Bucket-Sort and Radix-Sort\nIn the previous section, we showed that \u2126(nlogn) time is necessary, in the worst\ncase, tosort ann-element sequence withacomparison-based sorting algorithm. A\nnaturalquestion toask,then,iswhetherthereareotherkindsofsortingalgorithms\nthat can be designed to run asymptotically faster than O(nlogn) time. Interest-\ningly, such algorithms exist, but they require special assumptions about the input\nsequencetobesorted. Evenso,suchscenariosoftenariseinpractice,sodiscussing\nthemisworthwhile. Inthissection, weconsider theproblem ofsorting asequence\nofentries, eachakey-valuepair,wherethekeyshavearestricted type.\nBucket-Sort\nConsider asequence S of nentries whose keys are integers inthe range [0,N 1],\n\u2212\nforsome integer N 2, and suppose that S should be sorted according tothe keys\n\u2265\nof the entries. Inthis case, it ispossible to sort S in O(n+N)time. Itmight seem\nsurprising, but this implies, for example, that if N is O(n), then we can sort S in\nO(n)time. Ofcourse,thecrucialpointisthat,becauseoftherestrictiveassumption\nabouttheformatoftheelements, wecanavoidusingcomparisons.\nThemainidea istouse analgorithm called bucket-sort, whichisnot based on\ncomparisons, but on using keys as indices into a bucket array B that has cells in-\ndexed from 0 to N 1. An entry with key k is placed in the \u201cbucket\u201d B[k], which\n\u2212\nitself is a sequence (of entries with key k). After inserting each entry of the input\nsequenceSintoitsbucket,wecanputtheentriesbackintoSinsortedorderbyenu-\nmerating the contents of the buckets B[0],B[1],...,B[N 1] in order. We describe\n\u2212\nthebucket-sort algorithm inCodeFragment11.8.\nAlgorithmbucketSort(S):\nInput: SequenceSofentries withintegerkeysintherange[0,N 1]\n\u2212\nOutput: SequenceSsortedinnondecreasing orderofthekeys\nletBbeanarrayofN sequences, eachofwhichisinitially empty\nforeachentryeinSdo\nk e.key()\n\u2190\nremoveefromSandinsertitattheendbucket(sequence) B[k]\nfori 0toN 1do\n\u2190 \u2212\nforeachentryeinsequence B[i]do\nremoveefromB[i]andinsertitattheendofS\nCodeFragment11.8: Bucket-sort.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 529 \u2014 #551\ni i\n11.3. StudyingSortingthroughanAlgorithmicLens 529\nIt is easy to see that bucket-sort runs in O(n+N) time and uses O(n+N)\nspace. Hence, bucket-sort is efficient when the range N of values for the keys is\nsmall compared to the sequence size n, say N =O(n) or N =O(nlogn). Still, its\nperformance deteriorates asN growscomparedton.\nAn important property of the bucket-sort algorithm is that it works correctly\nevenifthere aremanydifferent elements withthesamekey. Indeed, wedescribed\nitinawaythatanticipates suchoccurrences.\nStable Sorting\nWhensortingkey-valuepairs,animportantissueishowequalkeysarehandled. Let\nS=((k ,x ),...,(k ,x ))beasequence ofsuchentries. Wesaythatasorting\n0 0 n\u22121 n\u22121\nalgorithm isstable if, foranytwoentries (k,x)and(k ,x )ofS,such thatk =k\ni i j j i j\nand (k,x) precedes (k ,x ) in S before sorting (that is, i< j), entry (k,x) also\ni i j j i i\nprecedes entry (k ,x ) after sorting. Stability is important for a sorting algorithm\nj j\nbecauseapplications maywanttopreservetheinitialorderingofelementswiththe\nsamekey.\nOur informal description ofbucket-sort in CodeFragment 11.8 does not guar-\nanteestability. Thisisnotinherentinthebucket-sortmethoditself,however,forwe\ncaneasilymodifyourdescription tomakebucket-sort stable,whilestillpreserving\nits O(n+N) running time. Indeed, we can obtain a stable bucket-sort algorithm\nbyalwaysremovingthefirstelementfromsequenceSandfromthesequences B[i]\nduringtheexecutionofthealgorithm.\nRadix-Sort\nOneofthereasonsthatstablesortingissoimportantisthatitallowsthebucket-sort\napproach tobeapplied tomoregeneral contexts thantosortintegers. Suppose, for\nexample, that we want to sort entries with keys that are pairs (k,l), where k and\nl are integers in the range [0,N 1], for some integer N 2. In a context such\n\u2212 \u2265\nas this, it is natural to define an ordering on these keys using the lexicographical\n(dictionary) convention, where (k ,l )<(k ,l ) if k <k or if k =k and l <\n1 1 2 2 1 2 1 2 1\nl (Section 8.1.2). This is a pair-wise version of the lexicographic comparison\n2\nfunction,usuallyappliedtoequal-lengthcharacterstrings(anditeasilygeneralizes\ntotuplesofd numbersford >2).\nTheradix-sort algorithm sorts asequence S ofentries withkeysthatare pairs,\nby applying astable bucket-sort on the sequence twice; first using one component\nof the pair as the ordering key and then using the second component. But which\norder is correct? Should we first sort on the k\u2019s (the first component) and then on\nthel\u2019s(thesecondcomponent), orshoulditbetheotherwayaround?\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 530 \u2014 #552\ni i\n530 Chapter11. Sorting,Sets,andSelection\nBeforeweanswerthisquestion, weconsider thefollowingexample.\nExample 11.5: ConsiderthefollowingsequenceS(weshowonlythekeys):\nS=((3,3),(1,5),(2,5),(1,2),(2,3),(1,7),(3,2),(2,2)).\nIfwesortSstablyonthefirstcomponent,thenwegetthesequence\nS =((1,5),(1,2),(1,7),(2,5),(2,3),(2,2),(3,3),(3,2)).\n1\nIfwethenstablysortthissequenceS usingthesecondcomponent,thenwegetthe\n1\nsequence\nS =((1,2),(2,2),(3,2),(2,3),(3,3),(1,5),(2,5),(1,7)),\n1,2\nwhichisnotexactlyasortedsequence.Ontheotherhand,ifwefirststablysortS\nusingthesecondcomponent,thenwegetthesequence\nS =((1,2),(3,2),(2,2),(3,3),(2,3),(1,5),(2,5),(1,7)).\n2\nIfwethenstablysortsequenceS usingthefirstcomponent,thenwegetthese-\n2\nquence\nS =((1,2),(1,5),(1,7),(2,2),(2,3),(2,5),(3,2),(3,3)),\n2,1\nwhichisindeedsequenceSlexicographicallyordered.\nSo, from this example, we are led to believe that we should first sort using\nthe second component and then again using the first component. This intuition is\nexactly right. By first stably sorting by the second component and then again by\nthe first component, we guarantee that if two entries are equal in the second sort\n(by the first component), then their relative order in the starting sequence (which\nis sorted by the second component) is preserved. Thus, the resulting sequence is\nguaranteed to be sorted lexicographically every time. We leave the determination\nofhowthisapproach canbeextended totriplesandotherd-tuplesofnumbers asa\nsimpleexercise(ExerciseR-11.20). Wecansummarizethissectionasfollows:\nProposition 11.6: LetSbeasequenceofnkey-valuepairs,eachofwhichhasa\nkey(k ,k ,...,k ),wherek isanintegerintherange[0,N 1]forsomeinteger\n1 2 d i\n\u2212\nN 2.WecansortSlexicographicallyintimeO(d(n+N))usingradix-sort.\n\u2265\nAs important as it is, sorting is not the only interesting problem dealing with\na total order relation on a set of elements. There are some applications, for ex-\nample, that do not require an ordered listing of an entire set, but nevertheless call\nfor some amount of ordering information about the set. Before we study such a\nproblem(called\u201cselection\u201d), letusstepbackandbrieflycompareallofthesorting\nalgorithms wehavestudiedsofar.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 531 \u2014 #553\ni i\n11.3. StudyingSortingthroughanAlgorithmicLens 531\n11.3.3 Comparing Sorting Algorithms\nAt this point, it might be useful for us to take a breath and consider all the algo-\nrithmswehavestudiedinthisbooktosortann-elementvector,nodelist,orgeneral\nsequence.\nConsidering Running Time and Other Factors\nWe have studied several methods, such as insertion-sort and selection-sort, that\nhaveO(n2)-timebehaviorintheaverageandworstcase. Wehavealsostudiedsev-\neral methods with O(nlogn)-time behavior, including heap-sort, merge-sort, and\nquick-sort. Finally, we have studied a special class of sorting algorithms, namely,\nthe bucket-sort and radix-sort methods, that run in linear time for certain types of\nkeys. Certainly, the selection-sort algorithm is a poor choice in any application,\nsince it runs in O(n2) time even in the best case. But, of the remaining sorting\nalgorithms, whichisthebest?\nAswithmanythingsinlife, thereisnoclear\u201cbest\u201d sorting algorithm fromthe\nremainingcandidates. Thesortingalgorithmbestsuitedforaparticularapplication\ndepends on several properties of that application. We can offer some guidance\nand observations, therefore, based on the known properties of the \u201cgood\u201d sorting\nalgorithms.\nInsertion-Sort\nIf implemented well, the running time of insertion-sort is O(n+m), where m is\nthe number of inversions (that is, the number of pairs of elements out of order).\nThus,insertion-sort isanexcellent algorithm forsorting smallsequences (say, less\nthan50elements),becauseinsertion-sortissimpletoprogram,andsmallsequences\nnecessarily have few inversions. Also, insertion-sort is quite effective for sorting\nsequences thatarealready\u201calmost\u201dsorted. By\u201calmost,\u201dwemeanthatthenumber\nofinversions issmall. ButtheO(n2)-timeperformance ofinsertion-sort makesita\npoorchoiceoutside ofthesespecialcontexts.\nMerge-Sort\nMerge-sort, on the other hand, runs in O(nlogn) time in the worst case, which is\noptimal for comparison-based sorting methods. Still, experimental studies have\nshown that, since it is difficult to make merge-sort run in-place, the overheads\nneededtoimplementmerge-sortmakeitlessattractivethanthein-placeimplemen-\ntationsofheap-sortandquick-sortforsequencesthatcanfitentirelyinacomputer\u2019s\nmain memory area. Even so, merge-sort is an excellent algorithm for situations\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 532 \u2014 #554\ni i\n532 Chapter11. Sorting,Sets,andSelection\nwheretheinputcannotallfitintomainmemory,butmustbestoredinblocksonan\nexternal memorydevice, suchasadisk. Inthesecontexts, thewaythatmerge-sort\nprocesses runs of data in long merge streams makes the best use of all the data\nbrought into main memory in a block from disk. Thus, for external memory sort-\ning,themerge-sort algorithm tendstominimizethetotalnumberofdiskreadsand\nwritesneeded, whichmakesthemerge-sort algorithm superiorinsuchcontexts.\nQuick-Sort\nExperimental studies have shown that ifan input sequence can fitentirely inmain\nmemory, then the in-place versions of quick-sort and heap-sort run faster than\nmerge-sort. The extra overhead needed for copying nodes or entries puts merge-\nsort at a disadvantage to quick-sort and heap-sort in these applications. In fact,\nquick-sort tends, on average, to beat heap-sort in these tests. So, quick-sort is an\nexcellent choice as a general-purpose, in-memory sorting algorithm. Indeed, it is\nincludedintheqsortsortingutilityprovidedinClanguagelibraries. Still,itsO(n2)\ntime worst-case performance makes quick-sort a poor choice in real-time applica-\ntions where we must make guarantees on the time needed to complete a sorting\noperation.\nHeap-Sort\nIn real-time scenarios where we have a fixed amount of time to perform a sorting\noperation and the input data can fit into main memory, the heap-sort algorithm is\nprobably the best choice. It runs in O(nlogn) worst-case time and can easily be\nmadetoexecutein-place.\nBucket-Sort and Radix-Sort\nFinally, if our application involves sorting entries with small integer keys or d-\ntuples of small integer keys, then bucket-sort or radix-sort is an excellent choice,\nbecause it runs in O(d(n+N)) time, where [0,N 1] is the range of integer keys\n\u2212\n(and d =1 for bucket sort). Thus, if d(n+N) is significantly \u201cbelow\u201d the nlogn\nfunction, then this sorting method should run faster than even quick-sort or heap-\nsort.\nThus, our study of all these different sorting algorithms provides us with a\nversatilecollection ofsortingmethodsinouralgorithm engineering \u201ctoolbox.\u201d\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 533 \u2014 #555\ni i\n11.4. SetsandUnion/FindStructures 533\n11.4 Sets and Union/Find Structures\nInthissection, westudysets, including operations thatdefinethemandoperations\nthatcanbeappliedtoentiresets.\n11.4.1 The Set ADT\nAsetisacollectionofdistinctobjects. Thatis,therearenoduplicateelementsina\nset,andthereisnoexplicitnotionofkeysorevenanorder. Evenso,iftheelements\ninasetarecomparable, thenwecanmaintainsetstobeordered. Thefundamental\nfunctions ofthesetADTforasetSarethefollowing:\ninsert(e): InserttheelementeintoSandreturnaniteratorreferring\ntoitslocation;iftheelementalreadyexiststheoperation\nisignored.\nfind(e): IfScontainse,returnaniterator preferringtothisentry,\nelsereturnend.\nerase(e): RemovetheelementefromS.\nbegin(): Returnaniteratortothebeginning ofS.\nend(): Return an iterator to an imaginary position just beyond\ntheendofS.\nThe C++ Standard Template Library provides a class set that contains all of\nthese functions. It actually implements an ordered set, and supports the following\nadditional operations aswell.\nlower bound(e): Returnaniteratortothelargestelementlessthanorequal\ntoe.\nupper bound(e): Returnaniteratortothesmallestelementgreater thanor\nequaltoe.\nequal range(e): Returnaniteratorrangeofelementsthatareequaltoe.\nTheSTLsetistemplatedwiththeelementtype. AswiththeotherSTLclasses\nwehaveseensofar,thesetisanexampleofacontainer, andhencesupportsaccess\nbyiterators. Inordertodeclareanobjectoftypeset,itisnecessary tofirstinclude\nthedefinition filecalled \u201cset.\u201d Thesetispartofthestdnamespace, andhence itis\nnecessary eithertouse\u201cstd::set\u201dortoprovideanappropriate \u201cusing\u201dstatement.\nTheSTLsetisimplementedbyadaptingtheSTLorderedmap(whichisbased\nonared-black tree). Eachentryhastheproperty thatthekeyandelementareboth\nequaltoe. Thatis,eachentryisoftheform(e,e).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 534 \u2014 #556\ni i\n534 Chapter11. Sorting,Sets,andSelection\n11.4.2 Mergable Sets and the Template Method Pattern\nLetusexploreafurtherextensionoftheorderedsetADTthatallowsforoperations\nbetween pairs of sets. This also serves to motivate a software engineering design\npatternknownasthetemplatemethod.\nFirst, we recall the mathematical definitions of the union, intersection, and\nsubtraction oftwosetsAandB:\nA B = x: xisinAorxisinB ,\n\u222a { }\nA B = x: xisinAandxisinB ,\n\u2229 { }\nA B = x: xisinAandxisnotinB .\n\u2212 { }\nExample 11.7: MostInternetsearchenginesstore,foreachwordx intheirdic-\ntionarydatabase,aset,W(x),ofWebpagesthatcontainx,whereeachWebpage\nisidentifiedbyauniqueInternetaddress.Whenpresentedwithaqueryforaword\nx,suchasearchengineneedonlyreturntheWebpagesinthesetW(x),sorted\naccordingtosomeproprietarypriorityrankingofpage\u201cimportance.\u201d Butwhen\npresentedwithatwo-wordqueryforwordsxandy,suchasearchenginemustfirst\ncomputetheintersectionW(x) W(y),andthenreturntheWebpagesintheresult-\n\u2229\ningsetsortedbypriority.Severalsearchenginesusethesetintersectionalgorithm\ndescribedinthissectionforthiscomputation.\nFundamental Methods of the Mergable Set ADT\nThe fundamental functions of the mergable set ADT, acting on a set A, are as fol-\nlows:\nunion(B): Replace A with the union of A and B, that is, execute\nA A B.\n\u2190 \u222a\nintersect(B): Replace A with the intersection of A and B, that is, exe-\ncuteA A B.\n\u2190 \u2229\nsubtract(B): ReplaceAwiththedifferenceofAandB,thatis,execute\nA A B.\n\u2190 \u2212\nA Simple Mergable Set Implementation\nOne of the simplest ways of implementing a set is to store its elements in an or-\ndered sequence. This implementation is included in several software libraries for\ngeneric data structures, for example. Therefore, let us consider implementing the\nset ADT with an ordered sequence (we consider other implementations in several\nexercises). Anyconsistenttotalorderrelationamongtheelementsofthesetcanbe\nused,provided thesameorderisusedforallthesets.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 535 \u2014 #557\ni i\n11.4. SetsandUnion/FindStructures 535\nWeimplementeachofthethreefundamentalsetoperationsusingagenericver-\nsionofthemergealgorithm thattakes, asinput,twosortedsequences representing\ntheinputsets,andconstructsasequencerepresentingtheoutputset,beittheunion,\nintersection,orsubtractionoftheinputsets. Incidentally,wehavedefinedtheseop-\nerations so that they modify the contents of the set A involved. Alternatively, we\ncould have defined these functions so that they do not modify A but return a new\nsetinstead.\nThegenericmergealgorithmiterativelyexaminesandcomparesthecurrentel-\nements aand bof the input sequence A and B, respectively, and finds out whether\na<b, a=b, or a>b. Then, based on the outcome of this comparison, it deter-\nmines whether it should copy one of the elements a and b tothe end of the output\nsequence C. This determination is made based on the particular operation we are\nperforming, be it a union, intersection, or subtraction. For example, in a union\noperation, weproceedasfollows:\nIfa<b,wecopyatotheendofC andadvancetothenextelementofA\n\u2022\nIf a=b, we copy a to the end ofC and advance to the next elements of A\n\u2022\nandB\nIfa>b,wecopybtotheendofC andadvancetothenextelementofB\n\u2022\nPerformance of Generic Merging\nLetusanalyzetherunningtimeofgenericmerging. Ateachiteration, wecompare\ntwo elements of the input sequences A and B, possibly copy one element to the\noutput sequence, and advance the current element of A, B, or both. Assuming\nthat comparing and copying elements takes O(1) time, the total running time is\nO(n +n ), where n is the size of A and n is the size of B; that is, generic\nA B A B\nmerging takes time proportional to the number of elements. Thus, we have the\nfollowing:\nProposition 11.8: ThesetADTcanbeimplementedwithanorderedsequence\nandagenericmergeschemethatsupportsoperationsunion,intersect,andsubtract\ninO(n)time,wherendenotesthesumofsizesofthesetsinvolved.\nGeneric Merging as a Template Method Pattern\nThe generic merge algorithm is based on the template method pattern (see Sec-\ntion 7.3.7). The template method pattern is a software engineering design pattern\ndescribing ageneric computation mechanism thatcanbespecialized byredefining\ncertain steps. In this case, we describe a method that merges two sequences into\noneandcanbespecialized bythebehavior ofthreeabstract methods.\nCode Fragments 11.9 and 11.10 show the class Merge providing a C++ im-\nplementation of the generic merge algorithm. This class has no data members. It\ndefinesapublicfunctionmerge,whichmergesthetwolistsAandB,andstoresthe\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 536 \u2014 #558\ni i\n536 Chapter11. Sorting,Sets,andSelection\nresultinC. Itprovidesthreevirtualfunctions,fromA,fromB,andfromBoth. These\nare pure virtual functions (that is, they are not defined here), but are overridden in\nsubclasses of Merge, to achieve adesired effect. Thefunction fromA specifies the\naction to be taken when the next element to be selected in the merger is from A.\nSimilarly, fromB specifies theaction whenthe next element tobe selected isfrom\nB. Finally, fromBoth is the action to be taken when the two elements of A and B\nareequal,andhencebotharetobeselected.\ntemplate <typename E>\nclass Merge // generic Merge\n{\npublic: // global types\ntypedef std::list<E> List; // list type\nvoid merge(List& A, List& B, List& C); // generic merge function\nprotected: // local types\ntypedef typename List::iterator Itor; // iterator type\n// overridden functions\nvirtual void fromA(const E& a, List& C) = 0;\nvirtual void fromBoth(const E& a, const E& b, List& C) = 0;\nvirtual void fromB(const E& b, List& C) = 0;\n;\n}\nCodeFragment11.9: DefinitionoftheclassMergeforgeneric merging.\nThe function merge, which ispresented in Code Fragment 11.10 performs the\nactual merger. It is structurally similar to the list-based merge procedure given in\nCode Fragment 11.3. Rather than simply taking an element from list A or list B,\nit invokes one of the virtual functions to perform the appropriate specialized task.\nThefinalresultisstoredinthelistC.\ntemplate <typename E> // generic merge\nvoid Merge<E>::merge(List& A, List& B, List& C)\n{\nItor pa = A.begin(); // A\u2019s elements\nItor pb = B.begin(); // B\u2019s elements\nwhile (pa != A.end() && pb != B.end()) // main merging loop\n{\nif (*pa < *pb)\nfromA(*pa++, C); // take from A\nelse if (*pa == *pb)\nfromBoth(*pa++, *pb++, C); // take from both\nelse\nfromB(*pb++, C); // take from B\n}\nwhile (pa != A.end()) fromA(*pa++, C); // take rest from A\n{ }\nwhile (pb != B.end()) fromB(*pb++, C); // take rest from B\n{ }\n}\nCodeFragment11.10: Memberfunctionmergewhichimplementsgenericmerging\nforclassMerge.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 537 \u2014 #559\ni i\n11.4. SetsandUnion/FindStructures 537\nToconvertMergeintoausefulclass,weprovidedefinitionsforthethreeauxil-\niaryfunctions, fromA,fromBoth,andfromB.SeeCode11.11.\nIn class UnionMerge, merge copies every element from A and B intoC, but\n\u2022\ndoesnotduplicate anyelement.\nInclass IntersectMerge, mergecopies everyelement thatisinboth AandB\n\u2022\nintoC,but\u201cthrowsaway\u201delementsinonesetbutnotintheother.\nInclassSubtractMerge,mergecopieseveryelementthatisinAandnotinB\n\u2022\nintoC.\ntemplate <typename E> // set union\nclass UnionMerge : public Merge<E>\n{\nprotected:\ntypedef typename Merge<E>::List List;\nvirtual void fromA(const E& a, List& C)\nC.push back(a); // add a\n{ }\nvirtual void fromBoth(const E& a, const E& b, List& C)\nC.push back(a); // add a only\n{ }\nvirtual void fromB(const E& b, List& C)\nC.push back(b); // add b\n{ }\n;\n}\ntemplate <typename E> // set intersection\nclass IntersectMerge : public Merge<E>\n{\nprotected:\ntypedef typename Merge<E>::List List;\nvirtual void fromA(const E& a, List& C)\n// ignore\n{ }\nvirtual void fromBoth(const E& a, const E& b, List& C)\nC.push back(a); // add a only\n{ }\nvirtual void fromB(const E& b, List& C)\n// ignore\n{ }\n;\n}\ntemplate <typename E> // set subtraction\nclass SubtractMerge : public Merge<E>\n{\nprotected:\ntypedef typename Merge<E>::List List;\nvirtual void fromA(const E& a, List& C)\nC.push back(a); // add a\n{ }\nvirtual void fromBoth(const E& a, const E& b, List& C)\n// ignore\n{ }\nvirtual void fromB(const E& b, List& C)\n// ignore\n{ }\n;\n}\nCodeFragment11.11: Classesextending theMergeclassbyspecializing theauxil-\niaryfunctions toperformsetunion,intersection, andsubtraction, respectively.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 538 \u2014 #560\ni i\n538 Chapter11. Sorting,Sets,andSelection\n11.4.3 Partitions with Union-Find Operations\nA partition isa collection of disjoint sets. Wedefine the functions of the partition\nADTusingpositionobjects(Section6.2.1),eachofwhichstoresanelementx. The\npartition ADTsupports thefollowingfunctions.\nmakeSet(x): Createasingletonsetcontainingtheelementxandreturn\ntheposition storingxinthisset.\nunion(A,B): ReturnthesetA B,destroying theoldAandB.\n\u222a\nfind(p): Returnthesetcontaining theelementinposition p.\nA simple implementation of a partition with a total of n elements is using a\ncollection ofsequences, oneforeach set, wherethesequence forasetAstores set\npositions as its elements. Each position object stores a variable, element, which\nreferences itsassociated elementxandallowstheexecutionoftheelement()func-\ntioninO(1)time. Inaddition, wealsostoreavariable, set,ineachposition, which\nreferences the sequence storing p, since this sequence is representing the set con-\ntaining p\u2019s element. (See Figure 11.16.) Thus, we can perform operation find(p)\nin O(1) time, by following the set reference for p. Likewise, makeSet also takes\nO(1)time. Operationunion(A,B)requiresthatwejointwosequencesintooneand\nupdate the set references of the positions in one of the two. We choose to imple-\nment this operation by removing all the positions from the sequence with smaller\nsize, and inserting them in the sequence with larger size. Each time we take a\nposition p from the smaller set s and insert it into the larger set t, we update the\nset reference for p to now point tot. Hence, the operation union(A,B) takes time\nO(min(A , B )), whichisO(n),because, intheworstcase, A = B =n/2. Nev-\n| | | | | | | |\nertheless, as shown below, an amortized analysis shows this implementation to be\nmuchbetterthanappearsfromthisworst-caseanalysis.\nA B\n4 1 7 9 3 6 2\nC\n5 11 12 10 8\nFigure11.16:Sequence-basedimplementationofapartitionconsistingofthreesets:\nA= 1,4,7 , B= 2,3,6,9 , andC= 5,8,10,11,12 .\n{ } { } { }\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 539 \u2014 #561\ni i\n11.4. SetsandUnion/FindStructures 539\nPerformance of the Sequence Implementation\nThesequenceimplementationaboveissimple,butitisalsoefficient,asthefollow-\ningtheorem shows.\nProposition 11.9: PerformingaseriesofnmakeSet,union,andfindoperations,\nusingthesequence-basedimplementationabove,startingfromaninitiallyempty\npartitiontakesO(nlogn)time.\nJustification: Weuse the accounting method and assume that one cyber-dollar\ncanpayforthetimetoperformafindoperation,amakeSetoperation,orthemove-\nmentofapositionobjectfromonesequencetoanotherinaunionoperation. Inthe\ncase of afind or makeSet operation, we charge the operation itself 1 cyber-dollar.\nInthecaseofaunionoperation,however,wecharge1cyber-dollartoeachposition\nthat we move from one set to another. Note that we charge nothing to the union\noperations themselves. Clearly, the total charges to find and makeSet operations\nadduptoO(n).\nConsider,then,thenumberofchargesmadetopositionsonbehalfofunionop-\nerations. Theimportantobservation isthateachtimewemoveapositionfromone\nsettoanother,thesizeofthenewsetatleastdoubles. Thus,eachpositionismoved\nfromonesettoanother atmostlogntimes;hence, eachposition canbecharged at\nmostO(logn)times. Sinceweassumethatthepartitionisinitiallyempty,thereare\nO(n)differentelementsreferenced inthegivenseriesofoperations, whichimplies\nthatthetotaltimeforalltheunionoperations isO(nlogn).\nTheamortized running timeofanoperation inaseriesofmakeSet,union,and\nfindoperations, isthetotaltimetakenfortheseriesdividedbythenumberofoper-\nations. We conclude from the proposition above that, for a partition implemented\nusing sequences, the amortized running time of each operation is O(logn). Thus,\nwecan summarize theperformance ofour simplesequence-based partition imple-\nmentationasfollows.\nProposition 11.10: Usingasequence-basedimplementationofapartition,ina\nseriesofn makeSet,union,andfind operationsstartingfromaninitiallyempty\npartition,theamortizedrunningtimeofeachoperationisO(logn).\nNotethatinthissequence-based implementation ofapartition, eachfindoper-\nationtakesworst-caseO(1)time. Itistherunningtimeoftheunionoperationsthat\nisthecomputational bottleneck.\nInthenextsection, wedescribe atree-based implementation ofapartition that\ndoes not guarantee constant-time find operations, but has amortized time much\nbetterthanO(logn)perunionoperation.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 540 \u2014 #562\ni i\n540 Chapter11. Sorting,Sets,andSelection\n\u22c6\nA Tree-Based Partition Implementation\nAnalternativedatastructureusesacollectionoftreestostorethenelementsinsets,\nwhereeachtreeisassociated withadifferent set. (SeeFigure11.17.) Inparticular,\nwe implement each tree with a linked data structure whose nodes are themselves\nthe set position objects. We still view each position p as being a node having a\nvariable, element, referring to its element x, and a variable, set, referring to a set\ncontaining x, as before. But now we also view each position p as being of the\n\u201cset\u201d data type. Thus, the set reference of each position p can point to a position,\nwhichcouldevenbe pitself. Moreover,weimplementthisapproachsothatallthe\npositions andtheirrespective setreferences togetherdefineacollection oftrees.\nWeassociateeachtreewithaset. Foranyposition p,if p\u2019ssetreferencepoints\nback to p, then p is the root of its tree, and the name of the set containing p is\n\u201cp\u201d (that is, we use position names as set names in this case). Otherwise, the set\nreferencefor ppointsto p\u2019sparentinitstree. Ineithercase,thesetcontaining pis\ntheoneassociated withtherootofthetreecontaining p.\nFigure11.17: Tree-based implementation of apartition consisting of three disjoint\nsets: A= 1,4,7 , B= 2,3,6,9 , andC= 5,8,10,11,12 .\n{ } { } { }\nWith this partition data structure, operation union(A,B)is called withposition\narguments p and q that respectively represent the sets A and B (that is, A= p and\nB = q). We perform this operation by making one of the trees a subtree of the\nother (Figure11.18b), whichcanbedone inO(1)timebysetting theset reference\nof the root of one tree to point to the root of the other tree. Operation find for a\nposition pisperformedbywalkinguptotherootofthetreecontainingtheposition\np(Figure11.18a), whichtakesO(n)timeintheworstcase.\nAtfirst,thisimplementation mayseemtobenobetterthanthesequence-based\ndatastructure, butweaddthefollowingtwosimpleheuristicstomakeitrunfaster.\nUnion-by-Size: Store, with each position node p, the size of the subtree rooted\nat p. Inaunionoperation, makethetreeofthesmallersetbecomeasubtree\noftheothertree,andupdatethesizefieldoftherootoftheresulting tree.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 541 \u2014 #563\ni i\n11.4. SetsandUnion/FindStructures 541\n2\n2\n5\n3 6 5\n3 6\n8 10\n9 8 10\n9\n11\n11\n12\n12\n(a) (b)\nFigure11.18: Tree-based implementation of apartition: (a) operation union(A,B);\n(b)operation find(p),where pdenotestheposition objectforelement12.\nPathCompression: In a find operation, for each node v that the find visits, reset\ntheparentpointerfromvtopointtotheroot. (SeeFigure11.19.)\n2\n2\n5\n5 3 6\n3 6\n8 10\n8 10\n9\n9\n11\n11\n12\n12\n(a) (b)\nFigure 11.19: Path-compression heuristic: (a) path traversed by operation find on\nelement12;(b)restructured tree.\nAsurprisingpropertyofthisdatastructure,whenimplementedusingtheunion-\nby-sizeandpath-compression heuristics, isthatperforming aseriesofnunionand\nfindoperations takes O(nlog\u2217n)time, wherelog\u2217nisthelog-star function, which\nis the inverse of the tower-of-twos function. Intuitively, log\u2217n is the number of\ntimesthatonecaniterativelytakethelogarithm(base2)ofanumberbeforegetting\nanumbersmallerthan2. Table11.1showsafewsamplevalues.\nMinimumn 2 22 =4 222 =16 2222 =65,536 22222 =265,536\n\u2217\nlog n 1 2 3 4 5\nTable11.1: Somevaluesoflog\u2217nandcriticalvaluesforitsinverse.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 542 \u2014 #564\ni i\n542 Chapter11. Sorting,Sets,andSelection\n11.5 Selection\nThereareanumber ofapplications inwhichweareinterested inidentifying asin-\ngle element in terms of its rank relative to an ordering of the entire set. Examples\ninclude identifying the minimum and maximum elements, but we may also be in-\nterested in, say, identifying the median element, that is, theelement such that half\nof the other elements are smaller and the remaining half are larger. In general,\nqueriesthataskforanelementwithagivenrankarecalledorderstatistics.\nDefining the Selection Problem\nIn this section, we discuss the general order-statistic problem of selecting the kth\nsmallest element from an unsorted collection of n comparable elements. This is\nknown as the selection problem. Of course, we can solve this problem by sorting\nthe collection and then indexing into the sorted sequence at index k 1. Using\n\u2212\nthebestcomparison-based sorting algorithms, thisapproach wouldtake O(nlogn)\ntime, which is obviously an overkill for the cases where k=1 or k =n (or even\nk =2, k=3, k =n 1, or k =n 5), because we can easily solve the selection\n\u2212 \u2212\nproblem for these values of k in O(n) time. Thus, a natural question to ask is\nwhether we can achieve an O(n) running time for all values of k (including the\ninteresting caseoffindingthemedian,wherek= n/2 ).\n\u230a \u230b\n11.5.1 Prune-and-Search\nThismaycomeasasmallsurprise,butwecanindeedsolvetheselectionproblemin\nO(n)timeforanyvalueofk. Moreover, thetechnique weusetoachievethisresult\ninvolves an interesting algorithmic design pattern. This design pattern is known\nas prune-and-search or decrease-and-conquer. In applying this design pattern,\nwe solve a given problem that is defined on a collection of n objects by pruning\nawayafractionofthenobjectsandrecursivelysolvingthesmallerproblem. When\nwe have finally reduced the problem to one defined on a constant-sized collection\nof objects, then we solve the problem using some brute-force method. Returning\nback from all the recursive calls completes the construction. In some cases, we\ncan avoid using recursion, in which case we simply iterate the prune-and-search\nreduction step until wecan apply a brute-force method and stop. Incidentally, the\nbinary search method described in Section 9.3.1 is an example of the prune-and-\nsearchdesignpattern.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 543 \u2014 #565\ni i\n11.5. Selection 543\n11.5.2 Randomized Quick-Select\nIn applying the prune-and-search pattern to the selection problem, we can design\nasimpleand practical method, called randomized quick-select, forfinding thekth\nsmallest element in an unordered sequence of n elements on which a total order\nrelation is defined. Randomized quick-select runs in O(n) expected time, taken\noverallpossiblerandomchoicesmadebythealgorithm. Thisexpectation doesnot\ndepend whatsoever on any randomness assumptions about the input distribution.\nWenotethoughthatrandomized quick-select runsinO(n2)timeintheworstcase.\nThe justification of this is left as an exercise (Exercise R-11.26). We also provide\nanexercise (Exercise C-11.32)formodifying randomized quick-select togetade-\nterministic selection algorithm that runs in O(n) worst-case time. The existence\nof this deterministic algorithm is mostly of theoretical interest, however, since the\nconstant factorhiddenbythebig-Ohnotation isrelativelylargeinthiscase.\nSuppose we are given an unsorted sequence S of n comparable elements to-\ngether with an integer k [1,n]. At a high level, the quick-select algorithm for\n\u2208\nfindingthekthsmallestelementinSissimilarinstructuretotherandomizedquick-\nsortalgorithm describedinSection11.2.1. WepickanelementxfromSatrandom\nandusethisasa\u201cpivot\u201dtosubdivideSintothreesubsequencesL,E,andG,storing\nthe elements of S less than x, equal to x, and greater than x, respectively. This is\ntheprune step. Then, based onthe value ofk,wedetermine which ofthese setsto\nrecuron. Randomized quick-select isdescribed inCodeFragment11.12.\nAlgorithmquickSelect(S,k):\nInput: SequenceSofncomparableelements, andanintegerk [1,n]\n\u2208\nOutput: ThekthsmallestelementofS\nifn=1then\nreturnthe(first)elementofS.\npickarandom(pivot)elementxofSanddivideSintothreesequences:\nL,storingtheelementsinSlessthanx\n\u2022\nE,storing theelementsinSequaltox\n\u2022\nG,storingtheelementsinSgreaterthanx.\nifk\u2022 L then\n\u2264| |\nquickSelect(L,k)\nelseifk L + E then\n\u2264| | | |\nreturnx eachelementinE isequaltox\n{ }\nelse\nquickSelect(G,k L E ) notethenewselectionparameter\n\u2212| |\u2212| | { }\nCodeFragment11.12: Randomized quick-select algorithm.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 544 \u2014 #566\ni i\n544 Chapter11. Sorting,Sets,andSelection\n11.5.3 Analyzing Randomized Quick-Select\nShowing that randomized quick-select runs in O(n) time requires a simple prob-\nabilistic argument. The argument is based on the linearity of expectation, which\nstatesthatifX andY arerandomvariables andcisanumber,then\nE(X+Y)=E(X)+E(Y) and E(cX)=cE(X),\nwhereweuseE( )todenote theexpected valueoftheexpression .\nZ Z\nLett(n)betherunningtimeofrandomizedquick-selectonasequenceofsizen.\nSincethisalgorithm depends onrandom events,itsrunningtime,t(n),isarandom\nvariable. WewanttoboundE(t(n)),theexpectedvalueoft(n). Saythatarecursive\ninvocation of our algorithm is \u201cgood\u201d if it partitions S so that the size of L and G\nis at most 3n/4. Clearly, a recursive call is good with probability 1/2. Let g(n)\ndenote the number of consecutive recursive calls we make, including the present\none, before weget agood one. Thenwecan characterize t(n) using the following\nrecurrenceequation\nt(n) bn g(n)+t(3n/4),\n\u2264 \u00b7\nwhereb 1isaconstant. Applyingthelinearity ofexpectation forn>1,weget\n\u2265\nE(t(n)) E(bn g(n)+t(3n/4))=bn E(g(n))+E(t(3n/4)).\n\u2264 \u00b7 \u00b7\nSince arecursive call isgood withprobability 1/2, and whether arecursive call is\ngoodornotisindependent onitsparentcallbeinggood,theexpectedvalueofg(n)\nisthesameastheexpectednumberoftimeswemustflipafaircoinbeforeitcomes\nup \u201cheads.\u201d That is, E(g(n))=2. Thus, if we let T(n) be shorthand for E(t(n)),\nthenwecanwritethecaseforn>1as\nT(n) T(3n/4)+2bn.\n\u2264\nTo convert this relation into a closed form, let us iteratively apply this inequality\nassumingnislarge. So,forexample,aftertwoapplications,\nT(n) T((3/4)2n)+2b(3/4)n+2bn.\n\u2264\nAtthispoint,weshouldseethatthegeneralcaseis\n\u2308log n\u2309\n4/3\nT(n) 2bn \u2211 (3/4)i.\n\u2264 \u00b7\ni=0\nIn other words, the expected running time is at most 2bn times a geometric sum\nwhosebaseisapositivenumberlessthan1. Thus,byProposition4.5,T(n)isO(n).\nProposition 11.11: Theexpectedrunningtimeofrandomizedquick-selectona\nsequenceSofsizenisO(n),assumingtwoelementsofScanbecomparedinO(1)\ntime.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 545 \u2014 #567\ni i\n11.6. Exercises 545\n11.6 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-11.1 What is the best algorithm for sorting each of the following: general\ncomparableobjects,longcharacterstrings,double-precisionfloatingpoint\nnumbers, 32-bitintegers,andbytes? Justifyyouranswer.\nR-11.2 SupposeSisalistofnbits, thatis,n0\u2019sand1\u2019s. Howlongwillittaketo\nsortSwiththemerge-sort algorithm? Whataboutquick-sort?\nR-11.3 SupposeSisalistofnbits, thatis,n0\u2019sand1\u2019s. Howlongwillittaketo\nsortSstablywiththebucket-sort algorithm?\nR-11.4 Giveacompletejustification ofProposition 11.1.\nR-11.5 Inthemerge-sorttreeshowninFigures11.2through11.4,someedgesare\ndrawnasarrows. Whatisthemeaningofadownwardarrow? Howabout\nanupwardarrow?\nR-11.6 Give a complete pseudo-code description of the recursive merge-sort al-\ngorithm thattakesanarrayasitsinputandoutput.\nR-11.7 Show that the running time of the merge-sort algorithm on an n-element\nsequence isO(nlogn),evenwhennisnotapowerof2.\nR-11.8 Supposewearegiventwon-elementsortedsequencesAandBthatshould\nnot be viewed as sets (that is, A and B may contain duplicate entries).\nDescribeanO(n)-timemethodforcomputingasequencerepresentingthe\nsetA B(withnoduplicates).\n\u222a\nR-11.9 Showthat(X A) (X B)=X (A B),foranythreesetsX,A,andB.\n\u2212 \u222a \u2212 \u2212 \u2229\nR-11.10 Suppose wemodify the deterministic version of the quick-sort algorithm\nso that, instead of selecting the last element in an n-element sequence as\nthepivot,wechoosetheelementatindex n/2 . Whatistherunningtime\n\u230a \u230b\nofthisversionofquick-sort onasequence thatisalreadysorted?\nR-11.11 Consider a modification of the deterministic version of the quick-sort al-\ngorithm where we choose the element at index n/2 as our pivot. De-\n\u230a \u230b\nscribe the kind ofsequence that would cause this version ofquick-sort to\nrunin\u2126(n2)time.\nR-11.12 Show that the best-case running time of quick-sort on a sequence of size\nnwithdistinctelementsisO(nlogn).\nR-11.13 Describearandomized versionofin-place quick-sort inpseudo-code.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 546 \u2014 #568\ni i\n546 Chapter11. Sorting,Sets,andSelection\nR-11.14 Show that theprobability that any given input element xbelongs tomore\nthan 2logn subproblems in size group i, for randomized quick-sort, is at\nmost1/n2.\nR-11.15 Suppose algorithm inPlaceQuickSort (Code Fragment 11.6) is executed\nonasequence withduplicate elements. Showthatthe algorithm stillcor-\nrectlysortstheinputsequence, buttheresultofthedividestepmaydiffer\nfrom the high-level description given in Section 11.2, and may result in\ninefficiencies. Inparticular, whathappensinthepartitionstepwhenthere\nare elements equal to the pivot? Is the sequence E (storing the elements\nequal to the pivot) actually computed? Does the algorithm recur on the\nsubsequences L andG,or onsomeother subsequences? Whatisthe run-\nningtimeofthealgorithm ifalltheinputelementsareequal?\nR-11.16 Of the n! possible inputs to a given comparison-based sorting algorithm,\nwhatistheabsolutemaximumnumberofinputsthatcouldbesortedwith\njustncomparisons?\nR-11.17 Bella has a comparison-based sorting algorithm that sorts the first k ele-\nmentsinsequence ofsizeninO(n)time. Giveabig-Ohcharacterization\nofthebiggest thatkcanbe?\nR-11.18 Isthemerge-sort algorithm inSection11.1stable? Whyorwhynot?\nR-11.19 An algorithm that sorts key-value entries by key is said to be straggling\nif,anytimetwoentriese ande haveequalkeys,bute appearsbeforee\ni j i j\nintheinput, thenthealgorithm placese aftere intheoutput. Describea\ni j\nchangetothemerge-sortalgorithminSection11.1tomakeitstraggling.\nR-11.20 Describearadix-sortmethodforlexicographicallysortingasequenceSof\ntriplets (k,l,m), where k, l, and m are integers inthe range [0,N 1], for\n\u2212\nsomeN 2. Howcouldthisschemebeextendedtosequencesofd-tuples\n\u2265\n(k ,k ,...,k ),whereeachk isanintegerintherange[0,N 1]?\n1 2 d i\n\u2212\nR-11.21 Isthebucket-sort algorithm in-place? Whyorwhynot?\nR-11.22 Give an example input list that requires merge-sort and heap-sort to take\nO(nlogn) time to sort, but insertion-sort runs in O(n) time. What if you\nreversethislist?\nR-11.23 Describe, inpseudo-code, howto perform path compression onapath of\nlengthhinO(h)timeinatree-based partition union/find structure.\nR-11.24 Edward claims he has a fast way to do path compression in a partition\nstructure, starting atanode v. Heputs vinto alist L,and starts following\nparent pointers. Each time he encounters a new node, u, he adds u to L\nand updates the parent pointer of each node in L to point to u\u2019s parent.\nShowthatEdward\u2019salgorithm runsin\u2126(h2)timeonapathoflengthh.\nR-11.25 Describeanin-placeversionofthequick-selectalgorithminpseudo-code.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 547 \u2014 #569\ni i\n11.6. Exercises 547\nR-11.26 Show that the worst-case running time of quick-select on an n-element\nsequence is\u2126(n2).\nCreativity\nC-11.1 Describeanefficientalgorithmforconvertingadictionary,D,implemented\nwith a linked list, into a map, M, implemented with a linked list, so that\neach key in D has an entry in M, and the relative order of entries in M is\nthesameastheirrelativeorderinD.\nC-11.2 Linda claims to have an algorithm that takes an input sequence S and\nproduces anoutputsequence T thatisasortingofthenelementsinS.\na. Giveanalgorithm, isSorted,fortestinginO(n)timeifT issorted.\nb. Explain why the algorithm isSorted is not sufficient to prove a par-\nticularoutputT ofLinda\u2019salgorithm isasortingofS.\nc. Describe what additional information Linda\u2019s algorithm could out-\nput so that her algorithm\u2019s correctness could be established on any\ngivenSandT inO(n)time.\nC-11.3 Giventwosets Aand Brepresented assorted sequences, describe aneffi-\ncientalgorithm forcomputing A B,whichisthesetofelementsthatare\n\u2295\ninAorB,butnotinboth.\nC-11.4 Suppose that we represent sets with balanced search trees. Describe and\nanalyzealgorithmsforeachofthefunctionsinthesetADT,assumingthat\noneofthetwosetsismuchsmallerthantheother.\nC-11.5 Describe and analyze an efficient function for removing all duplicates\nfromacollection Aofnelements.\nC-11.6 Consider sets whoseelements areintegers intherange [0,N 1]. Apop-\n\u2212\nularschemeforrepresenting asetAofthistypeisbymeansofaBoolean\narray,B,wherewesaythatxisinAifandonlyifB[x]=true. Sinceeach\ncell of B can be represented with a single bit, B is sometimes referred to\nas a bit vector. Describe and analyze efficient algorithms for performing\nthefunctions ofthesetADTassumingthisrepresentation.\nC-11.7 Consider a version of deterministic quick-sort where wepick the median\nofthed lastelementsintheinputsequenceofnelementsasourpivot,for\na fixed, constant odd number d 3. What is the asymptotic worst-case\n\u2265\nrunning timeofquick-sort inthiscase?\nC-11.8 Another way to analyze randomized quick-sort is to use a recurrence\nequation. In this case, we let T(n) denote the expected running time\nofrandomized quick-sort, andweobserve that,because oftheworst-case\npartitions forgoodandbadsplits,wecanwrite\n1 1\nT(n) (T(3n/4)+T(n/4))+ (T(n 1))+bn,\n\u2264 2 2 \u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 548 \u2014 #570\ni i\n548 Chapter11. Sorting,Sets,andSelection\nwherebnisthetimeneededtopartitionalistforagivenpivotandconcate-\nnatetheresultsublistsaftertherecursivecallsreturn. Show,byinduction,\nthatT(n)isO(nlogn).\nC-11.9 Modify inPlaceQuickSort (Code Fragment 11.6) to handle the general\ncaseefficientlywhentheinputsequence, S,mayhaveduplicate keys.\nC-11.10 Describeanonrecursive,in-placeversionofthequick-sortalgorithm. The\nalgorithmshouldstillbebasedonthesamedivide-and-conquer approach,\nbutuseanexplicitstacktoprocesssubproblems.\nC-11.11 An inverted file is a critical data structure for implementing a search en-\ngine or the index of a book. Given a document D, which can be viewed\nasanunordered, numberedlistofwords,aninvertedfileisanorderedlist\nof words, L, such that, for each w word in L, we store the indices of the\nplacesinDwherewappears. Designanefficientalgorithm forconstruct-\ningLfromD.\nC-11.12 GivenanarrayAofnentrieswithkeysequalto0or1,describeanin-place\nfunction fororderingAsothatallthe0\u2019sarebeforeevery1.\nC-11.13 Suppose we are given an n-element sequence S such that each element\nin S represents a different vote for president, where each vote is given\nas an integer representing a particular candidate. Design an O(nlogn)-\ntime algorithm to see who wins the election S represents, assuming the\ncandidate withthemostvoteswins(evenifthereareO(n)candidates).\nC-11.14 ConsiderthevotingproblemfromExerciseC-11.13,butnowsupposethat\nweknowthenumberk<nofcandidatesrunning. DescribeanO(nlogk)-\ntimealgorithm fordetermining whowinstheelection.\nC-11.15 Consider the voting problem from Exercise C-11.13, but now suppose a\ncandidate winsonly ifheor she gets amajority ofthe votes cast. Design\nandanalyzeafastalgorithm fordetermining thewinnerifthereisone.\nC-11.16 Show that any comparison-based sorting algorithm can be made to be\nstablewithoutaffecting itsasymptoticrunning time.\nC-11.17 Suppose we are given two sequences A and B of n elements, possibly\ncontaining duplicates, onwhichatotalorderrelation isdefined. Describe\nan efficient algorithm for determining if A and B contain the same set of\nelements. Whatistherunning timeofthismethod?\nC-11.18 Given an array A of n integers in the range [0,n2 1], describe a simple\n\u2212\nfunction forsortingAinO(n)time.\nC-11.19 Let S ,S ,...,S be k different sequences whose elements have integer\n1 2 k\nkeys in the range [0,N 1], for some parameter N 2. Describe an al-\n\u2212 \u2265\ngorithm running in O(n+N) time for sorting all the sequences (not as a\nunion), wherendenotesthetotalsizeofallthesequences.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 549 \u2014 #571\ni i\n11.6. Exercises 549\nC-11.20 Given a sequence S of n elements, on which a total order relation is de-\nfined,describeanefficientfunctionfordeterminingwhethertherearetwo\nequalelementsinS. Whatistherunning timeofyourfunction?\nC-11.21 Let S be a sequence of n elements on which a total order relation is de-\nfined. Recall that an inversion in S is a pair of elements x and y such\nthat x appears before y in S but x>y. Describe an algorithm running in\nO(nlogn)timefordetermining thenumberofinversions inS.\nC-11.22 Let S be a random permutation of n distinct integers. Argue that the ex-\npectedrunning timeofinsertion-sort onSis\u2126(n2).\n(Hint: Note that half of the elements ranked in the top half of a sorted\nversionofSareexpected tobeinthefirsthalfofS.)\nC-11.23 Let A and B be two sequences of n integers each. Given an integer m,\ndescribeanO(nlogn)-timealgorithmfordeterminingifthereisaninteger\nainAandanintegerbinBsuchthatm=a+b.\nC-11.24 Given a set of n integers, describe and analyze a fast method for finding\nthe logn integersclosest tothemedian.\n\u2308 \u2309\nC-11.25 James has a set A of n nuts and a set B of n bolts, such that each nut in\nA has a unique matching bolt in B. Unfortunately, the nuts in A all look\nthesame, andthebolts inBalllook thesameaswell. Theonlykind ofa\ncomparison thatBobcanmakeistotakeanut-boltpair(a,b),suchthata\nisinAandbisinB,andtestittoseeifthethreadsofaarelarger,smaller,\noraperfectmatchwiththethreadsofb. Describeandanalyzeanefficient\nalgorithm forBobtomatchupallofhisnutsandbolts.\nC-11.26 Show how to use a deterministic O(n)-time selection algorithm to sort a\nsequence ofnelementsinO(nlogn)worst-casetime.\nC-11.27 GivenanunsortedsequenceSofncomparableelements,andanintegerk,\ngive an O(nlogk)expected-time algorithm for finding the O(k)elements\nthathaverank n/k ,2 n/k ,3 n/k , andsoon.\n\u2308 \u2309 \u2308 \u2309 \u2308 \u2309\nC-11.28 Let S be a sequence of n insert and removeMin operations, where all the\nkeys involved are integers in the range [0,n 1]. Describe an algorithm\n\u2212\nrunning inO(nlog\u2217n)fordetermining theanswertoeachremoveMin.\nC-11.29 Spacealienshavegivenusaprogram,alienSplit,thatcantakeasequence\nSofnintegersandpartitionSinO(n)timeintosequencesS ,S ,...,S of\n1 2 k\nsizeatmost n/k each,suchthattheelementsinS arelessthanorequal\ni\n\u2308 \u2309\ntoeveryelement inS ,fori=1,2,...,k 1,forafixednumber, k<n.\ni+1\n\u2212\nShowhowtousealienSplittosortSinO(nlogn/logk)time.\nC-11.30 Karen has a new way to do path compression in a tree-based union/find\npartition datastructure startingatanodev. Sheputsallthenodesthatare\nonthepathfromvtotherootinasetS. ThenshescansthroughSandsets\nthe parent pointer of each node in S to its parent\u2019s parent pointer (recall\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 550 \u2014 #572\ni i\n550 Chapter11. Sorting,Sets,andSelection\nthattheparentpointeroftherootpointstoitself). Ifthispasschangedthe\nvalueofanynode\u2019sparentpointer,thensherepeatsthisprocess,andgoes\non repeating this process until she makes a scan through S that does not\nchange any node\u2019s parent value. Show that Karen\u2019s algorithm is correct\nandanalyzeitsrunning timeforapathoflengthh.\nC-11.31 Let S be a sequence of n integers. Describe a method for printing out all\nthepairsofinversionsinSinO(n+k)time,wherekisthenumberofsuch\ninversions.\nC-11.32 This problem deals with modification of the quick-select algorithm to\nmakeitdeterministic yetstillruninO(n)timeonann-elementsequence.\nThe idea is to modify the way we choose the pivot so that it is chosen\ndeterministically, notrandomly, asfollows:\nPartitionthesetSinto n/5 groupsofsize5each(exceptpos-\n\u2308 \u2309\nsiblyforonegroup). Sorteachlittlesetandidentifythemedian\nelementinthisset. Fromthissetof n/5 \u201cbaby\u201dmedians,ap-\n\u2308 \u2309\nplytheselectionalgorithmrecursivelytofindthemedianofthe\nbaby medians. Usethiselement asthepivot andproceed asin\nthequick-select algorithm.\nShow that this deterministic method runs in O(n) time by answering the\nfollowing questions (please ignore floorandceiling functions ifthatsim-\nplifiesthemathematics, fortheasymptotics arethesameeitherway):\na. Howmanybabymediansarelessthanorequaltothechosen pivot?\nHowmanyaregreaterthanorequaltothepivot?\nb. For each baby median less than or equal to the pivot, how many\nother elements are less than or equal to the pivot? Is the same true\nforthosegreater thanorequaltothepivot?\nc. Argue whythemethod for findingthe deterministic pivot andusing\nittopartition StakesO(n)time.\nd. Based on these estimates, write a recurrence equation to bound the\nworst-caserunningtimet(n)forthisselectionalgorithm(notethatin\ntheworstcasethere aretworecursive calls\u2014one tofindthemedian\nofthebabymediansandonetorecuronthelargerofLandG).\ne. Usingthisrecurrence equation, showbyinduction thatt(n)isO(n).\nProjects\nP-11.1 Design and implement two versions of the bucket-sort algorithm in C++,\none for sorting an array of char values and one for sorting an array of\nshort values. Experimentally compare the performance of your imple-\nmentationswiththesortingalgorithm oftheStandardTemplateLibrary.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 551 \u2014 #573\ni i\nChapterNotes 551\nP-11.2 Experimentallycomparetheperformanceofin-placequick-sortandaver-\nsionofquick-sort thatisnotin-place.\nP-11.3 Design and implement a version of the bucket-sort algorithm for sorting\na linked list of n entries (for instance, a list of type std::list<int>) with\ninteger keys taken from the range [0,N 1], for N 2. The algorithm\n\u2212 \u2265\nshouldruninO(n+N)time.\nP-11.4 Implement merge-sort and deterministic quick-sort and perform a series\nofbenchmarkingteststoseewhichoneisfaster. Yourtestsshouldinclude\nsequences thatare\u201crandom\u201daswellas\u201calmost\u201dsorted.\nP-11.5 Implement deterministic and randomized versions of the quick-sort al-\ngorithm and perform a series of benchmarking tests to see which one is\nfaster. Yourtestsshouldincludesequencesthatarevery\u201crandom\u201dlooking\naswellasonesthatare\u201calmost\u201dsorted.\nP-11.6 Implementanin-placeversionofinsertion-sort andanin-placeversionof\nquick-sort. Perform benchmarking tests to determine the range of values\nofnwherequick-sort isonaveragebetterthaninsertion-sort.\nP-11.7 Designandimplementananimation foroneofthesorting algorithms de-\nscribedinthischapter. Youranimationshouldillustratethekeyproperties\nofthisalgorithm inanintuitivemanner.\nP-11.8 Implement the randomized quick-sort and quick-select algorithms, and\ndesignaseriesofexperiments totesttheirrelativespeeds.\nP-11.9 Implement an extended set ADT that includes the functions union(B),\nintersect(B), subtract(B), size(), empty(), plus the functions equals(B),\ncontains(e),insert(e),andremove(e)withobviousmeaning.\nP-11.10 Implementthetree-based union/find partition datastructurewithboththe\nunion-by-size andpath-compression heuristics.\nChapter Notes\nKnuth\u2019s classic text on Sorting and Searching [60] contains an extensive history of the\nsorting problem and algorithms for solving it. Huang and Langston [48] show how to\nmergetwo sorted lists in-placein linear time. Our set ADT is derivedfromthat of Aho,\nHopcroft,andUllman[5]. Thestandardquick-sortalgorithmisduetoHoare[45]. More\ninformation about randomization, including Chernoff bounds, can be found in the ap-\npendix and the book by Motwani and Raghavan [80]. The quick-sort analysis given in\nthis chapter is a combinationof the analysis givenin a previousedition of this bookand\ntheanalysisofKleinbergandTardos[55]. ExerciseC-11.8isduetoLittman. Gonnetand\nBaeza-Yates[37]analyzeandexperimentallycompareseveralsortingalgorithms.Theterm\n\u201cprune-and-search\u201dcomesoriginallyfromthecomputationalgeometryliterature(suchas\nintheworkofClarkson[21]andMegiddo[71,72]). Theterm\u201cdecrease-and-conquer\u201dis\nfromLevitin[65].\ni i\ni i\nThis page intentionally left blank\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 553 \u2014 #575\ni i\nChapter\n12\nStrings and Dynamic Programming\nContents\n12.1 String Operations . . . . . . . . . . . . . . . . . . . . 554\n12.1.1 The STL String Class . . . . . . . . . . . . . . . . . 555\n12.2 Dynamic Programming . . . . . . . . . . . . . . . . . 557\n12.2.1 Matrix Chain-Product . . . . . . . . . . . . . . . . . 557\n12.2.2 DNA and Text Sequence Alignment . . . . . . . . . 560\n12.3 Pattern Matching Algorithms . . . . . . . . . . . . . . 564\n12.3.1 Brute Force . . . . . . . . . . . . . . . . . . . . . . 564\n12.3.2 The Boyer-Moore Algorithm . . . . . . . . . . . . . 566\n12.3.3 The Knuth-Morris-Pratt Algorithm . . . . . . . . . . 570\n12.4 Text Compression and the Greedy Method . . . . . . 575\n12.4.1 The Huffman-Coding Algorithm . . . . . . . . . . . 576\n12.4.2 The Greedy Method . . . . . . . . . . . . . . . . . . 577\n12.5 Tries . . . . . . . . . . . . . . . . . . . . . . . . . . . . 578\n12.5.1 Standard Tries . . . . . . . . . . . . . . . . . . . . . 578\n12.5.2 Compressed Tries . . . . . . . . . . . . . . . . . . . 582\n12.5.3 Suffix Tries . . . . . . . . . . . . . . . . . . . . . . 584\n12.5.4 Search Engines . . . . . . . . . . . . . . . . . . . . 586\n12.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 587\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 554 \u2014 #576\ni i\n554 Chapter12. StringsandDynamicProgramming\n12.1 String Operations\nDocument processing is rapidly becoming one of the dominant functions of com-\nputers. Computers are used to edit documents, to search documents, to transport\ndocuments over the Internet, and to display documents on printers and computer\nscreens. For example, the Internet document formats HTML and XML are pri-\nmarily text formats, with added tags for multimedia content. Making sense of the\nmany terabytes of information on the Internet requires a considerable amount of\ntextprocessing.\nIn addition to having interesting applications, text processing algorithms also\nhighlight some important algorithmic design patterns. In particular, the pattern\nmatching problem gives rise to the brute-force method, which is often inefficient\nbuthaswideapplicability. Fortextcompression, wecanapplythegreedymethod,\nwhich often allows us to approximate solutions to hard problems, and for some\nproblems (such as in text compression) actually gives rise to optimal algorithms.\nFinally, in discussing text similarity, we introduce the dynamic programming de-\nsign pattern, which can beapplied insome special instances to solve aproblem in\npolynomial timethatappears atfirsttorequireexponential timetosolve.\nText Processing\nAttheheartofalgorithms forprocessing textaremethodsfordealing withcharac-\nter strings. Character strings can come from a wide variety of sources, including\nscientific, linguistic, andInternet applications. Indeed, the following areexamples\nofsuchstrings:\nP = \u201cCGTAAACTGCTTTAATCAAACGC\u201d\nS = \u201chttp://www.wiley.com\u201d.\nThe first string, P, comes from DNA applications, and the second string, S, is the\nInternetaddress (URL)forthepublisher ofthisbook.\nSeveralofthetypicalstringprocessingoperationsinvolvebreakinglargestrings\ninto smaller strings. In order to be able to speak about the pieces that result from\nsuch operations, weuse the term substring of anm-character string Pto refer to a\nstringoftheformP[i]P[i+1]P[i+2] P[j],forsome0 i j m 1,thatis,the\n\u00b7\u00b7\u00b7 \u2264 \u2264 \u2264 \u2212\nstringformedbythecharactersinPfromindexitoindex j,inclusive. Technically,\nthismeansthatastringisactuallyasubstringofitself(takingi=0and j=m 1),\n\u2212\nso if we want to rule this out as a possibility, we must restrict the definition to\npropersubstrings, whichrequirethateitheri>0or j<m 1.\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 555 \u2014 #577\ni i\n12.1. StringOperations 555\nTo simplify the notation for referring to substrings, let us use P[i..j] to denote\nthesubstring ofPfromindexitoindex j,inclusive. Thatis,\nP[i..j]=P[i]P[i+1] P[j].\n\u00b7\u00b7\u00b7\nWe use the convention that if i> j, then P[i..j] is equal to the null string, which\nhas length 0. In addition, in order to distinguish some special kinds of substrings,\nletusrefer toanysubstring oftheform P[0..i], for0 i m 1, asaprefix ofP,\n\u2264 \u2264 \u2212\nand any substring of the form P[i..m 1], for 0 i m 1, as a suffix of P. For\n\u2212 \u2264 \u2264 \u2212\nexample,ifweagaintakePtobethestringofDNAgivenabove,then\u201cCGTAA\u201disa\nprefixofP,\u201cCGC\u201disasuffixofP,and\u201cTTAATC\u201disa(proper) substring ofP. Note\nthatthenullstringisaprefixandasuffixofanyotherstring.\nTo allow for fairly general notions of a character string, we typically do not\nrestrict the characters in T and P to explicitly come from a well-known character\nset,liketheASCIIorUnicodecharacter sets. Instead, wetypically usethesymbol\n\u03a3to denote the character set, oralphabet, from whichcharacters can come. Since\nmost document processing algorithms are used in applications where the underly-\ningcharactersetisfinite,weusuallyassumethatthesizeofthealphabet\u03a3,denoted\nwith \u03a3 ,isafixedconstant.\n| |\n12.1.1 The STL String Class\nRecall from Chapter 1 that C++ supports two types of strings. A C-style string is\njust an array of type char terminated by anull character \u2019\\0\u2019. Bythemselves, C-\nstylestringsdonotsupportcomplexstringoperations. TheC++StandardTemplate\nLibrary (STL)provides a complete stringclass. This class supports a bewildering\nnumber of string operations. We list just a few of them. In the following, let S\ndenote theSTLstringobject onwhichtheoperation isbeing performed, andletQ\ndenoteanotherSTLstringoraC-stylestring.\nsize(): Returnthenumberofcharacters, n,ofS.\nempty(): Returntrueifthestringisemptyandfalseotherwise.\noperator[i]: Return the character at index i of S, without performing\narrayboundschecking.\nat(i): Return the character at index i of S. An out of range\nexception isthrownifiisoutofbounds.\ninsert(i,Q): InsertstringQpriortoindexiinSandreturnareference\ntotheresult.\nappend(Q): AppendstringQtotheendofSandreturnareferenceto\ntheresult.\nerase(i,m): Removemcharacters starting atindexiandreturn aref-\nerencetotheresult.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 556 \u2014 #578\ni i\n556 Chapter12. StringsandDynamicProgramming\nsubstr(i,m): Returnthesubstring ofSoflengthmstartingatindexi.\nfind(Q): IfQisasubstring ofS,returntheindexofthebeginning\nofthefirstoccurrence ofQinS,elsereturnn,thelength\nofS.\nc str(): ReturnaC-stylestringcontaining thecontents ofS.\nBydefault,astringisinitializedtotheemptystring. Astringmaybeinitialized\nfrom another STL string or from a C-style string. It is not possible, however, to\ninitialize anSTLstringfromasinglecharacter. STLstrings alsosupport functions\nthat return both forward and backward iterators. All operations that are defined in\ntermsofintegerindiceshavecounterparts thatarebasedoniterators.\nTheSTLstring class alsosupports assignment of onestring toanother. Itpro-\nvides relational operators, such as ==, <, >=, which are performed lexicograph-\nically. Strings can be concatenated using +, and we may append one string to\nanother using +=. Strings can be input using >> and output using <<. The func-\ntiongetline(in,S) readsanentirelineofinputfromtheinputstream inandassigns\nittothestringS.\nThe STL string class is actually a special case of a more general templated\nclass, called basic string<T>, which supports all the string operations but allows\nits elements to be of an arbitrary type, T, not just char. The STL string is just a\nshort wayofsaying basic string<char>. A\u201cstring ofintegers\u201d could bedefinedas\nbasic string<int>.\nExample 12.1: Considerthefollowingseriesofoperations,whichareperformed\nonthestringS=\u201cabcdefghijklmnop\u201d:\nOperation Output\nS.size() 16\nS.at(5) \u2019f\u2019\nS[5] \u2019f\u2019\nS + \"qrs\" \"abcdefghijklmnopqrs\"\nS == \"abcdefghijklmnop\" true\nS.find(\"ghi\") 6\nS.substr(4,6) \"efghij\"\nS.erase(4,6) \"abcdklmnop\"\nS.insert(1,\"xxx\") \"axxxbcdklmnop\"\nS += \"xy\" \"axxxbcdklmnopxy\"\nS.append(\"z\") \"axxxbcdklmnopxyz\"\nWith the exception of the find(Q) function, which we discuss in Section 12.3,\nalltheabovefunctionsareeasilyimplementedsimplybyrepresenting thestringas\nanarrayofcharacters.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 557 \u2014 #579\ni i\n12.2. DynamicProgramming 557\n12.2 Dynamic Programming\nInthissection, wediscussthedynamicprogrammingalgorithm-design technique.\nThis technique is similar to the divide-and-conquer technique (Section 11.1.1), in\nthat it can be applied to a wide variety of different problems. There are few al-\ngorithmic techniques thatcan take problems that seem torequire exponential time\nand produce polynomial-time algorithms to solve them. Dynamic programming\nis one such technique. In addition, the algorithms that result from applications of\nthedynamicprogrammingtechniqueareusuallyquitesimple\u2014often needinglittle\nmorethanafewlinesofcodetodescribe somenestedloopsforfillinginatable.\n12.2.1 Matrix Chain-Product\nRather than starting out with an explanation of the general components of the dy-\nnamic programming technique, we begin by giving a classic, concrete example.\nSupposewearegivenacollectionofntwo-dimensionalarrays(matrices)forwhich\nwewishtocomputetheproduct\nA=A A A A ,\n0 1 2 n\u22121\n\u00b7 \u00b7 \u00b7\u00b7\u00b7\nwhere A is a d d matrix, for i = 0,1,2,...,n 1. In the standard matrix\ni i i+1\n\u00d7 \u2212\nmultiplication algorithm (which is the one we use), to multiply a d e-matrix B\n\u00d7\ntimesane f-matrixC,wecomputetheproduct, A,as\n\u00d7\ne\u22121\n\u2211\nA[i][j]= B[i][k] C[k][j].\n\u00b7\nk=0\nThis definition implies that matrix multiplication is associative, that is, it implies\nthatB (C D)=(B C) D. Thus,wecanparenthesizetheexpressionforAanyway\n\u00b7 \u00b7 \u00b7 \u00b7\nwewishandwestill endupwiththesameanswer. Wedonotnecessarily perform\nthesamenumberofprimitive(thatis,scalar) multiplications ineachparenthesiza-\ntion,however,asisillustrated inthefollowingexample.\nExample 12.2: LetBbea2 10-matrix,letCbea10 50-matrix,andletDbe\n\u00d7 \u00d7\na50 20-matrix. ComputingB (C D)requires2 10 20+10 50 20 =10,400\n\u00d7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nmultiplications,whereascomputing(B C) Drequires2 10 50+2 50 20=3000\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nmultiplications.\nThematrix chain-product problem is todetermine the parenthesization of the\nexpression defining the product A that minimizes the total number of scalar mul-\ntiplications performed. As the example above illustrates, the differences between\ndifferent solutions canbedramatic, sofindingagoodsolution canresultinsignifi-\ncantspeedups.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 558 \u2014 #580\ni i\n558 Chapter12. StringsandDynamicProgramming\nDefining Subproblems\nOf course, one way to solve the matrix chain-product problem is to simply enu-\nmerate all the possible ways of parenthesizing the expression for A and determine\nthenumber ofmultiplications performed byeachone. Unfortunately, thesetofall\ndifferent parenthesizations of the expression for A is equal in number to the set of\nalldifferent binary trees thathave nexternal nodes. Thisnumber isexponential in\nn. Thus,thisstraightforward(\u201cbruteforce\u201d)algorithmrunsinexponentialtime,for\nthere are an exponential number of ways to parenthesize an associative arithmetic\nexpression.\nWe can improve the performance achieved by the brute-force algorithm sig-\nnificantly, however, by making a few observations about the nature of the matrix\nchain-product problem. The first observation is that the problem can be split into\nsubproblems. Inthis case, wecandefine anumber ofdifferent subproblems, each\nofwhichcomputesthebestparenthesizationforsomesubexpressionA A A .\ni i+1 j\n\u00b7 \u00b7\u00b7\u00b7\nAs a concise notation, we use N to denote the minimum number of multipli-\ni,j\ncations needed to compute this subexpression. Thus, the original matrix chain-\nproduct problem can be characterized as that of computing the value of N .\n0,n\u22121\nThisobservation isimportant,butweneedonemoreinordertoapplythedynamic\nprogramming technique.\nCharacterizing Optimal Solutions\nTheotherimportantobservationwecanmakeaboutthematrixchain-productprob-\nlemisthatitispossibletocharacterize anoptimalsolutiontoaparticular subprob-\nlem in terms of optimal solutions to its subproblems. We call this property the\nsubproblem optimality condition.\nIn the case of the matrix chain-product problem, we observe that, no mat-\nter how we parenthesize a subexpression, there has to be some final matrix mul-\ntiplication that we perform. That is, a full parenthesization of a subexpression\nA A A has to be of the form (A A ) (A A ), for some k i,i+\ni i+1 j i k k+1 j\n\u00b7 \u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7 \u00b7 \u00b7\u00b7\u00b7 \u2208{\n1,...,j 1 . Moreover, forwhichever k isthecorrect one, theproducts (A A )\ni k\n\u2212 } \u00b7\u00b7\u00b7\nand(A A )mustalsobesolvedoptimally. Ifthiswerenotso,thentherewould\nk+1 j\n\u00b7\u00b7\u00b7\nbeaglobaloptimalthathadoneofthesesubproblemssolvedsuboptimally. Butthis\nisimpossible,sincewecouldthenreducethetotalnumberofmultiplicationsbyre-\nplacingthecurrentsubproblemsolutionbyanoptimalsolutionforthesubproblem.\nThisobservation implies awayofexplicitly defining theoptimization problem for\nN intermsofother optimal subproblem solutions. Namely, wecancompute N\ni,j i,j\nbyconsidering eachplacekwherewecouldputthefinalmultiplication andtaking\ntheminimumoverallsuchchoices.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 559 \u2014 #581\ni i\n12.2. DynamicProgramming 559\nDesigning a Dynamic Programming Algorithm\nWecanthereforecharacterize theoptimalsubproblem solution, N ,as\ni,j\nN = min N +N +dd d ,\ni,j i,k k+1,j i k+1 j+1\ni\u2264k<j{ }\nwhere N = 0, since no work is needed for a single matrix. That is, N is the\ni,i i,j\nminimum, taken over allpossible places toperform the final multiplication, ofthe\nnumber ofmultiplications needed tocompute eachsubexpression plusthenumber\nofmultiplications neededtoperform thefinalmatrixmultiplication.\nNotice that there is a sharing of subproblems going on that prevents us from\ndividingtheproblemintocompletelyindependent subproblems (aswewouldneed\nto do to apply the divide-and-conquer technique). We can, nevertheless, use the\nequation for N to derive an efficient algorithm by computing N values in a\ni,j i,j\nbottom-up fashion, and storing intermediate solutions inatable ofN values. We\ni,j\ncan begin simply enough by assigning N =0 for i=0,1,...,n 1. Wecan then\ni,i\n\u2212\napplythegeneralequationforN tocomputeN values,sincetheydependonly\ni,j i,i+1\non N and N values that are available. Given the N values, wecan then\ni,i i+1,i+1 i,i+1\ncompute the N values, and so on. Therefore, wecan build N values up from\ni,i+2 i,j\npreviouslycomputedvaluesuntilwecanfinallycomputethevalueofN ,which\n0,n\u22121\nisthenumberthatwearesearching for. Thedetailsofthisdynamicprogramming\nsolution aregiveninCodeFragment12.1.\nAlgorithmMatrixChain(d ,...,d ):\n0 n\nInput: Sequenced ,...,d ofintegers\n0 n\nOutput: For i,j = 0,...,n 1, the minimum number of multiplications N\ni,j\n\u2212\nneededtocomputetheproductA A A ,whereA isad d matrix\ni i+1 j k k k+1\n\u00b7 \u00b7\u00b7\u00b7 \u00d7\nfori 0ton 1do\n\u2190 \u2212\nN 0\ni,i\n\u2190\nforb 1ton 1do\n\u2190 \u2212\nfori 0ton b 1do\n\u2190 \u2212 \u2212\nj i+b\n\u2190\nN +\ni,j\n\u2190 \u221e\nfork ito j 1do\n\u2190 \u2212\nN min N ,N +N +dd d .\ni,j i,j i,k k+1,j i k+1 j+1\n\u2190 { }\nCode Fragment 12.1: Dynamic programming algorithm for the matrix chain-\nproductproblem.\nThus,wecancomputeN withanalgorithmthatconsistsprimarilyofthree\n0,n\u22121\nnested for-loops. The outside loop is executed n times. The loop inside is exe-\ncuted at most n times. And the inner-most loop is also executed at most n times.\nTherefore, thetotalrunning timeofthisalgorithm isO(n3).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 560 \u2014 #582\ni i\n560 Chapter12. StringsandDynamicProgramming\n12.2.2 DNA and Text Sequence Alignment\nA common text processing problem, which arises in genetics and software engi-\nneering, istotestthesimilarity betweentwotextstrings. Inagenetics application,\nthetwostrings couldcorrespond totwostrands ofDNA,thatwewanttocompare.\nLikewise, in a software engineering application, the two strings could come from\ntwoversions ofsource codeforthesameprogram. Wemightwanttocompare the\ntwo versions to determine what changes have been made from one version to the\nnext. Indeed,determiningthesimilaritybetweentwostringsissocommonthatthe\nUnix and Linux operating systems have a built-in program, diff, for comparing\ntextfiles.\nGiven a string X =x x x x , a subsequence of X is any string that is of\n0 1 2 n\u22121\n\u00b7\u00b7\u00b7\ntheform x x x , wherei <i ;that is, itisasequence ofcharacters thatare\ni1 i2\u00b7\u00b7\u00b7 ik j j+1\nnotnecessarilycontiguousbutareneverthelesstakeninorderfromX. Forexample,\nthestringAAAGisasubsequence ofthestringCGATAATTGAGA.\nThe DNA and text similarity problem we address here is the longest common\nsubsequence (LCS)problem. In this problem, weare given twocharacter strings,\nX =x x x x andY =y y y y ,oversomealphabet(suchasthealpha-\n0 1 2 n\u22121 0 1 2 m\u22121\n\u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7\nbet A,C,G,T commonincomputationalgenetics)andareaskedtofindalongest\n{ }\nstring S that is a subsequence of both X and Y. One way to solve the longest\ncommonsubsequence problem istoenumerate allsubsequences ofX andtake the\nlargest one that is also a subsequence ofY. Since each character of X is either in\nornotinasubsequence, there arepotentially 2n different subsequences ofX,each\nofwhichrequires O(m)timetodetermine whether itisasubsequence ofY. Thus,\nthisbrute-forceapproachyieldsanexponential-time algorithmthatrunsinO(2nm)\ntime,whichisveryinefficient. Fortunately,theLCSproblemisefficientlysolvable\nusingdynamicprogramming.\nThe Components of a Dynamic Programming Solution\nAs mentioned above, the dynamic programming technique is used primarily for\noptimization problems, wherewewishtofindthe\u201cbest\u201d wayofdoing something.\nWecanapplythedynamicprogrammingtechniqueinsuchsituationsiftheproblem\nhascertainproperties.\nSimpleSubproblems: Therehastobesomewayofrepeatedlybreakingtheglobal-\noptimization problem intosubproblems. Moreover, thereshouldbeasimple\nwayofdefiningsubproblems withjustafewindices, likei, j,k,andsoon.\nSubproblemOptimization: Anoptimal solution totheglobal problem mustbea\ncomposition ofoptimalsubproblem solutions.\nSubproblemOverlap: Optimal solutions to unrelated subproblems can contain\nsubproblems incommon.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 561 \u2014 #583\ni i\n12.2. DynamicProgramming 561\nApplying Dynamic Programming to the LCS Problem\nRecall that in the LCS problem, we are given two character strings, X and Y, of\nlength n and m, respectively, and are asked to find a longest string S that is a sub-\nsequence of both X andY. Since X andY are character strings, wehave a natural\nsetofindices withwhichtodefinesubproblems\u2014indices intothestrings X andY.\nLetusdefineasubproblem, therefore, asthatofcomputing thevalueL[i,j],which\nwe will use to denote the length of a longest string that is a subsequence of both\nX[0..i]=x x x ...x andY[0..j]=y y y ...y . Thisdefinitionallowsustorewrite\n0 1 2 i 0 1 2 j\nL[i,j]intermsofoptimalsubproblem solutions. Thisdefinition depends onwhich\noftwocaseswearein. (SeeFigure12.1.)\nFigure 12.1: The two cases in the longest common subsequence algorithm: (a)\nx =y ; (b) x =y . Note that the algorithm stores only the L[i,j] values, not the\ni j i j\n6\nmatches.\nx =y . In this case, we have a match between the last character of X[0..i]\ni j\n\u2022\nand the last character ofY[0..j]. We claim that this character belongs to a\nlongestcommonsubsequence ofX[0..i]andY[0..j]. Tojustifythisclaim,let\nussupposeitisnottrue. Therehastobesomelongestcommonsubsequence\nx x ...x =y y ...y . If x =x or y =y , then we get the same se-\ni1 i2 ik j1 j2 jk ik i jk j\nquence by setting i =i and j = j. Alternately, if x =x, then wecan get\nk k jk\n6\ni\nanevenlongercommonsubsequencebyaddingx totheend. Thus,alongest\ni\ncommonsubsequence ofX[0..i]andY[0..j]endswithx. Therefore, weset\ni\nL[i,j]=L[i 1,j 1]+1 ifx =y .\ni j\n\u2212 \u2212\nx =y . In this case, we cannot have a common subsequence that includes\ni j\n\u2022 6\nboth x and y . That is, we can have a common subsequence end with x or\ni j i\nonethatendswithy (orpossiblyneither), butcertainlynotboth. Therefore,\nj\nweset\nL[i,j]=max L[i 1,j],L[i,j 1] ifx =y .\ni j\n{ \u2212 \u2212 } 6\nIn order to make both of these equations make sense in the boundary cases when\ni=0or j=0,weassignL[i, 1]=0fori= 1,0,1,...,n 1andL[ 1,j]=0for\n\u2212 \u2212 \u2212 \u2212\nj= 1,0,1,...,m 1.\n\u2212 \u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 562 \u2014 #584\ni i\n562 Chapter12. StringsandDynamicProgramming\nThe LCS Algorithm\nThe definition of L[i,j] satisfies subproblem optimization, since we cannot have a\nlongest common subsequence without also having longest common subsequences\nforthesubproblems. Also,itusessubproblemoverlap,becauseasubproblemsolu-\ntion L[i,j]can beused inseveral other problems (namely, the problems L[i+1,j],\nL[i,j+1], and L[i+1,j+1]). Turning this definition of L[i,j] into an algorithm\nis actually quite straightforward. We initialize an (n+1) (m+1) array, L, for\n\u00d7\nthe boundary cases when i = 0 or j = 0. Namely, we initialize L[i, 1] = 0 for\n\u2212\ni= 1,0,1,...,n 1 and L[ 1,j]=0 for j= 1,0,1,...,m 1. Then, we iter-\n\u2212 \u2212 \u2212 \u2212 \u2212\natively build up values in L until we have L[n 1,m 1], the length of a longest\n\u2212 \u2212\ncommonsubsequence ofX andY. Wegiveapseudo-code description ofthisalgo-\nrithminCodeFragment12.2.\nAlgorithmLCS(X,Y):\nInput: StringsX andY withnandmelements, respectively\nOutput: For i = 0,...,n 1, j = 0,...,m 1, the length L[i,j] of a longest\n\u2212 \u2212\nstring that is a subsequence of both the string X[0..i]=x x x x and the\n0 1 2 i\n\u00b7\u00b7\u00b7\nstringY[0..j]=y y y y\n0 1 2 j\n\u00b7\u00b7\u00b7\nfori 1ton 1do\n\u2190\u2212 \u2212\nL[i, 1] 0\n\u2212 \u2190\nfor j 0tom 1do\n\u2190 \u2212\nL[ 1,j] 0\n\u2212 \u2190\nfori 0ton 1do\n\u2190 \u2212\nfor j 0tom 1do\n\u2190 \u2212\nifx =y then\ni j\nL[i,j] L[i 1,j 1]+1\n\u2190 \u2212 \u2212\nelse\nL[i,j] max L[i 1,j],L[i,j 1]\n\u2190 { \u2212 \u2212 }\nreturnarrayL\nCodeFragment12.2: Dynamicprogramming algorithm fortheLCSproblem.\nThe running time of the algorithm of Code Fragment 12.2 is easy to analyze,\nbecauseitisdominatedbytwonestedforloops,withtheouteroneiteratingntimes\nand the inner one iterating m times. Since the if-statement and assignment inside\nthe loop each requires O(1) primitive operations, this algorithm runs in O(nm)\ntime. Thus, the dynamic programming technique can be applied to the longest\ncommon subsequence problem to improve significantly over the exponential-time\nbrute-force solutiontotheLCSproblem.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 563 \u2014 #585\ni i\n12.2. DynamicProgramming 563\nAlgorithmLCS(CodeFragment12.2)computesthelengthofthelongestcom-\nmon subsequence (stored in L[n 1,m 1]), but not the subsequence itself. As\n\u2212 \u2212\nshown in the following proposition, a simple postprocessing step can extract the\nlongestcommonsubsequence fromthearrayLreturnedbythealgorithm.\nProposition 12.3: GivenastringXofncharactersandastringY ofmcharacters,\nwecanfindthelongestcommonsubsequenceofX andY inO(nm)time.\nJustification: Algorithm LCScomputes L[n 1,m 1], the length ofalongest\n\u2212 \u2212\ncommon subsequence, in O(nm) time. Given the table of L[i,j] values, construct-\ningalongestcommonsubsequence isstraightforward. Onemethodistostartfrom\nL[n,m] and work back through the table, reconstructing a longest common sub-\nsequence from back to front. At any position L[i,j], we can determine whether\nx = y . If this is true, then we can take x as the next character of the subse-\ni j i\nquence (noting that x is before the previous character we found, if any), moving\ni\nnext to L[i 1,j 1]. If x =y , then we can move to the larger of L[i,j 1] and\ni j\n\u2212 \u2212 6 \u2212\nL[i 1,j]. (SeeFigure12.2.) Westopwhenwereachaboundarycell(withi= 1\n\u2212 \u2212\nor j= 1). This method constructs a longest common subsequence in O(n+m)\n\u2212\nadditional time.\nFigure12.2: The algorithm for constructing a longest common subsequence from\nthearrayL.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 564 \u2014 #586\ni i\n564 Chapter12. StringsandDynamicProgramming\n12.3 Pattern Matching Algorithms\nIntheclassic pattern matchingproblem onstrings, wearegivenatextstring T of\nlengthnandapatternstringPoflengthm,andwanttofindwhetherPisasubstring\nof T. The notion of a \u201cmatch\u201d is that there is a substring of T starting at some\nindex i that matches P,character by character, so that T[i]=P[0], T[i+1]=P[1],\n..., T[i+m 1]=P[m 1]. That is, P=T[i..i+m 1]. Thus, the output from\n\u2212 \u2212 \u2212\na pattern matching algorithm could either be some indication that the pattern P\ndoes not exist in T or an integer indicating the starting index in T of a substring\nmatching P. Thisisexactly thecomputation performed bythefindfunction ofthe\nSTL string interface. Alternatively, one may want to find all the indices where a\nsubstring ofT matchingPbegins.\nIn this section, we present three pattern matching algorithms (with increasing\nlevelsofdifficulty).\n12.3.1 Brute Force\nThe brute-force algorithmic design pattern is a powerful technique for algorithm\ndesign when we have something we wish to search for or when we wish to opti-\nmize some function. Inapplying this technique ina general situation wetypically\nenumerateallpossibleconfigurations oftheinputsinvolvedandpickthebestofall\ntheseenumeratedconfigurations.\nIn applying this technique to design the brute-force pattern matching algo-\nrithm, we derive what is probably the first algorithm that we might think of for\nsolving the pattern matching problem\u2014we simply test allthe possible placements\nofPrelativetoT. Thisalgorithm, showninCodeFragment12.3,isquitesimple.\nAlgorithmBruteForceMatch(T,P):\nInput: StringsT (text)withncharacters andP(pattern) withmcharacters\nOutput: Starting index of the first substring of T matching P, or an indication\nthatPisnotasubstring ofT\nfori 0ton m foreachcandidate indexinT do\n\u2190 \u2212 { }\nj 0\n\u2190\nwhile(j<mandT[i+ j]=P[j])do\nj j+1\n\u2190\nif j=mthen\nreturni\nreturn\u201cThereisnosubstring ofT matchingP.\u201d\nCodeFragment12.3: Brute-forcepattern matching.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 565 \u2014 #587\ni i\n12.3. PatternMatchingAlgorithms 565\nPerformance\nThebrute-forcepatternmatchingalgorithmcouldnotbesimpler. Itconsistsoftwo\nnested loops, with the outer loop indexing through all possible starting indices of\nthe pattern in the text, and the inner loop indexing through each character of the\npattern, comparing it to its potentially corresponding character in the text. Thus,\nthe correctness ofthe brute-force pattern matching algorithm followsimmediately\nfromthisexhaustivesearchapproach.\nTherunningtimeofbrute-force patternmatchingintheworstcaseisnotgood,\nhowever,because,foreachcandidateindexinT,wecanperformuptomcharacter\ncomparisons todiscover thatPdoesnotmatchT atthecurrentindex. Referringto\nCode Fragment 12.3, we see that the outer for loop is executed at most n m+1\n\u2212\ntimes,andtheinnerloopisexecutedatmostmtimes. Thus,therunningtimeofthe\nbrute-force method is O((n m+1)m), which is simplified as O(nm). Note that\n\u2212\nwhenm=n/2,thisalgorithm hasquadratic running timeO(n2).\nExample 12.4: Supposewearegiventhetextstring\nT =\"abacaabaccabacabaabb\"\nandthepatternstring\nP=\"abacab\".\nInFigure12.3,weillustratetheexecutionofthebrute-forcepatternmatching\nalgorithmonT andP.\nFigure12.3: Examplerunofthebrute-force patternmatchingalgorithm. Thealgo-\nrithmperforms27character comparisons, indicated abovewithnumericallabels.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 566 \u2014 #588\ni i\n566 Chapter12. StringsandDynamicProgramming\n12.3.2 The Boyer-Moore Algorithm\nAt first, we might feel that it is always necessary to examine every character in T\nin order to locate a pattern P as a substring. But this is not always the case. The\nBoyer-Moore(BM)patternmatchingalgorithm,whichwestudyinthissection,can\nsometimes avoid comparisons between P and a sizable fraction of the characters\nin T. The only caveat is that, whereas the brute-force algorithm can work even\nwith a potentially unbounded alphabet, the BM algorithm assumes the alphabet is\nof fixed, finite size. It works the fastest when the alphabet is moderately sized\nand the pattern is relatively long. Thus, the BM algorithm is ideal for searching\nwordsindocuments. Inthissection,wedescribeasimplifiedversionoftheoriginal\nalgorithm byBoyerandMoore.\nThemainideaoftheBMalgorithmistoimprovetherunningtimeofthebrute-\nforce algorithm by adding two potentially time-saving heuristics. Roughly stated,\ntheseheuristics areasfollows:\nLooking-GlassHeuristic: WhentestingapossibleplacementofPagainstT,begin\nthecomparisons fromtheendofPandmovebackward tothefrontofP.\nCharacter-JumpHeuristic: DuringthetestingofapossibleplacementofPagainst\nT,amismatchoftextcharacterT[i]=cwiththecorresponding patternchar-\nacterP[j]ishandledasfollows. IfcisnotcontainedanywhereinP,thenshift\nP completely past T[i] (for it cannot match any character in P). Otherwise,\nshiftPuntilanoccurrence ofcharacter cinPgetsalignedwithT[i].\nWe formalize these heuristics shortly, but at an intuitive level, they work as an\nintegrated team. Thelooking-glass heuristic sets up theother heuristic toallow us\ntoavoidcomparisonsbetweenPandwholegroupsofcharactersinT. Inthiscaseat\nleast,wecangettothedestinationfasterbygoingbackwards,forifweencountera\nmismatchduringtheconsiderationofPatacertainlocationinT,thenwearelikely\ntoavoidlotsofneedlesscomparisons bysignificantly shiftingPrelativetoT using\nthecharacter-jump heuristic. Thecharacter-jump heuristic pays offbig ifitcanbe\nappliedearlyinthetestingofapotential placementofPagainstT.\nLet us therefore get down to the business of defining how the character-jump\nheuristicscanbeintegratedintoastringpatternmatchingalgorithm. Toimplement\nthisheuristic,wedefineafunctionlast(c)thattakesacharactercfromthealphabet\nand characterizes how far we may shift the pattern P if a character equal to c is\nfoundinthetextthatdoesnotmatchthepattern. Inparticular, wedefinelast(c)as:\nIf c is inP, last(c) is the index of the last (right-most) occurrence of c in P.\n\u2022\nOtherwise,weconventionally definelast(c)= 1.\n\u2212\nIf characters can be used as indices in arrays, then the last function can be easily\nimplemented as a lookup table. We leave the method for computing this table in\nO(m+ \u03a3 )time,givenP,asasimpleexercise(ExerciseR-12.8). Thislastfunction\n| |\ngivesusalltheinformation weneedtoperformthecharacter-jump heuristic.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 567 \u2014 #589\ni i\n12.3. PatternMatchingAlgorithms 567\nInCodeFragment12.4,weshowtheBMpatternmatchingalgorithm.\nAlgorithmBMMatch(T,P):\nInput: StringsT (text)withncharacters andP(pattern) withmcharacters\nOutput: Starting index of the first substring of T matching P, or an indication\nthatPisnotasubstring ofT\ncomputefunction last\ni m 1\n\u2190 \u2212\nj m 1\n\u2190 \u2212\nrepeat\nifP[j]=T[i]then\nif j=0then\nreturni amatch!\n{ }\nelse\ni i 1\n\u2190 \u2212\nj j 1\n\u2190 \u2212\nelse\ni i+m min(j,1+last(T[i])) jumpstep\n\u2190 \u2212 { }\nj m 1\n\u2190 \u2212\nuntili>n 1\n\u2212\nreturn\u201cThereisnosubstring ofT matchingP.\u201d\nCodeFragment12.4: TheBoyer-Moore patternmatchingalgorithm.\nThejumpstepisillustrated inFigure12.4.\n(a)\n(b)\nFigure12.4: The jump step in the algorithm of Code Fragment 12.4, where we let\nl =last(T[i]). We distinguish two cases: (a) 1+l j, where we shift the pattern\n\u2264\nby j l units;(b) j<1+l,whereweshiftthepatternbyoneunit.\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 568 \u2014 #590\ni i\n568 Chapter12. StringsandDynamicProgramming\nInFigure12.5,weillustratetheexecutionoftheBoyer-Moorepatternmatching\nalgorithm onaninputstringsimilartoExample12.4.\nThelast(c)function:\nc a b c d\nlast(c) 4 5 3 1\n\u2212\nFigure12.5: TheBMpatternmatchingalgorithm. Thealgorithmperforms13char-\nactercomparisons, whichareindicated withnumerical labels.\nThe correctness of the BM pattern matching algorithm follows from the fact\nthat each time the method makes a shift, it is guaranteed not to \u201cskip\u201d over any\npossible matches. Thisisbecause last(c)indicates thelastoccurrence ofcinP.\nTheworst-case running timeoftheBMalgorithm isO(nm+ \u03a3 ). Namely,the\ncomputationofthelastfunctiontakesO(m+ \u03a3 )timeandtheact | ua | lsearchforthe\n| |\npattern takes O(nm) timein the worst case, the same as the brute-force algorithm.\nAnexampleofatext-pattern pairthatachievestheworstcaseis\nn\nT = aaaaaa a\n\u00b7\u00b7\u00b7\nm\u22121\nP = zbaa }|a. {\n\u00b7\u00b7\u00b7\nThe worst-case performance, however, is unlikely to be achieved for English text\nz }| {\nbecause, in this case, the BMalgorithm isoften able to skip large portions oftext.\n(See Figure 12.6.) Experimental evidence on English text shows that the average\nnumberofcomparisonsdonepercharacteris0.24forafive-characterpatternstring.\nFigure12.6: AnexampleofaBoyer-Moore executiononEnglishtext.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 569 \u2014 #591\ni i\n12.3. PatternMatchingAlgorithms 569\nAC++implementationoftheBMpatternmatchingalgorithm,basedonanSTL\nvector, isshowninCodeFragment12.5.\n/** Simplified version of the Boyer-Moore algorithm. Returns the index of\n* the leftmost substring of the text matching the pattern, or -1 if none.\n*/\nint BMmatch(const string& text, const string& pattern)\n{\nstd::vector<int> last = buildLastFunction(pattern);\nint n = text.size();\nint m = pattern.size();\nint i = m 1;\n\u2212\nif (i > n 1) // pattern longer than text?\n\u2212\nreturn 1; // ...then no match\n\u2212\nint j = m 1;\n\u2212\ndo\n{\nif (pattern[j] == text[i])\nif (j == 0) return i; // found a match\nelse // looking-glass heuristic\n{\ni ; j ; // proceed right-to-left\n\u2212\u2212 \u2212\u2212\n}\nelse // character-jump heuristic\n{\ni = i + m std::min(j, 1 + last[text[i]]);\n\u2212\nj = m 1;\n\u2212\n}\nwhile (i <= n 1);\n} \u2212\nreturn 1; // no match\n\u2212\n}\n// construct function last\nstd::vector<int> buildLastFunction(const string& pattern)\n{\nconst int N ASCII = 128; // number of ASCII characters\nint i;\nstd::vector<int> last(N ASCII); // assume ASCII character set\nfor (i = 0; i < N ASCII; i++) // initialize array\nlast[i] = 1;\n\u2212\nfor (i = 0; i < pattern.size(); i++)\n{\nlast[pattern[i]] = i; // (implicit cast to ASCII code)\n}\nreturn last;\n}\nCode Fragment 12.5: C++ implementation of the Boyer-Moore (BM) pattern\nmatching algorithm. The algorithm is expressed by two static functions: Method\nBMmatch performs the matching and calls the auxiliary function buildLastFunc-\ntiontocomputethelastfunction,expressedbyanarrayindexedbytheASCIIcode\nof the character. Method BMmatch indicates the absence of a match by returning\ntheconventional value 1.\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 570 \u2014 #592\ni i\n570 Chapter12. StringsandDynamicProgramming\nWe have actually presented a simplified version of the Boyer-Moore (BM) al-\ngorithm. TheoriginalBMalgorithmachievesrunningtimeO(n+m+ \u03a3 )byusing\n| |\nan alternative shift heuristic to the partially matched text string, whenever it shifts\nthe pattern more than the character-jump heuristic. This alternative shift heuristic\nis based on applying the main idea from the Knuth-Morris-Pratt pattern matching\nalgorithm, whichwediscussnext.\n12.3.3 The Knuth-Morris-Pratt Algorithm\nInstudyingtheworst-caseperformanceofthebrute-forceandBMpatternmatching\nalgorithmsonspecificinstancesoftheproblem,suchasthatgiveninExample12.4,\nweshouldnoticeamajorinefficiency. Specifically,wemayperformmanycompar-\nisons while testing a potential placement of the pattern against the text, yet if we\ndiscoverapatterncharacter thatdoesnotmatchinthetext,thenwethrowawayall\ntheinformationgainedbythesecomparisonsandstartoveragainfromscratchwith\nthenextincrementalplacementofthepattern. TheKnuth-Morris-Pratt(or\u201cKMP\u201d)\nalgorithm discussed inthissection, avoids this wasteofinformation and, insodo-\ning, it achieves a running time of O(n+m), which is optimal in the worst case.\nThat is, in the worst case any pattern matching algorithm will have to examine all\nthecharacters ofthetextandallthecharacters ofthepatternatleastonce.\nThe Failure Function\nThe main idea of the KMP algorithm is to preprocess the pattern string P so as to\ncompute a failure function, f, that indicates the proper shift of P so that, to the\nlargest extent possible, we can reuse previously performed comparisons. Specif-\nically, the failure function f(j) is defined as the length of the longest prefix of P\nthat is a suffix of P[1..j] (note that we did not put P[0..j] here). We also use the\nconvention that f(0)=0. Later, we discuss how to compute the failure function\nefficiently. The importance of this failure function is that it \u201cencodes\u201d repeated\nsubstrings insidethepatternitself.\nExample 12.5: ConsiderthepatternstringP = \"abacab\" fromExample12.4.\nTheKnuth-Morris-Pratt(KMP)failurefunction, f(j),forthestringPisasshown\ninthefollowingtable:\nj 0 1 2 3 4 5\nP[j] a b a c a b\nf(j) 0 0 1 0 1 2\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 571 \u2014 #593\ni i\n12.3. PatternMatchingAlgorithms 571\nThe KMP pattern matching algorithm, shown in Code Fragment 12.6, incre-\nmentallyprocesses thetextstringT comparingittothepatternstringP. Eachtime\nthere isamatch, weincrement the current indices. Onthe other hand, if there is a\nmismatch and wehave previously made progress in P, then we consult the failure\nfunction to determine the new index in P where we need to continue checking P\nagainst T. Otherwise(there wasamismatchandweareatthebeginning ofP),we\nsimply increment the index for T (and keep the index variable for P at its begin-\nning). We repeat this process until we find a match of P in T or the index for T\nreachesn,thelengthofT (indicating thatwedidnotfindthepatternPinT).\nAlgorithmKMPMatch(T,P):\nInput: StringsT (text)withncharacters andP(pattern) withmcharacters\nOutput: Starting index of the first substring of T matching P, or an indication\nthatPisnotasubstring ofT\nf KMPFailureFunction(P) construct thefailurefunction f forP\n\u2190 { }\ni 0\n\u2190\nj 0\n\u2190\nwhilei<ndo\nifP[j]=T[i]then\nif j=m 1then\n\u2212\nreturni m+1 amatch!\n\u2212 { }\ni i+1\n\u2190\nj j+1\n\u2190\nelseif j>0 nomatch,butwehaveadvanced inP then\n{ }\nj f(j 1) jindexesjustafterprefixofPthatmustmatch\n\u2190 \u2212 { }\nelse\ni i+1\n\u2190\nreturn\u201cThereisnosubstring ofT matchingP.\u201d\nCodeFragment12.6: TheKMPpattern matchingalgorithm.\nThemainpartoftheKMPalgorithm isthewhileloop,whichperformsacom-\nparison between a character in T and a character in P each iteration. Depending\nupon the outcome of this comparison, the algorithm either moves on to the next\ncharactersinT andP,consultsthefailurefunctionforanewcandidatecharacterin\nP,orstartsoverwiththenextindexinT. Thecorrectnessofthisalgorithm follows\nfromthedefinitionofthefailurefunction. Anycomparisonsthatareskippedareac-\ntually unnecessary, forthe failure function guarantees that allthe ignored compar-\nisonsareredundant\u2014they wouldinvolve comparingthesamematching characters\noveragain.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 572 \u2014 #594\ni i\n572 Chapter12. StringsandDynamicProgramming\nFigure12.7: TheKMPpattern matching algorithm. The failure function f for this\npattern is given in Example 12.5. The algorithm performs 19 character compar-\nisons,whichareindicated withnumerical labels.\nIn Figure 12.7, we illustrate the execution of the KMP pattern matching algo-\nrithm on the same input strings as in Example 12.4. Note the use of the failure\nfunction to avoid redoing one of the comparisons between a character of the pat-\nternandacharacterofthetext. Alsonotethatthealgorithmperformsfeweroverall\ncomparisons thanthebrute-force algorithm runonthesamestrings(Figure12.3).\nPerformance\nExcluding the computation of the failure function, the running time of the KMP\nalgorithm isclearly proportional tothenumberofiterations ofthewhileloop. For\nthesakeofanalysis,letusdefinek=i j. Intuitively,kisthetotalamountbywhich\n\u2212\nthe pattern P has been shifted with respect to the text T. Note that throughout the\nexecutionofthealgorithm, wehavek n. Oneofthefollowingthreecasesoccurs\n\u2264\nateachiterationoftheloop.\nIf T[i] = P[j], then i increases by 1, and k does not change, since j also\n\u2022\nincreases by1.\nIfT[i]=P[j]and j>0,thenidoesnotchange andkincreases byatleast1,\n\u2022 6\nsince, inthiscase, k changes from i j toi f(j 1), which isanaddition\n\u2212 \u2212 \u2212\nof j f(j 1),whichispositivebecause f(j 1)< j.\n\u2212 \u2212 \u2212\nIf T[i]=P[j] and j=0, then i increases by 1 and k increases by 1, since j\n\u2022 6\ndoesnotchange.\nThus, at each iteration of the loop, either i or k increases by at least 1 (possibly\nboth); hence, the total number of iterations of the while loop in the KMP pattern\nmatchingalgorithmisatmost2n. Ofcourse,achievingthisboundassumesthatwe\nhavealreadycomputed thefailurefunctionforP.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 573 \u2014 #595\ni i\n12.3. PatternMatchingAlgorithms 573\nConstructing the KMP Failure Function\nToconstructthefailurefunction,weusethemethodshowninCodeFragment12.7,\nwhichisa\u201cbootstrapping\u201d process quitesimilar totheKMPMatchalgorithm. We\ncompare the pattern to itself as in the KMP algorithm. Each time we have two\ncharactersthatmatch,weset f(i)= j+1. Notethatsincewehavei> jthroughout\ntheexecutionofthealgorithm, f(j 1)isalwaysdefinedwhenweneedtouseit.\n\u2212\nAlgorithmKMPFailureFunction(P):\nInput: StringP(pattern) withmcharacters\nOutput: Thefailurefunction f forP,whichmaps jtothelengthofthelongest\nprefixofPthatisasuffixofP[1..j]\ni 1\n\u2190\nj 0\n\u2190\nf(0) 0\n\u2190\nwhilei<mdo\nifP[j]=P[i]then\nwehavematched j+1characters\n{ }\nf(i) j+1\n\u2190\ni i+1\n\u2190\nj j+1\n\u2190\nelseif j>0then\njindexesjustafteraprefixofPthatmustmatch\n{ }\nj f(j 1)\n\u2190 \u2212\nelse\nwehavenomatchhere\n{ }\nf(i) 0\n\u2190\ni i+1\n\u2190\nCodeFragment12.7: Computation ofthefailure function used intheKMPpattern\nmatchingalgorithm. Notehowthealgorithmusesthepreviousvaluesofthefailure\nfunction toefficientlycomputenewvalues.\nAlgorithm KMPFailureFunction runs in O(m) time. Its analysis is analogous\ntothatofalgorithm KMPMatch. Thus,wehave:\nProposition 12.6: TheKnuth-Morris-Prattalgorithmperformspatternmatching\nonatextstringoflengthnandapatternstringoflengthminO(n+m)time.\nA C++ implementation of the KMP pattern matching algorithm, based on an\nSTLvector, isshowninCodeFragment12.8.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 574 \u2014 #596\ni i\n574 Chapter12. StringsandDynamicProgramming\n// KMP algorithm\nint KMPmatch(const string& text, const string& pattern)\n{\nint n = text.size();\nint m = pattern.size();\nstd::vector<int> fail = computeFailFunction(pattern);\nint i = 0; // text index\nint j = 0; // pattern index\nwhile (i < n)\n{\nif (pattern[j] == text[i])\n{\nif (j == m 1)\n\u2212\nreturn i m + 1; // found a match\n\u2212\ni++; j++;\n}\nelse if (j > 0) j = fail[j 1];\n\u2212\nelse i++;\n}\nreturn 1; // no match\n\u2212\n}\nstd::vector<int> computeFailFunction(const string& pattern)\n{\nstd::vector<int> fail(pattern.size());\nfail[0] = 0;\nint m = pattern.size();\nint j = 0;\nint i = 1;\nwhile (i < m)\n{\nif (pattern[j] == pattern[i]) // j + 1 characters match\n{\nfail[i] = j + 1;\ni++; j++;\n}\nelse if (j > 0) // j follows a matching prefix\nj = fail[j 1];\n\u2212\nelse // no match\n{\nfail[i] = 0;\ni++;\n}\n}\nreturn fail;\n}\nCodeFragment12.8: C++implementationoftheKMPpatternmatchingalgorithm.\nThealgorithmisexpressedbytwostaticfunctions. FunctionKMPmatchperforms\nthematchingandcallstheauxiliary functioncomputeFailFunctiontocomputethe\nfailure function, expressed by an array. Method KMPmatchindicates the absence\nofamatchbyreturning theconventional value 1.\n\u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 575 \u2014 #597\ni i\n12.4. TextCompressionandtheGreedyMethod 575\n12.4 Text Compression and the Greedy Method\nIn this section, we consider an important text processing task, text compression.\nIn this problem, we are given a string X defined over some alphabet, such as the\nASCIIorUnicode character sets, andwewanttoefficiently encode X into asmall\nbinary stringY (using only the characters 0 and 1). Text compression is useful in\nanysituation wherewearecommunicating overalow-bandwidth channel, suchas\namodem line orinfrared connection, and wewishtominimize thetimeneeded to\ntransmit our text. Likewise, text compression is also useful for storing collections\nof large documents more efficiently, in order to allow for a fixed-capacity storage\ndevicetocontain asmanydocuments aspossible.\nThemethodfortextcompressionexploredinthissectionistheHuffmancode.\nStandard encoding schemes, such as the ASCII and Unicode systems, use fixed-\nlength binary strings to encode characters (with 7 bits in the ASCII system and\n16 in the Unicode system). A Huffman code, on the other hand, uses a variable-\nlength encoding optimized for the string X. The optimization is based on the use\nof character frequencies, where wehave, for each character c, a count f(c) of the\nnumber of times c appears in the string X. The Huffman code saves space over a\nfixed-length encoding by using short code-word strings to encode high-frequency\ncharacters andlongcode-wordstringstoencodelow-frequency characters.\nTo encode the string X, we convert each character in X from its fixed-length\ncode word to its variable-length code word, and we concatenate all these code\nwords in order to produce the encoding Y for X. In order to avoid ambiguities,\nweinsistthatnocodewordinourencoding isaprefixofanothercodewordinour\nencoding. Such a code is called a prefix code, and it simplifies the decoding ofY\nin order to get back X. (See Figure 12.8.) Even with this restriction, the savings\nproduced byavariable-length prefixcodecanbesignificant, particularly ifthereis\nawidevariance incharacter frequencies (asisthecasefornatural language textin\nalmosteveryspoken language).\nHuffman\u2019s algorithm for producing an optimal variable-length prefix code for\nX is based on the construction of a binary tree T that represents the code. Each\nnode in T, except the root, represents a bit in a code word, with each left child\nrepresenting a\u201c0\u201d and eachright child representing a\u201c1.\u201d Eachexternal node vis\nassociated withaspecificcharacter, andthecodewordforthatcharacterisdefined\nbythesequenceofbitsassociatedwiththenodesinthepathfromtherootofT tov.\n(SeeFigure12.8.) Eachexternalnodevhasafrequency, f(v),whichissimplythe\nfrequencyinX ofthecharacterassociatedwithv. Inaddition,wegiveeachinternal\nnode vinT afrequency, f(v), that isthesumofthefrequencies ofallthe external\nnodesinthesubtreerootedatv.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 576 \u2014 #598\ni i\n576 Chapter12. StringsandDynamicProgramming\n(a)\n(b)\nFigure 12.8: An example Huffman code for the input string\nX = \"a fast runner need never be afraid of the dark\": (a) fre-\nquency of each character of X; (b) Huffman tree T for string X. The code for a\ncharacter c is obtained by tracing the path from the root of T to the external node\nwhere c is stored, and associating a left child with 0 and a right child with 1. For\nexample,thecodefor\u201ca\u201dis010,andthecodefor\u201cf\u201dis1100.\n12.4.1 The Huffman-Coding Algorithm\nTheHuffman-coding algorithm beginswitheachofthed distinct characters ofthe\nstring X toencode beingtherootnode ofasingle-node binary tree. Thealgorithm\nproceeds in a series of rounds. In each round, the algorithm takes the two binary\ntrees with the smallest frequencies and merges them into a single binary tree. It\nrepeatsthisprocess untilonlyonetreeisleft. (SeeCodeFragment12.9.)\nEach iteration of the while loop in Huffman\u2019s algorithm can be implemented\nin O(logd) time using a priority queue represented with a heap. In addition, each\niteration takes twonodes outofQandaddsonein,aprocess thatisrepeated d 1\n\u2212\ntimes before exactly one node is left in Q. Thus, this algorithm runs in O(n+\ndlogd)time. Althoughafulljustificationofthisalgorithm\u2019scorrectness isbeyond\nour scope, we note that its intuition comes from a simple idea\u2014any optimal code\ncanbeconverted intoanoptimalcodeinwhichthecodewordsforthetwolowest-\nfrequency characters, aand b, differ only in their last bit. Repeating the argument\nforastringwithaandbreplaced byacharacter c,givesthefollowing.\nProposition 12.7: Huffman\u2019salgorithmconstructsanoptimalprefixcodefora\nstringoflengthnwithddistinctcharactersinO(n+dlogd)time.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 577 \u2014 #599\ni i\n12.4. TextCompressionandtheGreedyMethod 577\nAlgorithmHuffman(X):\nInput: StringX oflengthnwithd distinctcharacters\nOutput: CodingtreeforX\nComputethefrequency f(c)ofeachcharacter cofX.\nInitializeapriorityqueueQ.\nforeachcharactercinX do\nCreateasingle-node binarytreeT storing c.\nInsertT intoQwithkey f(c).\nwhileQ.size()>1do\nf Q.min()\n1\n\u2190\nT Q.removeMin()\n1\n\u2190\nf Q.min()\n2\n\u2190\nT Q.removeMin()\n2\n\u2190\nCreateanewbinarytreeT withleftsubtreeT andrightsubtreeT .\n1 2\nInsertT intoQwithkey f + f .\n1 2\nreturntreeQ.removeMin()\nCodeFragment12.9: Huffman-coding algorithm.\n12.4.2 The Greedy Method\nHuffman\u2019s algorithm for building an optimal encoding is an example application\nof an algorithmic design pattern called the greedy method. This design pattern is\napplied tooptimization problems, whereweare trying to construct some structure\nwhileminimizingormaximizingsomeproperty ofthatstructure.\nThe general formula for the greedy method pattern is almost as simple as that\nfor the brute-force method. In order to solve a given optimization problem using\nthe greedy method, we proceed by a sequence of choices. The sequence starts\nfrom some well-understood starting condition, and computes the cost for that ini-\ntial condition. The pattern then asks that we iteratively make additional choices\nby identifying the decision that achieves the best cost improvement from all of\nthe choices that are currently possible. This approach does not always lead to an\noptimalsolution.\nButthereareseveralproblemsthatitdoesworkfor,andsuchproblemsaresaid\nto possess the greedy-choice property. This is the property that a global optimal\ncondition can be reached by a series of locally optimal choices (that is, choices\nthat are each the current best from among the possibilities available at the time),\nstartingfromawell-definedstartingcondition. Theproblemofcomputinganopti-\nmalvariable-length prefixcodeisjustoneexampleofaproblemthatpossesses the\ngreedy-choice property.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 578 \u2014 #600\ni i\n578 Chapter12. StringsandDynamicProgramming\n12.5 Tries\nThe pattern matching algorithms presented in the previous section speed up the\nsearch in a text by preprocessing the pattern (to compute the failure function in\nthe KMP algorithm or the last function in the BM algorithm). In this section, we\ntake a complementary approach, namely, we present string searching algorithms\nthatpreprocessthetext. Thisapproachissuitableforapplicationswhereaseriesof\nqueriesisperformedonafixedtext,sothattheinitialcostofpreprocessing thetext\nis compensated by a speedup in each subsequent query (for example, a Web site\nthatofferspattern matchinginShakespeare\u2019s Hamletorasearchenginethatoffers\nWebpagesontheHamlettopic).\nA trie (pronounced \u201ctry\u201d) is a tree-based data structure for storing strings in\norder to support fast pattern matching. The main application for tries is in infor-\nmation retrieval. Indeed, the name \u201ctrie\u201d comes from the word \u201cretrieval.\u201d In an\ninformation retrieval application, suchasasearchforacertainDNAsequence ina\ngenomicdatabase,wearegivenacollectionSofstrings,alldefinedusingthesame\nalphabet. Theprimaryqueryoperations thattriessupport arepattern matchingand\nprefixmatching. Thelatter operation involves being givenastring X,andlooking\nforallthestringsinSthatcontainX asaprefix.\n12.5.1 Standard Tries\nLet S be a set of s strings from alphabet \u03a3 such that no string in S is a prefix\nof another string. A standard trie for S is an ordered tree T with the following\nproperties (seeFigure12.9):\nEachnodeofT,excepttheroot,islabeledwithacharacterof\u03a3.\n\u2022\nThe ordering of the children of an internal node of T is determined by a\n\u2022 canonical ordering ofthealphabet \u03a3.\nT hassexternal nodes, eachassociated withastring ofS,suchthat thecon-\n\u2022\ncatenation ofthelabels ofthenodes onthepath fromtheroot toanexternal\nnodevofT yieldsthestringofSassociated withv.\nThus,atrieT representsthestringsofSwithpathsfromtheroottotheexternal\nnodes of T. Note the importance of assuming that no string in S is a prefix of\nanother string. This ensures that each string of S is uniquely associated with an\nexternal node of T. We can always satisfy this assumption by adding a special\ncharacter thatisnotintheoriginal alphabet \u03a3attheendofeachstring.\nAninternal nodeinastandard trieT canhaveanywherebetween1andd chil-\ndren, whered isthesizeofthealphabet. Thereisanedgegoing fromtherootr to\noneofitschildren foreach character that isfirstinsomestring inthecollection S.\nInaddition,apathfromtherootofT toaninternalnodevatdepthicorrespondsto\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 579 \u2014 #601\ni i\n12.5. Tries 579\nFigure12.9:Standardtrieforthestrings bear,bell,bid,bull,buy,sell,stock,stop .\n{ }\nani-character prefixX[0..i 1]ofastring X ofS. Infact, foreach character cthat\n\u2212\ncanfollowtheprefixX[0..i 1]inastring ofthesetS,thereisachildofvlabeled\n\u2212\nwithcharacter c. Inthisway,atrieconcisely storesthecommonprefixesthatexist\namongasetofstrings.\nIf there are only two characters in the alphabet, then the trie is essentially a\nbinarytree,withsomeinternalnodespossiblyhavingonlyonechild(thatis,itmay\nbe an improper binary tree). In general, if there are d characters in the alphabet,\nthen the trie will be a multi-way tree where each internal node has between 1 and\nd children. In addition, there are likely to be several internal nodes in a standard\ntrie that have fewer than d children. For example, the trie shown in Figure 12.9\nhasseveralinternalnodeswithonlyonechild. Wecanimplementatriewithatree\nstoringcharacters atitsnodes.\nThe following proposition provides some important structural properties of a\nstandard trie.\nProposition 12.8: AstandardtriestoringacollectionSofsstringsoftotallength\nnfromanalphabetofsizedhasthefollowingproperties:\nEveryinternalnodeofT hasatmostdchildren\n\u2022\nT hassexternalnodes\n\u2022\nTheheightofT isequaltothelengthofthelongeststringinS\n\u2022\nThenumberofnodesofT isO(n)\n\u2022\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 580 \u2014 #602\ni i\n580 Chapter12. StringsandDynamicProgramming\nThe worst case for the number of nodes of a trie occurs when no two strings\nshare a common nonempty prefix; that is, except for the root, all internal nodes\nhaveonechild.\nAtrieT forasetSofstringscanbeusedtoimplementadictionarywhosekeys\nare the strings of S. Namely, we perform a search in T for a string X by tracing\ndown from the root the path indicated by the characters in X. If this path can be\ntracedandterminatesatanexternalnode, thenweknowX isinthedictionary. For\nexample,inthetrieinFigure12.9,tracingthepathfor\u201cbull\u201dendsupatanexternal\nnode. If the path cannot be traced or the path can be traced but terminates at an\ninternalnode,thenX isnotinthedictionary. IntheexampleinFigure12.9,thepath\nfor \u201cbet\u201d cannot be traced and the path for \u201cbe\u201d ends at an internal node. Neither\nsuch word is in the dictionary. Note that in this implementation of a dictionary,\nsingle characters are compared instead of the entire string (key). It is easy to see\nthat the running time of the search for a string of size m is O(dm), where d is the\nsizeofthealphabet. Indeed, wevisitatmostm+1nodesofT andwespendO(d)\ntime at each node. Forsome alphabets, wemay be able to improve the time spent\nat a node to be O(1) or O(logd) by using a dictionary of characters implemented\ninahashtableorsearchtable. However,sinced isaconstant inmostapplications,\nwecanstickwiththesimpleapproach thattakesO(d)timepernodevisited.\nFrom the discussion above, it follows that we can use a trie to perform a spe-\ncial type of pattern matching, called word matching, where wewant to determine\nwhether a given pattern matches one of the words of the text exactly. (See Fig-\nure12.10.) Wordmatchingdiffersfromstandardpatternmatchingsincethepattern\ncannot match an arbitrary substring ofthe text, but only one of its words. Using a\ntrie,wordmatchingforapatternoflengthmtakesO(dm)time,whered isthesize\nofthealphabet,independentofthesizeofthetext. Ifthealphabethasconstantsize\n(as is the case for text in natural languages and DNAstrings), aquery takes O(m)\ntime, proportional to the size of the pattern. A simple extension of this scheme\nsupports prefix matching queries. However, arbitrary occurrences ofthepattern in\nthe text (for example, the pattern is a proper suffix of a word or spans two words)\ncannotbeefficientlyperformed.\nTo construct a standard trie for a set S of strings, we can use an incremental\nalgorithmthatinsertsthestringsoneatatime. Recalltheassumptionthatnostring\nof S is a prefix of another string. To insert a string X into the current trie T, we\nfirsttrytotracethepathassociatedwithX inT. SinceX isnotalreadyinT andno\nstringinSisaprefixofanotherstring,westoptracingthepathataninternalnodev\nofT beforereachingtheendofX. Wethencreateanewchainofnodedescendents\nof v to store the remaining characters of X. The time to insert X is O(dm), where\nmisthelength ofX andd isthesizeofthealphabet. Thus, constructing theentire\ntrieforsetStakesO(dn)time,wherenisthetotallengthofthestrings ofS.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 581 \u2014 #603\ni i\n12.5. Tries 581\n(a)\n(b)\nFigure12.10: Word matching and prefix matching with a standard trie: (a) text to\nbe searched; (b) standard trie for the words in the text (articles and prepositions,\nwhich are also known as stop words, excluded), with external nodes augmented\nwithindications ofthewordpositions.\nThereisapotentialspaceinefficiencyinthestandardtriethathaspromptedthe\ndevelopment of the compressed trie, which is also known (for historical reasons)\nasthePatriciatrie. Namely,therearepotentially alotofnodesinthestandard trie\nthathaveonlyonechild,andtheexistenceofsuchnodesisawaste. Wediscussthe\ncompressed trienext.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 582 \u2014 #604\ni i\n582 Chapter12. StringsandDynamicProgramming\n12.5.2 Compressed Tries\nAcompressedtrieissimilartoastandardtriebutitensuresthateachinternalnode\nin the trie has at least two children. It enforces this rule by compressing chains of\nsingle-child nodes into individual edges. (See Figure 12.11.) Let T be a standard\ntrie. Wesaythat aninternal node vof T isredundant ifvhas one child and isnot\nthe root. For example, the trie of Figure 12.9 has eight redundant nodes. Let us\nalsosaythatachainofk 2edges\n\u2265\n(v ,v )(v ,v ) (v ,v ),\n0 1 1 2 k\u22121 k\n\u00b7\u00b7\u00b7\nisredundantif:\nv isredundant fori=1,...,k 1\ni\n\u2022 \u2212\nv andv arenotredundant\n0 k\n\u2022\nWe can transform T into a compressed trie by replacing each redundant chain\n(v ,v ) (v ,v ) of k 2 edges into a single edge (v ,v ), relabeling v with\n0 1 k\u22121 k 0 k k\n\u00b7\u00b7\u00b7 \u2265\ntheconcatenation ofthelabelsofnodesv ,...,v .\n1 k\nFigure12.11: Compressed trie forthe strings bear, bell, bid, bull, buy, sell, stock,\n{\nstop . Comparethiswiththestandard trieshowninFigure12.9.\n}\nThus,nodesinacompressed triearelabeledwithstrings, whicharesubstrings\nofstringsinthecollection,ratherthanwithindividualcharacters. Theadvantageof\nacompressedtrieoverastandardtrieisthatthenumberofnodesofthecompressed\ntrie is proportional to the number of strings and not to their total length, as shown\ninthefollowingproposition (comparewithProposition 12.8).\nProposition 12.9: AcompressedtriestoringacollectionS ofsstringsfroman\nalphabetofsizedhasthefollowingproperties:\nEveryinternalnodeofT hasatleasttwochildrenandmostdchildren\n\u2022\nT hassexternalnodes\n\u2022\nThenumberofnodesofT isO(s)\n\u2022\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 583 \u2014 #605\ni i\n12.5. Tries 583\nThe attentive reader may wonder whether the compression of paths provides\nany significant advantage, since it is offset by a corresponding expansion of the\nnodelabels. Indeed,acompressedtrieistrulyadvantageousonlywhenitisusedas\nanauxiliaryindexstructure overacollection ofstringsalreadystoredinaprimary\nstructure, andisnotrequiredtoactuallystoreallthecharacters ofthestringsinthe\ncollection.\nSuppose,forexample,thatthecollection SofstringsisanarrayofstringsS[0],\nS[1], ..., S[s 1]. Instead of storing the label X of a node explicitly, we represent\n\u2212\nitimplicitly byatripletofintegers (i,j,k),suchthatX =S[i][j..k]; thatis,X isthe\nsubstring ofS[i] consisting ofthe characters from the jth tothe kthincluded. (See\ntheexampleinFigure12.12. AlsocomparewiththestandardtrieofFigure12.10.)\n(a)\n(b)\nFigure12.12: (a) Collection S of strings stored in an array. (b) Compact represen-\ntationofthecompressed trieforS.\nThisadditional compression schemeallowsustoreduce thetotalspace forthe\ntrie itself from O(n) for the standard trie to O(s) for the compressed trie, where n\nis the total length of the strings in S and s is the number of strings in S. We must\nstillstorethedifferent strings inS,ofcourse, butwenevertheless reduce thespace\nforthetrie.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 584 \u2014 #606\ni i\n584 Chapter12. StringsandDynamicProgramming\n12.5.3 Suffix Tries\nOne of the primary applications for tries is for the case when the strings in the\ncollectionSareallthesuffixesofastringX. Suchatrieiscalledthesuffixtrie(also\nknown as a suffix tree or position tree) of string X. Forexample, Figure 12.13(a)\nshowsthesuffixtriefortheeightsuffixesofstring\u201cminimize.\u201d Forasuffixtrie,the\ncompactrepresentation presented intheprevious sectioncanbefurther simplified.\nNamely, the label of each vertex is a pair (i,j) indicating the string X[i..j]. (See\nFigure12.13(b).) TosatisfytherulethatnosuffixofX isaprefixofanothersuffix,\nwecanaddaspecialcharacter,denotedwith$,thatisnotintheoriginalalphabet\u03a3\nattheendofX (andthustoeverysuffix). Thatis,ifstringX haslengthn,webuild\natrieforthesetofnstringsX[i..n 1]$,fori=0,...,n 1.\n\u2212 \u2212\nSaving Space\nUsingasuffixtrieallowsustosavespaceoverastandardtriebyusingseveralspace\ncompression techniques, including thoseusedforthecompressed trie.\nTheadvantageofthecompactrepresentationoftriesnowbecomesapparentfor\nsuffixtries. SincethetotallengthofthesuffixesofastringX oflengthnis\nn(n+1)\n1+2+ +n= ,\n\u00b7\u00b7\u00b7 2\nstoring all the suffixes of X explicitly would take O(n2) space. Even so, the suf-\nfix trie represents these strings implicitly in O(n) space, as formally stated in the\nfollowingproposition.\nProposition 12.10: ThecompactrepresentationofasuffixtrieT forastringX\noflengthnusesO(n)space.\nConstruction\nWe can construct the suffix trie for a string of length n with an incremental algo-\nrithm like the one given in Section 12.5.1. This construction takes O(dn2) time\nbecause the total length of the suffixes is quadratic in n. However, the (compact)\nsuffixtrieforastringoflengthncanbeconstructedinO(n)timewithaspecialized\nalgorithm, different from the one for general tries. This linear-time construction\nalgorithm is fairly complex, however, and is not reported here. Still, we can take\nadvantage oftheexistence ofthisfastconstruction algorithm whenwewanttouse\nasuffixtrietosolveotherproblems.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 585 \u2014 #607\ni i\n12.5. Tries 585\n(a)\n(b)\nFigure 12.13: (a) Suffix trie T for the string X = \u2018\u2018minimize\u2019\u2019. (b) Compact\nrepresentation ofT,wherepair(i,j)denotesX[i..j].\nUsing a Suffix Trie\nThesuffixtrieT forastring X canbeusedtoefficiently perform pattern matching\nqueries on text X. Namely, we can determine whether a pattern P is a substring\nof X by trying to trace a path associated with P in T. P is a substring of X if and\nonlyifsuchapathcanbetraced. ThesearchdownthetrieT assumesthatnodesin\nT storesomeadditional information, withrespecttothecompactrepresentation of\nthesuffixtrie:\nIfnodevhaslabel(i,j)andY isthestringoflengthyassociated with\nthepathfromtheroottov(included), thenX[j y+1..j]=Y.\n\u2212\nThis property ensures that we can easily compute the start index of the pattern in\nthetextwhenamatchoccurs.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 586 \u2014 #608\ni i\n586 Chapter12. StringsandDynamicProgramming\n12.5.4 Search Engines\nThe World Wide Web contains a huge collection of text documents (Web pages).\nInformation about these pages are gathered by a program called a Web crawler,\nwhich then stores thisinformation in aspecial dictionary database. A Websearch\nengine allows users to retrieve relevant information from this database, thereby\nidentifying relevant pages on the Web containing given keywords. In this section,\nwepresentasimplifiedmodelofasearchengine.\nInverted Files\nThe core information stored by a search engine is a dictionary, called an inverted\nindex or inverted file, storing key-value pairs (w,L), where w is a word and L is\na collection of pages containing word w. The keys (words) in this dictionary are\ncalled index terms and should be a set of vocabulary entries and proper nouns as\nlarge as possible. The elements in this dictionary are called occurrence lists and\nshouldcoverasmanyWebpagesaspossible.\nWecanefficientlyimplementaninvertedindexwithadatastructureconsisting\nof:\n1. Anarraystoringtheoccurrence listsoftheterms(innoparticular order)\n2. Acompressedtrieforthesetofindexterms,whereeachexternalnodestores\ntheindexoftheoccurrence listoftheassociated term.\nThereasonforstoring theoccurrence listsoutside thetrieistokeepthesizeofthe\ntrie data structure sufficiently small to fit in internal memory. Instead, because of\ntheirlargetotalsize,theoccurrence listshavetobestoredondisk.\nWithourdatastructure,aqueryforasinglekeywordissimilartoawordmatch-\ning query (Section 12.5.1). Namely, wefind the keyword in the trie and wereturn\ntheassociated occurrence list.\nWhen multiple keywords are given and the desired output are the pages con-\ntaining all the given keywords, we retrieve the occurrence list of each keyword\nusing the trie and return their intersection. To facilitate the intersection computa-\ntion,eachoccurrencelistshouldbeimplementedwithasequencesortedbyaddress\norwithadictionary (see,forexample,thegenericmergecomputation discussed in\nSection11.4).\nIn addition to the basic task of returning a list of pages containing given key-\nwords,searchenginesprovideanimportantadditionalservicebyrankingthepages\nreturned by relevance. Devising fast and accurate ranking algorithms for search\nengines is a major challenge for computer researchers and electronic commerce\ncompanies.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 587 \u2014 #609\ni i\n12.6. Exercises 587\n12.6 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-12.1 Whatisthebestwaytomultiplyachainofmatriceswithdimensions that\nare10 5,5 2,2 20,20 12,12 4,and4 60? Showyourwork.\n\u00d7 \u00d7 \u00d7 \u00d7 \u00d7 \u00d7\nR-12.2 Designanefficientalgorithm forthematrixchainmultiplication problem\nthat outputs afully parenthesized expression for how to multiply the ma-\ntricesinthechainusingtheminimumnumberofoperations.\nR-12.3 ListtheprefixesofthestringP=\"aaabbaaa\"thatarealsosuffixesofP.\nR-12.4 Draw a figure illustrating the comparisons done by brute-force pattern\nmatchingforthetext\"aaabaadaabaaa\"andpattern\"aabaaa\".\nR-12.5 Repeat the previous problem for theBM pattern matching algorithm, not\ncounting thecomparisons madetocomputethelast(c)function.\nR-12.6 RepeatthepreviousproblemfortheKMPpatternmatchingalgorithm,not\ncounting thecomparisons madetocomputethefailurefunction.\nR-12.7 Compute a table representing the last function used in the BM pattern\nmatchingalgorithm forthepatternstring\n\"the quick brown fox jumped over a lazy cat\"\nassumingthefollowingalphabet (whichstartswiththespacecharacter):\n\u03a3= ,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z .\n{ }\nR-12.8 Assumingthatthecharacters inalphabet\u03a3canbeenumeratedandcanbe\nusedtoindexarrays,giveanO(m+ \u03a3 )-timemethodforconstructing the\n| |\nlastfunction fromanm-lengthpatternstringP.\nR-12.9 Compute a table representing the KMP failure function for the pattern\nstring\"cgtacgttcgtac\".\nR-12.10 Drawastandard trieforthefollowingsetofstrings:\nabab,baba,ccccc,bbaaaa,caa,bbaacc,cbcc,cbca .\n{ }\nR-12.11 Drawacompressed trieforthesetofstringsgiveninExerciseR-12.10.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 588 \u2014 #610\ni i\n588 Chapter12. StringsandDynamicProgramming\nR-12.12 Drawthecompactrepresentation ofthesuffixtrieforthestring\n\"minimize minime\".\nR-12.13 Whatisthelongest prefixofthestring \"cgtacgttcgtacg\"thatisalsoa\nsuffixofthisstring?\nR-12.14 Drawthefrequency arrayandHuffmantreeforthefollowingstring:\n\"dogs do not spot hot pots or cats\".\nR-12.15 Showthelongest commonsubsequence arrayLforthetwostrings\nX = \"skullandbones\"\nY = \"lullabybabies\".\nWhatisalongest commonsubsequence betweenthesestrings?\nCreativity\nC-12.1 AnativeAustraliannamedAnatjariwishestocrossadesertcarryingonly\nasinglewaterbottle. Hehasamapthatmarksallthewateringholesalong\ntheway. Assuming hecanwalkk milesononebottle ofwater, design an\nefficient algorithm for determining where Anatjari should refill his bottle\nin order to make as few stops as possible. Argue why your algorithm is\ncorrect.\nC-12.2 Describe an efficient greedy algorithm for making change for a specified\nvalueusingaminimumnumberofcoins,assumingtherearefourdenom-\ninationsofcoins,calledquarters,dimes,nickels,andpennies,withvalues\n25,10,5,and1,respectively. Arguewhyyouralgorithm iscorrect.\nC-12.3 Give an example set of denominations of coins so that a greedy change-\nmakingalgorithm willnotusetheminimumnumberofcoins.\nC-12.4 In the art gallery guarding problem we are given a line L that repre-\nsents a long hallway in an art gallery. We are also given a set X =\nx ,x ,...,x of real numbers that specify the positions of paintings\n0 1 n\u22121\n{ }\nin this hallway. Suppose that a single guard can protect all the paintings\nwithin distance at most 1 of his or her position (on both sides). Design\nan algorithm for finding a placement of guards that uses the minimum\nnumberofguardstoguardallthepaintings withpositions inX.\nC-12.5 Let P be a convex polygon, a triangulation of P is an addition of diag-\nonals connecting the vertices of P so that each interior face is a triangle.\nThe weight of a triangulation is the sum of the lengths of the diagonals.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 589 \u2014 #611\ni i\n12.6. Exercises 589\nAssumingthatwecancomputelengthsandaddandcomparethemincon-\nstant time, give an efficient algorithm for computing a minimum-weight\ntriangulation ofP.\nC-12.6 Give an example of a text T of length n and a pattern P of length m that\nforce the brute-force pattern matching algorithm to have a running time\nthatis\u2126(nm).\nC-12.7 GiveajustificationofwhytheKMPFailureFunctionfunction(CodeFrag-\nment12.7)runsinO(m)timeonapatternoflengthm.\nC-12.8 Showhowtomodify theKMPstring pattern matching algorithm soasto\nfindeveryoccurrenceofapatternstringPthatappearsasasubstringinT,\nwhilestillrunninginO(n+m)time. (Besuretocatcheventhosematches\nthatoverlap.)\nC-12.9 LetT beatextoflengthn,andletPbeapatternoflengthm. Describean\nO(n+m)-timemethodforfindingthelongestprefixofPthatisasubstring\nofT.\nC-12.10 Say that a pattern P of length m is a circular substring of a text T of\nlengthnifthereisanindex0 i<m,suchthatP=T[n m+i..n 1]+\n\u2264 \u2212 \u2212\nT[0..i 1], that is, if P is a (normal) substring of T or P is equal to the\n\u2212\nconcatenation of a suffix of T and a prefix of T. Give an O(n+m)-time\nalgorithm fordetermining whetherPisacircular substring ofT.\nC-12.11 The KMP pattern matching algorithm can be modified to run faster on\nbinarystringsbyredefiningthefailurefunction as\nf(j)=thelargestk< jsuchthatP[0..k 2]p isasuffixofP[1..j],\nk\n\u2212\nwhere p denotes the complement of the kth bit of P. Describe how to\nk b\nmodify the KMP algorithm to be able to take advantage of this new fail-\nure function and also give a function for computing this failure function.\nb\nShow that this function makes at most n comparisons between the text\nandthepattern(asopposedtothe2ncomparisonsneededbythestandard\nKMPalgorithm giveninSection12.3.3).\nC-12.12 ModifythesimplifiedBMalgorithmpresented inthischapterusingideas\nfromtheKMPalgorithm sothatitrunsinO(n+m)time.\nC-12.13 GivenastringX oflengthnandastringY oflengthm,describeanO(n+\nm)-timealgorithmforfindingthelongestprefixofX thatisasuffixofY.\nC-12.14 Give an efficient algorithm for deleting a string from a standard trie and\nanalyzeitsrunning time.\nC-12.15 Give an efficient algorithm for deleting a string from a compressed trie\nandanalyzeitsrunning time.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 590 \u2014 #612\ni i\n590 Chapter12. StringsandDynamicProgramming\nC-12.16 Describe an algorithm for constructing the compact representation of a\nsuffix trie, given its noncompact representation, and analyze its running\ntime.\nC-12.17 Let T be a text string of length n. Describe an O(n)-time method for\nfindingthelongest prefixofT thatisasubstring ofthereversalofT.\nC-12.18 Describe an efficient algorithm to find the longest palindrome that is a\nsuffixofastringT oflengthn. Recallthatapalindromeisastringthatis\nequaltoitsreversal. Whatistherunningtimeofyourmethod?\nC-12.19 GivenasequenceS=(x ,x ,x ,...,x )ofnumbers,describeanO(n2)-\n0 1 2 n\u22121\ntimealgorithmforfindingalongestsubsequenceT =(x ,x ,x ,...,x )\ni0 i1 i2 ik\u22121\nof numbers, such that i <i and x >x . Thatis, T isalongest de-\nj j+1 ij ij+1\ncreasing subsequence ofS.\nC-12.20 Define the edit distance between two strings X andY of length n and m,\nrespectively, tobethenumberofeditsthatittakestochangeX intoY. An\nedit consists of a character insertion, a character deletion, or a character\nreplacement. Forexample,thestrings \"algorithm\"and\"rhythm\"have\nedit distance 6. Design an O(nm)-time algorithm for computing the edit\ndistance betweenX andY.\nC-12.21 Design a greedy algorithm for making change after someone buys some\ncandycostingxcentsandthecustomergivestheclerk$1. Youralgorithm\nshouldtrytominimizethenumberofcoinsreturned.\na. Show that your greedy algorithm returns the minimum number of\ncoinsifthecoinshavedenominations$0.25,$0.10,$0.05,and$0.01.\nb. Give a set of denominations for which your algorithm may not re-\nturntheminimumnumberofcoins. Includeanexamplewhereyour\nalgorithm fails.\nC-12.22 GiveanefficientalgorithmfordeterminingifapatternPisasubsequence\n(notsubstring) ofatextT. Whatistherunningtimeofyouralgorithm?\nC-12.23 Let x and y be strings of length n and m respectively. Define B(i,j) to\nbe the length of the longest common substring of the suffix of length i\nin x and the suffix of length j in y. Design an O(nm)-time algorithm for\ncomputing allthevaluesofB(i,j)fori=1,...,nand j=1,...,m.\nC-12.24 Raji has just won a contest that allows her to take n pieces of candy out\nofacandy store forfree. Rajiisold enough torealize that somecandy is\nexpensive, while other candy is relatively cheap, costing much less. The\njars of candy are numbered 0, 1, ..., m 1, so that jar j has n pieces in\nj\n\u2212\nit, with a price of c per piece. Design an O(n+m)-time algorithm that\nj\nallows Raji to maximize the value of the pieces of candy she takes for\nherwinnings. Showthatyouralgorithmproduces themaximumvaluefor\nRaji.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 591 \u2014 #613\ni i\n12.6. Exercises 591\nC-12.25 Let three integer arrays, A, B, andC, be given, each of size n. Given an\narbitrary integer x, design an O(n2logn)-time algorithm to determine if\nthereexistnumbers,ainA,binB,andcinC,suchthatx=a+b+c.\nC-12.26 GiveanO(n2)-timealgorithm forthepreviousproblem.\nProjects\nP-12.1 Implement the LCS algorithm and use it to compute the best sequence\nalignment between some DNAstrings that you can get online from Gen-\nBank.\nP-12.2 Perform an experimental analysis, using documents found on the Inter-\nnet,oftheefficiency(numberofcharactercomparisonsperformed)ofthe\nbrute-force andKMPpatternmatchingalgorithmsforvarying-length pat-\nterns.\nP-12.3 Perform an experimental analysis, using documents found on the Inter-\nnet,oftheefficiency(numberofcharactercomparisonsperformed)ofthe\nbrute-force and BM pattern matching algorithms for varying-length pat-\nterns.\nP-12.4 Perform an experimental comparison of the relative speeds of the brute-\nforce, KMP, and BM pattern matching algorithms. Document the time\ntaken forcoding upeach ofthese algorithms aswellastheirrelative run-\nningtimesondocumentsfoundontheInternetthatarethensearchedusing\nvarying-length patterns.\nP-12.5 Implement a compression and decompression scheme that is based on\nHuffmancoding.\nP-12.6 Create a class that implements a standard trie for a set of ASCII strings.\nThe class should have a constructor that takes as an argument a list of\nstrings, and the class should have a method that tests whether a given\nstringisstoredinthetrie.\nP-12.7 CreateaclassthatimplementsacompressedtrieforasetofASCIIstrings.\nThe class should have a constructor that takes as an argument a list of\nstrings, and the class should have a function that tests whether a given\nstringisstoredinthetrie.\nP-12.8 CreateaclassthatimplementsaprefixtrieforanASCIIstring. Theclass\nshouldhaveaconstructorthattakesasanargumentastringandafunction\nforpatternmatchingonthestring.\nP-12.9 Implement the simplified search engine described in Section 12.5.4 for\nthe pages of a small Web site. Use all the words in the pages of the site\nas index terms, excluding stop words such as articles, prepositions, and\npronouns.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 592 \u2014 #614\ni i\n592 Chapter12. StringsandDynamicProgramming\nP-12.10 Implement a search engine for the pages of a small Web site by adding\na page-ranking feature to the simplified search engine described in Sec-\ntion 12.5.4. Your page-ranking feature should return the most relevant\npages first. Use all the words in the pages of the site as index terms, ex-\ncluding stopwords,suchasarticles, prepositions, andpronouns.\nP-12.11 Write aprogram that takes twocharacter strings (which could be, forex-\nample, representations ofDNAstrands) andcomputes theireditdistance,\nshowingthecorresponding pieces. (SeeExerciseC-12.20.)\nChapter Notes\nTheKMPalgorithmisdescribedbyKnuth,Morris,andPrattintheirjournalarticle[61],\nand Boyer and Moore describe their algorithm in a journal article published the same\nyear [14]. In their article, however, Knuth et al. [61] also prove that the BM algorithm\nrunsinlineartime. Morerecently,Cole[22]showsthattheBMalgorithmmakesatmost\n3ncharactercomparisonsintheworstcase,andthisboundistight. Allofthealgorithms\ndiscussedabovearealsodiscussedinthebookchapterbyAho[3],althoughinamorethe-\noretical framework, including the methods for regular-expressionpattern matching. The\nreader interested in further study of string pattern matching algorithms is referred to the\nbookbyStephen[90]andthebookchaptersbyAho[3]andCrochemoreandLecroq[26].\nThe trie was invented by Morrison [79] and is discussed extensively in the classic\nSorting and Searching book by Knuth [60]. The name \u201cPatricia\u201d is short for \u201cPractical\nAlgorithmtoRetrieveInformationCodedinAlphanumeric\u201d[79]. McCreight[69] shows\nhow to construct suffix tries in linear time. An introduction to the field of information\nretrieval, which includes a discussion of search engines for the Web, is provided in the\nbookbyBaeza-YatesandRibeiro-Neto[7].\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 593 \u2014 #615\ni i\nChapter\n13\nGraph Algorithms\nContents\n13.1 Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . 594\n13.1.1 The Graph ADT . . . . . . . . . . . . . . . . . . . . 599\n13.2 Data Structures for Graphs . . . . . . . . . . . . . . . 600\n13.2.1 The Edge List Structure. . . . . . . . . . . . . . . . 600\n13.2.2 The Adjacency List Structure . . . . . . . . . . . . . 603\n13.2.3 The Adjacency Matrix Structure . . . . . . . . . . . 605\n13.3 Graph Traversals . . . . . . . . . . . . . . . . . . . . . 607\n13.3.1 Depth-First Search . . . . . . . . . . . . . . . . . . 607\n13.3.2 Implementing Depth-First Search . . . . . . . . . . . 611\n13.3.3 A Generic DFS Implementation in C++ . . . . . . . . 613\n\u22c6\n13.3.4 Polymorphic Objects and Decorator Values . . . . 621\n13.3.5 Breadth-First Search . . . . . . . . . . . . . . . . . 623\n13.4 Directed Graphs . . . . . . . . . . . . . . . . . . . . . 626\n13.4.1 Traversing a Digraph . . . . . . . . . . . . . . . . . 628\n13.4.2 Transitive Closure . . . . . . . . . . . . . . . . . . . 630\n13.4.3 Directed Acyclic Graphs . . . . . . . . . . . . . . . . 633\n13.5 Shortest Paths . . . . . . . . . . . . . . . . . . . . . . 637\n13.5.1 Weighted Graphs . . . . . . . . . . . . . . . . . . . 637\n13.5.2 Dijkstra\u2019s Algorithm . . . . . . . . . . . . . . . . . . 639\n13.6 Minimum Spanning Trees . . . . . . . . . . . . . . . . 645\n13.6.1 Kruskal\u2019s Algorithm . . . . . . . . . . . . . . . . . . 647\n13.6.2 The Prim-Jarn\u00b4\u0131k Algorithm . . . . . . . . . . . . . . 651\n13.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 654\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 594 \u2014 #616\ni i\n594 Chapter13. GraphAlgorithms\n13.1 Graphs\nA graph is a way of representing relationships that exist between pairs of objects.\nThat is, a graph is a set of objects, called vertices, together with a collection of\npairwise connections between them. This notion of a \u201cgraph\u201d should not be con-\nfusedwithbarchartsandfunctionplots,asthesekindsof\u201cgraphs\u201dareunrelatedto\nthe topic of this chapter. Graphs have applications in a host of different domains,\nincluding mapping, transportation, electrical engineering, andcomputernetworks.\nViewed abstractly, a graph G is simply a setV of vertices and a collection E\nof pairs of vertices fromV, called edges. Thus, a graph is a way of representing\nconnectionsorrelationshipsbetweenpairsofobjectsfromsomesetV. Somebooks\nusedifferentterminologyforgraphsandrefertowhatwecallverticesasnodesand\nwhatwecalledgesasarcs. Weusetheterms\u201cvertices\u201d and\u201cedges.\u201d\nEdges in a graph are either directed or undirected. An edge (u,v) is said to\nbe directed from u to v if the pair (u,v) is ordered, with u preceding v. An edge\n(u,v)issaidtobeundirectedifthepair(u,v)isnotordered. Undirectededgesare\nsometimes denoted with set notation, as u,v , but for simplicity we use the pair\n{ }\nnotation(u,v),notingthatintheundirectedcase(u,v)isthesameas(v,u). Graphs\naretypicallyvisualizedbydrawingtheverticesasovalsorrectanglesandtheedges\nas segments orcurves connecting pairs of ovals and rectangles. The following are\nsomeexamplesofdirectedandundirected graphs.\nExample 13.1: Wecanvisualizecollaborationsamongtheresearchersofacer-\ntaindisciplinebyconstructingagraphwhoseverticesareassociatedwiththere-\nsearchersthemselves,andwhoseedgesconnectpairsofverticesassociatedwith\nresearcherswhohavecoauthoredapaperorbook. (SeeFigure13.1.)Suchedges\nareundirectedbecausecoauthorshipisasymmetricrelation;thatis,ifAhascoau-\nthoredsomethingwithB,thenBnecessarilyhascoauthoredsomethingwithA.\nFigure13.1: Graphofcoauthorship amongsomeauthors.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 595 \u2014 #617\ni i\n13.1. Graphs 595\nExample 13.2: Anobject-orientedprogramcanbeassociatedwithagraphwhose\nverticesrepresenttheclassesdefinedintheprogramandwhoseedgesindicatein-\nheritancebetweenclasses. Thereisanedgefromavertexv toavertexu ifthe\nclassforvextendstheclassforu.Suchedgesaredirectedbecausetheinheritance\nrelationonlygoesinonedirection(thatis,itisasymmetric).\nIfalltheedgesinagraphareundirected,thenwesaythegraphisanundirected\ngraph. Likewise, a directed graph, also called a digraph, is a graph whose edges\narealldirected. Agraphthathasbothdirectedandundirectededgesisoftencalled\na mixed graph. Note that an undirected or mixed graph can be converted into a\ndirected graph by replacing every undirected edge (u,v) by the pair of directed\nedges (u,v) and (v,u). It is often useful, however, to keep undirected and mixed\ngraphs represented as they are, for such graphs have several applications, such as\nthatofthefollowingexample.\nExample 13.3: Acitymapcanbemodeledbyagraphwhoseverticesareinter-\nsectionsordeadends,andwhoseedgesarestretchesofstreetswithoutintersec-\ntions.Thisgraphhasbothundirectededges,whichcorrespondtostretchesoftwo-\nwaystreets,anddirectededges,whichcorrespondtostretchesofone-waystreets.\nThus,inthisway,agraphmodelingacitymapisamixedgraph.\nExample 13.4: Physicalexamplesofgraphsarepresentintheelectricalwiring\nandplumbingnetworksofabuilding. Suchnetworkscanbemodeledasgraphs,\nwhereeachconnector,fixture,oroutletisviewedasavertex,andeachuninter-\nruptedstretchofwireorpipeisviewedasanedge.Suchgraphsareactuallycom-\nponentsofmuchlargergraphs,namelythelocalpowerandwaterdistributionnet-\nworks.Dependingonthespecificaspectsofthesegraphsthatweareinterestedin,\nwemayconsidertheiredgesasundirectedordirected,because,inprinciple,water\ncanflowinapipeandcurrentcanflowinawireineitherdirection.\nThe two vertices joined by an edge are called the end vertices (or endpoints)\noftheedge. Ifanedgeisdirected,itsfirstendpointisitsoriginandtheotheristhe\ndestination of the edge. Twovertices uand vare said tobe adjacent ifthere isan\nedge whose end vertices are u and v. An edge is said to be incident on a vertex if\nthe vertex is one of the edge\u2019s endpoints. The outgoing edges of a vertex are the\ndirected edges whoseorigin isthatvertex. Theincomingedges ofavertexarethe\ndirected edges whose destination is that vertex. The degree of a vertex v, denoted\ndeg(v), is the number of incident edges of v. The in-degree and out-degree of a\nvertex v are the number of the incoming and outgoing edges ofv, and are denoted\nindeg(v)andoutdeg(v),respectively.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 596 \u2014 #618\ni i\n596 Chapter13. GraphAlgorithms\nExample 13.5: WecanstudyairtransportationbyconstructingagraphG,called\na flight network,whoseverticesareassociatedwithairports,andwhoseedges\nareassociatedwithflights. (SeeFigure13.2.) IngraphG,theedgesaredirected\nbecauseagivenflighthasaspecifictraveldirection(fromtheoriginairporttothe\ndestinationairport).TheendpointsofanedgeeinGcorrespondrespectivelytothe\noriginanddestinationfortheflightcorrespondingtoe. Twoairportsareadjacent\ninG ifthereisaflightthatfliesbetweenthem,andanedgee isincidentupona\nvertexvinGiftheflightforefliestoorfromtheairportforv.Theoutgoingedges\nofavertexvcorrespondtotheoutboundflightsfromv\u2019sairport,andtheincoming\nedgescorrespondtotheinboundflightstov\u2019sairport. Finally,thein-degreeofa\nvertexvofGcorrespondstothenumberofinboundflightstov\u2019sairport,andthe\nout-degreeofavertexvinGcorrespondstothenumberofoutboundflights.\nThedefinition ofagraph referstothegroupofedgesasacollection, notaset,\nthus allowing for two undirected edges to have the same end vertices, and for two\ndirected edges to have the same origin and the same destination. Such edges are\ncalled parallel edges or multiple edges. Parallel edges can be in a flight network\n(Example 13.5), in which case multiple edges between the same pair of vertices\ncouldindicatedifferentflightsoperating onthesamerouteatdifferenttimesofthe\nday. Anotherspecialtypeofedgeisonethatconnectsavertextoitself. Namely,we\nsaythatanedge(undirectedordirected)isaself-loopifitstwoendpointscoincide.\nAself-loopmayoccurinagraphassociatedwithacitymap(Example13.3),where\nitwouldcorrespond toa\u201ccircle\u201d(acurving streetthatreturns toitsstartingpoint).\nWith few exceptions, graphs do not have parallel edges or self-loops. Such\ngraphs are said to be simple. Thus, we can usually say that the edges of a simple\ngraph area setof vertex pairs (and notjust acollection). Throughout this chapter,\nweassumethatagraphissimpleunlessotherwisespecified.\nFigure13.2: Example of a directed graph representing a flight network. The end-\npoints of edge UA 120 are LAX and ORD; hence, LAX and ORD are adjacent.\nThein-degree ofDFWis3,andtheout-degree ofDFWis2.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 597 \u2014 #619\ni i\n13.1. Graphs 597\nInthepropositionsthatfollow,weexploreafewimportantpropertiesofgraphs.\nProposition 13.6: IfGisagraphwithmedges,then\n\u2211\ndeg(v)=2m.\nvinG\nJustification: Anedge (u,v)iscounted twiceinthesummation above; onceby\nitsendpoint uand once byitsendpoint v. Thus, thetotal contribution ofthe edges\ntothedegreesoftheverticesistwicethenumberofedges.\nProposition 13.7: IfGisadirectedgraphwithmedges,then\n\u2211 \u2211\nindeg(v) = outdeg(v)=m.\nvinG vinG\nJustification: In a directed graph, an edge (u,v) contributes one unit to the\nout-degree of its origin u and one unit to the in-degree of its destination v. Thus,\nthe total contribution of the edges to the out-degrees of the vertices is equal to the\nnumberofedges,andsimilarlyfortheout-degrees.\nWenextshowthatasimplegraphwithnverticeshasO(n2)edges.\nProposition 13.8: LetGbeasimplegraphwithnverticesandmedges. IfGis\nundirected,thenm n(n 1)/2,andifGisdirected,thenm n(n 1).\n\u2264 \u2212 \u2264 \u2212\nJustification: Suppose that G is undirected. Since no two edges can have the\nsame endpoints and there are no self-loops, the maximum degree of a vertex in G\nisn 1 inthis case. Thus, byProposition 13.6, 2m n(n 1). Nowsuppose that\n\u2212 \u2264 \u2212\nG is directed. Since no two edges can have the same origin and destination, and\ntherearenoself-loops,themaximumin-degreeofavertexinGisn 1inthiscase.\n\u2212\nThus,byProposition 13.7,m n(n 1).\n\u2264 \u2212\nApathisasequenceofalternatingverticesandedgesthatstartsatavertexand\nends at a vertex such that each edge is incident to its predecessor and successor\nvertex. A cycle is a path with at least one edge that has the same start and end\nvertices. We say that a path is simple if each vertex in the path is distinct, and\nwe say that a cycle is simple if each vertex in the cycle is distinct, except for the\nfirstandlastone. Adirected pathisapathsuch thatalledges aredirected andare\ntraversed along theirdirection. Adirected cycle issimilarly defined. Forexample,\nin Figure 13.2, (BOS,NW 35, JFK, AA 1387, DFW)is in a directed simple path,\nand(LAX,UA120,ORD,UA877,DFW,AA49,LAX)isadirectedsimplecycle.\nIfapathPorcycleC isasimplegraph, wemayomittheedgesinPorC,asthese\nare well defined, in which case P is a list of adjacent vertices andC is a cycle of\nadjacent vertices.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 598 \u2014 #620\ni i\n598 Chapter13. GraphAlgorithms\nExample 13.9: GivenagraphGrepresentingacitymap(seeExample13.3),we\ncanmodelacoupledrivingtodinneratarecommendedrestaurantastraversinga\npaththoughG.Iftheyknowtheway,anddon\u2019taccidentallygothroughthesame\nintersectiontwice,thentheytraverseasimplepathinG.Likewise,wecanmodel\ntheentiretripthecoupletakes,fromtheirhometotherestaurantandback,asa\ncycle.Iftheygohomefromtherestaurantinacompletelydifferentwaythanhow\ntheywent,notevengoingthroughthesameintersectiontwice,thentheirentire\nroundtripisasimplecycle. Finally,iftheytravelalongone-waystreetsfortheir\nentiretrip,wecanmodeltheirnightoutasadirectedcycle.\nA subgraph of a graph G is a graph H whose vertices and edges are subsets\nof the vertices and edges of G, respectively. For example, in the flight network of\nFigure 13.2, vertices BOS, JFK, and MIA, and edges AA 903 and DL 247 form\na subgraph. A spanning subgraph of G is a subgraph of G that contains all the\nvertices of the graph G. A graph is connected if, for any two vertices, there is a\npathbetweenthem. IfagraphGisnotconnected,itsmaximalconnectedsubgraphs\nare called the connected components of G. A forest is a graph without cycles. A\ntree isaconnected forest, thatis, aconnected graph without cycles. Notethat this\ndefinitionofatreeissomewhatdifferentfromtheonegiveninChapter7. Namely,\ninthecontext ofgraphs, atree hasnoroot. Whenever there isambiguity, thetrees\nof Chapter 7 should be referred to as rooted trees, while the trees of this chapter\nshouldbereferredtoasfreetrees. Theconnectedcomponentsofaforestare(free)\ntrees. Aspanningtreeofagraphisaspanning subgraph thatisa(free)tree.\nExample 13.10: PerhapsthemosttalkedaboutgraphtodayistheInternet,which\ncanbeviewedasagraphwhoseverticesarecomputersandwhose(undirected)\nedgesarecommunicationconnectionsbetweenpairsofcomputersontheInter-\nnet. Thecomputersandtheconnectionsbetweentheminasingledomain,like\nwiley.com,formasubgraphoftheInternet.Ifthissubgraphisconnected,thentwo\nusersoncomputersinthisdomaincansende-mailtooneanotherwithouthaving\ntheirinformationpacketseverleavetheirdomain. Supposetheedgesofthissub-\ngraphformaspanningtree. Thisimpliesthat,ifevenasingleconnectiongoes\ndown(forexample,becausesomeonepullsacommunicationcableoutoftheback\nofacomputerinthisdomain),thenthissubgraphwillnolongerbeconnected.\nThereareanumberofsimplepropertiesoftrees,forests,andconnectedgraphs.\nProposition 13.11: LetGbeanundirectedgraphwithnverticesandmedges.\nIfGisconnected,thenm n 1\n\u2022 \u2265 \u2212\nIfGisatree,thenm=n 1\n\u2022 \u2212\nIfGisaforest,thenm n 1\n\u2022 \u2264 \u2212\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 599 \u2014 #621\ni i\n13.1. Graphs 599\n13.1.1 The Graph ADT\nIn this section, we introduce a simplified graph abstract data type (ADT), which\nis suitable for undirected graphs, that is, graphs whose edges are all undirected.\nAdditional functions fordealing withdirected edgesarediscussed inSection13.4.\nAs an abstract data type, a graph is a collection of elements that are stored at\nthe graph\u2019s positions\u2014its vertices and edges. Hence, we can store elements in a\ngraphateitheritsedgesoritsvertices(orboth). ThegraphADTdefinestwotypes,\nVertex and Edge. It also provides two list types for storing lists of vertices and\nedges,calledVertexListandEdgeList,respectively.\nEach Vertex object u supports the following operations, which provide access\ntothevertex\u2019s element andinformation regarding incident edges andadjacent ver-\ntices.\noperator*(): Returntheelementassociated withu.\nincidentEdges(): Returnanedgelistoftheedgesincident onu.\nisAdjacentTo(v): Testwhetherverticesuandvareadjacent.\nEach Edge object e supports the following operations, which provide access\ntotheedge\u2019s endvertices andinformation regarding theedge\u2019s incidence relation-\nships.\noperator*(): Returntheelementassociated withe.\nendVertices(): Returnavertexlistcontaining e\u2019sendvertices.\nopposite(v): Returntheendvertexofedgeedistinctfromvertexv;an\nerroroccursifeisnotincident onv.\nisAdjacentTo(f): Testwhetheredgeseand f areadjacent.\nisIncidentOn(v): Testwhethereisincident onv.\nFinally,thefullgraphADTconsistsofthefollowingoperations, whichprovide\naccess to the lists of vertices and edges, and provide functions for modifying the\ngraph.\nvertices(): Returnavertexlistofalltheverticesofthegraph.\nedges(): Returnanedgelistofalltheedgesofthegraph.\ninsertVertex(x): Insertandreturnanewvertexstoringelementx.\ninsertEdge(v,w,x): Insertandreturnanewundirectededgewithendvertices\nvandwandstoringelementx.\neraseVertex(v): Removevertexvandallitsincident edges.\neraseEdge(e): Removeedgee.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 600 \u2014 #622\ni i\n600 Chapter13. GraphAlgorithms\nThe VertexList and EdgeList classes support the standard list operations, as\ndescribed in Chapter 6. In particular, we assume that each provides an iterator\n(Section 6.2.1), which we call VertexItor and EdgeItor, respectively. They also\nprovidefunctionsbeginandend,whichreturniteratorstothebeginningandendof\ntheirrespective lists.\n13.2 Data Structures for Graphs\nIn this section, we discuss three popular ways of representing graphs, which are\nusually referred to as the edge list structure, the adjacency list structure, and the\nadjacency matrix. Inallthreerepresentations, weuseacollection tostorethever-\nticesofthegraph. Regardingtheedges, thereisafundamental difference between\nthe firsttwostructures and thelatter. Theedge list structure andthe adjacency list\nstructure only store the edges actually present in the graph, while the adjacency\nmatrix stores aplaceholder for every pair ofvertices (whether there isan edge be-\ntweenthemornot). Aswewillexplain inthissection, thisdifference impliesthat,\nforagraphGwithnverticesandmedges,anedgelistoradjacencylistrepresenta-\ntion uses O(n+m)space, whereas an adjacency matrix representation uses O(n2)\nspace.\n13.2.1 The Edge List Structure\nThe edge list structure is possibly the simplest, though not the most efficient, rep-\nresentation ofagraph G. Inthisrepresentation, avertex vofGstoring anelement\nx is explicitly represented by a vertex object. All such vertex objects are stored in\nacollectionV, such asavector ornode list. IfV is avector, forexample, then we\nnaturally thinkoftheverticesasbeingnumbered.\nVertex Objects\nThevertexobjectforavertexvstoring elementxhasmembervariables for:\nAcopyofx\n\u2022\nTheposition (orentry)ofthevertex-object incollectionV\n\u2022\nThedistinguishingfeatureoftheedgeliststructureisnothowitrepresentsvertices,\nbutthewayinwhichitrepresentsedges. Inthisstructure,anedgeeofGstoringan\nelement x is explicitly represented by an edge object. The edge objects are stored\ninacollection E,whichwouldtypically beavectorornodelist.\nEdge Objects\nTheedgeobjectforanedgeestoringelementxhasmembervariablesfor:\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 601 \u2014 #623\ni i\n13.2. DataStructuresforGraphs 601\nAcopyofx\n\u2022\nThevertexpositions associated withtheendpoint verticesofe\n\u2022\nTheposition (orentry)oftheedge-object incollection E\n\u2022\nVisualizing the Edge List Structure\nWeillustrate anexampleoftheedgeliststructure foragraphGinFigure13.3.\n(a)\n(b)\nFigure13.3: (a) A graph G. (b) Schematic representation of the edge list structure\nfor G. We visualize the elements stored in the vertex and edge objects with the\nelementnames,instead ofwithactualreferences totheelementobjects.\nThereasonthisstructureiscalledtheedgeliststructureisthatthesimplestand\nmostcommonimplementation oftheedge collection E isbyusing alist. Evenso,\ninordertobeabletoconvenientlysearchforspecificobjectsassociatedwithedges,\nwemaywishtoimplementE withadictionary (whoseentriesstoretheelementas\nthe key and the edge as the value) in spite of our calling this the \u201cedge list.\u201d We\nmay also want to implement the collection V by using a dictionary for the same\nreason. Still,inkeepingwithtradition, wecallthisstructuretheedgeliststructure.\nThemainfeatureoftheedgeliststructure isthatitprovidesdirectaccessfrom\nedges to the vertices they are incident upon. This allows us to define simple algo-\nrithmsforfunctions e.endVertices()ande.opposite(v).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 602 \u2014 #624\ni i\n602 Chapter13. GraphAlgorithms\nPerformance of the Edge List Structure\nOne method that is inefficient for the edge list structure is that of accessing the\nedges that are incident upon a vertex. Determining this set of vertices requires an\nexhaustive inspection of all the edge objects in the collection E. That is, in order\ntodeterminewhichedgesareincident toavertexv,wemustexaminealltheedges\nin the edge list and check, for each one, if it happens to be incident to v. Thus,\nfunction v.incidentEdges()runsintimeproportional tothenumberofedgesinthe\ngraph, not in time proportional to the degree of vertex v. In fact, even to check if\ntwovertices vand ware adjacent by the v.isAdjacentTo(w)function, requires that\nwesearchtheentireedgecollection lookingforanedgewithendverticesvandw.\nMoreover, since removing a vertex involves removing all of its incident edges,\nfunction eraseVertexalsorequiresacompletesearchoftheedgecollection E.\nTable 13.1 summarizes the performance of the edge list structure implemen-\ntation of a graph under the assumption that collections V and E are realized with\ndoublylinkedlists(Section3.3).\nOperation Time\nvertices O(n)\nedges O(m)\nendVertices, opposite O(1)\nincidentEdges, isAdjacentTo O(m)\nisIncidentOn O(1)\ninsertVertex, insertEdge, eraseEdge, O(1)\neraseVertex O(m)\nTable 13.1: Running times of the functions of a graph implemented with the edge\nliststructure. ThespaceusedisO(n+m),wherenisthenumberofverticesandm\nisthenumberofedges.\nDetailsforselected functions ofthegraphADTareasfollows:\nMethodsvertices()andedges()areimplementedbyusingtheiteratorsforV\n\u2022\nandE,respectively, toenumeratetheelementsofthelists.\nMethodsincidentEdgesandisAdjacentToalltakeO(m)time,sincetodeter-\n\u2022\nminewhichedgesareincident uponavertexvwemustinspectalledges.\nSincethecollectionsV andE arelistsimplementedwithadoublylinkedlist,\n\u2022\nwecaninsertvertices,andinsertandremoveedges,inO(1)time.\nThe update function eraseVertex(v) takes O(m) time, since it requires that\n\u2022\nweinspectalltheedgestofindandremovethoseincident uponv.\nThus,theedgelistrepresentation issimplebuthassignificantlimitations.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 603 \u2014 #625\ni i\n13.2. DataStructuresforGraphs 603\n13.2.2 The Adjacency List Structure\nThe adjacency list structure for a graph G adds extra information to the edge list\nstructure thatsupports direct access to theincident edges (and thus tothe adjacent\nvertices)ofeachvertex. Thisapproach allowsustousetheadjacency liststructure\ntoimplementseveralfunctionsofthegraphADTmuchfasterthanwhatispossible\nwith the edge list structure, even though both of these two representations use an\namount of space proportional to the number of vertices and edges in the graph.\nThe adjacency list structure includes all the structural components of the edge list\nstructure plusthefollowing:\nAvertex object vholds areference to acollection I(v), called theincidence\n\u2022\ncollection ofv,whoseelementsstorereferences totheedgesincident onv.\nThe edge object for an edge e with end vertices v and w holds references to\n\u2022\nthe positions (or entries) associated with edge e in the incidence collections\nI(v)andI(w).\nTraditionally, theincidence collection I(v)foravertexvisalist,whichiswhy\nwecallthiswayofrepresentingagraphtheadjacencyliststructure. Theadjacency\nliststructureprovidesdirectaccessbothfromtheedgestotheverticesandfromthe\nverticestotheirincidentedges. Weillustratetheadjacencyliststructureofagraph\ninFigure13.4.\n(a)\n(b)\nFigure13.4: (a)AgraphG.(b)Schematicrepresentationoftheadjacencyliststruc-\ntureofG. AsinFigure13.3,wevisualize theelementsofcollections withnames.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 604 \u2014 #626\ni i\n604 Chapter13. GraphAlgorithms\nPerformance of the Adjacency List Structure\nAll of the functions of the graph ADT that can be implemented with the edge list\nstructure in O(1) time can also be implemented in O(1) time with the adjacency\nliststructure, usingessentially thesamealgorithms. Inaddition, beingabletopro-\nvideaccessbetweenverticesandedgesinbothdirectionsallowsustospeedupthe\nperformance of a number of graph functions by using an adjacency list structure\ninsteadofanedgeliststructure. Table13.2summarizestheperformanceofthead-\njacencyliststructureimplementationofagraph,assumingthatcollectionsV andE\nandtheincidencecollectionsoftheverticesareallimplementedwithdoublylinked\nlists. Foravertexv,thespace usedbytheincidence collection ofvisproportional\ntothedegreeofv,thatis,itisO(deg(v)). Thus,byProposition13.6,thespaceused\nbytheadjacency liststructure isO(n+m).\nOperation Time\nvertices O(n)\nedges O(m)\nendVertices, opposite O(1)\nv.incidentEdges() O(deg(v))\nv.isAdjacentTo(w) O(min(deg(v),deg(w))\nisIncidentOn O(1)\ninsertVertex, insertEdge, eraseEdge, O(1)\neraseVertex(v) O(deg(v))\nTable13.2: Running times of the functions of a graph implemented with the adja-\ncencyliststructure. ThespaceusedisO(n+m),wherenisthenumberofvertices\nandmisthenumberofedges.\nIn contrast to the edge-list way of doing things, the adjacency list structure\nprovidesimprovedrunningtimesforthefollowingfunctions:\nMethodsvertices()andedges()areimplementedbyusingtheiteratorsforV\n\u2022\nandE,respectively, toenumeratetheelementsofthelists.\nMethod v.incidentEdges()takes timeproportional tothenumberofincident\n\u2022\nverticesofv,thatis,O(deg(v))time.\nMethod v.isAdjacentTo(w) can be performed by inspecting either the inci-\n\u2022\ndencecollectionofvorthatofw. Bychoosingthesmallerofthetwo,weget\nO(min(deg(v),deg(w)))running time.\nMethoderaseVertex(v)takesO(deg(v))time.\n\u2022\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 605 \u2014 #627\ni i\n13.2. DataStructuresforGraphs 605\n13.2.3 The Adjacency Matrix Structure\nLiketheadjacencyliststructure, theadjacencymatrixstructureofagraphalsoex-\ntendstheedgeliststructurewithanadditionalcomponent. Inthiscase,weaugment\ntheedgelistwithamatrix(atwo-dimensional array)Athatallowsustodetermine\nadjacenciesbetweenpairsofverticesinconstanttime. Intheadjacencymatrixrep-\nresentation, wethinkoftheverticesasbeingtheintegersintheset 0,1,...,n 1\n{ \u2212 }\nand theedges asbeing pairs of such integers. Thisallows ustostore references to\nedges in the cells of a two-dimensional n n array A. Specifically, the adjacency\n\u00d7\nmatrixrepresentation extendstheedgeliststructure asfollows(seeFigure13.5):\nAvertexobject vstores adistinct integer iintherange 0,1,...,n 1, called\n\u2022 \u2212\ntheindexofv.\nWe keep a two-dimensional n n array A such that the cell A[i,j] holds a\n\u2022 \u00d7\nreferencetotheedge(v,w),ifitexists,wherevisthevertexwithindexiand\nwisthevertexwithindex j. Ifthereisnosuchedge,thenA[i,j]=null.\n(a)\n(b)\nFigure13.5: (a)Agraph Gwithoutparallel edges. (b)Schematicrepresentation of\nthesimplifiedadjacency matrixstructure forG.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 606 \u2014 #628\ni i\n606 Chapter13. GraphAlgorithms\nPerformance of the Adjacency Matrix Structure\nFor graphs with parallel edges, the adjacency matrix representation must be ex-\ntendedsothat,insteadofhavingA[i,j]storingapointertoanassociatededge(v,w),\nitmuststore apointer toanincidence collection I(v,w), whichstores alltheedges\nfrom vto w. Since most ofthe graphs weconsider are simple, wedo not consider\nthiscomplication here.\nTheadjacency matrixAallows ustoperform v.isAdjacentTo(w)inO(1)time.\nThis is done by accessing vertices v and w to determine their respective indices i\nand j, and then testing whether A[i,j] is null. The efficiency of isAdjacentTo is\ncounteracted by an increase in space usage, however, which is now O(n2), and in\nthe running timeof other functions. Forexample, function v.incidentEdges() now\nrequires thatweexamineanentireroworcolumnofarrayAandthusrunsinO(n)\ntime. Moreover, any vertex insertions or deletions now require creating a whole\nnewarrayA,oflargerorsmallersize,respectively, whichtakesO(n2)time.\nTable 13.3 summarizes the performance of the adjacency matrix structure im-\nplementation of agraph. From this table, weobserve that the adjacency list struc-\nture is superior to the adjacency matrix in space, and is superior in time for all\nfunctions exceptfortheisAdjacentTofunction.\nOperation Time\nvertices O(n)\nedges O(n2)\nendVertices, opposite O(1)\nisAdjacentTo, isIncidentOn O(1)\nincidentEdges O(n)\ninsertEdge, eraseEdge, O(1)\ninsertVertex, eraseVertex O(n2)\nTable13.3: Runningtimesforagraphimplementedwithanadjacency matrix.\nHistorically, Boolean adjacency matrices were the first representations used\nfor graphs (so that A[i,j]= true if and only if (i,j) is an edge). We should not\nfind this fact surprising, however, for the adjacency matrix has a natural appeal\nas a mathematical structure (for example, an undirected graph has a symmetric\nadjacency matrix). The adjacency list structure came later, with its natural appeal\nin computing due to its faster methods for most algorithms (many algorithms do\nnotusefunction isAdjacentTo)anditsspaceefficiency.\nMost of the graph algorithms we examine run efficiently when acting upon a\ngraph stored using the adjacency list representation. In some cases, however, a\ntrade-off occurs, where graphs with few edges are most efficiently processed with\nan adjacency list structure, and graphs with many edges are most efficiently pro-\ncessedwithanadjacency matrixstructure.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 607 \u2014 #629\ni i\n13.3. GraphTraversals 607\n13.3 Graph Traversals\nGreek mythology tells of an elaborate labyrinth that was built to house the mon-\nstrousMinotaur, whichwaspartbullandpartman. Thislabyrinth wassocomplex\nthat neither beast nor human could escape it. No human, that is, until the Greek\nhero,Theseus,withthehelpoftheking\u2019sdaughter, Ariadne,decidedtoimplement\na graph-traversal algorithm. Theseus fastened a ball of thread to the door of the\nlabyrinthandunwounditashetraversedthetwistingpassagesinsearchofthemon-\nster. Theseus obviously knew about good algorithm design, because, after finding\nanddefeatingthebeast,Theseuseasilyfollowedthestringbackoutofthelabyrinth\nto the loving arms of Ariadne. Formally, a traversal is a systematic procedure for\nexploring agraphbyexaminingallofitsverticesandedges.\n13.3.1 Depth-First Search\nThefirsttraversalalgorithmweconsiderinthissectionisdepth-firstsearch(DFS)\nin an undirected graph. Depth-first search is useful for testing a number of prop-\nerties of graphs, including whether there is a path from one vertex to another and\nwhetherornotagraphisconnected.\nDepth-first search in an undirected graph G is analogous to wandering in a\nlabyrinthwithastringandacanofpaintwithoutgettinglost. Webeginataspecific\nstarting vertex s in G, which we initialize by fixing one end of our string to s and\npainting s as \u201cvisited.\u201d The vertex s is now our \u201ccurrent\u201d vertex\u2014call our current\nvertex u. We then traverse G by considering an (arbitrary) edge (u,v) incident\nto the current vertex u. If the edge (u,v) leads us to an already visited (that is,\npainted) vertex v, we immediately return to vertex u. If, on the other hand, (u,v)\nleadstoanunvisited vertexv,thenweunroll ourstring,andgotov. Wethenpaint\nv as \u201cvisited,\u201d and make it the current vertex, repeating the computation above.\nEventually,wegettoa\u201cdeadend,\u201dthatis,acurrentvertexusuchthatalltheedges\nincident on u lead to vertices already visited. Thus, taking any edge incident on\nu causes us to return to u. To get out of this impasse, we roll our string back up,\nbacktrackingalongtheedgethatbroughtustou,goingbacktoapreviouslyvisited\nvertex v. Wethen make vour current vertex and repeat the computation above for\nany edges incident upon v that we have not looked at before. If all of v\u2019s incident\nedges leadtovisited vertices, thenweagainrollupourstring andbacktrack tothe\nvertex wecamefrom togettov, and repeat the procedure atthat vertex. Thus, we\ncontinuetobacktrackalongthepaththatwehavetracedsofaruntilwefindavertex\nthathas yetunexplored edges, takeone suchedge, and continue thetraversal. The\nprocess terminates when our backtracking leads us back to the start vertex s, and\ntherearenomoreunexplored edgesincident ons.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 608 \u2014 #630\ni i\n608 Chapter13. GraphAlgorithms\nThissimpleprocesstraverses alltheedgesofG. (SeeFigure13.6.)\n(a) (b)\n(c) (d)\n(e) (f)\nFigure13.6: Exampleofdepth-first searchtraversalonagraphstartingatvertexA.\nDiscoveryedgesareshownwithsolidlinesandbackedgesareshownwithdashed\nlines: (a) input graph; (b) path of discovery edges traced from A until back edge\n(B,A)ishit;(c)reachingF,whichisadeadend;(d)afterbacktrackingtoC,resum-\ning with edge (C,G), and hitting another dead end, J; (e) after backtracking to G;\n(f)afterbacktracking toN.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 609 \u2014 #631\ni i\n13.3. GraphTraversals 609\nDiscovery Edges and Back Edges\nWecanvisualizeaDFStraversalbyorientingtheedgesalongthedirectioninwhich\nthey are explored during the traversal, distinguishing the edges used to discover\nnewvertices, called discovery edges, ortreeedges, from those thatlead toalready\nvisited vertices, called back edges. (See Figure 13.6(f).) In the analogy above,\ndiscovery edges are the edges where we unroll our string when we traverse them,\nand back edges are the edges where we immediately return without unrolling any\nstring. As we will see, the discovery edges form a spanning tree of the connected\ncomponent ofthestarting vertex s. Wecallthe edges notinthis tree\u201cback edges\u201d\nbecause, assuming that the tree is rooted at the start vertex, each such edge leads\nbackfromavertexinthistreetooneofitsancestors inthetree.\nThepseudo-code foraDFStraversal starting atavertexvfollowsouranalogy\nwith string and paint. We use recursion to implement the string analogy, and we\nassume that we have a mechanism (the paint analogy) to determine if a vertex or\nedge has been explored or not, and to label the edges as discovery edges or back\nedges. This mechanism will require additional space and may affect the running\ntime of the algorithm. A pseudo-code description of the recursive DFS algorithm\nisgiveninCodeFragment13.1.\nAlgorithmDFS(G,v):\nInput: AgraphGandavertexvofG\nOutput: Alabeling ofthe edges intheconnected component ofvasdiscovery\nedgesandbackedges\nlabelvasvisited\nforalledgeseinv.incidentEdges()do\nifedgeeisunvisited then\nw e.opposite(v)\n\u2190\nifvertexwisunexplored then\nlabeleasadiscoveryedge\nrecursively callDFS(G,w)\nelse\nlabeleasabackedge\nCodeFragment13.1: TheDFSalgorithm.\nThere are a number of observations that we can make about the depth-first\nsearchalgorithm,manyofwhichderivefromthewaytheDFSalgorithmpartitions\nthe edges of the undirected graph G into two groups, the discovery edges and the\nback edges. For example, since back edges always connect a vertex v to a pre-\nviously visited vertex u, each back edge implies a cycle in G, consisting of the\ndiscoveryedgesfromutovplusthebackedge(u,v).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 610 \u2014 #632\ni i\n610 Chapter13. GraphAlgorithms\nProposition 13.12: LetGbeanundirectedgraphonwhichaDFStraversalstart-\ningatavertexs hasbeenperformed. Thenthetraversalvisitsallverticesinthe\nconnectedcomponentofs,andthediscoveryedgesformaspanningtreeofthe\nconnectedcomponentofs.\nJustification: Supposethereisatleastonevertexvins\u2019sconnected component\nnotvisited,andletwbethefirstunvisitedvertexonsomepathfromstov(wemay\nhave v=w). Since w is the first unvisited vertex on this path, it has a neighbor u\nthat wasvisited. Butwhenwevisited u, wemusthave considered theedge (u,w);\nhence, it cannot be correct that w is unvisited. Therefore, there are no unvisited\nverticesins\u2019sconnected component.\nSinceweonlymarkedgeswhenwegotounvisitedvertices,wewillneverform\na cycle with discovery edges, that is, discovery edges form a tree. Moreover, this\nis a spanning tree because, as we have just seen, the depth-first search visits each\nvertexintheconnected componentofs.\nIntermsofitsrunningtime,depth-firstsearchisanefficientmethodfortravers-\ning a graph. Note that DFS is called exactly once on each vertex, and that every\nedge is examined exactly twice, once from each of its end vertices. Thus, if n\ns\nverticesandm edgesareintheconnectedcomponentofvertexs,aDFSstartingat\ns\nsrunsinO(n +m )time,providedthefollowingconditions aresatisfied:\ns s\nThe graph is represented by a data structure such that creating and iterat-\n\u2022\ningthroughthelistgeneratedbyv.incidentEdges()takesO(degree(v))time,\nand e.opposite(v) takes O(1) time. The adjacency list structure is one such\nstructure, buttheadjacency matrixstructureisnot.\nWehaveawayto\u201cmark\u201davertexoredgeasexplored, andtotestifavertex\n\u2022\nor edge has been explored in O(1) time. We discuss ways of implementing\nDFStoachievethisgoalinthenextsection.\nGiventheassumptions above,wecansolveanumberofinteresting problems.\nProposition 13.13: LetG beagraphwithn verticesandm edgesrepresented\nwithanadjacencylist.ADFStraversalofGcanbeperformedinO(n+m)time,\nandcanbeusedtosolvethefollowingproblemsinO(n+m)time:\nTestingwhetherGisconnected\n\u2022\nComputingaspanningtreeofG,ifGisconnected\n\u2022\nComputingtheconnectedcomponentsofG\n\u2022\nComputingapathbetweentwogivenverticesofG,ifitexists\n\u2022\nComputingacycleinG,orreportingthatGhasnocycles\n\u2022\nThe justification of Proposition 13.13 is based on algorithms that use slightly\nmodifiedversionsoftheDFSalgorithm assubroutines.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 611 \u2014 #633\ni i\n13.3. GraphTraversals 611\n13.3.2 Implementing Depth-First Search\nAswehavementionedabove,thedatastructureweusetorepresentagraphimpacts\ntheperformance oftheDFSalgorithm. Forexample,anadjacency listcanbeused\nto yield a running time of O(n+m) for traversing a graph with n vertices and m\nedges. Usinganadjacencymatrix,ontheotherhand,wouldresultinarunningtime\nof O(n2), since each of the n calls to the incidentEdges function would take O(n)\ntime. If the graph is dense, that is, it has close toO(n2)edges, then the difference\nbetween these two choices is minor, as they both would run in O(n2) time. But if\nthe graph is sparse, that is, it has close to O(n) edges, then the adjacency matrix\napproach wouldbemuchslowerthantheadjacency listapproach.\nAnotherimportantimplementationdetaildealswiththewayverticesandedges\narerepresented. Inparticular,weneedtohaveawayofmarkingverticesandedges\nasvisited ornot. Therearetwosimplesolutions, buteachhasdrawbacks.\nWecanbuildourvertexandedgeobjectstocontainavisitedfield,whichcan\n\u2022\nbe used by the DFS algorithm for marking. This approach is quite simple,\nand supports constant-time marking and unmarking, but it assumes that we\nare designing our graph with DFS in mind, which will not always be valid.\nFurthermore, this approach needlessly restricts DFS to graphs with vertices\nhavingavisitedfield. Thus,ifwewantagenericDFSalgorithmthatcantake\nanygraphasinput,thisapproachhaslimitations.\nWecanuseanauxiliaryhashtabletostorealltheexploredverticesandedges\n\u2022\nduring the DFS algorithm. This scheme is general, in that it does not re-\nquire anyspecial fieldsinthepositions ofthegraph. Butthisapproach does\nnotachieve worst-case constant timeformarking andunmarking ofvertices\nedges. Instead, such a hash table only supports the mark (insert) and test\n(find)operations inconstant expectedtime(seeSection9.2).\nFortunately, thereisamiddlegroundbetweenthesetwoextremes.\nThe Decorator Pattern\nMarking the explored vertices in a DFS traversal is an example of the decorator\nsoftware engineering design pattern. This pattern is used to add decorations (also\ncalled attributes) to existing objects. Each decoration is identified by a key iden-\ntifying this decoration and by a value associated with the key. The use of decora-\ntions is motivated by the need of some algorithms and data structures to add extra\nvariables,ortemporaryscratchdata,toobjectsthatdonotnormallyhavesuchvari-\nables. Hence, a decoration is a key-value pair that can be dynamically attached to\nan object. In our DFS example, we would like to have \u201cdecorable\u201d vertices and\nedgeswithavisited decoration andaBooleanvalue.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 612 \u2014 #634\ni i\n612 Chapter13. GraphAlgorithms\nMaking Graph Vertices Decorable\nWecanrealizethedecoratorpatternforanypositionbyallowingittobedecorated.\nThisallows ustoadd labels tovertices and edges, without requiring that weknow\ninadvancethekindsoflabelsthatwewillneed. Wesaythatanobjectisdecorable\nifitsupportsthefollowingfunctions:\nset(a,x): Setthevalueofattribute atox.\nget(a): Returnthevalueofattribute a.\nWe assume that Vertex and Edge objects of our graph ADT are decorable,\nwhere attribute keys are strings and attribute values are pointers to a generic ob-\njectclass,calledObject.\nAs an example of how this works, suppose that we want to mark vertices as\nbeing either visited or not visited by a search procedure. To implement this, we\ncould create two new instances of the Object class, and store pointers to these\nobjectsintwovariables,sayyesandno. Thevaluesoftheseobjectsareunimportant\ntous\u2014allwerequire istheability todistinguish between them. Letvbeanobject\nof type Decorator. To indicate that v is visited we invoke v.set(\"visited\",yes)\nandtoindicate that itwasnot visited weinvoke v.set(\"visited\",no). Inorder to\ntestthevalueofthisdecorator,weinvokev.get(\"visited\")andtesttoseewhether\ntheresultisyesorno. Thisisshowninthefollowingcodefragment.\nObject* yes = new Object; // decorator values\nObject* no = new Object;\nDecorator v; // a decorable object\n// ...\nv.set(\"visited\", yes); // set \u201cvisited\u201d attribute\n// ...\nif (v.get(\"visited\") == yes) cout << \"v was visited\";\nelse cout << \"v was not visited\";\nIn Code Fragment 13.2, wepresent aC++ implementation of class Decorator.\nItworksbycreatinganSTLmap(Section9.1.3),whosekeysarestringsandwhose\nvaluesareoftypeObject*.\nclass Decorator\n{\nprivate: // member data\nstd::map<string,Object*> map; // the map\npublic:\nObject* get(const string& a) // get value of attribute\nreturn map[a];\n{ }\nvoid set(const string& a, Object* d) // set value\nmap[a] = d;\n{ }\n;\n}\nCodeFragment13.2: AC++implementation ofclassDecorator.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 613 \u2014 #635\ni i\n13.3. GraphTraversals 613\nDFS Traversal using Decorable Positions\nUsingdecorable positions, thecomplete DFStraversal algorithm can bedescribed\nin more detail, as shown in Code Fragment 13.3. We create an attribute named\n\u201cstatus\u201d in which to record the status information about vertices and edges. This\nattribute maytakeononeoffourpossiblevalues: unvisited,visited,discovery,and\nback. Initially, all attribute values are assumed to have been set to unvisited. On\ntermination,edgeswillbelabeledasdiscoveryorback,dependingonwhetherthey\narediscoveryedgesorbackedges.\nAlgorithmDFS(G,v):\nInput: AgraphGwithdecorable vertices andedges, avertexvofG,suchthat\nallverticesandedgeshavebeendecorated withthestatusvalueofunvisited\nOutput: Adecoration ofthevertices oftheconnected component ofvwiththe\nvalue visited and of the edges in the connected component of v with values\ndiscovery andback,according toadepth-firstsearchtraversal ofG\nv.set(\"status\",visited)\nforalledgeseinv.incidentEdges()do\nife.get(\"status\")=unvisited then\nw e.opposite(v)\n\u2190\nifw.get(\"status\")=unvisited then\ne.set(\"status\",discovered)\nDFS(G,w)\nelse\ne.set(\"status\",back)\nCodeFragment13.3: DFSonagraphwithdecorable edgesandvertices.\n13.3.3 A Generic DFS Implementation in C++\nIn this section, we present a C++ implementation of a generic depth-first search\ntraversal by means of a class, called DFS. This class defines a recursive member\nfunction, dfsTraversal(v), which performs a DFStraversal of the graph starting at\nvertex v. The behavior of the traversal function can be specialized for a particular\napplication by redefining anumber of functions, which are invoked in response to\nvariouseventsthatariseinthetraversal.\nWeassume thatthevertices and edgesaredecorable positions andusedecora-\ntions todetermine whethervertices andedges havebeen visited. Thegeneric DFS\nclasscontainsthefollowingvirtualfunctions,whichmaybeoverriddenbyconcrete\nsubclasses toaffectadesired behavior:\nstartVisit(v): calledatthestartofthevisitofv\n\u2022\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 614 \u2014 #636\ni i\n614 Chapter13. GraphAlgorithms\ntraverseDiscovery(e,v): calledwhenadiscoveryedgeeoutofvistraversed\n\u2022\ntraverseBack(e,v): calledwhenabackedgeeoutofvistraversed\n\u2022\nisDone(): calledtodeterminewhethertoendthetraversalearly\n\u2022\nfinishVisit(v): calledwhenwearefinishedexploring fromv\n\u2022\nThe class DFS is presented in Code Fragment 13.4. The class is templated\nwith the graph type G. It begins with a number of convenience type definitions to\nallowustoaccesselementsoftheunderlying graphtypemoresuccinctly. Wehave\nomittedsomeofthetypedefinitions, suchasVertexList,EdgeList,VertexItor, and\nEdgeItor. This is followed by the member data of the class, which consists of a\nreference tothegraph, thevertexatwhichthedepth-first traversal begins, andtwo\ndecorator objects yes and no, which will be used in decorating vertices and edges.\nTheiractualvaluesareirrelevant,aslongaswecandistinguish onefromtheother.\ntemplate <typename G>\nclass DFS // generic DFS\n{\nprotected: // local types\ntypedef typename G::Vertex Vertex; // vertex position\ntypedef typename G::Edge Edge; // edge position\n// ...insert other typename shortcuts here\nprotected: // member data\nconst G& graph; // the graph\nVertex start; // start vertex\nObject *yes, *no; // decorator values\nprotected: // member functions\nDFS(const G& g); // constructor\nvoid initialize(); // initialize a new DFS\nvoid dfsTraversal(const Vertex& v); // recursive DFS utility\n// overridden functions\nvirtual void startVisit(const Vertex& v) // arrived at v\n{}\n// discovery edge e\nvirtual void traverseDiscovery(const Edge& e, const Vertex& from)\n{}\n// back edge e\nvirtual void traverseBack(const Edge& e, const Vertex& from)\n{}\nvirtual void finishVisit(const Vertex& v) // finished with v\n{}\nvirtual bool isDone() const return false; // finished?\n{ }\n// ...insert marking utilities here\n;\n}\nCodeFragment13.4: Agenericimplementation ofdepth-first search.\nTheclass\u2019smemberfunctionsareallprotected. Theyareinvokedonlybypublic\nmembersofthederivedsubclasses. Thesememberfunctionsincludeaconstructor,\naninitialization function,andthegenericDFStraversalfunction. Thereareanum-\nber of virtual functions corresponding to each of the above operations, which are\noverridden bysubclasses ofclassDFS.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 615 \u2014 #637\ni i\n13.3. GraphTraversals 615\nWe specify whether vertices and edges have been visited during the traversal\nthroughcallstothemarkingutilityfunctionsvisit,unvisit,andisVisited,whichare\nshowninCodeFragment13.5.\nprotected: // marking utilities\nvoid visit(const Vertex& v) v.set(\"visited\", yes);\n{ }\nvoid visit(const Edge& e) e.set(\"visited\", yes);\n{ }\nvoid unvisit(const Vertex& v) v.set(\"visited\", no);\n{ }\nvoid unvisit(const Edge& e) e.set(\"visited\", no);\n{ }\nbool isVisited(const Vertex& v) return v.get(\"visited\") == yes;\n{ }\nbool isVisited(const Edge& e) return e.get(\"visited\") == yes;\n{ }\nCodeFragment13.5: Vertexandedgemarkingutilities, whicharepartofDFS.\nIn Code Fragment 13.6, we present the class constructor and a function that\nperforms initializations before the DFS traversal is performed. (We present the\nexternal member functions using the condensed notation, which we introduced in\nSection 9.2.7.) The constructor initializes the graph reference and allocates the\ngeneric objects yes and no, which are used by the marking utilities. (Eventually,\nthese are deallocated by the class destructor, which wehave omitted.) The initial-\nizationfunction marksallvertices andedgesas\u201cunvisited.\u201d\n/* DFS G :: */ // constructor\nh i\nDFS(const G& g)\n: graph(g), yes(new Object), no(new Object)\n{}\n/* DFS G :: */ // initialize a new DFS\nh i\nvoid initialize()\n{\nVertexList verts = graph.vertices();\nfor (VertexItor pv = verts.begin(); pv != verts.end(); ++pv)\nunvisit(*pv); // mark vertices unvisited\nEdgeList edges = graph.edges();\nfor (EdgeItor pe = edges.begin(); pe != edges.end(); ++pe)\nunvisit(*pe); // mark edges unvisited\n}\nCodeFragment13.6: Theclassconstructor forDFSandtheinitialization function.\nTherecursive DFStraversal function ispresented inCodeFragment13.7. The\nfunction follows the same structure as presented in Code Fragment 13.3. Note,\nhowever, the introduction of calls to the virtual functions startVisit, isDone, tra-\nverseDiscovery, traverseBack, and finishVisit. These have not yet been specified,\nbuttheirdefinitions determinetheconcrete behavior ofthetraversal process.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 616 \u2014 #638\ni i\n616 Chapter13. GraphAlgorithms\n/* DFS G :: */ // recursive traversal\nh i\nvoid dfsTraversal(const Vertex& v)\n{\nstartVisit(v); visit(v); // visit v and mark visited\nEdgeList incident = v.incidentEdges();\nEdgeItor pe = incident.begin();\nwhile (!isDone() && pe != incident.end()) // visit v\u2019s incident edges\n{\nEdge e = *pe++;\nif (!isVisited(e)) // discovery edge?\n{\nvisit(e); // mark it visited\nVertex w = e.opposite(v); // get opposing vertex\nif (!isVisited(w)) // unexplored?\n{\ntraverseDiscovery(e, v); // let\u2019s discover it\nif (!isDone()) dfsTraversal(w); // continue traversal\n}\nelse traverseBack(e, v); // process back edge\n}\n}\nif (!isDone()) finishVisit(v); // finished with v\n}\nCodeFragment13.7: The function dfsTraversal, which implements ageneric DFS\ntraversal.\nUsing the Template Method Pattern for DFS\nIntheremainder ofthis section, weillustrate anumber ofconcrete applications of\nourgenericDFStraversal. Inordertodoanythinginteresting,wemustextendDFS\nand redefine some of its auxiliary functions. This is an example of the template\nmethod pattern (see Section 7.3.7), in which a generic computation mechanism is\nspecialized byproviding concrete implementations ofcertaingenericsteps.\nOur first example is the class Components, which counts the number of con-\nnected components of a graph. The class is presented in Code Fragment 13.8.\nObserve that this class is derived from DFS, and so inherits its members. The\nComponentsclasscontainsasingledatamember,whichisacounternComponents\nofthenumberofconnected components ithasencountered.\ntemplate <typename G>\nclass Components : public DFS<G> // count components\n{\nprivate:\nint nComponents; // num of components\npublic:\nComponents(const G& g): DFS<G>(g) // constructor\n{}\nint operator()(); // count components\n;\n}\nCodeFragment13.8: TheclassComponents,whichextendstheDFSclassinorder\ntocountthenumberofcomponents ofagraphbyoverloading the\u201c()\u201doperator.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 617 \u2014 #639\ni i\n13.3. GraphTraversals 617\nThe class provides a simple constructor, which simply invokes the constructor\nforthebaseclassbypassingitthegraph. Inordertodefinethecomponentcounting\nfunction, we have overloaded the \u201c()\u201d operator. This overloaded function returns\nthe number of components. This means that, given a graph G, we can declare a\nComponentsobjects andinvoke itasfollows:\nComponents components(G); // declare a Components object\nint nc = components(); // compute the number of components\nThe function that computes the number of connected components is shown in\nCodeFragment13.9. Afterinitializing (byinvoking theDFSmemberfunctionini-\ntializeandsettingthecomponentcountertozero),ititeratesthroughtheverticesof\nthegraph. Wheneveritfindsanunvisitedvertex,itinvokestheDFStraversalonthis\nvertex and increments the component counter. The DFS traversal returns only af-\ntereveryvertexofthisconnected component hasbeenvisited (Proposition 13.12).\nTherefore,anyunvisitedvertexmustlieinadifferentcomponent. Byrepeatingthis\noneveryunvisitedvertex,eventuallyeveryconnectedcomponentwillbefoundand\ncounted.\n/* Components G :: */ // count components\nh i\nint operator()()\n{\ninitialize(); // initialize DFS\nnComponents = 0; // init vertex count\nVertexList verts = graph.vertices();\nfor (VertexItor pv = verts.begin(); pv != verts.end(); ++pv)\n{\nif (!isVisited(*pv)) // not yet visited?\n{\ndfsTraversal(*pv); // visit\nnComponents++; // one more component\n}\n}\nreturn nComponents;\n}\nCode Fragment 13.9: The overloaded () operator for class Components, which\ncomputesthenumberofconnected components ofagraph.\nOurnextexampleisclassFindPath,whichfindsapathbetweenagivensource\nvertexandtargetvertex. TheclassispresentedinCodeFragment13.10. Theclass\u2019s\nmember data consists of the vertex list forming the path (path), the target vertex\n(target), and a boolean variable indicating whether the search is complete (done).\nLike before, the principal path finding function has been defined by overloading\nthe\u201c()\u201doperator. Thisfunctionisgiventhesourcevertexsandtargetvertext,and\nreturns the path as a list of vertices from s tot. If there is no such path, an empty\nlist is returned. Also like before, to use this class, we first create a new FindPath\nobject,sayfindPath,andthenweinvokefindPath(s,t),forthedesiredsourcevertex\nsandtargetvertext.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 618 \u2014 #640\ni i\n618 Chapter13. GraphAlgorithms\ntemplate <typename G>\nclass FindPath : public DFS<G> // find a path by DFS\n{\nprivate: // local data\nVertexList path; // the path\nVertex target; // the target vertex\nbool done; // is target found?\nprotected: // overridden functions\nvoid startVisit(const Vertex& v); // visit vertex\nvoid finishVisit(const Vertex& v); // finished with vertex\nbool isDone() const; // done yet?\npublic:\nFindPath(const G& g) : DFS<G>(g) // constructor\n{}\n// find path from s to t\nVertexList operator()(const Vertex& s, const Vertex& t);\n;\n}\nCodeFragment13.10: TheclassFindPath,whichextendstheDFSclassinorderto\ncomputeapathfromsourcevertexstotargetvertext.\nThe path function is presented in Code Fragment 13.11. After initializing\nsearchandthememberdata,itinvokestherecursiveDFStraversal. Ontermination,\nthevertexlistcontaining thepathisreturned.\n/* FindPath G :: */ // find path from s to t\nh i\nVertexList operator()(const Vertex& s, const Vertex& t)\n{\ninitialize(); // initialize DFS\npath.clear(); // clear the path\ntarget = t; // save the target\ndone = false;\ndfsTraversal(s); // traverse starting at s\nreturn path; // return the path\n}\nCodeFragment13.11:Theoverloaded()operatorforclassFindPath,whichreturns\napathfromstot.\nTheapproachistoperformadepth-firstsearchtraversalbeginningatthesource\nvertex. We maintain the path of discovery edges from the source to the current\nvertex. Whenweencounter anunexplored vertex, weaddittotheendofthepath.\nThisisprocessed byoverriding thefunction startVisit. Whenwefinishprocessing\navertex,weremoveitfromthepath. ThisisdonebyoverridingfunctionfinishVisit.\nThus,atanypoint,thevertexlistconsistsofverticesalongthepathoftheDFStree\nfrom the source to the current vertex. The traversal is terminated when the target\nvertex is encountered. This is done by setting the boolean flag done. We override\nthe function isDoneto check forthis event. Theseoverridden functions are shown\ninCodeFragment13.12.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 619 \u2014 #641\ni i\n13.3. GraphTraversals 619\n/* FindPath G :: */ // visit vertex\nh i\nvoid startVisit(const Vertex& v)\n{\npath.push back(v); // insert into path\nif (v == target) done = true; // reached target vertex\n}\n/* FindPath G :: */ // finished with vertex\nh i\nvoid finishVisit(const Vertex& v)\nif (!done) path.pop back(); // remove last vertex\n{ }\n/* FindPath G :: */ // done yet?\nh i\nbool isDone() const\nreturn done;\n{ }\nCodeFragment13.12: Theoverridden functions usedbyclassFindPath.\nOur final example is class FindCycle, which finds a cycle in the connected\ncomponent of a given start vertex s. (The cycle need not contain s.) The class is\ngiveninCodeFragment13.13. Itsmemberdataconsistsoftheedgelistcontaining\nthe cycle (cycle), the first vertex of the cycle (cycleStart), and a boolean variable\nthatindicateswhetherthesearchiscomplete(done). Thecyclefunctionisgivenby\noverloading the \u201c()\u201d operator and passing in the start vertex s. It returns the cycle\nasalistofedges. Ifthereisnosuchcycle,anemptylistisreturned.\ntemplate <typename G>\nclass FindCycle : public DFS<G>\n{\nprivate: // local data\nEdgeList cycle; // cycle storage\nVertex cycleStart; // start of cycle\nbool done; // cycle detected?\nprotected: // overridden functions\nvoid traverseDiscovery(const Edge& e, const Vertex& from);\nvoid traverseBack(const Edge& e, const Vertex& from);\nvoid finishVisit(const Vertex& v); // finished with vertex\nbool isDone() const; // done yet?\npublic:\nFindCycle(const G& g) : DFS<G>(g) // constructor\n{}\nEdgeList operator()(const Vertex& s); // find a cycle\n;\n}\nCodeFragment13.13: The class FindCycle, which extends the DFS class in order\ntocomputeacycleintheconnected component ofagivenstartvertexs.\nThecycle finding function ispresented in Code Fragment 13.14. After initial-\nizing search and the member data, it invokes the recursive DFS traversal. As we\nshow below, upon termination, the edge list consists of an initial prefix of edges\nfromstothevertexcycleStart,followedbytheedgesofthecycle. Wetraverse the\nedges of the cycle and remove each until reaching the first edge that is incident to\ncycleStart.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 620 \u2014 #642\ni i\n620 Chapter13. GraphAlgorithms\n/* FindCycle G :: */ // find a cycle\nh i\nEdgeList operator()(const Vertex& s)\n{\ninitialize(); // initialize DFS\ncycle = EdgeList(); done = false; // initialize members\ndfsTraversal(s); // do the search\nif (!cycle.empty() && s != cycleStart) // found a cycle?\n{\nEdgeItor pe = cycle.begin();\nwhile (pe != cycle.end()) // search for prefix\n{\nif ((pe++) >isIncidentOn(cycleStart)) break; // last edge of prefix?\n\u2212\n}\ncycle.erase(cycle.begin(), pe); // remove prefix\n}\nreturn cycle; // return the cycle\n}\nCodeFragment13.14: ThefunctionofclassFindCycle,whichcomputes thecycle.\nOurapproachisbasedonperformingaDFStraversalandstoringthediscovery\nedges in the edge list. As shown in Code Fragment 13.15, in traverseDiscovery,\nwepushthecurrentedgeontotheedgelist. InthefunctiontraverseBack,whenwe\nencounter a back edge we complete a cycle and set the boolean flag done to true\nto indicate that the cycle has been detected. We also set the variable cycleStart to\nthe vertex on the opposite side of the back edge. When backing out of a vertex,\nasshown inthefunction finishVisit,wepop the mostrecent edge off theedge list,\nunlessthecyclehasbeenfound.\n/* FindCycle G :: */ // discovery edge e\nh i\nvoid traverseDiscovery(const Edge& e, const Vertex& from)\nif (!done) cycle.push back(e); // add edge to list\n{ }\n/* FindCycle G :: */ // back edge e\nh i\nvoid traverseBack(const Edge& e, const Vertex& from)\n{\nif (!done) // no cycle yet?\n{\ndone = true; // cycle now detected\ncycle.push back(e); // insert final edge\ncycleStart = e.opposite(from); // save starting vertex\n}\n}\n/* FindCycle G :: */ // finished with vertex\nh i\nvoid finishVisit(const Vertex& v)\n{\nif (!cycle.empty() && !done) // not building a cycle?\ncycle.pop back(); // remove this edge\n}\n/* FindCycle G :: */ // done yet?\nh i\nbool isDone() const\nreturn done;\n{ }\nCodeFragment13.15: Theoverriddenfunctions usedbyclassFindCycle.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 621 \u2014 #643\ni i\n13.3. GraphTraversals 621\n13.3.4 Polymorphic Objects and Decorator Values \u22c6\nProgramming decorations that support multiple value types poses an interesting\nprobleminC++. Toillustratetheproblem,letussupposethatwewishtoimplement\nanalgorithmthatassociates astringwithapersonsnameandanintegercontaining\nthepersons current age witheach vertex ofasocial network. Givenavertex v, we\nwouldliketoassociate itwithtwodecorators, onefornameandoneforage.\nv.set(\"name\", \"Bob\");\nv.set(\"age\", 23);\nC++\u2019sstrongtypecheckingdoesnotallowthis,however,sincewemustspecifythe\ntypeoftheattributevalue, eitherstringorint,butnotboth.\nTosolvethisproblem,wecreateapolymorphicvaluetype(Section2.2.2). We\ndefine a generic class, called Object, and we derive subclasses from this. Each\nsubclass is specialized to store a single value of a particular type, for example,\nbool, char, int, or string. To make this more concrete, let us consider a simple\nexampleforjusttwotypes,intandstring. Itisstraightforward togeneralize thisto\nothertypes,evenuser-defined types.\nOur generic Object class is shown in Code Fragment 13.16. It has no data\nmembers, but it supports two member functions, intValue and stringValue. The\nfirst returns the value from an integer subclass and the second returns the value\nfrom a string subclass. An attempt to extract a string value from an integer object\noranintegervaluefromastringargumentresultsinanexception beingthrown.\nclass Object // generic object\n{\npublic:\nint intValue() const throw(BadCast);\nstring stringValue() const throw(BadCast);\n;\n}\nCode Fragment 13.16: A generic class, called Object, for storing a polymorphic\nobjectoftypeintorstring.\nNext,wederivetwoconcretesubclasses fromObject. Thefirst,calledInteger,\nstores a single integer, and the second, called String, stores a single STL string.\nTheseareshowninCodeFragment13.17. Inadditiontoasimpleconstructor, they\neachprovideamemberfunction getValue,whichreturnsthestoredvalue.\nFinally,wedefinethememberfunctions intValueandstringValueofclassOb-\nject. We show only intValue in Code Fragment 13.18 (stringValue is analogous).\nThis function assumes that the underlying object is a pointer to an Integer. It at-\ntempts to dynamically cast itself to an Integer pointer. If successful, it returns the\nresulting integervalue. Ifnot,anexception isthrown.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 622 \u2014 #644\ni i\n622 Chapter13. GraphAlgorithms\nclass Integer : public Object class String : public Object\n{ {\nprivate: private:\nint value; string value;\npublic: public:\nInteger(int v = 0) : value(v) String(string v = \"\") : value(v)\n{ } { }\nint getValue() const string getValue() const\nreturn value; return value;\n{ } { }\n; ;\n} }\nCodeFragment13.17: Concretesubclasses, IntegerandString,forstoring asingle\nintegerandasinglestring,respectively.\nint Object::intValue() const throw(BadCast) // cast to Integer\n{\nconst Integer* p = dynamic cast<const Integer*>(this);\nif (p == NULL) throw BadCast(\"Illegal attempt to cast to Integer\");\nreturn p >getValue();\n\u2212\n}\nCode Fragment 13.18: The member function intValue of class Object, which re-\nturnstheunderlying integervalue.\nToshowhowtoapplythisusefulpolymorphicobject,letusreturntoourearlier\nexample. Recallthatvisavertextowhichwewanttoassigntwoattributes,aname\nand an age. We create new entities, the first of type Stringand the second of type\nInteger. Weinitialize each withthedesired value. Because these aresubclasses of\nObject,wemaystoretheseentitiesasdecoratorsasshowninCodeFragment13.19.\nDecorator v; // a decorable object\nv.set(\"name\", new String(\"Bob\")); // store name as \u201cBob\u201d\nv.set(\"age\", new Integer(23)); // store age as 23\n// ...\nstring n = v.get(\"name\") >stringValue(); // n = \u201cBob\u201d\n\u2212\nint a = v.get(\"age\") >intValue(); // a = 23\n\u2212\nCodeFragment13.19: ExampleuseofObjectwithapolymorphic dictionary.\nWhenweextractthevaluesofthesedecorators,wemakeuseofthefactthatwe\nknow that the name is a string, and the age is an integer. Thus, we may apply the\nappropriate function,stringValueorintValue,toextractthedesiredattributevalue.\nThisexampleshowstheusefulness ofpolymorphic behavior ofobjectsinC++.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 623 \u2014 #645\ni i\n13.3. GraphTraversals 623\n13.3.5 Breadth-First Search\nIn this section, we consider a different traversal algorithm, called breadth-first\nsearch (BFS). Like DFS, BFS traverses a connected component of a graph, and\ninso doing itdefines auseful spanning tree. BFSisless \u201cadventurous\u201d than DFS,\nhowever. Instead of wandering the graph, BFSproceeds in rounds and subdivides\ntheverticesintolevels. BFScanalsobethoughtofasatraversalusingastringand\npaint,withBFSunrolling thestringinamoreconservative manner.\nBFSstartsatvertexs,whichisatlevel0anddefinesthe\u201canchor\u201dforourstring.\nIn the first round, we let out the string the length of one edge and we visit all the\nverticeswecanreachwithoutunrollingthestringanyfarther. Inthiscase,wevisit,\nandpaintas\u201cvisited,\u201d thevertices adjacent tothestartvertexs\u2014these vertices are\nplaced into level 1. In the second round, we unroll the string the length of two\nedges and we visit all the new vertices we can reach without unrolling our string\nany farther. These new vertices, which are adjacent to level 1 vertices and not\npreviouslyassignedtoalevel,areplacedintolevel2,andsoon. TheBFStraversal\nterminateswheneveryvertexhasbeenvisited.\nPseudo-code foraBFSstartingatavertexsisshowninCodeFragment13.20.\nWe use auxiliary space to label edges, mark visited vertices, and store collections\nassociated with levels. That is, the collections L , L , L , and so on, store the\n0 1 2\nvertices that are in level 0, level 1, level 2, and so on. These collections could, for\nexample,beimplementedasqueues. TheyalsoallowBFStobenonrecursive.\nAlgorithmBFS(s):\ninitializecollection L tocontainvertexs\n0\ni 0\n\u2190\nwhileL isnotemptydo\ni\ncreatecollection L toinitiallybeempty\ni+1\nforallverticesvinL do\ni\nforalledgeseinv.incidentEdges()do\nifedgeeisunexplored then\nw e.opposite(v)\n\u2190\nifvertexwisunexplored then\nlabeleasadiscovery edge\ninsertwintoL\ni+1\nelse\nlabeleasacrossedge\ni i+1\n\u2190 CodeFragment13.20: TheBFSalgorithm.\nWeillustrate aBFStraversal inFigure13.7.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 624 \u2014 #646\ni i\n624 Chapter13. GraphAlgorithms\n(a) (b)\n(c) (d)\n(e) (f)\nFigure 13.7: Example of breadth-first search traversal, where the edges incident\non a vertex are explored by the alphabetical order of the adjacent vertices. The\ndiscovery edges are shown with solid lines and the cross edges are shown with\ndashed lines: (a) graph before the traversal; (b) discovery of level 1; (c) discovery\noflevel2;(d)discoveryoflevel3;(e)discoveryoflevel4;(f)discoveryoflevel5.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 625 \u2014 #647\ni i\n13.3. GraphTraversals 625\nOne ofthe nice properties of the BFSapproach isthat, in performing the BFS\ntraversal, wecan label each vertex by thelength ofashortest path (interms ofthe\nnumber of edges) from the start vertex s. In particular, if vertex v is placed into\nlevel i by a BFS starting at vertex s, then the length of a shortest path from s to v\nisi.\nAswith DFS,we can visualize the BFStraversal by orienting the edges along\nthedirection inwhichtheyareexploredduringthetraversal, andbydistinguishing\nthe edges used to discover new vertices, called discovery edges, from those that\nlead to already visited vertices, called cross edges. (See Figure 13.7(f).) As with\nthe DFS,the discovery edges form a spanning tree, which in this case we call the\nBFS tree. We do not call the nontree edges \u201cback edges\u201d in this case, however,\nbecausenoneofthemconnectsavertextooneofitsancestors. Everynontreeedge\nconnects avertexvtoanothervertexthatisneitherv\u2019sancestornoritsdescendent.\nThe BFS traversal algorithm has a number of interesting properties, some of\nwhichweexploreintheproposition thatfollows.\nProposition 13.14: LetGbeanundirectedgraphonwhichaBFStraversalstart-\ningatvertexshasbeenperformed.Then\nThetraversalvisitsallverticesintheconnectedcomponentofs\n\u2022\nThediscovery-edgesformaspanningtreeT,whichwecalltheBFStree,of\n\u2022\ntheconnectedcomponentofs\nForeachvertexvatleveli,thepathoftheBFStreeT betweensandvhasi\n\u2022\nedges,andanyotherpathofGbetweensandvhasatleastiedges\nIf(u,v)isanedgethatisnotintheBFStree,thenthelevelnumbersofuand\n\u2022\nvdifferbyatmost1\nWeleavethejustificationofthisproposition asanexercise(ExerciseC-13.13).\nTheanalysisoftherunningtimeofBFSissimilartotheoneofDFS,whichimplies\nthefollowing.\nProposition 13.15: LetG beagraphwithn verticesandm edgesrepresented\nwiththeadjacencyliststructure.ABFStraversalofGtakesO(n+m)time.Also,\nthereexistO(n+m)-timealgorithmsbasedonBFSforthefollowingproblems:\nTestingwhetherGisconnected\n\u2022\nComputingaspanningtreeofG,ifGisconnected\n\u2022\nComputingtheconnectedcomponentsofG\n\u2022\nGivenastartvertexsofG,computing,foreveryvertexvofG,apathwith\n\u2022\ntheminimumnumberofedgesbetweens andv,orreportingthatnosuch\npathexists\nComputingacycleinG,orreportingthatGhasnocycles\n\u2022\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 626 \u2014 #648\ni i\n626 Chapter13. GraphAlgorithms\n13.4 Directed Graphs\nInthissection,weconsiderissuesthatarespecifictodirectedgraphs. Recallthata\ndirected graph(digraph), isagraphwhoseedgesarealldirected.\nMethods Dealing with Directed Edges\nInordertoallowsomeoralltheedgesinagraphtobedirected,weaddthefollow-\ningfunctions tothegraphADT.\ne.isDirected(): Testwhetheredgeeisdirected.\ne.origin(): Returntheoriginvertexofedgee.\ne.dest(): Returnthedestination vertexofedgee.\ninsertDirectedEdge(v,w,x): Insertandreturnanewdirectededgewithoriginvand\ndestination wandstoringelementx.\nAlso,ifanedgeeisdirected,thefunctione.endVertices()shouldreturnavertexlist\nwhosefirstelement istheorigin ofe, andwhosesecond element isthedestination\nof e. The running time for the functions e.isDirected(), e.origin(), and e.dest()\nshould be O(1), and the running time of the function insertDirectedEdge(v,w,x)\nshouldmatchthatofundirected edgeinsertion.\nReachability\nOne of the most fundamental issues with directed graphs is the notion of reacha-\nbility, which deals with determining which vertices can be reached by a path in a\ndirected graph. A traversal in a directed graph always goes along directed paths,\nthat is, paths where all the edges are traversed according to their respective direc-\ntions. Given vertices u and v of a digraph G, we say that u reaches v (and v is\nreachable fromu)ifGhasadirected pathfrom utov. Wealsosay thatavertex v\nreachesanedge(w,z)ifvreaches theoriginvertexwoftheedge.\nAdigraphGisstronglyconnectedifforanytwoverticesuandvofG,ureaches\nvandvreachesu. AdirectedcycleofGisacyclewherealltheedgesaretraversed\naccording to their respective directions. (Note that G may have a cycle consisting\noftwoedgeswithoppositedirection betweenthesamepairofvertices.) Adigraph\nGisacyclicifithasnodirected cycles. (SeeFigure13.8forsomeexamples.)\nThetransitiveclosureofadigraphGisthedigraphG\u2217suchthattheverticesof\nG\u2217 are the sameas the vertices ofG, and G\u2217 has an edge (u,v), whenever G has a\ndirected pathfromutov. Thatis,wedefineG\u2217 bystarting withthedigraph Gand\nadding inanextraedge (u,v)foreachuandvsuchthatvisreachable fromu(and\nthereisn\u2019talreadyanedge(u,v)inG).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 627 \u2014 #649\ni i\n13.4. DirectedGraphs 627\n(a) (b)\n(c) (d)\nFigure13.8: Examples of reachability in a digraph: (a) a directed path from BOS\nto LAX is drawn in blue; (b) a directed cycle (ORD, MIA, DFW, LAX, ORD) is\nshowninblue; itsvertices induce astrongly connected subgraph; (c)the subgraph\nof the vertices and edges reachable from ORD is shown in blue; (d) removing the\ndashedblueedgesgivesanacyclicdigraph.\nInteresting problems that dealwithreachability inadigraph Ginclude thefol-\nlowing:\nGivenverticesuandv,determinewhetherureachesv\n\u2022\nFindalltheverticesofGthatarereachable fromagivenvertexs\n\u2022\nDeterminewhetherGisstrongly connected\n\u2022\nDeterminewhetherGisacyclic\n\u2022\nComputethetransitive closureG\u2217 ofG\n\u2022\nIntheremainderofthissection, weexploresomeefficientalgorithmsforsolv-\ningtheseproblems.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 628 \u2014 #650\ni i\n628 Chapter13. GraphAlgorithms\n13.4.1 Traversing a Digraph\nAswithundirectedgraphs,wecanexploreadigraphinasystematicwaywithmeth-\nods akin to the depth-first search (DFS)and breadth-first search (BFS)algorithms\ndefinedpreviously forundirected graphs(Sections13.3.1and13.3.5). Suchexplo-\nrations can be used, for example, to answer reachability questions. The directed\ndepth-first search and breadth-first search methods we develop in this section for\nperforming such explorations are very similar to their undirected counterparts. In\nfact, theonlyrealdifference isthatthedirected depth-first search andbreadth-first\nsearchmethodsonlytraverseedgesaccording totheirrespective directions.\nThe directed version of DFS starting at a vertex v can be described by the re-\ncursivealgorithm inCodeFragment13.21. (SeeFigure13.9.)\nAlgorithmDirectedDFS(v):\nMarkvertexvasvisited.\nforeachoutgoing edge(v,w)ofvdo\nifvertexwhasnotbeenvisited then\nRecursively callDirectedDFS(w).\nCodeFragment13.21: TheDirectedDFSalgorithm.\n(a) (b)\nFigure13.9: DFSinadigraphstarting atvertexBOS:(a)intermediate step,where,\nfor the first time, an already visited vertex (DFW) is reached; (b) the completed\nDFS.Thetreeedgesareshownwithsolidbluelines,thebackedgesareshownwith\ndashed blue lines, and the forward and cross edges are shown with dashed black\nlines. Theorderinwhichtheverticesarevisitedisindicatedbyalabelnexttoeach\nvertex. Theedge(ORD,DFW)isabackedge,but(DFW,ORD)isaforwardedge.\nEdge(BOS,SFO)isaforwardedge,and(SFO,LAX)isacrossedge.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 629 \u2014 #651\ni i\n13.4. DirectedGraphs 629\nA DFS on a digraph G partitions the edges of G reachable from the starting\nvertex into tree edges or discovery edges, which lead us to discover a new vertex,\nand nontree edges, which take us to a previously visited vertex. The tree edges\nform a tree rooted at the starting vertex, called the depth-first search tree. There\narethreekindsofnontree edges:\nBackedges,whichconnect avertextoanancestor intheDFStree\n\u2022\nForwardedges, whichconnect avertextoadescendent intheDFStree\n\u2022\nCross edges, which connect a vertex to a vertex that is neither its ancestor\n\u2022\nnoritsdescendent\nReferbacktoFigure13.9(b)toseeanexampleofeachtypeofnontreeedge.\nProposition 13.16: LetG beadigraph. Depth-firstsearchonG startingata\nvertexs visitsalltheverticesofG thatarereachablefroms. Also,theDFStree\ncontainsdirectedpathsfromstoeveryvertexreachablefroms.\nJustification: Let V be the subset of vertices of G visited by DFS starting at\ns\nvertex s. We want to show that V contains s and every vertex reachable from s\ns\nbelongstoV . Supposenow,forthesakeofacontradiction, thatthereisavertexw\ns\nreachablefromsthatisnotinV . Consideradirectedpathfromstow,andlet(u,v)\ns\nbe the first edge on such a path taking us out ofV , that is, u is inV but v is not\ns s\ninV . When DFSreaches u, itexplores all the outgoing edges ofu, and thus must\ns\nalsoreachvertexvviaedge (u,v). Hence, vshould beinV ,andwehaveobtained\ns\nacontradiction. Therefore,V mustcontain everyvertexreachable froms.\ns\nAnalyzing the running time of the directed DFS method is analogous to that\nforitsundirected counterpart. Inparticular, arecursivecallismadeforeachvertex\nexactly once, and each edge is traversed exactly once (from its origin). Hence, if\nn vertices and m edges are reachable from vertex s, a directed DFS starting at s\ns s\nruns in O(n +m ) time, provided the digraph is represented with a data structure\ns s\nthat supports constant-time vertex and edge methods. The adjacency list structure\nsatisfiesthisrequirement, forexample.\nByProposition 13.16, wecanuseDFStofindalltheverticesreachable froma\ngivenvertex, andhencetofindthetransitive closure ofG. Thatis,wecanperform\naDFS,startingfromeachvertexvofG,toseewhichverticeswarereachablefrom\nv, adding an edge (v,w) to the transitive closure for each such w. Likewise, by\nrepeatedly traversing digraph GwithaDFS,starting inturnateachvertex, wecan\neasilytestwhetherGisstronglyconnected. Thatis,Gisstronglyconnectedifeach\nDFSvisitsalltheverticesofG.\nThus,wemayimmediately derivetheproposition thatfollows.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 630 \u2014 #652\ni i\n630 Chapter13. GraphAlgorithms\nProposition 13.17: LetGbeadigraphwithnverticesandmedges.Thefollow-\ningproblemscanbesolvedbyanalgorithmthattraversesG n timesusingDFS,\nrunsinO(n(n+m))time,andusesO(n)auxiliaryspace:\nComputing,foreachvertexvofG,thesubgraphreachablefromv\n\u2022\nTestingwhetherGisstronglyconnected\n\u2022\nComputingthetransitiveclosureG\u2217ofG\n\u2022\nTesting for Strong Connectivity\nActually,wecandetermineifadirectedgraphGisstronglyconnectedmuchfaster\nthan this, just by using two depth-first searches. We begin by performing a DFS\nof our directed graph G starting at an arbitrary vertex s. If there is any vertex of\nGthat isnot visited by this DFSand isnot reachable from s, then the graph is not\nstrongly connected. So, if this first DFS visits each vertex of G, then we reverse\nall the edges of G (using the reverseDirection function) and perform another DFS\nstarting at s in this \u201creverse\u201d graph. If every vertex of G is visited by this second\nDFS, then the graph is strongly connected because each of the vertices visited in\nthis DFS can reach s. Since this algorithm makes just two DFS traversals of G, it\nrunsinO(n+m)time.\nDirected Breadth-First Search\nAswithDFS,wecanextendbreadth-firstsearch(BFS)toworkfordirectedgraphs.\nThealgorithm still visits vertices level bylevel and partitions theset of edges into\ntreeedges(ordiscoveryedges). Togethertheseformadirectedbreadth-firstsearch\ntreerooted atthestartvertexandnontreeedges. Unlikethedirected DFSmethod,\nhowever, the directed BFS method only leaves two kinds of nontree edges: back\nedges, which connect avertex toone ofitsancestors, and cross edges, whichcon-\nnectavertextoanother vertexthatisneither itsancestor noritsdescendent. There\narenoforwardedges,whichisafactweexploreinanexercise(ExerciseC-13.9).\n13.4.2 Transitive Closure\nIn this section, we explore an alternative technique for computing the transitive\nclosure ofadigraph. LetGbeadigraph withnverticesandmedges. Wecompute\nthe transitive closure of G in a series of rounds. We initialize G =G. We also\n0\narbitrarilynumbertheverticesofGasv ,v ,...,v . Wethenbeginthecomputation\n1 2 n\nof the rounds, beginning with round 1. In ageneric round k, weconstruct digraph\nG startingwithG =G andaddtoG thedirectededge(v,v )ifdigraphG\nk k k\u22121 k i j k\u22121\ncontains both the edges (v,v ) and (v ,v ). In this way, we enforce a simple rule\ni k k j\nembodiedintheproposition thatfollows.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 631 \u2014 #653\ni i\n13.4. DirectedGraphs 631\nProposition 13.18: Fori=1,...,n,digraphG hasanedge(v,v )ifandonlyif\nk i j\ndigraphGhasadirectedpathfromv tov ,whoseintermediatevertices(ifany)are\ni j\nintheset v ,...,v .Inparticular,G isequaltoG\u2217,thetransitiveclosureofG.\n1 k n\n{ }\nProposition13.18suggestsasimplealgorithmforcomputingthetransitiveclo-\nsureofGthatisbased ontheseries ofrounds wedescribed above. Thisalgorithm\nis known as the Floyd-Warshall algorithm, and its pseudo-code is given in Code\nFragment13.22. Fromthispseudo-code, wecaneasilyanalyzetherunningtimeof\ntheFloyd-Warshall algorithm assuming thatthe datastructure representing Gsup-\nportsfunctionsisAdjacentToandinsertDirectedEdgeinO(1)time. Themainloop\nis executed n times and the inner loop considers each of O(n2) pairs of vertices,\nperformingaconstant-time computation foreachone. Thus,thetotalrunningtime\noftheFloyd-Warshall algorithm isO(n3).\nAlgorithmFloydWarshall(G):\nInput: Adigraph Gwithnvertices\nOutput: ThetransitiveclosureG\u2217 ofG\nletv ,v ,...,v beanarbitrary numberingoftheverticesofG\n1 2 n\nG G\n0\n\u2190\nfork 1tondo\n\u2190\nG G\nk k\u22121\n\u2190\nforalli,jin 1,...,n withi= jandi,j=kdo\n{ } 6 6\nifbothedges(v,v )and(v ,v )areinG then\ni k k j k\u22121\naddedge(v,v )toG (ifitisnotalready present)\ni j k\nreturnG\nn\nCode Fragment13.22: Pseudo-code for the Floyd-Warshall algorithm. This algo-\nrithmcomputesthetransitiveclosureG\u2217 ofGbyincrementally computing aseries\nofdigraphs G ,G ,...,G ,wherek=1,...,n.\n0 1 n\nThisdescription isactuallyanexampleofanalgorithmicdesignpatternknown\nasdynamicprogramming, whichisdiscussed inmoredetailinSection12.2. From\nthedescriptionandanalysisabove,wemayimmediatelyderivethefollowingpropo-\nsition.\nProposition 13.19: LetGbeadigraphwithnvertices,andletGberepresented\nbyadatastructurethatsupportslookupandupdateofadjacencyinformationin\nO(1)time.ThentheFloyd-WarshallalgorithmcomputesthetransitiveclosureG\u2217\nofGinO(n3)time.\nWeillustrate anexamplerunoftheFloyd-Warshall algorithm inFigure13.10.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 632 \u2014 #654\ni i\n632 Chapter13. GraphAlgorithms\n(a) (b)\n(c) (d)\n(e) (f)\nFigure13.10:SequenceofdigraphscomputedbytheFloyd-Warshallalgorithm: (a)\ninitial digraph G=G and numbering of the vertices; (b) digraph G ; (c) G ; (d)\n0 1 2\nG ;(e)G ;(f)G . (NotethatG =G =G .) IfdigraphG hastheedges(v,v )\n3 4 5 5 6 7 k\u22121 i k\nand(v ,v ),butnottheedge(v,v ). Inthedrawingofdigraph G ,weshowedges\nk j i j k\n(v,v )and(v ,v )withdashedbluelines,andedge(v,v )withathickblueline.\ni k k j i j\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 633 \u2014 #655\ni i\n13.4. DirectedGraphs 633\nPerformance of the Floyd-Warshall Algorithm\nThe running time of the Floyd-Warshall algorithm might appear to be slower than\nperforming a DFS of a directed graph from each of its vertices, but this depends\nupon the representation of the graph. If a graph is represented using an adjacency\nmatrix,thenrunningtheDFSmethodonceonadirected graphGtakesO(n2)time\n(we explore the reason for this in Exercise R-13.9). Thus, running DFS n times\ntakes O(n3)time, which isnobetter than asingle execution ofthe Floyd-Warshall\nalgorithm,buttheFloyd-Warshallalgorithmwouldbemuchsimplertoimplement.\nNevertheless, if the graph is represented using an adjacency list structure, then\nrunning the DFS algorithm n times would take O(n(n+m)) time to compute the\ntransitive closure. Even so, if the graph is dense, that is, if it has \u2126(n2) edges,\nthen this approach still runs in O(n3) time and is more complicated than a single\ninstance of the Floyd-Warshall algorithm. The only case where repeatedly calling\nthe DFS method is better is when the graph is not dense and is represented using\nanadjacencyliststructure.\n13.4.3 Directed Acyclic Graphs\nDirected graphs without directed cycles are encountered in many applications.\nSuch a digraph is often referred to as a directed acyclic graph, or DAG,for short.\nApplications ofsuchgraphsinclude thefollowing:\nInheritance betweenclassesofaC++program\n\u2022\nPrerequisites betweencourses ofadegreeprogram\n\u2022\nScheduling constraints betweenthetasksofaproject\n\u2022\nExample 13.20: Inordertomanagealargeproject,itisconvenienttobreakitup\nintoacollectionofsmallertasks. Thetasks,however,arerarelyindependent,be-\ncauseschedulingconstraintsexistbetweenthem.(Forexample,inahousebuilding\nproject,thetaskoforderingnailsobviouslyprecedesthetaskofnailingshingles\ntotheroofdeck.)Clearly,schedulingconstraintscannothavecircularities,because\ntheywouldmaketheprojectimpossible. (Forexample,inordertogetajobyou\nneedtohaveworkexperience,butinordertogetworkexperienceyouneedtohave\najob.) Theschedulingconstraintsimposerestrictionsontheorderinwhichthe\ntaskscanbeexecuted. Namely,ifaconstraintsaysthattaskamustbecompleted\nbeforetaskbisstarted,thenamustprecedebintheorderofexecutionofthetasks.\nThus,ifwemodelafeasiblesetoftasksasverticesofadirectedgraph,andwe\nplaceadirectededgefromvtowwheneverthetaskforvmustbeexecutedbefore\nthetaskforw,thenwedefineadirectedacyclicgraph.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 634 \u2014 #656\ni i\n634 Chapter13. GraphAlgorithms\nTheexampleabovemotivatesthefollowingdefinition. LetGbeadigraphwith\nn vertices. A topological ordering of G is an ordering v ,...,v of the vertices of\n1 n\nGsuchthat foreveryedge(v,v )ofG,i< j. Thatis, atopological ordering isan\ni j\norderingsuchthatanydirectedpathinGtraversesverticesinincreasingorder. (See\nFigure13.11.) Notethatadigraph mayhavemorethanonetopological ordering.\n(a) (b)\nFigure13.11: Twotopological orderings ofthesameacyclicdigraph.\nProposition 13.21: Ghasatopologicalorderingifandonlyifitisacyclic.\nJustification: The necessity (the \u201conly if\u201d part of the statement) is easy to\ndemonstrate. Suppose G is topologically ordered. Assume, for the sake of a con-\ntradiction, that G has a cycle consisting of edges (v ,v ),(v ,v ),...,(v ,v ).\ni0 i1 i1 i2 ik\u22121 i0\nBecauseofthetopological ordering, wemusthavei <i < <i <i ,which\n0 1 k\u22121 0\n\u00b7\u00b7\u00b7\nisclearlyimpossible. Thus,Gmustbeacyclic.\nWe now argue the sufficiency of the condition (the \u201cif\u201d part). Suppose G is\nacyclic. Wegiveanalgorithmic description ofhowtobuild atopological ordering\nfor G. Since G is acyclic, G must have a vertex with no incoming edges (that\nis, with in-degree 0). Let v be such a vertex. Indeed, if v did not exist, then in\n1 1\ntracingadirectedpathfromanarbitrarystartvertexwewouldeventuallyencounter\na previously visited vertex, thus contradicting the acyclicity of G. If we remove\nv from G, together with its outgoing edges, the resulting digraph is still acyclic.\n1\nHence, the resulting digraph also has a vertex with no incoming edges, and welet\nv be such a vertex. By repeating this process until the digraph becomes empty,\n2\nwe obtain an ordering v ,...,v of the vertices of G. Because of the construction\n1 n\nabove, if (v,v ) is an edge of G, then v must be deleted before v can be deleted,\ni j i j\nandthusi< j. Thus,v ,...,v isatopological ordering.\n1 n\nProposition13.21\u2019sjustificationsuggestsanalgorithm(CodeFragment13.23),\ncalledtopological sorting,forcomputingatopological ordering ofadigraph.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 635 \u2014 #657\ni i\n13.4. DirectedGraphs 635\nAlgorithmTopologicalSort(G):\nInput: Adigraph Gwithnvertices\nOutput: Atopological orderingv ,...,v ofG\n1 n\nS aninitially emptystack.\n\u2190\nforalluinG.vertices()do\nLetincounter(u)bethein-degreeofu.\nifincounter(u)=0then\nS.push(u)\ni 1\n\u2190\nwhile!S.empty()do\nu S.pop()\n\u2190\nLetubevertexnumberiinthetopological ordering.\ni i+1\n\u2190\nforalloutgoing edges(u,w)ofudo\nincounter(w) incounter(w) 1\n\u2190 \u2212\nifincounter(w)=0then\nS.push(w)\nCodeFragment13.23:Pseudo-codeforthetopologicalsortingalgorithm. (Weshow\nanexampleapplication ofthisalgorithm inFigure13.12.)\nProposition 13.22: LetGbeadigraphwithnverticesandmedges.Thetopolog-\nicalsortingalgorithmrunsinO(n+m)timeusingO(n)auxiliaryspace,andeither\ncomputesatopologicalorderingofGorfailstonumbersomevertices,whichindi-\ncatesthatGhasadirectedcycle.\nJustification: The initial computation of in-degrees and setup of the incounter\nvariables can be done with a simple traversal of the graph, which takes O(n+m)\ntime. Weusethedecorator patterntoassociate counter attributes withthevertices.\nSaythatavertexuisvisitedbythetopologicalsortingalgorithmwhenuisremoved\nfromthestackS. Avertexucanbevisitedonlywhenincounter(u)=0,whichim-\npliesthatallitspredecessors (verticeswithoutgoing edgesintou)werepreviously\nvisited. Asaconsequence, anyvertex that ison adirected cycle willnever be vis-\nited, and any other vertex willbe visited exactly once. Thealgorithm traverses all\nthe outgoing edges of each visited vertex once, so its running time is proportional\nto the number of outgoing edges of the visited vertices. Therefore, the algorithm\nrunsinO(n+m)time. Regardingthespaceusage,observethatthestackSandthe\nincounter variables attachedtotheverticesuseO(n)space.\nAsasideeffect,thetopologicalsortingalgorithmofCodeFragment13.23also\ntests whether the input digraph G is acyclic. Indeed, if the algorithm terminates\nwithout ordering all the vertices, then the subgraph of the vertices that have not\nbeenordered mustcontain adirectedcycle.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 636 \u2014 #658\ni i\n636 Chapter13. GraphAlgorithms\n(a) (b) (c)\n(d) (e) (f)\n(g) (h) (i)\nFigure 13.12: Example of a run of algorithm TopologicalSort (Code Frag-\nment 13.23): (a) initial configuration; (b\u2013i) after each while-loop iteration. The\nvertex labels show the vertex number and the current incounter value. The edges\ntraversed are shown with dashed blue arrows. Thick lines denote the vertex and\nedgesexaminedinthecurrentiteration.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 637 \u2014 #659\ni i\n13.5. ShortestPaths 637\n13.5 Shortest Paths\nAswesawinSection13.3.5, thebreadth-first search strategy canbeusedtofinda\nshortest pathfrom somestarting vertextoeveryothervertexinaconnected graph.\nThis approach makes sense in cases where each edge is as good as any other, but\nthere aremanysituations wherethis approach isnotappropriate. Forexample, we\nmightbeusingagraphtorepresent acomputernetwork(suchastheInternet), and\nwemightbeinterestedinfindingthefastestwaytorouteadatapacketbetweentwo\ncomputers. Inthiscase,itisprobablynotappropriateforalltheedgestobeequalto\neachother,sincesomeconnectionsinacomputernetworkaretypicallymuchfaster\nthanothers(forexample,someedgesmightrepresentslowphone-line connections\nwhile others might represent high-speed, fiber-optic connections). Likewise, we\nmight want to use a graph to represent the roads between cities, and we might be\ninterested infinding the fastest waytotravel cross country. Inthis case, itisagain\nprobably not appropriate for all the edges to be equal to each other, because some\ninter-city distances will likely be much larger than others. Thus, it is natural to\nconsider graphswhoseedgesarenotweightedequally.\n13.5.1 Weighted Graphs\nA weighted graph is a graph that has a numeric (for example, integer) label w(e)\nassociated witheachedgee,calledtheweightofedgee. Weshowanexampleofa\nweightedgraphinFigure13.13.\nFigure13.13: A weighted graph whose vertices represent major U.S. airports and\nwhose edge weights represent distances in miles. This graph has apath from JFK\ntoLAXoftotalweight2,777(goingthroughORDandDFW).Thisistheminimum\nweightpathinthegraphfromJFKtoLAX.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 638 \u2014 #660\ni i\n638 Chapter13. GraphAlgorithms\nDefining Shortest Paths in a Weighted Graph\nLet G be a weighted graph. The length (or weight) of a path is the sum of the\nweightsoftheedgesofP. Thatis,ifP=((v ,v ),(v ,v ),...,(v ,v )),thenthe\n0 1 1 2 k\u22121 k\nlengthofP,denoted w(P),isdefinedas\nk\u22121\n\u2211\nw(P)= w((v,v )).\ni i+1\ni=0\nThe distance from a vertex v to a vertex u in G, denoted d(v,u), is the length of a\nminimumlengthpath(alsocalledshortestpath)fromvtou,ifsuchapathexists.\nPeopleoftenusetheconventionthatd(v,u)=+ ifthereisnopathatallfrom\n\u221e\nv to u in G. Even if there is a path from v to u in G, the distance from v to u may\nnot be defined, however, if there is a cycle in G whose total weight is negative.\nFor example, suppose vertices in G represent cities, and the weights of edges in\nG represent how much money it costs to go from one city to another. If someone\nwerewilling to actually pay ustogo from say JFKtoORD,then the \u201ccost\u201d ofthe\nedge(JFK,ORD)wouldbenegative. Ifsomeone elsewerewillingtopayustogo\nfromORDtoJFK,thentherewouldbeanegative-weight cycleinGanddistances\nwould no longer be defined. That is, anyone could now build a path (with cycles)\nin G from any city A to another city B that first goes to JFK and then cycles as\nmany times as he or she likes from JFK to ORD and back, before going on to B.\nThe existence of such paths would allow us to build arbitrarily low negative-cost\npaths (and, in this case, make a fortune in the process). But distances cannot be\narbitrarily lownegativenumbers. Thus,anytimeweuseedgeweightstorepresent\ndistances, wemustbecarefulnottointroduce anynegative-weight cycles.\nSuppose weare given aweighted graph G, and weare asked to find ashortest\npathfromsomevertexvtoeachothervertexinG,viewingtheweightsontheedges\nas distances. In this section, we explore efficient ways of finding all such shortest\npaths, if they exist. The first algorithm we discuss is for the simple, yet common,\ncasewhenalltheedgeweightsinGarenonnegative(thatis,w(e) 0foreachedge\n\u2265\neofG); hence, weknow inadvance that there areno negative-weight cycles in G.\nRecallthatthespecialcaseofcomputingashortestpathwhenallweightsareequal\ntoonewassolvedwiththeBFStraversal algorithm presented inSection13.3.5.\nThere is an interesting approach for solving this single-source problem based\nonthegreedymethoddesignpattern(Section12.4.2). Recallthatinthispatternwe\nsolvetheproblemathandbyrepeatedlyselectingthebestchoicefromamongthose\navailableineachiteration. Thisparadigmcanoftenbeusedinsituations wherewe\naretrying tooptimize somecost function overacollection ofobjects. Wecan add\nobjects toourcollection, oneatatime, always picking the nextonethatoptimizes\nthefunction fromamongthoseyettobechosen.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 639 \u2014 #661\ni i\n13.5. ShortestPaths 639\n13.5.2 Dijkstra\u2019s Algorithm\nThe main idea behind applying the greedy method pattern to the single-source,\nshortest-path problem istoperform a\u201cweighted\u201d breadth-first search starting atv.\nInparticular, wecanusethegreedymethodtodevelopanalgorithmthatiteratively\ngrows a \u201ccloud\u201d of vertices out of v, with the vertices entering the cloud in order\nof their distances from v. Thus, in each iteration, the next vertex chosen is the\nvertex outside the cloud that is closest to v. The algorithm terminates when no\nmore vertices are outside the cloud, atwhich point wehave ashortest path from v\nto every other vertex of G. This approach is a simple, but nevertheless powerful,\nexampleofthegreedymethoddesignpattern.\nA Greedy Method for Finding Shortest Paths\nApplying thegreedy methodtothesingle-source, shortest-path problem, resultsin\nan algorithm known as Dijkstra\u2019s algorithm. When applied to other graph prob-\nlems,however, thegreedy methodmaynotnecessarily findthebestsolution (such\nasintheso-calledtravelingsalesmanproblem,inwhichwewishtofindtheshort-\nestpath thatvisits allthevertices inagraph exactly once). Nevertheless, there are\na number of situations in which the greedy method allows us to compute the best\nsolution. Inthis chapter, wediscuss twosuch situations: computing shortest paths\nandconstructing aminimumspanning tree.\nIn order to simplify the description of Dijkstra\u2019s algorithm, we assume, in the\nfollowing, thattheinputgraphGisundirected (thatis,allitsedgesareundirected)\nand simple (that is, it has no self-loops and no parallel edges). Hence, we denote\ntheedgesofGasunordered vertexpairs(u,z).\nInDijkstra\u2019salgorithmforfindingshortestpaths,thecostfunctionwearetrying\ntooptimizeinourapplication ofthegreedymethodisalsothefunctionthatweare\ntrying to compute\u2014the shortest path distance. This mayat first seem like circular\nreasoning untilwerealizethatwecanactuallyimplementthisapproach byusinga\n\u201cbootstrapping\u201dtrick,consistingofusinganapproximationtothedistancefunction\nwearetryingtocompute,whichintheendisequaltothetruedistance.\nEdge Relaxation\nLetus definealabel D[u]for each vertexuinV,whichweusetoapproximate the\ndistance in G from v to u. The meaning of these labels is that D[u] always stores\nthe length of the best path we have found so far from v to u. Initially, D[v]= 0\nand D[u]=+ for each u=v, and we define the setC (which is our \u201ccloud\u201d of\n\u221e 6\nvertices)toinitiallybetheemptyset . Ateachiterationofthealgorithm,weselect\n\u2205\na vertex u not inC with smallest D[u] label, and wepull u intoC. In the very first\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 640 \u2014 #662\ni i\n640 Chapter13. GraphAlgorithms\niteration wewill,ofcourse, pullvintoC. Onceanewvertexuispulled intoC,we\nthen update thelabel D[z]ofeach vertexzthatisadjacent touandisoutside ofC,\ntoreflectthefactthattheremaybeanewandbetterwaytogettozviau.\nThis update operation is known as a relaxation procedure, because it takes an\nold estimate and checks if it can be improved to get closer to its true value. (A\nmetaphor for why we call this a relaxation comes from a spring that is stretched\nout and then \u201crelaxed\u201d back to its true resting shape.) In the case of Dijkstra\u2019s al-\ngorithm,therelaxation isperformedforanedge(u,z)suchthatwehavecomputed\nanewvalueofD[u]andwishtoseeifthereisabettervalueforD[z]usingtheedge\n(u,z). Thespecificedgerelaxation operation isasfollows:\nEdgeRelaxation:\nifD[u]+w((u,z))<D[z]then\nD[z] D[u]+w((u,z))\n\u2190\nWe give the pseudo-code for Dijkstra\u2019s algorithm in Code Fragment 13.24.\nNotethatweuseapriority queueQtostoretheverticesoutsideofthecloudC.\nAlgorithmShortestPath(G,v):\nInput: A simple undirected weighted graph G with nonnegative edge weights\nandadistinguished vertexvofG\nOutput: A label D[u], for each vertex u of G, such that D[u] is the length of a\nshortest pathfromvtouinG\nInitializeD[v] 0andD[u] + foreachvertexu=v.\n\u2190 \u2190 \u221e 6\nLetapriorityqueueQcontain alltheverticesofGusingtheDlabelsaskeys.\nwhileQisnotemptydo\npullanewvertexuintothecloud\n{ }\nu Q.removeMin()\n\u2190\nforeachvertexzadjacenttousuchthatzisinQdo\nperformtherelaxation procedure onedge(u,z)\n{ }\nifD[u]+w((u,z))<D[z]then\nD[z] D[u]+w((u,z))\n\u2190\nChangetoD[z]thekeyofvertexzinQ.\nreturnthelabelD[u]ofeachvertexu\nCode Fragment 13.24: Dijkstra\u2019s algorithm for the single-source, shortest-path\nproblem.\nWe illustrate several iterations of Dijkstra\u2019s algorithm in Figures 13.14 and\n13.15.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 641 \u2014 #663\ni i\n13.5. ShortestPaths 641\n(a) (b)\n(c) (d)\n(e) (f)\nFigure13.14: Anexecution of Dijkstra\u2019s algorithm on aweighted graph. Thestart\nvertex is BWI. A box next to each vertex v stores the label D[v]. The symbol is\n\u2022\nused instead of + . The edges of the shortest-path tree are drawn as thick blue\n\u221e\narrows and, for each vertex u outside the \u201ccloud,\u201d we show the current best edge\nforpullinginuwithasolidblueline. (Continues inFigure13.15.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 642 \u2014 #664\ni i\n642 Chapter13. GraphAlgorithms\n(g) (h)\n(i) (j)\nFigure13.15: Anexampleexecution ofDijkstra\u2019s algorithm. (Continued fromFig-\nure13.14.)\nWhy It Works\nThe interesting, and possibly even a little surprising, aspect of the Dijkstra algo-\nrithm is that, at the moment a vertex u is pulled into C, its label D[u] stores the\ncorrect length ofashortest pathfrom vtou. Thus, whenthealgorithm terminates,\nit willhave computed the shortest-path distance from vto every vertex of G. That\nis,itwillhavesolvedthesingle-source, shortest-path problem.\nIt is probably not immediately clear why Dijkstra\u2019s algorithm correctly finds\nthe shortest path from the start vertex v to each other vertex u in the graph. Why\nis it that the distance from v to u is equal to the value of the label D[u] at the time\nvertex u is pulled into the cloudC (which is also the time u is removed from the\npriorityqueueQ)? Theanswertothisquestiondependsontherebeingnonegative-\nweight edges in the graph, since that allows the greedy method to work correctly,\nasweshowintheproposition thatfollows.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 643 \u2014 #665\ni i\n13.5. ShortestPaths 643\nProposition 13.23: InDijkstra\u2019salgorithm,wheneveravertexu ispulledinto\nthecloud,thelabelD[u]isequaltod(v,u),thelengthofashortestpathfromvtou.\nJustification: Suppose that D[t]>d(v,t) for some vertex t inV, and let u be\nthe first vertex the algorithm pulled into the cloud C (that is, removed from Q)\nsuch that D[u] > d(v,u). There is a shortest path P from v to u (for otherwise\nd(v,u)=+ =D[u]). Letusthereforeconsiderthemomentwhenuispulledinto\n\u221e\nC,and letzbethefirstvertexofP(whengoing from vtou)that isnotinC atthis\nmoment. Let y be the predecessor of z in path P (note that we could have y=v).\n(SeeFigure13.16.) Weknow,byourchoiceofz,thatyisalreadyinCatthispoint.\nMoreover, D[y]=d(v,y), since u is the first incorrect vertex. When y was pulled\nintoC,wetested(andpossiblyupdated) D[z]sothatwehadatthatpoint\nD[z] D[y]+w((y,z))=d(v,y)+w((y,z)).\n\u2264\nButsincezisthenextvertexontheshortest pathfromvtou,thisimpliesthat\nD[z]=d(v,z).\nButwearenowatthemomentwhenwepicku,notz,tojoinC;hence\nD[u] D[z].\n\u2264\nIt should be clear that a subpath of a shortest path is itself a shortest path. Hence,\nsincezisontheshortest pathfromvtou\nd(v,z)+d(z,u)=d(v,u).\nMoreover, d(z,u) 0becausetherearenonegative-weight edges. Therefore\n\u2265\nD[u] D[z]=d(v,z) d(v,z)+d(z,u)=d(v,u).\n\u2264 \u2264\nButthiscontradicts thedefinitionofu;hence,therecanbenosuchvertexu.\nFigure13.16: Aschematic forthejustification ofProposition 13.23.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 644 \u2014 #666\ni i\n644 Chapter13. GraphAlgorithms\nThe Running Time of Dijkstra\u2019s Algorithm\nInthissection, weanalyze thetimecomplexityofDijkstra\u2019s algorithm. Wedenote\nthe number of vertices and edges of the input graph G with n and m, respectively.\nWe assume that the edge weights can be added and compared in constant time.\nBecause of the high level of the description we gave for Dijkstra\u2019s algorithm in\nCodeFragment13.24,analyzingitsrunningtimerequiresthatwegivemoredetails\nonitsimplementation. Specifically,weshouldindicatethedatastructuresusedand\nhowtheyareimplemented.\nLet us first assume that we are representing the graph G using an adjacency\nlist structure. This data structure allows us to step through the vertices adjacent to\nu during the relaxation step in time proportional to their number. It still does not\nsettle allthedetails forthealgorithm, however, aswemustsaymoreabouthowto\nimplementtheotherprincipledatastructureinthealgorithm\u2014thepriorityqueueQ.\nAnefficient implementation of the priority queue Quses a heap (Section 8.3).\nThisallowsustoextract thevertex uwithsmallest Dlabel (call totheremoveMin\nfunction) in O(logn) time. As noted in the pseudo-code, each time we update a\nD[z] label we need to update the key of z in the priority queue. Thus, we actually\nneed a heap implementation of an adaptable priority queue (Section 8.4). If Q is\nan adaptable priority queue implemented as a heap, then this key update can, for\nexample, be done using the replace(e,k), where e is the entry storing the key for\nthevertexz. Ifeislocation aware,thenwecaneasilyimplementsuchkeyupdates\nin O(logn) time, since a location-aware entry for vertex z would allow Q to have\nimmediateaccesstotheentryestoringzintheheap(seeSection8.4.2). Assuming\nthisimplementation ofQ,Dijkstra\u2019salgorithm runsinO((n+m)logn)time.\nReferringbacktoCodeFragment13.24,thedetailsoftherunning-timeanalysis\nareasfollows:\nInserting all the vertices in Q with their initial key value can be done in\n\u2022\nO(nlogn)timebyrepeatedinsertions, orinO(n)timeusingbottom-upheap\nconstruction (seeSection8.3.6).\nAteachiterationofthewhileloop,wespendO(logn)timetoremovevertex\n\u2022\nu from Q, and O(degree(v)logn) time to perform the relaxation procedure\nontheedgesincident onu.\nTheoverallrunningtimeofthewhileloopis\n\u2022\n\u2211\n(1+degree(v))logn,\nvinG\nwhichisO((n+m)logn)byProposition 13.6.\nNote that if we wish to express the running time as a function of n only, then it is\nO(n2logn)intheworstcase.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 645 \u2014 #667\ni i\n13.6. MinimumSpanningTrees 645\n13.6 Minimum Spanning Trees\nSuppose we wish to connect all the computers in a new office building using the\nleastamountofcable. WecanmodelthisproblemusingaweightedgraphGwhose\nvertices represent the computers, and whose edges represent all the possible pairs\n(u,v)ofcomputers,wheretheweightw((v,u))ofedge(v,u)isequaltotheamount\nof cable needed to connect computer v to computer u. Rather than computing a\nshortest-pathtreefromsomeparticularvertexv,weareinterestedinsteadinfinding\na(free)treeT thatcontains allthevertices ofGandhastheminimumtotalweight\noverallsuchtrees. Methodsforfindingsuchatreearethefocusofthissection.\nProblem Definition\nGiven a weighted undirected graph G, we are interested in finding a tree T that\ncontains alltheverticesinGandminimizesthesum\n\u2211\nw(T)= w((v,u)).\n(v,u)inT\nAtree,suchasthis,thatcontainseveryvertexofaconnectedgraphGissaidto\nbeaspanningtree, andtheproblem ofcomputing aspanning treeT withsmallest\ntotalweightisknownastheminimumspanningtree(orMST)problem.\nThe development of efficient algorithms for the minimum spanning tree prob-\nlem predates the modern notion of computer science itself. In this section, we\ndiscuss two classic algorithms for solving the MST problem. These algorithms\nare both applications ofthe greedy method, which, aswas discussed briefly in the\nprevioussection,isbasedonchoosingobjectstojoinagrowingcollectionbyitera-\ntivelypicking anobject thatminimizes somecost function. Thefirstalgorithm we\ndiscuss isKruskal\u2019s algorithm, which\u201cgrows\u201d theMSTinclusters byconsidering\nedgesinorderoftheirweights. ThesecondalgorithmwediscussisthePrim-Jarn\u00b4\u0131k\nalgorithm, whichgrowstheMSTfrom asingle rootvertex, muchinthesameway\nasDijkstra\u2019s shortest-path algorithm.\nAsinSection 13.5.2, inorder tosimplify thedescription ofthealgorithms, we\nassume, in thefollowing, that theinput graph Gis undirected (that is, all itsedges\nare undirected) and simple (that is, it has no self-loops and no parallel edges).\nHence,wedenotetheedgesofGasunordered vertexpairs(u,z).\nBeforewediscussthedetailsofthesealgorithms,however,letusgiveacrucial\nfactaboutminimumspanning treesthatformsthebasisofthealgorithms.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 646 \u2014 #668\ni i\n646 Chapter13. GraphAlgorithms\nA Crucial Fact About Minimum Spanning Trees\nThetwoMSTalgorithmswediscussarebasedonthegreedymethod,whichinthis\ncasedepends crucially onthefollowingfact. (SeeFigure13.17.)\nFigure13.17: Thecrucialfactaboutminimumspanning trees.\nProposition 13.24: LetGbeaweightedconnectedgraph,andletV andV bea\n1 2\npartitionoftheverticesofGintotwodisjointnonemptysets.Furthermore,letebe\nanedgeinGwithminimumweightfromamongthosewithoneendpointinV and\n1\ntheotherinV .ThereisaminimumspanningtreeT thathaseasoneofitsedges.\n2\nJustification: Let T be a minimum spanning tree of G. If T does not contain\nedge e, the addition of e to T must create a cycle. Therefore, there is some edge\nf of this cycle that has one endpoint inV and the other inV . Moreover, by the\n1 2\nchoiceofe,w(e) w(f). Ifweremove f fromT e ,weobtainaspanning tree\n\u2264 \u222a{ }\nwhose total weight is no more than before. Since T is a minimum spanning tree,\nthisnewtreemustalsobeaminimumspanning tree.\nIn fact, if the weights in G are distinct, then the minimum spanning tree is\nunique. Weleavethejustificationofthislesscrucialfactasanexercise(ExerciseC-\n13.17). In addition, note that Proposition 13.24 remains valid even if the graph G\ncontainsnegative-weightedgesornegative-weightcycles,unlikethealgorithmswe\npresented forshortestpaths.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 647 \u2014 #669\ni i\n13.6. MinimumSpanningTrees 647\n13.6.1 Kruskal\u2019s Algorithm\nThereason Proposition 13.24 is so important is that it can be used as the basis for\nbuilding a minimum spanning tree. In Kruskal\u2019s algorithm, it is used to build the\nminimum spanning tree in clusters. Initially, each vertex is in its own cluster all\nby itself. The algorithm then considers each edge in turn, ordered by increasing\nweight. If an edge e connects two different clusters, then e is added to the set\nof edges of the minimum spanning tree, and the two clusters connected by e are\nmerged into a single cluster. If, on the other hand, e connects two vertices that\nare already in the same cluster, then e is discarded. Once the algorithm has added\nenough edges to form a spanning tree, it terminates and outputs this tree as the\nminimumspanning tree.\nWe give pseudo-code for Kruskal\u2019s MST algorithm in Code Fragment 13.25\nandweshowtheworkingofthisalgorithm inFigures13.18,13.19,and13.20.\nAlgorithmKruskal(G):\nInput: Asimpleconnected weightedgraphGwithnvertices andmedges\nOutput: Aminimumspanning treeT forG\nforeachvertexvinGdo\nDefineanelementary clusterC(v) v .\n\u2190{ }\nInitialize apriorityqueueQtocontainalledgesinG,usingtheweightsaskeys.\nT T willultimatelycontaintheedgesoftheMST\n\u2190\u2205 { }\nwhileT hasfewerthann 1edgesdo\n\u2212\n(u,v) Q.removeMin()\n\u2190\nLetC(v)betheclustercontaining v,andletC(u)betheclustercontaining u.\nifC(v)=C(u)then\n6\nAddedge(v,u)toT.\nMergeC(v)andC(u)intoonecluster, thatis,unionC(v)andC(u).\nreturntreeT\nCodeFragment13.25: Kruskal\u2019salgorithm fortheMSTproblem.\nAs mentioned before, the correctness of Kruskal\u2019s algorithm follows from the\ncrucialfactaboutminimumspanningtrees,Proposition13.24. EachtimeKruskal\u2019s\nalgorithm adds an edge (v,u) to the minimum spanning tree T, we can define a\npartitioning of the set of vertices V (as in the proposition) by letting V be the\n1\nclustercontaining vandlettingV containtherestoftheverticesinV. Thisclearly\n2\ndefines a disjoint partitioning of the vertices ofV and, more importantly, since we\nareextractingedgesfromQinorderbytheirweights,emustbeaminimum-weight\nedge with one vertex inV and the other inV . Thus, Kruskal\u2019s algorithm always\n1 2\naddsavalidminimumspanning treeedge.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 648 \u2014 #670\ni i\n648 Chapter13. GraphAlgorithms\n(a) (b)\n(c) (d)\n(e) (f)\nFigure13.18:ExampleofanexecutionofKruskal\u2019sMSTalgorithmonagraphwith\nintegerweights. Weshowtheclusters asshadedregionsandwehighlight theedge\nbeingconsidered ineachiteration. (Continues inFigure13.19.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 649 \u2014 #671\ni i\n13.6. MinimumSpanningTrees 649\n(g) (h)\n(i) (j)\n(k) (l)\nFigure 13.19: Example of an execution of Kruskal\u2019s MST algorithm. Rejected\nedgesareshowndashed. (ContinuesinFigure13.20.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 650 \u2014 #672\ni i\n650 Chapter13. GraphAlgorithms\n(m) (n)\nFigure 13.20: Example of an execution of Kruskal\u2019s MST algorithm. The edge\nconsidered in (n) merges the last two clusters, which concludes this execution of\nKruskal\u2019salgorithm. (ContinuedfromFigure13.19.)\nThe Running Time of Kruskal\u2019s Algorithm\nWe denote the number of vertices and edges of the input graph G with n and m,\nrespectively. Because of the high level of the description we gave for Kruskal\u2019s\nalgorithm in Code Fragment 13.25, analyzing its running time requires that we\ngive more details on its implementation. Specifically, we should indicate the data\nstructures usedandhowtheyareimplemented.\nWecanimplementthepriorityqueueQusingaheap. Thus,wecaninitializeQ\nin O(mlogm) time by repeated insertions, or in O(m) time using bottom-up heap\nconstruction(seeSection8.3.6). Inaddition,ateachiterationofthewhileloop,we\ncan remove a minimum-weight edge inO(logm)time, which actually isO(logn),\nsince G is simple. Thus, the total time spent performing priority queue operations\nisnomorethanO(mlogn).\nWecanrepresenteachclusterCusingoneoftheunion-findpartitiondatastruc-\ntures discussed inSection 11.4.3. Recallthatthesequence-based union-find struc-\ntureallowsustoperformaseriesofNunionandfindoperationsinO(NlogN)time,\nandthetree-basedversioncanimplementsuchaseriesofoperationsinO(Nlog\u2217N)\ntime. Thus, since we perform n 1 calls to function union and at most m calls to\n\u2212\nfind,thetotaltimespentonmergingclusters anddetermining theclustersthatver-\ntices belong to is no more than O(mlogn) using the sequence-based approach or\nO(mlog\u2217n)usingthetree-based approach.\nTherefore, using arguments similar to those used for Dijkstra\u2019s algorithm, we\nconclude that the running time of Kruskal\u2019s algorithm is O((n+m)logn), which\ncanbesimplifiedasO(mlogn),sinceGissimpleandconnected.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 651 \u2014 #673\ni i\n13.6. MinimumSpanningTrees 651\n\u00b4\u0131\n13.6.2 The Prim-Jarn k Algorithm\nIn the Prim-Jarn\u00b4\u0131k algorithm, we grow a minimum spanning tree from a single\ncluster starting from some \u201croot\u201d vertex v. The main idea is similar to that of\nDijkstra\u2019s algorithm. We begin with some vertex v, defining the initial \u201ccloud\u201d of\nverticesC. Then, in each iteration, we choose a minimum-weight edge e=(v,u),\nconnecting avertexvinthecloudC toavertexuoutsideofC. Thevertexuisthen\nbroughtintothecloudCandtheprocessisrepeateduntilaspanningtreeisformed.\nAgain, the crucial fact about minimum spanning trees comes to play, because by\nalways choosing the smallest-weight edge joining a vertex insideC to one outside\nC,weareassuredofalwaysaddingavalidedgetotheMST.\nToefficientlyimplementthisapproach,wecantakeanothercuefromDijkstra\u2019s\nalgorithm. We maintain a label D[u] for each vertex u outside the cloud C, so\nthat D[u] stores the weight of the best current edge for joining u to the cloud C.\nThese labels allow us to reduce the number of edges that we must consider in\ndeciding which vertex is next to join the cloud. We give the pseudo-code in Code\nFragment13.26.\nAlgorithmPrimJarnik(G):\nInput: Aweightedconnected graphGwithnverticesandmedges\nOutput: Aminimumspanning treeT forG\nPickanyvertexvofG\nD[v] 0\n\u2190\nforeachvertexu=vdo\n6\nD[u] +\n\u2190 \u221e\nInitialize T .\n\u2190\u2205\nInitialize a priority queue Q with an entry ((u,null),D[u]) for each vertex u,\nwhere(u,null)istheelementandD[u])isthekey.\nwhileQisnotemptydo\n(u,e) Q.removeMin()\n\u2190\nAddvertexuandedgeetoT.\nforeachvertexzadjacent tousuchthatzisinQdo\nperform therelaxation procedure onedge(u,z)\n{ }\nifw((u,z))<D[z]then\nD[z] w((u,z))\n\u2190\nChangeto(z,(u,z))theelementofvertexzinQ.\nChangetoD[z]thekeyofvertexzinQ.\nreturnthetreeT\nCodeFragment13.26: ThePrim-Jarn\u00b4\u0131kalgorithm fortheMSTproblem.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 652 \u2014 #674\ni i\n652 Chapter13. GraphAlgorithms\nAnalyzing the Prim-Jarn\u00b4\u0131k Algorithm\nLetnandmdenote thenumberofvertices andedges oftheinput graphG,respec-\ntively. TheimplementationissuesforthePrim-Jarn\u00b4\u0131kalgorithmaresimilartothose\nforDijkstra\u2019s algorithm. Ifweimplementtheadaptable priority queueQasaheap\nthat supports location-aware entries (Section 8.4.2), then wecanextract the vertex\nu in each iteration in O(logn) time. In addition, we can update each D[z] value in\nO(logn) time, as well, which is a computation considered at most once for each\nedge (u,z). Theother steps ineach iteration canbeimplemented inconstant time.\nThus,thetotalrunning timeisO((n+m)logn),whichisO(mlogn).\nIllustrating the Prim-Jarn\u00b4\u0131k Algorithm\nWeillustrate thePrim-Jarn\u00b4\u0131kalgorithm inFigures13.21through13.22.\n(a) (b)\n(c) (d)\nFigure13.21: ThePrim-Jarn\u00b4\u0131kMSTalgorithm. (Continues inFigure13.22.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 653 \u2014 #675\ni i\n13.6. MinimumSpanningTrees 653\n(e) (f)\n(g) (h)\n(i) (j)\nFigure13.22: ThePrim-Jarn\u00b4\u0131kMSTalgorithm. (Continued fromFigure13.21.)\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 654 \u2014 #676\ni i\n654 Chapter13. GraphAlgorithms\n13.7 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-13.1 Draw a simple undirected graph G that has 12 vertices, 18 edges, and 3\nconnected components. Why would it be impossible to draw G with 3\nconnected components ifGhad66edges?\nR-13.2 Draw an adjacency list and adjacency matrix representation of the undi-\nrectedgraphshowninFigure13.1.\nR-13.3 Drawasimpleconnecteddirectedgraphwith8verticesand16edgessuch\nthat the in-degree and out-degree of each vertex is 2. Show that there is\na single (nonsimple) cycle that includes all the edges of your graph, that\nis, you can trace all the edges in their respective directions without ever\nliftingyourpencil. (SuchacycleiscalledanEulertour.)\nR-13.4 Repeat the previous problem and then remove one edge from the graph.\nShowthatnowthereisasingle(nonsimple)paththatincludesalltheedges\nofyourgraph. (SuchapathiscalledanEulerpath.)\nR-13.5 Boblovesforeignlanguagesandwantstoplanhiscoursescheduleforthe\nfollowing years. He is interested in the following nine language courses:\nLA15, LA16, LA22, LA31, LA32, LA126, LA127, LA141, and LA169.\nThecourseprerequisites are:\nLA15: (none)\n\u2022\nLA16: LA15\n\u2022\nLA22: (none)\n\u2022\nLA31: LA15\n\u2022\nLA32: LA16,LA31\n\u2022\nLA126: LA22,LA32\n\u2022\nLA127: LA16\n\u2022\nLA141: LA22,LA16\n\u2022\nLA169: LA32\n\u2022\nFind the sequence of courses that allows Bob to satisfy all the prerequi-\nsites.\nR-13.6 Suppose we represent a graph G having n vertices and m edges with the\nedge list structure. Why, in this case, does the insertVertex function run\ninO(1)timewhiletheeraseVertexfunctionrunsinO(m)time?\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 655 \u2014 #677\ni i\n13.7. Exercises 655\nR-13.7 Let G be a graph whose vertices are the integers 1 through 8, and let the\nadjacent verticesofeachvertexbegivenbythetablebelow:\nVertex AdjacentVertices\n1 (2,3,4)\n2 (1,3,4)\n3 (1,2,4)\n4 (1,2,3,6)\n5 (6,7,8)\n6 (4,5,7)\n7 (5,6,8)\n8 (5,7)\nAssumethat,inatraversalofG,theadjacentverticesofagivenvertexare\nreturned inthesameorderastheyarelistedinthetableabove.\na. DrawG.\nb. Give the sequence of vertices of G visited using a DFS traversal\nstarting atvertex1.\nc. Give the sequence of vertices visited using a BFS traversal starting\natvertex1.\nR-13.8 Would you use the adjacency list structure or the adjacency matrix struc-\ntureineachofthefollowingcases? Justifyyourchoice.\na. Thegraph has10,000 vertices and20,000 edges, anditisimportant\ntouseaslittlespaceaspossible.\nb. The graph has 10,000 vertices and 20,000,000 edges, and it is im-\nportanttouseaslittlespaceaspossible.\nc. You need to answer the query isAdjacentTo as fast as possible, no\nmatterhowmuchspaceyouuse.\nR-13.9 Explain why the DFS traversal runs in O(n2) time on an n-vertex simple\ngraphthatisrepresented withtheadjacency matrixstructure.\nR-13.10 Drawthetransitive closureofthedirected graphshowninFigure13.2.\nR-13.11 Compute a topological ordering for the directed graph drawn with solid\nedgesinFigure13.8(d).\nR-13.12 Canweuseaqueueinsteadofastackasanauxiliary datastructureinthe\ntopological sorting algorithm shown in Code Fragment 13.23? Why or\nwhynot?\nR-13.13 Draw a simple, connected, weighted graph with 8 vertices and 16 edges,\neachwithuniqueedgeweights. Identifyonevertexasa\u201cstart\u201dvertexand\nillustrate arunning ofDijkstra\u2019salgorithm onthisgraph.\nR-13.14 Showhowtomodifythepseudo-codeforDijkstra\u2019salgorithmforthecase\nwhenthegraphmaycontainparalleledgesandself-loops.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 656 \u2014 #678\ni i\n656 Chapter13. GraphAlgorithms\nR-13.15 Showhowtomodifythepseudo-codeforDijkstra\u2019salgorithmforthecase\nwhenthegraphisdirectedandwewanttocomputeshortestdirectedpaths\nfromthesourcevertextoalltheothervertices.\nR-13.16 Show how to modify Dijkstra\u2019s algorithm to not only output the distance\nfromvtoeachvertexinG,butalsotooutputatreeT rootedatvsuchthat\nthepathinT fromvtoavertexuisashortest pathinGfromvtou.\nR-13.17 There are eight small islands in alake, and the state wants to build seven\nbridgestoconnectthemsothateachislandcanbereachedfromanyother\none viaone ormorebridges. Thecostofconstructing abridge ispropor-\ntionaltoitslength. Thedistancesbetweenpairsofislandsaregiveninthe\nfollowingtable.\n1 2 3 4 5 6 7 8\n1 - 240 210 340 280 200 345 120\n2 - - 265 175 215 180 185 155\n3 - - - 260 115 350 435 195\n4 - - - - 160 330 295 230\n5 - - - - - 360 400 170\n6 - - - - - - 175 205\n7 - - - - - - - 305\n8 - - - - - - - -\nFindwhichbridges tobuildtominimizethetotalconstruction cost.\nR-13.18 Draw a simple, connected, undirected, weighted graph with 8 vertices\nand 16 edges, each with unique edge weights. Illustrate the execution of\nKruskal\u2019s algorithm onthis graph. (Note that there isonly one minimum\nspanning treeforthisgraph.)\nR-13.19 Repeattheprevious problemforthePrim-Jarn\u00b4\u0131kalgorithm.\nR-13.20 Consider the unsorted sequence implementation of the priority queue Q\nusedinDijkstra\u2019salgorithm. Inthiscase,whyisthisthebest-caserunning\ntimeofDijkstra\u2019salgorithm O(n2)onann-vertexgraph?\nR-13.21 Describe the meaning of the graphical conventions used in Figure 13.6\nillustrating a DFS traversal. What do the colors blue and black refer to?\nWhatdothearrowssignify? Howaboutthicklinesanddashedlines?\nR-13.22 RepeatExerciseR-13.21forFigure13.7illustrating aBFStraversal.\nR-13.23 RepeatExerciseR-13.21forFigure13.9illustratingadirectedDFStraver-\nsal.\nR-13.24 Repeat ExerciseR-13.21 forFigure 13.10illustrating the Floyd-Warshall\nalgorithm.\nR-13.25 RepeatExerciseR-13.21forFigure13.12illustratingthetopologicalsort-\ningalgorithm.\nR-13.26 RepeatExerciseR-13.21forFigures13.14and13.15illustratingDijkstra\u2019s\nalgorithm.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 657 \u2014 #679\ni i\n13.7. Exercises 657\nR-13.27 RepeatExerciseR-13.21forFigures13.18and13.20illustratingKruskal\u2019s\nalgorithm.\nR-13.28 RepeatExerciseR-13.21forFigures13.21and13.22illustratingthePrim-\nJarn\u00b4\u0131kalgorithm.\nR-13.29 Howmanyedgesareinthetransitive closure ofagraphthat consists ofa\nsimpledirected pathofnvertices?\nR-13.30 Given a complete binary tree T with n nodes, consider a directed graph\nG having the nodes of T as its vertices. For each parent-child pair in T,\ncreate a directed edge in G from the parent to the child. Show that the\ntransitive closureofGhasO(nlogn)edges.\nR-13.31 Asimpleundirectedgraphiscompleteifitcontainsanedgebetweenevery\npairofdistinct vertices. Whatdoesadepth-first searchtreeofacomplete\ngraphlooklike?\nR-13.32 RecallingthedefinitionofacompletegraphfromExerciseR-13.31,what\ndoesabreadth-first searchtreeofacompletegraphlooklike?\nR-13.33 Saythatamazeisconstructedcorrectlyifthereisonepathfromthestart\nto the finish, the entire maze is reachable from the start, and there are no\nloops around any portions of the maze. Given a maze drawn in an n n\n\u00d7\ngrid, how can we determine if it is constructed correctly? What is the\nrunning timeofthisalgorithm?\nCreativity\nC-13.1 Saythat ann-vertex directed acyclic graph G iscompact if there issome\nwayofnumberingtheverticesofGwiththeintegersfrom0ton 1such\n\u2212\nthat G contains the edge (i,j) if and only if i< j, for all i,j in [0,n 1].\n\u2212\nGiveanO(n2)-timealgorithm fordetecting ifGiscompact.\nC-13.2 Describe, inpseudo-code, an O(n+m)-timealgorithm for computing all\ntheconnectedcomponentsofanundirectedgraphGwithnverticesandm\nedges.\nC-13.3 LetT bethespanningtreerootedatthestartvertexproducedbythedepth-\nfirstsearch ofaconnected, undirected graphG. Arguewhyeveryedgeof\nG not in T goes from a vertex in T to one of its ancestors, that is, it is a\nbackedge.\nC-13.4 Suppose we wish to represent an n-vertex graph G using the edge list\nstructure,assumingthatweidentifytheverticeswiththeintegersintheset\n0,1,...,n 1 . Describe how to implement the collection E to support\n{ \u2212 }\nO(logn)-time performance for the areAdjacent function. How are you\nimplementing thefunctioninthiscase?\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 658 \u2014 #680\ni i\n658 Chapter13. GraphAlgorithms\nC-13.5 TamarindoUniversityandmanyotherschoolsworldwidearedoingajoint\nproject on multimedia. A computer network is built to connect these\nschools using communication links that form a free tree. The schools\ndecide toinstall afileserveratoneoftheschools tosharedataamongall\ntheschools. Sincethetransmissiontimeonalinkisdominatedbythelink\nsetupandsynchronization, thecostofadatatransferisproportionaltothe\nnumberoflinksused. Hence,itisdesirabletochoosea\u201ccentral\u201dlocation\nfor the file server. Givena free tree T and a node vof T, the eccentricity\nofvisthelength ofalongest pathfrom vtoanyothernode ofT. Anode\nofT withminimumeccentricity iscalledacenterofT.\na. Designanefficientalgorithmthat,givenann-nodefreetreeT,com-\nputesacenterofT.\nb. Is the center unique? If not, how many distinct centers can a free\ntreehave?\nC-13.6 Showthat, ifT isaBFStreeproduced foraconnected graph G,then, for\neachvertexvatleveli,thepathofT betweensandvhasiedges,andany\notherpathofGbetweensandvhasatleastiedges.\nC-13.7 The time delay of a long-distance call can be determined by multiplying\nasmallfixedconstant bythenumberofcommunication links onthetele-\nphone network between the caller and callee. Suppose the telephone net-\nwork of a company named RT&Tis a free tree. The engineers of RT&T\nwant to compute the maximum possible time delay that may be experi-\nenced in a long-distance call. Given a free tree T, the diameter of T is\nthe length of a longest path between two nodes of T. Give an efficient\nalgorithm forcomputing thediameterofT.\nC-13.8 AcompanynamedRT&Thasanetworkofnswitchingstationsconnected\nbymhigh-speed communication links. Eachcustomer\u2019s phoneisdirectly\nconnected to one station in his or her area. The engineers of RT&Thave\ndeveloped a prototype video-phone system that allows two customers to\nsee each other during a phone call. In order to have acceptable image\nquality, however, the number of links used to transmit video signals be-\ntween the two parties cannot exceed four. Suppose that RT&T\u2019snetwork\nisrepresentedbyagraph. Designanefficientalgorithmthatcomputes,for\neachstation, thesetofstations reachable usingnomorethanfourlinks.\nC-13.9 ExplainwhytherearenoforwardnontreeedgeswithrespecttoaBFStree\nconstructed foradirectedgraph.\nC-13.10 An Euler tour of a directed graph G with n vertices and m edges is a\ncyclethattraverseseachedgeofGexactlyonceaccordingtoitsdirection.\nSuch a tour always exists if G is connected and the in-degree equals the\nout-degree ofeachvertex inG. Describe anO(n+m)-timealgorithm for\nfindinganEulertourofsuchadigraphG.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 659 \u2014 #681\ni i\n13.7. Exercises 659\nC-13.11 An independent set of an undirected graph G=(V,E) is a subset I ofV\nsuchthatnotwoverticesinI areadjacent. Thatis,ifuandvareinI,then\n(u,v) is not in E. A maximal independent set M is an independent set\nsuch that, ifweweretoadd anyadditional vertex toM,then itwould not\nbe independent any more. Every graph has a maximal independent set.\n(Canyouseethis? Thisquestionisnotpartoftheexercise,butitisworth\nthinking about.) Give an efficient algorithm that computes a maximal\nindependent setforagraphG. Whatisthisalgorithm\u2019s running time?\nC-13.12 Let G be an undirected graph G with n vertices and m edges. Describe\nanO(n+m)-timealgorithmfortraversingeachedgeofGexactlyoncein\neachdirection.\nC-13.13 JustifyProposition 13.14.\nC-13.14 Give an example of an n-vertex simple graph G that causes Dijkstra\u2019s\nalgorithm torunin\u2126(n2logn)timewhenitsimplementedwithaheap.\nC-13.15 Give an example of a weighted directed graph G with negative-weight\nedges but no negative-weight cycle, such that Dijkstra\u2019s algorithm incor-\nrectlycomputestheshortest-path distances fromsomestartvertexv.\nC-13.16 Consider the following greedy strategy for finding a shortest path from\nvertexstarttovertexgoalinagivenconnected graph.\n1. Initialize pathtostart.\n2. Initialize VisitedVertices to start .\n{ }\n3. Ifstart=goal, returnpathandexit. Otherwise,continue.\n4. Findtheedge(start,v)ofminimumweightsuchthatvisadjacentto\nstartandvisnotinVisitedVertices.\n5. Addvtopath.\n6. AddvtoVisitedVertices.\n7. Setstartequaltovandgotostep3.\nDoes this greedy strategy always find a shortest path from start to goal?\nEitherexplainintuitively whyitworks,orgiveacounterexample.\nC-13.17 Showthatifalltheweightsinaconnected weightedgraphGaredistinct,\nthenthereisexactlyoneminimumspanning treeforG.\nC-13.18 Design an efficient algorithm for finding a longest directed path from a\nvertexstoavertext ofanacyclic weighteddigraph G. Specifythegraph\nrepresentation used and any auxiliary data structures used. Also, analyze\nthetimecomplexity ofyouralgorithm.\nC-13.19 Consider a diagram of a telephone network, which is a graph G whose\nverticesrepresentswitchingcentersandwhoseedgesrepresentcommuni-\ncationlinesjoiningpairsofcenters. Edgesaremarkedbytheirbandwidth,\nandthebandwidthofapathisthebandwidthofitslowestbandwidthedge.\nGive an algorithm that, given adiagram and two switching centers a and\nb,outputsthemaximumbandwidthofapathbetweenaandb.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 660 \u2014 #682\ni i\n660 Chapter13. GraphAlgorithms\nC-13.20 Computer networks should avoid single points offailure, thatis, network\nnodes that can disconnect the network if they fail. We say a connected\ngraph G is biconnected if it contains no vertex whose removal would di-\nvide G into two or more connected components. Give an O(n+m)-time\nalgorithm for adding at mostn edges toa connected graph G, with n 3\n\u2265\nverticesandm n 1edges,toguarantee thatGisbiconnected.\n\u2265 \u2212\nC-13.21 NASAwantstolinknstationsspreadoverthecountryusingcommunica-\ntion channels. Each pair of stations has a different bandwidth available,\nwhichisknownapriori. NASAwantstoselect n 1channels (themini-\n\u2212\nmumpossible)insuchawaythatallthestationsarelinkedbythechannels\nand the total bandwidth (defined as thesum ofthe individual bandwidths\nof the channels) is maximum. Give an efficient algorithm for this prob-\nlemanddetermineitsworst-casetimecomplexity. Considertheweighted\ngraph G=(V,E), whereV is the set of stations and E is the set of chan-\nnelsbetweenthestations. Definetheweightw(e)ofanedgeeinE asthe\nbandwidth ofthecorresponding channel.\nC-13.22 Supposeyouaregivenatimetable, whichconsistsof:\nA set of n airports, and for each airport a in , a minimum con-\n\u2022 A A\nnectingtimec(a).\nAset ofmflights,andthefollowing,foreachflight f in :\n\u2022 F F\nOriginairporta (f)in\n1\n\u25e6 A\nDestination airporta (f)in\n2\n\u25e6 A\nDeparturetimet (f)\n1\n\u25e6\nArrivaltimet (f)\n2\n\u25e6\nDescribe an efficient algorithm for the flight scheduling problem. In this\nproblem,wearegivenairportsaandb,andatimet,andwewishtocom-\npute asequence offlights thatallows onetoarrive attheearliest possible\ntime in b when departing from a at or after timet. Minimum connecting\ntimes at intermediate airports should be observed. What is the running\ntimeofyouralgorithm asafunction ofnandm?\nC-13.23 Inside the Castle ofAsymptopia there isamaze, and along each corridor\nof the maze there is a bag of gold coins. The amount of gold in each\nbagvaries. Anobleknight, namedSirPaul,willbegiventheopportunity\nto walk through the maze, picking up bags of gold. He may enter the\nmaze only through a door marked \u201cENTER\u201d and exit through another\ndoor marked \u201cEXIT.\u201d While in the maze, he may not retrace his steps.\nEachcorridor ofthemazehasanarrowpaintedonthewall. SirPaulmay\nonly go down the corridor in the direction of the arrow. There is no way\nto traverse a\u201cloop\u201d in the maze. Given amap of the maze, including the\namountofgoldinandthedirectionofeachcorridor,describeanalgorithm\ntohelpSirPaulpickupthemostgold.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 661 \u2014 #683\ni i\n13.7. Exercises 661\nC-13.24 LetGbeaweighteddigraphwithnvertices. DesignavariationofFloyd-\nWarshall\u2019salgorithm forcomputingthelengthsoftheshortest pathsfrom\neachvertextoeveryothervertexinO(n3)time.\nC-13.25 SupposewearegivenadirectedgraphGwithnvertices,andletM bethe\nn nadjacencymatrixcorresponding toG.\n\u00d7\na. Lettheproduct ofM withitself(M2)bedefined, for1 i,j n,as\n\u2264 \u2264\nfollows\nM2(i,j)=M(i,1) M(1,j) M(i,n) M(n,j),\n\u2299 \u2295\u00b7\u00b7\u00b7\u2295 \u2299\nwhere \u201c \u201d is the Boolean or operator and \u201c \u201d is Boolean and.\n\u2295 \u2299\nGiven this definition, what does M2(i,j) =1 imply about the ver-\nticesiand j? WhatifM2(i,j)=0?\nb. Suppose M4 istheproduct ofM2 withitself. Whatdotheentries of\nM4 signify? How about the entries of M5 =(M4)(M)? In general,\nwhatinformation iscontained inthematrixMp?\nc. Nowsuppose thatGisweightedandassumethefollowing:\n(a) [1.] For1 i n,M(i,i)=0.\n\u2264 \u2264\n(b) [2.] For1 i,j n,M(i,j)=weight(i,j)if(i,j)isinE.\n\u2264 \u2264\n(c) [3.] Forfor1 i,j n,M(i,j)= if(i,j)isnotinE.\n\u2264 \u2264 \u221e\nAlso,letM2 bedefined,for1 i,j n,asfollows\n\u2264 \u2264\nM2(i,j)=min M(i,1)+M(1,j),...,M(i,n)+M(n,j) .\n{ }\nIf M2(i,j) = k, what may we conclude about the relationship be-\ntweenverticesiand j?\nC-13.26 AgraphGisbipartiteifitsverticescanbepartitionedintotwosetsX and\nY such that every edge in G has one end vertex in X and the other inY.\nDesignandanalyzeanefficientalgorithmfordeterminingifanundirected\ngraphGisbipartite(withoutknowingthesetsX andY inadvance).\nC-13.27 AnoldMSTmethod, called Baru\u02davka\u2019s algorithm, worksas followson a\ngraphGhavingnverticesandmedgeswithdistinctweights.\nLetT beasubgraph ofGinitiallycontaining justtheverticesinV.\nwhileT hasfewerthann 1edgesdo\n\u2212\nforeachconnected componentC ofT do\ni\nFindthe lowest-weight edge(v,u) inE withvinC andunotin\ni\nC.\ni\nAdd(v,u)toT (unlessitisalreadyinT).\nreturnT\nArguewhythisalgorithm iscorrectandwhyitrunsinO(mlogn)time.\nC-13.28 LetGbeagraphwithnverticesandmedgessuchthatalltheedgeweights\ninGareintegers intherange [1,n]. Giveanalgorithm forfindingamini-\nmumspanning treeforGinO(mlog\u2217n)time.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 662 \u2014 #684\ni i\n662 Chapter13. GraphAlgorithms\nProjects\nP-13.1 Write a class implementing a simplified graph ADT that has only func-\ntions relevant toundirected graphs anddoes not include update functions\nusing the adjacency matrix structure. Your class should include a con-\nstructor thattakestwocollections (forexample,sequences)\u2014a collection\nV ofvertex elements and acollection E ofpairs ofvertex elements\u2014and\nproduces thegraphGthatthesetwocollections represent.\nP-13.2 Implement the simplified graph ADT described in Project P-13.1 using\ntheadjacency liststructure.\nP-13.3 Implement the simplified graph ADT described in Project P-13.1 using\ntheedgeliststructure.\nP-13.4 ExtendtheclassofProjectP-13.2tosupportallthefunctionsofthegraph\nADT(including functions fordirectededges).\nP-13.5 ImplementagenericBFStraversalusingthetemplatemethodpattern.\nP-13.6 Implementthetopological sorting algorithm.\nP-13.7 ImplementtheFloyd-Warshall transitiveclosurealgorithm.\nP-13.8 Design an experimental comparison of repeated DFS traversals versus\nthe Floyd-Warshall algorithm for computing the transitive closure of a\ndigraph.\nP-13.9 Implement Dijkstra\u2019s algorithm assuming that the edge weights are inte-\ngers.\nP-13.10 Implement Kruskal\u2019s algorithm assuming that the edge weights are inte-\ngers.\nP-13.11 Implement the Prim-Jarn\u00b4\u0131k algorithm assuming that the edge weights are\nintegers.\nP-13.12 Perform an experimental comparison of two of the minimum spanning\ntree algorithms discussed in this chapter (Kruskal and Prim-Jarn\u00b4\u0131k). De-\nvelop an extensive set of experiments to test the running times of these\nalgorithms usingrandomly generated graphs.\nP-13.13 Onewaytoconstruct amazestarts withann ngrid such that each grid\n\u00d7\ncell is bounded by four unit-length walls. Wethen remove two boundary\nunit-length walls, to represent the start and finish. For each remaining\nunit-length wall not on the boundary, we assign a random value and cre-\nate a graph G, called the dual, such that each grid cell is a vertex in G\nand there is an edge joining the vertices for two cells if and only if the\ncells share a common wall. The weight of each edge is the weight of the\ncorresponding wall. We construct the maze by finding a minimum span-\nning tree T for G and removing all the walls corresponding to edges in\nT. Write a program that uses this algorithm to generate mazes and then\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 663 \u2014 #685\ni i\nChapterNotes 663\nsolvesthem. Minimally,yourprogramshoulddrawthemazeand,ideally,\nitshould visualizethesolution aswell.\nP-13.14 Writeaprogram thatbuildstheroutingtablesforthenodesinacomputer\nnetwork, basedonshortest-path routing, wherepathdistance ismeasured\nby hop count, that is, the number of edges in a path. The input for this\nproblem is the connectivity information for all the nodes in the network,\nasinthefollowingexample:\n241.12.31.14: 241.12.31.15 241.12.31.18 241.12.31.19\nwhich indicates three network nodes that are connected to 241.12.31.14,\nthatis,threenodesthatareonehopaway. Theroutingtableforthenodeat\naddress Aisasetofpairs (B,C),whichindicates that, toroute amessage\nfrom A to B, the next node to send to (on the shortest path from A to B)\nisC. Your program should output the routing table for each node in the\nnetwork, given an input list of node connectivity lists, each of which is\ninputinthesyntaxasshownabove,oneperline.\nChapter Notes\nThedepth-firstsearchmethodisapartofthe\u201cfolklore\u201dofcomputerscience,butHopcroft\nand Tarjan [46, 94] are the ones who showed how useful this algorithm is for solving\nseveral different graph problems. Knuth [59] discusses the topological sorting problem.\nThe simple linear-time algorithm that we describe for determining if a directed graph is\nstronglyconnectedis due to Kosaraju. The Floyd-Warshallalgorithmappearsin a paper\nby Floyd [32] and is based upon a theorem of Warshall [102]. To learn about different\nalgorithms for drawing graphs, please see the book chapter by Tamassia and Liotta [92]\nandthe bookby DiBattista, Eades, Tamassia andTollis [28]. The first knownminimum\nspanningtreealgorithmisduetoBaru\u02davka[8],andwaspublishedin1926.ThePrim-Jarn\u00b4\u0131k\nalgorithmwas first publishedin Czech by Jarn\u00b4\u0131k[50] in 1930 and in English in 1957by\nPrim [85]. Kruskal published his minimum spanning tree algorithm in 1956 [62]. The\nreaderinterestedinfurtherstudyofthehistoryoftheminimumspanningtreeproblemis\nreferredtothepaperbyGrahamandHell[41].Thecurrentasymptoticallyfastestminimum\nspanningtree algorithmisa randomizedalgorithmofKarger,Klein, andTarjan[52]that\nrunsinO(m)expectedtime.\nDijkstra[29]publishedhissingle-source,shortest-pathalgorithmin1959. Thereader\ninterestedinfurtherstudyofgraphalgorithmsisreferredtothebooksbyAhuja,Magnanti,\nandOrlin[6],Cormen,Leiserson,andRivest[24],Even[31],Gibbons[36],Mehlhorn[74],\nandTarjan[95],andthebookchapterbyvanLeeuwen[98]. Incidentally,therunningtime\nfor the Prim-Jarn\u00b4\u0131k algorithm, and also that of Dijkstra\u2019s algorithm, can actually be im-\nprovedtobeO(nlogn+m)byimplementingthequeueQwitheitheroftwomoresophis-\nticateddatastructures,the\u201cFibonacciHeap\u201d[34]orthe\u201cRelaxedHeap\u201d[30].\ni i\ni i\nThis page intentionally left blank\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 665 \u2014 #687\ni i\nChapter\n14\nMemory Management and B-Trees\nContents\n14.1 Memory Management . . . . . . . . . . . . . . . . . . 666\n14.1.1 Memory Allocation in C++ . . . . . . . . . . . . . . 669\n14.1.2 Garbage Collection . . . . . . . . . . . . . . . . . . 671\n14.2 External Memory and Caching . . . . . . . . . . . . . 673\n14.2.1 The Memory Hierarchy . . . . . . . . . . . . . . . . 673\n14.2.2 Caching Strategies . . . . . . . . . . . . . . . . . . 674\n14.3 External Searching and B-Trees . . . . . . . . . . . . 679\n14.3.1 (a,b) Trees . . . . . . . . . . . . . . . . . . . . . . 680\n14.3.2 B-Trees . . . . . . . . . . . . . . . . . . . . . . . . 682\n14.4 External-Memory Sorting . . . . . . . . . . . . . . . . 683\n14.4.1 Multi-Way Merging . . . . . . . . . . . . . . . . . . 684\n14.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . 685\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 666 \u2014 #688\ni i\n666 Chapter14. MemoryManagementandB-Trees\n14.1 Memory Management\nIn order to implement any data structure on an actual computer, we need to use\ncomputer memory. Computer memory is simply a sequence of memory words,\neach of which usually consists of 4, 8, or 16 bytes (depending on the computer).\nThese memory words are numbered from 0 to N 1, where N is the number of\n\u2212\nmemorywords available tothe computer. Thenumber associated witheach mem-\nory wordisknownasits address. Thus, thememoryin acomputer can beviewed\nasbasicallyonegiantarrayofmemorywords. Usingthismemorytoconstructdata\nstructures (and run programs) requires that we manage the computer\u2019s memory\ntoprovide the space needed for data\u2014including variables, nodes, pointers, arrays,\nandcharacter strings\u2014and theprograms thecomputer runs. Wediscuss thebasics\nofmemorymanagementinthissection.\nThe C++ Run-Time Stack\nA C++ program is compiled into a binary executable file, which is then executed\nwithin the context of the C++ run-time environment. The run-time environment\nprovides importantfunctions forexecuting yourprogram,suchasmanaging mem-\noryandperforming inputandoutput.\nStacks have animportant application to the run-time environment ofC++ pro-\ngrams. A running program has a private stack, called the function call stack or\njust call stack for short, which is used to keep track of local variables and other\nimportantinformationonfunctionsastheyareinvokedduringexecution. (SeeFig-\nure14.1.)\nMorespecifically,duringtheexecutionofaprogram,therun-timeenvironment\nmaintains a stack whose elements are descriptors of the currently active (that is,\nnonterminated) invocations of functions. These descriptors are called frames. A\nframe for some invocation of function \u201cfool\u201d stores the current values of the local\nvariablesandparametersoffunctionfool,aswellasinformationonfunction\u201ccool\u201d\nthatcalledfoolandonwhatneedstobereturned tofunction \u201ccool.\u201d\nKeeping Track of the Program Counter\nYourcomputer\u2019s run-time system maintains aspecial variable, called the program\ncounter, which keeps track of which machine instruction is currently being exe-\ncuted. When thefunction cool() invokes another function fool(), thecurrent value\noftheprogram counter isrecorded intheframeofthecurrent invocation ofcool()\n(sothesystemknowswheretoreturntowhenfunctionfool()isdone). Atthetopof\nthestackistheframeoftherunningfunction,thatis,thefunctionthatiscurrently\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 667 \u2014 #689\ni i\n14.1. MemoryManagement 667\nmain() {\nint i=5;\n14 cool(i);\nfool:\nPC = 320\nm = 7 }\ncool: cool(int j) {\nPC =216\nint k=7;\nj = 5\nk = 7\n216 fool(k);\nmain:\nPC = 14\ni = 5 }\n320 fool(int m) {\nC++ Stack\n}\nC++ Program\nFigure14.1: An example of the C++ call stack: function fool has just been called\nby function cool, which itself was previously called by function main. Note the\nvalues of the program counter, parameters, and local variables stored in the stack\nframes. Whentheinvocationoffunctionfoolterminates,theinvocationoffunction\ncool resumes its execution at instruction 217, which is obtained by incrementing\nthevalueoftheprogram counter storedinthestackframe.\nexecuting. Theremaining elementsofthestackareframesofthesuspendedfunc-\ntions,thatis,functionsthathaveinvokedanotherfunctionandarecurrentlywaiting\nfor it to return control to them upon its termination. The order of the elements in\nthe stack corresponds to the chain of invocations of the currently active functions.\nWhenanewfunctionisinvoked, aframeforthisfunctionispushedontothestack.\nWhenitterminates, itsframeispoppedfromthestackandthesystem resumesthe\nprocessing ofthepreviously suspended function.\nUnderstanding Call-by-Value Parameter Passing\nThe system uses the call stack to perform parameter passing to functions. Unless\nreference parameters are involved, C++ uses the call-by-value parameter passing\nprotocol. Thismeansthatthe current valueofavariable (orexpression) iswhatis\npassedasanargument toacalledfunction.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 668 \u2014 #690\ni i\n668 Chapter14. MemoryManagementandB-Trees\nIfthevariablexbeingpassedisnotspecifiedasareferenceparameter,itsvalue\niscopiedtoalocalvariableinthecalledfunction\u2019sframe. Thisappliestoprimitive\ntypes(suchasintandfloat),pointers(suchas\u201cint*\u201d),andeventoclasses(suchas\n\u201cstd::vector<int>\u201d). Notethatifthecalled function changes thevalueofthislocal\nvariable, itwillnotchange thevalueofthevariableinthecallingfunction.\nOn the other hand, if the variable x is passed as a reference parameter, such\nas \u201cint&,\u201d the address of x is passed instead, and this address is assigned to some\nlocal variable y in the called function. Thus, y and x refer to the same object. If\nthe called function changes the internal state of the object that y refers to, it will\nsimultaneously be changing the internal state of the object that x refers to (since\ntheyrefertothesameobject).\nC++ arrays behave somewhat differently, however. Recall from Section 1.1.3,\nthat a C++ array is represented internally as a pointer to its first element. Thus,\npassing an array parameter passes a copy of this pointer, not a copy of the array\ncontents. Since the variable xin the calling function and the associated local vari-\nable y in the called function share the same copy of this pointer, x[i] and y[i] refer\ntothesameobjectinmemory.\nImplementing Recursion\nOne of the benefits of using a stack to implement function invocation is that it\nallowsprogramstouserecursion. Thatis,itallowsafunction tocallitself, asdis-\ncussed in Section 3.5. Interestingly, early programming languages, such as Cobol\nand Fortran, did notoriginally use run-time stacks toimplement function and pro-\ncedure calls. But because of the elegance and efficiency that recursion allows,\nall modern programming languages, including the modern versions of classic lan-\nguages like Cobol and Fortran, utilize arun-time stack for function and procedure\ncalls.\nIn the execution of a recursive function, each box of the recursion trace corre-\nsponds to aframeof thecall stack. Also, the content of thecall stack corresponds\ntothechainofboxesfromtheinitialfunction invocation tothecurrentone.\nTo better illustrate how a run-time stack allows for recursive functions, let us\nconsider a C++ implementation of the classic recursive definition of the factorial\ntion\nn!=n(n 1)(n 2) 1\n\u2212 \u2212 \u00b7\u00b7\u00b7\nasshowninCodeFragment14.1.\nThefirsttimewecallfunctionfactorial,itsstackframeincludesalocalvariable\nstoring the value n. Function factorial recursively calls itself to compute (n 1)!,\n\u2212\nwhich pushes a new frame on the call stack. In turn, this recursive invocation\ncalls itself to compute (n 2)!, etc. The chain of recursive invocations, and thus\n\u2212\nthe run-time stack, only grows up to size n, because calling factorial(1) returns\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 669 \u2014 #691\ni i\n14.1. MemoryManagement 669\nint recursiveFactorial(int n) // recursive factorial function\n{\nif (n == 0) return 1; // basis case\nelse return n * recursiveFactorial(n 1); // recursive case\n\u2212\n}\nCodeFragment14.1: Arecursiveimplementation ofthefactorialfunction.\n1 immediately without invoking itself recursively. The run-time stack allows for\nfunction factorialto exist simultaneously inseveral active frames (as manyasnat\nsomepoint). Eachframe stores the value ofits parameter naswellasthe value to\nbereturned. Eventually, whenthefirstrecursive callterminates, itreturns(n 1)!,\n\u2212\nwhich is then multiplied by n to compute n! for the original call of the factorial\nfunction.\n14.1.1 Memory Allocation in C++\nWehavealreadydiscussed(inSection14.1)howtheC++run-timesystemallocates\na function\u2019s local variables in that function\u2019s frame on the run-time stack. The\nstack is not the only kind of memory available for program data in C++, however.\nMemory can also be allocated dynamically by using the new operator, which is\nbuiltintoC++. Forexample,inChapter1,welearnedthatwecanallocateanarray\nof100integersasfollows:\nint* items = new int[100];\nMemoryallocated inthismannercanbedeallocated with\u201cdelete [ ] items.\u201d\nThe Memory Heap\nInstead of using the run-time stack for this object\u2019s memory, C++ uses memory\nfrom another area of storage\u2014the memory heap (which should not be confused\nwith the \u201cheap\u201d data structure discussed in Chapter 8). We illustrate this memory\narea,togetherwiththeothermemoryareas,inFigure14.2. Thestorageavailablein\nthememoryheapisdivided intoblocks, whicharecontiguous array-like \u201cchunks\u201d\nofmemorythatmaybeofvariableorfixedsizes.\nTo simplify the discussion, let us assume that blocks in the memory heap are\nof a fixed size, say, 1,024 bytes, and that one block is big enough for any object\nwemightwanttocreate. (Efficiently handling themoregeneralcaseisactually an\ninteresting researchproblem.)\nThe memory heap must be able to allocate memory blocks quickly for new\nobjects. Differentrun-timesystemsusedifferentapproaches. Wethereforeexercise\nthisfreedomandchoosetouseaqueuetomanagetheunusedblocksinthememory\nheap. When a function uses the new operator to request a block of memory for\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 670 \u2014 #692\ni i\n670 Chapter14. MemoryManagementandB-Trees\nFigure14.2: AschematicviewofthelayoutofmemoryinaC++program.\nsome new object, the run-time system can perform a dequeue operation on the\nqueue of unused blocks to provide a free block of memory in the memory heap.\nLikewise,whentheuserdeallocatesablockofmemoryusingdelete,thentherun-\ntimesystem canperform anenqueueoperation toreturn thisblock tothequeue of\navailable blocks.\nMemory Allocation Algorithms\nIt is important that the run-time systems of modern programming languages, such\nas C++ and Java, are able to quickly allocate memory for new objects. Different\nsystems adopt difference approaches. One popular method is to keep contiguous\n\u201choles\u201d of available free memory in a doubly linked list, called the free list. The\nlinksjoiningtheseholesarestoredinsidetheholesthemselves,sincetheirmemory\nis not being used. Asmemory is allocated and deallocated, the collection of holes\nin the free lists changes, with the unused memory being separated into disjoint\nholes divided by blocks of used memory. This separation of unused memory into\nseparate holes is known as fragmentation. Of course, we would like to minimize\nfragmentation asmuchaspossible.\nThere are two kinds of fragmentation that can occur. Internal fragmentation\noccurs when a portion of an allocated memory block is not actually used. For\nexample, a program may request an array of size 1,000 but only use the first 100\ncells of this array. There isn\u2019t much that a run-time environment can do to reduce\ninternal fragmentation. External fragmentation, on the other hand, occurs when\nthereisasignificantamountofunusedmemorybetweenseveralcontiguous blocks\nof allocated memory. Since the run-time environment has control over where to\nallocatememorywhenitisrequested(forexample,whenthenewkeywordisused\nin C++), the run-time environment should allocate memory in a way that tries to\nreduceexternalfragmentation asmuchasreasonably possible.\nSeveral heuristics have been suggested for allocating memory from the heap\nin order to minimize external fragmentation. The best-fit algorithm searches the\nentirefreelisttofindtheholewhosesizeisclosesttotheamountofmemorybeing\nrequested. The first-fit algorithm searches from the beginning of the free list for\nthe first hole that is large enough. The next-fit algorithm is similar, in that it also\nsearches the free list for the first hole that is large enough, but it begins its search\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 671 \u2014 #693\ni i\n14.1. MemoryManagement 671\nfrom where it left off previously, viewing the free list as a circularly linked list\n(Section3.4.1). Theworst-fitalgorithmsearchesthefreelisttofindthelargesthole\nofavailablememory,whichmightbedonefasterthanasearchoftheentirefreelist\nif this list were maintained as a priority queue (Chapter 8). In each algorithm, the\nrequested amount of memory is subtracted from the chosen memory hole and the\nleftoverpartofthatholeisreturned tothefreelist.\nAlthough it might sound good at first, the best-fit algorithm tends to produce\nthe worst external fragmentation, since the leftover parts of the chosen holes tend\nto be small. The first-fit algorithm is fast, but it tends to produce a lot of external\nfragmentation at the front of the free list, which slows down future searches. The\nnext-fitalgorithmspreadsfragmentationmoreevenlythroughoutthememoryheap,\nthus keeping search times low. This spreading also makesit moredifficult toallo-\ncate large blocks, however. Theworst-fitalgorithm attempts toavoid this problem\nbykeepingcontiguous sections offreememoryaslargeaspossible.\n14.1.2 Garbage Collection\nInC++,thememoryspace forobjects mustbeexplicitly allocated anddeallocated\nbytheprogrammer through theuseoftheoperators new anddelete, respectively.\nOther programming languages, such as Java, place the burden of memory man-\nagement entirely on the run-time environment. In this section, we discuss how\nthe run-time systems of languages like Java manage the memory used by objects\nallocated bythenew operation.\nAs mentioned above, memory for objects is allocated from the memory heap\nand the space forthe member variables ofarunning program areplaced inits call\nstacks, one for each running program. Since member variables in a call stack can\nrefer toobjects inthememory heap, all the variables and objects inthe call stacks\nof running threads are called root objects. All those objects that can be reached\nby following object references that start from a root object are called live objects.\nTheliveobjectsaretheactiveobjectscurrentlybeingusedbytherunningprogram;\ntheseobjectsshouldnotbedeallocated. Forexample,arunningprogrammaystore,\ninavariable,areferencetoasequenceSthatisimplementedusingadoublylinked\nlist. The reference variable to S is a root object, while the object for S is a live\nobject, as are all the node objects that are referenced from this object and all the\nelementsthatarereferenced fromthesenodeobjects.\nFrom time to time, the run-time environment may notice that available space\nin the memory heap is becoming scarce. At such times, the system can elect to\nreclaimthespacethatisbeingusedforobjectsthatarenolongerlive,andreturnthe\nreclaimed memory to the free list. This reclamation process is known as garbage\ncollection. Thereareseveraldifferentalgorithmsforgarbagecollection, butoneof\nthemostusedisthemark-sweepalgorithm.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 672 \u2014 #694\ni i\n672 Chapter14. MemoryManagementandB-Trees\nInthemark-sweepgarbagecollectionalgorithm,weassociatea\u201cmark\u201dbitwith\neachobjectthatidentifies ifthatobjectisliveornot. Whenwedetermine, atsome\npoint, that garbage collection is needed, we suspend all other running threads and\nclear the mark bits of all the objects currently allocated in the memory heap. We\nthen trace through the call stack of the currently running program and we mark\nall the (root) objects in this stack as \u201clive.\u201d We must then determine all the other\nlive objects\u2014the ones that are reachable from the root objects. To do this effi-\nciently, we can use the directed-graph version of the depth-first search traversal\n(Section13.3.1). Inthiscase,eachobjectinthememoryheapisviewedasavertex\ninadirected graph, andthereference fromoneobjecttoanother isviewedasadi-\nrectededge. ByperformingadirectedDFSfromeachrootobject,wecancorrectly\nidentify and mark each live object. This process is known as the \u201cmark\u201d phase.\nOnce this process has completed, we then scan through the memory heap and re-\nclaim any space that is being used for an object that has not been marked. At this\ntime, we can also optionally coalesce all the allocated space in the memory heap\ninto a single block, thereby eliminating external fragmentation for the time being.\nThis scanning and reclamation process is known as the \u201csweep\u201d phase, and when\nit completes, we resume running the suspended threads. Thus, the mark-sweep\ngarbage collection algorithm willreclaim unused space intimeproportional tothe\nnumberofliveobjects andtheirreferences plusthesizeofthememoryheap.\nPerforming DFS In-place\nThe mark-sweep algorithm correctly reclaims unused space in the memory heap,\nbut there is an important issue we must face during the mark phase. Since we are\nreclaimingmemoryspaceatatimewhenavailablememoryisscarce,wemusttake\ncare not to use extra space during the garbage collection itself. The trouble is that\ntheDFSalgorithm, intherecursive waywedescribed itinSection 13.3.1, canuse\nspace proportional to the number of vertices in the graph. In the case of garbage\ncollection, theverticesinourgrapharetheobjects inthememoryheap;hence, we\nprobably don\u2019t have this much memory to use. We want a way to perform DFS\nin-place, usingonlyaconstant amountofadditional storage.\nThe main idea for performing DFS in-place is to simulate the recursion stack\nusingtheedgesofthegraph(which,inthecaseofgarbagecollection, corresponds\nto object references). When we traverse an edge from a visited vertex v to a new\nvertexw,wechange theedge(v,w)stored inv\u2019sadjacency listtopointback tov\u2019s\nparent in the DFS tree. When we return back to v (simulating the return from the\n\u201crecursive\u201d callatw),wecannowswitchtheedgewemodifiedtopointbacktow.\nOfcourse,weneedtohavesomewayofidentifyingwhichedgeweneedtochange\nback. Onepossibility istonumberthereferences going outofvas1,2,andsoon,\nand store, in addition to the mark bit (which we are using for the \u201cvisited\u201d tag in\nourDFS),acountidentifierthattellsuswhichedgeswehavemodified.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 673 \u2014 #695\ni i\n14.2. ExternalMemoryandCaching 673\n14.2 External Memory and Caching\nThereareseveralcomputerapplicationsthatmustdealwithalargeamountofdata.\nExamples include the analysis of scientific data sets, the processing of financial\ntransactions, andtheorganizationandmaintenanceofdatabases(suchastelephone\ndirectories). Infact,theamountofdatathatmustbedealtwithisoftentoolargeto\nfitentirelyintheinternal memoryofacomputer.\n14.2.1 The Memory Hierarchy\nIn order to accommodate large data sets, computers have a hierarchy of different\nkinds of memories that vary in terms of their size and distance from the CPU.\nClosesttotheCPUaretheinternalregistersthattheCPUitselfuses. Accesstosuch\nlocationsisveryfast,buttherearerelativelyfewsuchlocations. Atthesecondlevel\ninthehierarchy isthecachememory. Thismemoryisconsiderably largerthanthe\nregistersetofaCPU,butaccessingittakeslonger(andtheremayevenbemultiple\ncacheswithprogressivelysloweraccesstimes). Atthethirdlevelinthehierarchyis\ntheinternalmemory,whichisalso knownasmainmemoryorcorememory. The\ninternal memory is considerably larger than the cache memory, but also requires\nmore time to access. Finally, at the highest level in the hierarchy is the external\nmemory, which usually consists of disks, CD drives, DVD drives, and/or tapes.\nThismemoryisverylarge,butitisalsoveryslow. Thus,thememoryhierarchyfor\ncomputers can be viewed as consisting of four levels, each of which is larger and\nslowerthanthepreviouslevel. (SeeFigure14.3.)\nIn most applications, however, only two levels really matter\u2014the one that can\nholdalldataitemsandtheleveljustbelowthatone. Bringingdataitemsinandout\nof the higher memory that can hold all items will typically be the computational\nbottleneck inthiscase.\nFigure14.3: Thememoryhierarchy.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 674 \u2014 #696\ni i\n674 Chapter14. MemoryManagementandB-Trees\nCaches and Disks\nSpecifically, the two levels that matter most depend on the size of the problem\nwe are trying to solve. For a problem that can fit entirely in main memory, the\ntwomostimportant levelsarethe cachememoryand theinternal memory. Access\ntimes for internal memory can be as much as 10 to 100 times longer than those\nfor cache memory. It is desirable, therefore, to be able to perform most memory\naccessesincachememory. Foraproblemthatdoesnotfitentirelyinmainmemory,\non the other hand, the two most important levels are the internal memory and the\nexternalmemory. Herethedifferencesareevenmoredramatic. Foraccesstimesfor\ndisks, the usual general-purpose, external-memory devices, are typically as much\nas100,000 to1,000,000 timeslongerthanthoseforinternal memory.\nToputthislatterfigureintoperspective,imaginethereisastudentinBaltimore\nwho wants to send a request-for-money message to his parents in Chicago. If the\nstudent sends his parents an e-mail message, it can arrive at their home computer\nin about five seconds. Think of this mode of communication as corresponding to\naninternal-memory accessbyaCPU.Amodeofcommunicationcorresponding to\nan external-memory access that is 500,000 times slower would be for the student\nto walk to Chicago and deliver his message in person, which would take about a\nmonth if he can average 20 miles per day. Thus, we should make as few accesses\ntoexternal memoryaspossible.\n14.2.2 Caching Strategies\nMost algorithms are not designed with the memory hierarchy in mind, in spite of\nthe great variance between access times for the different levels. Indeed, all of the\nalgorithm analyses described in this book so far have assumed that all memory\naccesses are equal. Thisassumption might seem, at first, tobeagreat oversight\u2014\nandoneweareonlyaddressingnowinthefinalchapter\u2014buttherearegoodreasons\nwhyitisactually areasonable assumptiontomake.\nOnejustification forthisassumption isthatitisoftennecessary toassumethat\nallmemoryaccessestakethesameamountoftime,sincespecificdevice-dependent\ninformation about memory sizes is often hard to come by. In fact, information\nabout memorysize maybe impossible to get. Forexample, aC++ program that is\ndesignedtorunonmanydifferentcomputerplatformscannotbedefinedintermsof\na specific computer architecture configuration. We can certainly use architecture-\nspecific information, if we have it (and we show how to exploit such information\nlaterinthischapter). Butoncewehaveoptimized oursoftware foracertain archi-\ntecture configuration, our software is no longer device-independent. Fortunately,\nsuchoptimizations arenotalwaysnecessary, primarilybecauseofthesecondjusti-\nficationfortheequal-time, memory-access assumption.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 675 \u2014 #697\ni i\n14.2. ExternalMemoryandCaching 675\nCaching and Blocking\nAnother justification for the memory-access equality assumption is that operating\nsystemdesigners havedeveloped generalmechanismsthatallowformostmemory\naccesses to be fast. These mechanisms are based on two important locality-of-\nreferenceproperties thatmostsoftwarepossesses.\nTemporal locality: If a program accesses a certain memory location, then\n\u2022\nit is likely to access this location again in the near future. For example, itis\nquite common to use the value of a counter variable in several different ex-\npressions, includingonetoincrementthecounter\u2019svalue. Infact,acommon\nadageamongcomputerarchitects isthat\u201caprogramspends90percentofits\ntimein10percentofitscode.\u201d\nSpatial locality: Ifaprogram accesses acertain memory location, then itis\n\u2022\nlikelytoaccessotherlocationsthatarenearthisone. Forexample,aprogram\nusinganarrayislikely toaccessthelocations ofthisarrayinasequential or\nnear-sequential manner.\nComputerscientistsandengineers haveperformedextensivesoftwareprofilingex-\nperiments to justify the claim that most software possesses both of these kinds of\nlocality-of-reference. For example, a for-loop used to scan through an array ex-\nhibitsbothkindsoflocality.\nTemporal and spatial localities have, in turn, given rise to two fundamental\ndesign choices for two-level computer memory systems (which are present in the\ninterface between cache memory and internal memory, and also in the interface\nbetweeninternalmemoryandexternalmemory).\nThefirstdesign choice iscalled virtualmemory. Thisconcept consists ofpro-\nviding an address space as large as the capacity of the secondary-level memory,\nandoftransferring datalocatedinthesecondarylevel,intotheprimarylevel,when\ntheyareaddressed. Virtualmemorydoesnotlimittheprogrammertotheconstraint\noftheinternal memorysize. Theconcept ofbringing dataintoprimary memoryis\ncalledcaching,anditismotivatedbytemporallocality. Because, bybringing data\ninto primary memory, we are hoping that it will be accessed again soon, and we\nwillbeabletorespondquicklytoalltherequestsforthisdatathatcomeinthenear\nfuture.\nThe second design choice is motivated by spatial locality. Specifically, if data\nstored at a secondary-level memory location l is accessed, then we bring into\nprimary-level memory, a large block of contiguous locations that include the lo-\ncation l. (SeeFigure14.4.) Thisconcept isknownasblocking, anditismotivated\nbytheexpectationthatothersecondary-level memorylocationsclosetol willsoon\nbe accessed. In the interface between cache memory and internal memory, such\nblocks are often called cache lines, and in the interface between internal memory\nandexternalmemory,suchblocksareoftencalledpages.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 676 \u2014 #698\ni i\n676 Chapter14. MemoryManagementandB-Trees\nFigure14.4: Blocksinexternalmemory.\nWhen implemented with caching and blocking, virtual memory often allows\nus to perceive secondary-level memory as being faster than it really is. There is\nstill a problem, however. Primary-level memory is much smaller than secondary-\nlevel memory. Moreover, because memory systems use blocking, any program\nof substance will likely reach a point where it requests data from secondary-level\nmemory, but the primary memory is already full of blocks. In order to fulfill the\nrequestandmaintainouruseofcachingandblocking,wemustremovesomeblock\nfrom primary memory to make room for a new block from secondary memory in\nthis case. Deciding how to do this eviction brings up a number of interesting data\nstructure andalgorithm designissues.\nCaching Algorithms\nThere are several Web applications that must deal with revisiting information pre-\nsented inWebpages. Theserevisits have been showntoexhibit localities ofrefer-\nence, both in time and in space. To exploit these localities of reference, it is often\nadvantageous tostorecopies ofWebpages inacachememory, sothesepages can\nbequickly retrieved whenrequested again. Inparticular, suppose wehaveacache\nmemorythathasm\u201cslots\u201dthatcancontainWebpages. WeassumethataWebpage\ncanbeplacedinanyslotofthecache. Thisisknownasafullyassociative cache.\nAsabrowser executes, itrequests different Webpages. Eachtimethebrowser\nrequests such a Web page l, the browser determines (using a quick test) if l is\nunchangedandcurrentlycontainedinthecache. Ifl iscontainedinthecache,then\nthe browser satisfies the request using the cached copy. If l is not in the cache,\nhowever,thepageforlisrequestedovertheInternetandtransferredintothecache.\nIf one of the m slots in the cache is available, then the browser assigns l to one of\ntheemptyslots. Butifallthemcellsofthecache areoccupied, thenthecomputer\nmust determine which previously viewed Web page to evict before bringing in l\nto take its place. There are, of course, many different policies that can be used to\ndeterminethepagetoevict.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 677 \u2014 #699\ni i\n14.2. ExternalMemoryandCaching 677\nPage Replacement Algorithms\nSome of the better-known page replacement policies include the following (see\nFigure14.5):\nFirst-in, first-out (FIFO): Evict the page that has been in the cache the\n\u2022\nlongest,thatis,thepagethatwastransferredtothecachefurthestinthepast.\nLeastrecentlyused(LRU):Evictthepagewhoselastrequestoccurred fur-\n\u2022\nthestinthepast.\nInaddition, wecanconsiderasimpleandpurelyrandomstrategy:\nRandom: Chooseapageatrandom toevictfromthecache.\n\u2022\nFigure14.5: TheRandom,FIFO,andLRUpagereplacement policies.\nTheRandomstrategyisoneoftheeasiestpoliciestoimplement,becauseitonly\nrequires arandom orpseudo-random number generator. Theoverhead involved in\nimplementing this policy is an O(1) additional amount of work per page replace-\nment. Moreover,thereisnoadditionaloverheadforeachpagerequest,otherthanto\ndetermine whetherapagerequest isinthecacheornot. Still,thispolicymakesno\nattempttotakeadvantageofanytemporalorspatiallocalitiesthatauser\u2019sbrowsing\nexhibits.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 678 \u2014 #700\ni i\n678 Chapter14. MemoryManagementandB-Trees\nThe FIFO strategy is quite simple to implement, because it only requires a\nqueue Q to store references to the pages in the cache. Pages are enqueued in Q\nwhentheyarereferenced byabrowser, andthenarebrought intothecache. When\na page needs to be evicted, the computer simply performs a dequeue operation on\nQtodeterminewhichpagetoevict. Thus,thispolicyalsorequiresO(1)additional\nwork per page replacement. Also, the FIFO policy incurs no additional overhead\nforpagerequests. Moreover,ittriestotakesomeadvantage oftemporallocality.\nThe LRU strategy goes a step further than the FIFO strategy, since the LRU\nstrategy explicitly takes advantage oftemporal locality asmuchaspossible, byal-\nways evicting the page that was least recently used. From a policy point of view,\nthisisanexcellentapproach, butitiscostlyfromanimplementation pointofview.\nThat is, its way of optimizing temporal and spatial locality is fairly costly. Im-\nplementing the LRU strategy requires the use of a priority queue Q that supports\nsearching for existing pages, for example, using special pointers or \u201clocators.\u201d If\nQisimplemented withasorted sequence based on alinked list, then the overhead\nfor each page request and page replacement is O(1). When we insert a page in Q\norupdateitskey,thepageisassigned thehighest keyinQandisplaced attheend\nofthelist,whichcanalsobedoneinO(1)time. EventhoughtheLRUstrategyhas\nconstant-time overhead, using the implementation above, the constant factors in-\nvolved,intermsoftheadditionaltimeoverheadandtheextraspaceforthepriority\nqueueQ,makethispolicylessattractive fromapractical pointofview.\nSince these different page replacement policies have different trade-offs be-\ntween implementation difficulty and the degree to which they seem to take advan-\ntage of localities, it is natural for us to ask for some kind of comparative analysis\nofthesemethodstoseewhichone,ifany,isthebest.\nFrom a worst-case point of view, the FIFO and LRU strategies have fairly\nunattractive competitive behavior. For example, suppose we have a cache con-\ntaining m pages, and consider the FIFO and LRU methods for performing page\nreplacement for a program that has a loop that repeatedly requests m+1 pages in\nacyclicorder. BoththeFIFOandLRUpolicies perform badlyonsuchasequence\nofpage requests, because they perform apage replacement onevery page request.\nThus, from a worst-case point of view, these policies are almost the worst we can\nimagine\u2014they requireapagereplacement oneverypagerequest.\nThis worst-case analysis is a little too pessimistic, however, for it focuses on\neach protocol\u2019s behavior for one bad sequence of page requests. An ideal analy-\nsis would be to compare these methods over all possible page-request sequences.\nOf course, this is impossible to do exhaustively, but there have been a great num-\nberofexperimental simulations doneonpage-request sequences derived fromreal\nprograms. Based on these experimental comparisons, the LRU strategy has been\nshown tobe usually superior to the FIFOstrategy, whichis usually better than the\nRandomstrategy.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 679 \u2014 #701\ni i\n14.3. ExternalSearchingandB-Trees 679\n14.3 External Searching and B-Trees\nConsidertheproblemofimplementingthemapADTforalargecollectionofitems\nthat do not fit in main memory. Since one of the main uses of a large map is in a\ndatabase, we refer to the secondary-memory blocks as disk blocks. Likewise, we\nrefer to the transfer of a block between secondary memory and primary memory\nas a disk transfer. Recalling the great time difference that exists between main\nmemoryaccessesanddiskaccesses,themaingoalofmaintainingamapinexternal\nmemory isto minimize the number of disk transfers needed toperform aquery or\nupdate. Infact,thedifferenceinspeedbetweendiskandinternalmemoryissogreat\nthat we should be willing to perform a considerable number of internal-memory\naccesses if they allow us to avoid a few disk transfers. Let us, therefore, analyze\ntheperformance ofmapimplementations bycounting thenumberofdisktransfers\neachwouldrequire toperform thestandard mapsearchandupdateoperations. We\nrefertothiscountastheI/Ocomplexity ofthealgorithmsinvolved.\nSome Inefficient External-Memory Dictionaries\nLet us first consider the simple map implementations that use a list to store n en-\ntries. If the list is implemented as an unsorted, doubly linked list, then insert and\nremove operations can be performed with O(1) transfers each, but removals and\nsearchesrequirentransfersintheworstcase,sinceeachlinkhopweperformcould\naccess a different block. This search time can be improved to O(n/B) transfers\n(see Exercise C-14.2), whereB denotes the number ofnodes of thelist that can fit\nintoablock,butthisisstillpoorperformance. Wecouldalternately implementthe\nsequence using a sorted array. In this case, a search performs O(log n) transfers,\n2\nviabinarysearch, whichisaniceimprovement. Butthissolution requires \u0398(n/B)\ntransfers toimplementaninsertorremoveoperation intheworstcase,becausewe\nmayhave toaccess allblocks tomoveelements upordown. Thus, list-based map\nimplementations arenotefficientinexternalmemory.\nSincethesesimpleimplementations areI/Oinefficient, weshould consider the\nlogarithmic-time, internal-memory strategies that use balanced binary trees (for\nexample, AVLtrees or red-black trees) orother search structures withlogarithmic\naverage-case queryandupdatetimes(forexample,skiplistsorsplaytrees). These\nmethods store the mapitemsatthenodes ofabinary tree orofagraph. Typically,\neach node accessed for a query or update in one of these structures will be in a\ndifferent block. Thus, these methods all require O(log n) transfers in the worst\n2\ncase to perform a query or update operation. This performance is good, but we\ncan do better. In particular, we can perform map queries and updates using only\nO(log n)=O(logn/logB)transfers.\nB\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 680 \u2014 #702\ni i\n680 Chapter14. MemoryManagementandB-Trees\n14.3.1 (a,b) Trees\nToreduce the importance oftheperformance difference between internal-memory\naccesses and external-memory accesses for searching, we can represent our map\nusing a multi-way search tree (Section 10.4.1). This approach gives rise to a gen-\neralization ofthe(2,4)treedatastructure knownasthe(a,b)tree.\nAn(a,b)treeisamulti-waysearchtreesuchthateachnodehasbetweenaand\nbchildrenandstoresbetweena 1andb 1entries. Thealgorithmsforsearching,\n\u2212 \u2212\ninserting, andremovingentriesinan(a,b)treearestraightforward generalizations\nof the corresponding algorithms for (2,4) trees. The advantage of generalizing\n(2,4) trees to (a,b) trees is that a generalized class of trees provides a flexible\nsearch structure, where the size of the nodes and the running time of the various\nmap operations depends on the parameters a and b. By setting the parameters a\nand b appropriately with respect to the size of disk blocks, we can derive a data\nstructure thatachievesgoodexternal-memory performance.\nDefinition of an (a,b) Tree\nAn(a,b) tree, whereaand b areintegers, such that 2 a (b+1)/2, is amulti-\n\u2264 \u2264\nwaysearchtreeT withthefollowingadditional restrictions:\nSizeProperty: Each internal node has atleast achildren, unless itis theroot, and\nhasatmostbchildren.\nDepthProperty: Alltheexternalnodeshavethesamedepth.\nProposition 14.1: Theheightofan(a,b)treestoringnentriesis\u2126(logn/logb)\nandO(logn/loga).\nJustification: LetT bean(a,b)treestoring nentries, andlethbetheheightof\nT. Wejustifytheproposition byestablishing thefollowingboundsonh\n1 1 n+1\nlog(n+1) h log +1.\nlogb \u2264 \u2264 loga 2\nBy the size and depth properties, the number n\u2032\u2032 of external nodes of T is at least\n2ah\u22121 andatmostbh. ByProposition 10.7,n\u2032\u2032=n+1. Thus\n2ah\u22121 n+1 bh.\n\u2264 \u2264\nTakingthelogarithm inbase2ofeachterm,weget\n(h 1)loga+1 log(n+1) hlogb.\n\u2212 \u2264 \u2264\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 681 \u2014 #703\ni i\n14.3. ExternalSearchingandB-Trees 681\nSearch and Update Operations\nWe recall that in a multi-way search tree T, each node v of T holds a secondary\nstructure M(v), which is itself a map (Section 10.4.1). If T is an (a,b) tree, then\nM(v) stores at most b entries. Let f(b) denote the time for performing a search\nin a map, M(v). The search algorithm in an (a,b) tree is exactly like the one for\nmulti-way search trees given in Section 10.4.1. Hence, searching in an (a,b) tree\nT withnentries takes O((f(b)/loga)logn)time. Notethat ifbis aconstant (and\nthusaisalso),thenthesearchtimeisO(logn).\nThe main application of (a,b) trees is for maps stored in external memory.\nNamely, to minimize disk accesses, we select the parameters a and b so that each\ntreenodeoccupies asinglediskblock(sothat f(b)=1ifwewishtosimplycount\nblock transfers). Providing the right a and b values in this context gives rise to a\ndatastructure knownastheB-tree, whichwedescribe shortly. Beforewedescribe\nthis structure, however, let us discuss how insertions and removals are handled in\n(a,b)trees.\nThe insertion algorithm for an (a,b) tree is similar to that for a (2,4) tree.\nAn overflow occurs when an entry is inserted into a b-node v, which becomes an\nillegal (b+1)-node. (Recall that anode in a multi-way tree is a d-node if ithas d\nchildren.) Toremedyanoverflow,wesplitnodevbymovingthemedianentryofv\ninto the parent of vand replacing v with a (b+1)/2 -node v\u2032 and a (b+1)/2 -\n\u2308 \u2309 \u230a \u230b\nnode v\u2032\u2032. We can now see the reason for requiring a (b+1)/2 in the definition\n\u2264\nof an (a,b) tree. Note that, as a consequence of the split, we need to build the\nsecondary structures M(v\u2032)andM(v\u2032\u2032).\nRemoving an entry from an (a,b) tree is similar to what was done for (2,4)\ntrees. Anunderflowoccurswhenakeyisremovedfromana-node v,distinctfrom\ntheroot,whichcausesvtobecomeanillegal(a 1)-node. Toremedyanunderflow,\n\u2212\nweperformatransferwithasiblingofvthatisnotana-nodeorweperformafusion\nofvwithasiblingthatisana-node. Thenewnodewresulting fromthefusionisa\n(2a 1)-node, whichisanotherreasonforrequiring a (b+1)/2.\n\u2212 \u2264\nTable14.1showstheperformance ofamaprealizedwithan(a,b)tree.\nOperation Time\nfind O f(b) logn\nloga\ninsert O(cid:16)g(b) logn(cid:17)\nloga\nerase O(cid:16)g(b) logn(cid:17)\nloga\nTable14.1:Timeboundsforann-entrymap(cid:16)realizedby(cid:17)an(a,b)treeT. Weassume\nthesecondarystructureofthenodesofT supportsearchin f(b)time,andsplitand\nfusion operations in g(b) time, for some functions f(b) and g(b), which can be\nmadetobeO(1)whenweareonlycounting disktransfers.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 682 \u2014 #704\ni i\n682 Chapter14. MemoryManagementandB-Trees\n14.3.2 B-Trees\nA version of the (a,b) tree data structure, which is the best known method for\nmaintainingamapinexternalmemory,iscalledthe\u201cB-tree.\u201d (SeeFigure14.6.) A\nB-tree of order d is an (a,b) tree with a= d/2 and b=d. Since we discussed\n\u2308 \u2309\nthe standard map query and update methods for (a,b) trees above, we restrict our\ndiscussion heretotheI/OcomplexityofB-trees.\nFigure14.6: AB-treeoforder6.\nAnimportantproperty ofB-treesisthatwecanchoosed sothatthed children\nreferences and the d 1 keys stored at a node can all fit into a single disk block,\n\u2212\nimplying that d is proportional to B. This choice allows us to assume that a and\nb are also proportional to B in the analysis of the search and update operations on\n(a,b) trees. Thus, f(b) and g(b) are both O(1), because each time we access a\nnode to perform a search or an update operation, we need only perform a single\ndisktransfer.\nAs we have already observed above, each search or update requires that we\nexamine at most O(1) nodes for each level of the tree. Therefore, any map search\norupdate operation onaB-treerequires onlyO(log n), thatis,O(logn/logB)\n\u2308d/2\u2309\ndisktransfers. Forexample,aninsertoperation proceeds downtheB-treetolocate\nthe node in which to insert the new entry. If the node overflows (to have d+1\nchildren) because of this addition, then this node is split into two nodes that have\n(d+1)/2 and (d+1)/2 children, respectively. This process is then repeated\n\u230a \u230b \u2308 \u2309\natthenextlevelup,andcontinues foratmostO(log n)levels.\nB\nLikewise,ifaremoveoperationresultsinanodeunderflow(tohave d/2 1\n\u2308 \u2309\u2212\nchildren), then we move references from a sibling node with at least d/2 +1\n\u2308 \u2309\nchildrenorweneedtoperformafusionoperationofthisnodewithitssibling(and\nrepeat this computation atthe parent). Aswith the insert operation, this continues\nuptheB-treeforatmostO(log n)levels. Therequirement thateachinternalnode\nB\nhasatleast d/2 children implies thateach disk block used tosupport aB-treeis\n\u2308 \u2309\natleasthalffull. Thus,wehavethefollowing.\nProposition 14.2: AB-treewithnentrieshasI/OcomplexityO(log n)forsearch\nB\norupdateoperation,andusesO(n/B)blocks,whereBisthesizeofablock.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 683 \u2014 #705\ni i\n14.4. External-MemorySorting 683\n14.4 External-Memory Sorting\nInadditiontodatastructures,suchasmaps,thatneedtobeimplementedinexternal\nmemory,therearemanyalgorithmsthatmustalsooperateoninputsetsthataretoo\nlarge to fit entirely into internal memory. In this case, the objective is to solve the\nalgorithmic problem using as few block transfers as possible. The most classic\ndomainforsuchexternal-memory algorithms isthesortingproblem.\nMulti-Way Merge-Sort\nAnefficient wayto sort aset S of nobjects inexternal memoryamounts to asim-\npleexternal-memoryvariationonthefamiliarmerge-sortalgorithm. Themainidea\nbehind this variation is to merge many recursively sorted lists at a time, thereby\nreducing the number of levels of recursion. Specifically, a high-level description\nofthis multi-way merge-sort method istodivide S into d subsets S , S , ...,S of\n1 2 d\nroughly equal size, recursively sort each subset S,and then simultaneously merge\ni\nalld sortedlistsintoasortedrepresentation ofS. Ifwecanperformthemergepro-\ncess using only O(n/B)disktransfers, then, forlarge enough values ofn, thetotal\nnumberoftransfers performedbythisalgorithm satisfiesthefollowingrecurrence\nt(n)=d t(n/d)+cn/B,\n\u00b7\nfor some constant c 1. We can stop the recursion when n B, since we can\n\u2265 \u2264\nperform a single block transfer at this point, getting all of the objects into internal\nmemory, and then sort the set with an efficient internal-memory algorithm. Thus,\nthestopping criterionfort(n)is\nt(n)=1 ifn/B 1.\n\u2264\nThisimpliesaclosed-form solution thatt(n)isO((n/B)log (n/B)),whichis\nd\nO((n/B)log(n/B)/logd).\nThus, if we can choose d to be \u0398(M/B), then the worst-case number of block\ntransfersperformedbythismulti-waymerge-sortalgorithmisquitelow. Wechoose\nd =(1/2)M/B.\nTheonlyaspectofthisalgorithmlefttospecifyishowtoperformthed-waymerge\nusingonlyO(n/B)blocktransfers.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 684 \u2014 #706\ni i\n684 Chapter14. MemoryManagementandB-Trees\n14.4.1 Multi-Way Merging\nWeperform the d-way merge by running a\u201ctournament.\u201d We let T be a complete\nbinary tree with d external nodes, and wekeep T entirely in internal memory. We\nassociateeachexternalnodeiofT withadifferentsortedlistS. WeinitializeT by\ni\nreadingintoeachexternalnodei,thefirstobjectinS. Thishastheeffectofreading\ni\ninto internal memory the first block of each sorted list S. For each internal-node\ni\nparent v of two external nodes, wethen compare the objects stored at v\u2019s children\nand we associate the smaller of the two with v. We repeat this comparison test at\nthenextlevelupinT,andthenext, andsoon. Whenwereach therootr ofT,we\nassociate the smallest object from among all the lists with r. This completes the\ninitialization forthed-waymerge. (SeeFigure14.7.)\nFigure14.7: Ad-waymerge. Weshowafive-waymergewithB=4.\nInageneralstepofthed-waymerge,wemovetheobjectoassociated withthe\nrootrofT intoanarraywearebuildingforthemergedlistS\u2032. Wethentracedown\nT, following the path to the external node i that o came from. Wethen read into i\nthenextobjectinthelistS. Ifowasnotthelastelementinitsblock,thenthisnext\ni\nobject isalready ininternal memory. Otherwise, wereadinthenextblock ofS to\ni\naccessthisnewobject(ifS isnowempty,associatethenodeiwithapseudo-object\ni\nwithkey+ ). Wethenrepeattheminimumcomputations foreachoftheinternal\n\u221e\nnodes from i to the root of T. This again gives us the complete tree T. We then\nrepeat this process of moving the object from the root of T to the merged list S\u2032,\nandrebuildingT,untilT isemptyofobjects. EachstepinthemergetakesO(logd)\ntime; hence, the internal time for the d-way merge is O(nlogd). The number of\ntransfers performed inamergeisO(n/B),sincewescaneachlistS inorderonce,\ni\nandwewriteoutthemergedlistS\u2032 once. Thus,wehave:\nProposition 14.3: Givenanarray-basedsequenceS ofn elementsstoredinex-\nternalmemory,wecansortS usingO((n/B)log(n/B)/log(M/B)) transfersand\nO(nlogn)internalCPUtime,whereMisthesizeoftheinternalmemoryandBis\nthesizeofablock.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 685 \u2014 #707\ni i\n14.5. Exercises 685\n14.5 Exercises\nForhelpwithexercises,pleasevisitthewebsite,www.wiley.com/college/goodrich.\nReinforcement\nR-14.1 Juliajustboughtanewcomputerthatuses64-bitintegerstoaddressmem-\nory cells. Argue why Julia will never in her life be able to upgrade the\nmain memory of her computer so that it is the maximum size possible,\nassumingthatyouhavetohavedistinctatomstorepresentdifferentbits.\nR-14.2 Describe, indetail, addandremovealgorithms foran(a,b)tree.\nR-14.3 SupposeT isamulti-waytreeinwhicheachinternalnodehasatleastfive\nand at most eight children. For what values of a and b is T a valid (a,b)\ntree?\nR-14.4 For what values of d is the tree T of the previous exercise an order-d\nB-tree?\nR-14.5 Showeach levelofrecursion inperforming afour-way, external-memory\nmerge-sort ofthesequence giveninthepreviousexercise.\nR-14.6 Consideraninitiallyemptymemorycacheconsisting offourpages. How\nmany page misses does the LRU algorithm incur on the following page\nrequestsequence: (2,3,4,1,2,5,1,3,5,4,1,2,3)?\nR-14.7 Consideraninitiallyemptymemorycacheconsisting offourpages. How\nmany page misses does the FIFO algorithm incur on the following page\nrequestsequence: (2,3,4,1,2,5,1,3,5,4,1,2,3)?\nR-14.8 Consideraninitiallyemptymemorycacheconsisting offourpages. How\nmany page misses can the random algorithm incur onthe following page\nrequest sequence: (2,3,4,1,2,5,1,3,5,4,1,2,3)? Showalloftheran-\ndomchoices youralgorithm madeinthiscase.\nR-14.9 Draw the result of inserting, into an initially empty order-7 B-tree, the\nkeys(4,40,23,50,11,34,62,78,66,22,90,59,25,72,64,77,39,12).\nR-14.10 Show each level of recursion in performing a four-way merge-sort of the\nsequence givenintheprevious exercise.\nCreativity\nC-14.1 Describeanefficientexternal-memory algorithm forremovingallthedu-\nplicateentriesinavectorofsizen.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 686 \u2014 #708\ni i\n686 Chapter14. MemoryManagementandB-Trees\nC-14.2 Showhowtoimplementamapinexternalmemoryusinganunorderedse-\nquencesothatinsertions requireonlyO(1)transfersandsearches require\nO(n/B)transfersintheworstcase,wherenisthenumberofelementsand\nBisthenumberoflistnodesthatcanfitintoadiskblock.\nC-14.3 Change the rules that define red-black trees so that each red-black tree T\nhasacorresponding (4,8)treeandviceversa.\nC-14.4 DescribeamodifiedversionoftheB-treeinsertion algorithm sothateach\ntimewecreate an overflow because ofasplit of anode v, weredistribute\nkeysamongallofv\u2019ssiblings,sothateachsiblingholdsroughlythesame\nnumber ofkeys (possibly cascading the split uptotheparent ofv). What\nistheminimumfractionofeachblockthatwillalwaysbefilledusingthis\nscheme?\nC-14.5 Another possible external-memory map implementation is to use a skip\nlist,buttocollectconsecutivegroupsofO(B)nodes,inindividualblocks,\non any level in the skip list. In particular, we define an order-d B-skip\nlist to be such a representation of a skip-list structure, where each block\ncontains at least d/2 list nodes and at most d list nodes. Let us also\n\u2308 \u2309\nchoosedinthiscasetobethemaximumnumberoflistnodesfromalevel\nof a skip list that can fitinto one block. Describe how we should modify\nthe skip-list insertion and removal algorithms for a B-skip list so that the\nexpected heightofthestructure isO(logn/logB).\nC-14.6 Describeanexternal-memorydatastructuretoimplementthequeueADT\nsothatthetotalnumber ofdisk transfers needed toprocess asequence of\nnenqueueanddequeueoperations isO(n/B).\nC-14.7 Solvetheprevious problem forthedequeADT.\nC-14.8 DescribehowtouseaB-treetoimplementthepartition(union-find)ADT\n(from Section 11.4.3) so that the union and find operations each use at\nmostO(logn/logB)disktransfers.\nC-14.9 Suppose we are given a sequence S of n elements with integer keys such\nthat some elements in S are colored \u201cblue\u201d and some elements in S are\ncolored \u201cred.\u201d In addition, say that a red element e pairs with a blue\nelement f iftheyhavethesamekeyvalue. Describeanefficientexternal-\nmemoryalgorithm forfinding all thered-blue pairs inS. Howmanydisk\ntransfers doesyouralgorithm perform?\nC-14.10 Consider the page caching problem where the memory cache can hold m\npages, and we are given a sequence P of n requests taken from a pool\nof m+1 possible pages. Describe the optimal strategy for the offline\nalgorithm and show that it causes at most m+n/m page misses in total,\nstarting fromanemptycache.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 687 \u2014 #709\ni i\nChapterNotes 687\nC-14.11 Consider the page caching strategy based on the least frequently used\n(LFU) rule, where the page in the cache that has been accessed the least\noften is theone that isevicted when anewpage isrequested. Ifthere are\nties, LFUevicts the least frequently used page that has been in the cache\nthelongest. ShowthatthereisasequencePofnrequeststhatcausesLFU\ntomiss\u2126(n)timesforacacheofmpages,whereastheoptimalalgorithm\nwillmissonlyO(m)times.\nC-14.12 Suppose that instead of having the node-search function f(d)=1 in an\norder-d B-tree T, we have f(d)=logd. What does the asymptotic run-\nningtimeofperforming asearchinT nowbecome?\nC-14.13 Describeanefficientexternal-memory algorithm thatdetermineswhether\nanarrayofnintegerscontains avalueoccurring morethann/2times.\nProjects\nP-14.1 Write a C++ class that simulates the best-fit, worst-fit, first-fit, and next-\nfitalgorithmsformemorymanagement. Determineexperimentally which\nmethodisthebestundervarioussequences ofmemoryrequests.\nP-14.2 Write a C++ class that implements all the functions of the ordered map\nADTbymeansofan(a,b)tree,whereaandbareintegerconstantspassed\nasparameterstoaconstructor.\nP-14.3 Implement the B-tree data structure, assuming a block size of 1,024 and\ninteger keys. Test the number of \u201cdisk transfers\u201d needed to process a\nsequence ofmapoperations.\nP-14.4 Implement an external-memory sorting algorithm and compare it experi-\nmentallytoanyinternal-memory sortingalgorithm.\nChapter Notes\nThe mark-sweep garbage collection method we describe is one of many different algo-\nrithms for performing garbage collection. We encourage the reader interested in further\nstudyofgarbagecollectiontoexaminethebookbyJones[51].\nKnuth [57] has very nice discussions about external-memory sorting and searching,\nand Ullman [97] discusses externalmemory structuresfor database systems. The reader\ninterestedinthestudyofthearchitectureofhierarchicalmemorysystemsisreferredtothe\nbookchapterbyBurgeretal.[18]orthebookbyHennessyandPatterson[44]. Thehand-\nbookbyGonnetandBaeza-Yates[37]comparestheperformanceofanumberofdifferent\nsortingalgorithms,manyofwhichareexternal-memoryalgorithms.\nB-treeswereinventedbyBayerandMcCreight[10] andComer[23] providesa very\nniceoverviewofthisdatastructure.ThebooksbyMehlhorn[73]andSamet[87]alsohave\nnice discussions about B-trees and their variants. Aggarwal and Vitter [2] study the I/O\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 688 \u2014 #710\ni i\n688 Chapter14. MemoryManagementandB-Trees\ncomplexityofsortingandrelatedproblems,establishingupperandlowerbounds,includ-\ning the lower bound for sorting given in this chapter. Goodrich et al. [40] study the I/O\ncomplexityofseveralcomputationalgeometryproblems. Thereaderinterestedinfurther\nstudyofI/O-efficientalgorithmsisencouragedtoexaminethesurveypaperofVitter[99].\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 689 \u2014 #711\ni i\nAppendix\nA\nUseful Mathematical Facts\nIn this appendix, we give several useful mathematical facts. We begin with some\ncombinatorial definitionsandfacts.\nLogarithms and Exponents\nThelogarithm function isdefinedas\nlog a=c if a=bc.\nb\nThefollowingidentities holdforlogarithmsandexponents:\n1. log ac=log a+log c\nb b b\n2. log a/c=log a log c\nb b b\n\u2212\n3. log ac=clog a\nb b\n4. log a=(log a)/log b\nb c c\n5. blog c a=alog c b\n6. (ba)c=bac\n7. babc=ba+c\n8. ba/bc =ba\u2212c\nInaddition, wehavethefollowing.\nProposition A.1: Ifa>0,b>0,andc>a+b,then\nloga+logb 2logc 2.\n\u2264 \u2212\nJustification: Itisenoughtoshowthatab<c2/4. Wecanwrite\na2+2ab+b2 a2+2ab b2\nab = \u2212 \u2212\n4\n(a+b)2 (a b)2 (a+b)2 c2\n= \u2212 \u2212 < .\n4 \u2264 4 4\nThenaturallogarithmfunctionlnx=log x,wheree=2.71828...,isthevalue\ne\nofthefollowingprogression:\n1 1 1\ne=1+ + + + .\n1! 2! 3! \u00b7\u00b7\u00b7\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 690 \u2014 #712\ni i\n690 AppendixA. UsefulMathematicalFacts\nInaddition,\nx x2 x3\nex=1+ + + +\n1! 2! 3! \u00b7\u00b7\u00b7\nx2 x3 x4\nln(1+x)=x + + .\n\u22122! 3!\u22124! \u00b7\u00b7\u00b7\nThere are a number of useful inequalities relating to these functions (which\nderivefromthesedefinitions).\nProposition A.2: Ifx> 1\n\u2212\nx\nln(1+x) x.\n1+x \u2264 \u2264\nProposition A.3: For0 x<1\n\u2264\n1\n1+x ex .\n\u2264 \u2264 1 x\n\u2212\nProposition A.4: Foranytwopositiverealnumbersxandn\nx n x n+x/2\n1+ ex 1+ .\nn \u2264 \u2264 n\n(cid:16) (cid:17) (cid:16) (cid:17)\nInteger Functions and Relations\nThe\u201cfloor\u201dand\u201cceiling\u201d functions aredefinedrespectively asfollows:\n1. x =thelargestintegerlessthanorequaltox\n\u230a \u230b\n2. x =thesmallestintegergreaterthanorequaltox.\n\u2308 \u2309\nThemodulooperatorisdefinedforintegersa 0andb>0as\n\u2265\na\na mod b=a b.\n\u2212 b\nj k\nThefactorial function isdefinedas\nn!=1 2 3 (n 1)n.\n\u00b7 \u00b7 \u00b7\u00b7\u00b7\u00b7\u00b7 \u2212\nThebinomialcoefficientis\nn n!\n= ,\nk k!(n k)!\n(cid:18) (cid:19) \u2212\nwhichisequaltothenumberofdifferentcombinationsonecandefinebychoosing\nk different items from a collection of n items (where the order does not matter).\nThename\u201cbinomialcoefficient\u201d derivesfromthebinomialexpansion\n(a+b)n= \u2211 n n akbn\u2212k.\nk\nk=0(cid:18) (cid:19)\nWealsohavethefollowingrelationships.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 691 \u2014 #713\ni i\nAppendixA.UsefulMathematicalFacts 691\nProposition A.5: If0 k n,then\n\u2264 \u2264\nn k n nk\n.\nk \u2264 k \u2264 k!\n(cid:18) (cid:19)\n(cid:16) (cid:17)\nProposition A.6: StirlingsApproximation\nn n 1\nn!=\u221a2\u03c0n 1+ +\u03b5(n) ,\ne 12n\n(cid:18) (cid:19)\n(cid:16) (cid:17)\nwhere\u03b5(n)isO(1/n2).\nTheFibonacci progression isanumeric progression such that F =0, F =1,\n0 1\nandF =F +F forn 2.\nn n\u22121 n\u22122\n\u2265\nProposition A.7: IfF isdefinedbytheFibonacciprogression,thenF is\u0398(gn),\nn n\nwhereg=(1+\u221a5)/2istheso-calledgoldenratio.\nSummations\nThereareanumberofusefulfactsaboutsummations.\nProposition A.8: Factoringsummations\nn n\n\u2211 \u2211\naf(i)=a f(i),\ni=1 i=1\nprovidedadoesnotdependuponi.\nProposition A.9: Reversingtheorder\nn m m n\n\u2211 \u2211 \u2211 \u2211\nf(i,j)= f(i,j).\ni=1j=1 j=1i=1\nOnespecialformofsummationisatelescoping sum\nn\n\u2211\n(f(i) f(i 1))= f(n) f(0),\n\u2212 \u2212 \u2212\ni=1\nwhicharisesoftenintheamortized analysisofadatastructure oralgorithm.\nThe following are some other facts about summations that arise often in the\nanalysis ofdatastructures andalgorithms.\nProposition A.10: \u2211n i=n(n+1)/2.\ni=1\nProposition A.11: \u2211n i2=n(n+1)(2n+1)/6.\ni=1\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 692 \u2014 #714\ni i\n692 AppendixA. UsefulMathematicalFacts\nProposition A.12: Ifk 1isanintegerconstant,then\n\u2265\nn\n\u2211 ikis\u0398(nk+1).\ni=1\nAnother common summation is the geometric sum, \u2211n ai, for any fixed real\ni=0\nnumber0<a=1.\n6\nProposition A.13:\n\u2211 n ai= an+1 \u2212 1 ,\na 1\ni=0 \u2212\nforanyrealnumber0<a=1.\n6\nProposition A.14:\n\u2211 \u221e ai= 1\n1 a\ni=0 \u2212\nforanyrealnumber0<a<1.\nThereisalsoacombination ofthetwocommonforms, called thelinearexpo-\nnentialsummation, whichhasthefollowingexpansions\nProposition A.15: For0<a=1,andn 2\n6 \u2265\n\u2211 n iai= a \u2212 (n+1)a(n+1)+na(n+2) .\n(1 a)2\ni=1 \u2212\nThenthHarmonicnumberH isdefinedas\nn\n\u2211 n 1\nH = .\nn\ni\ni=1\nProposition A.16: IfH isthenthharmonicnumber,thenH islnn+\u0398(1).\nn n\nBasic Probability\nWe review some basic facts from probability theory. The most basic such fact is\nthat any statement about a probability is defined upon a sample space S, which is\ndefined as the set of all possible outcomes from some experiment. We leave the\nterms\u201coutcomes\u201d and\u201cexperiment\u201d undefinedinanyformalsense.\nExample A.17: Consideranexperimentthatconsistsoftheoutcomefromflip-\npingacoin5 times. Thissamplespacehas25 differentoutcomes,oneforeach\ndifferentorderingofpossibleflipsthatcanoccur.\nSamplespacescanalsobeinfinite,asthefollowingexampleillustrates.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 693 \u2014 #715\ni i\nAppendixA.UsefulMathematicalFacts 693\nExample A.18: Consideranexperimentthatconsistsofflippingacoinuntilit\ncomesupheads.Thissamplespaceisinfinite,witheachoutcomebeingasequence\nofitailsfollowedbyasingleflipthatcomesupheads,fori=1,2,3,....\nA probability space is a sample space S together with a probability function\nPr that maps subsets of S to real numbers in the interval [0,1]. It mathematically\ncapturesthenotionoftheprobability ofcertain\u201cevents\u201doccurring. Formally,each\nsubset A of S is called an event, and the probability function Pr is assumed to\npossessthefollowingbasicproperties withrespect toeventsdefinedfromS:\n1. Pr( )=0\n\u2205\n2. Pr(S)=1\n3. 0 Pr(A) 1,foranyA S\n\u2264 \u2264 \u2286\n4. IfA,B SandA B= ,thenPr(A B)=Pr(A)+Pr(B)\n\u2286 \u2229 \u2205 \u222a\nTwoeventsAandBareindependentif\nPr(A B)=Pr(A) Pr(B).\n\u2229 \u00b7\nAcollection ofevents A ,A ,...,A ismutuallyindependentif\n1 2 n\n{ }\nPr(A A A )=Pr(A )Pr(A ) Pr(A ).\ni1\u2229 i2\u2229\u00b7\u00b7\u00b7\u2229 ik i1 i2\n\u00b7\u00b7\u00b7\nik\nforanysubset A ,A ,...,A .\n{\ni1 i2 ik}\nTheconditionalprobability thataneventAoccurs,givenaneventBisdenoted\nasPr(A B),andisdefinedastheratio\n|\nPr(A B)\n\u2229 ,\nPr(B)\nassumingthatPr(B)>0.\nAn elegant way of dealing with events is in terms of random variables. Intu-\nitively, random variables are variables whose values depend upon the outcome of\nsomeexperiment. Formally,arandomvariableisafunctionX thatmapsoutcomes\nfrom some sample space S to real numbers. An indicator random variable is a\nrandom variable that maps outcomes to the set 0,1 . Often in data structure and\n{ }\nalgorithm analysis weusearandom variable X tocharacterize therunning timeof\na randomized algorithm. In this case the sample space S is defined by all possible\noutcomesoftherandom sourcesusedinthealgorithm.\nInsuchcaseswearemostinterestedinthetypical,average,or\u201cexpected\u201dvalue\nof such a random variable. The expected value of a random variable X is defined\nas\n\u2211\nE(X)= xPr(X =x),\nx\nwherethesummationisdefinedovertherangeofX (whichinthiscaseisassumed\ntobediscrete).\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 694 \u2014 #716\ni i\n694 AppendixA. UsefulMathematicalFacts\nProposition A.19 (The Linearity of Expectation): LetX andY betworan-\ndomvariablesandletcbeanumber.Then\nE(X+Y)=E(X)+E(Y) and E(cX)=cE(X).\nExample A.20: LetX bearandomvariablethatassignstheoutcomeoftheroll\noftwofairdicetothesumofthenumberofdotsshowing.ThenE(X)=7.\nJustification: TojustifythisclaimletX andX berandomvariablescorre-\n1 2\nspondingtothenumberofdotsoneachdie. Thus,X =X (thatis,theyaretwo\n1 2\ninstancesofthesamefunction)andE(X)=E(X +X )=E(X )+E(X ). Each\n1 2 1 2\noutcomeoftherollofafairdieoccurswithprobability1/6.Thus,\n1 2 3 4 5 6 7\nE(X)= + + + + + = ,\ni\n6 6 6 6 6 6 2\nfori=1,2.Therefore,E(X)=7.\nTworandom variablesX andY areindependentif\nPr(X =xY =y)=Pr(X =x),\n|\nforallrealnumbersxandy.\nProposition A.21: IftworandomvariablesX andY areindependent,then\nE(XY)=E(X)E(Y).\nExample A.22: LetX bearandomvariablethatassignstheoutcomeofarollof\ntwofairdicetotheproductofthenumberofdotsshowing.ThenE(X)=49/4.\nJustification: LetX andX berandomvariablesdenotingthenumberofdots\n1 2\noneachdie.ThevariablesX andX areclearlyindependent;hence,\n1 2\nE(X)=E(X X )=E(X )E(X )=(7/2)2 =49/4.\n1 2 1 2\nThefollowingboundandcorollariesthatfollowfromitareknownasChernoff\nbounds.\nProposition A.23: LetX bethesumofafinitenumberofindependent0/1ran-\ndomvariablesandlet\u00b5>0betheexpectedvalueofX.Then,for\u03b4>0\n\u03b4 \u00b5\ne\nPr(X >(1+\u03b4)\u00b5)< .\n\"(1+\u03b4)(1+\u03b4)\n#\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 695 \u2014 #717\ni i\nAppendixA.UsefulMathematicalFacts 695\nUseful Mathematical Techniques\nTocomparethegrowthratesofdifferentfunctions, itissometimeshelpfultoapply\nthefollowingrule.\nProposition A.24 (L\u2019H\u02c6opital\u2019s Rule): Ifwehavelim f(n)=+ andwe\nn\u2192\u221e\n\u221e\nhave lim g(n)=+ ,then lim f(n)/g(n)=lim f\u2032(n)/g\u2032(n),where\nn\u2192\u221e n\u2192\u221e n\u2192\u221e\n\u221e\nf\u2032(n)andg\u2032(n)denotethederivativesoff(n)andg(n),respectively.\nInderiving anupper orlowerbound forasummation, itisoften useful tosplit\nasummationasfollows\nn j n\n\u2211 \u2211 \u2211\nf(i)= f(i)+ f(i).\ni=1 i=1 i=j+1\nAnother useful technique is to bound a sum by an integral. If f is a non-\ndecreasing function, then,assumingthefollowingtermsaredefined\nb b b+1\n\u2211\nf(x)dx f(i) f(x)dx.\nZ a\u22121 \u2264 i=a \u2264Z a\nThere is a general form of recurrence relation that arises in the analysis of\ndivide-and-conquer algorithms\nT(n)=aT(n/b)+ f(n),\nforconstants a 1andb>1.\n\u2265\nProposition A.25: LetT(n)bedefinedasabove.Then:\n1. If f(n)isO(nlog b a\u2212\u03b5 ),forsomeconstant\u03b5>0,thenT(n)is\u0398(nlog b a)\n2. Iff(n)is\u0398(nlog b alogkn),forafixednonnegativeintegerk 0,thenT(n)is\n\u0398(nlog\nb\nalogk+1n) \u2265\n3. Iff(n)is\u2126(nlog b a+\u03b5 ),forsomeconstant\u03b5>0,andifaf(n/b) cf(n),then\nT(n)is\u0398(f(n)) \u2264\nThis proposition is known as the master method for characterizing divide-and-\nconquer recurrence relations asymptotically.\ni i\ni i\nThis page intentionally left blank\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 697 \u2014 #719\ni i\nBibliography\n[1] G. M. Adel\u2019son-Vel\u2019skii and Y. M. Landis, \u201cAn algorithm for the organization of\ninformation,\u201dDokladyAkademiiNaukSSSR,vol.146,pp.263\u2013266,1962. English\ntranslationinSovietMath.Dokl.,3,1259\u20131262.\n[2] A. Aggarwaland J. S. Vitter, \u201cThe input/outputcomplexity of sorting and related\nproblems,\u201dCommun.ACM,vol.31,pp.1116\u20131127,1988.\n[3] A. V. Aho, \u201cAlgorithms for finding patterns in strings,\u201d in Handbook of Theoreti-\ncal Computer Science (J. van Leeuwen, ed.), vol. A. Algorithmsand Complexity,\npp.255\u2013300,Amsterdam:Elsevier,1990.\n[4] A.V.Aho,J.E.Hopcroft,andJ.D.Ullman,TheDesignandAnalysisofComputer\nAlgorithms. Reading,MA:Addison-Wesley,1974.\n[5] A.V.Aho,J.E.Hopcroft,andJ.D.Ullman,DataStructuresandAlgorithms. Read-\ning,MA:Addison-Wesley,1983.\n[6] R.K.Ahuja,T.L.Magnanti,andJ.B.Orlin,NetworkFlows: Theory,Algorithms,\nandApplications. EnglewoodCliffs,NJ:PrenticeHall,1993.\n[7] R. Baeza-Yates and B. Ribeiro-Neto, Modern Information Retrieval. Reading,\nMass.: Addison-Wesley,1999.\n[8] O. Baruvka, \u201cO jistem problemu minimalnim,\u201d Praca Moravske Prirodovedecke\nSpolecnosti,vol.3,pp.37\u201358,1926. (inCzech).\n[9] R.Bayer,\u201cSymmetricbinaryB-trees: Datastructureandmaintenance,\u201dActaInfor-\nmatica,vol.1,no.4,pp.290\u2013306,1972.\n[10] R. Bayer and McCreight, \u201cOrganization of large ordered indexes,\u201d Acta Inform.,\nvol.1,pp.173\u2013189,1972.\n[11] J.L.Bentley,\u201cProgrammingpearls:Writingcorrectprograms,\u201dCommunicationsof\ntheACM,vol.26,pp.1040\u20131045,1983.\n[12] J.L.Bentley,\u201cProgrammingpearls: Thanks,heaps,\u201dCommunicationsoftheACM,\nvol.28,pp.245\u2013250,1985.\n[13] G.Booch,Object-OrientedAnalysisandDesignwithApplications. RedwoodCity,\nCA:Benjamin/Cummings,1994.\n[14] R. S.BoyerandJ.S.Moore,\u201cAfaststringsearchingalgorithm,\u201dCommunications\noftheACM,vol.20,no.10,pp.762\u2013772,1977.\n[15] G.Brassard,\u201cCrusadeforabetternotation,\u201dSIGACTNews,vol.17,no.1,pp.60\u2013\n64,1985.\n[16] T. Budd, An Introduction to Object-Oriented Programming. Reading, Mass.:\nAddison-Wesley,1991.\n[17] T.Budd,C++forJavaProgrammers. Reading,Mass.:Addison-Wesley,1999.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 698 \u2014 #720\ni i\n698 Bibliography\n[18] D. Burger, J. R. Goodman, and G. S. Sohi, \u201cMemory systems,\u201d in The Computer\nScience and Engineering Handbook(A. B. Tucker, Jr., ed.), ch. 18, pp. 447\u2013461,\nCRCPress,1997.\n[19] L.CardelliandP.Wegner,\u201cOnunderstandingtypes,dataabstractionandpolymor-\nphism,\u201dACMComputingSurveys,vol.17,no.4,pp.471\u2013522,1985.\n[20] S.Carlsson,\u201cAveragecaseresultsonheapsort,\u201dBIT,vol.27,pp.2\u201317,1987.\n[21] K. L. Clarkson, \u201cLinear programming in\nO(n3d2\n) time,\u201d Inform. Process. Lett.,\nvol.22,pp.21\u201324,1986.\n[22] R. Cole, \u201cTight bounds on the complexity of the Boyer-Moore pattern matching\nalgorithm,\u201dSIAMJournalonComputing,vol.23,no.5,pp.1075\u20131091,1994.\n[23] D.Comer,\u201cTheubiquitousB-tree,\u201dACMComput.Surv.,vol.11,pp.121\u2013137,1979.\n[24] T.H.Cormen,C.E.Leiserson,andR.L.Rivest,IntroductiontoAlgorithms. Cam-\nbridge,MA:MITPress,1990.\n[25] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction to Algo-\nrithms. Cambridge,MA:MITPress,2nded.,2001.\n[26] M.CrochemoreandT.Lecroq,\u201cPatternmatchingandtextcompressionalgorithms,\u201d\ninTheComputerScienceandEngineeringHandbook(A.B.Tucker,Jr.,ed.),ch.8,\npp.162\u2013202,CRCPress,1997.\n[27] S.A.Demurjian,Sr.,\u201cSoftwaredesign,\u201dinTheComputerScienceandEngineering\nHandbook(A.B.Tucker,Jr.,ed.),ch.108,pp.2323\u20132351,CRCPress,1997.\n[28] G.DiBattista,P.Eades,R.Tamassia,andI.G.Tollis,GraphDrawing.UpperSaddle\nRiver,NJ:PrenticeHall,1999.\n[29] E. W. Dijkstra, \u201cA note on two problems in connexion with graphs,\u201d Numerische\nMathematik,vol.1,pp.269\u2013271,1959.\n[30] J.R.Driscoll,H.N.Gabow,R.Shrairaman,andR.E.Tarjan,\u201cRelaxedheaps: An\nalternativetoFibonacciheapswithapplicationstoparallelcomputation.,\u201dCommun.\nACM,vol.31,pp.1343\u20131354,1988.\n[31] S.Even,GraphAlgorithms. Potomac,Maryland:ComputerSciencePress,1979.\n[32] R. W. Floyd, \u201cAlgorithm 97: Shortest path,\u201d Communicationsof the ACM, vol. 5,\nno.6,p.345,1962.\n[33] R. W. Floyd, \u201cAlgorithm 245: Treesort 3,\u201d Communications of the ACM, vol. 7,\nno.12,p.701,1964.\n[34] M.L.FredmanandR.E.Tarjan,\u201cFibonacciheapsandtheirusesinimprovednet-\nworkoptimizationalgorithms,\u201dJ.ACM,vol.34,pp.596\u2013615,1987.\n[35] E. Gamma, R. Helm, R. Johnson, and J. Vlissides, Design Patterns: Elements of\nReusableObject-OrientedSoftware. Reading,Mass.: Addison-Wesley,1995.\n[36] A.M.Gibbons,AlgorithmicGraphTheory. Cambridge,UK:CambridgeUniversity\nPress,1985.\n[37] G.H.GonnetandR.Baeza-Yates,HandbookofAlgorithmsandDataStructuresin\nPascalandC. Reading,Mass.: Addison-Wesley,1991.\n[38] G. H. Gonnet and J. I. Munro, \u201cHeaps on heaps,\u201d SIAM Journal on Computing,\nvol.15,no.4,pp.964\u2013971,1986.\n[39] M. T. Goodrich, M. Handy, B. Hudson, and R. Tamassia, \u201cAccessing the internal\norganization of data structures in the JDSL library,\u201d in Proc. Workshop on Algo-\nrithmEngineeringandExperimentation(M.T.GoodrichandC.C.McGeoch,eds.),\nvol.1619ofLectureNotesComput.Sci.,pp.124\u2013139,Springer-Verlag,1999.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 699 \u2014 #721\ni i\nBibliography 699\n[40] M. T. Goodrich, J.-J. Tsay, D. E. Vengroff, and J. S. Vitter, \u201cExternal-memory\ncomputationalgeometry,\u201dinProc.34thAnnu.IEEESympos.Found.Comput.Sci.,\npp.714\u2013723,1993.\n[41] R.L.GrahamandP.Hell,\u201cOnthehistoryoftheminimumspanningtreeproblem,\u201d\nAnnalsoftheHistoryofComputing,vol.7,no.1,pp.43\u201357,1985.\n[42] L. J. Guibas and R. Sedgewick, \u201cA dichromatic frameworkfor balanced trees,\u201d in\nProc.19thAnnu.IEEESympos.Found.Comput.Sci.,LectureNotesComput.Sci.,\npp.8\u201321,Springer-Verlag,1978.\n[43] Y. Gurevich, \u201cWhat does O(n) mean?,\u201d SIGACT News, vol. 17, no. 4, pp. 61\u201363,\n1986.\n[44] J. Hennessy and D. Patterson, Computer Architecture: A Quantitative Approach.\nSanFrancisco:MorganKaufmann,2nded.,1996.\n[45] C.A.R.Hoare,\u201cQuicksort,\u201dTheComputerJournal,vol.5,pp.10\u201315,1962.\n[46] J.E.HopcroftandR.E.Tarjan,\u201cEfficientalgorithmsforgraphmanipulation,\u201dCom-\nmunicationsoftheACM,vol.16,no.6,pp.372\u2013378,1973.\n[47] C.S.Horstmann,ComputingConceptswithC++Essentials. NeyYork:JohnWiley\nandSons,2nded.,1998.\n[48] B. Huang and M. Langston, \u201cPractical in-place merging,\u201d Communications of the\nACM,vol.31,no.3,pp.348\u2013352,1988.\n[49] J. Ja\u00b4Ja\u00b4, An Introductionto ParallelAlgorithms. Reading, Mass.: Addison-Wesley,\n1992.\n[50] V. Jarnik, \u201cO jistem problemu minimalnim,\u201d Praca Moravske Prirodovedecke\nSpolecnosti,vol.6,pp.57\u201363,1930. (inCzech).\n[51] R.E.Jones,GarbageCollection:AlgorithmsforAutomaticDynamicMemoryMan-\nagement. JohnWileyandSons,1996.\n[52] D.R.Karger,P.Klein,andR.E.Tarjan,\u201cArandomizedlinear-timealgorithmtofind\nminimumspanningtrees,\u201dJournaloftheACM,vol.42,pp.321\u2013328,1995.\n[53] R. M. Karp and V. Ramachandran, \u201cParallel algorithms for shared memory ma-\nchines,\u201d in Handbook of Theoretical Computer Science (J. van Leeuwen, ed.),\npp.869\u2013941,Amsterdam:Elsevier/TheMITPress,1990.\n[54] P. Kirschenhofer and H. Prodinger, \u201cThe path length of random skip lists,\u201d Acta\nInformatica,vol.31,pp.775\u2013792,1994.\n[55] J. Kleinberg and E. Tardos, Algorithm Design. Reading, MA: Addison-Wesley,\n2006.\n[56] D.E.Knuth,FundamentalAlgorithms,vol.1ofTheArtofComputerProgramming.\nReading,MA:Addison-Wesley,2nded.,1973.\n[57] D. E. Knuth,SortingandSearching,vol.3of TheArtofComputerProgramming.\nReading,MA:Addison-Wesley,1973.\n[58] D.E.Knuth,\u201cBigomicronandbigomegaandbigtheta,\u201dinSIGACTNews,vol.8,\npp.18\u201324,1976.\n[59] D.E.Knuth,FundamentalAlgorithms,vol.1ofTheArtofComputerProgramming.\nReading,MA:Addison-Wesley,3rded.,1997.\n[60] D. E. Knuth,SortingandSearching,vol.3of TheArtofComputerProgramming.\nReading,MA:Addison-Wesley,2nded.,1998.\n[61] D. E. Knuth, J. H. Morris, Jr., and V. R. Pratt, \u201cFast pattern matching in strings,\u201d\nSIAMJournalonComputing,vol.6,no.1,pp.323\u2013350,1977.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 700 \u2014 #722\ni i\n700 Bibliography\n[62] J. B. Kruskal, Jr., \u201cOn the shortest spanning subtree of a graph and the traveling\nsalesmanproblem,\u201dProc.Amer.Math.Soc.,vol.7,pp.48\u201350,1956.\n[63] N.G.LevesonandC.S.Turner,\u201cAninvestigationoftheTherac-25accidents,\u201dIEEE\nComputer,vol.26,no.7,pp.18\u201341,1993.\n[64] R. Levisse,\u201cSomelessonsdrawnfromthehistoryofthebinarysearchalgorithm,\u201d\nTheComputerJournal,vol.26,pp.154\u2013163,1983.\n[65] A. Levitin, \u201cDo we teach the right algorithm design techniques?,\u201d in 30th ACM\nSIGCSESymp.onComputerScienceEducation,pp.179\u2013183,1999.\n[66] S.Lippmann,EssentialC++. Reading,Mass.: Addison-Wesley,2000.\n[67] S.LippmannandJ.Lajoie,C++Primer. Reading,Mass.:Addison-Wesley,3rded.,\n1998.\n[68] B. Liskov and J. Guttag, Abstraction and Specification in Program Development.\nCambridge,Mass./NewYork:TheMITPress/McGraw-Hill,1986.\n[69] E.M.McCreight,\u201cAspace-economicalsuffixtreeconstructionalgorithm,\u201dJournal\nofAlgorithms,vol.23,no.2,pp.262\u2013272,1976.\n[70] C.J.H.McDiarmidandB.A.Reed,\u201cBuildingheapsfast,\u201dJournalofAlgorithms,\nvol.10,no.3,pp.352\u2013365,1989.\n[71] N.Megiddo,\u201cLinear-timealgorithmsforlinearprogramminginR3andrelatedprob-\nlems,\u201dSIAMJ.Comput.,vol.12,pp.759\u2013776,1983.\n[72] N. Megiddo,\u201cLinear programmingin linear time whenthe dimensionis fixed,\u201d J.\nACM,vol.31,pp.114\u2013127,1984.\n[73] K. Mehlhorn, Data Structures and Algorithms 1: Sorting and Searching, vol. 1\nof EATCS Monographs on Theoretical Computer Science. Heidelberg, Germany:\nSpringer-Verlag,1984.\n[74] K. Mehlhorn, Data Structures and Algorithms 2: Graph Algorithms and NP-\nCompleteness,vol.2ofEATCSMonographsonTheoreticalComputerScience.Hei-\ndelberg,Germany:Springer-Verlag,1984.\n[75] K.MehlhornandA.Tsakalidis,\u201cDatastructures,\u201dinHandbookofTheoreticalCom-\nputerScience(J.vanLeeuwen,ed.),vol.A.AlgorithmsandComplexity,pp.301\u2013\n341,Amsterdam:Elsevier,1990.\n[76] S.Meyers,MoreEffectiveC++. Reading,Mass.: Addison-Wesley,1996.\n[77] S.Meyers,EffectiveC++. Reading,Mass.: Addison-Wesley,2nded.,1998.\n[78] M.H.Morgan,Vitruvius: TheTenBooksonArchitecture. NewYork: DoverPubli-\ncations,Inc.,1960.\n[79] D. R. Morrison,\u201cPATRICIA\u2014practicalalgorithmto retrieveinformationcodedin\nalphanumeric,\u201dJournaloftheACM,vol.15,no.4,pp.514\u2013534,1968.\n[80] R.MotwaniandP.Raghavan,RandomizedAlgorithms. NewYork,NY:Cambridge\nUniversityPress,1995.\n[81] D.R.MusserandA.Saini,STLTutorialandReferenceGuide: C++Programming\nwiththeStandardTemplateLibrary. Reading,Mass.: Addison-Wesley,1996.\n[82] T. Papadakis, J. I. Munro, and P. V. Poblete, \u201cAverage search and update costs in\nskiplists,\u201dBIT,vol.32,pp.316\u2013332,1992.\n[83] P.V.Poblete,J.I.Munro,andT.Papadakis,\u201cThebinomialtransformanditsappli-\ncationtotheanalysisofskiplists,\u201d inProceedingsoftheEuropeanSymposiumon\nAlgorithms(ESA),pp.554\u2013569,1995.\n[84] I.Pohl,C++ForCProgrammers. Reading,Mass.: Addison-Wesley,3rded.,1999.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 701 \u2014 #723\ni i\nBibliography 701\n[85] R. C. Prim, \u201cShortest connection networks and some generalizations,\u201d Bell Syst.\nTech.J.,vol.36,pp.1389\u20131401,1957.\n[86] W.Pugh,\u201cSkiplists: aprobabilisticalternativetobalancedtrees,\u201dCommun.ACM,\nvol.33,no.6,pp.668\u2013676,1990.\n[87] H. Samet, The Design and Analysis of Spatial Data Structures. Reading, MA:\nAddison-Wesley,1990.\n[88] R. Schafferand R. Sedgewick, \u201cThe analysis of heapsort,\u201d Journalof Algorithms,\nvol.15,no.1,pp.76\u2013100,1993.\n[89] D.D.SleatorandR.E.Tarjan,\u201cSelf-adjustingbinarysearchtrees,\u201dJ.ACM,vol.32,\nno.3,pp.652\u2013686,1985.\n[90] G.A.Stephen,StringSearchingAlgorithms. WorldScientificPress,1994.\n[91] B.Stroustrup,TheC++ProgrammingLanguage.Reading,Mass.:Addison-Wesley,\n3rded.,1997.\n[92] R.TamassiaandG.Liotta,\u201cGraphdrawing,\u201dinHandbookofDiscreteandCompu-\ntationalGeometry(J.E.GoodmanandJ.O\u2019Rourke,eds.),CRCPress, seconded.,\n2004.\n[93] R.TarjanandU.Vishkin,\u201cAnefficientparallelbiconnectivityalgorithm,\u201dSIAMJ.\nComput.,vol.14,pp.862\u2013874,1985.\n[94] R. E. Tarjan, \u201cDepth first search and linear graph algorithms,\u201d SIAM Journal on\nComputing,vol.1,no.2,pp.146\u2013160,1972.\n[95] R. E. Tarjan, Data StructuresandNetwork Algorithms, vol. 44 of CBMS-NSF Re-\ngional Conference Series in Applied Mathematics. Philadelphia, PA: Society for\nIndustrialandAppliedMathematics,1983.\n[96] A. B. Tucker,Jr., The ComputerScienceandEngineeringHandbook. CRC Press,\n1997.\n[97] J. D. Ullman, Principles of Database Systems. Potomac, MD: Computer Science\nPress,1983.\n[98] J.vanLeeuwen,\u201cGraphalgorithms,\u201dinHandbookofTheoreticalComputerScience\n(J. van Leeuwen, ed.), vol. A. Algorithms and Complexity, pp. 525\u2013632, Amster-\ndam:Elsevier,1990.\n[99] J.S.Vitter,\u201cEfficientmemoryaccessinlarge-scalecomputation,\u201dinProc.8thSym-\npos. Theoret. Aspects Comput. Sci., Lecture Notes Comput. Sci., Springer-Verlag,\n1991.\n[100] J.S.VitterandW.C.Chen,DesignandAnalysisofCoalescedHashing. NewYork:\nOxfordUniversityPress,1987.\n[101] J.S.VitterandP.Flajolet,\u201cAverage-caseanalysisofalgorithmsanddatastructures,\u201d\ninAlgorithmsandComplexity(J.vanLeeuwen,ed.),vol.AofHandbookofTheo-\nreticalComputerScience,pp.431\u2013524,Amsterdam:Elsevier,1990.\n[102] S. Warshall, \u201cA theorem on boolean matrices,\u201d Journalof the ACM, vol. 9, no. 1,\npp.11\u201312,1962.\n[103] J.W.J.Williams,\u201cAlgorithm232: Heapsort,\u201dCommunicationsoftheACM,vol.7,\nno.6,pp.347\u2013348,1964.\n[104] D.Wood,DataStructures,Algorithms,andPerformance.Reading,Mass.:Addison-\nWesley,1993.\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 702 \u2014 #724\ni i\nIndex\nabove,403,405\u2013407,419 ADT,seeabstractdatatype\nabstract,88 after,403,405,406\nabstractclass,88 Aggarwal,687\nabstractdatatype,viii,68 Aho,226,266,320,497,551,592\ndeque,217 Ahuja,663\ndictionary,411\u2013412 algorithm,162\ngraph,594\u2013600 algorithmanalysis,162\u2013180\nlist,240\u2013242 averagecase,165\u2013166\nmap,368\u2013372 worstcase,166\norderedmap,394 alphabet,555\npartition,538\u2013541 amortization,234\u2013235,538\u2013541\npriorityqueue,322\u2013329 ancestor,270,625\nqueue,208\u2013211 antisymmetric,323\nsequence,255 API,seeapplicationprogramminginter-\nset,533\u2013541 face\nstack,195\u2013198 applicationprogramminginterface,87,196\nstring,554\u2013556 arc,594\ntree,272\u2013273 Archimedes,162,192\nvector,228\u2013229 arguments\nabstraction,68 actual,28\n(a,b)tree,680\u2013682 formal,28\ndepthproperty,680 Ariadne,607\nsizeproperty,680 array,8\u20139,104\u2013116\naccesscontrol,34 matrix,112\naccessspecifier,34 two-dimensional,111\u2013116\naccessorfunctions,35 arraylist,seevector\nactualarguments,28 assignmentoperator,42\nacyclic,626 associativecontainers,368\nadaptability,66,67 associativestores,368\nadaptablepriorityqueue,357 asymmetric,595\nadapter,221 asymptoticanalysis,170\u2013180\nadapterpattern,220\u2013222 asymptoticnotation,166\u2013170\nadd,340\u2013345,348,364 big-Oh,167\u2013169,172\u2013180\naddress-of,7 big-Omega,170\naddRoot,291,292 big-Theta,170\nAdel\u2019son-Vel\u2019skii,497 at,228\u2013230,396\nadjacencylist,600,603 atIndex,255\u2013258,260\nadjacencymatrix,600,605 attribute,611\nadjacent,595 AVLtree,438\u2013449\n702\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 703 \u2014 #725\ni i\nIndex 703\nbalancefactor,446 Boyer,592\nheight-balanceproperty,438 Brassard,192\nbreadth-firstsearch,623\u2013625,630\nback,217,220,519 breadth-firsttraversal,283\nbackedge,609,629,630,657 breakpoint,59\nBaeza-Yates,497,551,592,687 bruteforce,564\nbag,420 brute-force,564\nbalancefactor,446 brute-forcepatternmatching,564\nbalancedsearchtree,464 B-tree,682\nBaru\u02davka,661,663 bubble-sort,259\u2013261,266\nbaseclass,71 bucketarray,375\nBayer,687 bucket-sort,528\u2013529\nbefore,403,405\u2013407,419 bucketSort,528\nbegin,240,241,245,258,332,370,374, Budd,64,102\n390,391,412,424,435,600 Burger,687\nbelow,403\u2013405 byreference,29\nBentley,366,421 byvalue,28\nbest-fitalgorithm,670\nBFS,seebreadth-firstsearch C++,2\u201364,71\u201397\nbiconnectedgraph,660 array,8\u20139\nbig-Ohnotation,167\u2013169,172\u2013180 arrays,104\u2013116\nbig-Omeganotation,170 break,24\nbig-Thetanotation,170 callstack,666\u2013668\nbinaryrecursion,144 casting,20\u201322,86\u201387\nbinarysearch,300,395\u2013398 class,32\u201344\nbinarysearchtree,424\u2013437 comments,3\ninsertion,428\u2013429 const,14\nremoval,429 constantreference,29,197,211,329\nrotation,442 controlflow,23\u201326\ntrinoderestructuring,442 default,24\nbinarytree,284\u2013294,309,501 defaultarguments,37,200\ncomplete,338,340\u2013343 dependenttypenames,334\nfull,284 dynamicbinding,76\nimproper,284 exceptions,93\u201397\nleftchild,284 expressions,16\u201322\nlevel,287 extern,47\nlinkedstructure,289\u2013294 functions,26\u201332\nproper,284 fundamentaltypes,4\u20137\nrightchild,284 globalscope,14\u201315\nvectorrepresentation,295\u2013296 headerfile,48\nbinomialexpansion,690 input,19\nbipartitegraph,661 localscope,14\u201315\nbitvector,547 mainfunction,3\nblock,14 memoryallocation,11\u201313,40\u201342\nblocking,675 multipleinheritance,84\nBooch,102 namebinding,334\nbootstrapping,463 output,19\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 704 \u2014 #726\ni i\n704 Index\noverloading,30\u201332 public,34,74\npointer,7\u20138 template,91\nreference,13 classinheritancediagram,72\nstaticbinding,76 classscopeoperator,73\nstring,10 clock,163\nstruct,10\u201311 clustering,385\ntemplates,90\u201392 coding,53\ntypename,334 Cole,592\nvirtualdestructor,77 collisionresolution,376,382\u2013386\nC-stylecast,21 collision-resolution,382\nC-stylestrings,10 Comer,687\nC-stylestructure,11 comparator,325\ncache,673 compiler,2\ncacheline,675 completebinarytree,338,340\u2013343\ncachingalgorithms,676\u2013678 completegraph,657\ncall-by-value,667 compositionpattern,369\nCardelli,102,226 compressionfunction,376,381\nCarlsson,366 conditionalprobability,693\ncast,20 connectedcomponents,598,610,625\ncasting,20\u201322 constantfunction,154\ndynamic,87 constructor,33,37\nexplicit,21 container,236,239\u2013240,247\u2013255\nimplicit,22 contradiction,181\nstatic,22 contrapositive,181\ncatchblocks,94 copyconstructor,37,42\nceilingfunction,161 corememory,673\nceilingEntry,394,396,399,401,410 Cormen,497,663\ncharacter-jumpheuristic,566 CRCcards,55\nChernoffbound,551,694 Crochemore,592\nchild,269 crossedge,625,629,630\nchildclass,71 cubicfunction,158\nchildren,269 cursor,129,242\nchildren,272,274,277,279,286 cycle,597\nChineseRemainderTheorem,63 directed,597\ncircularlylinkedlist,129,265\nClarkson,551 DAG,seedirectedacyclicgraph\nclass,2,32\u201344,66,68 datamember,33\nabstract,88\u201390 datapackets,265\nconstructor,37\u201339,75 datastructure,162\ndestructor,39,75 secondary,464\nfriend,43 debugger,59\ninheritance,71\u201387 debugging,53\ninterface,87 decisiontree,284,426,526\nmember,33 decoratorpattern,611\u2013622\nmemberfunctions,35\u201340 decrease-and-conquer,seeprune-and-search\nprivate,34,74 defaultarguments,37,200\nprotected,74 defaultconstructor,37\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 705 \u2014 #727\ni i\nIndex 705\ndegree,158,595 doublered,475\ndegree,610,644 double-endedqueue,seedeque\nDeMorgan\u2019sLaw,181 double-hashing,385\nDemurjian,102,226 doublylinkedlist,123\u2013128,133\u2013134\ndepth,275\u2013277 down-heapbubbling,346,355\ndepth-firstsearch,607\u2013621,629 dynamicbinding,76\ndeque,217\u2013220 dynamiccast,87\nabstractdatatype,217 dynamicprogramming,146,557\u2013563,631\nlinked-listimplementation,218\u2013220\ndereferencing,7 Eades,320,663\ndescendent,270,625 edge,271,594\ndesignpatterns,viii,55,70 destination,595\nadapter,220\u2013222 endvertices,595\namortization,234\u2013235 incident,595\nbruteforce,564 multiple,596\ncomparator,324\u2013327 origin,595\ncomposition,369 outgoing,595\ndecorator,611\u2013622 parallel,596\ndivide-and-conquer,500\u2013504,513\u2013 self-loop,596\n514 edgelist,600\ndynamicprogramming,557\u2013563 edgeliststructure,601\ngreedymethod,577 edges,599,602,604,606\niterator,239\u2013242 editdistance,590,592\nposition,239\u2013240 element,239,257,506,519\nprune-and-search,542\u2013544 elementuniquenessproblem,179\ntemplatefunction,303\u2013308 empty,195,197\u2013199,202,205,209,210,\ntemplatemethod,535,616 213, 215, 217, 220, 221, 228,\ndest,626 230, 240, 245, 258, 272, 274,\ndestination,595 286, 294, 295, 297, 327\u2013329,\ndestructor,37,39,42 332, 333, 344, 348, 349, 355,\nDFS,seedepth-firstsearch 359, 370, 371, 398, 410\u2013412,\nDiBattista,320,663 424, 431, 445, 472, 487, 519,\ndiameter,316 551,635\ndictionary,411\u2013412 encapsulation,68\nabstractdatatype,411\u2013412 end, 240, 241, 245, 247, 258, 370, 371,\ndigraph,626 374, 382, 389, 390, 392, 394,\nDijkstra,663 396, 401, 411, 412, 414, 424,\nDijkstra\u2019salgorithm,639\u2013644 434,435,533,600\ndirectedacyclicgraph,633\u2013635 endvertices,595\ndirectedcycle,626 endpoints,595\ndiscoveryedge,609,625,629,630 endVertices,599,601,602,604,606,626\ndistance,638 entry,368\ndivide-and-conquer,500\u2013504,513\u2013514 erase,228\u2013231,241,246,258,370\u2013372,\ndivisionmethod,381 374, 381\u2013384, 395, 398, 401,\nd-node,461 407, 408, 410, 412, 415, 416,\ndo-whileloop,24 418, 424, 428, 429, 431, 444,\ndoubleblack,480 445,472,487,494,495,681\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 706 \u2014 #728\ni i\n706 Index\neraseAll,494 firstEntry,394,410\neraseBack,217,220,231,241,248,519 floorfunction,161\neraseEdge,599,602,604,606 floorEntry,394,396,399,401,410\neraseFront,217,220,221,231,241,248, Floyd,366\n506,519 Floyd-Warshallalgorithm,631,663\neraseVertex,599,602,604,606,654 forloop,25\nEuclid\u2019sAlgorithm,63 forest,598\nEulerpath,654 formalarguments,28\nEulertour,654,658 forwardedge,629\nEulertourtraversal,301,320 fragmentation,670\nEven,663 frame,666\nevent,693 freelist,670\nevolvability,67 freestore,11\nexceptions,93\u201397 friend,43\ncatching,94 front,217,220,221,506,509\ngeneric,97 fullbinarytree,284\nspecification,96 function,26\nthrowing,94 functionobject,324\nEXIT SUCCESS,4 functionoverloading,30\nexpandExternal,291\u2013295,297,317 functiontemplate,90\nexpectedvalue,693 functional-stylecast,21\nexplicitcast,22 functions,26\u201332\nexponentfunction,seeexponentialfunc- arguments,28\u201330\ntion arrayarguments,30\nexponentialfunction,159 declaration,27\nexponentiation,176 defaultarguments,37,200\nexpression,16 definition,27\nexpressions,16\u201322 passbyreference,28\nextension,79 passbyvalue,28\nexternalmemory,673\u2013684,688 prototype,27\nexternal-memoryalgorithm,673\u2013684 signature,27\nexternal-memorysorting,683\u2013684 template,90\nvirtual,76\nfactorial,134\u2013135,690 fusion,470,681,682\nfailurefunction,570\nFibonacciprogression,82,691 gametree,319\nfield,10 Gamma,102\nFIFO,208 garbagecollection,671\u2013672\nfind,370,371,374,381\u2013384,392,395\u2013 mark-sweep,671\n398, 404, 408, 410\u2013412,424\u2013 Gauss,157\n427, 431, 436, 440, 445, 472, genericmergealgorithm,535\n487,681 geometricsum,692\nfindAll,411\u2013415,418,419,424,427,432, get,384,612,613\n437,494 Gibbons,663\nfirst,494 global,14\nfirst-fitalgorithm,670 goldenratio,691\nfirst-infirst-out,208 Gonnet,366,497,551,687\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 707 \u2014 #729\ni i\nIndex 707\nGoodrich,688 header,123\nGraham,663 headerfile,48\ngraph,594\u2013663 headerfiles,3\nabstractdatatype,594\u2013600 heap,337\u2013356\nacyclic,626 bottom-upconstruction,353\u2013356\nbreadth-firstsearch,623\u2013625,628\u2013 heapmemory,11\n630 heap-orderproperty,337\nconnected,598,625 heap-sort,351\u2013356\ndatastructures,600\u2013606 height,275\u2013277,431\nadjacencylist,603\u2013604 height-balance property, 438, 440, 442,\nadjacencymatrix,605\u2013606 444\nedgelist,600\u2013602 Hell,663\ndense,611,633 Hennessy,687\ndepth-firstsearch,607\u2013621,628\u2013630 hierarchical,268\ndigraph,626 hierarchy,69\ndirected,594,595,626\u2013635 higherEntry,394,396,399,401,410\nacyclic,633\u2013635 Hoare,551\nstronglyconnected,626 Hopcroft,226,266,320,497,551,663\nfunctions,599\u2013600 Horner\u2019smethod,191\nmixed,595 Horstmann,64\nreachability,626\u2013627,630\u2013633 HTMLtags,205\nshortestpaths,630\u2013633 Huang,551\nsimple,596 Huffmancoding,575\u2013576\nsparse,611\ntraversal,607\u2013625 I/Ocomplexity,679\nundirected,594,595 ifstatement,23\nweighted,637\u2013663 implicitcast,22\ngraph-traversal,607 improperbinarytree,284\ngreedymethod,577,638,639 in-degree,595\ngreedy-choice,577 in-place,523,672\nGuibas,497 incidencecollection,603\nGuttag,102,226 incident,595\nincidentEdges,599,602,604,606,609\u2013\nHarmonicnumber,178,191,692 611,613,623\nhashcode,376 incomingedges,595\nhashfunction,376,385 independent,693,694\nhashtable,375\u2013394 index,8,228,368,395\ncapacity,375 indexOf,255\u2013258\nchaining,382 induction,182\u2013183\nclustering,385 infix,314\ncollision,376 informalinterface,88\ncollisionresolution,382\u2013386 inheritance,71\u201387\ndoublehashing,385 initializerlist,39\nlinearprobing,384 inordertraversal,425,429,441,442\nopenaddressing,385 insert,228\u2013231,241,245\u2013247,258,323,\nquadraticprobing,385 327\u2013332, 334, 336, 344, 346,\nrehashing,386 348, 350, 351, 353, 357\u2013360,\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 708 \u2014 #730\ni i\n708 Index\n381, 395, 398, 408, 410\u2013414, Kleinberg,551\n418, 424, 428, 431, 436, 440, Knuth,152,192,266,320,366,497,551,\n444,445,472,487,495,681 592,663,687\ninsertAfterAbove,405,406 Kosaraju,663\ninsertAtExternal,428,440,441 Kruskal,663\ninsertBack,217,220,221,231,241,245\u2013 Kruskal\u2019salgorithm,647\u2013650\n248, 258, 374, 505, 506, 509,\n519 L\u2019Ho\u02c6pital\u2019sRule,695\ninsertDirectedEdge,626,631 Lajoie,64,266\ninsertEdge,599,602,604,606 Landis,497\ninsertFront,217,220,221,231,240,241, Langston,551\n245,246,248,257,258 last-infirst-out,194\ninsertion-sort,109,336 lastEntry,394,410\ninsertVertex,599,602,604,606,654 LCS,seelongestcommonsubsequence\nintegraltypes,5 leaves,270\nintegrateddevelopmentenvironment,56 Lecroq,592\ninterface,87,88,196 left, 286, 294, 295, 297\u2013299, 302\u2013304,\ninternalmemory,673 426,428\nInternet,265 leftchild,284\ninversion,336,549 leftsubtree,284\ninversions,531 Leiserson,497,663\ninvertedfile,548 level,287,623\nisAdjacentTo, 599, 602, 604, 606, 631, levelnumbering,295\n655 levelordertraversal,317\nisDirected,626 Levisse,421\nisExternal,272,274,276,277,286,294, lexicographicordering,324\n295,297,303,426 lexicographical,529\nisIncidentOn,599,602,604,606 life-criticalapplications,66\nisInternal,272,428 LIFO,194\nisRoot, 272, 274, 275, 286, 294, 295, linearexponential,692\n297 linearfunction,156\nIterator,411,413 linearprobing,384\niterator,239\u2013242,600 linearityofexpectation,544,694\nbidirectional,250,372 linkedlist,117\u2013134,202\u2013203,213\u2013216\nconst,251 circularlylinked,129\u2013132,213\u2013216\nrandomaccess,250,343 cursor,129\ndoubly linked, 123\u2013128, 133\u2013134,\nJa\u00b4Ja\u00b4,320 218\u2013220,242\u2013247,255\u2013258\nJarn\u00b4\u0131k,663 header,123\nJDSL,266 sentinel,123\nJones,687 singlylinked,117\u2013122\ntrailer,123\nKarger,663 linkedstructure,274,289\nKarp,320 linker,3,47\nkey,322,368,461 linkingout,124\nkey,374,396,401,404,405,426,528 Liotta,320,663\nKlein,663 Lippmann,64,266\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 709 \u2014 #731\ni i\nIndex 709\nLiskov,102,226 member,10,33,66\nlist,228,238\u2013255 memberfunction,66\nabstractdatatype,240\u2013242 memberselectionoperator,11\nimplementation,242\u2013247 membervariable,33\nliteral,5 memberfunction,33\nLittman,551 memoryallocation,670\nliveobjects,671 memoryheap,669\nloadfactor,383 memoryhierarchy,673\nlocal,14 memoryleak,13\nlocality-of-reference,675 memorymanagement,666\u2013672,676\u2013678\nlocator-awareentry,360 merge,505,506\nlog-star,541 merge-sort,500\u2013513\nlogarithmfunction,154,689 multi-way,683\u2013684\nnatural,689 tree,501\nlongestcommonsubsequence,560\u2013563 mergeableheap,495\nlooking-glassheuristic,566 method,33,66\nloopinvariant,184 Meyers,64\nlowerEntry,394,396,399,410 min, 323, 327\u2013332, 334\u2013336, 344, 348,\nlowestcommonancestor,316 349,359,577\nlvalue,16 minimax,319\nminimumspanningtree,645\u2013652\nMagnanti,663 Kruskal\u2019salgorithm,647\u2013650\nmainmemory,673 Prim-Jarnikalgorithm,651\u2013652\nmap,368 Minotaur,607\n(2,4)tree,461\u2013472 modularity,68\nabstractdatatype,368\u2013372 modulo,212,690\nAVLtree,438\u2013449 Moore,592\nbinarysearchtree,424\u2013437 Morris,592\nhashtable,375\u2013394 Morrison,592\nordered,431 Motwani,421,551\nred-blacktree,473\u2013490 MST,seeminimumspanningtree\nskiplist,402\u2013410 multi-waysearchtree,461\nupdateoperations,405,407,428,429, multi-waytree,461\u2013464\n440,444 multipleinheritance,84\nmap,372 multiplerecursion,147\nmark-sweepalgorithm,671 Munro,366\nmastermethod,695 Musser,64,266\nmatrix,112 mutuallyindependent,693\nmatrixchain-product,557\u2013559\nMatrixChain,559 n-log-nfunction,156\nmaximalindependentset,659 namespace,15\nMcCreight,592,687 naturaljoin,265\nMcDiarmid,366 naturallogarithm,689\nmedian,542 nestedclass,44\nmedian-of-three,525 next-fitalgorithm,670\nMegiddo,551 node,238,269,272,594\nMehlhorn,497,663,687 ancestor,270\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 710 \u2014 #732\ni i\n710 Index\nbalanced,440 override,78\nchild,269\ndescendent,270 palindrome,151,590\nexternal,270 parent,269\ninternal,270 parent,272,274,275,286,294,295,297\nparent,269 parentclass,71\nredundant,582 parentheticstringrepresentation,279\nroot,269 partition,538\u2013541\nsibling,270 path,271,597\nsize,456 directed,597\nunbalanced,440 length,638\nNonexistentElement,372 simple,597\nnontreeedge,629,630 pathcompression,541\nnullpointer,8 pathlength,317\nnullstring,555 patternmatching,564\u2013573\nnumericprogression,79 Boyer-Moorealgorithm,566\u2013570\nbruteforce,564\u2013565\nobject,66 Knuth-Morris-Prattalgorithm,570\u2013\nobject-orienteddesign,66\u2013102 573\nopen-addressing,384,385 Patterson,687\noperatoroverloading,19,31 Pohl,64\noperators,16\u201322 pointer,7\u20138\narithmetic,16 pointerarithmetic,252\nassignment,18 polymorphic,78\nbitwise,18 polymorphism,78\ndelete,12 polynomial,158,190\nincrement,17 portability,67\nindexing,16 position,239\u2013240,272,403\nnew,11\u201313 positionalgames,111\nprecedence,19\u201320 positions, 272,274, 276, 286,291, 294,\nrelational,17 295,297\nscope,36,73 post-increment,17\nopposite, 599, 601, 602, 604, 606, 609, postfixnotation,224,314\n610,613,623 postordertraversal,281\norderstatistic,542 powerfunction,176\norderdmap,394\u2013401 Pratt,592\nabstractdatatype,394 pre-increment,17\norderedmap precedence,19\nsearchtable,395\u2013398 prefix,555\norigin,595 prefixcode,575\norigin,626 prefixsum,175\nOrlin,663 preorder,278\nout-degree,595 preprocessor,48\noutgoingedge,595 Prim,663\noverflow,467 Prim-Jarnikalgorithm,651\u2013652\noverflows,682 primitiveoperations,164\u2013166\nOverloading,30 priorityqueue,322\u2013366,549\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 711 \u2014 #733\ni i\nIndex 711\nadaptable,357\u2013360 binary,144\u2013146\nADT,327 higher-order,144\u2013148\nheapimplementation,344\u2013348 linear,140\u2013143\nlistimplementation,331\u2013335 multiple,147\u2013148\nprioritysearchtree,365 tail,143\npriority queue,330 traces,141\u2013142\nprivate,34 recursiontrace,135\nprivateinheritance,86 red-blacktree,473\u2013490\nprobability,692\u2013694 depthproperty,473\nprobabilityspace,693 externalproperty,473\nprocedure,27 internalproperty,473\nprogramcounter,666 recoloring,477\nprotectedinheritance,86 rootproperty,473\nprotocol,54 Reed,366\nprune-and-search,542\u2013544 reference,13\npseudo-code,54\u201355 reflexive,323\npseudo-randomnumbergenerators,402 rehashing,386\npublic,34 reinterpretcast,380\npublicinterface,33,34 relaxation,640\nPugh,421 remove,340\u2013343,346,348,357\u2013360,364,\npurevirtual,88 365\nput, 370, 371, 373, 374, 382, 383, 385, removeMin,323,327\u2013330,332,334\u2013336,\n392,401,424 346, 348, 350, 351, 357, 359,\n577,640,644,647,651\nquadraticfunction,156 removeAboveExternal,291\u2013295,297,429,\nquadraticprobing,385 444,495\nqueue,208\u2013216 replace,357\u2013360,644\nabstractdatatype,208\u2013211 restructure,442\narrayimplementation,211\u2013213 restructure,442,444,446,476,480,484\nlinked-listimplementation,213\u2013216 reusability,66,67\nQueueEmpty,210,329 reverseDirection,630\nquick-sort,513\u2013525 Ribeiro-Neto,592\ntree,514 right,286,294,295,297\u2013299,302\u2013304,\nquickSelect,543 426\nquine,100 rightchild,284\nrightsubtree,284\nradix-sort,529\u2013530 Rivest,497,663\nRaghavan,421,551 robustness,66\nRamachandran,320 root,269\nrandomvariable,693 root,272,274,278,286,291,294,295,\nrandomization,402,403 297, 304, 310\u2013312, 426, 428,\nrandomizedquick-select,543 429\nrandomizedquick-sort,521 rootobjects,671\nrank,228 rotation,442\nreachability,626 double,442\nrecurrenceequation,511,544,547 single,442\nrecursion,134\u2013148,668\u2013669 runningtime,162\u2013180\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 712 \u2014 #734\ni i\n712 Index\nSaini,64,266 Sleator,497\nSamet,687 slicingfloorplan,318\nsamplespace,692 slicingtree,318\nscanforward,404 sorting,109,329\u2013330,500\u2013530\nSchaffer,366 bubble-sort,259\u2013261\nscheduling,366 bucket-sort,528\u2013529\nscope,14 external-memory,683\u2013684\nsearchengine,534,586 heap-sort,351\u2013356\nsearchtable,395\u2013398 in-place,352,523\nsearchtrees,424 insertion-sort,109,336\nSedgewick,366,497 lowerbound,526\u2013527\nseed,402 merge-sort,500\u2013513\nselection,542\u2013544 priority-queue,329\u2013330\nselection-sort,335 quick-sort,513\u2013525\nself-loop,596 radix-sort,529\u2013530\nsentinel,123 selection-sort,335\nseparatechaining,382 stable,529\nsequence,228,255\u2013261 Sourcefiles,47\nabstractdatatype,255 spaceusage,162\nimplementation,255\u2013258 spanningsubgraph,598\nset,533\u2013541 spanning tree, 598, 609, 610, 623, 625,\nset,228\u2013230,612,613 645\nshallowcopy,41 sparsearray,265\nshortestpath,638\u2013644 specialization,78\nDijkstra\u2019salgorithm,639\u2013644 splaytree,450\u2013460\nsibling,270 split,467,682\nsibling,295 stable,529\nsievealgorithm,418 stack,194\u2013208\nsignature,31 abstractdatatype,195\u2013198\nsinglylinkedlist,117\u2013122 arrayimplementation,198\u2013201\nsize, 195, 197\u2013199, 202, 209, 210, 213, linked-listimplementation,202\u2013203\n215, 217, 220, 221, 228, 230, StackEmpty,197\n240, 245, 258, 272, 274, 286, standardcontainers,45\n294, 295, 297, 327\u2013329, 332, standarderror,4\n333, 344, 348, 349, 359, 370, standardinput,4\n371, 398, 410\u2013412, 424, 431, standardlibrary,4\n445, 472, 487, 505, 519, 551, standardoutputstream,4\n577 StandardTemplateLibrary,seeSTL\nskiplist,402\u2013410 statements\nanalysis,408\u2013410 break,26\ninsertion,405 continue,26\nlevels,403 do-while,24\nremoval,407\u2013408 for,25\nsearching,404\u2013405 if,23\ntowers,403 include,48\nupdateoperations,405\u2013408 namespace,15\nSkipSearch,404,405 switch,23\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 713 \u2014 #735\ni i\nIndex 713\ntypedef,14 summation,159,691\nusing,4,16 geometric,160\nwhile,24 summationpuzzles,147\nstaticbinding,76 superclass,71\nstdnamespace switchstatement,23\ncerr,4 symmetric,594\ncin,4\ncout,4 Tamassia,320,663\nendl,4 Tardos,551\nStein,497 Tarjan,320,497,663\nStephen,592 telescopingsum,691\nStirling\u2019sApproximation,691 template,45\nSTL,45\u201347,266 templatefunctionpattern,303\u2013308\ncontainer,236,247\u2013255 templatemethod,534\ndeque,218 templatemethodpattern,535,616\niterator,248\u2013255 templates,90\u201392\nlist,247\u2013255,509 testing,53\nmap,372\u2013373,488 textcompression,575\u2013576\nmultimap,488 Theseus,607\npriority queue,330 this,41\nqueue,209\u2013210 three-waysetdisjointness,178\nset,533 Tic-Tac-Toe,114\nstack,196 tic-tac-toe,319\nstring,10,46\u201347,555\u2013556 token,204\nvector, 45\u201346, 113\u2013114, 236\u2013237, Tollis,320,663\n249\u2013255 topologicalordering,634\u2013635\nstopwords,580,591 totalorder,323\nstraggling,546 tower-of-twos,541\nstring TowersofHanoi,151\nabstractdatatype,554\u2013556 trailer,123\nnull,555 transfer,470\nprefix,555 transitive,323\nsuffix,555 transitiveclosure,626,629\nstrongtyping,86 travelingsalesmanproblem,639\nstronglyconnected,626 tree,269\u2013277,598\nStroustrup,64,266 abstractdatatype,272\u2013273\nstructure,10 binary,seebinarytree\nstub,58 binarytreerepresentation,309\nsubclass,71 childnode,269\nsubgraph,598 decision,284\nsubproblemoptimality,558 depth,275\u2013277\nsubproblemoptimization,560 edge,271\nsubproblemoverlap,560 externalnode,270\nsubsequence,560 height,275\u2013277\nsubstring,554 internalnode,270\nsubtree,270 level,287\nsuffix,555 linkedstructure,274\u2013275\ni i\ni i\ni i\n\u201cmain\u201d \u2014 2011/1/13 \u2014 9:10 \u2014 page 714 \u2014 #736\ni i\n714 Index\nmulti-way,461\u2013464 virtualfunctions,76\nnode,269 virtualmemory,675\nordered,271 Vishkin,320\nparentnode,269 Vitter,687,688\npath,271\nrootnode,269 Wegner,102,226\ntreeedge,629,630 whileloop,24\ntreereflection,314 Williams,366\ntreetraversal,278\u2013283,297\u2013308 Wood,266\nEulertour,301\u2013308 worst-fitalgorithm,671\ngeneric,303\u2013308 wrapper,221\ninorder,299\u2013301\nzig,451,458\nlevelorder,317\nzig-zag,451,458\npostorder,281\u2013283,297\u2013299\nzig-zig,450,458\npreorder,278\u2013280,297\ntrees,268\nTreeSearch,426,427,429,494\ntriangulation,588\ntrie,578\u2013586\ncompressed,582\nstandard,578\ntrinoderestructuring,441,476\ntryblock,94\ntry-catchblock,95\nTsakalidis,497\n(2,4)tree,461\u2013472\ndepthproperty,465\nsizeproperty,465\ntypename,334\nUllman,226,266,320,497,551,687\nunderflow,470,682\nunion-by-size,540\nunion-find,538\u2013541\nup-heapbubbling,346\nupdatefunctions,35\nvalue,401\nvanLeeuwen,663\nvector,228\u2013237,395\nabstractdatatype,228\u2013229\nimplementation,229\u2013237\nvertex,594\ndegree,595\nin-degree,595\nout-degree,595\nvertices,599,602,604,606,635\ni i\ni i\n",
  "context": "This page intentionally left blank\nwww.allitebooks.com\ni i",
  "source_file": "resources\\Year 1\\C++ Docs\\Data Structures and Algorithms in C++, 2nd edition.pdf",
  "line_numbers": [
    5,
    31562
  ]
}